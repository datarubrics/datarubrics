Precedence-Constrained Winter Value for Effective
Graph Data Valuation
Hongliang Chi1 Wei Jin2 Charu Aggarwal3 Yao Ma1
1Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY 12180
2Department of Computer Science, Emory University, Atlanta, GA 30322
3IBM T. J. Watson Research Center, Yorktown Heights, NY 10598
{chih3,may13}@rpi.edu, wei.jin@emory.edu, charu@us.ibm.com
Abstract
Data valuation is essential for quantifying data’s worth, aiding in assessing data1
quality and determining fair compensation. While existing data valuation methods2
have proven effective in evaluating the value of Euclidean data, they face limita-3
tions when applied to the increasingly popular graph-structured data. Particularly,4
graph data valuation introduces unique challenges, primarily stemming from the5
intricate dependencies among nodes and the growth in value estimation costs. To6
address the challenging problem of graph data valuation, we put forth an innovative7
solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the8
complex graph structure. Furthermore, we develop a variety of strategies to address9
the computational challenges and enable efficient approximation of PC-Winter.10
Extensive experiments demonstrate the effectiveness of PC-Winter across diverse11
datasets and tasks.12
1 Introduction13
The abundance of training data has been a key driver of recent advancements in machine learning14
(ML) [ 51]. As models and the requisite training data continue to expand in scale, data valuation15
has gained significant attention due to its ability to quantify the usefulness of data for ML tasks and16
determine fair compensation [28, 34]. Notable techniques in this field include Data Shapley [ 13]17
and its successors [ 20, 39, 29], which have gained prominence in assessing data value. Despite18
the promise of these methods, they are primarily designed for Euclidean data, where samples are19
often assumed to be independent and identically distributed (i.i.d.). Given the prevalence of graph-20
structured data in the real world [10, 31, 22], there arises a compelling need to perform data valuation21
for graphs. However, due to the interconnected nature of samples (nodes) on graphs, existing data22
valuation frameworks are not directly applicable to addressing the graph data valuation problem.23
In particular, designing data valuation methods for graph-structured data faces several fundamen-24
tal challenges: Challenge I: Graph machine learning algorithms such as Graph Neural Networks25
(GNNs) [19, 37, 41] often involve both labeled and unlabeled nodes in their model training process.26
Therefore, unlabeled nodes, despite their absence of explicit labels, also hold intrinsic value. Existing27
data valuation methods, which typically assess a data point’s value based on its features and the28
associated label, do not readily accommodate the valuation of unlabeled nodes within graphs. Chal-29
lenge II: Nodes in a graph contribute to model performance in an interdependent and complex way:30
(1) Unlabeled nodes, while not providing direct supervision, can contribute to model performance by31
potentially affecting multiple labeled nodes through message-passing. (2) Labeled nodes, on the other32
Submitted to the 38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets
and Benchmarks. Do not distribute.

hand, contribute by providing direct supervision signals for model training, and similarly to unlabeled33
nodes, they also contribute by affecting other labeled nodes through message-passing. Challenge III:34
Traditional data valuation methods are often computationally expensive due to repeated retraining35
of models [13]. The challenge is magnified in the context of graph-structured data, where samples36
contribute to model performance in multifaceted manners. Additionally, the inherent message-passing37
mechanism in GNN models further amplifies the computational demands for model re-training.38
In this work, we make the first attempt to explore the challenging graph data valuation problem, to39
the best of our knowledge. In light of the aforementioned challenges, we propose the Precedence-40
Constrained Winter (PC-Winter) Value, a pioneering approach designed to intricately unravel and41
analyze the contributions of nodes within graph structures, thereby offering a detailed perspective on42
the valuation of graph elements. Our key contributions are as follows:43
• We formulate the graph data valuation problem as a unique cooperative game [38] with special44
coalition structures. Specifically, we decompose each node in the graph into several “players”45
within the game, each representing a distinct contribution to model performance. We then devise46
the PC-Winter to address the game, enabling the accurate valuation of all players. ThePC-Winter47
values of these players can be conveniently combined to generate values for nodes and edges.48
• To tackle the computational challenges of calculating PC-Winter values, we develop a set of49
strategies including hierarchical truncation and local propagation. These strategies together enable50
an efficient approximation of PC-Winter values.51
• Extensive experiments on various datasets and tasks, along with detailed ablation studies and52
parameter analyses, validate the effectiveness of PC-Winter and provide insights into its behavior.53
2 Preliminary and Related Work54
In this section, we delve into some fundamental concepts that are essential for developing our55
methodology. More extensive literature exploration can be found in Appendix A.56
2.1 Cooperative Game Theory57
Cooperative game theory explores the dynamics where players, or decision-makers, can form alliances,58
known as coalitions, to achieve collectively beneficial outcomes [2, 7]. The critical components of59
such a game include a player set P consisting of all players in the game and a utility function U(·),60
which quantifies the value or payoff that each coalition of players can attain. Shapley Value [32] is61
developed to fairly and efficiently distribute payoffs (values) among players.62
Shapley value. The Shapley value ϕi(P, U) for a player i ∈ Pcan be defined on permutations of P63
as follows.64
ϕi(P, U) = 1
|Π(P)|
X
π∈Π(P)
[U (Pπ
i ∪ {i}) − U (Pπ
i )] (1)
where Π(P) denotes the set of all possible permutations of P with |Π(P)| denoting its cardinality,65
and Pπ
i is predecessor set of i, i.e, the set of players that appear before player i in a permutation π:66
Pπ
i = {j ∈ P |π(j) < π(i)}. (2)
The Shapley value considers each player’s contribution to every possible coalition they could be67
a part of. Specifically, in Eq. (1), for each permutation π, the marginal contribution of player i is68
calculated as the difference in the utility function U when player i is added to an existing coalition69
Pπ
i . The Shapley value ϕi(P, U) for i is the average of these marginal contributions across all70
permutations in Π(P). The Shapley value has been widely applied in ML for various tasks such71
as data valuation [13, 17] and model explanation [24, 11]. In the context of graph ML, it has been72
primarily used for GNN explainability [8, 47, 25, 1]. A more detailed discussion on Shapley Value73
on graph ML can be found in Appendix A.3.74
1
3
2
4
5
6 7
8 9
Figure 1: Level
Coalition Structure
Winter Value. The Shapley value is to address cooperative games, where75
players collaborate freely and contribute on an equal footing. However, in many76
practical cases, cooperative games, exhibit a Level Coalition Structure [26, 36,77
48], reflecting a hierarchical organization. For instance, consider a corporate78
setting where different tiers of management and staff contribute to a project in79
2

varying capacities and with differing degrees of decision-making authority. Players within such a game80
are hierarchically categorized into nested coalitions with several levels, as depicted in Figure 1. The81
outermost and largest ellipse represents the entire coalition and each of the smaller ellipse within the82
largest ellipse symbolizes a “sub-coaliation” at various hierarchical levels. Collaborations originate83
within the smallest sub-coalitions at the base level (illustrated by the innermost ellipses in Figure 1.84
These base units are then integrated into the next level, facilitating inter-coalition collaboration and85
enabling contributions to ascend to higher levels. This bottom-up flow of contributions continues,86
with each layer consolidating and passing on inputs to the next, culminating in a multi-leveled87
collaborative contribution to the final objective of the entire coalition. To accommodate such88
complex Level Coalition Structure, Winter value [40] was introduced. Winter value follows a similar89
permutation-based definition as Shapley Value (Eq. (1)) but with only a specific subset of permutations90
that respect the Level Coalition Structure. In these permutations, members of the same sub-coalition,91
regardless of the level, must appear in an unbroken sequence without interruptions. This ensures that92
the value attributed to each player is consistent with the level structure of the coalition. A formal93
definition of the Winter value can be found in Appendix B.94
2.2 Data Valuation and Data Shapley95
Data valuation quantifies the contribution of data points for machine learning tasks. The seminal96
work [ 13] introduces Data Shapley, applying cooperative game theory to data valuation, where97
training samples are the players P, and the utility function U assesses a model’s performance98
on subsets of these players using a validation set. With P and U, data values can be calculated99
with Eq. (1). However, Data Shapley and subsequent methods [13, 20, 39] primarily focus on i.i.d.100
data, overlooking potential coalitions or dependencies among data points.101
2.3 Graphs and Graph Neural Networks102
Consider a graph G = {V, E} where V denotes the set of nodes and E denotes the set of edges. Each103
node vi ∈ Vcarries a feature vector xi ∈ Rd, where d is the dimensionality of the feature space.104
Additionally, each node vi is associated with a label yi from a set of possible labels C. We assume105
that only a subset Vl ⊂ Vare with known labels.106
GNNs [ 19, 37, 41] are prominent models for graph ML tasks. Specifically, from a local per-107
spective for node vi, the k-th GNN layer generally performs a feature averaging process as108
h(k)
i = 1
deg(vi)
P
vj ∈N(vi)
Wh(k−1)
j , where W is the parameter matrix, deg(vi) and N(vi) denote109
the degree and neighbors of node vi, respectively. After a total of K layers, h(K)
i are utilized as the110
learned representation of vi. Such a feature aggregation process can be also described with a K-level111
computation tree [15] rooted on node vi.112
Definition 1 (Computation Tree). For a node vi ∈ V, its K-level computation tree corresponding to113
a K-layer GNN model is denoted as T K
i with vi as its root node. The first level of the tree consists of114
the immediate neighbors of vi, and each subsequent level is formed by the neighbors of nodes in the115
level directly above. This pattern of branching out continues, expanding through successive levels of116
neighboring nodes until the depth of the tree grows to K.117
The feature aggregation process in aK-layer GNN can be regarded as a bottom-up feature propagation118
process in the computation tree, where nodes in the lowest level are associated with their initial119
features. Therefore, the final representation h(K)
i of a node vi is affected by all nodes within its120
K-hop neighborhood, which is referred to as thereceptive field of node vi. The GNN model is trained121
using the (h(K)
i , yi) pairs, where each labeled node vi in Vl is represented by its final representation122
and corresponding label. Thus, in addition to labeled nodes, those unlabeled nodes that are within123
the receptive field of labeled nodes also contribute to model performance.124
3 Methodology125
In classic machine learning models designed for Euclidean data, such as images and texts, training126
samples are typically assumed as i.i.d. Thus, each labeled sample contributes to the model perfor-127
mance by directly providing supervision signals through the training objective. However, due to the128
3

interdependent nature of graph data, nodes in a graph contribute to GNN performance in a more129
complicated way, which poses unique challenges. Specifically, as discussed in Section 2.3, both130
labeled and unlabeled nodes are involved in the training stage through the feature aggregation. Next,131
we discuss how these nodes contribute to GNN performance.132
Observation 1. Unlabeled nodes influence GNN performance by affecting the final representation of133
labeled nodes. On the other hand, labeled nodes can contribute to GNN performance in two ways:134
(1) they provide direct supervision signals to GNN with their labels, and (2) just like unlabeled nodes,135
they can impact the final representation of other labeled nodes through feature aggregation. Note136
that both labeled nodes and unlabeled nodes can affect the final representations of multiple labeled137
nodes, as long as they lie within the receptive field of these labeled nodes. Hence, a single node138
can make multifaceted and heterogeneous contributions to GNN performance by affecting multiple139
labeled nodes in various manners.140
3.1 The Graph Data Valuation Problem141
Based on Observation 1, due to the heterogeneous and diverse effects of labeled and unlabeled nodes,142
it is necessary to perform fine-grained data valuation on graph data elements. In particular, we143
propose to decompose a node into distinct “duplicates” corresponding to their impact on different144
labeled nodes. We then aim to obtain values for all “duplicates” of these nodes. This could clearly145
express and separate how nodes impact GNN performance in various aspects. Following existing146
literature [13, 39, 43], we approach the graph data value problem through a cooperative game. Next,147
we introduce the player set and the utility function of this game. In general, we define the graph data148
valuation game based on K-layer GNN models.149
Definition 2 (Player Set). The player set P in a graph data valuation game is defined as the union150
of nodes in the computation trees of labeled nodes. Duplication of nodes may occur within a151
single computation tree T K
i or across different labeled nodes’ computation trees. In the graph data152
valuation game, these potential duplicates are treated as distinct players, uniquely identified by their153
paths to the corresponding labeled node. We define the player set P as the set of all these distinct154
players across the computation trees of all labeled nodes in Vl.155
Definition 3 (Utility Function). Given a subset S ⊂ P, we first generate a node-induced graph156
Gin(S) using their corresponding edges in the computation trees. Then, a GNN model A is trained157
on the induced graph Gin(S). Its performance is evaluated on a held-out validation set to serve as158
the utility of S, calculated as U(S) = acc(A(Gin(S))), where acc measures the accuracy of the159
trained GNN model A(Gin(S)) on a held-out validation set.160
The goal of the graph data valuation problem is to assign a value to all players in P with the help161
of the utility function U. When calculated properly, these values are supposed to provide a detailed162
understanding of how players in P contribute to the GNN performance in a fine-grained manner.163
Furthermore, these values can be flexibly combined to generate higher-level values for nodes and164
edges, which will be discussed in Section 3.5.165
3.2 Precedence-Constrained Winter Value166
As discussed in Section 2.3, the final representations of a labeled node vi come from the hierarchical167
collaboration of all players in the computation tree T K
i . These labeled nodes with the updated168
representations then contribute to the GNN performance through the training objective. Such a169
contribution process forms a hierarchical collaboration between the players in P, which can be170
illustrated with a contribution tree T as shown in Figure 2a. In particular, the contribution tree T is171
constructed by linking the root nodes of the computation trees of all labeled nodes with a dummy172
node representing the GNN training objective O. In Figure 2a, for the ease of illustration, we set173
K = 2, include only 2 labeled nodes, i.e, v0, v1, and utilize wi, ui to denote the nodes in the lower174
level. The subtree rooted at a labeled node vi ∈ Vis the corresponding computation tree T 2
i . With175
this, we observe the following about the coalition structure of the graph data valuation game.176
Observation 2 (Level Coalition Structure). As shown in Figure 2a, the players in P hierarchically177
collaborate to contribute. At the bottom level, the players are naturally grouped by their parents.178
Specifically, players with a common parent such as u0, u1, u2 with their parent w0, establish a179
foundation sub-coalition. This sub-coalition is clearly depicted in Figure 2b. Moving up the tree,180
4

these parent nodes, like w0, serve as “delegates” for their respective sub-coalitions, further engaging181
in collaborations with other sub-coalitions. This interaction forms higher-level sub-coalitions, such182
as the one between w0, w1, w2, and v0 in Figure 2b, indicating inter-coalition cooperation. This183
ascending process of coalition formation continues until the root nodeO is reached, which represents184
the objective of the entire coalition consisting of all players. The depicted hierarchical collaboration185
process aligns with the Level Coalition Structure discussed in Section 2.1.186
(a) Contribution Tree
 (b) Coalition Structure
Figure 2: Graph Data Valuation Game Structure
While the contribution tree shares similarities with the187
Level Coalition Structure illustrated in Section 2.1, a188
pivotal distinction lies in the representation and func-189
tion of “delegates” (highlighted in red in Figure 2b)190
within each coalition. In the traditional Level Coali-191
tion Structure, contributions within a sub-coalition are192
made collectively, with each player or lower-level sub-193
coalition participating on an equitable basis. In contrast, the contribution tree framework distinguishes194
itself by designating a “delegate” within each sub-coalition, a player that represents and advances195
the collective contributions, establishing a directed and tiered flow of influence, hence forming a196
Unilateral Dependency Structure.197
Observation 3 (Unilateral Dependency Structure). In the contribution tree framework, a player198
p ∈ Pcontributes to the final objective through a hierarchical pathway facilitated by its ancestors199
(its “delegates” at different levels). Therefore, the collaboration between players in P exhibits a200
Unilateral Dependency Structure, where a player p’s contribution is dependent on its ancestors.201
According to these two observations, the players demonstrate unique coalition structures in the graph202
data valuation game. We aim to propose a permutation-based valuation framework similar to Eq. (1)203
to address the cooperative game with both Level Coalition Structure and Unilateral Dependency204
Structure. In particular, instead of utilizing all the permutations as in Eq. (1), only the permissible205
permutations aligning with such coalition structures are included in the value calculations. As we206
described in Section 2.1, cooperative games with Level Coalition Structure have been addressed by207
the Winter value [40, 4]. Specifically, a permutation respecting the Level Coalition Structure must208
ensure that players in the same (sub-)coalition, regardless of its level, are grouped together without209
interruption from other players [40]. In our scenario, any subtree of the contribution tree corresponds210
to a sub-coalition as demonstrated in Figure 2. Hence, we need to ensure that for any player p ∈ P,211
the player p and its descendants in the contribution tree should be grouped together in the permutation.212
For example, the players w0, u0, u1, u2 should present together as a group in the permutation with213
potentially different orders. On the other hand, to ensure the Unilateral Dependency Structure, a214
permutation must maintain a partial order. Specifically, for any player p in the permutation, its215
descendants must present in later positions in the permutation than p. Otherwise, the descendants of216
p cannot make non-trivial contributions, resulting in 0 marginal contributions.217
We formally define the permissible permutations that align with both Level Coalition Structure and218
Unilateral Dependency Structure utilizing the following two constraints.219
Constraint 1 (Level Constraint). For any player p ∈ P, the set of its descendants in the contribution220
tree is denoted as D(p). Then, a permutation π aligning with the Level Coalition Structure satisfies221
the following Level Constraint: |π[i] −π[j]| ≤ |D(p)|, ∀i, j∈ D(p) ∪p, ∀p ∈ P, where π[i] denotes222
the positional rank of the i in π.223
Constraint 2 (Precedence Constraint). A permutation π aligning with the Unilateral Dependency224
Structure satisfies the following Precedence Constraint: π[p] < π[i], ∀i ∈ D(p), ∀p ∈ P.225
We denote the set of permissible permutations satisfying both Level Constraint and Precedence226
Constraint as Ω. Then, we define the Precedence-Constrained Winter (PC-Winter) value for a227
player p ∈ Pwith the permutations in Ω as follows.228
ψp(P, U) = 1
|Ω|
X
π∈Ω
 
U
 
Pπ
p ∪ p

− U
 
Pπ
p

, (3)
where U(·) is the utility function (see Definition 3), and Pπ
p denotes the predecessor set of p in π as229
defined in Eq. (2).230
5

3.3 Permissible Permutations for PC-Winter231
To calculatePC-Winter value, it is required to obtain all permissible permutations. A straightforward232
way is to enumerate all permutations and only retain the permissible permutations. However, such an233
approach is extremely computationally intensive and typically not feasible in reality. In this section,234
to address this challenge, we propose a novel method to directly generate these permutations by235
traversing the contribution tree with Depth-First Search (DFS). Specifically, each DFS traversal results236
in a preordering, which is a list of the nodes (players) in the order that they were visited by DFS.237
Such a preordering naturally defines a permutation of P by simply removing the dummy node in the238
contribution tree from the preordering. By iterating all possible DFS traversals of the contribution239
tree, we can obtain all permutations in Ω, which is demonstrated in the following theorems.240
Theorem 1 (Specificity). Given a contribution tree T with a set of players P, any DFS traversal241
over the T results in a permissible permutation of P that satisfies both the Level Constraint and242
Precedence Constraint.243
Theorem 2 (Exhaustiveness). Given a contribution tree T with a set of players P, any permissible244
permutation π ∈ Ω can be generated by a corresponding DFS traversal of T .245
The proofs for two theorems can be found in Appendix C. Theorem 1 demonstrates that DFS246
traversals specifically generate permissible permutations. On the other hand, Theorem 2 ensures247
the exhaustiveness of generation, which allows us to obtain all permutations in Ω by DFS traversal.248
Together, these two theorems ensure us toexactly generate the set of permissible permutations Ω.249
Notably, the calculation ofPC-Winter value involves two steps: 1) generatingΩ with DFS traversals;250
and 2) calculating the PC-Winter value according to Eq. (3). Nonetheless, it can be done in a251
streaming way while we perform the DFS traversals. Specifically, once we reach a player p in a DFS252
traversal, we can immediately calculate its marginal contribution. The PC-Winter values for all253
players are computed by averaging their marginal contributions from all possible DFS traversals.254
3.4 Efficient Approximation of PC-Winter255
Calculating the PC-Winter value for players in P is infeasible due to computational intensity, arising256
from: 1) The exponential growth in the number of permissible permutations with more players,257
rendering exhaustive enumeration intractable; 2) The necessity to re-train the GNN within the utility258
function for each permutation, a process repeated |P| times to account for every player’s marginal259
contribution; and 3) The intensive computation involved in GNN re-training, requiring feature260
aggregation over the graph that increases in complexity with the graph’s size. These challenges261
necessitate an efficient approximation method for PC-Winter valuation in practical applications. We262
propose three strategies to address these computational issues.263
Permutation Sampling. Following Data Shapley [13], we adopt Monte Carlo (MC) sampling to264
randomly sample a subset of permissible permutations denoted as Ωs. Then, we utilize Ωs to replace265
Ω in Eq. (3) for approximating PC-Winter value.266
Hierarchical Truncation. GNN models often demonstrate a phenomenon of neighborhood satura-267
tion, i.e, these models achieve satisfactory performance even when trained on a subgraph using only268
a small subset of neighbors, rather than the full neighborhood [14, 23, 45, 5], indicating diminishing269
returns from additional neighbors beyond a certain point. This indicates that for a player p in a270
permissible permutation π generated by DFS over the contribution tree, the marginal contributions of271
its late visited child players are insignificant. Thus, we propose hierarchical truncation for efficiently272
obtaining the marginal contributions by directly approximating insignificant values as 0. Specifically,273
during the DFS traversal, given a truncation ratio r, we only compute actual marginal contributions274
for players in the first 1 − r portion of each node’s child subtrees, approximating the marginal275
contributions of players in the remaining subtrees as 0. For example, in Figure 2a, given a truncation276
ratio r = 2/3, when DFS reaches player v0, we only calculate marginal contributions for players in277
the subtree rooted at w0. Furthermore, in the subtree rooted at w0, due to the hierarchical truncation,278
only the marginal contribution of u0 is evaluated, those for nodeu1 and u2 are set to 0. This approach279
is further optimized by adjusting truncation ratios based on the tree level, accommodating varying280
contribution patterns across levels. In particular, we organize the pair of truncation ratio as r1-r2,281
6

indicating we truncate r1 (or r2) portion of subtrees (or child players) of vi (or wi). We show how282
the hierarchical truncation helps tremendously reduce the model re-training in Appendix D.283
Local Propagation. To enhance scalability, we leverage SGC [41] in our utility function, which284
simplifies GNNs by aggregating node features before applying an MLP. According to the Level285
Constraint (Constraint 1), the players within the same computation tree are grouped together in the286
permutation. Therefore, the induced graph of any coalition Pπ
p defined by a permissible permutation287
consists of a set of separated computation trees (or a partial computation tree corresponding to the last288
visited labeled node in Pπ
p ). A key observation is that the feature aggregation process for the labeled289
nodes can be done independently within their own computation trees. Hence, instead of performing290
the feature propagation for the entire induced graph, we propose to perform local propagation only291
on necessary computation trees. In particular, the aggregated representation for a labeled node is292
fixed after we traverse its entire computation tree in DFS. Therefore, for evaluating a player p’s293
marginal contribution, only the partial computation tree of the last visited labeled node requires local294
propagation, minimizing feature propagation efforts.295
The PC-Winter values for all players are approximated with these three strategies in a streaming296
manner. In particular, we randomly traverse the contribution tree with DFS for|Ωs| times. During297
each DFS traversal, the marginal contributions for all players in P are efficiently obtained with the298
help of hierarchical truncation and local propagation. The marginal contributions calculated through299
these |Ωs| DFS traversals are averaged to approximate the PC-Winter value for all players. In300
Appendix H.5, we provide a detailed complexity analysis of the PC-Winter algorithm.301
3.5 From PC-Winter to Node and Edge Values302
The PC-Winter values for players in P can be flexibly combined to obtain the values for elements303
in the original graph, which are illustrated in this section. Specifically, as discussed in Section 3.1,304
multiple “duplicates” of a node v ∈ Vin the original graph may potentially present in P. Thus, we305
could obtain node value for the node v by summing the PC-Winter values of all its “duplicates” in P.306
On the other hand, each player (except for the rooted labeled players) inP corresponds to an “edge” in307
the contribution tree as identified by the player and its parent. For instance, in Figure 2a, the playeru0308
corresponds to “edge” connecting u0 and w0. Therefore, DFS traversals also generate permutations309
for these “edges”. From this perspective, the marginal contribution for a player p calculated through310
a DFS traversal can be also regarded as the marginal contribution of its corresponding edge, if we311
treat this process as gradually adding “edges” to connecting the players in P. Hence, the PC-Winter312
values for players in P can be regarded as PC-Winter values for their corresponding “edges” in the313
contribution tree. Multiple “duplicates” of an edge e ∈ Ein the original graph may be present in the314
contribution tree. Hence, similar to the node values, we define the edge value for e ∈ Eby taking the315
summation of the PC-Winter value for all its “duplicates” in the contribution tree.316
4 Experiment317
Datasets and Settings. We assess the proposed approach on six real-world benchmark datasets:318
Cora, Citeseer, and Pubmed [30], Amazon-Photo, Amazon-Computer, and Coauther-Physics [33].319
The detailed statistics of datasets are summarized in Table 2 in Appendix G. Our experiments focus320
on the inductive node classification task. The detailed setup of the inductive setting can be found in321
Appendix G.1. To obtain thePC-Winter values, we run permutations in a streaming way as described322
in Section 3.4. This process terminates with a convergence criterion as detailed in Appendix G.4.323
PC-Winter typically terminates with a different number of permutations for different datasets. The324
other hyper-parameters are detailed in Appendix G.5.325
4.1 Dropping High-Value Nodes326
In this section, we aim to evaluate the quality of data values produced byPC-Winter via dropping327
high-value nodes from the graph. Dropping high-value nodes is expected to significantly diminish328
performance, and thus the performance observed after removing high-value nodes serves as a strong329
indicator of the efficacy of graph data valuation. Notably, PC-Winter values values are calculated as330
described in Section 3.5.331
7

To demonstrate the effectiveness of PC-Winter, we include Random value, Degree value, Leave-332
one-out (LOO) value, and Data Shapley value as baselines. A more detailed description of these333
baselines is included in Appendix G.6. To conduct node-dropping experiments, nodes are ranked by334
their assessed values for each method and removed sequentially from the training graph Gtr. After335
each removal, we train a GNN model based on the remaining graph and evaluate its performance336
on the testing graph Gte. Performance changes are depicted through a curve that tracks the model’s337
accuracy as nodes are progressively eliminated. Labeled nodes often contribute more significantly338
to model performance than unlabeled nodes because they directly offer supervision. Thereby, with339
accurately assigned node values, labeled nodes should be prioritized for removal over unlabeled340
nodes. We empirically validate this hypothesis in Figure 6, discussed in Appendix E. Specifically, in341
nearly all datasets, our observations reveal that the majority of labeled nodes are removed prior to the342
unlabeled nodes by both PC-Winter and Data Shapley. This leads to a plateau in the latter portion343
of the performance curves since a GNN model cannot be effectively trained with only unlabeled344
nodes. Consequently, this scenario significantly hampers the ability to assess the value of unlabeled345
nodes. Therefore, we propose to conduct separate assessments for the values of labeled and unlabeled346
nodes. Here, we only inlcude the results for unlabeled nodes, while the results for labeled nodes are347
presented in Appendix F.348
0 100 200 300 400
Number of Node Removed
0.60
0.65
0.70Prediction Accuracy (%)
Cora
0 100 200 300 400
Number of Node Removed
0.600
0.625
0.650
Citeseer
0 1000 2000
Number of Node Removed
0.65
0.70
0.75Prediction Accuracy (%)
Pubmed
0 1000 2000 3000 4000
Number of Node Removed
0.6
0.7
0.8
Amazon-Photo
0 2000 4000 6000
Number of Node Removed
0.5
0.6
0.7Prediction Accuracy (%)
Amazon-Computers
0 2000 4000
Number of Node Removed
0.88
0.90
0.92
Coauther-Physics
Random Degree LOO Data Shapley PC-Winter
Figure 3: Dropping High-Value Nodes
Results and Analysis. Figure 3 illustrates the per-349
formance comparison between PC-Winter and350
other baselines across various datasets. From Fig-351
ure 3, we make the following observations. First,352
the removal of high-value unlabeled nodes iden-353
tified by PC-Winter consistently results in the354
most significant decline in model performance355
across various datasets. This is particularly ev-356
ident after removing a relatively small fraction357
(10%-20%) of the highest-value nodes. This trend358
underscores the importance of high-value nodes.359
Notably, in most datasets PC-Winter outper-360
forms the best baseline method, Data Shapley,361
by a considerable margin, highlighting its effec-362
tiveness. Second, the decrease in performance363
caused by our method is not only substantial364
but also persistent throughout the node-dropping365
process, further validating the effectiveness of366
PC-Winter. Third, the performance curves of PC-Winter and Data Shapley eventually rebound367
towards the end. This rebound corresponds to the removal of unlabeled nodes that make negative con-368
tributions. Their removal aids in improving performance, ultimately reaching the MLP performance369
when all nodes are excluded. This upswing not only evidences the discernment of PC-Winter and370
Data Shapley in ascertaining node values but also showcases the particularly acute precision of371
PC-Winter. These insights collectively affirm the capability of PC-Winter in accurately assessing372
node values.373
4.2 Adding High-Value Edges374
In this section, we explore the impact of adding high-value elements to a graph, providing an375
alternative perspective to validate the effectiveness of data valuation. Notably, adding high-value376
nodes to a graph typically involves the concurrent addition of edges, which complicates the addition377
process. Thus, we target the addition of high-value edges, providing a complementary perspective378
to our analysis. As described in Section 3.5, the flexibility of PC-Winter allows for obtaining edge379
values without a separate “reevaluation” process for edges.380
Here, we keep all nodes in Gtr and sequentially add edges according to the edge values in descend-381
ing order, starting with the highest-valued ones. Similar to the node-dropping experiments, the382
effectiveness of the edge addition is shown through performance curves. We includeRandom value,383
8

Edge-Betweeness, Leave-one-out (LOO) as baselines. Notably, here, Random and LOO specifically384
pertain to edges, and while we use the same terminology as in the prior section, they are distinct385
methods, which are detailed in Appendix G.6.386
0 200 400 600
Number of Edge Added
0.675
0.700
0.725Prediction Accuracy (%)
Cora
0 200 400 600
Number of Edge Added
0.600
0.625
0.650
0.675
Citeseer
0 1000 2000 3000
Number of Edge Added
0.70
0.72
0.74
0.76Prediction Accuracy (%)
Pubmed
0 10000 20000 30000
Number of Edge Added
0.7
0.8
Amazon-Photo
0 20000 40000 60000
Number of Edge Added
0.70
0.75
0.80Prediction Accuracy (%)
Amazon-Computers
0 2000 4000 6000 8000
Number of Edge Added
0.91
0.92
0.93
Coauthor-Physics
Random Edge Betweeness LOO PC-Winter Full Graph
Figure 4: Adding the High-Value Edges
Results and Analysis. Figure 4 illustrates that387
the Random, LOO, and Edge-Betweeness base-388
lines achieve only linear performance improve-389
ments with the addition of more edges, failing390
to discern the most impactful ones for a sparse391
yet informative graph. In contrast, the inclu-392
sion of edges based on the PC-Winter value re-393
sults in a steep performance climb, affirming the394
PC-Winter’s efficacy in pinpointing key edges.395
Notably, the Cora dataset reaches full-graph per-396
formance using merely 8% of the edges selected397
by PC-Winter. Moreover, with just 10% of398
PC-Winter-selected edges, the accuracy climbs399
to 72.9%, outperforming the full graph’s 71.3%,400
underscoring PC-Winter’s capability to identify401
valuable edges. This trend is generally consistent402
across other datasets as well.403
4.3 Ablation Study, Parameter and Efficiency Analysis404
In this section, we conduct an ablation study, parameter analysis, and efficiency analysis to gain405
deeper insights into PC-Winter using node-dropping experiments.406
0 100 200 300 400
Number of Node Removed
0.60
0.65
0.70Prediction Accuracy (%)
Cora
0 1000 2000 3000 4000
Number of Node Removed
0.6
0.7
0.8
Amazon-Photo
PC-Winter-L PC-Winter-P PC-Winter
Figure 5: Ablation Study
Ablation Study. We conduct an ablation study to407
understand how the two constraints in Section 3.2408
affect the effectiveness of PC-Winter. We intro-409
duce two variants of PC-Winter by lifting one410
of the constraints for the permutations. In par-411
ticular, we define PC-Winter-L using the per-412
mutations satisfying the Level Constraint. Simi-413
larly, PC-Winter-P is defined with permutations414
only satisfying Precedence Constraint. As shown in Figure 5, PC-Winter value outperforms the415
PC-Winter-L and PC-Winter-P on both datasets, which demonstrates that both constraints are416
crucial for PC-Winter. Additional results on other datasets are provided in Appendix H.1.417
Parameter Analysis. We conduct parameter analyses to investigate the impact of permutation418
number and truncation ratios on PC-Winter’s performance. The results reveal that PC-Winter419
achieves robust performance even with a significantly reduced number of permutations and high420
truncation ratios. Detailed findings are presented in Appendix H.2 and Appendix H.3, respectively.421
Efficiency Analysis. We compare the efficiency of PC-Winter and Data Shapley. Analysis of422
converged permutation count and time per permutation across 6 datasets underscores PC-Winter’s423
significantly higher efficiency. A comprehensive breakdown is available in Appendix H.4.424
5 Conclusion425
In this paper, we introduce PC-Winter, an innovative approach for effective graph data valuation.426
The method is specifically designed for graph-structured data and addresses the challenges posed by427
unlabeled elements and complex node dependencies within graphs. Furthermore, we introduce a set428
of strategies for reducing the computational cost, enabling efficient approximation of PC-Winter.429
Extensive experiments demonstrate the practicality and effectiveness of PC-Winter in various430
datasets and tasks. While PC-Winter demonstrates improved efficiency compared toData Shapley,431
we acknowledge that further efficiency enhancements are crucial to fully unlock the potential of graph432
data valuation in real-world applications. Our work can be seen as a foundation for future research in433
this direction.434
9

Appendix C.589
3. If you ran experiments (e.g. for benchmarks)...590
(a) Did you include the code, data, and instructions needed to reproduce the main exper-591
imental results (either in the supplemental material or as a URL)? [Yes] The code is592
provided in an anonymous repository (Appendix H.6). The repository also includes593
instructions for downloading the datasets using PyTorch Geometric, allowing for the594
reproduction of the main experimental results.595
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they596
were chosen)? [Yes] The datasets and data splits are described in Appendix G.2 and597
G.3. Model hyperparameters and the convergence criteria for the experiments are598
specified in Appendix G.4 and G.5.599
(c) Did you report error bars (e.g., with respect to the random seed after running experi-600
ments multiple times)? [No] Error bars or results from multiple runs are applicable in601
our setting.602
(d) Did you include the total amount of compute and the type of resources used (e.g., type603
of GPUs, internal cluster, or cloud provider)? [Yes] Appendix H.4 includes the total604
GPU hours and hardware used for the experiments.605
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...606
(a) If your work uses existing assets, did you cite the creators? [Yes] The paper cites the607
creators of the benchmark datasets used in the experiments, including Cora, Citeseer,608
Pubmed, Amazon-Photo, Amazon-Computer, and Coauthor-Physics (Appendix G.2).609
(b) Did you mention the license of the assets? [No] The licenses of the datasets are not610
explicitly mentioned.611
13

(c) Did you include any new assets either in the supplemental material or as a URL? [No]612
No new assets are included in the supplemental material or as a URL.613
(d) Did you discuss whether and how consent was obtained from people whose data you’re614
using/curating? [N/A]615
(e) Did you discuss whether the data you are using/curating contains personally identifiable616
information or offensive content? [No] The paper does not discuss if the benchmark617
graph datasets used contain personally identifiable information or offensive content.618
5. If you used crowdsourcing or conducted research with human subjects...619
(a) Did you include the full text of instructions given to participants and screenshots, if620
applicable? [N/A]621
(b) Did you describe any potential participant risks, with links to Institutional Review622
Board (IRB) approvals, if applicable? [N/A]623
(c) Did you include the estimated hourly wage paid to participants and the total amount624
spent on participant compensation? [N/A]625
A Additional Related Work626
This section presents an extended review of related works, offering a broader and more nuanced627
exploration of the literature surrounding Data Valuation and Graph Neural Networks.628
A.1 Data Valuation629
Data Shapley is proposed in [13] which computes data values with Shapley values in cooperative630
game theory. Beta Shapley [20] is a further generalization of Data Shapley by relaxing the efficiency631
axiom of the Shapley value. Data Banzhaf [39] offers a data valuation method which is robust to data632
noises. Data Valuation with Reinforcement Learning is also explored by [46]. KNN-Shapley [17]633
estimates the shapley Value for the K-Nearest Neighbours algorithm in linear time. CS-Shapley [29]634
provides a new valuation method that differentiate in-class contribution and out-class contribution.635
Data-OOB [21] proposes a data valuation method for a bagging model which leverages the out-of-bag636
estimate. Just, Hoang Anh, et al [ 18] introduce a learning-agnostic data valuation framework by637
approximating the utility of a dataset according to its class-wise Wasserstein distance. Another638
training-free data valuation method utilizing the complexity-gap score is proposed at the same time639
[27]. However, those methods are not designed for the evaluation of data value of graph data which640
bears higher complexity due to the interconnections of individual nodes.641
A.2 Graph Neural Networks642
Graph Neural Networks (GNNs) generate informative representations from graph-structured data and643
facilitate the solving of many graph-related tasks. Bruna et al. [3] first apply the spectral convolution644
operation to graph-structured data. From the spatial perspective, the spectral convolution can be645
interpreted to combine the information from its neighbors. GCN [ 19] simplified this spectral646
convolution and proposed to use first-order approximation. Since then, many other attention-based,647
sampling-based and simplified GNN variants which follow the same neighborhood aggregation design648
have been proposed [ 37, 14, 12, 41].Theoretically, those Graph neural networks typically enhance649
node representations and model expressiveness through a message-passing mechanism, efficiently650
integrating graph data into the learning of representations [42].651
A.3 Shapley Value in Graph Machine Learning652
The Shapley value has found several applications in graph machine learning, primarily in the domain653
of explainability for Graph Neural Networks. GraphSVX [8] is one of the early works that utilizes654
the Shapley value to explain the predictions of GNNs. It identifies influential nodes and features655
for a particular prediction by treating them as players in a cooperative game. However, GraphSVX656
focuses on local explanations for individual predictions of a fixed GNN. SubgraphX [ 47] takes a657
14

different approach by explaining GNN predictions through identifying important subgraphs, rather658
than individual nodes or edges. It uses Monte Carlo tree search to efficiently explore different659
subgraphs and proposes to use Shapley values as a measure of subgraph importance. EdgeSHAPer660
[25] is another method that assesses edge importance for GNN predictions using the Shapley value661
concept. It is particularly relevant for molecular graphs where edges represent chemical bonds.662
GNNShap [1] extends upon previous Shapley value based GNN explanation methods by providing663
explanations for edge, leading to better fidelity scores and faster explanations. SAME [44] proposes a664
structure-aware Shapley-based multipiece explanation method for GNNs that can identify important665
substructures and provide explanations composed of multiple connected components.666
In addition to explainability, Shapley has also been widely adopted for data valuation for conventional667
machine learning methods as discussed in Section 2. However, it has rarely been utilized for data668
valuation on graph data. In this work, we pioneer the exploration of graph data valuation, a challenging669
and previously unexplored problem. Although a recent survey [50] inadvertently refers to GraphSVX670
as a graph data valuation method, it does not align with the traditional definition of data valuation. We671
clarify the key differences between graph data valuation (such as our method) and graph explainability672
(such as GraphSVX) as follows.673
1. In general, data valuation (such as our method) aims to understand how graph elements674
contribute to the model training process, while explainability methods (such as GraphSVX)675
provide post-hoc explanations for a fixed, pre-trained model.676
2. Specifically, our method differs from GraphSVX in several aspects:677
(a) GraphSVX focuses on the explainablity of a local prediction for a single sample, while678
our method aims to quantify the global contribution of graph elements to the overall679
model performance.680
(b) GraphSVX operates post hoc, analyzing the contributions of features and nodes in the681
testing graph to the predictions of an already-trained GNN model, while our approach682
focuses on the global contribution of each data element in the training graph to the683
GNN model’s training process.684
(c) GraphSVX employs the standard Shapley value formulation, which assumes free685
collaboration among players, while our work introduces the PC-Winter value to686
handle the unique hierarchical coalition structures inherent in graph data valuation.687
To the best of our knowledge, our investigation constitutes the first foray into graph data valuation,688
pioneering research in this previously uncharted domain.689
B Mathematical Formulation of Winter Value690
The Shapley value offers a solution for equitable payoff distribution in cooperative games, assuming691
that players cooperate without any predefined structure. In reality, however, cooperative games often692
have inherent hierarchical coalitions. To accommodate these structured coalitions, the Winter value693
extends Shapley value to handle this extra coalition constraints.694
Specifically, considering level structures B, with B = B0, . . . , Bn representing a sequence of player695
partitions. Here, a partition, Bm, subdivides the player set P into a set of disjoint, non-empty subsets696
T1, T2, . . . , Tk. These disjoint subsets satisfy the condition that their union reconstructs the original697
player set P, which means T1 ∪ T2 ∪ . . .∪ Tk = P. This partition sequence forms a hierarchy where698
B0 represents individual players as the leaves of the structure and Bn functions as the root of this699
hierarchy.700
We then determine Ω(B), the set of all permissible permutations, starting with a single partition Bm:701
Ω(Bm) = {π ∈ Π(P) : ∀T ∈ Bm, ∀i, j∈ T and k ∈ P,
if π(i) < π(k) < π(j) then k ∈ T}.
Ω(B) can be further defined as the set of permutations which satisfy all constraints of all levels,702
Ω(B) = Tn
t=0 Ω (Bt).703
15

A permissible permutation π from the set Ω(B) requires that players from any derived coalition of B
must appear consecutively. Given the defined set of permissible permutations Ω(B), the Winter value
Φ for player i is calculated as:
Φi(P, U,B) = 1
|Ω(B)|
X
π∈Ω(B)
(U (Pπ
i ∪ i) − U (Pπ
i ))
where Pπ
i = {j ∈ N : π(j) < π(i)} is the set of predecessors of i at the permutation σ and U is the704
utility function in the cooperative game.705
C Proofs of Theorems706
Theorem 1 (Specificity). Given a contribution tree T with a set of players P, any DFS traversal707
over the T results in a permissible permutation of P that satisfies both the Level Constraint and708
Precedence Constraint.709
Proof. We validate the theorem by demonstrating that a permutation obtained through pre-order710
traversal on T meets Level Constraints and Precedence Constraints. (1) Level Constraints: During a711
pre-order traversal of T , a node p and its descendants D(p) are visited sequentially before moving712
to another subtree. Thus, in the resulting permutation π, the positions of p and any i, j∈ D(p)713
are inherently close to each other, satisfying the condition |π[i] − π[j]| ≤ |D(p)|. This contiguous714
traversal ensures that all descendants and the node itself form a continuous sequence in π, meeting715
the Level Constraint. (2) Precedence Constraints: In the same traversal, each node p is visited before716
its descendants. Therefore, in π, the position of p always precedes the positions of its descendants,717
i.e., π[p] < π[i] for all i ∈ D(p). This traversal pattern naturally embeds the hierarchy of the tree718
into the permutation, ensuring that ancestors are positioned before their descendants, in line with the719
Precedence Constraint.720
Theorem 2 (Exhaustiveness). Given a contribution tree T with a set of players P, any permissible721
permutation π ∈ Ω can be generated by a corresponding DFS traversal of T .722
Proof. To prove the theorem of exhaustiveness, consider a contribution treeT with a set of players723
P and any permissible permutation π ∈ Ω. We apply induction on the depth of T . For the base case,724
when T has a depth of 1, which means there are no dependencies among players, any permissible725
permutation of players is trivially generated by a DFS traversal since there are no constraints on the726
order of traversal. For the inductive step, assume the theorem holds for contribution trees of depth k.727
For a contribution tree of depth k + 1 T k+1, consider its root node and subtrees of depth k rooted728
at the child nodes of the root node. For any given permissible permutation π corresponding to the729
T k+1, according to the Level Constraint, it is a direct composition of the permissible permutations730
corresponding to the subtrees of depth k rooted at the child nodes of the root node. Now we can731
construct a DFS traversal over the contribution tree T k+1 that can generate π. Specifically, the order732
of composition defines the traversal order of the child nodes of the root node. Furthermore, by the733
inductive hypothesis, any permissible permutations corresponding to the subtrees can be generated734
by DFS traversal over the subtrees. Hence, at each child node of the root node, we just follow the735
corresponding DFS traversal of its corresponding tree. This DFS traversal can generate the given736
permutation π, which completes the proof.737
D Hierarchical Truncation738
In Table 1, we present data comparing the number of model re-trainings on the all six dataset with739
and without the application of truncation. For the Citeseer dataset, the truncation ratios are defined as740
1st-hop: 0.5 and 2nd-hop: 0.7. For the remaining datasets, the truncation ratios are set at 1st-hop: 0.7741
and 2nd-hop: 0.9. The results clearly indicate that the number of model re-trainings is substantially742
reduced when truncation is applied. For instance, focusing on the Citeseer dataset the application743
of truncation significantly reduces the number of retrainings from 1388 to 535. This significant744
16

decrease, especially in larger datasets like Amazon-Photo and Amazon-Computer, where retraining745
instances decrease from 147664 to 6258 and from 317959 to 12139 respectively, can be attributed to746
the substantial number of 2-distance neighbors present in these datasets. The application of truncation747
effectively reduces the computation by omitting a considerable portion of these neighbors. This748
finding also implies that overall training time is decreased while still maintaining the ability to749
accurately measure the total marginal contribution.750
Table 1: Retraining Number Comparison Per Permutation
Dataset w.o. Truncation w.t. Truncation
Cora 2241 756
Citeseer 1388 535
Pubmed 3683 887
Amazon-Photo 147664 6258
Amazon-Computer 317959 12139
Coauther-Physics 11178 852
E Mixed Node Dropping Experiment751
As mentioned in the experiment, labeled nodes will dominate the performance curve when both752
labeled nodes and unlabeled nodes. The corresponding experiment result is shown in the Figure 6.753
This experiment validates the assumption that a effective data valuation method would naturally rank754
labeled nodes for earlier removal over their unlabeled counterparts. For instance, in the Cora dataset,755
we can observe that the initial drop in accuracy is significant, indicating the removal of high-value756
labeled nodes. As the experiment progresses and more nodes are removed, the accuracy barely757
changes, reflecting the removal of unlabeled nodes which has a minimal impact on performance758
when most labeled nodes are unavailable. The observed pattern across all datasets is consistent: there759
is a substantial drop in performance at the beginning, followed by a plateau with minimal changes.760
This suggests that the initial set of nodes removed, predominantly high-value labeled nodes, are761
those critical to the model’s performance, whereas the subsequent nodes show less influence on the762
outcome.
0 200 400 600
Number of Mixed Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Cora
0 100 200 300 400 500
Number of Mixed Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Citeseer
0 500 1000 1500 2000 2500
Number of Mixed Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Pubmed
0 1000 2000 3000 4000
Number of Mixed Node Removed
0.0
0.2
0.4
0.6
0.8Prediction Accuracy (%)
Amazon-Photo
0 2000 4000 6000
Number of Mixed Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Amazon-Computers
0 1000 2000 3000 4000 5000
Number of Mixed Node Removed
0.0
0.2
0.4
0.6
0.8Prediction Accuracy (%)
Coauthor-Physics
Data Shapley PC-Winter
Figure 6: Mixed Node Dropping Experiment
763
17

F Labeled Node Dropping Experiment764
Here, we perform node dropping experiment employing the aggregated value define in the main-765
body of paper, to demonstrate that PC-Winter can capture the heterogeneous influence of labeled766
nodes. As shown in the Figure 7, both PC-Winter and Data Shapley demonstrate effectiveness767
in capturing the diverse contributions of labeled nodes to the model’s performance. Particularly in768
the Pubmed and Amazon-Photo datasets, PC-Winter exhibits better performance compared to Data769
Shapley. In other datasets, such as Cora, Citeseer, and Coauthor-Physics, PC-Winter shows results770
that are on par with Data Shapley.771
0 50 100
Number of Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Cora
0 25 50 75 100
Number of Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Citeseer
0 20 40 60
Number of Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Pubmed
0 50 100 150
Number of Node Removed
0.0
0.2
0.4
0.6
0.8Prediction Accuracy (%)
Amazon-Photo
0 50 100 150 200
Number of Node Removed
0.0
0.2
0.4
0.6Prediction Accuracy (%)
Amazon-Computers
0 20 40 60 80 100
Number of Node Removed
0.0
0.2
0.4
0.6
0.8Prediction Accuracy (%)
Coauthor-Physics
Data Shapley PC-Winter
Figure 7: Labeled Node Dropping Experiment
G Experimental Details772
G.1 Inductive Setting773
Our experiments focus on the inductive node classification task, which aims to generalize a trained774
model to unseen nodes and is commonly adopted in real-world graph applications [ 14, 35, 16, 9].775
Unlike the transductive setting [19] which incorporates the test nodes in the model training process,776
the inductive setting separates them apart from the training graph. Such a separation allows us to777
measure the value of the graph elements in the training graph solely based on their contribution778
to GNN model training. Following [14], we split each graph G into 3 disjoint subgraphs: training779
graph Gtr, validation graph Gva, and test graph Gte. The training graph Gtr is constructed without780
any nodes from the validation or test set. Correspondingly, edges connecting to a validation node781
or a testing node are also removed from the training graph. For the validation graph Vva and the782
testing graph Vte, only edges with both nodes within the respective node sets are retained, which is783
aligned with the inductive setting in prior work [49]. We utilize Gtr to train the GNN model, which is784
evaluated on Vva for obtaining the data values for elements. The test graph Vte is utilized to evaluate785
the effectiveness of the obtained values.786
G.2 Datasets787
We assess the proposed approach on six real-world benchmark datasets. These include three citation788
graphs, Cora, Citeseer and Pubmed [30] and two Amazon Datasets, Amazon-Photo and Amazon-789
Computer, and Coauther-Physics [33]. The detailed statistics of datasets are summarized in Table790
2.791
18

Table 2: Dataset Summary
Dataset # Node # Edge # Class # Feature # Train/Val/Test
Cora 2,708 5,429 7 1,433 140 / 500 / 1,000
Citeseer 3,327 4,732 6 3,703 120 / 500 / 1,000
Pubmed 19,717 44,338 3 500 60 / 500 / 1,000
Amazon-Photo 7,650 119,081 8 745 160 / 20% / 20%
Amazon-Computer 13,752 245,861 10 767 200 / 20% / 20%
Coauthor-Physics 34,493 247,962 8 745 100 / 20% / 20%
G.3 Dataset Split792
In the conducted experiments, we split each graph G into 3 disjoint subgraphs: training graph Gtr,793
validation graph Gva, and test graph Gte. The training graph Gtr is constructed without any nodes794
from the validation or test set. Correspondingly, edges connecting to a validation node or a testing795
node are also removed from the training graph. For the validation graph Vva and the testing graph796
Vte, only edges with both nodes within the respective node sets are retained, which is aligned with the797
inductive setting in prior work [49]. We utilize Gtr to train the GNN model, which is evaluated onVva798
for obtaining the data values for elements. The test graph Vte is utilized to evaluate the effectiveness799
of the obtained values. In the case of the specific split for each dataset, for the citation networks, we800
adopt public train/val/test splits in our experiments. For the remaining datasets, we randomly select801
20 labeled nodes per class for training, 20% nodes for validation and 20% nodes as the testing set.802
G.4 Convergence Criteria803
Convergence Criterion. For permutation-based data valuation methods such as Data Shapley and
PC-Winter, we follow convergence criteria similar to the one applied in prior work [13] to determine
the number of permutations for approximating data values:
1
n
nX
i=1
vt
i − vt−20
i

|vt
i| < 0.05
where vt
i is the estimated value for the data element i using the first t sampled permutations.804
Time Limit. For larger datasets, sampling a sufficient number of permutations for converged data805
values could be impractical in time. To address this and to stay within a realistic scope, we cap the806
computation time at 120 GPU hours on NVIDIA Titan RTX, after which the calculation is terminated.807
G.5 Truncation Ratios and Hyper-parameters808
Table 3 includes the hyper-parameters and truncation ratios used for value estimation.809
Table 3: Truncation Ratios and Hyper-parameters
Dataset Truncation Ratio Learning Rate Epoch Weight Decay
Cora 0.5-0.7 0.01 200 5e-4
Citeseer 0.5-0.7 0.01 200 5e-4
Pubmed 0.5-0.7 0.01 200 5e-4
Amazon-Photo 0.7-0.9 0.1 200 0
Amazon-Computer 0.7-0.9 0.1 200 0
Coauthor-Physics 0.7-0.9 0.01 30 5e-4
G.6 Baselines810
G.6.1 Dropping High-Value Nodes811
Here, we introduce the baselines used for comparison to validate the effectiveness of the proposed812
method in the dropping node experiment:813
19

0 100 200 300 400
Number of Node Removed
0.600
0.625
0.650
0.675
0.700Prediction Accuracy (%)
Cora
0 100 200 300 400
Number of Node Removed
0.60
0.62
0.64
0.66Prediction Accuracy (%)
Citeseer
0 500 1000 1500 2000 2500
Number of Node Removed
0.625
0.650
0.675
0.700
0.725Prediction Accuracy (%)
Pubmed
0 1000 2000 3000 4000
Number of Node Removed
0.6
0.7
0.8Prediction Accuracy (%)
Amazon-Photo
0 2000 4000 6000
Number of Node Removed
0.5
0.6
0.7Prediction Accuracy (%)
Amazon-Computers
0 1000 2000 3000 4000 5000
Number of Node Removed
0.88
0.90
0.92Prediction Accuracy (%)
Coauther-Physics
PC-Winter-L PC-Winter-P PC-Winter
Figure 8: Ablation Study
• Random Value: It assigns nodes with random values, which leads to random ranking without any814
specific pattern or correlation to the node’s features.815
• Degree-based Value: A node is assigned its degree as its value, assuming that a node’s impor-816
tance in the graph is indicated by its degree.817
• Leave-one-out (LOO): This method calculates a node’s value based on its marginal contribution818
compared to the rest of the training nodes. Specifically, the value v(i) assigned to each node i819
is its marginal utility, calculated as v(i) = U (Gtr) − U
 
G−i
tr

, where G−i
tr denotes the training820
graph excluding node i. The utility function U measures the model’s validation performance when821
trained on the given graph. In essence, the drop in performance due to the removal of a node is822
treated as the value of that node.823
• Data Shapley: The node values are approximated with the Monte Carlo sampling method of824
Data Shapley [13] by treating both labeled nodes and unlabeled nodes as players. Notably, we825
only include those unlabeled nodes within the 2-hop neighbors of labeled nodes in the evaluation826
process. There are two approximation methods: Truncated Monte Carlo approximation and827
Gradient Shapley in [13]. We adopt the Truncated Monte Carlo approximation as it consistently828
outperforms the other variants in various experiments.829
Notably, there is a recent work [ 6] that aims at characterizing the impact of elements on model830
performance. Their goal is to approximate LOO value. Thus, we do not include it as a baseline as LOO831
is already included.832
G.6.2 Adding High-Value Edges833
Here are the detailed descriptions on the baselines applied in the edge adding experiment.834
• Random Value: it assigns edges with random values, reflecting a baseline where no information835
are used for differentiating the importance of edges.836
• Edge-Betweeness: the Edge-Betweeness of an edge e is the the fraction of all pairwise shortest837
paths that go through e. This classic approach assesses an edge’s importance based on its role in838
the overall network connectivity.839
• Leave-one-out (LOO): This method calculates a edge e’s value v(e) based on its marginal840
contribution compared to the rest of the training graph. In specific, v(e) = U(Gtr) − U
 
G−e
tr

841
Here, e ∈ Gtr represents an edge in the training graph Gtr, and G−e
tr refers to the training graph842
excluding the edge e.843
20

H Ablation Study and Parameter Analysis844
H.1 Ablation Study845
This Appendix Section offers an in-depth ablation analysis across full six datasets to investigates846
the necessity of both Level Constraint and Precedence Constraint in defining an effective graph847
value. The results, as shown in Figure 8, consistently demonstrate across all datasets that the absence848
of either constraint leads to a degraded result when compared to the one incorporating both. This849
underscores the importance of both two constraints in capturing the contributions of graph elements850
to overall model performance.851
H.2 The Impact of Permutation Number852
This part expands upon the permutation analysis presented in the main paper. It provides comprehen-853
sive results across various datasets, illustrating how different numbers of sample permutations impact854
the accuracy of PC-Winter. The results of full datasets are shown in Figure 9. The results reveals
0 100 200 300 400
Number of Node Removed
0.60
0.62
0.64
0.66
0.68
0.70Prediction Accuracy (%)
Cora
0 100 200 300 400
Number of Node Removed
0.58
0.60
0.62
0.64
0.66Prediction Accuracy (%)
Citeseer
0 500 1000 1500 2000 2500
Number of Node Removed
0.62
0.64
0.66
0.68
0.70
0.72
0.74Prediction Accuracy (%)
Pubmed
0 1000 2000 3000 4000
Number of Node Removed
0.55
0.60
0.65
0.70
0.75
0.80
0.85Prediction Accuracy (%)
Amazon-Photo
0 2000 4000 6000
Number of Node Removed
0.45
0.50
0.55
0.60
0.65
0.70Prediction Accuracy (%)
Amazon-Computers
0 1000 2000 3000 4000 5000
Number of Node Removed
0.87
0.88
0.89
0.90
0.91
0.92
0.93Prediction Accuracy (%)
Coauthor-Physics
Data Shapley 50 perms 100 perms Converged PC-Winter
Figure 9: The Impact of Permutation Numbers
855
that increasing the number of permutations generally improves the performance and accuracy of the856
valuation. PC-Winter also show robust results even with a limited number of permutations, high-857
lighting its effectiveness. The phenomenon is consistent across all datasets where our approach with858
just 50 to 100 permutations manages to compete closely with the fully converged Data Shapley,859
emphasizing the efficiency of PC-Winter in various settings.860
H.3 The Impact of Truncation Ratios861
Our approach involves truncating the iterations involving the first and second-hop neighbors of a862
labeled node during value estimation. Here, we investigate the impact of truncation proportion863
on overall performance, using the same number of permutations as in our primary node-dropping864
experiment. As shown in Figure 10, we adjusted the truncation ratios for the Citation Network865
datasets. The ratios ranged from truncating 50% of the first-hop and 70% of the second-hop neighbors866
(0.5-0.7), up to 90% truncation for either first-hop (0.9-0.7) or second-hop (0.5-0.9) neighbors. For867
the Cora and Citeseer datasets, increasing truncation at the first-hop level had a minimal impact868
on performance, and PC-Winter still significantly outperformed Data Shapley. In the case of869
the Pubmed dataset, more extensive truncation at the first-hop level notably reduced performance.870
Regarding large datasets such as the Amazon, while truncation at either the first or second-hop871
levels had a marginal negative effect on performance,PC-Winter ’s estimated data values generally872
remained superior to results of Data Shapley.873
21

In addition, we provide a detailed analysis of our truncation strategy across other datasets. It includes874
results not presented in the main text, focusing on the impact of limiting model retraining times to the875
first and second-hop neighbors in value estimation. We investigate the impact of truncation proportion876
on overall performance, using the same number of permutations as in our primary node-dropping877
experiment. The findings on full datasets are illustrated in Figure 10. Specifically, our findings reveal878
that in datasets like Cora and Citeseer, adjusting truncation primarily at the first-hop level has a879
negligible impact on the accuracy of node valuation, withPC-Winter still maintaining a considerable880
advantage over Data Shapley. For large datasets such as the Amazon-Photo, Amazon-Computers881
and Coauther-Physics, while truncations had a marginal negative effect on performance, PC-Winter882
’s estimated data values generally remained better than Data Shapley. This analysis indicates that883
PC-Winter can afford to employ larger truncation, enhancing computational efficiency without884
substantially sacrificing the quality of data valuation.885
0 100 200 300 400
Number of Node Removed
0.60
0.62
0.64
0.66
0.68
0.70Prediction Accuracy (%)
Cora
0 100 200 300 400
Number of Node Removed
0.60
0.62
0.64
0.66Prediction Accuracy (%)
Citeseer
0 500 1000 1500 2000 2500
Number of Node Removed
0.62
0.64
0.66
0.68
0.70
0.72Prediction Accuracy (%)
Pubmed
0 1000 2000 3000 4000
Number of Node Removed
0.55
0.60
0.65
0.70
0.75
0.80
0.85Prediction Accuracy (%)
Amazon-Photo
0 2000 4000 6000
Number of Node Removed
0.45
0.50
0.55
0.60
0.65
0.70Prediction Accuracy (%)
Amazon-Computers
0 1000 2000 3000 4000 5000
Number of Node Removed
0.87
0.88
0.89
0.90
0.91
0.92
0.93Prediction Accuracy (%)
Coauthor-Physics
Data Shapley 0.5-0.7 Truncation 0.9-0.7 Truncation 0.5-0.9 Truncation
Data Shapley 0.7-0.9 Truncation 0.9-0.9 Truncation 0.7-0.95 Truncation
Figure 10: The Impact of Truncation Ratios
Table 4: Permutation Number and Time Comparison
Dataset Truncation PC-Winter Data Shapley
Perm Number Perm Time (hrs) Perm Number Perm Time (hrs)
Cora 0.5-0.7 325 0.013 327 0.024
Citeseer 0.5-0.7 291 0.018 279 0.037
Pubmed 0.5-0.7 316 0.025 281 0.285
Amazon-Photo 0.7-0.9 418 0.211 109 1.105
Amazon-Computer 0.7-0.9 181 0.662 33 3.566
Coauthor-Physics 0.7-0.9 460 0.119 45 2.642
H.4 Efficiency Analysis886
Here, we compare the computational efficiency of our proposed method PC-Winter and the Data887
Shapley approach in terms of permutation number and time per permutation. As detailed in Table 4,888
the results indicate that PC-Winter requires significantly less time to compute each permutation889
across various datasets. Specifically, for the Cora dataset, PC-Winter completes each permuta-890
tion in approximately half the time required by Data Shapley. Moving to larger datasets, the891
efficiency of PC-Winter becomes even more pronounced. For instance, in the Amazon-Computer892
dataset, PC-Winter’s permutation time is only a fraction of what is required by Data Shapley893
—PC-Winter takes slightly over half an hour per permutation whereasData Shapley exceeds three894
22

and a half hours. This consistent reduction in permutation time demonstrates the computational895
advantage of PC-Winter, particularly when handling large graphs. Combining the insights from the896
Permutation Analysis shown in Figure 9 with the Permutation Comparison Table 4, we observe that897
for datasets such as Cora, Citeseer, Amazon-Photo, and Amazon-Computer, around 50 permutations898
are sufficient for PC-Winter to achieve performance comparable to that of Data Shapley. Simple899
calculations demonstrate that our method is significantly faster than Data Shapley in achieving900
similar performance levels. For instance, in the Cora dataset, the speedup factor is327×0.024
50×0.013 = 12.07,901
and for the Citeseer dataset, it is 279×0.037
50×0.018 = 11.47. The speedup factors for Amazon-Photo and902
Amazon-Computer are 109×1.105
50×0.211 = 11.42, and 33×3.566
50×0.662 = 3.57, respectively. For Coauthor-Physics,903
it takes about 100 permutations for PC-Winter to match the performance of Data Shapley, which904
implies a speedup factor of 45×2.642
100×0.119 = 10.00. In conclusion, PC-Winter can achieve stronger905
performance than Data Shapley using the same or even less time. Furthermore, it takesPC-Winter906
much less time to achieve comparable performance as Data Shapley. Notably, though PC-Winter907
is significantly more efficient than Data Shapley, its scalability is still limited, and future work in908
further improving its efficiency is desired.909
H.5 Complexity Analysis910
We analyze the complexity of the PC-Winter. For convenience, we assume that we are dealing with a911
d-regular graph. There are a total of L labeled nodes in the graph. As described in the paper, we deal912
with a GNN model with 2 layers. Without loss of generality, we use F to denote the dimensionality913
of node representations in each layer. We assume the number of classes in the dataset is C. For914
hierarchical truncation, we assume we adopt a truncation ratio of r1 − r2, which is consistent with915
the description in Section 3.4. Then, the number of nodes in a computation tree for any labeled916
node is Nfull = 1 + d + d2. With hierarchical truncation, the number of nodes in the truncated917
computation tree is Ntrun = 1 + d · (1 − r1) + d2 · (1 − r1)(1 − r2). When the truncation ratios918
are large, Ntrun ≪ Nfull . For instance, when r1 = r2 = 0.9, Ntrun could be less than 5Time919
Complexity Analysis: We now analyze the time complexity of a single permissible permutation of the920
PC-Winter algorithm. We begin by examining the time complexity of generating a single permissive921
permutation. Then, we investigate the complexity of a single model retraining and provide the total922
retraining number for a single permutation. Finally, we combine these analyses to derive the overall923
time complexity for generating one permissible permutation and going through it for calculating the924
marginal contributions. Time complexity of generating a single permissive permutation: The time925
complexity of traversing the truncated contribution tree to generate a single permissive permutation is926
O(L·Ntrun). In particular, there are L·Ntrun +1 nodes in the contribution tree (including the dummy927
node). Hence, the cost of a DFS traversal over the contribution tree is O(L · Ntrun + 1 +L · Ntrun)928
= O(L · Ntrun). Time complexity of one model retraining: As described in Section 3.4, with local929
propagation, for each model retraining, we only need to perform feature aggregation on a single partial930
computation tree. The size of a partial computation tree is, on average, Ntrun
2 . Therefore, the feature931
aggregation complexity for each retraining step is O(Ntrun
2 · F), where F is the dimension of node932
features. The feature transformation complexity for each model retraining isO(F ·F +F ·C)=O(F2),933
where C is the output dimension (number of classes) of the GNN model. Therefore, the total time934
complexity of a single retraining is O(Ntrun
2 · F + F2). Without local propagation, the feature935
aggregation complexity for each model retraining would be much larger, since the propagation needs936
to be performed on the entire graph. The number of model retraining in a single permutation: In a937
permissible permutation, we need to perform retraining for each node in the truncated contribution938
tree, which has L · Ntrun nodes in total. Therefore, L · Ntrun model retrainings are needed for a single939
permutation. Total time complexity for a single permissible permutation: With local propagation and940
hierarchical truncation, the total time complexity of a single permissible permutation in PC-Winter is:941
O(L·Ntrun+L·Ntrun·(Ntrun
2 ·F +F2)) = O(L·Ntrun·(1+ Ntrun
2 ·F +F2)) = O(L·Ntrun·(Ntrun
2 ·F +F2)).942
Notably, the time complexity of generating a permissible permutation is negligible compared to the943
cost of model retraining. The proposed strategies, hierarchical truncation, and local propagation, help944
reduce the overall time complexity of the PC-Winter algorithm. In particular, hierarchical truncation945
makes Ntrun much smaller than Nfull, greatly decreasing the total number of model retraining required946
23

for a single permutation. On the other hand, Local propagation reduces the feature aggregation947
complexity, greatly reducing the cost of each retraining.948
H.6 Code Availability949
To facilitate the reproducibility of our work and to encourage further research in the field of graph950
data valuation, we have made our code publicly available on an anonymous repository at https:951
//anonymous.4open.science/r/graph-data-valuation-B348 . The repository contains the952
implementation of thePC-Winter algorithm, along with scripts for running the experiments presented953
in this paper. We welcome researchers and practitioners to utilize and build upon our code for their954
own research and applications in graph data valuation.955
24