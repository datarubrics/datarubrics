The Tournesol dataset:
Which videos should be more largely recommended?
Anonymous Author(s)
Affiliation
Address
email
Abstract
This paper introduces the Tournesol public dataset, which was collected as part1
of the online deployed platform https://tournesol.app. Our dataset contains2
a list of 204,000 comparative judgments made by Tournesol’s 20,000 users on3
which YouTube videos should be more largely recommended. It also provides4
703,000 comparisons along secondary criteria like content reliability, topic impor-5
tance and layman-friendliness. The dataset also exports information about users’6
pretrust statuses and vouches. It is published at https://api.tournesol.app/7
exports/all under ODC-By license. The data is currently used by Tournesol to8
make community-driven video content recommendations to over 10,000 users.9
1 Introduction10
Recommendation algorithms have become extremely influential. In the last few years, beyond their11
impacts on mental health [54, 19, 91], because they amplify disinformation, cyberbullying and hate,12
they have been linked to major geopolitical events, including COVID disinformation [78, 43], the rise13
of far-right parties [90, 89, 94], and the Rohingya genocides [39, 71]. Crucially, in all these examples,14
the victims of recommendation algorithms are not only their users; hate amplification is threatening15
entire populations, even when these populations do not use recommendation algorithms themselves.16
This is in sharp contrast with the overwhelming majority of the scientific literature, which assumes17
that recommendation algorithms should be optimized for their users only [1, 69].18
As online activities grew, social media havede facto taken the role that was traditionally played by19
these intermediate bodies [88, 47]. This became particularly striking when, in 2020, the then US20
President was banned from Twitter, Facebook, and Youtube, long before any court sued him for21
inciting the Capitol riot violence [64, 65]. As another example, by amplifying the cyberbullying of22
climate scientists, Twitter provoked their exodus from the platform [ 92], thereby turning climate23
change into a mute news, which is endangering plenty of non-users [3]. The great replacement of the24
intermediate body by privately owned algorithms has been tied to an alarming decline of democratic25
norms worldwide, as many reports expose a global trend of autocratization [70, 7].26
So how do today’s large-scale recommendation algorithms address the ethical dilemmas that they face27
billions of times per day, when they are tasked with amplifying some (potentially hateful) content over28
others (of potential public interest)? Currently, they heavily rely on (highly sophisticated) machine29
learning [23, 61]. In other words, such algorithms leverage massive amounts of data to determine30
which content they will promote at scale. However, as an immediate corollary, such algorithms are31
exposed to manipulation by poisoning data [86]. In fact, this poisoning has been industralized, not32
only by authoritarian states [18, 45], but also by private companies based in the UK [49], Spain [14],33
Israel [6], France [87] and Switzerland [34]. The magnitude of this industry is well captured by one34
puzzling statistic: Facebook reportedly removes around 7 billion fake accounts per year [56].35
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.

While a recent line of research has provided numerous poisoning mitigations [13, 31, 32, 27, 80, 74],36
it is also known that there are fundamental impossibility theorems that prevent accurate learning in37
highly adversarial, heterogeneous and high-dimensional settings [28, 57, 36, 30]. In particular, there38
is no substitute for training datasets of high quality and security. In particular, to design trustworthy39
ethical algorithms, it is essential to train them on large, secured and trustworthy datasets of human40
ethical judgments. In this paper, we present the Tournesol public dataset, whose goal is to remedy41
the current state of affairs. More precisely we make the following contributions.42
Contributions. Our main contribution is to present and share the Tournesol public dataset, which43
can be downloaded directly from https://api.tournesol.app/exports/all. The dataset con-44
sists of over 204,000 pairwise comparisons of the recommendability of over 40,000 YouTube video by45
over 20,000 Tournesol accounts. Additionally, the dataset contains over 703,000 pairwise comparisons46
of the videos’ quality on secondary criteria, such as reliability, importance and layman-friendliness.47
Our dataset, published under ODC-By license, also contains pretrust information about contributors,48
vouches between contributors, as well as scores computed from the data using SOLIDAGO [12].49
Crucially, the dataset was collected in a fully deployed environment with actual stakes, as Tournesol50
eventually makes recommendations based on the provided data to over 10,000 users.51
The paper also presents an analysis of our dataset, with valuable insights for the ethics of content52
recommendation. One finding is that the topic importance highly matters in Tournesol’s contributors’53
judgments. While caveats apply, this suggests that the attention to “fake news” may be misguided;54
in fact, the disinformation industry often proceeds without producing false information, e.g. by55
overclaiming positive impacts, shifting blame or bullying critics [75]. Prioritizing greater exposure56
to mute news might be more urgent. Our analysis also highlights the need of psychological-based57
preference learning models, as we expose biases and variations in contributors’ judgments.58
Finally, our paper discusses numerous exciting research directions that our public dataset could59
inspire or facilitate. In particular, we believe that a lot more focus should be given to secure learning60
under poisoning attacks, but also to Proof of Personhood, expertise validation, volition learning,61
active learning and resilient collaborative filtering, among others.62
Literature review. Tournesol presents a new contribution to the growing field of AI alignment with63
human values [46, 21, 50, 76], which aims to teach human preferences to algorithms, and to design64
systems that maximize what humans prefer to maximize [81, 52]. Clearly, this requires finding out65
about humans’ judgments on how algorithms ought to behave. Unfortunately, so far, to the best of66
our knowledge and especially for the important case of recommendation algorithms, there have not67
been many secure, public and free-license datasets with such AI-safety-critical data.68
To collect such data in a realistic setting, Tournesol’s dataset draws inspiration from several previous69
AI ethics solutions, which leveraged collaborative governance to address cases of conflictual human70
judgments. In particular, [ 60] introduced WeBuildAI, a framework where stakeholders of a food71
donation system could weigh in on the identity of the recipient of a donation. One challenge is that72
such decisions must be made every day; but stakeholders are not available every time a decision needs73
to be made. To account for their preferences, WeBuildAI asks stakeholders to either write down74
an algorithm that describes their preferences, or to provide judgments on generated food donation75
dilemmas. In the latter case, a learning model is then used to infer how the stakeholders would likely76
assess other dilemmas. In any case, an algorithmic representative is thereby constructed for each77
stakeholder; and the resulting decision will follow from a vote of the algorithmic representatives.78
Similar approaches were proposed for kidney donation [42] and for the “trolley dilemmas” [40] that79
autonomous cars could one day face [10, 73].80
Perhaps most similar to our approach are Twitter’s Community Notes [95, 77], whose governance81
is intended to be fully community-driven. More specifically, the system allows a community of82
contributors to add a note to misleading tweets, e.g. to correct misinformation or to add context83
to prevent confusion. The contributors cannot only propose the note; they are also asked to assess84
other contributors’ notes. Notes that are judged helpful by a sufficiently large and diverse set of85
contributors are then published by the platform. The system is very transparent, and provides a lot of86
freely accessible data on human judgments1.87
1The data can be downloaded here: https://communitynotes.twitter.com/guide/en/
under-the-hood/download-data
2

Structure of the paper. In the sequel, Section 2 will present our public dataset, and the context in88
which the data was provided. Section 3 presents an analysis of our dataset. Section 4 then provides a89
list of research challenges that are raised by the dataset. Finally, Section 5 concludes.90
2 The dataset91
In this section, we describe our main contribution, namely the release of a new, scalable, secured and92
trustworthy database of reliable human judgments.93
2.1 Raw data94
Pretrust. To guarantee the security of our data, Tournesol aims to verify that every account is95
owned and controlled by a human, and that this human only owns and controls this single account96
on the platform. In other words, Tournesol aims to obtain a Proof of Personhood [15] to verify each97
active Tournesol account, and to thereby preventSybil attacks [25]. Unfortunately, there is currently98
no reliable and scalable solution for Proof of Personhood.99
Today’s main solution isemail certification. More precisely, when they create a Tournesol account,100
contributors are asked to validate, if possible, an email address from a trusted email domain. The list101
of trusted email domains is currently managed manually. An email domain will be considered trusted102
if it seems sufficiently unlikely that a large number of fake accounts can be created from this domain.103
This excludes domains like @gmail.com and personal domains like @my-personal-website.com.104
The concern is not only that the domain will maliciously create a large number of fake accounts; it105
is also that they may be hacked by a malicious entity that will create such fake accounts. The list106
of trusted email domains is available at https://tournesol.app/email_domains. It includes107
domains like @epfl.ch, @who.int and @rsf.org. 703 contributors are thereby authenticated.108
Evidently, however, this solution is still highly imperfect. On one hand, this does not guarantee the109
absence of fake accounts. On the other hand, and perhaps more importantly, this excludes most110
potential contributors from participating.111
Vouching mechanism. To propagate trust to more accounts, Tournesol also proposes a vouching112
mechanism. Namely, any account can vouch for the authenticity of another account. More precisely,113
the account must vouch that the other account is used by a human who is not using any other account114
on the platform. The dataset contains 129 vouches.115
Comparison-based judgments. Following a large literature on the topic [38, 17, 66, 10, 73, 60, 42],116
Tournesol relies on a comparison-based preference elicitation system. We believe that the need to117
distinguish among top content which should be more recommended makes this system more suitable118
than, e.g., using direct assessments [63, 2, 55, 85], which may yield too many “saturated” maximal119
assessments. Additionally, comparisons are labelled with the week in which the comparison was first120
submitted. This allows potentially observing changes or drifts in the contributors’ judgments.121
Figure 1 (left) presents the video comparison interface. Namely, contributors are asked to select two122
videos, and to tell Tournesol which one of the videos should be recommended at scale. Moreover,123
rather than a binary decision, the contributor is asked to provide the judgment by moving a slider on124
a more continuous scale, from −10 to 10, The value −10 means that the contributor would prefer125
Tournesol to recommend the left video vastly more often than the right videos, while the value 0126
means that they believe both videos should be recommended equally often.127
Quality criteria. Tournesol allows contributors to rate nine otheroptional quality criteria (Figure 1)128
• Reliable and not misleading: Is the presented information trustworthy, robustly backed and129
properly nuanced?130
• Clear and pedagogical: How efficiently does the content guide viewers in their understanding?131
• Important and actionable: Can additional focus on this topic have a significantly positive impact132
on the world?133
• Layman-friendly: How understandable is it, without prior knowledge?134
3

Figure 1: The interface through which contributors are asked to provide judgments. The judgments are
comparisons of video contents using a slider along the main criteria "should be largely recommended"
(left) and optional quality criteria (right).
• Entertaining and relaxing: Do people feel good watching it?135
• Engaging and thought-provoking: Does it catch people’s attention, spark curiosity and invite to136
question previous beliefs?137
• Diversity and inclusion: Does it promote tolerance, compassion and wider moral considerations?138
• Encourages better habits: Does it make people adopt habits that benefit themselves and beyond?139
• Resilience to backfiring risks: Is it adapted to viewers with opposing beliefs? Does it prevent140
misconceptions or undesirable reactions?141
While the criteria are further provided on Tournesol2, most contributors have surely not read thor-142
oughly our descriptions. Arguably, they will more likely judge these criteria according to their own143
understanding, which will be mostly based on the name of the criteria.144
2.2 Processed data145
In addition to the raw data presented thus far, the Tournesol public dataset exports processed data.146
The processing is performed by a pipeline called SOLIDAGO [12].147
Solidago. The pipeline has six modules. First, pretrust and vouches are used to assign trust scores148
to all users. Second, voting rights are assigned to the different users, in a way that includes untrusted149
users, while guaranteeing that they cannot outweigh trusted users. Third, for each criterion and each150
user, the comparisons are turned into the user’s raw scores, using the generalized Bradley-Terry151
model [33]. Fourth, raw scores are scaled, using Mehestan [4], zero-shift and standardization. Fifth,152
scaled scores are securely aggregated into global scores, using the Lipschitz-resilient quadratically153
regularized quantile [ 12]. Sixth, all scores are squashed into (−100, 100), using the map t 7→154
100t/
√
1 +t2. All along, left and right uncertainties on all variables are computed.155
Exported values. Trust scores, squashed individual scores and squashed global scores are provided156
in the public dataset.157
Results. Figure 2 lists the most recommendable videos, according to Tournesol’s contributors, as158
they are displayed on the website.159
2https://tournesol.app/criteria
4

Figure 2: Best videos (left), best English-speaking videos (middle) and best videos along the criterion
“diversity & inclusivity” (right).
2.3 Privacy160
Overall, we encourage transparency in our contributors, as we believe that this will foster important161
research on human judgments, and help make safer and more ethical algorithms. However, we162
acknowledge that, because of social and political pressures, some judgments are dangerous to make163
public, e.g. when criticizing one’s own employer or government. This is why we allow contributors164
to provide data publicly or privately. More precisely, each contributor can select the privacy setting165
of any video they rate. If a video is rated privately, then all its comparisons to any other video will be166
recorded privately. Only Tournesol’s server can access to such data. Conversely, all comparisons that167
involve two publicly rated videos are exported in the Tournesol public dataset.168
2.4 Data collection context169
The contributors to Tournesol receive no financial compensation. Their contributions are mostly170
motivated by the desire to contribute to a democratic AI governance project, and by the will to promote171
content of public interest. Their recruitment is thus organic, and mostly depends on how frequently172
they were exposed to the promotion of the Tournesol project. Evidently, this greatly correlates with173
Tournesol’s communication, which has been heavily supported by the (French-speaking) YouTube174
channel Science4All, and by other science communicators [51]. As a result, the set of contributors175
is in no way representative of the global population. Namely, it is heavily biased towards science176
enthusiasts. Nevertheless, we believe that the data provided by this community should be of great177
interest to AI alignment, at least on topics with a significant scientific component.178
3 Data analysis179
100 101 102 103 104
100
101
102
103
104
105
Number of comparisons provided by the contributors ordered by activity
Figure 3: Number of comparisons provided by the
different contributors, on a log-log scale, which is
typical of Zipf’s law [82].
This section presents some data analyses to pro-180
vide insights in the Tournesol public dataset.181
3.1 Contributors’ contributions182
Figure 3 displays the number of contributions183
per user. Perhaps unsurprisingly, this statistics184
is heavy-tailed; in fact, it seems to fit Zipf’s185
law [82], with a few contributors providing most186
of the comparisons, and most of them providing187
very few. Figure 4 plots the activity through188
time: Tournesol has 100 to 200 weekly active189
users, while the number of monthly active users190
fluctuates between 200 and 900.191
5

Figure 4: Contributors’ participation through time.
3.2 Video and contributor connectivity192
For scores to be meaningful, the contributors must have compared sufficiently many videos in193
common [4]. The contributor comparability graph has a connected component with 7187 contributors194
and diameter of 6, out of the 7,826 contributors that have compared at least 2 videos. The graph has195
208,323 edges out of 30,619,225 possible (0.68%) making it very sparse. But for the induced graph of196
the top 100 most active contributors with a trust at least 0.1 (which correspond to scaling-calibration197
contributors [12]), 3,442 (69.5%) pairs of contributors are comparable. This justifies the restriction198
of scaling calibration to the most active contributors.199
Figure 5 details video comparisons for some highly active users. Interestingly, because the platform200
lets contributors to select their videos to compare, we observe a wide variety of comparison graphs.201
This raises open questions about the uncertainties of the resulting learned scores [33], and about the202
possibility to improve accuracy through active learning [67, 83].203
(a) Contributor “scayrol”
 (b) Contributor “white”
 (c) Contributor “zekk”
 (d) Contributor “ThugFou”
Figure 5: Graphs of video comparisons for different users
3.3 Correlations between criteria204
Figure 6 reports the correlations between quality criteria, in contributors’ comparative judgments.205
Perhaps most remarkably, we observe that the criterion that best predicts whether a video “should206
be more largely recommended” is whether it is “important and actionable”. This finding highlights207
the need to pay greater attention to information prioritization, and especially combatting “ mute208
news” [51]. In particular, there may be an excess of attention to “ fake news”. In fact, [ 75] expose209
numerous strategies from the “merchants of doubts” that do not involve producing false information,210
such as shifting blame, cyberbullying critics or “striking a positive tone” [24].211
Figure 6 also shows that most criteria are only weakly correlated. Two notable exceptions212
are“important and actionable” and “encourage better habits”, and “reliable and not misleading”213
and “clear and pedagogical”, which could be argued to be slightly redundant.214
Note also that, as expected given Berkson’s paradox [11], the correlations decrease if we only consider215
the top 10% videos on Tournesol (i.e. those that are more likely to be recommended).216
6

(a) All videos comparisons
 (b) Comparisons between top 10% videos on Tournesol
Figure 6: Correlations between quality criteria
3.4 Distributions of reported comparisons217
As it is not formally defined how contributors should rate a pair of videos, we expected many218
different expression styles. We ran a clustering algorithm (K-means) on statistics of the distribution219
of comparison values for each user. Figure 7 shows the typical distribution of comparison values220
of each of the eight clusters we identified. While some contributors provided comparisons close to221
“recommend equally” (cluster 3 and 4), others’ comparisons were systematically towards the extreme222
(clusters 2, 5 and 6). This suggests that the discrepancies between their individual scores will be due223
to their expression style, rather than actual differences in their judgments, which justifies the research224
on mitigating the heterogeneity in expression styles [53, 93, 4].225
Figure 7: Example centroids of 8 clusters obtained by the K-means algorithm applied to the distribu-
tions of comparison values for each contributor with at least 20 comparisons.
3.5 Psychological biases in contributors’ judgments226
our dataset exposes psychological biases in contributors’ judgments. One example is a instinctive227
desire to over-recommend a recently watched high-quality video, known as the recency bias [62],228
which is depicted by Figure 8a. Namely, this figure plots all comparisons on the main criterion that229
correspond to a contributor evaluating a given video for the first time (negative scores correspond230
7

to the newly scored videos). The 95% confidence interval for the mean of first-time comparisons is231
[−0.40, −0.32], which is arguably a surprisingly significant bias.232
Another bias we observe is a tendency to favor left videos. The 95% confidence interval for the mean233
of the main-criterion comparisons (Figure 8b) is [−0.49, −0.44]. Considering all criteria (Figure 8c)234
yields a smaller bias, with a corresponding 95% confidence interval of [−0.17, −0.15]. This suggests235
that reflecting on more criteria reduces the left-video bias. And indeed, when they are accompanied236
with comparisons on other criteria, the main-criterion comparisons have a 95% confidence interval for237
the mean equal to [−0.38, −0.31], as opposed to [−0.57, 0.52] for main-criterion-only comparisons.238
We also observe that pretrusted contributors have a significantly reduced left-video bias (on all criteria,239
[−0.03, −0.002] for pretrusted, [−0.34, −0.31] for unpretrusted).240
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.0
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16 New video to be compared is left
New is right (but set left in Figure)
(a) First comparisons on main crite-
rion (newly compared video is left).
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.0
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16
Main criterion only
With optional criteria
(b) Comparisons on main criterion,
separated based on optional criteria.
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0 7.5 10.0
0.00
0.05
0.10
0.15
0.20
0.25
From trusted users
From untrusted users
(c) Comparisons on all criteria, sep-
arated based on trust.
Figure 8: Recency and left-video biases in contributors’ judgments.
3.6 Distribution of scores241
Figure 9: Distribution of un-
squashed scores, with logarithmic
y-scale.
Unsquashed scores (essentially, as outputs of the generalized242
Bradley-Terry model on contributors’ comparisons) are ex-243
tremely heavy tailed. Indeed, out of 634516 scores, 2803 devi-244
ate by more than 5 standard deviations. This is to be contrasted245
with the expected number 0.18 of such extreme scores, assum-246
ing a normal distribution of the scores. In fact, 428 scores247
deviate by more than 10 standard deviations. This observation248
justifies the use of comparisons to quantify the potential large249
deviations between top alternatives, which direct scoring ap-250
proaches might fail to account for appropriately, as well as of a251
(robustified) quantile to standardize scores [12].252
4 Research challenges253
Tournesol raises numerous fascinating research challenges. Below, we sketch some of these.254
Aggregate the different criteria into a score. We expect the combination of many different quality255
criteria to yield a more reliable judgment of what content ought to be recommended at scale, or to256
a given specific user. However, the appropriate aggregation of our different quality criteria is still257
unclear, especially given probable nonlinear phenomena. How best to do this should be investigated.258
Debiais the contributing population. Like in many online participatory projects [9], we expect259
huge participation imbalances. Leveraging demographic data to debias the Tournesol recommenda-260
tions, e.g., by giving more voting rights to individuals from underrepresented communities, could261
help, but it will require both (safely) collecting personal data and building new (secure) algorithms,262
akin to those used by the Community Notes3 or by Pol.is4.263
Volition. As Section 3.5 highlighted it, we cannot expect the Tournesol database to contain fully264
reliable human judgments. Many comparisons have surely been provided by contributors, at moments265
when they were not paying the utmost attention to all the possible ramifications and unwanted side266
3https://communitynotes.twitter.com/guide/en/under-the-hood/ranking-notes
4https://compdemocracy.org/algorithms/
8

effects of promoting a video at scale. In particular, some judgments will arguably be more reliable267
than others. Such more reliable judgments are sometimes called volitions, rather than preferences.268
There is a need for algorithms that model human psychology to distinguish these two [50, 59].269
Privacy. Tournesol’s current algorithms do not provide anydifferential privacy[26]. Future research270
should also investigate how to strengthen privacy without harming too much the quality and the271
security of the Tournesol scores. Perhaps most importantly, ideally, Tournesol’s servers would be272
able to leverage private comparisons to score videos without being a single point of failure for private273
data protection. Secure multi-party computations could be a promising venue to do so [20].274
Decentralize Tournesol. A longer-term goal is to fully decentralize Tournesol. In this vision, the275
data would no longer be stored on Tournesol’s server, but would be replicated appropriately on a276
large number of contributors’ devices. Moreover, the computations of Tournesol scores should also277
be decentralized, while guaranteeing Byzantine resilience [58]. Recent research in fully decentralized278
Byzantine learning has provided the building blocks of such a decentralization [29, 35], but more279
research is needed to understand how to best do so in the context of Tournesol.280
Preference generalization. Right now, contributors are only voting on the videos that they explicitly281
compared. However, if they consistently voted positively all the videos of a given channel, then we282
could guess that they would have voted positively a new video from this channel, and to include their283
likely vote even when they did not compare the new video. Evidently, additional information can284
be leveraged to make such generalizations, such as the other video features (description, transcript,285
length), and the other contributors’ judgments (using collaborative filtering [84]). Note however that286
generalization increases vulnerability risks. A careful security analysis would be required [68].287
Language model alignment. Tournesol’s database could help align language models, e.g. through288
reinforcement learning with Tournesol feedback[21, 76]. Determining how to combine large language289
models [37] with Tournesol’s database to design safer models is an exciting venue for future work.290
Leverage expertise. On technical topics like vaccination or climate change, especially when291
misconceptions are widespread in the general population, it seems desirable to assign more voting292
rights to experts, especially when judging the reliability of content within their domains of expertise.293
This issue is intimately connected to Condorcet’s jury problem [22, 72].294
Proof of Personhood with zero knowledge. Combatting fake accounts arguably remains the top295
priority to secure participatory systems. To address this, at least in democratic countries and in the296
short term, the state could be tasked with delivering Proofs of Personhood [16, 41], if possible in a297
zero-knowledge manner. More precisely, any citizen should ideally be able to provide to any platform298
a proof of citizenship, which does not enable neither the platform nor the state to identify which299
account is owned by which citizen. We believe that designing such a system could have applications300
beyond the particular case of Tournesol. Indeed, we could demand that social media only display301
the number of likes from users with a delivered proof of citizenship, and that their recommendation302
algorithms be trained only by such certified users’ data.303
Liquid democracy Finally, future work could investigate the extent to which a liquid democ-304
racy [48] could be set up on plateforms like Tournesol. Such a system through which a contributor305
can delegate their votes to other voters could help combat activity bias (i.e. better accounting for306
inactive contributors) and expertise (if voters delegate to more competent contributors). While307
philosophically appealing, the security of such a system should however be first investigated [5].308
5 Conclusion309
This paper introduced the Tournesol public dataset, which is a large, secured and trustworthy database310
of reliable human judgments. We detailed its construction, and provided an analysis of its content.311
We believe that this database can help stimulate and facilitate research and development on ethical312
algorithms, and could eventually help improve the informational diet of billions of people for the better.313
Given the current information crisis, we regard this as an “important and actionable” contribution.314
9

Datasheets for datasets.Commun. ACM, 64(12):86–449
92, 2021.450
[45] Dominique Geissler, Dominik Bär, Nicolas Pröllochs, and Stefan Feuerriegel. Russian pro-451
paganda on social media during the 2022 invasion of ukraine. EPJ Data Science, 12(1):35,452
2023.453
[46] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L. Isbell Jr., and Andrea Lock-454
erd Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. In455
Christopher J. C. Burges, Léon Bottou, Zoubin Ghahramani, and Kilian Q. Weinberger, editors,456
Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural457
Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake458
Tahoe, Nevada, United States, pages 2625–2633, 2013.459
12

[47] Gillian Kereldena Hadfield. Rules for a flat world: why humans invented law and how to460
reinvent it for a complex global economy. Oxford University Press, 2017.461
[48] Daniel Halpern, Joseph Y . Halpern, Ali Jadbabaie, Elchanan Mossel, Ariel D. Procaccia, and462
Manon Revel. In defense of liquid democracy. In Kevin Leyton-Brown, Jason D. Hartline,463
and Larry Samuelson, editors, Proceedings of the 24th ACM Conference on Economics and464
Computation, EC 2023, London, United Kingdom, July 9-12, 2023, page 852. ACM, 2023.465
[49] Adam D Hernandez. Cambridge analytica. Class, Race and Corporate Power, 11(2), 2023.466
[50] Lê Nguyên Hoang. Towards robust end-to-end alignment. In Huáscar Espinoza, Seán Ó467
hÉigeartaigh, Xiaowei Huang, José Hernández-Orallo, and Mauricio Castillo-Effen, editors,468
Workshop on Artificial Intelligence Safety 2019 co-located with the Thirty-Third AAAI Confer-469
ence on Artificial Intelligence 2019 (AAAI-19), Honolulu, Hawaii, January 27, 2019, volume470
2301 of CEUR Workshop Proceedings. CEUR-WS.org, 2019.471
[51] Lê Nguyên Hoang. Science communication desperately needs more aligned recommendation472
algorithms. Frontiers in Communication, 5:115, 2020.473
[52] Le Nguyen Hoang and El Mahdi El Mhamdi. Le fabuleux chantier: Rendre l’intelligence474
artificielle robustement bénéfique. edp Sciences, 2019.475
[53] Lê Nguyên Hoang, François Soumis, and Georges Zaccour. Measuring unfairness feeling in476
allocation problems. Omega, 65:138–147, 2016.477
[54] Chiungjung Huang. A meta-analysis of the problematic social media use and mental health.478
International Journal of Social Psychiatry, 68(1):12–33, 2022.479
[55] Ankur Joshi, Saket Kale, Satish Chandel, and D Kumar Pal. Likert scale: Explored and480
explained. Current Journal of Applied Science and Technology, pages 396–403, 2015.481
[56] Jastra Kanjec. Facebook removed more than 15 billion fake accounts in two years, five times482
more than its active user base. StockApps, 2021.483
[57] Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Byzantine-robust learning on heteroge-484
neous datasets via bucketing. In The Tenth International Conference on Learning Representa-485
tions, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022.486
[58] Leslie Lamport, Robert E. Shostak, and Marshall C. Pease. The byzantine generals problem.487
ACM Trans. Program. Lang. Syst., 4(3):382–401, 1982.488
[59] Mohamed Lechiakh and Alexandre Maurer. V olition learning: What would you prefer to prefer?489
In Helmut Degen and Stavroula Ntoa, editors, Artificial Intelligence in HCI - 4th International490
Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023,491
Copenhagen, Denmark, July 23-28, 2023, Proceedings, Part I, volume 14050 of Lecture Notes492
in Computer Science, pages 555–574. Springer, 2023.493
[60] Min Kyung Lee, Daniel Kusbit, Anson Kahng, Ji Tae Kim, Xinran Yuan, Allissa Chan, Daniel494
See, Ritesh Noothigattu, Siheon Lee, Alexandros Psomas, and Ariel D. Procaccia. Webuildai:495
Participatory framework for algorithmic governance. Proc. ACM Hum. Comput. Interact. ,496
3(CSCW):181:1–181:35, 2019.497
[61] Xiangru Lian, Binhang Yuan, Xuefeng Zhu, Yulong Wang, Yongjun He, Honghuan Wu, Lei498
Sun, Haodong Lyu, Chengjun Liu, Xing Dong, et al. Persia: An open, hybrid system scaling499
deep learning-based recommenders up to 100 trillion parameters. In Proceedings of the 28th500
ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 3288–3298, 2022.501
[62] David A Liebermann. Learning and memory: An integrative approach. Belmont, CA: Thom-502
son/Wadsworth, 2004.503
[63] Rensis Likert. A technique for the measurement of attitudes. Archives of psychology, 1932.504
[64] Zhifan Luo. “why should facebook (not) ban trump?”: connecting divides in reasoning and505
morality in public deliberation. Information, Communication & Society, 25(5):654–668, 2022.506
13

[65] Kirsten Martin. Recommending an insurrection: Facebook and recommendation algorithms. In507
Ethics of Data and Analytics, pages 225–239. Auerbach Publications, 2022.508
[66] Lucas Maystre. Efficient Learning from Comparisons. PhD thesis, EPFL, 2018.509
[67] Lucas Maystre and Matthias Grossglauser. Just sort it! A simple and effective approach to510
active preference learning. In Doina Precup and Yee Whye Teh, editors, Proceedings of the511
34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11512
August 2017, volume 70 of Proceedings of Machine Learning Research, pages 2344–2353.513
PMLR, 2017.514
[68] Bhaskar Mehta and Thomas Hofmann. A survey of attack-resistant collaborative filtering515
algorithms. IEEE Data Eng. Bull., 31(2):14–22, 2008.516
[69] Silvia Milano, Mariarosaria Taddeo, and Luciano Floridi. Ethical aspects of multi-stakeholder517
recommendation systems. The information society, 37(1):35–45, 2021.518
[70] Michael K Miller. A republic, if you can keep it: Breakdown and erosion in modern democracies.519
The Journal of Politics, 83(1):198–213, 2021.520
[71] Paul Mozur. A genocide incited on facebook, with posts from myanmar’s military. The New521
York Times, 15(10):2018, 2018.522
[72] Shmuel Nitzan and Jacob Paroush. Optimal decision rules in uncertain dichotomous choice523
situations. International Economic Review, pages 289–297, 1982.524
[73] Ritesh Noothigattu, Snehalkumar (Neil) S. Gaikwad, Edmond Awad, Sohan Dsouza, Iyad525
Rahwan, Pradeep Ravikumar, and Ariel D. Procaccia. A voting-based system for ethical526
decision making. In Sheila A. McIlraith and Kilian Q. Weinberger, editors, Proceedings of527
the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative528
Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational529
Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7,530
2018, pages 1587–1594. AAAI Press, 2018.531
[74] Alina Oprea and Apostol Vassilev. Adversarial machine learning: A taxonomy and terminology532
of attacks and mitigations. Technical report, National Institute of Standards and Technology,533
2023.534
[75] Naomi Oreskes and Erik M Conway. Merchants of doubt: How a handful of scientists obscured535
the truth on issues from tobacco smoke to global warming. Bloomsbury Publishing USA, 2011.536
[76] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and537
Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model.538
In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine,539
editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural540
Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 -541
16, 2023, 2023.542
[77] Luca Righes, Mohammed Saeed, Gianluca Demartini, and Paolo Papotti. The community notes543
observatory: Can crowdsourced fact-checking be trusted in practice? In Ying Ding, Jie Tang,544
Juan F. Sequeda, Lora Aroyo, Carlos Castillo, and Geert-Jan Houben, editors, Companion545
Proceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 -546
4 May 2023, pages 172–175. ACM, 2023.547
[78] Yasmim Mendes Rocha, Gabriel Acácio de Moura, Gabriel Alves Desidério, Carlos Henrique548
de Oliveira, Francisco Dantas Lourenço, and Larissa Deadame de Figueiredo Nicolete. The549
impact of fake news on social media and its influence on health during the covid-19 pandemic:550
A systematic review. Journal of Public Health, pages 1–10, 2021.551
[79] Allen L. Schirm Ronald Wasserstein and Nicole A. Lazar. Moving to a world beyond “p< 0.05”.552
The American Statistician, 73:1–19, 2019.553
[80] Sébastien Rouault. Practical Byzantine-resilient Stochastic Gradient Descent . PhD thesis,554
EPFL, 2021.555
14

[81] Stuart Russell. Human compatible: Artificial intelligence and the problem of control. Penguin,556
2019.557
[82] Alexander I. Saichev, Yannick Malevergne, and Didier Sornette. Theory of Zipf’s law and558
beyond, volume 632. Springer Science & Business Media, 2009.559
[83] Ayush Sekhari, Karthik Sridharan, Wen Sun, and Runzhe Wu. Contextual bandits and imitation560
learning with preference-based active queries. In Alice Oh, Tristan Naumann, Amir Globerson,561
Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information562
Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023,563
NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023.564
[84] Xiaoyuan Su and Taghi M. Khoshgoftaar. A survey of collaborative filtering techniques. Adv.565
Artif. Intell., 2009:421425:1–421425:19, 2009.566
[85] Basu Prasad Subedi. Using likert type data in social science research: Confusion, issues and567
challenges. International journal of contemporary applied sciences, 3(2):36–49, 2016.568
[86] Gan Sun, Yang Cong, Jiahua Dong, Qiang Wang, Lingjuan Lyu, and Ji Liu. Data poisoning569
attacks on federated machine learning. IEEE Internet of Things Journal, 9(13):11365–11375,570
2021.571
[87] Maxime Tellier. Enquête avisa partners : dans les coulisses de la sulfureuse agence d’influence572
soupçonnée de désinformation. France Info, 2023.573
[88] Mariame Tighanimine. L’affaiblissement des corps intermédiaires par les plateformes Internet.574
Le cas des médias et des syndicats français au moment des Gilets jaunes. Conservatoire National575
des Arts et Métiers, 2019.576
[89] Petter Törnberg. How digital media drive affective polarization through partisan sorting.577
Proceedings of the National Academy of Sciences, 119(42):e2207159119, 2022.578
[90] Zeynep Tufekci. Twitter and tear gas: The power and fragility of networked protest . Yale579
University Press, 2017.580
[91] Jean M Twenge, Jonathan Haidt, Jimmy Lozano, and Kevin M Cummins. Specification curve581
analysis shows that social media use is linked to poor mental health, especially among girls.582
Acta psychologica, 224:103512, 2022.583
[92] Myriam Vidal Valero. Thousands of scientists are cutting back on twitter. Nature, 620:482–4,584
2023.585
[93] Jingyan Wang and Nihar B. Shah. Your 2 is my 1, your 3 is my 9: Handling arbitrary586
miscalibrations in ratings. In Edith Elkind, Manuela Veloso, Noa Agmon, and Matthew E.587
Taylor, editors, Proceedings of the 18th International Conference on Autonomous Agents and588
MultiAgent Systems, AAMAS ’19, Montreal, QC, Canada, May 13-17, 2019, pages 864–872.589
International Foundation for Autonomous Agents and Multiagent Systems, 2019.590
[94] Gabriel Weimann and Natalie Masri. Research note: Spreading hate on tiktok. Studies in591
conflict & terrorism, 46(5):752–765, 2023.592
[95] Valerie Wirtschafter and Sharanya Majumder. Future challenges for online, crowdsourced593
content moderation: Evidence from twitter’s community notes. Journal of Online Trust and594
Safety, 2(1), Sep. 2023.595
15

A Datasheet for the Tournesol dataset596
In this appendix, we provide a datasheet for the Tournesol dataset, based on the framework proposed597
by [44].598
A.1 Motivation599
For what purpose was the dataset created? The dataset was created to identify videos of public600
interest that should be recommended more largely. Additionally, we hope that the dataset will help601
motivate research on the ethics and security of recommendation algorithms.602
Who created the dataset and on behalf of which entity? The dataset was created by the nonprofit603
Tournesol Association, which is based in Switzerland.604
Who funded the creation of the dataset? The Tournesol Association is supporting the creation605
and maintenance of the dataset. It is in majority funded by crowdsourced donations, with occasional606
services to private companies.607
A.2 Composition608
What do the instances that comprise the dataset represent? The dataset contains mostly pairwise609
comparisons of videos by users. The dataset also contains vouches between users, authentication610
status, as well as processed data from this raw data.611
How many instances are there in total? The dataset contains 20k users (703 pretrusted), 40k612
videos, 126 vouches, 204k comparisons along the main criterion and 703k comparisons along optional613
criteria.614
Does the dataset contain all possible instances or is it a sample of instances of a larger set? The615
dataset contains all public judgments provided on the Tournesol platform.616
What data does each instance consist of? Each user has a pretrust status, based on email domain617
Sybil resilience. Each comparison is along a criterion, and refers to a user and a pair of videos.618
Is there a label or target associated with each instance? Each comparison takes a value between619
-10 and 10.620
Is any information missing from individual instances? Yes, plenty, such as the time it took to621
provide an answer, whether it was provided on a phone or a desktop, or whether the contributor622
actually watched the compared videos.623
Are relationships between individual instances made explicit? Some of them, yes, such as the624
contributor’s identifier, or the videos that are compared.625
Are there recommended data splits? Yes, comparisons are naturally split by criterion, or by users.626
Trusted/untrusted contributions could be split.627
Are there any errors, sources of noise, or redundancies in the dataset? The comparisons come628
from humans, and are thus noisy, as well as potentially biased as discussed in the main part of the629
paper. Note that 4,446 comparisons were made before January 11, 2021, but because of a migration630
of the code, are dated on the January 11, 2021 week.631
Is the dataset self-contained, or does it link to or otherwise rely on external sources? The632
dataset refers to YouTube videos, but could be analyzed without knowledge of the videos.633
Does the dataset contain data that might be considered confidential? No. It was designed to be634
public.635
16

Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening636
or might otherwise cause anxiety? Some poorly scored videos could be of this sort. Their content637
is not directly in the dataset, but the dataset points to them.638
Does the dataset identify any subpopulations? Yes, trusted and untrusted contributors.639
Is it possible to identify individuals, either directly or indirectly, from the dataset? Yes,640
especially given their public usernames.641
Does the dataset contain data that might be considered sensitive in any way? Yes, indirectly, as642
it reveals consumption habits of contributors.643
Any other comments? The individuals not only gave their consent, but the Tournesol also aims to644
make it clear that their provided data are used to design a democratic governance, and as such, could645
and should be scrutinized.646
A.3 Collection process647
How was the data associated with each instance acquired? Through the Tournesol platform648
https://tournesol.app.649
What mechanisms or procedures were used to collect the data? Through the Tournesol compar-650
ison interface https://tournesol.app/comparison.651
If the dataset is a sample from a larger set, what was the sampling strategy? Based on652
public/private settings selected by the contributor.653
Who was involved in the data collection process and how were they compensated? Contributors654
are volunteers, most of whom are recruited through promotion in science YouTube videos. They are655
not compensated.656
Over what timeframe was the data collected? The first data was collected in May 2020. The657
collection has been continuously ongoing since.658
Were any ethical review processes conducted? Not by an institutional review board, as our work659
was done by a nonprofit association.660
Did you collect the data from the individuals in question directly, or obtain it via third parties661
or other sources? Yes, through the Tournesol platform that we designed.662
Were the individuals in question notified about the data collection? Yes. They had to cre-663
ate a Tournesol account, to consent with the data collection, and to select whether to make their664
contributions public or not.665
Did the individuals in question consent to the collection and use of their data? Yes.666
If consent was obtained, were the consenting individuals provided with a mechanism to revoke667
their consent in the future or for certain uses? Yes, contributors can delete their Tournesol668
account, which will delete their data from Tournesol’s (public) dataset.669
Has an analysis of the potential impact of the dataset and its use on data subjects been con-670
ducted? Yes, we are consistently trying to make our project robustly beneficial.671
A.4 Preprocessing/cleaning/labeling672
Was any preprocessing/cleaning/labeling of the data done? Yes. To output trust scores, as well673
as squashed individual and global scores.674
17

Was the “raw” data saved in addition to the preprocessed/cleaned/labeled data? Yes. It is675
published in the Tournesol dataset.676
Is the software that was used to preprocess/clean/label the data available? Yes. It is the677
open-source free-license Solidago python package.678
A.5 Uses679
Has the dataset been used for any tasks already? Yes, it is used to make content recommendations680
to 10k+ users.681
Is there a repository that links to any or all papers or systems that use the dataset? Such682
papers and systems are listed in tournesol.app/#research.683
What (other) tasks could the dataset be used for?684
Is there anything about the composition of the dataset or the way it was collected and prepro-685
cessed/cleaned/labeled that might impact future uses?686
Are there tasks for which the dataset should not be used? The dataset should not be used to687
harm individuals, communities or society.688
A.6 Distribution689
Will the dataset be distributed to third parties outside of the entity (e.g., company, insti-690
tution, organization) on behalf of which the dataset was created? Yes. It is published on691
api.tournesol.app/exports/all.692
How will the dataset be distributed? zip file downloadable from the website.693
When will the dataset be distributed? Already is.694
Will the dataset be distributed under a copyright or other intellectual property license, and/or695
under applicable terms of use? Yes, it is under ODC-By license.696
Have any third parties imposed IP-based or other restrictions on the data associated with the697
instances? No.698
Do any export controls or other regulatory restrictions apply to the dataset or to individual699
instances? Not to our knowledge.700
A.7 Maintenance701
Who will be supporting/hosting/maintaining the dataset? The Tournesol association.702
How can the owner/curator/manager of the dataset be contacted? hello@tournesol.app703
Is there an erratum? No.704
Will the dataset be updated? Yes. It is weekly updated, based on Tournesol’s users newly reported705
data.706
If the dataset relates to people, are there applicable limits on the retention of the data associated707
with the instances? No limit applies.708
Will older versions of the dataset continue to be supported/hosted/maintained? Yes, the dataset709
is consistently updated every week, based on contributors’ activity.710
18

If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for711
them to do so? The dataset is fully under the control of the Tournesol association. It is however712
under ODC-By license, thus any reuse is welcome, as long as attribution is appropriately provided.713
19

NeurIPS Paper Checklist714
1. Claims715
Question: Do the main claims made in the abstract and introduction accurately reflect the716
paper’s contributions and scope?717
Answer: [Yes]718
Justification: The main contribution is, as explained, the publication of the datset.719
2. Limitations720
Question: Does the paper discuss the limitations of the work performed by the authors?721
Answer: [Yes]722
Justification: We explained the context in which the data is provided, and the limitations723
that this implies.724
3. Theory Assumptions and Proofs725
Question: For each theoretical result, does the paper provide the full set of assumptions and726
a complete (and correct) proof?727
Answer: [NA]728
Justification: Our paper dos not provide theoretical results.729
4. Experimental Result Reproducibility730
Question: Does the paper fully disclose all the information needed to reproduce the main ex-731
perimental results of the paper to the extent that it affects the main claims and/or conclusions732
of the paper (regardless of whether the code and data are provided or not)?733
Answer: [Yes]734
Justification: The code base and the data is available online and under copyleft free license.735
5. Open access to data and code736
Question: Does the paper provide open access to the data and code, with sufficient instruc-737
tions to faithfully reproduce the main experimental results, as described in supplemental738
material?739
Answer: [Yes]740
Justification: The data is available at https://api.tournesol.app/exports/all, and741
the code is available at https://github.com/tournesol-app/tournesol/.742
6. Experimental Setting/Details743
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-744
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the745
results?746
Answer: [Yes]747
Justification: We748
7. Experiment Statistical Significance749
Question: Does the paper report error bars suitably and correctly defined or other appropriate750
information about the statistical significance of the experiments?751
Answer: [No]752
Justification: We did not provide statistical significance measures, mostly because statistical753
significance has been heavily criticized [ 79, 8]. Instead, we reported 95% confidence754
intervals. Note that the fact that they do not contain some “null hypothesis” is equivalent to755
saying that the null hypothesis has an associated p-value less than 5%. However, we believe756
that reporting confidence intervals is more meaningful, as it also communicates the effect757
size and an estimate of the uncertainty on the effect size.758
8. Experiments Compute Resources759
Question: For each experiment, does the paper provide sufficient information on the com-760
puter resources (type of compute workers, memory, time of execution) needed to reproduce761
the experiments?762
20

Answer: [No]763
Justification: No significant compute resource is needed. The graphs were all produced on764
basic machines, without the need of, e.g., a GPU.765
9. Code Of Ethics766
Question: Does the research conducted in the paper conform, in every respect, with the767
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?768
Answer: [Yes]769
Justification: Our data collection platform https://tournesol.app repeatedly stresses770
the fact that it aims to collect a public dataset of human judgments to help research. Explicit771
consent is asked when contributors create their account. We make it clear that the contri-772
butions should be made on a voluntarily basis, to help improve the security and ethics of773
recommendation algorithms.774
10. Broader Impacts775
Question: Does the paper discuss both potential positive societal impacts and negative776
societal impacts of the work performed?777
Answer: [Yes]778
Justification: The Tournesol project is fully motivated by the desire to have a positive societal779
impact, by advancing the frontier of the research on the governance of recommendation780
algorithms. We believe that these positive impacts clearly outweigh, and by far, the potential781
negative societal impact, which could include, for instance, the ability of cybercrime to782
better organize themselves.783
11. Safeguards784
Question: Does the paper describe safeguards that have been put in place for responsible785
release of data or models that have a high risk for misuse (e.g., pretrained language models,786
image generators, or scraped datasets)?787
Answer: [Yes]788
Justification: The dataset carefully annotates the source of the data, and contains information789
on the degree of authentication of the sources.790
12. Licenses for existing assets791
Question: Are the creators or original owners of assets (e.g., code, data, models), used in792
the paper, properly credited and are the license and terms of use explicitly mentioned and793
properly respected?794
Answer: [Yes]795
Justification: The dataset is published by ourselves, under ODC-By license.796
13. New Assets797
Question: Are new assets introduced in the paper well documented and is the documentation798
provided alongside the assets?799
Answer: [Yes]800
Justification: The dataset is documented in the paper, and a datasheet for datasets is provided801
in the appendix.802
14. Crowdsourcing and Research with Human Subjects803
Question: For crowdsourcing experiments and research with human subjects, does the paper804
include the full text of instructions given to participants and screenshots, if applicable, as805
well as details about compensation (if any)?806
Answer: [Yes]807
Justification: We provided screenshots and contextualized the data collection process.808
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human809
Subjects810
21

Question: Does the paper describe potential risks incurred by study participants, whether811
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)812
approvals (or an equivalent approval/review based on the requirements of your country or813
institution) were obtained?814
Answer: [Yes]815
Justification: The research was conducted by a nonprofit Association, and did not involve an816
IRB. We discussed the main risk for participants, namely retaliation from the entities they817
criticize. We stress, however, that this is usually not increasing the risk, compared to what818
they may already be publishing on social media.819
22