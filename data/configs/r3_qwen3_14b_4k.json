{
    "model_id": "/home/leelab-coling/.cache/huggingface/hub/models--rubricreward--R3-Qwen3-14B-4k/snapshots/2987caea7c1722f46bc14fa5e292b6a2825ef2d6",
    "use_vllm": true,
    "tensor_parallel_size": 2,
    "model_args": {
        "max_model_len": 10000,
        "gpu_memory_utilization": 0.9,
        "dtype": "float16",
        "trust_remote_code": true,
        "enforce_eager": true
    },
    "generation_args": {
        "temperature": 0.6,
        "top_p": 0.95,
        "top_k": 20,
        "max_tokens": 2048
    }
}
