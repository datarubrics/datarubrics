{"id": "yo9Jyt3XCY", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\n(a) @akhaliq Dataset\\n(b) @arankomatsuzaki Dataset\\n\\nFigure 4. 2-Sample Q-Q Plots comparing the experiment and control set distributions across every quantile. To build the plot, citation counts are log-scaled, normalized to the control distribution (z-scores), sorted, and paired in order. The dotted line shows an equal distribution; any points above the line show a higher experimental quantile, and vice versa. The plots show that both experimental distributions are consistently higher, especially closer to the median.\\n\\nOverall, the correlation between influencer tweets and citation count\u2014and not review scores\u2014points to a shift in how the community finds and reads papers. While traditionally, top conference acceptance (i.e. review score) has been a primary indicator of future citation count (Lee, 2018), we have shown that the sharing practices of far-reaching influencers are now a significant indicator of future research impact through citations.\\n\\nCausal Inference: Setup. Although we have shown a significant correlation between influencer sharing and citations, we have not investigated a causal link. For this, we turn to the model, techniques, and assumptions presented in Elazar et al. (2023). For additional background and details, see Appendix C.\\n\\nWe aim to estimate the causal effect of the treatment $A$, indicating that the paper was shared by influencers, on the outcome $Y$, if the paper is \u201chighly-cited\u201d or \u201cless-cited.\u201d\\n\\nTo increase sample size and simplify our analysis, we combine our test sets for this portion of the analysis.\\n\\nTest\\n\\n| Test         | p-value |\\n|--------------|---------|\\n| Kolmogorov-Smirnov | <0.0001 |\\n| Man-Whitney U  | <0.0001 |\\n\\nTable 5. 2-sample Statistical significance tests for the difference in distributions of the two experiment and control datasets. These tests suggest a statistically significant difference in the experimental and control distributions for both influencer datasets.\\n\\nBesides $A$, there are a number of other factors, known as confounders, that can affect $Y$. We divide these confounders into two sets: observed $C$\u2014which are the same used in our matching (Section 3)\u2014and unobserved $U$\u2014which are difficult to quantify or measure (e.g. novelty, contribution, hype).\\n\\nTo debias the effects of unobserved confounders $U$, we employ the negative outcome control (NOC) framework (Card & Krueger, 1993; Lipsitch et al., 2010). By finding a negative control outcome $N$ that shares the same confounders as $Y$, but is not causally affected by $A$, we can attempt to correct for the bias introduced by $U$. To this end, we select a paper's average review score for $N$, which we have already shown is not significantly correlated to $A$ (Figure 2) and which we believe share many of the same confounders (e.g., quality, contribution, author experience). However, another NCO can be substituted if deemed more suitable.\\n\\nTo account for fine-grained citation counts and review scores in comparison to the binary nature of $Y$ and $N$, we define $Y_p$ and $N_q$. For both, their value is 1 if the corresponding real-valued quality (citation count or average review score) is above the $p$th (or $q$th) quantile of the relevant sample distribution. We will use values of $\\\\{50, 75, 90\\\\}$ for both $p$ and $q$ in our analysis.\\n\\nFinally, we estimate the causal effect of influencer sharing on paper citations with the average treatment effect of the treated. Using the difference-in-difference assumption with NOC, we can write our estimate (Elazar et al., 2023):\\n\\n$$\\\\text{ATET} = E[Y_{A=1} - N_{A=1}] - E[Y_{A=0} - N_{A=0}]$$\\n\\nwhere $\\\\text{ATET} \\\\in [-100\\\\%, 100\\\\%]$ values closer to 0% indicate a significant shift in citation patterns.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\nFigure 5. Forest plot of ATET and confidence intervals approximated with negative outcome control (NOC). Larger positive values indicate a stronger positive causal effect of the treatment (influencer sharing) on the outcome (a paper being \u201chighly-cited\u201d). To ensure robust results, we vary the quantile threshold for \u201chighly-cited\u201d and \u201chighly-scored\u201d papers; \u201cUnadj.\u201d values (red squares) show the effect estimate before applying NOC. These results, where no confidence intervals contain 0%, indicate a significant positive causal effect of influencer sharing on paper citations.\\n\\nCausal Inference: Results.\\n\\nFirst, we estimate the effect of $A$ on $Y$ without accounting for the effects of $U$. We estimate ATET (95%-bootstrapping CI) to be 19% (15-24), 16% (13-20), 9% (6-12) for $p = \\\\{50, 75, 90\\\\}$, respectively. This confirms the significant association between influencer sharing and citations we investigated during the contrasting analysis. However, this does not preclude the existence of strong confounders. For that, we will use NOC to attempt to debias the effects of unobserved confounders, including quality. We record our results in Figure 5 and observe the following: (1) debiased effects are smaller than the unadjusted estimates, indicating our NCO has succeeded in accounting for some unobserved confounders; (2) all of our estimated effects are significant to the 95% level, because none contain 0 in their confidence interval; (3) influencer sharing is most successful at increasing the citations in lower percentiles\u2013papers with very high citation counts experience a smaller (yet still significant) effect compared to those with fewer citations.\\n\\nGeographic Distributions.\\n\\nIn exploring the evolving landscape of machine learning (ML) paper dissemination, it is essential to consider the implications of a more centralized curation model, particularly as it relates to geographic and gender diversity in scholarly works. Our approach is to present data and observations that highlight trends and do not attribute intentional bias to the influencers involved.\\n\\nOur analysis begins by examining the geographic distribution in the dissemination of ML papers. Given the American affiliations of AK and Aran Komatsuzaki, we explore whether this translates into a geographic skew in the papers they share. To contextualize our findings, we refer to the geographic distribution of AI repository publications from the Stanford HAI 2023 AI Index Report (Figure 7). We choose to view this data in particular, as our selected influencers share papers from repositories (i.e. ArXiV).\\n\\nTo test this, we first collect the geographic data of the shared papers. First, we use S2 and dblp (2023) to collect the affiliation data of all listed authors from each test set. We then utilize the Nominatim geocoding API to find the approximate latitude and longitude of each affiliation, manually adjusting visibly inaccurate coordinates. From this information, we find the country of each affiliation and then use majority voting to assign each publication a geographic area. At this point, we can see that both influencers share papers from around the world in Figure 6. Finally, we aggregate these countries into the same geographic areas used in the HAI Report and plot using a similar format (Figure 8).\\n\\nTo account for the discrepancy between date ranges in the HAI Report and our influencers\u2019 activity, we will limit our analysis to the overlap between them. Additionally, we will focus on the range from 2018 to 2021, because of the low sample size of shared papers pre-2018\u2013only 5 in total. During these years, Figure 7 indicates a slight decline in the United States\u2019 share of AI repository publications following its peak. Concurrently, the European Union and United Kingdom demonstrate a modest uptick in publications after a consistent decline from 2010-2017, while China\u2019s share continues to rise.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\n(a) affiliation heatmap of @akhaliq-shared authors\\n(b) affiliation heatmap of @arankomatsuzaki-shared authors\\n\\nFigure 6. Geographic heatmaps of the unique affiliations of influencer-shared paper authors. High density (red) on the map represents a large number of unique institutions and not a large number of papers, citations, or authors from the given area. Both influencers shared from institutions around the world, with especially large hotspots in the US and Europe.\\n\\nFigure 7. AI repository publications by geographic area and publication year, 2010\u20132021. Data extracted from Figure 1.1.19 of the Stanford HAI 2023 AI Index Report (Maslej et al., 2023).\\n\\nIn contrast, the sharing patterns of the influencers from 2018 to 2021, shown in Figure 8, demonstrate a notable deviation from these global trends. Specifically, both influencers' data exhibits a consistent focus on U.S.-affiliated papers, with a much smaller, relatively constant portion from other areas. The increase in U.S.-affiliated papers seems to be a change in reporting rather than a change in sharing practices.\\n\\nWe must note, though, that using solely self-reported affiliations can have an inherent bias toward the United States. For example, many researchers affiliated with U.S.-based organizations are assigned to the United States despite working out of another area. Additionally, we must note the prominence of the \\\"Unknown\\\" category in the data of both influencers, where affiliations were not found.\\n\\nNevertheless, our results highlight the potential for centralized individuals to shape the perceived narrative of AI research prominence.\\n\\nGender Distributions. Beyond geographic diversity, gender diversity is crucial in Computer Science and Engineering, fields historically dominated by men. We extract author names and affiliations as described above. In this section, we filter only the first authors of each paper. For gender classification, we used the AMiner Scholar Gender Prediction API, which categorizes authors as \\\"male,\\\" \\\"female,\\\" or \\\"UNKNOWN\\\" based on name and affiliation\u2014if available. The API uses a majority vote of the results from three sources: google image search and facial recognition, the Facebook Generated Names List (Tang et al., 2011), and WebGP (Gu et al., 2016).\\n\\nTo ground our view of the overall gender distribution in the field, we reference the Taulbee survey's reported gender distribution of US Ph.D. awardees and faculty in CS and related fields from 2021-2022 (Zweben & Bizot, 2023). To match the classifications we have available, we will consider the binary reported genders from the survey.\\n\\nOur analysis revealed an 80:20 male-to-female ratio among authors with identifiable genders in the @akhaliq dataset and an 81:19 ratio in the @arankomatsuzaki dataset. These ratios align somewhat with the Taulbee survey's reported 77:23 ratio in computing Ph.D. awardees and deviated slightly more from the 76:24 ratio in faculty. These deviations may stem from a trend toward increasing female representation in the ML space; the survey is recent data, while our influencer data spans several years into the past.\\n\\n5. Discussion\\n\\nOur analysis suggests that ML influencers strongly affect paper visibility, indicating a change in how ideas are propagated through the community. We discuss the downstream implications of influencers on the community and make recommendations on how to help improve the paper curation problem and enhance equity in publication visibility.\\n\\nInfluencers and the ML Community. Influencers serve as pivotal curators in the ML landscape. With the expl...\"}"}
{"id": "yo9Jyt3XCY", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\n(a) @akhaliq-shared papers by geographic area per year\\n(b) @arankomatsuzaki-shared papers by geographic area per year\\n\\nFigure 8. Influencer-shared publications by geographic area and publication year, 2018-2023, from Semantic Scholar and DBLP affiliation data.\\n\\nThe explosive growth of machine learning research, the community increasingly relies on social media to keep up-to-date with new developments. Their role in streamlining the dissemination process is akin to that of journalists in news media, making novel ideas and breakthroughs more accessible. Yet, reliance on a select few narrows the full spectrum of research. We propose maintaining a competitive, open academic space with diverse, highly visible ideas, advocating for influencers to diversify showcased techniques and concepts. This encourages a broad exploration of the ML landscape, mitigating the risk of a homogeneous research narrative.\\n\\nEnhancing Equity.\\n\\nThe move towards influencer-led dissemination opens paths to greater equity in the ML community. Our findings\u2014pointing out the geographic and gender disparities in shared research\u2014underscore the potential for a more inclusive academic dialogue. We clarify that our analysis does not suggest influencers currently exhibit bias; rather, it highlights an opportunity to mitigate existing inequities through proactive online engagement. By promoting diverse global perspectives and addressing gender disparities, influencers can foster a more equitable field. This effort aligns with our commitment to enhance equity without overemphasizing certain demographics, reflecting the concentration of ML research.\\n\\nTo stimulate community reflection and action, we recommend collaborating with conference chairs to address the pace of research, organizing workshops to explore dissemination improvements, and convening panels of influencers, industry, and academia to discuss enhancements in AI/ML research visibility. These steps aim to refine the research dissemination process and uplift the ICML community\u2019s engagement with emerging and diverse ideas.\\n\\n6. Conclusion\\n\\nOur study delves into the influence of social media influencers on the dissemination and recognition of academic work in AI/ML, specifically examining the impact of AK and Aran Komatsuzaki on platforms like X and Hugging Face. Our analysis demonstrates that papers endorsed by these influencers receive significantly more citations than those that are not, underscoring the role of influencers in not only amplifying the reach of specific research but also in shaping its visibility in the field. This influence extends beyond merely sharing higher-quality papers, highlighting their ability to promote substantial findings within the community.\\n\\nWe further discuss the dual role of influencers as both catalysts for visibility and curators of content, emphasizing the need for a balance in their influence to ensure a diversity of perspectives in the AI/ML research landscape. The implications of this influence are profound, suggesting a need for the academic community to reassess traditional methods of paper selection and review. Our findings encourage a dialogue among conference organizers and academic institutions to evolve the peer-review process and adapt to these changing norms. Additionally, we encourage future research into these trends in other scientific fields and the mechanisms behind the influence of social media on academic recognition.\\n\\nImpact Statement\\n\\nRecognizing the influential role of social media influencers in the academic community, particularly in the fields of AI/ML, it\u2019s important to gently encourage them to be aware of their impact. Influencers play a key role in shaping discussions and trends, and there is a growing need for them to consider the diversity and inclusivity of the research they share. This is not to undermine their contributions but to encourage them to foster a more equitable and inclusive academic environment.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\nIain Xie Weissburg 1\\nMehir Arora 2\\nXinyi Wang 2\\nLiangming Pan 2\\nWilliam Yang Wang 2\\n\\nAbstract\\nAs the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.\\n\\n1. Introduction\\nIn the evolving landscape of artificial intelligence and machine learning (AI/ML), the exponential increase in conference papers, as depicted in Figure 1, alongside rapid technological advancements, has significantly transformed the dissemination of scholarly knowledge. A notable aspect of this transformation is the practice of online preprint sharing, with platforms like ArXiv becoming particularly prominent within the AI/ML community. This phenomenon allows for early access to research, often months before official publication, raising questions about these papers' evolving relevance and reception in traditional academic forums. Most notably, how do people select papers to read in the online age?\\n\\nThis paper aims to explore the changing dynamics of academic discourse within the AI/ML community, emphasizing the constructive role of social media in addressing the challenges posed by the sheer volume of literature. We study the class of X (formerly Twitter) influencers. Specifically, we require that influencers (1) share freshly posted preprints from ArXiv, (2) regularly post about papers, (3) do not focus on self-promotion, and (4) have a large audience. AK (@akhaliq) and Aran Komatsuzaki (@arankomatsuzaki) are the only influencers found to satisfy our requirements. Acknowledging the vital function of these influencers as curators, we examine the impact of their endorsements on the citation counts of shared papers. However, we also underscore the importance of maintaining a balanced research ecosystem. An over-reliance on a select group of curators may inadvertently skew the research landscape, emphasizing certain topics or perspectives over others. Therefore, we advocate for a responsible approach to curation, encouraging influencers to maintain journalistic standards, showcasing diverse research topics, authors, and institutions.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"AI/ML Influencers Have a Place in the Academic Process\\n\\nTo this end, we provide the following three main contributions to the discussion about the increasing impact of academic social media figures in the AI/ML domain:\\n\\n\u2022 Comprehensive Dataset with Control Samples. We collect a dataset of shared papers from AK and Komatsuzaki containing key paper information. We select control samples through precise matching, using several paper and author covariates.\\n\\n\u2022 Thorough Analysis of Citations and Demographics. Our comprehensive analysis aims to determine if papers these influencers share receive higher citation counts than non-shared papers. We conduct statistical and causal inference analysis and find significant evidence for a direct effect. We then explore the geographic and gender distributions of influencer-shared papers and compare them to reference points from the community.\\n\\n\u2022 Proposals for Future AI/ML Information Sharing. Finally, we propose that the academic community engage in a future discussion on evolving the conference system. We want to collaborate with program chairs at major ML conferences to find solutions to the AI/ML research cycle outpacing current conference cycles, making many works outdated by the time of conferences. Second, we propose a future workshop to address the issue by informing the AI/ML community and gathering solutions from community members. Third, we call for a panel of influencers, industry, and academics to discuss how the evolving landscape of AI/ML research can be improved.\\n\\n2. Related Work\\n\\nFor over a decade now, social media platforms\u2013namely X\u2013have been studied as an influential means of scholarly communication. Darling et al. (2013) discusses the potential role of Twitter in many stages of the 'life-cycle' of academic authorship and publication. Eysenbach (2011) provides early evidence to support social media sharing as a predictor of higher citation count in medical publications. More recently, studies have shown a statistically significant relationship between Twitter presence and citation counts across fields, especially after the first tweet (Peoples et al., 2016; Vaghjiani et al., 2021). Others suggest that the correlation between tweets and citations is insignificant through randomized trials (Tonia et al., 2016; Branch et al., 2023). We note that the AI/ML community is much more active on platforms like X. While many previous works examine fields with a much lower volume of repository publications, the short research cycle and the need for quick dissemination of results, coupled with the rise of arXiv, motivates us to study the problem from the perspectives of modern AI/ML research lens. Additionally, the literature thus far has focused on social media as a forum for multi-user online discussion. In our work, we examine top-down dissemination from singular influencers, with many more followers than previously studied. We also contribute a geographic and gender analysis of influencer-sharing patterns and provide recommendations to conferences, influencers, and the wider community on managing the evolving field of Artificial Intelligence research.\\n\\n3. Data Collection\\n\\nWe model our analysis on retrospective cohort studies, in which a treatment and control group with identical underlying covariates are compared to determine the average treatment effect. In our case, we assume that a paper's citation count is most strongly influenced by elapsed time, quality, topic, and author prominence. While elapsed time is simple to measure, paper quality and topic are difficult to quantify. We use the publication venue and year as a proxy for quality and use a text embedding of the paper's title and abstract to approximate the topic. We use author citations and h-indices to adjust for their prominence.\\n\\nAs such, our data collection process consists of three parts: (1) collecting the Target Set, the papers tweeted by @akhaliq and @arankomatsuzaki, (2) collecting a large dataset of potential papers to match against, and (3) forming the Control Set by matching papers from (1) to papers from (2) with respect to the year of publication, the publication venue, and a text embedding of title and abstract. We detail each step below.\\n\\nTable 1. The number of unique papers tweeted by each influencer, the subset of papers with all desired attributes available through S2 (Table 3), and the papers finally included in our analysis after matching.\\n\\n| AK | Komatsuzaki |\\n|----|-------------|\\n| # Unique Papers | 9,171 | 1,273 |\\n| # with all attributes | 8,259 (90%) | 1,191 (94%) |\\n| # Matched Papers | 6,890 (75%) | 955 (78%) |\\n\\nTable 2. The top 5 most common authors shared by each user and the number of papers where they are credited.\\n\\n| Name          | freq. |\\n|---------------|-------|\\n| S. Levine     | 85    |\\n| L. Zettlemoyer| 31    |\\n| Furu Wei      | 82    |\\n| Quoc V. Le    | 28    |\\n| Jianfeng Gao  | 71    |\\n| Yi Tay        | 26    |\\n| L. Zettlemoyer| 64    |\\n| Furu Wei      | 23    |\\n| Ziwei Liu     | 62    |\\n| M. Dehghani   | 18    |\\n\\nTable 2. The top 5 most common authors shared by each user and the number of papers where they are credited.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\ntitle, abstract, year, venue, citationCount, embedding.specter, authors\\n\\nTable 3. The desired attributes for each paper, queried from S2.\\nyear, venue, open access, n authors, first(h-index), max(h-index), first(citations), max(citations), topic embedding\\n\\nTable 4. The covariates used for control matching.\\n\\nTarget Set. The Target Set is collected by searching for document identifiers in the X feeds of both influencers (identifiers are found in links to arXiv.org or huggingface.co/papers). We use the Semantic Scholar (S2) API to query every document for desired attributes (Table 3). Notably, some papers are either not available on S2 or are not freely accessible. Hence, we remove any paper that lacks any required attribute. The number of unique papers and papers with all attributes for each influencer is shown in Table 1.\\n\\nWe find that roughly 90% of papers tweeted by either influencer have all attributes available. While we express moderate caution about the excluded minority of papers, as they may be systematically different from those included, we believe the many papers remaining in our analysis are sufficient to draw meaningful conclusions.\\n\\nAdditionally, we find that half of the papers are tweeted within 24 hours of their initial ArXiV release, with 95% of tweets occurring within a week. This verifies that our influencers do indeed tweet freshly posted papers. We also find significant overlap in sharing, with 65% of Komatsuzaki-shared papers also tweeted by AK.\\n\\nControl Set. To build our Control Set, we first collect a corpus of papers presented at the same venues and in the same years as those in the Target Set. Specifically, for every instance of a paper published in year y at venue v, we query S2 for all papers published in year y at venue v.\\n\\nWe follow the recommendations in (King & Nielsen, 2019) by performing exact matching on our categorical (year, venue, open access) and binned variables (n authors, h-index, author cites), and Euclidean distance matching on our continuous variables (topic embedding). Optimal matching can be reduced to the linear sum assignment problem, for which many efficient algorithms exist (Crouse, 2016). We use the implementation available in SciPy (Virtanen et al., 2020).\\n\\nUsing this methodology, we match each paper in the Target Set to a paper in the Control Set with respect to the gathered covariates (Table 4). We exclude any paper for which we cannot find an exact match on categorical variables. For matching on topic embeddings, we use SPECTER2 (Singh et al., 2022). Matches between papers were strong, and the distribution of cosine similarities and example matched pairs are detailed in Appendix A.\\n\\nReview Scores. To determine if we have successfully controlled for quality through our matching, we will look at the review scores of experimental and control pairs from some selected conferences. We extract the review data using OpenReview (2023). Across both paired datasets, we found 939 out of 7222 unique pairs with available scores.\\n\\nWe plot each treatment paper\u2019s mean review score against its paired control\u2019s mean score (Figure 2). For conferences that do not use numbered review scores, we assign numbers based on those of other conferences (7: Accept, 5: Borderline Accept, 3: Borderline Reject, 2: Reject).\\n\\nUsing the same three significance tests from Table 5, we do not find sufficient evidence to reject the null hypothesis that the control and experimental scores are from the same distribution (p-value > 0.2). Assuming that mean review scores are an accurate measure of paper quality, we conclude that we have effectively controlled for paper quality in our matching.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\nFigure 3. Plots showing the distribution of citations in the two experimental datasets and matched control samples. Citation counts are scaled with the natural logarithm using $\\\\text{numpy.log1p}$. Both comparisons show that papers shared by influencers have attained significantly higher citations for all three quartiles than those in the control sets.\\n\\n4. Analysis\\n\\nTo answer the central question of our work, we compare the impacts of papers shared by AK and Komatsuzaki against our control set. Then, we conduct multivariate analyses by geographic distributions and author attributes in their selected papers.\\n\\nContrasting Analysis. For the contrasting analysis, we will test the following hypotheses for correlation:\\n\\n- Null: Influencer-shared papers have the same citation count as others in the same field.\\n- Alternative: Influencer-shared papers have a higher citation count than others in the same field.\\n\\nWe compare our paired target and control sets, as described in Section 3. We find that papers tweeted by AK have a median citation count of 24 (95% CI: 23, 25) versus 14 (95% CI: 13, 15) in the control group, and papers tweeted by Komatsuzaki have a median citation count of 31 (95% CI: 27, 34) versus 12 (95% CI: 10.5, 13.5). Visually, we can see that both experimental set distributions are skewed toward higher citation counts when compared to their corresponding control sets (Figure 3). In the violin plots (Figures 3c and 3d), the three quartiles and max values are all higher in both of the shared paper distributions compared to the controls. In the 2-Sample Q-Q plots (Figure 4), we can see that the normalized quantiles are consistently higher for the test distributions.\\n\\nFinally, we establish statistical significance with three tests comparing the distributions of the experimental data with that of the control sets, Epps-Singleton (ES), Kolmogorov-Smirnov (KS), and Mann-Whitney U (MWU), none of which assume normal distribution, which is essential for our data. Table 5 shows the results, all with $p$-values well below even a stringent $\\\\alpha = 0.001$. From this, we can strongly reject the null hypothesis that the citation distributions for the influencer-shared papers and the control papers are the same.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\nB. Additional Analysis Plots\\n\\n(a) @akhaliq Dataset Cumulative Distribution Functions\\n\\n(b) @arankomatsuzaki Dataset Cumulative Distribution Functions\\n\\n(c) @akhaliq Dataset Box Plots\\n\\n(d) @arankomatsuzaki Dataset Box Plots\\n\\nFigure 10. Additional plots showing the distribution of citations in the two experimental datasets and matched control samples. Citation counts are scaled with the natural logarithm using `numpy.log1p`.\\n\\nFigure 11. Histogram and kernel distribution estimate of the OpenReview score difference between experiment and control samples in the merged dataset. The mean at 0, and symmetric KDE reinforce that both review scores are from the same distribution.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Causal Inference\\n\\nFor our causal inference analysis, we draw primarily from the model, techniques, and assumptions presented in Elazar et al. (2023). In turn, they point interested readers to Imbens & Rubin (2015) and Feder et al. (2021).\\n\\nBackground.\\nIn our work, we study the outcome as a binary variable $Y$, indicating if a paper is \u201chighly-cited\u201d ($Y = 1$) or \u201cless-cited\u201d ($Y = 0$). By introducing our treatment $A$, we can define two cases for any given paper: $Y_1$, the outcome if the paper were shared by influencers (when $A = 1$), or $Y_0$, the outcome if the paper were not shared by influencers (when $A = 0$). In actuality, we can only observe exactly one of these for each paper. Rather, the goal of causal inference is to estimate the change in outcome if the treatment were flipped (Figure 12). Specifically, we hope to answer the question, does influencer sharing increase the likelihood of a paper being highly-cited?\\n\\nTo accomplish this, we use the average treatment effect on treated: $\\\\text{ATET} = E[Y_1 - Y_0 | A = 1]$ which is the expected increase in highly-cited papers when shared by influencers, for those already shared.\\n\\nNegative Outcome Control and Difference-in-Difference.\\nTo debias the effects of our unobserved confounders, we will utilize the Negative Outcome Control (NOC) framework (Card & Krueger, 1993; Lipsitch et al., 2010). Specifically, we will use Difference-in-Difference (DiD) to estimate ATET over two time periods $t \\\\in \\\\{0, 1\\\\}$ (Sheppard et al., 1999):\\n\\n$\\\\text{ATET} = E[Y_1(1) - Y_0(1) - Y_1(0) + Y_0(0)]$\\n\\nwhich can be estimated by fitting a logistic model and bootstrapping for confidence intervals (Elazar et al., 2023).\\n\\nSofer et al. (2016) establishes that NCO and DiD-based estimators are equivalent, meaning ATET can be rewritten as:\\n\\n$\\\\text{ATET} = E[Y_1 - N_1 - Y_0 + N_0]$\\n\\nand solved by taking the difference across treatment groups of the difference between $Y$ and $N$.\\n\\nAssumptions.\\nTo perform our causal estimate, we assume the following conditions hold:\\n\\n1. Ignorability: $\\\\{Y_0, Y_1\\\\} \\\\perp \\\\perp A | (C, U)$\\n2. Positivity: $0 < P(A = 1 | C = c, U = u) < 1$\\n3. Consistency: $Y_a = Y_{\\\\text{obs}}$ if $A_{\\\\text{obs}} = a$\\n4. Negative control: $N_a = N$ for $a = 0, 1$\\n5. Additive equi-confounding: $E[Y_a(1) - Y_a(0) | U, A = a, C] = E[Y_a(1) - Y_a(0) | A = a, C]$ for $A = 0, 1$\\n\\nUnobserved Confounders:\\nCreativity, originality, fame\\n\\nTreatment: Influencer sharing\\n\\nNegative Control Outcome: Review score\\n\\nOutcome: Citation count\\n\\nObserved Confounders:\\nTopic, authors, venue\\n\\nFigure 12. Causal graph of our setup.\\n\\n$A$ and $Y$ are binary treatment and effect variables, respectively: whether a paper was shared by influencers, and whether the paper is highly cited. As we cannot measure the unobserved confounders (e.g. quality), we estimate the effect of sharing using a negative control outcome variable ($N$).\\n\\nSolid edges represent a directed causal effect, while dashed edges represent an association. Figure and caption modified from Elazar et al. (2023).\\n\\nIn other words, ignorability assumes $(C, U)$ are the only confounders with an effect on the outcome; positivity means each paper has a non-zero chance of being and not being influencer-shared; consistency establishes that the potential outcomes $Y_a$ and observed outcomes $Y_{\\\\text{obs}}$ agree for a given treatment level $A_{\\\\text{obs}}$; negative control assumes that the NCO is not causally affected by the treatment $A$; additive equi-confounding relies on a linear (or logistic) outcome model for $U$.\\n\\nReview Scores as a Negative Control Outcome.\\nThe goal of the Negative Outcome Control (NOC) framework (Card & Krueger, 1993; Lipsitch et al., 2010) is to find a Negative Control Outcome (NCO) variable that is affected by the same confounders $(C, U)$ as the outcome $Y$, but not the treatment. This way, we can de-bias the effects of confounders not captured by the metadata and text embeddings collected from S2. For this, we choose the average conference review score for each paper, collected as described in Section 3. We believe that this sub-sample is representative for the following reasons: (1) influencers often share preprint works before conference acceptance or proceedings are released; (2) our matching accounts for publication venue as a confounder; (3) using bootstrapping on the three tests from Table 5, we find there is not significant evidence to reject that the sub-sample and full dataset citations come from different distributions ($p$-value $> 0.05$).\\n\\nMatching and Causal Inference.\\nElazar et al. (2023) use tripartite matching on a number of covariates (Zhang et al., 2021), and only sampled from one venue. To control the topic covariate, they use SPECTER embeddings to build 20 topic clusters and minimize distance for numerical variables.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Instead, we group the treated and control samples based on a mix of exact matching (venue, year, open access) and quantile binning (number of authors, h-index, and author cites). From these groups, we match samples by minimizing the $L_2$ difference of text embeddings. This way, we can most accurately capture increased nuance between \\\"viral\\\" topics, techniques, and models.\\n\\nAdditionally, we use first-author information, rather than both minimum and average, to increase our group sizes and improve the quality of topic matches while maintaining descriptive author details.\\n\\nD. Limitations\\n\\nWhile our study provides valuable insights into the role of influencers in the machine learning (ML) community, there are several limitations that must be acknowledged:\\n\\nBinary Gender Analysis: Our gender prediction utilizes the AMiner Gender Prediction API, which combines the Facebook Generated Names List (Tang et al., 2011) with precision and recall of 95% and 81%, and MagicFG (Gu et al., 2016) with precision and recall of 93% and 94% respectively. Exact numbers for the combined API are not published by the creators but can reasonably be assumed to be higher than each individual method. We will ensure that these details are more accessible in the final paper.\\n\\nAdditionally, the gender prediction API only outputs binary genders (male and female), limiting our ability to capture the full spectrum of gender identities. Consequently, our findings may not accurately represent the diversity of gender identities within the ML community.\\n\\nAccuracy with Non-Western Names: The gender prediction API may exhibit lower accuracy when analyzing non-Western names (Gu et al., 2016). As a result, the study's conclusions regarding gender disparity might not fully capture the global diversity of our samples.\\n\\nSelf-Reported Affiliations: The affiliations in our dataset are self-reported, which can lead to inconsistencies such as misspellings or missing location information. This limitation affects the accuracy of our geographical analysis, as the data may not accurately reflect the true affiliations or locations of the authors. Consequently, our observations regarding geographical concentration and diversity must be interpreted with caution. Additionally, this limitation posed as a barrier to investigating institutions as an observed cofounder for causal inference. We invite future studies with more complete affiliation data to investigate this.\\n\\nLack of Randomized Control Trial: The study did not include a randomized control trial, often considered the gold standard for establishing causality. Without this, we cannot conclusively determine whether the patterns observed are directly attributable to the influencers' activities or are coincidental. Though we attempt to remedy this through causal inference, such techniques are contingent upon the validity of our assumptions.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\nEnhance the richness of academic discourse. Similarly, the academic community might benefit from reevaluating traditional metrics of research impact, embracing both peer-reviewed channels and digital platforms for a more holistic approach to recognizing scholarly work. In doing so, we hope to spark future research into understanding any unintentional biases influencers might have, such as favoring research from prestigious institutions or specific regions. This is a subtle yet crucial aspect of ensuring a balanced representation in the academic landscape, preventing the overshadowing of significant but less publicized work. While influencers may have personal or commercial interests, we trust in their capacity to acknowledge and manage these to avoid conflicts of interest. This approach would help in preventing echo chambers and promoting a diverse range of perspectives in AI/ML research. Overall, we advocate for a collaborative and mindful effort among influencers and the academic community to foster an equitable and inclusive environment for scholarly discussions.\\n\\nAcknowledgements\\n\\nThis work was supported in part by the National Science Foundation Research Experience for Undergraduates under CAREER Award Grant No. 2048122.\\n\\nReferences\\n\\nBranch, T. A., C \u02c6ot\u00b4e, I. M., David, S. R., Drew, J., LaRue, M., M \u00b4arquez, M. C., Parsons, E. C. M., Rabaiotti, D., Shiffman, D., Steen, D. A., and Wild, A. L. Controlled experiment finds no detectable citation bump from Twitter promotion. bioRxiv, 2023. URL https://api.semanticscholar.org/CorpusID:262087567.\\n\\nCard, D. and Krueger, A. B. Minimum wages and employment: A case study of the fast food industry in New Jersey and Pennsylvania. NBER Working Paper Series, 1993. URL https://api.semanticscholar.org/CorpusID:1140202.\\n\\nCrouse, D. F. On implementing 2D rectangular assignment algorithms. IEEE Transactions on Aerospace and Electronic Systems, 52(4):1679\u20131696, 2016. doi: 10.1109/TAES.2016.140952.\\n\\nDarling, E. S., Shiffman, D. S., C\u02c6ot\u00b4e, I. M., and Drew, J. A. The role of Twitter in the life cycle of a scientific publication. ArXiv, abs/1305.0435, 2013. URL https://api.semanticscholar.org/CorpusID:7583994.\\n\\ndblp. dblp Computer Science Bibliography: Monthly Snapshot Release of October 2023. https://dblp.org/xml/release/dblp-2023-10-01.xml.gz, 2023. Accessed: 2023-10-01.\\n\\nElazar, Y ., Zhang, J., Wadden, D., Zhang, B., and Smith, N. A. Estimating the causal effect of early arXiving on paper acceptance. ArXiv, abs/2306.13891, 2023. URL https://api.semanticscholar.org/CorpusID:259251893.\\n\\nEysenbach, G. Can Tweets Predict Citations? Metrics of Social Impact Based on Twitter and Correlation with Traditional Metrics of Scientific Impact. Journal of Medical Internet Research, 13, 2011. URL https://api.semanticscholar.org/CorpusID:2157129.\\n\\nFeder, A., Keith, K. A., Manzoor, E. A., Pryzant, R., Sridhar, D., Wood-Doughty, Z., Eisenstein, J., Grimmer, J., Reichart, R., Roberts, M. E., Stewart, B. M., Veitch, V ., and Yang, D. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. Transactions of the Association for Computational Linguistics, 10:1138\u20131158, 2021. URL https://api.semanticscholar.org/CorpusID:237386009.\\n\\nGu, X., Yang, H., Tang, J., and Zhang, J. Web User Profiling Using Data Redundancy. In Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM '16, pp. 358\u2013365. IEEE Press, 2016. ISBN 9781509028467.\\n\\nImbens, G. and Rubin, D. B. Causal inference for statistics, social, and biomedical sciences: An introduction. 2015. URL https://api.semanticscholar.org/CorpusID:123646167.\\n\\nKing, G. and Nielsen, R. Why Propensity Scores Should Not Be Used for Matching. Political Analysis, 27(4):435\u2013454, 2019 2019. URL https://doi.org/10.1017/pan.2019.11.\\n\\nLee, D. H. Predictive power of conference-related factors on citation rates of conference papers. Sciento-metrics, 118:281\u2013304, 2018. URL https://api.semanticscholar.org/CorpusID:53247921.\\n\\nLi, X. Conference-Acceptance-Rate, 2023. URL https://github.com/lixin4ever/Conference-Acceptance-Rate. GitHub repository. Accessed: 2023-12-18.\\n\\nLipsitch, M., Tchetgen, E. J. T., and Cohen, T. Negative controls: A tool for detecting confounding and bias in observational studies. Epidemiology, 21:383\u2013388, 2010. URL https://api.semanticscholar.org/CorpusID:13292337.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yo9Jyt3XCY", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Position: AI/ML Influencers Have a Place in the Academic Process\\n\\nA. Target-Control Matching\\n\\n(a) Cosine Distances of Matches for @akhaliq\\n\\n(b) Cosine Distances of Matches for @arankomatsuzaki\\n\\nFigure 9. Plots of the cosine distances (1 - cosine similarity) between matched pairs for each of @akhaliq and @arankomatsuzaki. We note that the cosine distances are low, with the a mode of around 0.07 for both. This indicates that most pairs are very well matched in topic.\\n\\nQualitatively, the matched pairs are very similar in topic, almost always covering the same sub-field of research (for example, language model hallucinations). We supply a random sample of matched pairs in table 6. The distribution of scores is shown in table 9, and shows that the matched pairs have high cosine similarity scores. Our results are consistent across many choices of matching schemes, such as when we use more than three quantiles for binned variables, or exclude author characteristics altogether.\"}"}
{"id": "yo9Jyt3XCY", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6. Randomly sampled matched pairs of papers tweeted by Komatsuzaki. Score refers to $1 - \\\\cos$ cosine similarity, so lower scores indicate a closer match. Controls show similar topics to the target individuals across similarity levels, indicating a good match.\"}"}
