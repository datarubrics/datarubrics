{"id": "ZZ7UKgK4c1", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\n**Movie Name:** Ghost Ship\\n\\n**Candidates:** {Epps, Greer, Dodge, Murphy}\\n\\n**Background:**\\n\\nINT. Chimera \u2212 Aquarium tank \u2212 Later \u2212 Day\\n\\nP0: Must've been him all along.\\n\\n**Background:**\\n\\nP0 and P1 look on from the outside in the promenade.\\n\\nP0: Smashed the radio. Scuttled the boat. Killed Dodge. Would've killed you. He's off his nut, no doubt there.\\n\\n**Background:**\\n\\nThey watch him in silence a moment as Greer mutters and bobs.\\n\\nP0: What do you think?\\n\\nP1: Could be a stroke. Who knows? (a beat) The general log said the crew were fighting among themselves. \\\"Like wild dogs.\\\"\\n\\nP0: Over the gold.\\n\\nP1: Maybe it was more than that.\\n\\n**Background:**\\n\\nGreer gets up, comes to the window, looking out at them. He presses his face to the glass.\\n\\nP1: They went crazy.\\n\\nP0: Crazy with greed. Not crazy. Not like him.\\n\\n**Background:**\\n\\nA beat as P1 looks off. In the window Greer drags his hideously distorted face over the glass, the blood from his wounds smearing in broad red streaks.\\n\\n**Answer:**\\n\\nP0: Murphy,\\nP1: Epps\\n\\n**Figure 11:** Example of a human mistake.\\n\\n**Unsolvable Case**\\n\\n**Movie name:** South Park\\n\\n**Candidates:** {Stan, Kyle, Cartman}\\n\\n**Background:**\\n\\nEXT. inside the prison camp Mole pops his head out of the ground. immediately, a search light passes over the hole.\\n\\n**Background:**\\n\\n... Then mole takes a long drag off his cigarette and slowly blows the smoke.\\n\\nMole: Now listen carefully. Stan and Kyle, you stand watch here and await my return. If any guards come by, make a sound like a dying giraffe.\\n\\nP0: What's a dying giraffe sound like?\\n\\nMole: (Putting his hands to his mouth) Gwpaapa. Gwpaapa.\\n\\nP0: Kay.\\n\\n**Background:**\\n\\nThe Mole turns to P2.\\n\\nMole: Cartman, over there, is the electrical box. You must sneak over there and shut it off before I return with Terrance and Phillip or the alarms will sound and I will be shot full of holes. Got it?\\n\\nP2: Okay.\\n\\nMole: You must shut off the power, this is very important do you understa\u2212\\n\\nP2: I heard you the first time! I'm not Lou Ferigno for Pete's sake!\\n\\n**Background:**\\n\\nP2 storms off.\\n\\nMole: I will tunnel my way into the buildings, and find the prisoners.\\n\\n**Background:**\\n\\nThe mole starts to dig.\\n\\nP0: Be careful, dude.\\n\\nMole: Careful? Was my mother careful when she stabbed me in the heart with a clothes hanger while I was still in the womb?\\n\\n**Background:**\\n\\nAnd with that, the mole quickly starts to tunnel his way underground.\\n\\nP1: Damn, dude, that kid is fucked up.\\n\\n**Answer:**\\n\\nP0: Kyle,\\nP1: Stan,\\nP2: Cartman\\n\\n**Figure 12:** Example of unsolvable case.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We show examples of good and bad cases of metal states generated by ToMPro and make the following observations:\\n\\n- In general, we found that the GPT-4 is good at understanding the emotions of the fictional characters. Figure 13 and 14 show an example of an input scene and its output states, where the emotion description is not only accurate but also comprehensive.\\n\\n- In most of the cases, the generated desires are bad, due to the lack of history information as discussed at the end of Section 7.4. The correct desires of characters are usually not reflected in one scene but require reasoning through a sequence of important events. Figure 15 gives an example of the bad cases for the same input scene of Figure 13.\\n\\n- Another type of bad case is where the GPT-4 tends to follow shallow text cues and output non-informative and misleading descriptions. Figure 15 shows an example along the belief dimension. Here believing himself not an alien is not part of Hulk\u2019s thoughts. Though the fact is not incorrect, including such information in the mental states deviates the persona of Hulk, which further misleads the guessing model when predicting the identities. A similar problem exists in the part of regaining some dignity of the intention dimension. This highlights a fundamental challenge faced by LLMs trained using co-occurrence-based objectives: distinguishing what is important from the unimportant ones still remains difficult.\\n\\n- Even with access to the history, the GPT-4 may still make mistakes in understanding the personalities, as shown in the example in Figure 16 and 17, where the character Taylor (Tank) is mistakenly portrayed from a crew member and technical expert to a leader. This will lead to error propagation in the iterative generation process, which explains why incorporating the iterative generation into the other four dimensions hurt the performance, due to the existence of misleading information shown in the previous bullet.\\n\\n- Finally and most crucially, even for most of the scenes, GPT-4 can generate mental descriptions that are majorly correct and meaningful, but the guessing model still cannot make correct predictions. There are two reasons: (1) Insufficient ToM reasoning capabilities: The generated mental states along the dimensions like belief, intention, and desire are usually described with specific details that may not always align with the events in a testing scene. While humans can establish connections between disparate events and induce abstract patterns of thoughts, GPT-4 struggles in this regard. (2) Insufficient global understanding: A commonly observed issue is the lack of contextual coherence between the current testing scene and the immediate thoughts stemming from preceding scenes (Figure 18). In such scenarios, it requires either locating relevant mental states that originated several scenes ago or synthesizing the character\u2019s cognitive processes from a multitude of past states. This global perspective remains absent in LLMs.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Background: [INT. ABANDONED BUILDING \u2212 DAY]\\n\\nAlex wakes up, in human form. He looks around and sees he is IN A PILE OF RUBBLE and looks up at the OPEN CEILING HE CRASHED IN. AND IS COMPLETELY NAKED. A SECURITY GUARD stands there, amazed.\\n\\nSECURITY GUARD: You fell out of the sky.\\n\\nALEX: Did I hurt anybody?\\n\\nSECURITY GUARD: There's nobody around here to get hurt. You did scare the hell out of some pigeons though.\\n\\nALEX: Lucky.\\n\\nSECURITY GUARD: Or just good aim. You were awake when you fell.\\n\\nALEX: You saw?\\n\\nSECURITY GUARD: The whole thing, right through the ceiling. Big and green and buck ass nude. Here ...\u201d\\n\\nBackground: [He throws Alex a pair of big pants. Alex pulls on his pants.]\\n\\nSECURITY GUARD: I didn't think those would fit you until you shrunk down to a regular size fella.\\n\\nALEX: Thank you.\\n\\nBackground: [A beat.]\\n\\nSECURITY GUARD: Are you an alien?\\n\\nALEX: What?\\n\\nSECURITY GUARD: From outer space, an alien?\\n\\nALEX: No.\\n\\nSECURITY GUARD: Well then, son, you've got a condition.\\n\\nFigure 13: Example of the input scenes for ToMPro in The Avengers.\\n\\n[Mental States] of ALEX \u2212 Hulk\\n\\nAlex's equilibrium of tranquil demeanor and profound medical knowledge persists, now coupled with an unexpected resilience to physical transformation and the capacity to maintain ethical integrity in the most bewildering circumstances. His ability to remain composed and concerned for the safety of others, even when faced with personal disarray, underscores his dedication to community welfare. However, this scene reveals a heightened vulnerability to extraordinary stress, which can manifest in a loss of physical control, adding a layer of complexity to his character. While his adaptability to drastic changes is commendable, it also introduces an element of unpredictability that could compromise his medical professionalism. Alex must navigate this newfound volatility while safeguarding his moral compass, as his emotional involvement remains a double-edged sword that can both inspire and cloud his judgment. His tendency toward impulsiveness in the face of ethical dilemmas is a weakness that continues to challenge the balance between his personal identity and his professional obligations.\\n\\n[emotions] Alex likely feels a mixture of confusion and relief upon waking up. His confusion stems from the unfamiliar and potentially dangerous situation of being in a pile of rubble and naked. Relief may come from the security guard's assurance that no one was hurt. The brief expression \\\"Lucky\\\" indicates a possible fleeting feeling of gratitude or relief. When questioned about being an alien, his response, \\\"What?\\\" may indicate surprise or disbelief.\\n\\nFigure 14: Example of the good cases of the mental states generated by ToMPro in The Avengers.\\n\\n[Mental States] of ALEX \u2212 Hulk\\n\\n[beliefs] Alex seems to believe that he could have caused harm, as his first question upon gaining consciousness is about the safety of others. He does not believe he is an alien, as indicated by his response to the security guard's question.\\n\\n[intentions] Alex's intention upon waking seems to be to understand what happened to him and to ensure that his actions did not harm anyone. His acceptance of the pants from the security guard indicates an intention to address his immediate need for clothing and to regain some dignity.\\n\\n[desires] Alex desires to remain unharmed and to ensure others are safe, as evidenced by his concern about potentially hurting someone. He also desires to cover himself, shown by his quick action to put on the pants provided by the security guard. Alex likely desires to understand his situation better and to resolve any issues arising from his condition, as suggested by the security guard's final comment.\\n\\nFigure 15: Example of the bad cases of mental states generated by ToMPro from the same scene in The Avengers.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"MARY: Mary\u2019s leadership is exemplified by her unwavering commitment to her team\u2019s safety and success, even at great personal risk, as she demonstrates the ability to prioritize critical objectives under extreme pressure. Her calm demeanor in the face of danger reinforces her role as a stabilizing force, while her nurturing philosophy and clear direction remain central to her approach. Mary\u2019s interrogation skills are essential in navigating complex situations. However, her preference for privacy and control can lead to inflexibility when unpredictability arises, a trait that may compromise her leadership in moments requiring swift action. Her empathetic nature fosters trust among her team, yet her cautiousness in high-stakes scenarios is a vulnerability that could hinder decisive decision-making in urgent circumstances.\\n\\nALEX: Alex\u2019s leadership continues to be defined by his willingness to make sacrifices and his readiness to take decisive action, especially in moments of crisis. His innovative problem-solving abilities, such as utilizing unconventional items for defense, highlight his resourcefulness and strategic acumen. The scene underscores Alex\u2019s resilience and mental fortitude, as he faces overwhelming odds with a smile and an unyielding spirit, indicating an inner strength that complements his physical combat skills. His adaptability and quick reflexes, essential in combat, are matched by his composure under pressure, allowing him to remain focused and tactically astute even in dire situations. Nonetheless, Alex\u2019s emotional detachment is a persistent shortcoming, creating a barrier to deeper connections with his team and potentially affecting group unity and morale. Despite his effective communication and skillful resource management, the challenge for Alex is to overcome his emotional reserve to achieve a more cohesive team dynamic. His weaknesses include a tendency towards emotional detachment and a possible overreliance on personal strength in situations that may call for collective effort.\\n\\nJORDAN: Jordan\u2019s intellectual rigor and analytical nature are now punctuated by his heightened perception, as he demonstrates an ability to detect and ponder the significance of irregularities, such as the phenomenon of deja vu. His blend of logic and intuition is refined by a cautious openness to the mystical, which he navigates without abandoning his inherent skepticism. This skepticism, however, may occasionally hinder his acceptance of inexplicable events, revealing a tension between his desire for empirical understanding and the enigmatic realities he encounters. Jordan\u2019s journey is marked by a struggle to reconcile his quest for knowledge with the acceptance of the unfathomable, with his reluctance to fully embrace such mysteries presenting a consistent challenge to his personal and intellectual growth.\\n\\nTAYLOR: Taylor\u2019s exuberance and cultural flair continue to be integral to his approach, as he displays a keen operational awareness and an ability to swiftly diagnose and respond to emergent challenges with confidence. His quick identification of nerve gas in a critical situation underscores his practical knowledge and readiness to act, reinforcing his potential as a leader. However, his impulsiveness remains a double-edged sword; while it enables rapid response, it also risks precipitous decisions that may not always align with a well-considered strategy. His mentorship is spirited and effective, yet his challenge lies in tempering his instinctive reactions with more deliberate planning to avoid jeopardizing the team\u2019s long-term objectives. Taylor\u2019s weakness is his propensity to prioritize immediate action over strategic depth, which could lead to oversight in complex operations.\\n\\nBackground: [INT. MAIN DECK]\\n\\nTAYLOR: No!\\n\\nFigure 16: Example of the input scene for ToMPro in The Matrix.\\n\\nFigure 17: Example of the bad cases of personality generated by ToMPro from an information-poor scene in The Matrix.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We're going to play a game to update the given character descriptions based on a new scene from a movie. First, I will give you the character descriptions of each character. So you will learn about the characteristics of these characters. Then, I will give you a scene so that you will have a new understanding of each character. What you have to do is to improve the character descriptions of the character based on the original character descriptions and the unique traits exhibited by the characters in the scene. Be careful not to change the original character descriptions easily, because you need to control the proportion of a scene's understanding of the character. And the format of the new character descriptions should be like the given character descriptions.\\n\\nYou are given the following character descriptions of some characters:\\n\\nCHAR1: DESC1\\nCHAR2: DESC2\\nCHAR3: DESC3\\nCHAR4: DESC4\\n\\nPlease read the following scene from a movie about some characters (CHAR2, CHAR3):\\n\\n{{ original scene with character names }}\\n\\nNow you can update and improve the character description for each character (CHAR2, CHAR3) by incorporating the unique traits exhibited by the characters in the scene. Please accentuate the unique personality traits, specific interests or hobbies, unique backgrounds or experiences of each character, while reducing the homogeneity among the six characters, thus creating unique and individualized character descriptions for each. Please provide an objective character description of each character, encompassing both positive and negative personality traits, with particular attention to not overlooking any character weaknesses. Please explicitly mention the characters' weaknesses. And don't provide suggestions regarding their weaknesses. Please don't delete the unique traits in the original character descriptions. Please preserve their most important and unique personality traits. If a character's character description doesn't need to be adjusted, just keep it as it is. And be careful the specific scene content should not appear in the character descriptions, because the character descriptions is a brief generalization of a character and not a generalization of the scene. You don't need to explain the reasons for adjustments, just provide the character descriptions. When the character descriptions need to be compressed due to excessive length, please retain the unique characteristics of each character, and abbreviate or disregard similar or identical features. Please answer in a format like: \\\"CHAR2: CHAR2...\\nCHAR3: CHAR3\\\". And do not answer other than that.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nE. Human Annotation\\n\\nE.1. Movies Used for Human Study\\nTwo raters evaluated 11 movies from movie genre that have more than 100 movies. Table 8 shows the movie names used in human study.\\n\\nE.2. Interface for the Human Study\\nFigure 10 shows the interfaces of the human study.\\n\\nE.3. Annotator Accuracy\\nWe provide the breakdown of the two annotators' accuracy in Table 9 and 10 for in-depth comparison to the models and for understanding the ratio of testing examples that require history information.\\n\\nE.4. Examples of Human Errors\\nTable 11 provides an example of human mistake cases and Table 12 provides an example of unsolvable cases. The human mislabeled characters are marked as red.\\n\\nE.5. Remark on Human Solutions that Related to Meta-Learning of ToM\\nOur human study revealed that to solve our task, humans frequently leverage their knowledge from seen movies, which corresponds to a \u201cmeta-learning\u201d style solution.\\n\\nSpecifically, in our human study, the raters reported the following strategies they used to understand a new character:\\n\\n1. They first classify the characters to rough archetypes they learned from previous experience, e.g., Hero and Villain that are common in action movies. When our human raters have these concepts learned from their previous experience, they can quickly assign these coarse tags to the characters.\\n\\n2. When archetypes are insufficient, e.g., many characters are unconventional to the archetypes or when there are multiple characters with the same archetype in one movie, they associate the new characters with the ones in the movies they have seen before, to make a fine-grained understanding. For example, when labeling Tomorrow Never Ends, the raters leverage their understanding of Ethan Hunt in the movie Mission Impossible to have a pre-impression of James Bond. Similarly, in the movie Ghost Ship, the protagonist Epps was the only person that survived. When evaluating the scene that a character saw the phantom girl, the rater intuitively considered Epps might be the top candidate compared to other candidates. Because such gifts of seeing supernatural figures that other characters could not usually happen to \u201cheroes\u201d in horror movies they have seen, such as Danny in The Shinning or Cole in The Sixth Sense.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\n(a) Introduction page of human study.\\n\\n(b) Character guessing task.\\n\\n(c) Identifying character names.\\n\\n(d) Performance report.\\n\\nFigure 10: Interfaces of human studies.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nTable 8: Human study examples from development set.\\n\\n| Movie Genre | Example | #Scene | #Instances |\\n|-------------|---------|--------|-----------|\\n| Action      | Rush Hour, Aliens | 88     | 143       |\\n| Adventure   | Mission Impossible II, Tomorrow Never Dies | 41     | 61        |\\n| Comedy      | South Park | 28     | 51        |\\n| Crime       | Croupier | 46     | 60        |\\n| Drama       | King Kong | 39     | 61        |\\n| Horror      | Ghost Ship | 30     | 61        |\\n| Romance     | Last Tango in Paris | 16     | 25        |\\n| Sci-Fi      | Jurassic Park the Lost World | 23     | 60        |\\n| Thriller    | Very Bad Things | 24     | 50        |\\n\\nTable 9: Annotator1 accuracy breakdown.\\n\\n| Movie Name       | Correct | #Instances | Requiring History | #Scenes |\\n|------------------|---------|------------|-------------------|---------|\\n| Rush Hour        | 33      | 37         | 21                | 22      |\\n| Very Bad Things  | 22      | 27         | 12                | 12      |\\n| Aliens           | 39      | 44         | 20                | 22      |\\n| Last Tango Paris | 11      | 11         | 8                 | 8       |\\n| Croupier         | 29      | 33         | 21                | 23      |\\n| South Park       | 22      | 27         | 14                | 14      |\\n| Mission Impossible II | 7   | 8          | 3                 | 4       |\\n| Tomorrow Never Dies | 18    | 18         | 15                | 16      |\\n| Jurassic Park the Lost World | 28 | 33         | 10                | 11      |\\n| Ghost Ship       | 24      | 31         | 14                | 15      |\\n| King Kong        | 27      | 29         | 16                | 19      |\\n| Total            | 260     | 298        | 154               | 166     |\\n\\nTable 10: Annotator2 accuracy breakdown.\\n\\n| Movie Name       | Correct | #Instances | Requiring History | #Scenes |\\n|------------------|---------|------------|-------------------|---------|\\n| Rush Hour        | 24      | 29         | 21                | 22      |\\n| Very Bad Things  | 23      | 23         | 11                | 12      |\\n| Aliens           | 27      | 33         | 21                | 22      |\\n| Last Tango Paris | 10      | 14         | 7                 | 8       |\\n| Croupier         | 27      | 27         | 21                | 23      |\\n| South Park       | 22      | 24         | 14                | 14      |\\n| Mission Impossible II | 14    | 14         | 4                 | 5       |\\n| Tomorrow Never Dies | 21    | 21         | 15                | 16      |\\n| Jurassic Park the Lost World | 25 | 27         | 12                | 12      |\\n| Ghost Ship       | 21      | 27         | 13                | 15      |\\n| King Kong        | 29      | 32         | 18                | 20      |\\n| Total            | 243     | 271        | 157               | 169     |\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nA. Perturbation Setting\\n\\nTo address the memorization problem of LLMs, we substitute the character names correspondingly with common names in Table 7 based on their gender as the perturbation setting. Specifically, for each movie, we first construct the mapping between the real name and the perturbed name for each character, then use this mapping to perform the perturbation throughout the movie. We employ gender-guesser to identify the gender of character names. We adopt perturbation in the training scenes and the guessing options in the anonymized testing scenes for ToMPro, and the guessing options of both few-shot examples and test cases for ICL. Additionally, movie titles are also redacted in ICL.\\n\\nTable 7: Common names for perturbation.\\n\\n| Male                  | Female                | Androgynous           |\\n|-----------------------|-----------------------|-----------------------|\\n| David                 | Elizabeth             | Alex                   |\\n| James                 | Emily                 | Casey                  |\\n| John                  | Jennifer              | Jordan                 |\\n| Michael               | Linda                 | Morgan                 |\\n| Robert                | Mary                  | Taylor                 |\\n\\nB. Details of the Implementations of the Non-LLM Baselines\\n\\nB.1. Details of the Base Learner Architecture\\n\\nWe follow (Sang et al., 2022b) to use the Longformer-based character predictor (Longformer-P) as our character encoder, as shown in Figure 2 (top). This architecture consists of two steps: encoding the scene into contextualized embeddings and then conducting attentive pooling to obtain character representations in the scene.\\n\\n(1) Scene Encoding:\\nThe input \\\\( S = T_0 \\\\oplus T_1 \\\\oplus ... \\\\oplus T_N \\\\) to the model is the concatenation of all the utterances \\\\( T_i \\\\)s in an anonymous scene. Each \\\\( T_i \\\\) has its text \\\\( U_i \\\\) prefixed by a speaker ID token \\\\([P_x_i] \\\\) and suffixed by a separation \\\\([SPLIT]\\\\) token, i.e., \\\\( T_i = [P_x_i] \\\\oplus U_i \\\\oplus [SPLIT] \\\\).\\n\\n(2) Attentive Pooling per Character:\\nFor each character ID \\\\( P_x \\\\), we introduce a mask \\\\( M_x \\\\) such that \\\\( M_x[j] = 1 \\\\) if the \\\\( j \\\\)-th word belongs to an utterance of \\\\( P_x \\\\); and 0 otherwise. For each character \\\\( P_x \\\\), we then collect the useful information from all their utterances as masked by \\\\( M_x \\\\) as \\\\( A = \\\\text{Attention}(H)\\\\), \\\\( \\\\alpha_x = \\\\text{Softmax}(A \\\\odot M_x) \\\\).\\n\\nThe character-specific attention \\\\( \\\\alpha_x \\\\) is then used to pool the hidden states to summarize a character representation in the input scene \\\\( S \\\\), \\\\( e_{P_x} | S = H^T \\\\alpha_x \\\\).\\n\\nB.2. Details of the Prototypical Network Implementation\\n\\nWhen applying the Prototypical Network (Snell et al., 2017) to our ToM-IN-AMC, each task \\\\( T_i \\\\) corresponds to a movie \\\\( M_i \\\\). For each masked character \\\\( P_x \\\\) in a training scene \\\\( S \\\\in M_i \\\\), by applying a base learner as the metric network \\\\( \\\\Lambda(\\\\cdot) \\\\), we achieve the character embedding conditioned on the scene as \\\\( e_{P_x} | S = \\\\Lambda(P_x, S) \\\\). Then for each main character \\\\( c_k \\\\), we compute the prototype as \\\\( e_{c_k} = \\\\text{avg} e_{P_x} | S | (P_x = c_k, S) \\\\in D_{train} \\\\).\\n\\nFor a testing case \\\\( x' \\\\) that corresponds to a \\\\( P'_x \\\\in S' \\\\), the prediction logits of score \\\\( (P'_x = c_k) = \\\\cos(e_{P'_x} | S', e_{c_k}) \\\\). The whole inference process is shown in Figure 2 (middle).\\n\\nDuring training, because some of the movies have a large number (>100) of training scenes, computing the prototypes from the full training scenes for each training iteration is time-consuming. We sample at most 5 support mini-batches (8 scenes in each batch) to compute the prototypes. Updating all the support instances together with the training instances also leads to memory issues; we fix the support embedding branch to overcome this issue.\\n\\n2 https://pypi.org/project/gender-guesser/\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nB.3. Details of the LEOPARD Implementation\\n\\nTo handle the challenge of varying numbers of classes across tasks, the LEOPARD introduce an additional parameter generator to MAML, which learns to generate the initial parameters of the prediction layer for a new task. We adapted LEOPARD to our problem as follows. We denote the training set of a task \\\\( T \\\\) as \\\\( D_{\\\\text{train}} \\\\). First, we sample a few scenes \\\\( S(i)_k = \\\\{ (P_x = c_k, S) \\\\} \\\\in D_{\\\\text{train}} \\\\) as the support set for each character \\\\( c_k \\\\) and compute its character embedding in the masked scene \\\\( S \\\\) as:\\n\\n\\\\[\\ne_{c_k|S} = e_{P_x|S} = \\\\Lambda_\\\\theta(P_x, S),\\n\\\\]\\n\\nwhere \\\\( \\\\Lambda_\\\\theta(\\\\cdot) \\\\) can be initialized with a trained prototypical network.\\n\\nSecond, LEOPARD generates a linear model \\\\( (w(i)_k, b(i)_k) \\\\) for each class \\\\( c(i)_k \\\\), as task \\\\( i \\\\)'s prediction layer:\\n\\n\\\\[\\nw(i)_k, b(i)_k = X_{S \\\\in S(i)_k} g_\\\\psi e_{c_k|S} / S(i)_k,\\n\\\\]\\n\\nwhere \\\\( g_\\\\psi \\\\) is an MLP with two layers and \\\\( \\\\tanh \\\\) activation. Then, for task \\\\( T(i) \\\\), we obtain its weight matrix \\\\( W(i) \\\\) and bias \\\\( b(i) \\\\) in the prediction layer by concatenating the weights and bias of all classes:\\n\\n\\\\[\\nW(i) = [w(i)_1; \\\\ldots; w(i)_N],\\nb(i) = [b(i)_1; \\\\ldots; b(i)_N].\\n\\\\]\\n\\nFinally, given this meta-predicted layer, the prediction given an input \\\\( (P_x, S) \\\\) can be obtained by\\n\\n\\\\[\\np(P_x = c|S) = \\\\text{softmax}(W(i)h_\\\\phi(\\\\Lambda_\\\\theta(P_x, S)) + b(i)),\\n\\\\]\\n\\nwhere \\\\( h_\\\\phi \\\\) is another MLP with parameters \\\\( \\\\phi \\\\) to map the instance embedding to the \\\\( l \\\\)-dimensional space.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nC. Details of In-Context Learning Solution with LLMs\\n\\nWe demonstrate our prompt template in Figure 7. k examples from the training scenes are demonstrated at the beginning of the prompt together with the correct answers.\\n\\n[SYSTEM]\\nYou are playing a game guessing the identity of anonymized characters from movie scenes. For each testing case, a few history scenes from the same movie are provided as examples and background.\\n\\n[USER]\\n\\n// Example 1\\nPlease read the following scene from the movie \\\"MOVIE_NAME\\\":\\n\\n{{ scene title }}\\nP0: {{ utterance }}\\n{{ narration }}\\nP1: {{ utterance }}\\nP0: {{ utterance }}\\nP1: {{ utterance }}\\n\\n{{ ... the rest of the scene is omitted ... }}\\n\\nChoose who the anonymous characters (P0, P1) are from the follows:\\n(a) CHAR1\\n(b) CHAR2\\n(c) CHAR3\\n(d) CHAR4\\n(e) CHAR5\\n\\nPlease answer in a format like:\\nP[0-1]-{CHAR1, CHAR2, CHAR3, CHAR4, CHAR5}.\\n\\nAnswer:\\nP0 - CHAR4\\nP1 - CHAR2\\n\\n// Example 2 - k\\n\\n{{ ... examples are omitted ... }}\\n\\n// Test Case\\nPlease read the following scene from the movie \\\"MOVIE_NAME\\\":\\n\\n{{ scene title }}\\nP0: {{ utterance }}\\nP1: {{ utterance }}\\nP2: {{ utterance }}\\n\\n{{ ... the rest of the scene is omitted ... }}\\n\\nChoose who the anonymous characters (P0, P1, P2) are from the follows:\\n(a) CHAR1\\n(b) CHAR2\\n(c) CHAR3\\n(d) CHAR4\\n(e) CHAR5\\n\\nPlease answer in a format like:\\nP[0-2]-{CHAR1, CHAR2, CHAR3, CHAR4, CHAR5}.\\n\\nFigure 7: GPT-4 Prompt Template with Few-Shot Enhancement\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nD. Details of ToM Prompting Solution with LLMs\\n\\nIn the long text input setting, we suggest a recurrent method to update character modeling by processing scenes in chronological order with LLMs. As depicted in Figure 3, our approach divides character modeling into personalities and the other 4 instant theory-of-mind dimensions, i.e., emotions, beliefs, desires, and intentions. Personalities $P(t)$ are modeled using a recurrent memory that updates chronologically through scene iterations, while the other 4 instant dimensions $I(t)$ are all derived from the current scene.\\n\\n$$P(t) = f_{\\\\text{personalities}}\\\\left(S(t), \\\\{P_x = ck\\\\}(t), P(t-1)\\\\right)$$\\n\\n$$I(t) = f_{\\\\text{instant dims}}\\\\left(S(t), \\\\{P_x = ck\\\\}(t)\\\\right)$$\\n\\nIn the testing phase, we create a guessing prompt that incorporates character modeling obtained in the previous steps attached to the choices.\\n\\n$$\\\\{P_x = ck\\\\}(t) = f_{\\\\text{guess}}(S(t), P(t), I(t))$$\\n\\n$S(t) \\\\in D_{\\\\text{test}}$\\n\\nComplete prompt templates for $f_{\\\\text{personalities}}$ and $f_{\\\\text{instant dims}}$ are provided in Figure 8 and 9. The guessing prompt $f_{\\\\text{guess}}$ is provided in Figure 3b.\\n\\n---\\n\\nYou are expected to use theory of mind to elucidate the emotions, beliefs, desires, intentions of CHAR based on the dialogue within a scene.\\n\\nThe following are explanations of emotions, beliefs, desires, intentions:\\n\\n**Emotions**: Emotions are strong feelings deriving from one's circumstances, mood, or relationships with others. And emotions are variously associated with thoughts, feelings, behavioral responses, and a degree of pleasure or displeasure.\\n\\n**Beliefs**: Beliefs encompass both objective facts and subjective perceptions concerning the existence or truth of something.\\n\\n**Desires**: Desires encompass both physical needs and psychological yearnings. Desires incline people toward action and fulfilling desires is pleasurable.\\n\\n**Intentions**: Intentions are blueprints that steer actions, encompassing both future plans and the motivations driving current behavior.\\n\\nPlease read the following scene from a movie:\\n\\n**[Scene]**\\n\\nPlease use theory of mind to elucidate the emotions, beliefs, desires, intentions of CHAR. Please answer in a format like: \u201cEmotions:\\nBeliefs:\\nDesires:\\nIntentions:\u201d.\\n\\nFigure 8: Prompt template for 4 instant ToM dimensions (emotions, beliefs, desires, and intentions).\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\n[Scene] in The Matrix (P0\u2212Jordan \u2212\u2212 Neo, P1\u2212Taylor \u2212\u2212 Tank, P2\u2212Mary \u2212\u2212 Trinity)\\n\\nBackground:\\n\\n[INT. MAIN DECK]\\nP0 looks at Alex whose body is covered with a cold sweat.\\nP0: What are they doing to him?\\nP1: They're cracking his mind.\\nP0: How?\\nP1: They inject virus \u2212like serums to break down the system. It 's like cracking a computer. All it takes is time.\\nP0: How much time?\\nP1: Depends on the mind. But eventually , it will crack and his alpha pattern will change from this to this .\\n\\nBackground:\\n\\n[P1 punches several commands on Alex' personal unit . The monitor waves change from a chaotic pattern to an orderly symmetrical one.]\\nP1: When it does, Alex will tell them anything they want to know.\\nP0: The access codes to Zion.\\nP1: If an agent got inside Zion's mainframe he could do anything . Disable the defense system. It would be the end of us.\\n\\nBackground:\\n\\n[He looks up at P2 who is pacing relentlessly .]\\nP1: We can't let that happen. We have to do it , P2. Zion has to be protected .\\n\\nBackground:\\n\\n[P2 sees Cypher's dead body. Rage overtakes her and she starts kicking him .]\\nP2: Goddamnit! Goddamnit!\\nP1: We have to pull the plug.\\nP2: No!\\nP1: We don't have any other choice .\\n\\nBackground:\\n\\n[Those words are like using gasoline to put out a fire and we watch the pain in her eyes burn into a blaze . She walks past him and gets into her chair .]\\nP1: P2, what are you doing?\\nP2: I'm going in after him.\\nP1: Alex could conform at any minute \u2212\u2212\\nP2: If he does I'm sure you' ll do what has to be done.\\nP1: You saw that place . It 's suicide .\\n\\nBackground:\\n\\n[She glares at him.]\\nP1: I know what Alex means to you \u2212\u2212\\nP2: No. No, I don't think you do. If you did , then you would know that I'm not letting him go. Not without a fight , P1.\\n\\nBackground:\\n\\n[She yanks her harness tight .]\\nP2: Not without a fight .\\n\\n// Model Prediction : P0\u2212Mary, P1\u2212Jordan, P2\u2212Taylor\\n\\n(A) Taylor [ personality ]\\nTaylor's leadership shines through his ability to take swift and decisive action , with his strategic mindset and situational awareness guiding him in commanding his team effectively . His quick thinking and operational leadership are enhanced by a vibrant personality and cultural savvy. However, his scene reveals a vulnerability to physical harm, highlighting his mortal limitations despite his strong leadership facade . Taylor's enthusiasm for mentorship and imparting practical knowledge is a strength , yet his tendency toward impetuousness can lead to hasty decisions that may bypass deeper strategic considerations . His challenge is to temper his instinctual responses with a more measured, analytical approach to ensure comprehensive mission success . Taylor's weakness is his impulsiveness , which could potentially compromise the well\u2212thought\u2212out strategies necessary in complex operations .\\n\\n[emotions]\\nTaylor likely feels pain from his injuries , indicated by his charred wounds, but he may also be experiencing emotional distress , possibly due to something that happened to Dozer. The tightening of his face upon Mary's inquiry about Dozer suggests he might be feeling sadness , guilt , or anger.\\n\\n[ beliefs ]\\nTaylor seems to believe that he can manage his injuries , as indicated by his reassurance to Mary that he' ll be alright . His belief may also extend to a sense of duty or responsibility , which is why he might be downplaying his own pain.\\n\\n[ intentions ]\\nTaylor's immediate intention appears to be to reassure Mary about his condition , possibly to keep her from worrying or to maintain a sense of normalcy in a stressful situation . His response to the mention of Dozer suggests he might be intending to avoid the topic , possibly because it 's painful or he needs to focus on the present situation .\\n\\n[ desires ]\\nTaylor desires to appear strong and capable , perhaps to maintain his own morale or that of Mary. He may also have a desire to protect Mary from further distress , which could be why he doesn't elaborate on his condition or the situation with Dozer. His desire could also include wishing to address his injuries and deal with the aftermath of whatever happened to Dozer, but these are secondary to his immediate interaction with Mary.\\n\\n(B) Alex\\n\\n(C) Mary\\n\\n(D) Jordan\\n\\n// The generated ToMs contain no information that Taylor is a technical expert .\\n\\nFigure 18:\\nExample of the bad cases of insufficient global understanding in The Matrix.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nAdditional Experimental Results\\n\\nPerformance Breakdown to Number of Speakers in a Scene.\\n\\nTable 11 presents the performance breakdown of different approaches. We make similar observations in Table 5, where humans and our ToMPro approach lead to smaller performance differences across different numbers of speakers.\\n\\nTable 11: Performance decomposition to the number of choices in a scene. (*) Conducted on the subset of human evaluation. There is only one 5-speaker scene, thus the number of 100% is not significant.\\n\\n| #Speakers | Transductive | Inductive | Human |\\n|-----------|--------------|-----------|-------|\\n| 1         | 56.9         | 81.1      | 65.5  |\\n| 2         | 55.3         | 64.9      | 61.3  |\\n| 3         | 50.2         | 62.5      | 53.7  |\\n| 4         | 43.0         | 55.4      | 41.5  |\\n| 5         | 46.1         | 22.0      | 36.5  |\\n\\nPerformance Breakdown to Movie Genres.\\n\\nTable 12 details the performance breakdown by movie genre across different methods.\\n\\nTable 12: Performance decomposition to movie genres. (*) Conducted on the subset of human evaluation.\\n\\n| Genre      | Transductive | Inductive | Human |\\n|------------|--------------|-----------|-------|\\n| Action     | 53.8         | 71.1      | 59.7  |\\n| Adventure  | 61.3         | 78.7      | 68.0  |\\n| Comedy     | 48.5         | 45.7      | 51.8  |\\n| Crime      | 69.6         | 85.0      | 80.4  |\\n| Drama      | 58.5         | 49.2      | 71.7  |\\n| Horror     | 66.7         | 64.7      | 64.1  |\\n| Romance    | 52.4         | 92.0      | 61.0  |\\n| Sci-Fi     | 50.7         | 60.3      | 45.1  |\\n| Thriller   | 55.1         | 70.0      | 59.3  |\\n\\nSubset of Testing Movies used in Table 4.\\n\\nTo keep the samples covering similar genres like in our development subset Table 8, we sample the testing movies following Table 13.\\n\\nTable 13: Sampled test set by genre.\\n\\n| Movie Genre | Example                  | #Scene | #Instances |\\n|------------|--------------------------|--------|------------|\\n| Action     | Terminator Salvation     | 26     | 40         |\\n| Adventure  | The Avengers             | 14     | 17         |\\n| Comedy     | American Pie             | 30     | 46         |\\n| Crime      | Catch Me If You Can       | 41     | 45         |\\n| Drama      | Precious                 | 30     | 33         |\\n| Horror     | A Nightmare On Elm Street | 19     | 26         |\\n| Romance    | Passengers               | 7      | 15         |\\n| Sci-Fi     | The Matrix               | 39     | 67         |\\n| Thriller   | Donnie Brasco            | 30     | 47         |\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nH. Details of Character Memory Solution with LLMs\\n\\nA straightforward inductive learning approach is to retrieve LLMs' memory of characters to text descriptions (with the prompt in Figure 19), then feed the descriptions as the character representation to LLMs for identity guessing (with the prompt in Figure 3b).\\n\\nThe performance of this method could be considered as the cap for the inductive approaches, as the generated text descriptions about characters contain spoiler information, which is in favor of fulfilling the evaluation tasks performed on movie endings.\\n\\nPlease summarize the personality and traits of the character **CHAR** in the movie **MOVIE_NAME** in a single paragraph.\\n\\n**Figure 19:** Prompt template for retrieving LLMs' memory.\\n\\nI. Study on the Quality of the Generated Mental States\\n\\nBecause the study requires the annotators to be quite familiar with the characters, we use the TV series *The Big Bang Theory* (TBBT) and the book *Pride and Prejudice* (*P&P*). As noted in Section 7, GPT-4 cannot successfully distinguish desire from intention. Therefore, we assessed whether GPT-4 can accurately generate results on the dimensions of intention, belief and emotion, based on our annotators' interpretation of the stories.\\n\\nTable 14 illustrates that GPT-4 generally performs well in identifying intentions but performs less effectively in the other two dimensions. There is a loose correlation between the generated quality of a dimension and its impact on character identification. The results also suggests that GPT-4 still has limitations in ToM understanding. Therefore, enhancing this capability would likely lead to further improvements in our task.\\n\\n|       | Intention-F1 | Belief-F1 | Emotion-F1 |\\n|-------|--------------|-----------|------------|\\n| TBBT  | 84.8         | 60.6      | 75.0       |\\n| P&P   | 77.7         | 63.0      | 56.3       |\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nFigure 2: Our two proposed meta-learning approaches for the character prediction task. (top) the base learner (Longformer-P); (middle) the prototypical network approach; (right) the LEOPARD approach.\\n\\nleads to data leak thus powerful LLMs like GPT-4 may resolve our task with its memorization instead of ToM reasoning. To mitigate this issue, we introduced perturbations in our testing tasks by replacing main character names with random English names while preserving their genders (details in Appendix A). This prevents the model from relying on memorized movie information. Non-LLM results are unaffected by these perturbations since they treat names as class labels, and human annotators had not seen the movies.\\n\\n5. Baseline Methods\\n\\nWe introduce the baselines adapted to our problem in the transductive and inductive settings, according to whether the method explicitly produces a mental model or a mental state of a character.\\n\\n5.1. Transductive Learning Approaches\\n\\nPrototypical Network (Snell et al., 2017). The method learns a metric network $\\\\Lambda$ for prediction. In our work, $\\\\Lambda$ is a base learner, Longformer-P (model architecture detailed in Appendix B.1), that produces embedding vectors of characters contextualized by the input scenes. For any input pair $(x, x')$, $\\\\Lambda(x) \\\\cdot \\\\Lambda(x')$ outputs a similarity score. During prediction, there is not a specific model for a character. The prediction is achieved based on the similarity between the input and the characters' historical scenes (Figure 2 (middle)). Therefore, it is a standard transductive learning method. The detailed implementation can be found in Appendix B.2.\\n\\nIn-Context Learning with LLMs. Large language models have demonstrated their in-context learning (ICL) capability (Brown et al., 2020). This approach naturally aligns with our few-shot learning task, where previous scenes from the training sets can be utilized as few-shot demonstrations to aid in making predictions for testing scenes. In our study, we use the ChatGPT and GPT-4 as the LLMs. Considering the maximum input lengths permitted by the model services, we include 10 or 20 demonstrations (referred to as 10-shot or 20-shot) along with a testing case for predictions. The detailed prompt construction can be found in Appendix C.\\n\\n5.2. Inductive Learning Approaches\\n\\nMulti-Task Learning. A most straightforward inductive baseline is to apply standard multi-task learning on all the training and evaluation tasks to learn a classifier for each character. All the tasks share the same Longformer encoder, i.e., the base learner in Appendix B.1. On top of the encoder, each task $i$ has its own prediction layer $f_i$, which is a linear classification head that makes prediction as $P(x = c | S) = f_i(e_{P(x | S)})$, where $f_i: \\\\mathbb{R}^d \\\\rightarrow \\\\mathbb{R}^C$. We do early stopping according to the averaged performance across the testing data of all development tasks for model selection.\\n\\nLEOPARD (Bansal et al., 2020). The LEOPARD algorithm is originally introduced to handle the challenge of varying numbers of classes across tasks in few-shot learning. Compared to the standard MAML (Finn et al., 2017) algorithm, it consists of an additional parameter generator, which learns to generate the initial parameters of the prediction layer for a new task. Therefore, the algorithm is able to output a model of each character for prediction and becomes an inductive approach. The details about how we adapt the LEOPARD to our problem can be found in Appendix B.3.\\n\\n6. The ToM Prompting Method\\n\\nWe introduce ToMPro, an LLM-based inductive learning method with two prompting stages. In Stage-1 (Figure 3a), it iteratively analyzes a stream of scenes to update character mental states across various ToM dimensions: personality, emotions, beliefs, desires, and intentions, following insights from psychological research (Baron-Cohen, 1991; Apperly & Butterfill, 2009). The prompt uses the current scene and characters' prior mental state descriptions for reference. In Stage-2 (Figure 3b), LLMs identify anonymized characters in test scenes based on descriptions obtained in the first stage. The two stages correspond to the two major functions of ToM, understanding others' mental states and reasoning about their future behaviors with the knowledge about their mental states.\\n\\nWe tune the format and phrasing of the prompts on the TV show transcripts from (Sang et al., 2022b), to prevent overfitting to our movie scripts. The final prompt for Stage-\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nYou are expected to use theory of mind to elucidate the emotions, beliefs, desires, intentions of based on the dialogue within a scene.\\n\\nPrior to this scene, the character has the following mental states:\\n\\nPlease read the following scene from a movie:\\n\\nWe're going to play a game to update the given character descriptions based on a new scene from a movie.\\n\\nYou are given the following character descriptions of some characters:\\n\\nPlease read the following scene from the movie:\\n\\nWilliam's technological expertise is not only evident in his proficiency with data management and ... Elizabeth is the head of MI6 and James's superior. She is a tough, authoritative, and pragmatic ...\\n\\nPlease answer who are the characters in the dialogue denoted as P0, P1.\\n\\nPlease do not answer other than that or other names.\\n\\nCharacter descriptions in the other ToM dimensions\\n\\nOn a Stream of Training Scenes\\n\\nOn an Anonymous Testing Scene\\n\\nFigure 3:\\n\\nOur proposed ToMPro approach. The method first (a) generates character mental descriptions along multiple ToM dimensions based on input scenes; then (b) predicts the identities of a new testing scene with the generated descriptions.\\n\\n7. Experiments\\n\\n7.1. Baselines and Implementation Details\\n\\nWe evaluate the instance-level accuracy. An instance is a masked speaker in a scene. We implement the non-LLM baselines based on HuggingFace (Wolf et al., 2020), with the allenai/longformer-base-4096 for initialization. We optimize the models with Adam. The LEOPARD starts with the encoder of the trained prototypical network. We train our model on a single V100 GPU. It takes around 2 hours to train one epoch. We train the MTL baseline and Prototypical Network baseline for 20 epochs and train the LEOPARD with 10 epochs. To generate the LLM results, we use the gpt-3.5-turbo-0613 and gpt-4-1106.\\n\\nHyperparameters.\\n\\nWe set the maximum length to 2000, which can handle most of the scenes. We set window size to 256 and batch size to 8. We set learning rate to 2e-5 for the MTL and prototypical network and update every 8 batches. For LEOPARD, the learning rate is 1e-5; and the parameters are updated after each inner-loop. For each model, we ran twice and found the average development accuracy varies by less than 1%. Hence, we report our results with a single run. For GPT-based methods, we set the temperature to 0.1 and take the average of 3 runs for evaluation. The temperature is set to 1.0 in Stage-1 of ToMPro for diverse generations.\\n\\n7.2. Main Results I: Human Performance\\n\\nTo understand the properties of TOM-IN-AMC, we conduct a human study on the development set. Specifically, we explore (1) the human performance on our task and (2) the dependency on the historical events to complete our task.\\n\\nWe sampled 11 movies from the genres with script counts greater than 100 in the development set. 335 scenes from the 11 movies are distributed to two raters who have not watched the movies. The raters perform two tasks on each scene: (1) guessing the character identities and (2) identifying whether the guessing task needs only the current scene or additional scenes from the movie. We evaluate the instance-level accuracy of the raters, where an instance refers to a masked speaker in a scene. For each instance, raters have five options who are the main characters. Figure 10 in Appendix E.2 shows our human study interfaces. In total, the raters annotated 569 instances in these scenes.\\n\\nResults.\\n\\nHumans can solve our tasks quite well, with an average human performance of 88.0%. As will be shown in the experimental section, it largely outperforms the model performance by >20%, showing a significant gap for machines to improve. Many human errors come from hard or unsolvable cases (such examples are shown in Appendix E.4). Importantly, our study shows that there is no significant shortcut for guessing the characters without persona un...\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nTable 3: ToM dimensions human used when solving our tasks.\\n\\n| Category        | Number | Percentage |\\n|-----------------|--------|------------|\\n| Stereotype/Trope| 73     | 44.8       |\\n| Intention       | 102    | 62.6       |\\n| Personality     | 101    | 62.0       |\\n| Attention       | 74     | 45.4       |\\n| Emotion         | 54     | 33.1       |\\n| Desire          | 52     | 31.9       |\\n| Belief          | 50     | 30.7       |\\n| Gender          | 33     | 20.2       |\\n| Linguistic      | 14     | 8.6        |\\n| Other           | 4      | 2.5        |\\n\\nRaters often need to read the whole movie script before the scene to understand the characters' personas. There are 311 scenes that require historical scenes to resolve, corresponding to 92.84% of the examples.\\n\\nAnalysis. We conduct an in-depth study to understand which ToM dimensions humans find useful for solving our task. Two of our co-authors, who had not participated in previous evaluation, annotated 163 cases from 3 movies (King Kong, Last Tango in Paris, Tomorrow Never Dies).\\n\\nDuring the annotation, besides the dimensions used in ToM-Pro, we identified two additional important categories:\\n\\n- **Attention**: It refers to the ability to recognize and interpret where and what others are focusing on. This dimension has been extensively studied in psychological research (Baron-Cohen, 1991; Apperly & Butterfill, 2009), but relatively less studied in the AI field.\\n\\n- **Stereotype/Trope**: It refers to the tendency of humans to classify fictional characters into character tropes (e.g., archetypes like Super Villain), and then attempt to resolve the task using common mental states associated with these tropes. For example, a Super Villain is often perceived as being Cruel and having a desire for Gaining Powers.\\n\\nThe Stereotype category corresponds to the frequently observed human strategy discussed in our introduction and the strategies reported by the raters in previous study (as detailed in Appendix E.5). The existence of this category indicates that humans' ToM exhibits the meta-learning capability. Humans acquire this knowledge from other stories or historical experiences and transfer it to new contexts, such as movies, for rapid comprehension. This process aligns with the machine learning definition of meta-learning.\\n\\nFor each instance, we ask the annotators to label multiple categories that they believe are useful. Table 3 gives the results, highlighting the most significant dimensions for humans to solve our tasks (Intention, Personality, and Attention). Additionally, humans solve 44.8% of instances via Stereotypes. This finding supports our argument regarding the meta-learning capability of human ToM.\\n\\nTable 4: Overall performance (%) on our ToM-IN-AMC task. (*) Evaluation was conducted on a subset of the dataset (see Appendix Table 8 and 13). \u2020 the dataset released by (Sang et al., 2022b).\\n\\n| System                  | Dev Acc | Test Acc |\\n|-------------------------|---------|----------|\\n| Random                  | 22.1    | 25.0     |\\n| Majority                | 34.9    | 36.0     |\\n| Human *                | 88.0    | \u2013        |\\n| Proto. Net - Trained on TVSG \u2020 | 45.9 | 46.4     |\\n| GPT-4 ICL (20-shot) * | 67.8    | \u2013        |\\n| - 10-shot               | 63.8    | \u2013        |\\n| - replaced with GPT-3.5 | 54.9    | \u2013        |\\n| Inductive Setting       |         |          |\\n| MTL of Classifiers      | 42.8    | 38.1     |\\n| LEOPARD                 | 59.4    | 58.6     |\\n| GPT-4 ToMPro            | 68.2    | 66.9     |\\n| - w/o update after training scenes | 61.7 | \u2013        |\\n| - non-iterative (128K context) | 61.5 | \u2013        |\\n| - replaced with GPT-3.5 | 60.3    | \u2013        |\\n\\n7.3. Main Results II: Machine Performance\\n\\nTransductive Setting. The middle part of Table 4 compares different models in the transductive setting. The prototypical network trained on our ToM-IN-AMC achieves 55.4%, significantly better than the random and majority baselines. To confirm the value of our training data, we directly use the TVSG model from (Sang et al., 2022b) as the prototypical network. Its inferior performance confirms the diversity among fictional characters, showing the limitations of prior work that relies on large data per character and justifying the importance of studying the meta-learning setting for character understanding. GPT-4 ICL approach achieves respectable performance on our task, which performs 12% higher than the best prototypical network result.\\n\\nInductive Setting. The bottom of Table 4 compares different approaches in the inductive setting, where each approach explicitly builds a model or a mental state description for a character. For the non-LLM methods, the multi-task learning (MTL) baseline suffers from limited training data and performs poorly; but the LEOPARD outperforms the prototypical network and becomes the best non-LLM baseline. Our ToMPro approach significantly outperforms all other inductive baselines. The ablation study shows that (1) all the ToM dimensions contribute to the improvement (Figure 4), affirming that our task necessitates a comprehensive understanding of ToM. Among the dimensions, desire and intention are most crucial for our task, while emotion is the least crucial among the five; (2) our iterative approach enables to utilize the immediate history of a testing scene, extending beyond the usage of training scenes alone. This feature is crucial for enhancing the quality of short-term\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nPersonality Desire Intention Belief Emotion\\n\\n50\\n55\\n60\\n65\\n70\\nDev Accuracy (%)\\n\\nToMPro (Full) = 68.2\\n\\n60.0\\n62.5\\n62.0\\n58.3\\n57.4\\n\\nFigure 4: Ablation of ToMPro on the 5 ToM dimensions.\\n\\nProtoNet ICL LEOPARD ToMPro\\n\\nICL\\nLEOPARD\\nToMPro\\nHuman\\n0.38\\n0.85\\n0.42\\n0.47\\n0.87\\n0.65\\n0.48\\n0.50\\n0.33\\n0.23\\n\\nFigure 5: Correlation between models across genres.\\n\\nmental states (61.7% to 68.2%). Despite ToMPro's success in generating characters' mental representations, the performance still significantly lags behind human by \u223c20%. It shows that the LLMs are still far from reaching human-level ToM, and suggests the great potential for future improvement. Through a qualitative analysis of ToMPro's generated descriptions (see Appendix F for examples and detailed discussions), we make the following observations: (1) In the descriptions, ToMPro tends to include the key evidence events it uses to infer the mental states, which offers a substitute representation to original scripts and helps surpass all transductive methods; (2) ToMPro struggles to generate high-quality desires, due to GPT-4's limited global picture of characters; (3) Error propagation occurs when using historical states as inputs, calling for improvements to utilize historical information for robust generation; (4) ToMPro often includes trivial facts, as GPT-4 struggles to distinguish significant information, leading to misleading character depictions; (5) Even a generated description is accurate, ToMPro may make mistakes during the guessing stage when contextual coherence between immediate mental states and the current scene is lacking. This reflects the deficiency in ToM reasoning of LLMs and calls for enhancement of LLMs to develop global understanding and abstraction of historical mental states.\\n\\n7.4. Analysis\\n\\nPerformance on Different Numbers of Choices. We investigate the dependency between accuracy and the number of characters contained in the scene to guess. Table 5 gives the performance decomposition according to if a scene consists of \u22653 characters (detailed performance breakdown to the number of choices in Table 11, Appendix G). As expected, the involvement of multiple speakers has a noticeable impact on all the evaluated approaches, primarily due to the limited evidence per speaker and the increasing complexity of the conversational logic. Furthermore, scenes with fewer speakers can sometimes be solved with shortcuts, e.g., exploiting correlations between locations, genders, and characters. In contrast, humans employ their ToM capabilities to tackle our tasks, consistently delivering comparable performance levels across scenes with varying numbers of options. Our ToMPro leads to a smaller gap between the two sets while maintaining top performance, indicating that our approach relies more on ToM reasoning rather than shortcuts.\\n\\nPerformance on Movie Genre. We analyze whether certain genres raise more challenges in our task. We find that different approach categories show clear discrepancies in their performance among different genres. Figure 5 gives the Spearman correlation coefficient matrix between models across different genres. It shows that the non-LLM approaches, LLM approaches and humans use very different strategies to reason the character identities. Detailed performance breakdowns of movie genres are in Table 12.\\n\\nIterative v.s. Non-Iterative Generation. We evaluated whether the ToMPro can benefit from the long context window of recent LLMs thus improves over our iterative Stage-1 prompt. The number in Table 4 shows no significant performance difference between the two methods in the setting when only the training scenes are used. It is noteworthy that the iterative prompt is always necessary when allowing the use of testing scenes.\\n\\nAblation of Stage-1 Models. We conducted experiments to understand the contributions of GPT-4 and our prompt in Stage-1, while keeping the usage of GPT-4 in Stage-2. By replacing GPT-3.5 with GPT-4 in Stage-1, ToMPro's performance drops from 68.2 to 65.8. This indicates that both GPT-4's strong ToM understanding in Stage-1 and ToM reasoning in Stage-2 are critical for good performance. Of the two, GPT-4's enhanced abilities in ToM reasoning have a slightly greater impact.\\n\\nWhen replacing our Stage-1 prompt with a simple iterative plot summarization prompt (Chang et al., 2023), the performance drops to 65.4. Specifically, this ablation lags behind on movies with more characters that act together (e.g., Stan and Kyle in South Park), where the plot summaries often provide similar descriptions for these characters, making them less distinct from one another. It is noteworthy that although this variation can still perform well, it cannot provide value in understanding characters' mental states, thus falling into the category of transductive approaches.\\n\\nReplacing GPT-4 with Open-Source LLMs. To understand how much our ToMPro benefits from the power of GPT-4, we compare with the open-source LLMs from the Mistral (Jiang et al., 2023; 2024) and Llama2 (Touvron et al., 2020).\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nMo Yu* 1\\nQiujing Wang* 2\\nShunchi Zhang* 2\\nYisi Sang 3\\nKangsheng Pu 3\\nZekai Wei 3\\nHan Wang 1\\nLiyan Xu 1\\nJing Li 4\\nYue Yu 5\\nJie Zhou 1\\n\\nAbstract\\n\\nWhen reading a story, humans can quickly understand new fictional characters with a few observations, mainly by drawing analogies to fictional and real people they already know. This reflects the few-shot and meta-learning essence of humans\u2019 inference of characters\u2019 mental states, i.e., theory-of-mind (ToM), which is largely ignored in existing research. We fill this gap with a novel NLP dataset in a realistic narrative understanding scenario, TO-M-IN-AMC. Our dataset consists of \u223c1,000 parsed movie scripts, each corresponding to a few-shot character understanding task that requires models to mimic humans\u2019 ability of fast digesting characters with a few starting scenes in a new movie. We further propose a novel ToM prompting approach designed to explicitly assess the influence of multiple ToM dimensions. It surpasses existing baseline models, underscoring the significance of modeling multiple ToM dimensions for our task. Our extensive human study verifies that humans are capable of solving our problem by inferring characters\u2019 mental states based on their previously seen movies. In comparison, all the AI systems lag >20% behind humans, highlighting a notable limitation in existing approaches\u2019 ToM capabilities. Code and data are available at https://github.com/ShunchiZhang/ToM-in-AMC.\\n\\n1. Introduction\\n\\nHumans are social animals who engage in a high frequency of social activities every day. To achieve efficient social interactions, humans need to understand other people\u2019s mental states, such as intentions and beliefs, with small amounts of information and to predict their next moves (Perner & Wimmer, 1985; Keysar et al., 2000). Such ability is known as theory-of-mind (ToM) (Premack & Woodruff, 1978). In AI research, there is also a growing interest in giving machines such theory-of-mind (Nematzadeh et al., 2018; Yuan et al., 2020; Zhu et al., 2021), mostly in synthetic settings. The accomplishments of these efforts have encouraged a shift in the study of ToM from synthetic environments to real-life scenarios for potential future applications. However, creating such evaluation benchmarks is challenging since it would be impossible to imitate human actions that take into account a variety of real-world elements. The NLP community hence resorts to fictional characters in stories as a delegate. Characters play a central role in stories\u2014while reading stories, humans build mental models for characters to understand their goals, emotions, personalities, future behaviors, etc. (Gernsbacher et al., 1998). Therefore, understanding characters in stories serves naturally as a proxy for assessing the machine\u2019s ToM ability. Benchmarks with different task formats have been established, including personality classification (Flekova & Gurevych, 2015), personalized dialogue generation (Li et al., 2020), and anonymous speaker guessing (Sang et al., 2022b).\\n\\nAll existing assessments model a character with a large amount of behavioral data and dialogues. In contrast, humans can usually understand new people with \u201cfew-shot\u201d observations. Instead of making judgments after accumulating observations over an extended period, when we meet strangers or read new fictional characters, we make primitive judgments based on the limited information currently available and dynamically change our impressions over time as we take in new information. Humans have this ability because of their prior experience of meeting different people and reading stories about various characters throughout their lifetime (Rowe et al., 2008; Jahan et al., 2021), as well as employing basic cognitive functions such as association (Ma et al., 2011). More broadly, this relates to the brain\u2019s abilities for analogy and categorization regarding individuals (Hofstadter & Sander, 2013).\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nFor example, Grindelwald in the Fantastic Beast movies (Figure 1) is not a simple villain but has a much more complex persona. Still, many people can easily understand his charismatic and idealistic persona as a revolutionary leader, if they have seen Magneto from the X-men, both of whom are revolutionary for their own kinds but are ruthless to others. Thus, the audience can understand Grindelwald has the exact persona to speak the last utterance in Figure 1b. This reflects the meta-learning capability of humans' ToM, which is largely ignored in previous works.\\n\\nWe aim to bridge this gap and evaluate the capacity of machines to meta-learn ToM similar to humans. Such an assessment raises two fundamental requirements for tasks. (1) We need natural few-shot tasks that humans can effectively tackle with knowledge from related tasks. To this end, we construct our dataset based on movie script understanding. When humans watch a new movie, they can rapidly comprehend the roles of unfamiliar characters based on a limited number of initial scenes from their knowledge of previously viewed movies. Here each movie naturally corresponds to a few-shot learning task, and the process of swiftly understanding new characters represents a meta-learning setting. (2) Each task should effectively assess the ToM capabilities in a comprehensive way. Among the existing task formats of character understanding, we adopt the task from (Sang et al., 2022b), which requires guessing the identities of speakers in a scene with all their utterances anonymized, as shown in Figure 1 (middle). Human study illustrated that the task requires understanding multiple types of character personas that are well aligned with humans' ToM during reading.\\n\\nBased on the two ideas, we created the first assessment for meta-learning of ToM. For each movie, the script is preprocessed (Figure 1a) to a sequence of scenes to form the character guessing instances (Figure 1b). A small number of starting scenes sufficient for humans to grasp characters are used for training, making each movie a few-shot task. We split the movies into meta-training and meta-testing tasks. A meta-model can learn from meta-training tasks, then make few-shot predictions on the meta-testing ones (Figure 1c).\\n\\nTransductive v.s. Inductive Settings. Our dataset enables the assessment of machines' ToM in two settings: a transductive setting, where a meta-model possesses access to and can leverage the characters' previous acts as examples during prediction, and a more stringent inductive setting, where a meta-model must generate a mental model or a mental state description of the character, relying solely on this information for prediction. While both settings are challenging, the inductive setting holds particular significance:\\n\\n- Emphasizing the effects of various ToM dimensions and improving explanability: While our task encompasses a broad range of ToM dimensions through the use of real-world scenarios, it lacks specific evaluations tailored to each dimension. The inductive approach offers the opportunity to model each dimension using the generated mental descriptions, allowing for explicit performance measurement and in-depth study of their respective impacts.\\n- Mitigating Shortcuts: The existing ToM assessments primarily focus on the end-task performance. This carries the risk that machines may achieve correct predictions through shortcuts, e.g., data leaks during pre-training or spurious correlations (Shapira et al., 2023) of non-ToM-related cues. Requiring to generate mental descriptions can help alleviate such shortcuts and lead to a more effective evaluation.\\n\\nMain Observations. We conduct a large-scale human study on our dataset. The human annotators are asked to perform the tasks on movies they have not seen before. The results show that they can solve our task with a $\\\\sim 90\\\\%$ accuracy, with the help of their knowledge acquired from their previously seen movie characters. This demonstrates that human strategies employ meta-models and draw analogies between new and familiar examples, aligning with core...\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind methods in the meta-learning field. In comparison, the widely used prototypical networks (Snell et al., 2017) and the LEOPARD (Bansal et al., 2020) lag \u224330% behind humans. We also investigate the usage of large language model (LLM) GPT-4. Our proposed ToM prompting, which explicitly models the separated mental states, including belief, intention, personality, and more, achieves the best performance, confirming the effectiveness in modeling various dimensions of ToM for our task. Nevertheless, it is >20% behind humans, emphasizing the significant challenge presented by our task and the substantial advancements that AI systems still need to achieve to fully grasp ToM.\\n\\nOur work makes the following contributions:\\n\\n1. We propose the problem of few-shot character understanding to assess machines' meta-learning ability of theory-of-mind, which is common in humans' daily life but has been overlooked by AI and NLP research; and build the first dataset to this end in a non-synthetic scenario.\\n\\n2. We benchmark existing meta-learning approaches and conduct comprehensive human study on our dataset, revealing that humans solve our problem with meta-learning-style strategies and significantly outperform all the AI methods.\\n\\n3. We propose a novel prompting approach for the inductive setting. It outperforms existing baselines and confirms that our task requires multiple ToM dimensions to solve.\\n\\n2. Related Work\\n\\nTheory of Mind in NLP.\\n\\nResearchers in the NLP field have proposed several tasks to evaluate machines' ToM in the language understanding setting (Ma et al., 2023), particularly in light of the promising advancements seen in LLMs' emerging ToM capabilities (Kosinski, 2023; Bubeck et al., 2023). Most of these tasks conduct assessments on the ToM dimension of belief (Nematzadeh et al., 2018; Cohen, 2021; He et al., 2023; Sileo & Lernould, 2023; Shapira et al., 2023), which some also cover other dimensions like intention, desire, emotion, etc (Zhang & Chai, 2010; Sap et al., 2019; Yuan et al., 2020; Zhu et al., 2021; Tracey et al., 2022; Zhou et al., 2023; Wu et al., 2023; Chen et al., 2024).\\n\\nDifferent from our work, these datasets primarily rely on synthetic settings. The drawback of synthetic settings is that the roles evaluated in the datasets lack clear associations with specific characters, which leads to a significant oversight from the crucial meta-learning perspective of ToM. Additionally, this limitation prevents the exploration of certain vital aspects of ToM, such as the influence of characters' personalities and their past experiences on ongoing events.\\n\\nFictional Character Understanding.\\n\\nThere are many tasks proposed for character understanding in stories, covering the assessments of factual information of characters (Chen & Choi, 2016; Chen et al., 2017), inter-character relationships (Massey et al., 2015), and personality of characters (Flekova & Gurevych, 2015; Yu et al., 2023). Recent work (Brahman et al., 2021; Sang et al., 2022b) proposed a new character guessing task \u2014 a form of guessing the identity of anonymized characters in a scene. Human studies showed that the task requires understanding multiple dimensions of characters' mental states, such as personalities, desires and intentions. Therefore, our work chooses this form due to its simplicity, comprehensiveness and assessment strength.\\n\\nMeta and Few-Shot Learning in NLP.\\n\\nMost of the meta and few-shot learning datasets have their tasks sampled from a single large dataset, leading to homogeneous settings. FewRel (Han et al., 2018) downsamples a relational classification dataset. SNIPS (Coucke et al., 2018) and CLINC150 (Larson et al., 2019) downsamples intent classification datasets from a few general domains. To encourage meta-learning across heterogeneous tasks, people build datasets that collect tasks from diverse resources. Crossfit (Ye et al., 2021) collected and down-sampled 160 NLP tasks from Huggingface Datasets. FewJoint (Hou et al., 2020) include slot-filling tasks from 59 domains. Yu et al. (2018) collect clients' proposed intent classification tasks. Compared to these prior work, our dataset has a natural few-shot learning setting from daily life that does not need artificial construction like down-sampling.\\n\\n3. Problem Definition\\n\\nTo provide an assessment to the machine's meta-learning ability of ToM, we propose to mimic the scenario where humans can quickly understand characters in a new movie based on movies they have seen before. For each movie, we build a character guessing task (Sang et al., 2022b) (Section 3.2), which has been verified as a valid ToM assessment. We build our meta-setting on top of this task in Section 3.3.\\n\\n3.1. Background: Meta-Learning Formulation\\n\\nIn a meta-learning problem, we are given $N$ tasks $T = \\\\{T_1, \\\\ldots, T_N\\\\}$, divided into training, development and test task sets $T_{\\\\text{train}}$, $T_{\\\\text{dev}}$, $T_{\\\\text{test}}$. Each task $T_i$ consists of a training data set $D_{\\\\text{train}}^i$ and a test data set $D_{\\\\text{test}}^i$. \\n\\n| Genre | Count | Example |\\n|-------|-------|---------|\\n| Action | 201   | Rush Hour2 |\\n| Horror  | 99    | Carrie |\\n| Adventure | 102  | Tropic Thunder |\\n| Musical | 12    | Nine |\\n| Animation | 21   | Toy Story |\\n| Mystery | 69    | Rear Window |\\n| Comedy  | 233   | Blue Valentine |\\n| Crime   | 147   | Deception |\\n| Sci-Fi  | 105   | Jurassic Park |\\n| Drama   | 394   | Fracture |\\n| Romance | 122   | Blue Valentine |\\n| Thriller | 257  | Chasing Sleep |\\n| Fantasy | 66    | Watchmen |\\n| Short   | 2     | Quantum Project |\\n| Family  | 17    | Up |\\n| War     | 15    | Platoon |\\n| Film-noir | 4  | Sunset Blvd. |\\n| Western | 7     | Roughshod |\\n| Film   | 2     | Ters (Chen & Choi, 2016; Chen et al., 2017) |\\n| Musical | 12    | Nine |\\n| Drama   | 394   | Fracture |\\n| Romance | 122   | Blue Valentine |\\n| Crime   | 147   | Deception |\\n| Sci-Fi  | 105   | Jurassic Park |\\n| Drama   | 394   | Fracture |\\n| Romance | 122   | Blue Valentine |\\n| Crime   | 147   | Deception |\\n| Sci-Fi  | 105   | Jurassic Park |\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nTable 2: Statistics of our ToM-IN-AMC.\\n\\n| Task Set        | Movies | Characters | Scenes | Instances | Scenes | Instances |\\n|-----------------|--------|------------|--------|-----------|--------|-----------|\\n| Training        | 807    | 3,063      | 59,301 | 36,662    | 59,743 | 22,639    |\\n| Development     | 100    | 401        | 7,430  | 4,544     | 7,609  | 2,886     |\\n| Testing         | 100    | 373        | 7,293  | 4,538     | 7,158  | 2,755     |\\n| Total           | 1,007  | 3,837      | 74,024 | 45,744    | 74,510 | 28,280    |\\n\\nA typical meta-learning model consists of two stages. (1) A meta-training stage learns a meta-model on the few-shot tasks in $T_{train}$. In each iteration, a task $T_i$ is sampled from $T_{train}$. The meta-model is trained on samples from $D_{train}^i$ and is tested on samples from $D_{test}^i$. The testing loss is used to optimize the meta-model's parameters. Its hyperparameters are determined with the meta-dev set $T_{dev}$. (2) A meta-testing stage evaluates the learned meta-model on the unseen tasks from $T_{test}$, which typically outputs a classifier by adapting on its small number of training samples. The ultimate goal of a meta-learning is to efficiently transfer the knowledge about learning on the training tasks to new tasks.\\n\\n3.2. Background: Character Guessing Task\\n\\nEach of our tasks has the character guessing format (Sang et al., 2022b). The task adopts a multi-choice setting. The input is a scene with the main characters (at most 5 for each movie) masked with their corresponding IDs. The IDs are randomly assigned to characters in different scenes. The goal is to map each ID to its identity. Formally, we denote the $t$-th anonymous scene in a movie as $S(t) = \\\\{s_1(t), s_2(t), ..., s_n(t)\\\\}$. $s_i(t)$ is an utterance or background description, which depicts the verbal or behavioral actions of anonymous characters with ID $P_x$, $x \\\\leq 5$. A scene is associated to a candidate character set $C = c_1, ..., c_k$, $k \\\\leq 5$. The goal is thus to predict each $P_x$'s actual identity $c_j$ as:\\n\\n$$P(P_x = c_j | S(t)).$$\\n\\n3.3. Meta-Learning of Character Guessing\\n\\nDifferent from (Sang et al., 2022b) where each character has a large amount of training data, our work has a natural few-shot setting. We have a set of movie scripts $M = \\\\{M_1, ..., M_N\\\\}$. Each movie $M_i$ corresponds to a task $T_i$ in the meta-learning formulation. The main characters in each movie $M_i$, denoted as $C_i$, are treated as class labels. Each instance of $T_i$ follows the task format in Section 3.2. It corresponds to a tuple $(P_x = c_k, S)$. Here $S$ and $c_k$ are both from movie $M_i$. For each $M_i$, we split a few starting scenes into the training set, which are sufficient for human to grasp characters. The problem asks a meta-model to learn from training movies, so as to perform well on unseen movies with few-shot examples. In this way, it assesses how to infer a new character's mental states rapidly by drawing analog from seen characters, i.e., the meta-learning ability of ToM.\\n\\n4. Our ToM-IN-AMC Benchmark\\n\\nWe constructed ToM-IN-AMC, the first dataset on ToM meta-learning assessment with Movie Characters as a testbed. We collect movie scripts from IMSDB (imsdb.com), divide the script into scenes, and recognize and anonymize the main characters in each scene. Finally, we build a task on each movie to simulate few-shot scenarios. In total, we collected 1,007 movies. Table 1 shows that Drama, Thrill, and Comedy are the 3 most popular genres. Script Parsing and Scene Splitting. Movie scripts are highly structured documents that have basic formatting elements (Riley, 2009), as shown in Figure 1(a), including (1) scene headings that indicate the start of a scene with place information; (2) actions that describe the characters' behaviors and the setting; and (3) dialogues of the characters. We process the scripts with a state-of-the-art parser from (Sang et al., 2022a) to identify headings, actions, and dialogues; then split the identified sequence of chunks into scenes according to the recognized scene headings. Since the scene headings always first illustrate if the scene is indoors (INT.) or outdoors (EXT.), they can be accurately identified with rules. The texts, including actions and dialogues, between two headings are considered as one scene. Evaluation Task Construction. We choose the top-5 characters with the most dialogue utterances as candidates for each movie, so that each has sufficient evidence for our character identification task. We use the first 3/5 of the movie script for training and the rest for testing. According to (Chase, 2022), in movie scripts, the main characters are usually introduced in the first 10 pages with their personalities and appearances, to provide a mental picture for the readers. Therefore, our training split is able to cover sufficient information for humans to understand characters. In our problem, we denote each character in a scene as an instance. As shown in Table 2, every character has less than 20 training instances on average, naturally leading to a few-shot problem setting. Name Perturbation. The LLMs have a vast amount of pre-training data, including some of the testing movies.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nTable 5: Performance by difficulty levels measured the number of speakers in a scene.\\n\\n| Difficulty | #Speakers | Transductive | Inductive | Human |\\n|------------|-----------|--------------|-----------|-------|\\n| Easy       | <3        | 56.0         | 72.0      | 63.1  |\\n| Hard       | \u2a7e3        | 47.7         | 57.7      | 48.6  |\\n| \u2206          |           | 8.3          | 14.3      | 14.4  |\\n\\n10-shot 20-shot\\n\\nTable 6: Performance of open-source LLMs on development set.\\n\\n| Model          | Acc  | Acc  |\\n|----------------|------|------|\\n| GPT-4 (our full system) | 68.2 |      |\\n| Llama2 7B-Chat  | 18.5 | 70.0 |\\n| Mistral 7B-Chat | 40.9 | 55.5 |\\n\\n2023) families. We substitute these models for the guessing model depicted in Figure 3. As shown in Table 6, these open-source LLMs significantly lag behind GPT-4.\\n\\nEffects of GPT-4's Memorization.\\n\\nTo gain a deeper understanding of GPT-4's memorization issue and the necessity of our perturbation setting, we conducted an analysis using the original non-perturbed data to compare the results. First, we devised a zero-shot experiment in which we asked GPT-4 to identify characters solely based on their names as options, without any historical context or character descriptions. This experiment resulted in an accuracy of 69.2%, which indicates that GPT-4 has indeed been extensively exposed to the content of our movies during its training. Second, we compared the performance of our GPT-4 ICL approach in both the perturbed and non-perturbed settings. Figure 6 shows a significant gap in their results. These results suggest that our perturbation setting effectively enhances the evaluation of ToM abilities by mitigating the impact of memorization.\\n\\nMental State Generation w/ and w/o GPT-4's Memorization.\\n\\nContinuing from the previous analysis, we delve deeper into the impact of GPT-4's memorization in our inductive setting. To facilitate a direct comparison to our ToMPro, this corresponds to generating the mental states (Stage-1) on the non-perturbed scenes and guessing the identities (Stage-2) in the perturbed scenario.\\n\\nFirst, we substitute the mental states produced by ToMPro with GPT-4's recollection of the characters' persona. The prompt we used can be found in Appendix H. It gives a score of 67.4. This method is akin to cheating because the description often includes spoilers to our testing scenes. In light of this, our ToMPro still gives better result (68.2%), highlighting the crucial role of generating a robust mental representation of characters in our task.\\n\\nSecond, employing the mental states generated by ToMPro on the non-perturbed scenes results in a small improvement from 68.2% to 70.7%. It shows that the mental state generation stage is less affected by shortcuts and memorization, highlighting the significance of our inductive setting. The fact that LLMs are still far from humans' ToM capabilities even with data leaks from real character names shows the great potential for future work.\\n\\nDoes GPT-4 Have Correct Understanding of the ToM Dimensions?\\n\\nTo ensure ToMPro accurately understands the definitions of various ToM dimensions and produces mental descriptions for the required dimensions, we perform human verification on 280 generated cases. It reveals that humans can recognize the dimension from GPT-4's mental descriptions 94% of the time. However, GPT-4 often struggles to generate long-term desire descriptions due to its limited big-picture understanding, leading to correlated desires and intentions (still distinguishable through expressions).\\n\\nUnderstanding the definitions correctly does not ensure that the generated mental states along the dimensions are always correct and useful. To evaluate the quality of these generated mental states, we conducted a pilot study using a novel and a TV series that our authors are well-acquainted with. The results indicate that GPT-4 generally performs well in identifying intentions but is less effective in the dimensions of emotion and belief, suggesting its limitations in ToM understanding. Detailed results are provided in Appendix I.\\n\\n8. Conclusion\\n\\nInspired by the fact that humans can quickly infer the mental states of fictional characters when seeing a new story, we present the problem of studying machines' ability in meta-learning of ToM and a benchmark for this assessment. Our experiments and human study justify the value of our benchmark, as (1) humans greatly outperform all the meta-learning approaches including the GPT-4 based ones on our dataset with a \u223c20% margin; (2) human solve our task largely with the knowledge about characters obtained from the stories they have read before; (3) our proposed ToM-Pro method demonstrates that our task benefits from the understanding of multiple ToM dimensions. Our work suggests the great value and potential for future study to fuel machines with ToM via meta-learning.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"few-shot character understanding in movies as an assessment to meta-learning of theory-of-mind\\n\\nimpact statement\\n\\nthis paper presents work whose goal is to advance the field of machine learning. there are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. nevertheless, we discuss certain biases and limitations present in our dataset as below.\\n\\nbiases existing in tom-amc.\\n\\nour dataset consists of several old movies that were created during a specific time period. as a result, they may exhibit certain limitations in terms of their content and representation, raising considerations of fairness. for instance, in the movie king kong, the heroine is portrayed as a blonde and beautiful lady, which may reflect certain biases of the era. additionally, some movies in our dataset contain vulgar language and are classified as r-rated, e.g., south park: bigger, longer & uncut.\\n\\nlastly, there is an imbalance in the number of characters across genders, making the female characters can be easily identified without the need for historical information. however, it's important to note that our dataset construction strategy can be used to create more instances with newly coming movie scripts. in the future, we can curate a subset of movies that are free from such biases and limitations.\\n\\nlimitation to the textual modality.\\n\\nmovies typically offer multi-modal observations that help audiences understand characters. directly incorporating this multi-modal information into our task presents challenges, such as the need to anonymize the visual appearance of characters. however, we emphasize that while our character identification task is text-only, our human study also relies exclusively on text. in this fair comparison setup, humans still significantly outperform machines.\\n\\nas the first work on the meta-learning perspective of tom, our primary arguments about the critical need for and the current deficiency in the study of the meta-learning perspective of tom remain valid.\\n\\nreferences\\n\\napperly, i. a. and butterfill, s. a. do humans have two systems to track beliefs and belief-like states? psychological review, 116(4):953, 2009.\\n\\nbansal, t., jha, r., and mccallum, a. learning to few-shot learn across diverse natural language classification tasks. in proceedings of the 28th international conference on computational linguistics. international committee on computational linguistics, 2020.\\n\\nbaron-cohen, s. precursors to a theory of mind: understanding attention in others. natural theories of mind: evolution, development and simulation of everyday mind, 1(233-251):1, 1991.\\n\\nbrahman, f., huang, m., tafjord, o., zhao, c., sachan, m., and chaturvedi, s. \\\"let your characters tell their story\\\": a dataset for character-centric narrative understanding. in findings of the association for computational linguistics: emnlp 2021. association for computational linguistics, 2021.\\n\\nbrown, t., mann, b., ryder, n., subbiah, m., kaplan, j. d., dhariwal, p., neelakantan, a., shyam, p., sastry, g., askell, a., et al. language models are few-shot learners. advances in neural information processing systems, 33:1877\u20131901, 2020.\\n\\nbubeck, s., chandrasekaran, v., eldan, r., gehrke, j., horvitz, e., kamar, e., lee, p., lee, y. t., li, y., lundberg, s., et al. sparks of artificial general intelligence: early experiments with gpt-4. arxiv preprint arxiv:2303.12712, 2023.\\n\\nchang, y., lo, k., goyal, t., and iyyer, m. bookscore: a systematic exploration of book-length summarization in the era of llms. in the twelfth international conference on learning representations, 2023.\\n\\nchase, n. how to introduce characters in a screenplay. https://neilchasefilm.com/how-to-introduce-characters-in-a-screenplay/, 2022.\\n\\nchen, h. y., zhou, e., and choi, j. d. robust coreference resolution and entity linking on dialogues: character identification on tv show transcripts. in proceedings of conll 2017, pp. 216\u2013225, 2017.\\n\\nchen, y.-h. and choi, j. d. character identification on multiparty conversation: identifying mentions of characters in tv shows. in proceedings of sigdial 2016, pp. 90\u2013100, 2016.\\n\\nchen, z., wu, j., zhou, j., wen, b., bi, g., jiang, g., cao, y., hu, m., lai, y., xiong, z., et al. tombench: benchmarking theory of mind in large language models. arxiv preprint arxiv:2402.15052, 2024.\\n\\ncohen, m. exploring roberta's theory of mind through textual entailment. 2021.\\n\\ncoucke, a., saade, a., ball, a., bluche, t., caulier, a., leroy, d., doumouro, c., gisselbrecht, t., caltagirone, f., lavril, t., et al. snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces. arxiv preprint arxiv:1805.10190, 2018.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nFlekova, L. and Gurevych, I. Personality profiling of fictional characters using sense-level links between lexical resources. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1805\u20131816, 2015.\\n\\nGernsbacher, M. A., Hallada, B. M., and Robertson, R. R. How automatically do readers infer fictional characters\u2019 emotional states? Scientific studies of reading, 2(3):271\u2013300, 1998.\\n\\nHan, X., Zhu, H., Yu, P., Wang, Z., Yao, Y., Liu, Z., and Sun, M. FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2018.\\n\\nHe, Y., Wu, Y., Jia, Y., Mihalcea, R., Chen, Y., and Deng, N. Hi-tom: A benchmark for evaluating higher-order theory of mind reasoning in large language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, 2023.\\n\\nHofstadter, D. R. and Sander, E. Surfaces and essences: Analogy as the fuel and fire of thinking. Basic books, 2013.\\n\\nHou, Y., Mao, J., Lai, Y., Chen, C., Che, W., Chen, Z., and Liu, T. Fewjoint: a few-shot learning benchmark for joint language understanding. arXiv preprint arXiv:2009.08138, 2020.\\n\\nJahan, L., Mittal, R., and Finlayson, M. Inducing stereotypical character roles from plot structure. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 492\u2013497, 2021.\\n\\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lachaux, M.-A., Stock, P., Scao, T. L., Lavril, T., and Sayed, W. E. Mistral 7b, 2023.\\n\\nJiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D. S., de las Casas, D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G., Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-A., Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao, T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. Mixtral of experts, 2024.\\n\\nKeysar, B., Barr, D. J., Balin, J. A., and Brauner, J. S. Taking perspective in conversation: The role of mutual knowledge in comprehension. Psychological Science, 11(1):32\u201338, 2000.\\n\\nKosinski, M. Theory of mind may have spontaneously emerged in large language models. arXiv preprint arXiv:2302.02083, 2023.\\n\\nLarson, S., Mahendran, A., Peper, J. J., Clarke, C., Lee, A., Hill, P., Kummerfeld, J. K., Leach, K., Laurenzano, M. A., Tang, L., and Mars, J. An evaluation dataset for intent classification and out-of-scope prediction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics, 2019.\\n\\nLi, A. W., Jiang, V., Feng, S. Y., Sprague, J., Zhou, W., and Hoey, J. Aloha: Artificial learning of human attributes for dialogue agents. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 8155\u20138163, 2020.\\n\\nMa, N., Vandekerckhove, M., Van Overwalle, F., Seurinck, R., and Fias, W. Spontaneous and intentional trait inferences recruit a common mentalizing network to a different degree: spontaneous inferences activate only its core areas. Social neuroscience, 6(2):123\u2013138, 2011.\\n\\nMa, Z., Sansom, J., Peng, R., and Chai, J. Towards a holistic landscape of situated theory of mind in large language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 1011\u20131031, 2023.\\n\\nMassey, P., Xia, P., Bamman, D., and Smith, N. A. Annotating character relationships in literary texts. arXiv:1512.00728, 2015.\\n\\nNematzadeh, A., Burns, K., Grant, E., Gopnik, A., and Griffiths, T. Evaluating theory of mind in question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2018.\\n\\nPerner, J. and Wimmer, H. \u201cjohn thinks that mary thinks that...\u201d attribution of second-order beliefs by 5-to 10-year-old children. Journal of experimental child psychology, 39(3):437\u2013471, 1985.\\n\\nPremack, D. and Woodruff, G. Does the chimpanzee have a theory of mind? Behavioral and brain sciences, 1(4):515\u2013526, 1978.\\n\\nRiley, C. The Hollywood standard: the complete and authoritative guide to script format and style. Michael Wiese Productions, 2009.\\n\\nRowe, J. P., Ha, E. Y., and Lester, J. C. Archetype-driven character dialogue generation for interactive narrative. In International Workshop on Intelligent Virtual Agents, pp. 45\u201358. Springer, 2008.\"}"}
{"id": "ZZ7UKgK4c1", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Few-Shot Character Understanding in Movies as an Assessment to Meta-Learning of Theory-of-Mind\\n\\nSang, Y., Mou, X., Yu, M., Wang, D., Li, J., and Stanton, J.\\n\\nMbti personality prediction for fictional characters using movie scripts. arXiv preprint arXiv:2210.10994, 2022a.\\n\\nSang, Y., Mou, X., Yu, M., Yao, S., Li, J., and Stanton, J. Tvshowguess: Character comprehension in stories as speaker guessing. arXiv preprint arXiv:2204.07721, 2022b.\\n\\nSap, M., Rashkin, H., Chen, D., Le Bras, R., and Choi, Y. Social IQa: Commonsense reasoning about social interactions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4463\u20134473, Hong Kong, China, November 2019. Association for Computational Linguistics.\\n\\nShapira, N., Levy, M., Alavi, S. H., Zhou, X., Choi, Y., Goldberg, Y., Sap, M., and Shwartz, V. Clever hans or neural theory of mind? stress testing social reasoning in large language models, 2023.\\n\\nSileo, D. and Lernould, A. Mindgames: Targeting theory of mind in large language models with dynamic epistemic modal logic. arXiv preprint arXiv:2305.03353, 2023.\\n\\nSnell, J., Swersky, K., and Zemel, R. Prototypical networks for few-shot learning. Advances in neural information processing systems, 30, 2017.\\n\\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. Llama 2: Open foundation and fine-tuned chat models, 2023.\\n\\nTracey, J., Rambow, O., Cardie, C., Dalton, A., Dang, H. T., Diab, M., Dorr, B., Guthrie, L., Markowska, M., Muresan, S., et al. Best: The belief and sentiment corpus. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pp. 2460\u20132467, 2022.\\n\\nVinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29, 2016.\\n\\nWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., and Rush, A. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Association for Computational Linguistics, 2020.\\n\\nWu, J., Chen, Z., Deng, J., Sabour, S., and Huang, M. Coke: A cognitive knowledge graph for machine theory of mind. arXiv preprint arXiv:2305.05390, 2023.\\n\\nYe, Q., Lin, B. Y., and Ren, X. CrossFit: A few-shot learning challenge for cross-task generalization in NLP. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2021.\\n\\nYu, M., Guo, X., Yi, J., Chang, S., Potdar, S., Cheng, Y., Tesauro, G., Wang, H., and Zhou, B. Diverse few-shot text classification with multiple metrics. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics, 2018.\\n\\nYu, M., Li, J., Yao, S., Pang, W., Zhou, X., Xiao, Z., Meng, F., and Zhou, J. Personality understanding of fictional characters during book reading. In The 61st Annual Meeting Of The Association For Computational Linguistics, 2023.\\n\\nYuan, L., Fu, Z., Shen, J., Xu, L., Shen, J., and Zhu, S.-C. Emergence of pragmatics from referential game between theory of mind agents. arXiv preprint arXiv:2001.07752, 2020.\\n\\nZhang, C. and Chai, J. Y. Towards conversation entailment: An empirical investigation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pp. 756\u2013766, 2010.\\n\\nZhou, P., Zhu, A., Hu, J., Pujara, J., Ren, X., Callison-Burch, C., Choi, Y., and Ammanabrolu, P. I cast detect thoughts: Learning to converse and guide with intents and theory-of-mind in dungeons and dragons. In Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics, 2023.\\n\\nZhu, H., Neubig, G., and Bisk, Y. Few-shot language coordination by modeling theory of mind. In International Conference on Machine Learning, pp. 12901\u201312911. PMLR, 2021.\"}"}
