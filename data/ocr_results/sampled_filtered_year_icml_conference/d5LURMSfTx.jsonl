{"id": "d5LURMSfTx", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this paper, we introduce InfiAgent-DABench, the first benchmark specifically designed to evaluate LLM-based agents on data analysis tasks. Agents need to solve these tasks end-to-end by interacting with an execution environment. This benchmark contains DAEval, a dataset consisting of 603 data analysis questions derived from 124 CSV files, and an agent framework which incorporates LLMs to serve as data analysis agents for both serving and evaluating. Since data analysis questions are often open-ended and hard to evaluate without human supervision, we adopt a format-prompting technique to convert each question into a closed-form format so that they can be automatically evaluated. Our extensive benchmarking of 34 LLMs uncovers the current challenges encountered in data analysis tasks. In addition, building upon our agent framework, we develop a specialized agent, DAAgent, which surpasses GPT-3.5 by 3.9% on DABench. Evaluation datasets and toolkits for InfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent.\"}"}
{"id": "d5LURMSfTx", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfinAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nModeration Aspect Prompt\\n\\nChecking the CSV Data\\n\\n\\\\{\\\\texttt{csv.head().to\\\\string()}}\\n\\nDo you think the above csv file contains any sensitive information including but not limited to Drug, Marijuana, Weeds, Cannabis, Violence, Sexual assault, Politics? Yes or no? If yes, what does it contain?\\n\\nChecking the Conversation\\n\\n\\\\{\\\\texttt{conversation}}\\n\\nDo you think the above dialogue contains any sensitive information including but not limited to Drug, Marijuana, Weeds, Cannabis, Violence, Sexual assault, Politics? Yes or no? If yes, what does it contain?\\n\\nTable 20. Prompts used for comprehensive content moderation.\\n\\nSteps Prompt\\n\\nInitial Prompt Answer the following questions as best you can. You have access to the following tools:\\n\\n\\\\python code\\\\sandbox\\\\[\\\\texttt{input}\\\\]: this tool can help to run python script with python code as input.\\n\\nUse the following format:\\n\\n\\\\begin{itemize}\\n  \\\\item \\\\textbf{Question}: the input question you must answer\\n  \\\\item \\\\textbf{Thought}: you should always think about what to do\\n  \\\\item \\\\textbf{Action}: the action to take, should be one of \\\\[\\\\texttt{python code}\\\\sandbox\\\\]\\n  \\\\item \\\\textbf{Action Input}: the input to the action\\n  \\\\item \\\\textbf{Observation}: the result of the action\\n\\\\end{itemize}\\n\\n\\\\#Thought: I now know the final answer\\n\\n\\\\textbf{Final Answer}: the final answer to the original input question\\n\\nFor all outputs in code, \\\\texttt{THE print()} function MUST be called\\n\\nFor example, when you need to call df.head(), please use \\\\texttt{print(df.head())}\\n\\nIf you have any files outputted write them to \"./output/\"\\n\\nBe mindful that when creating a piece of code for execution in python sandbox, DO NOT try to predict or complete its output.\\n\\nCease generating further and await the execution outcome from python sandbox.\\n\\nPlease note that any text beginning with \\\\[\\\\texttt{SYSTEM NOTIFICATION}\\\\] Running the above tool \\\\end{itemize} is an output from the python sandbox execution. You should NEVER try to generate it.\\n\\nBegin!\\n\\n\\\\textbf{Question}: User uploaded the following files: \\\\{\\\\texttt{filename}}\\n\\n\\\\{\\\\texttt{question}}\\n\\n\\\\textbf{Thought}:\\n\\n\\\\textbf{Reply Prompt Observation}:\\n\\n\\\\[\\\\texttt{\\\\{STDOUT}}\\\\]\\n\\n\\\\textbf{Thought}:\\n\\nTable 21. Prompts for data collection.\\n\\n26\"}"}
{"id": "d5LURMSfTx", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nSpeaker Conversation\\n\\nUser Answer the following questions as best you can. You have access to the following tools:\\n\\n- python code sandbox: this tool can help to run python script with python code as input.\\n\\nQuestion: User uploaded the following files: ['/mnt/ep7.csv']\\n\\nCompute the average number of lines per scene in the 'ep7.csv' dataset.\\n\\nThought: GPT-4 To answer this question, I will need to\\n\\n1. Load the CSV into a pandas DataFrame\\n2. Analyze the dataset to see what it looks like and identify which column contains the scene information\\n3. Count how many lines belong to each scene\\n4. Compute the average number of lines per scene\\n\\nAction: python code sandbox\\n\\nAction Input:\\n```\\nimport pandas as pd\\nfilename = \\\"/mnt/ep7.csv\\\"\\ndataframe = pd.read_csv(filename)\\nprint(dataframe.head())\\n```\\n\\nLet's load the file and see what the data looks like.\\n\\nUser Observation:\\n\\n[SYSTEM NOTIFICATION] Running the above tool with the following response:\\n\\nSTDOUT:\\n\\n[Output of dataframe.head()]\\n\\nThought: GPT-4 We can see that the dataset is a DataFrame with columns 'Season', 'Episode', 'Scene', 'Character', and 'Line'. The lines of script are contained in the 'Line' column, and each line is associated with a scene number in the 'Scene' column. Now I can calculate the total number of lines for each scene.\\n\\nAction: python code sandbox\\n\\nAction Input:\\n```\\nscene_lines_counts = dataframe['Scene'].value_counts().values\\navg_lines_per_scene = scene_lines_counts.mean()\\nprint(avg_lines_per_scene)\\n```\\n\\nHere, I'm counting the number of lines in each scene using the value_counts function on the 'Scene' column of the dataset. This will return a Series with the scene numbers as the index and the counts as the values. The values() function then gets the counts as a numpy array. The mean() function is then used to compute the average number of lines per scene by averaging the counts.\\n\\nUser Observation:\\n\\n[SYSTEM NOTIFICATION] Running the above tool with the following response:\\n\\nSTDOUT:\\n\\n6.018867924528302\\n\\nThought: GPT-4 I now know the final answer\\n\\nFinal Answer: The average number of lines per scene in the 'ep7.csv' dataset is approximately 6.02.\\n\\nTable 22. Case study on DAInstruct.\"}"}
{"id": "d5LURMSfTx", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nPrompts for Evaluation\\n\\nAnswer the following questions as best you can. You have access to the following tools:\\n\\nTable 23. Prompts for evaluation.\\n\\n| Model w/o reformatting | Model w/ reformatting |\\n|------------------------|------------------------|\\n| gpt-4-0613             | 72.76                  |\\n| qwen-72b-chat          | 44.75                  |\\n| qwen-14b-chat          | 18.29                  |\\n| mistral-7b-instruct-v0.2 | 6.23                 |\\n\\nTable 24. The ablation studies of models with and without reformatting. We use GPT-4 as an evaluator and conduct performance comparison between several LLMs (also including GPT-4, which means GPT-4 evaluates itself in this setting).\"}"}
{"id": "d5LURMSfTx", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nPrompts for Reformatting\\n\\nYou should strictly follow the output requirements in the Format part. Here are some examples:\\n\\nFormat\\n\\n@shapiro\\nwilk\\nstatistic@test\\nstatistic\\n\\n@shapiro\\nwilk\\np\\nvalue@test\\np\\nvalue\\n\\nwhere \\\"test\\nstatistic\\\" is a number between 0 and 1 representing the Shapiro-Wilk test statistic. Rounding off the answer to two decimal places.\\n\\nwhere \\\"p\\nvalue\\\" is a number between 0 and 1 representing the p-value from the Shapiro-Wilk test. Rounding off the answer to four decimal places.\\n\\nAnswer\\n\\n@shapiro\\nwilk\\nstatistic[0.56]\\n\\n@shapiro\\nwilk\\np\\nvalue[0.0002]\\n\\nFormat\\n\\n@total\\nvotes\\noutliers\\nnum@test\\noutlier\\nnum\\n\\nwhere \\\"outlier\\nnum\\\" is an integer representing the number of values considered outliers in the \\\"total\\nvotes\\\" column.\\n\\nAnswer\\n\\n@total\\nvotes\\noutliers[10]\\n\\nYour answer should contain all the \\\"@answer\\nname[answer]\\\" in the order mentioned, each \\\"answer\\\" should be in the range of value as required.\\n\\nThe format requirements of this question is:\\n\\nPlease give your answer:\\n\\nTable 25. Prompts for reformatting.\"}"}
{"id": "d5LURMSfTx", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nThe various reasons for using this method as stated in the introduction, it cannot entirely eliminate potential biases or the risk of data leakage in the evaluation. Additionally, we utilize OpenAI's ADA to obtain labels, which might make this benchmark impartial. We consider exploring effective ways to incorporate LLMs into benchmark creation as a direction for future research.\\n\\nB. Detailed related works\\n\\nB.1. Code LLMs\\n\\nCode LLMs are large language models specialized in understanding and generating programming code. These LLMs enjoy a fast development over past few years (Zan et al., 2023; Zhang et al., 2023b). Codex (Chen et al., 2021) is one of the most famous in these models provided by a commercial API from OpenAI. Meanwhile, researchers have developed a large sum of open-source code LLMs, e.g., Code Llama (Rozi`ere et al., 2023), WizardCoder (Luo et al., 2023), XwinCoder (Team, 2023c) and DeepSeek Coder (DeepSeek, 2023).\\n\\nB.2. Benchmarks for Code\\n\\nBenchmarks play an important roles for the development of AI (Hendrycks et al., 2021; Huang et al., 2023; Zhang et al., 2024a; Shen et al., 2023). Over the past years, various benchmarks with different tasks have been proposed to evaluate models for code. CodeXGLUE (Lu et al., 2021) is a comprehensive benchmark covering tasks for both code understanding and generation. In addition, some benchmarks focus on code generation, especially in a competition-level (Chen et al., 2021; Austin et al., 2021; Hendrycks et al., 2021; Li et al., 2022). DS-1000 (Lai et al., 2023) is a benchmark for code generation in data science. Bai et al. (2023) creates a dataset containing math, data visualization and other general-purpose tasks to assess LLMs' ability on using the Python code interpreter. We have a more detailed comparison between InfiAgent-DABench and this work in Appendix C.\\n\\nC. Comparison between InfiAgent-DABench and Code Interpreter Benchmark in Qwen-Agent\\n\\nThere are two main differences between InfiAgent-DABench and code interpreter benchmark in Qwen-Agent (Bai et al., 2023): 1. We benchmark LLMs in data analysis tasks covering series of concepts while Bai et al. (2023) only contains a few data analysis questions in data visualization and its other general-purpose tasks. 2. Our benchmark takes a closed-form evaluation on correctness which doesn't rely on any external models as evaluators. More importantly, Bai et al. (2023) evaluates code correctness for math and data visualization problems with the help of current multi-modal models but only code executability for its general-purpose tasks.\\n\\nD. Performances on InfiAgent-DABench\\n\\nTable 7 shows the accuracy of different models in InfiAgent-DABench. We also draw a spider chart to illustrate the performance in questions involved different concepts in Figure 8.\\n\\nE. Prompts for DAEval Construction\\n\\nIn this section, we list all the prompts used in the process of question generation.\\n\\nE.1. Description Generation\\n\\nTable 8 shows prompts for description generation.\\n\\nE.2. Question Generation\\n\\nTable 9 shows prompts for question generation. We prompt GPT-4 in the following way: 1) Three simple questions...\"}"}
{"id": "d5LURMSfTx", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\n2) Three complex questions involving one or multiple concepts.\\n3) Three more complex questions involving multiple concepts.\\n\\nE.3. Constraints and Format Requirements Generation\\nTable 10 shows prompts for constraints and format requirements generation.\\n\\nF. Detailed Information about Key Concepts\\nTable 11 shows key concepts on data analysis and corresponding explanations obtained from expert interview. We use GPT-3.5 to help us summarize the interview scripts. We could not directly publicize them for some reasons.\\n\\nG. Detailed Information about Domains\\nWe cluster the CSV files into 9 domains with the help of GPT-3.5. Table 12 shows the names of domain and corresponding explanations.\\n\\nH. Detailed Information about Pilot Experiments\\nWe randomly sample 119 questions and corresponding answers from GPT-4, GPT-3.5, DAAgent-34B and ask both human experts and GPT-4 to evaluate based on the same criteria. Each answer is rated based on the level of resolution:\\n0: Did not solve the problem or barely addressed it,\\n1: Partly solved the problem,\\n2: Mostly solved the problem and only have minor errors,\\n3: Completely and exactly solved the problem.\\nTable 13 shows the consistency rate between human experts and GPT-4. We found that when GPT-4 works as an evaluator on data analysis tasks, it only achieves about 67% consistency with human experts, which is obviously unsatisfactory as an evaluator for a benchmark.\\n\\nI. Extended Case Study on Generated Questions\\nTable 14 showcases several questions generated for the file test.csv. This file meticulously documents the personal information and travel details of passengers on the Titanic, including their survival status, cabin class, name, gender, age, and embarkation point, among other aspects. The generated questions include one or more subquestions according to the specific question and constraints.\\n\\nJ. Human Assessment\\nJ.1. Settings for Dataset Quality Assessment\\nFor a high-quality dataset, we invite 3 human experts with math and programming skills to assess the quality of files, questions and labels of all the data samples. For each part, we define one or more metrics. For each metric, to a precise assessment, we decompose it into several yes-or-no questions for experts. Table 15 shows our questionnaire, including questions and expected response formats. We invite 3 experts with math and programming skills to assess all data samples in DAEval. Only all yes-or-no questions of one metric are positive, the assessment results for this metric is positive. We report the percentage of positiveness on each metric and an overall percentage of positiveness on all the metrics. Only data samples positive on all the metrics are kept. Otherwise, we asked experts to compare difficulty on 216 anonymous question pairs (108 with single concept and 108 with multiple concepts) sampled from human-made and GPT-4 generated questions. Questions with single concept are only compared with other single ones, the same for those with multiple concepts. Table 16 shows the questionnaire to experts.\\n\\nJ.2. Bad Case Analysis\\nTable 17 presents two bad cases found from human assessment.\\nIn the first case, we found all values in \\\"Type\\\" column in 2019-08-edges.csv are the same, which means using Random Forest Classifier to predict it here is meaningless. This question doesn't meet our criteria on Alignment.\\nIn the second case, the question asks with \\\"the given dates\\\" but not provides with the specific dates in the following constraints, which means the question doesn't meet our criteria on Restrictiveness.\\n\\nJ.3. Settings for Comparison between Human vs GPT-4\\nWe invite 3 experts with data analysis skills to write 54 questions associated with 9 CSV files. For each file, 3 questions with single concept and 3 with multiple concepts are written. Combined with questions from GPT-4 on the same files, we form a dataset with 102 questions for assessment. Additionally, for difficulty, we randomly sample 216 question pairs on human-made and GPT-4 generated questions. All questions are anonymous to experts in this stage.\\n\\nK. Method for Assessing Difficulty\\nFor the difficulty assessment of DAEval, we randomly sample 80 groups from the dataset, each comprising 5 questions. GPT-4 ranks the questions within each group according to their difficulty, based on criteria such as data processing complexity, domain-specific knowledge, and coding sophistication.\"}"}
{"id": "d5LURMSfTx", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nThis ranking process is repeated 100 times for each group to ensure the robustness of the results. Each question has a score based on its ranking, with the most challenging question in a group earning 5 points and the least challenging 0 points. An average score was then calculated for each question, leading to a numerical difficulty ranking. These rankings allowed for the classification of questions into three levels: easy (0 to 1.667), medium (1.667 to 3.335), and hard (3.335 to 5).\\n\\nL. Statistics on DAInstruct\\n\\nDAInstruct includes 5131 data samples involved 631 CSV files, with the average length of ReAct conversations being 5.18.\\n\\nM. Prompts for DAInstruct Construction\\n\\nM.1. Question Generation\\n\\nTable 18 lists keywords and prompts used for generating questions.\\n\\nM.2. Filtering\\n\\nTable 19 lists prompts used for filtering.\\n\\nM.3. Content Moderation\\n\\nTable 20 lists prompts used for content moderation.\\n\\nN. Instruction-tuning data collection\\n\\nIn our data collection method, GPT-4 engages iteratively in problem-solving with our agent framework. The conversation begins with presenting a CSV file and an associated question. GPT-4 processes this and proposes code solutions, which are then executed. The results of the execution are fed back into the conversation, enabling GPT-4 to refine its responses and propose further iterations. This iterative cycle continues until GPT-4 determines that the accumulated information suffices to conclusively answer the problem. A critical aspect of this process is the design of the prompts, which directs GPT-4's outputs towards effective problem-solving. Table 21 lists prompts used in the process. To counter the challenge of hallucination, where GPT-4 might generate fictitious results, explicit instructions are included in the prompt to prevent GPT-4 from executing the code.\\n\\nO. Case Study on DAInstruct\\n\\nTable 22 shows a case study on DAInstruct, highlighting a dialogue between GPT-4 and the user, which poses questions and executes generated code. This iterative conversation continues until GPT-4 reaches a conclusive solution.\\n\\nP. Implementation Details for Evaluation\\n\\nFull prompts for evaluation can be found in Appendix P.1. We use accuracy as the metric, which is the proportion of questions for which all sub-questions are answered correctly. We use regular expression matching to draw the answer enclosed in \\\"answer name[answer]\\\" and the exact match to evaluate the performance. We set temperature 0.2, top p 1.0 with nucleus sampling and frequency penalty 0.0 for all the models in the experiments. All instances of GPT-3.5 and GPT-4 used in this paper, unless specifically indicated otherwise, are referred to as gpt-3.5-turbo-0613 and gpt-4-0613 respectively.\\n\\nP.1. Prompts for Evaluation\\n\\nTable 23 shows standard prompt templates for evaluation. In addition, we slightly modify the standard templates for Abab5.5-Chat to make its output meet the format requirements of the agent framework. Specifically, we add the following prompt: \\\"Note that you must output the string 'I now know the final answer' before the final answer.\\\"\\n\\nQ. Details for the Reformatting\\n\\nIn this section, we conduct ablation studies to demonstrate the necessity of adding a reformatting step after models' original responses, since most models have difficulties in strictly following the format requirements, while it is crucial for a closed-form evaluation. In addition, we conduct manual check to ensure this reformatting step doesn't effect the evaluation results by introducing external errors. We use gpt-3.5-turbo-16k-0613 on reformatting. Prompts for reformatting are in Appendix Q.3.\\n\\nQ.1. Ablation Studies\\n\\nWe add an additional reformatting step with GPT-3.5 to transform original responses into required formats. We conduct ablation studies in two settings: 1) w/o reformatting: directly prompt models with question, constraints and format requirements at one stage 2) w/ reformatting: first prompt models with question and constraints, and then use GPT-3.5 to reformat the original responses, with GPT-4, Qwen-72B-Chat, Qwen-14B-Chat and Mixtral-7B-Instruct-v0.2. Table 24 shows the results that even the performance of most powerful models like GPT-4 drops about 6%, and weaker models like Mistral-7B drops up to 32%, if prompted without reformatting, indicating the necessity of adding a reformatting step for evaluation.\"}"}
{"id": "d5LURMSfTx", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Q.2. Manual Check\\n\\nWe randomly sample 50 questions with corresponding original responses from models as well as responses processed by reformatting step and manually check if this step could introduce extra errors for evaluation. We found GPT-3.5 can reformat the responses into required formats in all samples, which means this extra step usually will not affect the results.\\n\\nQ.3. Prompts for reformatting\\n\\nTable 25 shows prompts used in reformatting step.\"}"}
{"id": "d5LURMSfTx", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model                               | # Params. (in B) | Accuracy (%) |\\n|-------------------------------------|-----------------|--------------|\\n| gpt-4-0613 (OpenAI, 2023b)         | 78.99           |              |\\n| autogen\u2020 (gpt-4-0613) (Wu et al., 2023a) |                | 71.48        |\\n| daagent-34b                         | 34              | 64.59        |\\n| abab5.5-chat (MiniMax, 2023)       |                 | 61.48        |\\n| gpt-3.5-turbo-0613 (OpenAI, 2023a) |                 | 60.70        |\\n| qwen-72b-chat (Bai et al., 2023)   | 72              | 59.92        |\\n| gemini-pro (Team et al., 2023)     |                 | 56.42        |\\n| daagent-13b                         | 13              | 55.86        |\\n| qwen-agent\u2020 (qwen-72b-chat) (Bai et al., 2023) | 72         | 55.25        |\\n| mixtral-8x7b-instruct-v0.1 \u2020        | 46.7 (12.9)     | 52.92        |\\n| daagent-7b                          | 7               | 51.36        |\\n| xagent\u2020 (gpt-4-0613) (Team, 2023b) |                 | 47.52        |\\n| claude-2.1 (Anthropic, 2023)       |                 | 47.47        |\\n| deepseek-coder-33b-instruct (DeepSeek, 2023) | 33         | 46.09        |\\n| phind-codellama-34b-v2 (Phind, 2023) | 34              | 43.87        |\\n| xwincoder-34b (Team, 2023c)        | 34              | 41.25        |\\n| mistral-7b-instruct-v0.2 (Mistral.ai, 2023) | 7              | 38.67        |\\n| yi-34b (01ai, 2023)                | 34              | 38.34        |\\n| qwen-14b-chat (Bai et al., 2023)   | 14              | 37.50        |\\n| vicuna-13b (Chiang et al., 2023)   | 13              | 35.83        |\\n| agentlm-70b (Zeng et al., 2023)    | 70              | 33.46        |\\n| codellama-34b-instruct (Rozi`ere et al., 2023) | 34       | 31.13        |\\n| vicuna-13b-v1.5 (Chiang et al., 2023) | 13             | 27.31        |\\n| qwen-7b-chat (Bai et al., 2023)    | 7               | 27.27        |\\n| vicuna-7b (Chiang et al., 2023)    | 7               | 26.95        |\\n| codellama-13b-instruct (Rozi`ere et al., 2023) | 13       | 26.67        |\\n| codellama-7b-instruct (Rozi`ere et al., 2023) | 7       | 24.61        |\\n| internlm-chat-20b (Team, 2023a)   | 20              | 24.51        |\\n| agentlm-13b (Zeng et al., 2023)    | 13              | 24.31        |\\n| wizard-coder-13b (Luo et al., 2023) | 13             | 23.14        |\\n| wizard-coder-7b (Luo et al., 2023) | 7               | 22.83        |\\n| xwincoder-13b (Team, 2023c)        | 13              | 19.69        |\\n| agentlm-7b (Zeng et al., 2023)     | 7               | 17.46        |\\n| chatglm3-6b (Zeng et al., 2022)    | 6               | 18.10        |\\n| xwincoder-7b (Team, 2023c)         | 7               | 10.71        |\\n| baichuan2-13b-chat (Yang et al., 2023a) | 13       | 9.34         |\\n| baichuan2-7b-chat (Yang et al., 2023a) | 7        | 8.95         |\\n\\nTable 7. Leaderboard of InfiAgent-DABench. Our DAAgent models are marked bold.\\n\\n\u2217 Mixtral is a model utilizing sparse mixture-of-experts (SMoE) architecture, with 46.7B total parameters but only uses 12.9B parameters per token.\\n\\n\u2020 All models except ready-made agent frameworks are equipped with our framework to interacter with files and code interpreter. We present LLMs those ready-made frameworks based in the experiments in parentheses.\"}"}
{"id": "d5LURMSfTx", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nPrompts for Description Generation\\n\\nHere's the example of a detailed description of the table's header: \\n\\n```\\nThe dataset contains 4599 entries and 5 columns. Here is a detailed description of each column:\\n1. Crime ID\\n   Unique identifier for each crime.\\n   Contains null values.\\n   Data type: Object (String)\\n2. Month\\n   The month when the crime was reported.\\n   No missing values.\\n   Data type: Object (String, in the format YYYY-MM)\\n3. Reported by\\n   The police force that the crime was reported to.\\n   No missing values.\\n   Data type: Object (String)\\n4. Falls within\\n   The higher-level police force that the crime report falls within. No missing values.\\n   Data type: Object (String)\\n5. Longitude\\n   The longitude where the crime occurred.\\n   Contains null values.\\n   Data type: Float64\\n```\\n\\nThis is the information of one table:\\n\\n```\\n{ \\n  info\\n  { \\n     head\\n     { \\n  \\n{ \\n\\nPlease provide a detailed description of this table's header.\\n\\nTable 8.\\n\\nPrompts for Question Generation\\n\\nYou are now a teacher responsible for creating data analysis questions. Please provide 3 possible question prompts based on the given scenario information. Ensure that the answers to these questions only require information within the given scenario and need to be solved using Python code. In data analysis, there are several key concepts:\\n\\n```\\n{ \\n  key\\n  concepts\\n\\nPlease provide questions that are complex. You do not need to answer the questions themselves.\\n\\nScenario: You have a file.\\n\\nHere is a detailed description of each column in the provided table:\\n\\n```\\n{ \\n  file\\n  description\\n\\nPlease use Question to wrap each of the 3 questions separately. Please use Concepts to point out which concepts this question wants to test.\\n\\nTable 9.\\n\\nPrompts for question generation.\\n\\n19\"}"}
{"id": "d5LURMSfTx", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nPrompts for Constrains and Format Generation\\n\\n1) Add more constraints to the question to make sure the question has a single fixed answer. Specify the requirements completely and precisely, so that the students don't need to do any assumption or determine the statistical methods or parameters by themselves. Please use Constraints to wrap all the constraints.\\n\\n2) Specify the desired output format requirements for the questions to make sure the answer can be easily checked. For a single answer, use format like @answer name[answer] for an easy parsing. You can define the \\\"answer name\\\" according to the specific question. \\\"answer\\\" should have a given format and a clear domain of value. Please use Format to wrap all the output requirements mentioned above. Some good demonstrations for constraints and format are: \\\"Constraints: {Calculate the Pearson correlation coefficient (r) to assess the strength and direction of the linear relationship between danceability and energy. Assess the significance of the correlation using a two-tailed test with a significance level (alpha) of 0.05. Report the p-value associated with the correlation test. Consider the relationship to be linear if the p-value is less than 0.05 and the absolute value of r is greater than or equal to 0.5. Consider the relationship to be nonlinear if the p-value is less than 0.05 and the absolute value of r is less than 0.5. If the p-value is greater than or equal to 0.05, report that there is no significant correlation.}\\\"\\n\\nFormat: {{@correlation coefficient[r value] @p value[p value] @relationship type[relationship type] where \\\"r value\\\" is a number between -1 and 1, rounded to two decimal places. where \\\"p value\\\" is a number between 0 and 1, rounded to four decimal places. where \\\"relationship type\\\" is a string that can either be \\\"linear\\\", \\\"nonlinear\\\", or \\\"none\\\" based on the conditions specified in the constraints.}}\\\"\\n\\nThe constraints and formats can be adjusted according to the specific problem to ensure diversity, but strictly use correct symbols as the demonstration like @answer name[answer]. The answer should be: Question\\n\\nConcepts\\n\\nConstraints\\n\\nFormat\\n\\nTable 10. Prompts for constrain and format requirements generation.\"}"}
{"id": "d5LURMSfTx", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nConcepts and corresponding explanations\\n\\nConcept: Summary Statistics\\nExplanation: To start, calculate key summary statistics such as mean, median, standard deviation, minimum, maximum, etc., to obtain an overview of the data. These statistics help understand the central tendencies and distribution range of the data.\\n\\nConcept: Distribution Analysis\\nExplanation: Explore the distribution of the data, including checking if it adheres to a normal distribution, exhibits skewness, heavy tails, or bimodality. This helps in selecting appropriate statistical methods and models.\\n\\nConcept: Correlation Analysis\\nExplanation: Analyze the correlations between various variables. This assists in determining linear or nonlinear relationships between variables.\\n\\nConcept: Outlier Detection\\nExplanation: Identify and deal with outliers, as they can potentially disrupt data analysis and modeling. Methods such as box plots, Z-scores, or specialized outlier detection algorithms can be employed for outlier identification.\\n\\nConcept: Comprehensive Data Preprocessing\\nExplanation: Comprehensive data preprocessing is a fundamental step in the data analysis workflow, encompassing data cleaning, transformation, and the handling of missing values. It begins with data cleaning, a process focused on ensuring the accuracy and consistency of the data by identifying and rectifying errors, duplications, and inconsistencies. In tandem, data transformation adjusts the data's format and structure, which includes normalization, encoding categorical variables, and generating derived features that better represent the underlying phenomena for analysis. Integral to this preprocessing stage is the management of missing values, which may involve strategies such as deletion, imputation, or interpolation, depending on the nature and extent of the missing data.\\n\\nConcept: Feature Engineering\\nExplanation: New features can be generated or existing ones transformed to extract more information or improve model performance.\\n\\nConcept: Machine Learning\\nExplanation: Harness algorithms to classify data into categories, make predictions through regression, discover hidden patterns using clustering techniques, and even uncover insights from time series data. Explore the fundamentals of model training, evaluation, and practical applications, enabling to extract valuable information and make data-driven decisions across a wide range of analytical tasks.\\n\\nTable 11. Concepts and corresponding explanations concluded from the expert interview.\"}"}
{"id": "d5LURMSfTx", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\n| Concepts                  | Summary Statistics | Feature Engineering | Correlation Analysis | Machine Learning | Distribution Analysis | Outlier Detection | Comprehensive Data Preprocessing |\\n|---------------------------|--------------------|---------------------|----------------------|------------------|-----------------------|-------------------|-----------------------------|\\n|                           | 41                 | 3                   | 10                   | 0                | 21                    | 5                 | 8                          |\\n|                           | 17                 | 14                  | 32                   | 0                | 23                    | 20                | 9                          |\\n|                           | 32                 | 33                  | 30                   | 19               | 20                    | 10                | 28                         |\\n|                           | 90                 | 50                  | 72                   | 19               | 64                    | 35                | 45                         |\\n\\nTable 4. Distribution of question difficulties across different concepts and number of concepts.\\n\\nWe utilize GPT-4 for the quantitative assessment of question difficulty in DAEval. The questions are classified into three levels: easy, medium, and hard. Table 4 shows the distribution of difficulty levels across various concepts and the number of concepts involved in each question. The detailed method of quantitative assessment is described in Appendix K. These results indicate a wide spectrum of complexities within DAEval, ensuring a comprehensive evaluation.\\n\\nSummary Statistics\\n\\n- Feature Engineering: 24.0%\\n- Correlation Analysis: 13.3%\\n- Machine Learning: 19.2%\\n- Distribution Analysis: 5.1%\\n- Outlier Detection: 17.1%\\n- Comprehensive Data Preprocessing: 9.3%\\n\\nFigure 4. Distribution of concepts the questions involve.\\n\\n2.5. Instruction-tuning Dataset\\n\\nIn this section, we introduce DAInstruct, an instruction-tuning (Wei et al., 2022a; Zhang et al., 2024b) dataset for data analysis, on which we train DAAgent, a specialized agent for data analysis. The collection of DAInstruct involves three steps: 1) Creating a diverse set of data analysis questions for CSV files. 2) Collecting response trajectories to these questions through our agent framework. 3) Filtering low-quality samples with rules and GPT-4. Statistics of DAInstruct are in Appendix L. Additionally, a case study on DAInstruct is provided in Appendix O. The following sections provide details on these steps.\\n\\nQuestion Generation.\\n\\nWe employ GPT-4 to generate a set of keywords relevant to data analysis. These keywords then undergo a manual screening process to ensure relevance and accuracy. GPT-4 is then prompted with file descriptions similar to those in DAEval, along with the keywords, to generate questions for each CSV file. The keywords and prompt can be found in Appendix M.\\n\\nResponse Collection.\\n\\nIn this step, we leverage our agent framework to generate responses in a ReAct (Yao et al., 2023) way. This involves iterative problem-solving steps, where GPT-4 engages with code execution environment in a conversational format. The process includes reasoning, code writing, execution, and iterative refinement based on the results obtained. Details can be found in Appendix N.\\n\\nFiltering.\\n\\nThis step involves a filtering with rules and GPT-4. Specific rules are employed to identify and eliminate data with hallucinations or incomplete solutions. Then, the data undergoes further filtering with the aid of GPT-4. The criteria include five aspects: Python code relevance, interpretation of system notifications, conciseness, understanding of the Python sandbox environment, and solution provision. All prompts can be found in Appendix M.\\n\\n3. Experiments\\n\\n3.1. Setup\\n\\n3.1.1. Models\\n\\nWe categorize the models benchmarked into 4 groups: proprietary models, open-source general LLMs, open-source code LLMs and agent frameworks.\\n\\nProprietary Models.\\n\\nThis group consists of LLMs available as commercial services with providing API access. We benchmark OpenAI GPT-4 (OpenAI, 2023b), GPT-3.5 (OpenAI, 2023a), Claude-2.1 (Anthropic, 2023), Abab5.5 (MiniMax, 2023) and Gemini-Pro (Team et al., 2023).\\n\\nOpen-source General LLMs.\\n\\nThis category includes open-source general LLMs.\"}"}
{"id": "d5LURMSfTx", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nQuestion: Generate a new feature called \u201cFamilySize\u201d by summing the \u201cSibSp\u201d and \u201cParch\u201d columns. Then, calculate the Pearson correlation coefficient \\\\( r \\\\) between the \u201cFamilySize\u201d and \u201cFare\u201d columns.\\n\\nConstraints:\\nCreate a new column \u2018FamilySize\u2019 that is the sum of \u2018SibSp\u2019 and \u2018Parch\u2019 for each row. Calculate the Pearson correlation coefficient between \u2018FamilySize\u2019 and \u2018Fare\u2019. Do not perform any further data cleaning or preprocessing steps before calculating the correlation.\\n\\nTo solve this problem, I need to load the data from the CSV file into a pandas DataFrame. Then, I can create the new feature \u201cFamilySize\u201d by adding the \u201cSibSp\u201d and \u201cParch\u201d columns. Finally, I can use the pandas method \\\\( \\\\text{corr()} \\\\) to calculate the Pearson correlation coefficient between the \u201cFamilySize\u201d and \u201cFare\u201d columns.\\n\\n```\\nimport pandas as pd\\n# Load the data\\ndf = pd.read_csv('/mnt/test_ave.csv')\\n# Create the new feature\\ndf['FamilySize'] = df['SibSp'] + df['Parch']\\n# Calculate the correlation\\ncorrelation = df[['FamilySize', 'Fare']].corr().iloc[0, 1]\\nprint(correlation)\\n```\\n\\n```\\n0.20510382556972825\\n```\\n\\nThe Pearson correlation coefficient between the \u201cFamilySize\u201d and \u201cFare\u201d columns is approximately 0.205. This indicates a weak positive correlation between the size of a passenger\u2019s family and the fare they paid.\\n\\nFinal Answer: The Pearson correlation coefficient between the \u201cFamilySize\u201d and \u201cFare\u201d columns is approximately 0.205.\"}"}
{"id": "d5LURMSfTx", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nFigure 6. The performance of models benchmarked in InfiAgent-DABench. Models are categorized into 4 groups: Proprietary Models, Open-source General LLMs, Open-source Code LLMs, Agent Frameworks. LLMs behind agent frameworks are shown in parentheses.\\n\\nWe also report our DAAgents. Models of known size are plotted as dots while models of unknown size as horizontal lines.\\n\\nEarly open-source models show an obvious gap behind proprietary models, they catch up quickly. Qwen-72B-Chat achieves 59.92%, the best performance among open-source models, which is only 0.78% lower than GPT-3.5 and even better than Gemini-Pro by 3.50%.\\n\\nDAAgent achieves a better performance than GPT-3.5. DAAgent-34B, our biggest model instruction-tuned by DAInstruct from CodeLlama, achieves 3.89% better performance than GPT-3.5, although it has much less parameters than that proprietary model. Otherwise, Table 5 compares DAAgent with Code Llama of corresponding sizes, showing a significant performance increase due to instruction-tuning on DAInstruct. Both indicate that DAInstruct is effective for enhancing a model's capability in data analysis.\\n\\n3.4. Self-Debug\\n\\nIn this section, we focus on self-debug (Chen et al., 2023b; Shinn et al., 2023; Hu et al., 2024), a specific ability of LLM-based agents in data analysis setting, which means agents can debug automatically based on feedback, e.g., error messages from the code interpreter. Figure 7 illustrates an agent does a successful self-debug through analyzing the error message. As shown in Table 6, we present the number of cases that passed or failed with or without self-debug on DABench. We recognize a successful self-debug by simultaneously detecting specific strings (e.g., \u201cTraceback\u201d) in the error messages during the interaction between agents and the sandbox, and the finally passed solution of the problem.\\n\\nWe define Self-Debug Success Rate (SDSR), as the ratio of successful self-debug cases to the total number of cases (including both passed and failed) with self-debug, to reflect...\"}"}
{"id": "d5LURMSfTx", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfinAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\n| Model                  | w/ debug #P | w/o debug #P | w/ debug #F | w/o debug #F | SDSR   |\\n|------------------------|-------------|--------------|-------------|--------------|--------|\\n| gpt-4-0613 (OpenAI, 2023b) | 42          | 161          | 17          | 37           | 0.71   |\\n| gpt-3.5-turbo-0613 (OpenAI, 2023a) | 36          | 120          | 41          | 60           | 0.47   |\\n| qwen-72b-chat (Bai et al., 2023) | 27          | 127          | 69          | 34           | 0.28   |\\n| daagent-34b (ours)     | 40          | 126          | 40          | 51           | 0.50   |\\n\\nTable 6. Performance comparison of different models on self-debug capability. The table shows the number of cases passed or failed with or without self-debug on the dev set of DABench. \\\"P\\\" and \\\"F\\\" represent if the agents pass or fail on the problem. \\\"w/ debug\\\" and \\\"w/o debug\\\" indicate if agents receive feedbacks from the code interpreter. SDSR stands for Self-Debug Success Rate, defined as the ratio of successful self-debug cases to the total number of self-debug attempts.\\n\\nWe find that GPT-4 has a much stronger self-debug ability compared with other models. The SDSR of DAAgent-34B is slightly higher than GPT-3.5, while Qwen-72B shows weakness in self-debug. We believe improving self-debug ability is a promising way to further develop LLM-based agents in data analysis domain for two reasons: 1) Allowing LLMs refine themselves based on feedback has been broadly studied recently, showing positive results in many different domains (Madaan et al., 2023; Shinn et al., 2023; Wang et al., 2023a). 2) Feedback from code interpreter is usually inexpensive and reliable. We leave the improvement of self-debug ability as an important direction for future research.\\n\\nFigure 7. Illustration of self-debug. The agent receives error messages from the code interpreter, analyzes the error and modifies the code accordingly. For brevity, we omit constraints, part of the textual output, error messages and code.\\n\\n4. Related works\\nThe rapid advancement of LLM-based agents and multi-agent systems (Liu et al., 2023b; Zhang et al., 2024c; Chen et al., 2023a; Wu et al., 2023b) necessitates precise and all-encompassing evaluation methods, while remains a challenge at present. Recent studies have introduced several new settings to evaluate from different angles. WebShop (Yao et al., 2022a) and WebArena (Zhou et al., 2023) benchmark LLM-based agents in web environments. Some other benchmarks evaluate LLM-based agents with tool using, like ToolBench (Qin et al., 2023b) and Gentopia (Xu et al., 2023a). In our work, we propose the InfinAgent-DABench that evaluates agents on data analysis tasks. Such tasks have a higher requirement for LLMs to produce structured and precise intermediate executable steps. Another series of works are Code LLMs and corresponding evaluations. Code LLMs, which specialize in understanding and generating programming code, have developed fast in the past few years (Zan et al., 2023; Zhang et al., 2023b; Chen et al., 2021; Rozi`ere et al., 2023; Luo et al., 2023). Various benchmarks on code and tabular processing have also been proposed (Lu et al., 2021; Lai et al., 2023; Lu et al., 2023; Zhuang et al., 2023; Yang et al., 2023b). However, these benchmarks still miss a comprehensive evaluation to check agents end-to-end task solving capability. More details about related works can be found in Appendix B.\\n\\n5. Conclusion\\nWe introduce InfinAgent-DABench, the first benchmark specifically designed for evaluating LLM-based agents on data analysis tasks. Our extensive benchmarking of 34 cutting-edge LLMs reveals that contemporary models still face challenges in effectively managing data analysis tasks. Additionally, we develop DAAgent, a specialized agent for data analysis, trained on DAInstruct, an instruction-tuning dataset generated by GPT-4. Our contributions not only offer a valuable benchmark for assessing LLM-based agents in data analysis but also provide insights into the current capabilities and limitations of these models in this domain.\"}"}
{"id": "d5LURMSfTx", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\n| Country | Happiness Rank | GDP per Capita |\\n|---------|----------------|----------------|\\n| Switzerland | 1 | 1.39651 |\\n| Iceland | 2 | 1.30232 |\\n| Denmark | 3 | 1.32548 |\\n| Norway | 4 | 1.45900 |\\n\\nIs there a linear relationship between the GDP per capita and the life expectancy score in the Happiness_rank.csv? Conduct linear regression and use the resulting coefficient of determination (R-squared) to evaluate the model's goodness of fit.\\n\\nTo answer this question, I need to load the dataset, conduct a linear regression analysis between GDP per capita and life expectancy score...\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression\\n\\n# Load the dataset\\ndf = pd.read_csv('/mnt/Happiness_rank.csv')\\n\\n# Extract the columns for GDP per capita and life expectancy score\\ngdp_per_capita = df['Economy (GDP per Capita)'].values.reshape(-1, 1)\\nlife_expectancy = df['Health (Life Expectancy)'].values\\n\\n# Conduct linear regression\\nmodel = LinearRegression()\\nmodel.fit(gdp_per_capita, life_expectancy)\\npredicted_life_expectancy = model.predict(gdp_per_capita)\\n\\n# Calculate R-squared\\nr_squared = r2_score(life_expectancy, predicted_life_expectancy)\\nprint(r_squared)\\n```\\n\\n**STDOUT:**\\n```\\n0.6666363295228102\\n```\\n\\nThe R-squared value is approximately **0.67**, which indicates a poor fit for the linear regression model.\\n\\nFor the given data analysis task, the R-squared value is 0.67. This indicates that the linear regression model has a poor fit for the relationship between GDP per capita and life expectancy. The model explains approximately 67% of the variance in life expectancy scores.\\n\\n---\\n\\nFigure 1. An illustration of evaluation on InfiAgent-DABench. An LLM-based agent is prompted with a data analysis question and corresponding CSV file. It plans, writes code, calls a Python sandbox and concludes to solve the problem in a ReAct way. The final answer is reformatted into specific format and matched with the closed-form label.\"}"}
{"id": "d5LURMSfTx", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we present InfiAgent-DABench, a benchmark created to assess the performance of LLM-based agents on data analysis tasks. Specifically, we design two main components of the benchmark: DAEval, the evaluation dataset which contains closed-form questions on data analysis, and the agent framework, which enables LLMs to solve data analysis problems in an agent setting. To ensure the quality of DAEval, we conduct a comprehensive human assessment and filter all unqualified data samples.\\n\\n2.1. Dataset Construction\\n\\nSimilar to other recent grounding datasets, such as VQA (Goyal et al., 2017) and DocQA (Mathew et al., 2021), DAEval is composed of realistic CSV files and the corresponding questions. The questions are generated according to several key concepts in the field of data analysis, which were identified through expert interviews. All questions are closed-form with corresponding answers for a straightforward assessment. Figure 2 illustrates the whole process for constructing the dataset. We introduce the main steps as follows:\\n\\nFiles Collection. We gather real-world CSV files from GitHub to form our dataset. We further assess the suitability of the CSV files for question generation based on the following criteria: 1) Meaningfulness: The presence of meaningful scenarios, 2) Language uniqueness: Predominantly English used in headers and content, 3) Scale sufficiency: The column count should be greater than 5 with a minimum row count of 20.\\n\\nDescription Generation. As directly putting all the content of the file into the LLMs to generate questions is usually infeasible, we utilize GPT-3.5 to summarize the following information for each CSV file: 1) Description of column names and contents, 2) Data types, 3) Identification of missing values, as a mediate step before question generation. More detailed information is in Appendix E.1.\\n\\nConcepts Determination. To ensure our dataset aligns with real-world demands, we conduct expert interviews to identify key concepts in data analysis. All the experts are professional data analysts. We list these concepts and corresponding explanations in Appendix F. We remove data visualization from original concepts since we assume that a question requiring visualization can hardly be closed-form. We have a more detailed discussion on it in Appendix A. These concepts are used to guide the generation of questions in subsequent stages.\\n\\nOpen-ended Question Generation. In this step, we leverage GPT-4 to generate open-ended questions based on both file descriptions and the pre-defined concepts. Each question involves one or multiple concepts. We prompt GPT-4 to generate questions with an increasing difficulty and more concepts for each file description. All questions for one file are generated in one dialogue to make sure no repeated questions. Prompts can be found in Appendix E.2.\\n\\nConstraints and Format Requirements Generation. Considering closed-form questions can be easily evaluated through regular expression and exact match without any external models or human efforts, we introduce a format-prompting technique that prompts GPT-4 to generate detailed constraints and format requirements for open-ended questions to make them closed-form. We have noticed that most powerful LLMs like GPT-4 have potential for automatic evaluation for open-ended questions (Fu et al., 2023; Chan et al., 2023), while many works point out issues of this approach (Wang et al., 2023b;d). We also conduct a pilot experiment on GPT-4 auto-evaluating for above open-ended questions. The results show that GPT-4 could only achieve 67% consistency with human experts, indicating that GPT-4 is still unsatisfactory as an evaluator on data analysis tasks. Details about pilot experiment is in Appendix H. However, closed-form questions allow us to bypass these issues. Constraints mainly contain detailed restrictions on methods, workflow, or statistical parameters used to answer the question. Format requirements are series of \\\"@answer name[answer]\\\" where \\\"answer name\\\" and \\\"answer\\\" are automatically defined according to the specific question, also natural description of the range of value to each \\\"answer\\\". We also call each \\\"@answer name[answer]\\\" a subquestion subsequently. We conduct human assessment and filtering to ensure adding constraints and format requirements on open-ended questions can make answers unique and easy to parse for evaluation. See Section 2.3 for details. Full prompts can be found in Appendix E.3.\\n\\nResponse Gathering. We leverage OpenAI ADA to generate answers for closed-form questions. Each question is\"}"}
{"id": "d5LURMSfTx", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nCSV Files\\n\\n|        |        |        |        |\\n|--------|--------|--------|--------|\\n| Income | 14,891 | 106,025| 104,593|\\n|        | 148,924|        |        |\\n| Limit  | 3,606  | 6,645  | 7,075  |\\n|        | 9,504  |        |        |\\n| Rating | 283    | 483    | 514    |\\n|        | 681    |        |        |\\n| Cards  | 2      | 3      | 4      |\\n|        | 3      |        |        |\\n\\nCredit.csv\\n\\nDescription\\n\\nIncome: The income of the individual. No missing values.\\nData type: float 64\\n\\nLimit: The credit limit of the individual. No missing values.\\nData type: int 64\\n\\nConcepts\\n\\nConcept: Outlier Detection\\nExplanation: Identify and deal with outliers, as they can potentially disrupt data analysis.\\n\\nConcept: Comprehensive Data Pre-processing\\nExplanation: Comprehensive data preprocessing is encompassing data cleaning, transformation...\\n\\nQuestion generation with Description & Concepts\\n\\nQuestions\\n\\nQuestion: Identify any outliers in the \\\"Limit\\\" column of the Credit.csv file using the Z-score method.\\n\\nConcepts: Outlier Detection, Comprehensive Data Pre-processing\\n\\nConstraints & Format\\n\\nConstraints: Define an outlier to be any data point that falls more than 3 standard deviations from the mean. Use the formula $Z = (X - \\\\mu) / \\\\sigma$... where \\\"outliers count\\\" is an integer indicating the total number of outliers identified.\\n\\nFormat: @outliers[outliers count], where \\\"outliers count\\\" is an integer indicating the total number of outliers identified.\\n\\nLabels\\n\\n@outliers[1] (from GPT 4 Advanced Data Analysis)\\n\\nFigure 2. The workflow of DAEval construction.\\n\\nData analysis questions are generated with GPT-4 based on the description of CSV files and pre-defined key concepts. Then, we generate constraints and format requirements to make questions closed-form for precise evaluation. The labels are obtained from OpenAI ADA. All these are undergone strict human assessment and filtering. The answer is only kept if ADA consistently generates the same answer in all trials.\\n\\nFigure 2 showcases a question generated from the file test_ave.csv. We provide an extended case study on generated questions in Appendix I.\\n\\n2.2. Agent Framework\\n\\nWe build an agent framework for LLM-based agents to reason in a ReAct (Yao et al., 2023) way, interact with files and invoke tools such as a Python code sandbox to facilitate evaluation. Agents here can be a model deployed online, such as GPT-4, or local models based on vLLM (Kwon et al., 2023). Simultaneously, we develop a Docker-based local Python code sandbox that allows the isolated execution of code, avoiding safety issues.\\n\\n2.3. Human Assessment\\n\\nTo ensure a high-quality dataset, we conduct an in-depth human assessment. We invite experts to evaluate the dataset quality, and also conduct a comparison between human-made and GPT-4 generated data analysis questions.\\n\\nMetrics.\\n\\nWe evaluate the quality of files, questions and labels. For each part, we define one or more metrics which are crucial for a data analysis dataset. Here's a brief introduction:\\n\\n\u2022 Suitableness: This measures whether a CSV file is suitable for data analysis.\\n\u2022 Reasonableness: This measures whether the question, constraints and format requirements express in a natural and reasonable way, with no conflict with each other.\\n\u2022 Value: This measures the value of generated questions. We want the questions to be valuable in practice. For instance, calculating the mean of salaries could be valuable as a data analysis question, while calculating the mean of ID numbers is usually valueless.\\n\u2022 Restrictiveness: This measures whether the constraints are strict enough to ensure the uniqueness of answers.\\n\u2022 Alignment: This measures the alignment between questions and data file. Questions should only require data existed in the file, also the type and range of the data are aligned with questions.\\n\u2022 Correctness: This measures whether the labels for questions are correct.\\n\\n2.3.1. DATASET QUALITY\\n\\nWe invite human experts to assess the quality of generated dataset and remove samples unqualified in any metric. We refer readers to Appendix J.1 for detailed settings for human assessment on dataset quality.\\n\\nResults.\\n\\nTable 1 shows the percentage of samples passed in specific metrics and overall pass rate. 85% samples are...\"}"}
{"id": "d5LURMSfTx", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1. Results of human assessment on the quality of DAEval. We conduct quality assessment over files, questions and labels, where each part has one or more metrics. We report the percentage of samples considered qualified on each metric. We keep questions qualified in all metrics. Overall represents the percentage of samples qualified in total.\\n\\n| Source | Reasonableness | Value | Restrictiveness | Alignment | Difficulty (%) |\\n|--------|---------------|-------|----------------|----------|---------------|\\n| Human | 4.66          | 4.73  | 4.14           | 4.71     | 39.34         |\\n| GPT-4  | 4.70          | 4.85  | 4.74           | 4.92     | 60.66         |\\n\\nTable 2. Results of human assessment to compare questions generated from human and GPT-4. Reasonableness, Value, Restrictiveness and Alignment are graded from 1-5 (1 is worst and 5 is best). Difficulty is calculated by win rate between human and GPT-4.\\n\\n2.3.2. Human vs GPT-4\\nTo ensure GPT-4 generated questions have quality comparable to human-made ones, we invite experts to write data analysis questions. Then other experts are asked to grade from 1 to 5 (1 is worst and 5 is best) on each of the mentioned metrics for the questions. Additionally, we ask experts to decide which question is more difficult in a question pair randomly sampled from human-made and GPT-4 generated questions respectively to compare the difficulty of questions from both sources. We calculate win rate to reflect the relative difficulty of questions. Detailed settings for this part of human assessment are in Appendix 2.\\n\\nResults. Table 2 shows results compared between human-made and GPT-4 generated questions. We found that GPT-4 generated questions excel in Restrictiveness, Alignment and Difficulty, with slightly better performance in Reasonableness and Value, indicating that DAEval is comparable to a human-made dataset.\\n\\n2.4. Benchmark Statistics\\nIn this section, we provide statistics on DAEval. We split the dataset into a validation set and a test set. The validation set is open to the public, including 257 questions with 52 csv files and the rest is designated for the test set, which is kept closed to avoid data leakage. All the subsequent information is based on the validation set.\\n\\nBasic Statistics. Table 3 lists basic statistical information on files and questions, including the number of files, questions, subquestions, etc.\\n\\n| Dataset Component | Count |\\n|------------------|-------|\\n| # of CSV Files   | 52    |\\n| # of Avg. Rows per File | 9639.7 |\\n| # of Avg. Columns per File | 10.6 |\\n| # of Questions   | 257   |\\n| # of Subquestions | 461   |\\n| # of Max Subquestions per Question | 8 |\\n\\nTable 3. Basic statistics on the validation set of DAEval.\\n\\nDomains of Files. Figure 3 shows the distribution of the different domains the files belong to. We cluster the files into 9 domains with the help of GPT-3.5. The result shows that our dataset covers a large range of domains. Details on the domains and their corresponding descriptions are listed in Appendix G.\\n\\nCulture 3.6%\\nTransportation 12.7%\\nEnergy 18.2%\\nDemographics 20.0%\\nFinance 25.5%\\nMarketing 3.6%\\nScientific 7.3%\\nHealth 5.5%\\nOther 3.6%\\n\\nFigure 3. Distribution of domains the files in. For brevity, we use the first word of each category as the label. The completed domain names are listed in Appendix G.\\n\\nConcepts of Questions. Figure 4 shows the distribution of different concepts the questions involve. Table 4 shows the distribution of questions based on the number of concepts involved. It reveals that a larger proportion of the questions involve 1 or 2 concepts. This is reasonable, as it is uncommon for a scenario where a question involves many concepts at once.\"}"}
{"id": "d5LURMSfTx", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nCategory Description\\n\\n- **Finance and Economics**: Covers financial market trends, economic indicators, real estate prices, and investment analysis, essential for understanding economic conditions and market dynamics.\\n- **Health and Medical**: Includes health insurance, disease statistics, hospital performance, and pharmaceutical research, key to evaluating public health policies and medical services effectiveness.\\n- **Demographics and Social Science**: Comprises education levels, employment status, demographics, and social welfare, fundamental for analyzing social structures and social science issues.\\n- **Marketing and Consumer Behavior**: Focuses on market segmentation, consumer preferences, and purchasing behavior, providing support for market strategy formulation and consumer behavior research.\\n- **Energy and Environmental Monitoring**: Contains energy consumption, environmental monitoring, and meteorological information, crucial for resource management, environmental policy, and climate change research.\\n- **Transportation, Logistics, and Tourism**: Involves traffic management, logistics efficiency, and tourism statistics, key to improving the efficiency of transportation and logistics as well as the management of the tourism industry.\\n- **Culture, Entertainment, and Media**: Includes music, gaming, media, and cultural activities, used to analyze trends in the entertainment and cultural industries.\\n- **Scientific Research and Technology**: Covers a broad range of scientific research and technological development, from genetics to engineering, suitable for scientific discovery and technological advancement.\\n- **Other Categories**: Includes data analysis, machine learning, statistical models, specialized studies, and datasets that do not fall under any of the above categories, applicable to a variety of interdisciplinary data analysis and research work.\\n\\nTable 12. Domains and corresponding descriptions.\\n\\n| Response Model | Consistency (%) |\\n|---------------|-----------------|\\n| GPT-4         | 66.4            |\\n| GPT-3.5       | 68.9            |\\n| DAAgent-34B   | 65.5            |\\n| Avg.          | 66.9            |\\n\\nTable 13. Consistency rate between human experts and GPT-4 on the evaluation of open-ended questions.\\n\\nWe gather responses from GPT-4, GPT-3.5 and DAAgent-34B on solving open-ended data analysis problems. We ask both human experts and GPT-4 to rate responses based on the same criteria and calculate the percentage of rating both sides reach consensus on.\"}"}
{"id": "d5LURMSfTx", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nGenerated questions for test\\n\\nave.csv\\n\\nQuestion: Calculate the mean fare paid by the passengers.\\nConcepts: Summary Statistics\\nConstraints: Calculate the mean fare using Python's built-in statistics module or appropriate statistical method in pandas. Rounding off the answer to two decimal places.\\nFormat: @mean_fare[mean_fare_value] where \\\"mean_fare_value\\\" is a floating-point number rounded to two decimal places.\\nLabels: @mean_fare[34.65]\\n\\nQuestion: Apply the linear regression algorithm from the sklearn library to predict whether a passenger survived or not based on the features 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', and 'Embarked'. Encode 'Sex' and 'Embarked' to numerical values before applying the model. Split the dataset into a training set (80%) and a testing set (20%), train the model on the training set, and evaluate its performance on the testing set using the accuracy score. Ensure that the train_test_split function's random_state parameter is set to 42 for consistency.\\nConcepts: Machine Learning\\nConstraints: Use one-hot encoding for the 'Sex' and 'Embarked' features. Use the \\\"linear regression\\\" model provided by the sklearn library in Python.\\nFormat: @prediction_accuracy[accuracy], where \\\"accuracy\\\" is a float number rounded to 2 decimal places and has a range of 0.0 to 1.0.\\nLabels: @prediction_accuracy[0.78]\\n\\nQuestion: Generate a new feature called \\\"FamilySize\\\" by summing the \\\"SibSp\\\" and \\\"Parch\\\" columns. Then, calculate the Pearson correlation coefficient (r) between the \\\"FamilySize\\\" and \\\"Fare\\\" columns.\\nConcepts: Feature Engineering, Correlation Analysis\\nConstraints: Create a new column 'FamilySize' that is the sum of 'SibSp' and 'Parch' for each row. Calculate the Pearson correlation coefficient between 'FamilySize' and 'Fare' Do not perform any further data cleaning or preprocessing steps before calculating the correlation.\\nFormat: @correlation_coefficient[r_value] where \\\"r_value\\\" is the Pearson correlation coefficient between 'FamilySize' and 'Fare', a number between -1 and 1, rounded to two decimal places.\\nLabels: @correlation_coefficient[0.21]\\n\\nQuestion: Create a new column called \\\"AgeGroup\\\" that categorizes the passengers into four age groups: 'Child' (0-12 years old), 'Teenager' (13-19 years old), 'Adult' (20-59 years old), and 'Elderly' (60 years old and above). Then, calculate the mean fare for each age group.\\nConcepts: Feature Engineering, Summary Statistics\\nConstraints: Make sure to round the mean fare of each group to 2 decimal places.\\nFormat: @mean_fare_child[mean_fare], @mean_fare_teenager[mean_fare], @mean_fare_adult[mean_fare], @mean_fare_elderly[mean_fare], where \\\"mean_fare\\\" is a float number rounded to 2 decimal places.\\nLabels: @mean_fare_elderly[43.47], @mean_fare_teenager[31.98], @mean_fare_child[31.09], @mean_fare_adult[35.17]\\n\\nQuestion: Perform a distribution analysis on the 'Fare' column for each passenger class ('Pclass') separately. Calculate the mean, median, and standard deviation of the fare for each class. Interpret the results in terms of the different passenger classes.\\nConcepts: Distribution Analysis, Summary Statistics\\nConstraints: Keep all numerical values rounded to 2 decimal points. The population standard deviation should be calculated.\\nFormat: @mean_fare_class1[mean_fare], @median_fare_class1[median_fare], @std_dev_fare_class1[std_dev], @mean_fare_class2[mean_fare], @median_fare_class2[median_fare], @std_dev_fare_class2[std_dev], @mean_fare_class3[mean_fare], @median_fare_class3[median_fare], @std_dev_fare_class3[std_dev], where \\\"mean_fare\\\", \\\"median_fare\\\", and \\\"std_dev\\\" are statistical measures in float format rounded to 2 decimal places.\\nLabels: @median_fare_class1[69.30], @median_fare_class2[15.05], @std_dev_fare_class1[80.86], @mean_fare_class3[13.23], @std_dev_fare_class2[13.19], @mean_fare_class2[21.47], @std_dev_fare_class3[10.04], @mean_fare_class1[87.96]\\n\\nTable 14. Extended case study on generated questions.\\n\\nAll \\\"@answer_name[answer]\\\" in Format and Labels are marked in red.\"}"}
{"id": "d5LURMSfTx", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nCategory Question and Answer\\n\\n1.1 (Suitableness): Does the csv file represent a meaningful scenario for data analysis? (Yes/No, reasons)\\n\\n1.2 (Suitableness): Is the file's Category correct? (Yes/No, correct category)\\n\\n1.3 (Suitableness): Does the file involve sensitive attributes or offensive content? (No/Yes, keywords)\\n\\nQuestion\\n\\n2.1 (Reasonableness): Can the expression be naturally and reasonably used for data analysis? (Yes/No, reasons)\\n\\n2.2 (Reasonableness): Are there Constraints limitations on the question? (Yes/No, reasons)\\n\\n2.3 (Reasonableness): Do the Constraints match the question? (Yes/No, reasons)\\n\\n2.4 (Reasonableness): Does the Format specify value type and range for all \"@answer name[answer]\"? (Yes/No, non-compliant items)\\n\\n2.5 (Reasonableness): Does the Format match the question/Constraints? (Yes/No, reasons)\\n\\n2.6: Do the question/Constraints involve sensitive content? (No/Yes, keywords)\\n\\n2.7 (Value): Do the question/Constraints have value for data analysis? (Yes/No, reasons)\\n\\n2.8: Do the question/Constraints/Format match the concepts? (No/Yes, necessary concepts)\\n\\n2.9 (Alignment): Does the table have required data columns for the question/Constraints? (Yes/No, missing columns)\\n\\n2.10 (Alignment): Do data types and ranges in columns match the question/Constraints/Format requirements? (Yes/No, non-compliant columns)\\n\\nLabel\\n\\n3.1 (Correctness): Is the Label correct? (Yes/No, incorrect \"@answer name[name]\"))\\n\\n3.2 (Correctness): Does the Label comply with the Format requirements? (Yes/No, non-compliant \"@answer name[name]\"))\\n\\n3.3 (Restrictiveness): Are the question/Constraints/Format sufficient for unique correct answers in the Label? (Yes/No, reasons)\\n\\nTable 15. Questionnaire to experts for assessing data quality on DAEval. Metrics (Suitableness, Reasonableness, Value, Alignment, Correctness, Restrictiveness) are marked in red, and dataset components (Question, Format, Constraints, Concepts, Label) are in italics.\\n\\nHuman experts should give answers according to requirements in parentheses.\\n\\nQuestion and Answer\\n\\n1 (Reasonableness): Is the expression natural and reasonable, and is it a question around data analysis? (5 points: Very natural and reasonable, 1 point: Very unnatural and unreasonable)\\n\\n2 (Value): Is it a valuable question? (5 points: Very valuable, 1 point: Not valuable at all)\\n\\n3 (Restrictiveness): Can it strictly limit the answer to the question as unique? (5 points: Completely strict, 1 point: Not strict at all)\\n\\n4 (Alignment): Can it align with the data? Can the data needed to solve the question be found in the table, and does it meet the requirements? (5 points: Completely aligned, 1 point: Not aligned at all)\\n\\n5 (Difficulty): Among two questions (A and B), which one is more difficult? (A/B/Close)\\n\\nTable 16. Questionnaire to experts for comparing human-made and GPT-4 generated questions. Metrics (Reasonableness, Value, Restrictiveness, Alignment, Difficulty) are marked in red. Assessors should rate each question according to requirements in parentheses.\"}"}
{"id": "d5LURMSfTx", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Bad Cases\\n\\nFile: 2019-08 edges.csv\\n\\nQuestion: Build a machine learning model to predict the \u201cType\u201d based on the other columns in the dataset.\\n\\nConstraints: Split the dataset into 70% training and 30% testing. Use Random Forest Classifier for building the model. Use \u201cSource\u201d, \u201cTarget\u201d, \u201cWeight\u201d, \u201clng org\u201d, \u201clat org\u201d, \u201clng dest\u201d, \u201clat dest\u201d, and the newly created \u201cDistance\u201d as features for training the model. Evaluate the model\u2019s performance using accuracy score, precision, recall, and F1 score.\\n\\nFormat: @accuracy_score[accuracy], @precision[precision], @recall[recall], @f1_score[f1] where \u201caccuracy\u201d, \u201cprecision\u201d, \u201crecall\u201d, and \u201cf1\u201d are the respective evaluation metrics for the model rounded to four decimal places.\\n\\nLabel: @precision[1.0000], @recall[1.0000], @accuracy_score[1.0000], @f1_score[1.0000]\\n\\nFile: treikone_eod_data.csv\\n\\nQuestion: Explore the distribution of the CBOE Volatility Index (.VIX) on the given dates.\\n\\nConstraints: Use the numpy histogram function to explore the distribution. Set the bin separator array to [10, 20, 30, 40, 50, 60, 70]. Only consider non-null values.\\n\\nFormat: @VIX_bin_counts[bin_counts] where \u201cbin_counts\u201d is an array of 6 integers representing the count of .VIX values in each bin.\\n\\nLabel: @VIX_bin_counts[1623, 352, 89, 15, 0, 0]\\n\\nTable 17. Bad cases found from human assessment. The questionable parts of the cases are marked in red.\\n\\n| Category Description | Domain Keywords Data Cleaning & Preprocessing, Data Exploration, Text Data Analysis, Queries, Data Visualization Recommendations, Ethics and Bias, Documentation & Communication, Data Integrity Analysis, Data Pattern Identification |\\n|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"}
{"id": "d5LURMSfTx", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgements\\n\\nThis work was supported by the National Natural Science Foundation of China (62441605, 62376243), and the Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study (SN-ZJU-SIAS-0010). We express sincere gratitude to the anonymous reviewers for their invaluable feedback and constructive suggestions. We appreciate the contribution of Haotian Zhou on helping construct the agent pipeline and environment. We also extend our gratitude to Rufei Liu, Feiyu Zhang and Xinxin Wang's hard work on data annotation, Sibo Xiao on the help of building demo for this work.\\n\\nImpact Statement\\n\\nThis paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.\\n\\nReferences\\n\\n01ai. Yi. https://01.ai/, 2023.\\nAnthropic. Claude-2.1. https://www.anthropic.com/index/claude-2-1, 2023.\\nAustin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.\\nBai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., et al. Qwen technical report. arXiv preprint arXiv:2309.16609, 2023.\\nChan, C.-M., Chen, W., Su, Y., Yu, J., Xue, W., Zhang, S., Fu, J., and Liu, Z. Chateval: Towards better llm-based evaluators through multi-agent debate. arXiv preprint arXiv:2308.07201, 2023.\\nChen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.\\nChen, W., Su, Y., Zuo, J., Yang, C., Yuan, C., Chan, C.-M., Yu, H., Lu, Y., Hung, Y.-H., Qian, C., Qin, Y., Cong, X., Xie, R., Liu, Z., Sun, M., and Zhou, J. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors, 2023a.\\nChen, X., Lin, M., Sch\u00e4rli, N., and Zhou, D. Teaching large language models to self-debug. arXiv preprint arXiv:2304.05128, 2023b.\\nChiang, W.-L., Li, Z., Lin, Z., Sheng, Y., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y., Gonzalez, J. E., Stoica, I., and Xing, E. P. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.\\nCovington, D. Analytics: Data Science, Data Analysis, and Predictive Analytics for Business. CreateSpace Independent Publishing Platform, 2016.\\nDai, Y., Tang, D., Liu, L., Tan, M., Zhou, C., Wang, J., Feng, Z., Zhang, F., Hu, X., and Shi, S. One model, multiple modalities: A sparsely activated approach for text, sound, image, video and code, 2022.\\nDeepSeek. Deepseek coder: Let the code write itself. https://github.com/deepseek-ai/DeepSeek-Coder, 2023.\\nFu, J., Ng, S.-K., Jiang, Z., and Liu, P. Gptscore: Evaluate as you desire. arXiv preprint arXiv:2302.04166, 2023.\\nGoyal, Y., Khot, T., Summers-Stay, D., Batra, D., and Parikh, D. Making the v in vqa matter: Elevating the role of image understanding in visual question answering, 2017.\\nHardy, M. A. and Bryman, A. Handbook of data analysis. 2004.\\nHendrycks, D., Basart, S., Kadavath, S., Mazeika, M., Arora, A., Guo, E., Burns, C., Puranik, S., He, H., Song, D., and Steinhardt, J. Measuring coding challenge competence with apps, 2021.\\nHu, X., Kuang, K., Sun, J., Yang, H., and Wu, F. Leveraging print debugging to improve code generation in large language models, 2024.\\nHuang, J. and Chang, K. C.-C. Towards reasoning in large language models: A survey, 2023.\\nHuang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., Fu, Y., Sun, M., and He, J. C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models, 2023.\\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:22199\u201322213, 2022.\\nKoop, G. Analysis of financial data. John Wiley & Sons Inc., 2022.\\nKwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient memory management for large language model serving.\"}"}
{"id": "d5LURMSfTx", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "d5LURMSfTx", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InfiniAgent-DABench: Evaluating Agents on Data Analysis Tasks\\n\\nKozhevnikov, A., Evtimov, I., Bitton, J., Bhatt, M., Ferret, C. C., Grattafiori, A., Xiong, W., D\u00b4efossez, A., Copet, J., Azhar, F., Touvron, H., Martin, L., Usunier, N., Scialom, T., and Synnaeve, G. Code llama: Open foundation models for code. 2023. URL https://arxiv.org/pdf/2308.12950.pdf\\n\\nSabina, L. and Zalta, E. N. Scientific research and big data. The Stanford Encyclopedia of Philosophy (Summer 2020 Edition), 2020.\\n\\nShen, Y., Song, K., Tan, X., Zhang, W., Ren, K., Yuan, S., Lu, W., Li, D., and Zhuang, Y. Taskbench: Benchmarking large language models for task automation, 2023.\\n\\nShinn, N., Cassano, F., Berman, E., Gopinath, A., Narasimhan, K., and Yao, S. Reflexion: Language agents with verbal reinforcement learning, 2023.\\n\\nSun, H., Zhuang, Y., Kong, L., Dai, B., and Zhang, C. Ada-planner: Adaptive planning from feedback with language models. arXiv preprint arXiv:2305.16653, 2023.\\n\\nTeam, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023.\\n\\nTeam, I. Internlm: A multilingual language model with progressively enhanced capabilities. https://github.com/InternLM/InternLM, 2023a.\\n\\nTeam, X. Xagent: An autonomous agent for complex task solving, 2023b.\\n\\nTeam, X.-L. Xwin-lm, 2023c. URL https://github.com/Xwin-LM/Xwin-LM.\\n\\nTorantulino. Autogpt. https://github.com/Significant-Gravitas/AutoGPT, 2023.\\n\\nWang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. Voyager: An open-ended embodied agent with large language models, 2023a.\\n\\nWang, J., Liang, Y., Meng, F., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. Is chatgpt a good nlg evaluator? A preliminary study. arXiv preprint arXiv:2303.04048, 2023b.\\n\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et al. A survey on large language model based autonomous agents. arXiv preprint arXiv:2308.11432, 2023c.\\n\\nWang, P., Li, L., Chen, L., Cai, Z., Zhu, D., Lin, B., Cao, Y., Liu, Q., Liu, T., and Sui, Z. Large language models are not fair evaluators, 2023d.\\n\\nWei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language models are zero-shot learners, 2022a.\\n\\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022b.\\n\\nWu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., Awadallah, A. H., White, R. W., Burger, D., and Wang, C. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. 2023a.\\n\\nWu, Y., Zhou, S., Liu, Y., Lu, W., Liu, X., Zhang, Y., Sun, C., Wu, F., and Kuang, K. Precedent-enhanced legal judgment prediction with llm and domain-model collaboration, 2023b.\\n\\nXi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., Zhou, E., et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.\\n\\nXie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y., Hua, T. J., Zhao, J., Liu, Q., Liu, C., et al. Openagents: An open platform for language agents in the wild. arXiv preprint arXiv:2310.10634, 2023.\\n\\nXu, B., Liu, X., Shen, H., Han, Z., Li, Y., Yue, M., Peng, Z., Liu, Y., Yao, Z., and Xu, D. Gentopia: A collaborative platform for tool-augmented llms, 2023a.\\n\\nXu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y., and Xu, D. Rewoo: Decoupling reasoning from observations for efficient augmented language models. arXiv preprint arXiv:2305.18323, 2023b.\\n\\nYang, A., Xiao, B., Wang, B., Zhang, B., Bian, C., Yin, C., Lv, C., Pan, D., Wang, D., Yan, D., Yang, F., Deng, F., Wang, F., Liu, F., Ai, G., Dong, G., Zhao, H., Xu, H., Sun, H., Zhang, H., Liu, H., Ji, J., Xie, J., Dai, J., Fang, K., Su, L., Song, L., Liu, L., Ru, L., Ma, L., Wang, M., Liu, M., Lin, M., Nie, N., Guo, P., Sun, R., Zhang, T., Li, T., Li, T., Cheng, W., Chen, W., Zeng, X., Wang, X., Chen, X., Men, X., Yu, X., Pan, X., Shen, Y., Wang, Y., Li, Y., Jiang, Y., Gao, Y., Zhang, Y., Zhou, Z., and Wu, Z. Baichuan 2: Open large-scale language models, 2023a.\\n\\nYang, J., Prabhakar, A., Narasimhan, K., and Yao, S. Intercode: Standardizing and benchmarking interactive coding with execution feedback, 2023b.\\n\\nYang, K., Liu, J., Wu, J., Yang, C., Fung, Y. R., Li, S., Huang, Z., Cao, X., Wang, X., Wang, Y., et al. If llm is the wizard, then code is the wand: A survey on how code\"}"}
{"id": "d5LURMSfTx", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A. Limitations and Future work\\n\\nA.1. Multimodal Tasks in Data Analysis\\n\\nOne limitation of our benchmark is that it only involves single-modal (language) tasks in data analysis, and does not include multimodal tasks, such as data visualization. However, designing closed-form questions for visualization is greatly challenging, as the outcomes are often pictorial rather than textual. To evaluate, two potential approaches emerge:\\n\\nEvaluating code correctness. This method allows for the use of text-only LLMs in evaluation. While it benefits from leveraging existing LLMs, this approach might lead to inaccuracies. The primary goal in data analysis tasks is to generate accurate visual representations, not just the underlying code. Only assessing from code could be challenging for a precise evaluation in some situations.\\n\\nEvaluating with multimodal models. Multimodal large models (Dai et al., 2022; OpenAI, 2023b; Team et al., 2023) have developed rapidly in recent times, making it possible for them to become automatic evaluators. Bai et al. (2023) leverages vision-language models like GPT-4V (OpenAI, 2023b) to evaluate visualization problems. This approach directly assesses the accuracy of the visual outputs. While this method is advantageous in evaluating the end product, current multimodal models are suffering from suboptimal performance and costly, leading to unsatisfactory assessment of data visualization.\\n\\nNeither of above approaches can achieve the accuracy and convenience of closed-form assessments. We leave the precise evaluation of visualization in data analysis as a direction for future research.\\n\\nA.2. Data Synthesis for Benchmarks\\n\\nIn this work, we generate data using a combination of LLM-synthesized data and thorough manual screening. Despite\"}"}
