{"id": "wang23n", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.1. Comprehensiveness\\n\\nThere is no universally best HPO method (Gijsbers et al., 2019). For the purpose of fairly comparing HPO methods, it is necessary to compare them on a variety of HPO problems that correspond to diverse objective functions and thus can comprehensively assess their performances.\\n\\nTo satisfy this need, we prepare various FL tasks, where their considered datasets and model architectures are quite different. Some datasets are provided by existing FL benchmarks, which are readily distributed and thus conform to the FL setting. Some are centralized initially, which we partition by FS's splitters to construct their FL counterparts with various kinds of Non-IIDness among clients. All these datasets are publicly available and can be downloaded and preprocessed by our prepared scripts. More details of these datasets can be found in Appendix D. Then the corresponding suitable model architecture is applied to handle each dataset. It is worth noticing that our prepared FL tasks cover both cross-silo and cross-device scenarios. In cross-device scenario, there are a lot more clients and a much lower client_sample_rate than in cross-silo scenario.\\n\\nFor each FL task, we basically employ two FL algorithms, FedAvg and FedOpt, to learn the model, respectively. Then the FedHPO problem is defined as optimizing the design choices of FL algorithm on each specific FL task. So we use the triple \\\\(<\\\\text{dataset}, \\\\text{model}, \\\\text{algorithm}>\\\\) to index a particular benchmark from now on. We summarize provided FedHPO problems in Table 1, and more details can be found in Appendix H. For each problem, \\\\#round and client_sample_rate are adopted as the fidelity dimensions.\\n\\nWe study the empirical cumulative distribution function (ECDF) for each model type in the cross-silo benchmarks. Specifically, in creating the lookup table for tabular mode, we have conducted function evaluations for the hyperparameter configurations located on a very dense grid over the search space, resulting in a finite set \\\\(\\\\{\\\\lambda, f(\\\\lambda)\\\\}\\\\) for each benchmark. Then we normalize the performances (i.e., \\\\(f(\\\\lambda)\\\\)) and show their ECDF in Fig. 3, where these curves exhibit different shapes. For example, the ratio of top-tier configurations for GNN on PubMed is remarkably less than on other datasets, which might imply a less smoothed landscape and difficulty in seeking the optimal configuration. As the varying shapes of ECDF curves have been regarded as an indicator of the diversity of benchmarks (Eggensperger et al., 2021), we can conclude from Fig. 3 that FedHPO-BENCH enables evaluating HPO methods comprehensively.\\n\\n4.2. Flexibility\\n\\nWe allow users to instantiate each benchmark with arguments other than the \\\\(<\\\\text{dataset}, \\\\text{model}, \\\\text{algorithm}>\\\\) triple to further specify the underlying objective function and system model, flexibly tailoring to their specific cases.\\n\\nObjective function. Despite the models' performance, users may have concerns about privacy (Qin et al., 2023) and fairness. For privacy protection, we employ a representative FL+DP algorithm NbAFL (Wei et al., 2020), where users can specify any valid value for the privacy budget. As for fairness, FS has provided many personalized FL algorithms, and FedHPO-BENCH can record client-wise performances. In designing the interface of FedHPO-BENCH, we allow users to specify their preferred measurements of privacy leakage risk and fairness. Then the execution of an FL algorithm can be regarded as evaluating a vector-valued function rather than a scalar-valued one. By default, FedHPO-BENCH transforms the vector result into a scalar one by treating privacy and fairness-related values as soft constraints to penalize.\\n\\nSystem model. It is very helpful to customize the system model as the runtime of the same FL training course can vary a lot when deployed in environments with different system conditions. Many existing HPO benchmarks record the runtime of training courses ever executed, which cannot be adapted to users' system conditions. Despite recorded runtimes, we provide a system model to estimate the time consumed by evaluating \\\\(f(\\\\lambda, b)\\\\) in realistic scenarios, which is configurable so that users with different system conditions can calibrate the model to their cases (Mohr et al., 2021).\\n\\nBased on the analysis of such a system model and a basic instance (Wang et al., 2021a), our system model estimates the execution time \\\\(T(f, \\\\lambda, b)\\\\) for each round in evaluating \\\\(f(\\\\lambda, b)\\\\) as the summation of time consumed by computation and communication. Roughly, the time for communication is the summation of the time for downloading and uploading transferred information and the latency for establishing connections. The time for computation is the summation of the time for the server's aggregation step and that for the straggler client's local update. Our system model exposes several adjustable parameters, for which we provide default choices based on the records collected from creating the tabular benchmarks. Meanwhile, users are allowed to specify these parameters according to their cases or other system statistic providers (Lai et al., 2022). We defer the details about our system model to Appendix E.\\n\\n4.3. Extensibility\\n\\nAs FedHPO is springing up, we must reduce the effort of introducing more FedHPO problems and novel FedHPO methods to FedHPO-BENCH. With FS, we can apply the off-the-shelf data splitters to transform an arbitrary centralized dataset into an FL dataset, reuse any open-sourced model implementation by registering it in FS, and develop a novel FL algorithm via plugging in the hook function that expresses its unique step(s).\"}"}
{"id": "wang23n", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 1. Summary of benchmarks in current FedHPO-BENCH\\n\\n| Scenario    | Model | #Dataset | Domain | #Client | #Algo. | #Cont. | #Disc. | Budget   |\\n|-------------|-------|----------|--------|---------|--------|--------|--------|----------|\\n| Cross-Silo  | CNN   | 2        | CV     | 200     | 2      | 4      | 2      | 20d      |\\n|             | BERT  | 2        | NLP    | 5       | 2      | 4      | 2      | 20d      |\\n|             | GNN   | 3        | Graph  | 5       | 2      | 4      | 1      | 1d       |\\n|             | GNN   | 1        | Hetero | 5       | 1      | 1      | 1      | 1d       |\\n|             | LR    | 7        | Tabular| 5       | 2      | 3      | 1      | 21,600s  |\\n|             | MLP   | 7        | Tabular| 5       | 2      | 4      | 3      | 43,200s  |\\n| Cross-Device| MF    | 1        | Rec.   | 480,189 | 2      | 3      | 1      | -        |\\n|             | LR    | 1        | NLP    | \u223c3300   | 2      | 3      | 1      | 1d       |\\n|             | MLP   | 1        | NLP    | \u223c3300   | 2      | 3      | 1      | 1d       |\\n\\n**Figure 3.** Empirical Cumulative Distribution Functions: The normalized regret is calculated for all evaluated configurations of the respective model on the respective FL task with FedAvg. However, FedHPO methods, such as FTS and FedEx, are fused with the FL training course to make concurrent exploration, as the dashed blue box in Fig. 1 and the red color \\\"FedHPO\\\" module in Fig. 2 shows. Thus, we need to implement such methods in FS if we want to benchmark them. At a high level, we can utilize the event-driven programming paradigm of FS to implement new FedHPO methods with minimal effort. Specifically, a standard FL training course is modularized into event-handler pairs that express all the subroutines. Thus, all we need to develop are augmenting the messages exchanged by FL participants (i.e., re-defining events) and plugging those HPO-related operations into the handlers. As a result, we have implemented FTS, FedEx, and a personalized FedEx in FS, where their differences mainly lie in just those plug-in operations. We defer more implementation details to Appendix F.\\n\\n### 5. Experiments\\n\\nWe conduct extensive empirical studies with our proposed FedHPO-BENCH, intending to (1) validate its usability and (2) investigate several aspects of FedHPO's uniqueness.\\n\\n#### 5.1. Usability of FedHPO-BENCH\\n\\nWe exemplify the use of FedHPO-BENCH in comparing traditional HPO methods (see Sec. 5.1.1) and comparing them with FedHPO methods wrapped by them (see Sec. 5.1.2).\\n\\n**5.1.1. Studies about traditional HPO methods**\\n\\n**Protocol.** We largely follow the experimental settings in HPOBench (Eggensperger et al., 2021) but focus on the FedHPO problems our FedHPO-BENCH provides. We employ up to ten optimizers (i.e., HPO methods) from widely adopted libraries (see Table 5 for more details). We apply these optimizers to solve the cross-silo FedHPO problems summarized in Table 1, where the time budget is relaxed for these traditional HPO methods to satisfy multiple full-fidelity function evaluations rather than a one-shot setting. The best-ever-seen validation loss over time is monitored for each optimizer (for multi-fidelity optimizers, higher fidelity results are preferred over lower ones). We sort the optimizers by their best-seen results and compare their mean ranks on all the considered FedHPO problems.\\n\\n**Results and Analysis.** We show the overall results in Fig. 4, and we defer detailed results to Appendix I. Overall, their eventual mean ranks do not deviate remarkably. For black-box optimizers (BBO), the performances of optimizers are close at the beginning but become more distinguishable along with their exploration. Ultimately, BO GP has successfully sought better configurations than other optimizers. In contrast to BBO, multi-fidelity optimizers (MF) perform pretty differently in the early stage, which might be rooted in the vast variance of low-fidelity function evaluations. Eventually, HB and BOHB become superior to others while...\"}"}
{"id": "wang23n", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\n![Graphs and tables showing results of different optimization methods on various problems.](image)\\n\\nFigure 4. Mean rank over time on all FedHPO problems (with FedAvg).\\n\\nTable 2. Compare the searched configurations: Mean test accuracy (%) \u00b1 standard deviation. The upward arrow indicates improvements.\\n\\n| Methods  | FEMNIST W/O FedEx | FEMNIST W/ FedEx | PubMed W/O FedEx | PubMed W/ FedEx |\\n|----------|-------------------|------------------|-----------------|-----------------|\\n| RS       | 79.93 \u00b1 2.45      | 82.03 \u00b1 2.08     | \u2191               | 72.92 \u00b1 2.48    | 79.44 \u00b1 3.02    | \u2191               |\\n| BO GP    | 82.18 \u00b1 0.94      | 83.20 \u00b1 1.24     | \u2191               | 85.52 \u00b1 1.25    | 86.34 \u00b1 2.05    | \u2191               |\\n| BO RF    | 81.86 \u00b1 1.10      | 82.20 \u00b1 0.54     | \u2191               | 83.76 \u00b1 2.96    | 80.63 \u00b1 4.18    | \u2191               |\\n| BO KDE   | 81.34 \u00b1 1.75      | 82.11 \u00b1 0.46     | \u2191               | 75.78 \u00b1 1.93    | 77.81 \u00b1 4.94    | \u2191               |\\n| HB       | 80.26 \u00b1 2.02      | 82.47 \u00b1 0.04     | \u2191               | 72.92 \u00b1 2.48    | 76.55 \u00b1 4.66    | \u2191               |\\n| BOHB     | 79.59 \u00b1 2.09      | 84.02 \u00b1 0.50     |                  | 71.75 \u00b1 1.01    | 75.15 \u00b1 5.90    |                  |\\n\\nachieving a very close mean rank. Then we conduct sign (i.e., win, tie, or lose) tests to compare the final rank of pairs of optimizers. Due to limited space, we defer detailed results to Appendix I.1 yet summarize the observations here: (1) Comparing model-based optimizers with their corresponding baselines, i.e., RS or HB, only BO GP, BO RF, and DE win on more than half of the FedHPO problems but have no significant improvement. (2) Meanwhile, no MF optimizers show any advantage in exploiting experience, which differs from the non-FL case. We presume the reason lies in the distribution of configurations\u2019 performances (see Fig. 3). (3) MF optimizers always outperform their corresponding single-fidelity version, which is consistent with the non-FL case. In the above discussion, the phenomenon of the non-FL case is reported by HPO-Bench (Eggensperger et al., 2021).\\n\\n5.1.2. Studies about FedHPO Methods\\n\\nProtocol. We select the superior optimizers from Sec. 5.1.1 to compare them with FedEx (Khodak et al., 2021) wrapped by them on <FEMNIST, CNN, FedAvg>, <PubMed, GNN, FedAvg>, and <FedNetflix, MF, FedAvg>. We use FedEx but not other methods because it is a one-shot method and satisfies our budget condition. As a full-fidelity function evaluation consumes 500 rounds on these datasets, we specify the total budget to \\\\(2 \\\\times 500\\\\) (i.e., 5 times the budget of a full-fidelity evaluation) in terms of \\\\(\\\\#\\\\text{rounds}\\\\). Precisely, each BBO method consists of 50 trials, each of which runs for 50 rounds. For MF optimizers, we set \\\\(\\\\eta\\\\) of Successive Halving Algorithm (SHA) (Jamieson & Talwalkar, 2016) to 3, the min and max budget to 9 and 81 rounds, respectively. Then we adopt these optimizers and FedEx wrapped by them (X+FedEx) to optimize the design choices of FedAvg, respectively. The wrapper is responsible for determining the arms for each execution of FedEx. We consider validation loss the metric of interest, and function evaluations are conducted in the raw mode. We repeat each method five times and report the best-ever-seen validation loss over budget. Then, for each considered method, we entirely run the FL course with the optimal solution it seeks. The averaged test accuracies of all the methods are compared.\\n\\nResults and Analysis. Due to the limited space, we defer the plots of best-ever-seen validation loss over budget to Appendix I.2, while summarizing the observations here: The best-ever-seen validation loss of all wrapped FedEx decreases slower than their corresponding wrappers. We speculate that the client-wise exploration increases the variance of local updates and thus hurts the aggregation. We present the main averaged test accuracies of all the methods in Table 2, and defer the results of <FedNetflix, MF, FedAvg> in Appendix I.2. On these three problems, most X+FedEx\u2019s searched configurations show significantly better generalization performances than their wrappers, which strongly confirms the effectiveness of concurrent exploration.\"}"}
{"id": "wang23n", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.2. Uniqueness of FedHPO\\n\\nIn addition to concurrent exploration, we now investigate other aspects of FedHPO's uniqueness with FedHPO-BENCH. Its extensibility enables us to effortlessly implement a personalized FedEx for studying personalization (see Sec. 5.2.1) and plug attack steps in clients' procedures for studying Byzantine fault tolerance (see Sec. 5.2.3). Its flexibility seamlessly lets us explore multi-objective optimization on FedHPO problems (see Sec. 5.2.2) and examine the system-dependent trade-offs between fidelity dimensions (see Appendix G).\\n\\n5.2.1. Studies about personalized FedHPO Protocol.\\n\\nFollowing Sec. 5.1.2, yet focus on the FedHPO problem <FEMNIST, CNN, FedAvg>, we compare X+FedEx with X+pFedEx, where pFedEx stands for personalized FedEx, a straightforward personalization method we quickly create with the help of FedHPO-BENCH. Specifically, pFedEx uses a parametric policy network to decide each client's hyperparameter configuration based on the client-specific context. For simplicity, we just report all the methods' averaged test accuracies.\\n\\nTable 3. Comparison between FedEx and pFedEx: Mean test accuracy (%) \u00b1 standard deviation. The boldface indicates the best performance.\\n\\n| Method   | FedEx | pFedEx |\\n|----------|-------|--------|\\n| RS       | 82.03 \u00b1 2.08 | 80.07 \u00b1 2.71 |\\n| BO       | 83.20 \u00b1 1.24 | 86.89 \u00b1 1.07 |\\n| GP       | 82.20 \u00b1 0.54 | 86.36 \u00b1 1.95 |\\n| RF       | 82.47 \u00b1 0.04 | 80.39 \u00b1 1.70 |\\n| HB       | 84.02 \u00b1 0.50 | 82.22 \u00b1 1.13 |\\n\\nResults and Analysis. We present the results in Table 3. Overall, X+pFedEx show competitive performance against X+FedEx, where the test accuracies corresponding to most wrappers are slightly lower than their non-personalized baselines, but BO GP+pFedEx and BO RF+pFedEx outperform their respective baselines and achieve the best performances among all methods. We also apply those traditional HPO methods solely with a personalized search space, which results in a test accuracy of around 4.50%. All these results imply that (1) directly solving the personalized FedHPO problem by traditional HPO methods is inviable; (2) There is enormous potential for personalized FedHPO, but simply personalizing a policy might not always give improvement.\\n\\n5.2.2. Studies about multi-objective FedHPO Protocol.\\n\\nWe largely follow the settings in Sec. 5.1.2 yet consider the FedHPO problem <CIFAR-10, CNN, FedAvg>. Furthermore, we instead optimize a vector-valued objective function simultaneously considering the validation loss averaged over all clients and a fairness-related metric, i.e., the standard deviation of client-wise validation loss. Then we examine a mean aggregation strategy and ParEGO (Cristescu & Knowles, 2015) as the optimizers, with different weights (i.e., 0.1, 1.0, and 10.0) of the fairness metric to transform the multi-objectives into a weighted sum of components. Meanwhile, to produce statistical heterogeneity among these clients, the CIFAR-10 dataset is split into 5 clients by Latent Dirichlet Allocation (LDA) with the \u03b1 \u2208 {0.05, 0.5, 5.0} to simulate different levels of heterogeneity among clients (the smaller the \u03b1, the greater the heterogeneity). For each considered optimizer, we entirely run the FL course with the optimal configuration it seeks. The averaged test accuracies and the standard deviation of client-wise test loss are compared.\\n\\nFigure 5. The performance of multi-objective optimization, where the triple represents <optimizer, weight, \u03b1 of LDA>. Considering fairness, the standard deviation of test accuracy is lower the better, while the test accuracy is higher the better.\\n\\nResults and Analysis. We present the overall results in Fig. 5. When the level of heterogeneity is the same (i.e., a fixed \u03b1), greater weight leads to lower test accuracy std., and lower weight leads to higher test accuracy, obviously because the weight controls the importance of each objective and makes the optimal configuration varies. Meanwhile, severer heterogeneity makes the FL task more challenging, and due to the uneven data distributions, the standard deviation of the client-wise test accuracy increases. In conclusion, (1) the interface of FedHPO-BENCH enables researchers to explore multi-objective FedHPO, and we establish several baselines; (2) Despite the importance of objectives can be effectively controlled, how to make trade-offs or even seek a Pareto optimal solution deserves further studies.\\n\\n5.2.3. Studies about Byzantine fault tolerance Protocol.\\n\\nWe largely follow the settings in Sec. 5.1.2 yet consider <FEMNIST, CNN, FedAvg>. Besides, we set different numbers of clients (0, 4, 16, and 64 among 200) as\"}"}
{"id": "wang23n", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\nResearch in the field of hyperparameter optimization (HPO) has been greatly accelerated by existing HPO benchmarks. Nonetheless, existing efforts in benchmarking all focus on HPO for traditional learning paradigms while ignoring federated learning (FL), a promising paradigm for collaboratively learning models from dispersed data. In this paper, we first identify some uniqueness of federated hyperparameter optimization (FedHPO) from various aspects, showing that existing HPO benchmarks no longer satisfy the need to study FedHPO methods. To facilitate the research of FedHPO, we propose and implement a benchmark suite \\\\textsc{FedHPO-Bench} that incorporates comprehensive FedHPO problems, enables flexible customization of the function evaluations, and eases continuing extensions. We conduct extensive experiments based on \\\\textsc{FedHPO-Bench} to provide the community with more insights into FedHPO. We open-sourced \\\\textsc{FedHPO-Bench} at https://github.com/alibaba/FederatedScope/tree/master/benchmark/FedHPOBench.\\n\\n1. Introduction\\nMost machine learning algorithms are sensitive to their hyperparameters. Hyperparameter optimization (HPO) (Feurer & Hutter, 2019) aims at making the right choices automatically. To this end, HPO methods often solve an optimization problem, where evaluating the objective function at a specific hyperparameter configuration $f(\\\\lambda)$ corresponds to executing the considered algorithm configured by $\\\\lambda$. Research in this line has been greatly facilitated by HPO benchmarks (Gijsbers et al., 2019; Eggensperger et al., 2021; Pineda-Arango et al., 2021), which prepare many HPO problems so that different HPO methods can be effortlessly compared in a fair and reproducible way.\\n\\nHowever, existing HPO benchmarks all focus on traditional learning paradigms. Federated learning (FL) (McMahan et al., 2017; Li et al., 2020a), as a privacy-preserving paradigm for collaboratively learning a model from distributed data, has not been considered. Actually, along with the increasing privacy concerns from the whole society, FL has been gaining increasing attention from academia and industry. Meanwhile, HPO for FL algorithms (denoted by FedHPO from now on) is identified as a critical and promising open problem in FL (Kairouz et al., 2019).\\n\\nIn this paper, we first elaborate on several aspects of FedHPO's uniqueness against traditional HPO (see Sec. 3), including (1) the concurrent exploration strategy FedHPO methods often adopt to improve efficiency, (2) personalization strategy potentially benefiting FedHPO methods, (3) multi-objective FedHPO problems raised from privacy and fairness concerns of FL, (4) runtime estimation and system-dependent trade-offs between fidelity dimensions required for studying FedHPO methods, and (5) Byzantine fault tolerance desired to be possessed by FedHPO methods. We attribute them to FL's distributed nature and the heterogeneity among federation partners. On the one hand, the HPO problems existing benchmarks prepared correspond to centralized learning tasks and thus fail to possess the above unique properties, such as the necessity for making personalization. On the other hand, the implementations of FedHPO methods need to be fused with the FL algorithm for studying the above unique strategies and desiderata. Existing HPO benchmarks are not built on an FL framework and thus cannot satisfy this need. Thus, recently proposed FedHPO methods (Zhou et al., 2021; Dai et al., 2020; Khoodak et al., 2021; Zhang et al., 2021; Guo et al., 2022) are evaluated on different problems and have not been uniformly implemented in one FL framework and well benchmarked.\\n\\nTo promote the research and application of FedHPO, we present \\\\textsc{FedHPO-Bench}, which is (1) Comprehensive: \\\\textsc{FedHPO-Bench} provides a comprehensive collection of FedHPO problems for drawing an unbiased conclusion from comparisons of related methods; (2) Flexible: \\\\textsc{FedHPO-Bench} allows users to flexibly tailor a FedHPO problem; (3) Enabling: \\\\textsc{FedHPO-Bench} is designed to enable continuing extensions and further research.\"}"}
{"id": "wang23n", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To our knowledge, we are the first to systematically analyze the uniqueness of FedHPO, and FedHPO-BENCH is the first dedicated benchmark. We conduct extensive experiments with FedHPO-BENCH to validate its usability and, with its facility, explore several facets of FedHPO's uniqueness that have not been studied before. We open-source FedHPO-BENCH and hope that both itself and the findings gained from our empirical studies are helpful for the community to push the research of FedHPO forward.\\n\\n2. Background\\n\\nIn the literature (Feurer & Hutter, 2019), HPO is often formulated as solving\\n\\\\[\\n\\\\min_{\\\\lambda \\\\in \\\\Lambda^1 \\\\times \\\\cdots \\\\times \\\\Lambda^K} f(\\\\lambda),\\n\\\\]\\nwhere each \\\\(\\\\Lambda_k\\\\) corresponds to candidate choices of a specific hyperparameter, and their Cartesian product (denoted by \\\\(\\\\times\\\\)) constitute the search space. In practice, such \\\\(\\\\Lambda_k\\\\) is often bounded and can be continuous or discrete. Each function evaluation at a specified hyperparameter configuration \\\\(\\\\lambda\\\\) means to execute the corresponding algorithm accordingly and return the value of the considered metric (e.g., validation loss) as the result \\\\(f(\\\\lambda)\\\\). HPO methods generally solve such a problem with a series of function evaluations. As a full-fidelity function evaluation is extremely costly, multi-fidelity methods exploit low-fidelity function evaluation, e.g., training for fewer epochs (Swersky et al., 2014; Domhan et al., 2015) or on a subset of data (Klein et al., 2017; Petrak, 2000; Swersky et al., 2013), to approximate the exact result. Thus, it would be convenient to extend \\\\(f\\\\) as\\n\\\\[\\nf(\\\\lambda, b), \\\\quad b \\\\in B^1 \\\\times \\\\cdots \\\\times B^L,\\n\\\\]\\nwhere each \\\\(B_l\\\\) corresponds to the possible choices of a specific fidelity dimension.\\n\\nHPO benchmarks (Gijsbers et al., 2019; Eggensperger et al., 2021; Pineda-Arango et al., 2021) have prepared many HPO problems, i.e., various kinds of objective functions, for comparing HPO methods. To evaluate these functions, HPO benchmarks, e.g., HPOBench (Eggensperger et al., 2021), often provide three modes: (1) \\\"Raw\\\" means truly executing the corresponding algorithm; (2) \\\"Tabular\\\" means querying a lookup table, where each entry corresponds to a specific \\\\(f(\\\\lambda, b)\\\\); (3) \\\"Surrogate\\\" means querying a surrogate model that might be trained on the tabular data. In addition to encouraging fair and reproducible comparisons, the tabular and surrogate modes significantly reduce the overhead of experiments. Thus, the research progress in HPO has been boosted by such benchmarks. However, as we will explain in Sec. 3, existing HPO benchmarks cannot be used for studying those recently proposed FedHPO methods (Khozdak et al., 2021; Zhou et al., 2021; Koskela & Honkela, 2020; Guo et al., 2022; Zhang et al., 2021), which thus were compared on respective FedHPO problems, and with inconsistent implementations. More related works are discussed in Appendix B.\\n\\n3. Uniqueness of FedHPO\\n\\nGenerally, traditional HPO methods (Bergstra & Bengio, 2012; Hutter et al., 2011; Li et al., 2017) are applicable to FedHPO problems. In each trial, a specific configuration \\\\((\\\\lambda, b)\\\\) is proposed, then an accordingly configured FL training course is conducted to produce \\\\(f(\\\\lambda, b)\\\\), as the dashed black box in Fig. 1 illustrates. In such an FL training course, there are \\\\(N\\\\) clients, each of which has its specific data, and a server coordinates them to learn a model \\\\(\\\\theta\\\\) collaboratively by an FL algorithm such as FedAvg (McMahan et al., 2017) and FedOpt (Asad et al., 2020). In the \\\\(t\\\\)-th round of a course, the server broadcasts the current model \\\\(\\\\theta(t)\\\\) to sampled clients; then, these clients make local updates and send the updates back; finally, the server aggregates these updates to produce \\\\(\\\\theta(t+1)\\\\). After executing the FL algorithm configured by \\\\(\\\\lambda\\\\) for several such rounds, e.g., \\\\(#\\\\text{round} = T\\\\) according to the specified fidelity \\\\(b\\\\), the performance, e.g., best validation loss ever achieved is returned as \\\\(f(\\\\lambda, b)\\\\).\\n\\nConcurrent exploration. The procedure of each round consists of two subroutines\u2014aggregation and local update. Thus, \\\\(\\\\lambda\\\\) can be divided into server-side and client-side hyperparameters according to which subroutine each hyperparameter influences. Denoting it as \\\\(\\\\lambda = (\\\\lambda_s, \\\\lambda_c)\\\\), the original optimization problem can be restated as its bi-level counterpart\\n\\\\[\\n\\\\min_{\\\\lambda_s} f(\\\\lambda_s, \\\\lambda_c^\\\\ast), \\\\quad \\\\text{s.t.,} \\\\quad \\\\lambda_c^\\\\ast = \\\\min_{\\\\lambda_c} f(\\\\lambda_s, \\\\lambda_c)\\n\\\\]\\nWith such a point of view, suppose a traditional HPO method has proposed a specific \\\\((\\\\lambda_s, b)\\\\); the idea of concurrent exploration leverages the distributed nature of FL to solve this lower-level sub-problem efficiently, as the dashed blue box in Fig. 1 shows. Specifically, clients are regarded as replicas of the black-box function \\\\(f(\\\\lambda_s, \\\\cdot)\\\\) or, at least, similar such functions whose evaluation results help fit \\\\(f(\\\\lambda_s, \\\\cdot)\\\\). Then it is natural to try client-side hyperparameter configurations client-wisely to collect \\\\(f(\\\\lambda_s, \\\\lambda_c)\\\\) for more than one \\\\(\\\\lambda_c\\\\) in each full or partial FL training course. Recently proposed FedHPO methods, such as FedEx (Khozdak et al., 2021) and FTS (Dai et al., 2020), have instantiated this idea. Taking FedEx as an example, in each trial of the outer loop, the traditional HPO method (see left-bottom of Fig. 1) proposes the arms (hyperparameter configurations) to be evaluated. Then, such a trial corresponds to one FL training course (see the dashed blue box), which consists of a specified number of communication rounds. In each round, FedEx samples client-wise arms, and the server broadcasts both model and arms. Then clients conduct local updates according to each one's assigned arm. At the end of each round...\"}"}
{"id": "wang23n", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"**Personalization.** The heterogeneity among clients is likely to give them different optimal configurations (Koskela & Honkela, 2020), where making decisions by the same policy would become unsatisfactory. This phenomenon tends to become severer when federated hetero-task learning (Yao et al., 2022) is considered. Trivially solving the personalized FedHPO problem\\n\\n\\\\[\\n\\\\min_{\\\\lambda(s), \\\\lambda(c)} \\\\sum_{i=1}^{N} f(\\\\lambda(s), \\\\lambda(c)_i)\\n\\\\]\\n\\nwhere \\\\(\\\\lambda(c)_i\\\\) denotes the \\\\(i\\\\)-th client's choice, is intractable, as the search space exponentially increases with \\\\(N\\\\). To promote studying personalized FedHPO, we provide a novel problem featured by heterogeneous tasks among the clients (see Sec. 4.1). Meanwhile, whether personalization is beneficial to FedHPO is explored in Sec. 5.2.1.\\n\\n**Multi-objective optimization.** Despite the model's performance, researchers are often concerned about other issues, such as privacy protection and fairness. Regarding privacy, the FL algorithm is often incorporated with privacy protection techniques such as differential privacy (DP) (Kairouz et al., 2019), which also exposes its hyperparameters. Intuitively, a low privacy budget specified for DP algorithms indicates a lower risk of privacy leakage yet a more significant degradation of the model's performance. As for fairness, namely, the uniformity of the model's performances across the clients, more and more FL algorithms have taken it into account (Li et al., 2021a; Wang et al., 2021b), which contains some hyperparameter(s) concerning fairness. Therefore, researchers may be interested in searching for a hyperparameter configuration that guarantees an acceptable privacy leakage risk (e.g., measured by R\u00e9nyi-DP (Mironov, 2017)) and fairness measurement (e.g., the standard deviation of client-wise performances) while optimizing the model's performance.\\n\\nThus, the interface of FEHPO-BENCH exposes a vector-valued objective function instead of a scalar-valued one, where the entries of a returned vector could be the quantitative measures corresponding to performance, privacy leakage risk, fairness, etc. Then, researchers can flexibly customize the objective (see Sec. 4.2) and study multi-objective HPO (Hern\u00e1ndez et al., 2021; Deb et al., 2002).\\n\\n**Runtime estimation and system-dependent trade-offs.** For the HPO purpose, an FL training course is usually simulated in a single computer rather than executed in a distributed system. As a result, simply recording the consumed time is meaningless for comparing actual runtimes.\"}"}
{"id": "wang23n", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\n```python\\nfrom fedhpob.benchmarks import TabularBenchmark\\nbenchmark = TabularBenchmark('cnn', 'femnist', 'avg')\\n# get hyperparameters space\\nconfig_space = benchmark.get_configuration_space()\\n# get fidelity space\\nfidelity_space = benchmark.get_fidelity_space()\\n# get results\\nres = benchmark(config_space.sample_configuration(), fidelity_space.sample_configuration(),\\n                 fairness_reg_func=np.var, fairness_reg_coef=1.0, seed=1)\\n```\\n\\nMeanwhile, FL's distributed nature introduces a new fidelity dimension\u2014client_sample_rate, which determines the fraction of clients sampled in each round. A smaller client_sample_rate often means less time each round would take because there is less likely to be a straggler. Meanwhile, it often leads to federated aggregation with larger variance, which is believed to need a larger #round for convergence. How we should balance these two fidelity dimensions to achieve more economical accuracy-efficiency trade-offs strongly depends on the system condition, e.g., choosing large #round but small client_sample_rate when the straggler issue is severe. As most existing HPO benchmarks overlook a runtime estimation functionality for studying FedHPO, in Sec. 4.2, we present our system model, with which we conduct an empirical study to show the effect of balancing client_sample_rate and #round in Appendix G.\\n\\nByzantine fault tolerance. Regarding fault tolerance, traditional HPO methods are desired to be robust w.r.t. noisy function evaluation results. As for FedHPO, some clients may report noisy or even adversarial function evaluation results. Then FedHPO methods should be able to solve for a satisfactory \\\\( \\\\lambda(c) \\\\) when, at least, more than half of all clients are trustworthy. With FedHPO-Bench, in Sec. 5.2.3, we provide the first empirical investigation of a FedHPO method's Byzantine resilience property.\\n\\nDue to all the facets of uniqueness discussed above, existing HPO benchmarks are inappropriate for studying FedHPO. A dedicated benchmark suite that can fill this gap must boost the research progress of FedHPO.\\n\\n4. Our Proposed Benchmark Suite\\n\\nWe present an overview of FedHPO-Bench in Fig. 2. Conceptually, FedHPO-Bench encapsulates function evaluation and provides a unified interface for HPO methods to interplay with it. Following the design of HPOBench (Eggensperger et al., 2021), function evaluations can be conducted in either of the three modes: raw, tabular, or surrogate. For the raw mode, we chose to build FedHPO-Bench upon the well-known FL platform FederatedScope (FS) (Xie et al., 2023), which has provided its docker images so that we can containerize FedHPO-Bench effortlessly by executing each FL algorithm in an FS docker container. To generate the lookup table for tabular mode, we truly execute the corresponding FL algorithms with the grids of search space as their configurations. These lookup tables are adopted as training data for the surrogate models, which are expected to approximate the objective functions (more details about this approximation are discussed in Appendix H.4.2). It's important to note that the distributed nature of FL makes it very expensive to run an FL course, so, in FedHPO, the tabular and surrogate modes are much in demand to meet the efficiency requirement. For users' convenience, we keep FedHPO-Bench's interface basically the same as HPOBench's yet expose extra arguments for customizing the instantiation of a benchmark. The relationship between FedHPO-Bench and HPOBench is discussed in Appendix B.1. We elaborate on three highlights of FedHPO-Bench as follows.\"}"}
{"id": "wang23n", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Fraction of budget | Mean rank |\\n|-------------------|-----------|\\n| 1e-4              |           |\\n| 1e-3              |           |\\n| 1e-2              |           |\\n| 1e-1              |           |\\n| 1                 |           |\\n\\n(a) ALL BERT\\n\\n(b) BBO BERT\\n\\n(c) MF BERT\\n\\n(d) ALL CoLA\\n\\n(e) BBO CoLA\\n\\n(f) MF CoLA\\n\\n(g) ALL SST-2\\n\\n(h) BBO SST-2\\n\\n(i) MF SST-2\\n\\nFigure 15. Mean rank over time on BERT benchmark (FedAvg).\"}"}
{"id": "wang23n", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 16. Mean rank over time on BERT benchmark (FedOpt).\"}"}
{"id": "wang23n", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"| Fraction of budget | Mean rank |\\n|--------------------|-----------|\\n| 1e-4               | 1         |\\n| 1e-3               | 2         |\\n| 1e-2               | 3         |\\n| 1e-1               | 4         |\\n| 1                  | 5         |\\n\\n**Figure 17.** Mean rank over time on GNN benchmark (FedAvg).\"}"}
{"id": "wang23n", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 18. Mean rank over time on GNN benchmark (FedOpt).\"}"}
{"id": "wang23n", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A. Maintenance of FedHPO-BENCH\\n\\nIn this section, we present our plan for maintaining FedHPO-BENCH following (Eggensperger et al., 2021).\\n\\n\u2022 Who is maintaining the benchmarking library?\\n  FedHPO-BENCH is developed and maintained by FedHPO-BENCH team of Alibaba Group.\\n\\n\u2022 How can the maintainer of the dataset be contacted (e.g., email address)?\\n  Users can reach out to the maintainer by creating issues on the GitHub repository with FedHPO-BENCH label.\\n\\n\u2022 Is there an erratum?\\n  No.\\n\\n\u2022 Will the benchmarking library be updated?\\n  Yes, as we discussed in Sec. 6, we will add more FedHPO problems and introduce more FL tasks to the existing benchmark. We will track updates and GitHub release on the README. In addition, we will fix potential issues regularly.\\n\\n\u2022 Will older versions of the benchmarking library continue to be supported/hosted/maintained?\\n  All older versions are available and maintained by the GitHub release, but limited support will be provided for older versions. Containers will be versioned and available via AliyunOSS.\\n\\n\u2022 If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?\\n  Any contribution is welcome, and all commits to FedHPO-BENCH must follow the guidelines and regulations at https://github.com/alibaba/FederatedScope/blob/master/benchmark/FedHPOBench/README.md.\\n\\nB. Related Work\\n\\nHyperparameter Optimization (HPO).\\n\\nGenerally, HPO is an optimization problem where the objective function is non-analytic, non-convex, and even non-differentiable. Therefore, most HPO methods solve such an optimization problem in a trial-and-error manner, with different strategies for balancing exploitation and exploration. Model-free methods such as random search (RS) (Bergstra & Bengio, 2012) and grid search query a set of initially determined hyperparameter configurations without any exploitation. Model-based methods such as Bayesian Optimization (BO) (Shahriari et al., 2016) employ a surrogate model to approximate the objective function. Methods in this line (Hutter et al., 2011; Lindauer et al., 2022; Falkner et al., 2018) mainly differ from each other in their surrogate model and how they determine the next query.\\n\\nThere are also Evolutionary Algorithms (EAs) that iteratively maintain a population. We consider differential EAs (Storn & Price, 1997; Awad et al., 2020) in our experiments.\\n\\nTraining a deep neural network on a large-scale dataset is costly, so the full-fidelity function evaluations made by BO methods are often unaffordable in practice. Naturally, researchers consider trading off the precision of a function evaluation for its efficiency by, e.g., training fewer epochs and training on a subset of the data. Hyperband (Li et al., 2017) is a representative multi-fidelity method that calls the Successive Halving Algorithm (SHA) (Jamieson & Talwalkar, 2016) again and again with a different number of initial candidates. However, in each execution of SHA, the initial candidates are randomly sampled without any exploitation. To exploit the experience of previous SHA executions, researchers combine BO methods with Hyperband (Falkner et al., 2018; Awad et al., 2021).\\n\\nBenchmarking HPO.\\n\\nAutoML-related optimization benchmarks have been proven helpful for promoting fair comparisons of related methods and reproducible research works. There have been many successful examples (Hutter et al., 2014; Hansen et al., 2021; Hase et al., 2021; Turner & Eriksson, 2019; Dong & Yang, 2020; Dong et al., 2021; Gijsbers et al., 2019).\\n\\nNoticeably, HPO-B (Pineda-Arango et al., 2021) is highlighted by its support for benchmarking transfer-HPO methods, and HPOBench (Eggensperger et al., 2021) fills the gap of missing multi-fidelity HPO benchmarks.\\n\\nHowever, existing HPO benchmarks mainly focus on centralized ML, yet FL, as a promising learning paradigm, has been ignored. In this paper, we identify the uniqueness of FedHPO (see Sec. 3) and implement FedHPO-BENCH to satisfy the demand for a FedHPO benchmark suite.\\n\\nFederated Learning (FL).\\n\\nIn this paper, we restrict our discussion of FL to the \u201cstandard\u201d scenario introduced in Sec. 3, where FedAvg (McMahan et al., 2017) is widely adopted. Fancy FL optimization algorithms, including FedProx (Li et al., 2020b) and FedOpt (Asad et al., 2020), are mainly designed to improve the convergence rate and/or better handle...\"}"}
{"id": "wang23n", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FedHPO-BENCH: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\nthe non-IIDness among clients (Wang et al., 2021a). Despite these synchronous optimization algorithms, asynchronous ones (Huba et al., 2022; Xie et al., 2023) are proposed to keep a high concurrency utility. Sometimes, learning one global model is insufficient to handle the non-IIDness, which calls for personalized FL (Kairouz et al., 2019; Wang et al., 2021a). Many popular pFL algorithms, such as FedBN (Li et al., 2021b) and Ditto (Li et al., 2021a), have been incorporated into FS (Xie et al., 2023; Chen et al., 2022), with their unique hyperparameters exposed. Thus, we can further extend FedHPO-BENCH by considering FedHPO tasks of optimizing the hyperparameters of such algorithms.\\n\\nFedHPO. When we consider HPO in the FL setting, as mentioned in Sec. 3, there is some uniqueness that brings in challenges while, at the same time, it can be leveraged by deliberately designed FedHPO methods. For example, in contrast to traditional HPO methods that query one configuration in each trial, FedEx (Khodak et al., 2021) maintains one policy for determining the client-side hyperparameters and independently samples each client's configuration in each communication round. Different configurations may be evaluated with the same model parameters, which is in analogy to the weight-sharing idea in neural architecture search (NAS) (Liu et al., 2019), as summarized by the authors of FedEx. However, due to the non-IIDness among clients, clients' HPO objective functions tend to be different, where determining their configurations by only one policy might be unsatisfactory. Regarding this issue, FTS (Dai et al., 2020) can be treated as a personalized FedHPO method, where each client maintains its own policy. During the learning procedure, the clients benefit each other by sharing the policies in a privacy-preserving manner and conducting Thompson sampling. It is worth mentioning that parallel algorithms have been utilized in HPO (Jones, 2001; Hutter et al., 2012). However, in FedHPO, the clients actually do not correspond to the same black-box function due to the heterogeneity among them. Essentially, FedHPO methods instantiate the concurrent exploration idea with extra assumptions. Besides, vanilla parallel HPO methods may leak privacy in the aggregation step, which has been carefully taken into account by FTS. Dynamic algorithm configuration methods (Biedenkapp et al., 2020; Adriaensen et al., 2022) employ reinforcement learning to learn policies for online adjustments of algorithm parameters since different parameter values can be optimal at different stages. In contrast to DAC methods, the policy $\\\\pi$ learned in FedEx is responsible for determining the optimal lower-level response of the bi-level optimization problem discussed in Sec. 3, which can be regarded as a multi-armed bandit problem rather than a Markov decision process. In other words, combined with the concurrent exploration strategy, FedEx tries out one arm at a client in each round, where the underlying reward function is assumed to be unchanged across the clients and the whole training course.\\n\\nAs an emerging research topic, existing works relating to FedHPO include Fed-Tuning (Zhang et al., 2021) concerning system-related performance, learning rate adaptation (Koskela & Honkela, 2020), FLoRA for Gradient Boosted Decision Trees (GBDT), online adaptation scheme-based method (Mostafa, 2020), Auto-FedRL (Guo et al., 2022) for RL-based hyperparameter adaptation, and insightful comparison between local and global HPO (Holly et al., 2021). These methods can also be easily incorporated into FS, enabling FedHPO-BENCH to benchmark them.\\n\\nB.1. Relation to HPOBench\\n\\nHPOBench (Eggensperger et al., 2021) is a collection of multi-fidelity HPO benchmarks, highlighted by their efficiency, reproducibility, and flexibility. These benchmarks can be accessed in either tabular, surrogate, or raw mode. On the one hand, the tabular and surrogate modes enable function evaluation without truly executing the corresponding ML algorithm and thus are efficient. On the other hand, the raw mode means execution in a docker container, which ensures reproducibility. HPOBench provides twelve families of benchmarks that correspond to different data domains, model types, fidelity spaces, etc., and thus flexible usages to validate HPO methods. This collection of HPO benchmarks can promote fair comparisons of related works and reproducible research work, so HPOBench has gained more and more attention from the community.\\n\\nAs noted in Sec. 3 that evaluating the objective function that corresponds to an FL algorithm is extremely expensive, FedHPO-BENCH also prepares tabular and surrogate modes for users to avoid truly executing FL courses. Meanwhile, we provide the raw mode to execute an FL course in the FederatedScope (FS) docker container (Xie et al., 2023). Sharing the same modes, a question naturally arises\u2014is it possible to reuse HPOBench's interface for FedHPO-BENCH?\\n\\nWe answer this question by discussing their commonality and the unique ingredients of FedHPO-BENCH:\\n\\nCommonality. As the code snippet in Fig. 2 shows, the instantiation of a benchmark class, the \u201cConfigSpace\u201d package-based specification of search space, and the protocol for the interaction between an HPO method and a benchmark object are roughly consistent with HPOBench.\"}"}
{"id": "wang23n", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In addition to a collection of benchmarks, FedHPO-BENCH is flexible in terms of enabling users to tailor one benchmark to their scenarios (see Sec. 4.2). To this end, users are allowed to instantiate a specific benchmark object with extra optional arguments:\\n\\n- Privacy budget with which function evaluation corresponds to the execution of NbAFL (Wei et al., 2020) instead of vanilla FedAvg. Taking the tabular mode, for example, means looking up a privacy budget-specific table.\\n- The type of fairness metric and its strength with which FedHPO-BENCH will consider a vector-valued objective function (i.e., client-wise results) rather than a scalar-valued objective function. Besides, the return value of calling the function evaluation will be the mean performance regularized by the specified fairness regularizer.\\n- The parameter(s) for our system model with which the execution time is estimated regarding the user's system condition. Without using a system model, FedHPO-BENCH can provide the recorded execution time in the creation of this benchmark.\\n- The ability to compare FedHPO methods, such as FedEx, FTS, and FLoRA, where the fidelity of function evaluation is controlled in finer-grained granularity, allows FedEx to use a subset of each client-specific validation set to estimate the reward signal for updating a policy. Meanwhile, it allows FLoRA to use a subset of each client-specific dataset to generate <hyperparameter configuration, validation loss> pairs, which are used to estimate the global loss surface.\\n\\nCurrently, we implement the interfaces of FedHPO-BENCH by ourselves, where the style of our interfaces is kept similar to HPOBench for the convenience of users who are familiar with HPOBench. We also provide several examples (https://github.com/alibaba/FederatedScope/tree/master/benchmark/FedHPOBench/demo) to access our tabular, surrogate, and raw benchmarks by implementing HPOBench's abstract base class. As a first step, we are going to contribute more such subclasses to the repository of HPOBench so that users can access our benchmarks via HPOBench's interfaces, where flexible customization cannot be provided temporarily. In our next step, we plan to extend the interfaces of HPOBench such that the benchmarks of FedHPO-BENCH can be accessed with our proposed flexible customization.\\n\\nC. HPO Methods\\n\\nAs shown in Table 5, we provide an overview of the optimizers (i.e., HPO methods) we use in this paper. For black-box optimizers (BBO), we consider random search (RS), the evolutionary search approach of differential evolution (DE (Storn & Price, 1997; Awad et al., 2020)), and bayesian optimization with a GP model (BO GP (Hutter et al., 2011)), a random forest model (BO RF (Hutter et al., 2011)), and a kernel density estimator (BO KDE (Falkner et al., 2018)), respectively. For multi-fidelity optimizers (MF), we consider Hyperband (HB (Li et al., 2017)), its model-based extensions with KDE-based model (BOHB (Falkner et al., 2018)), and differential evolution (DEHB (Awad et al., 2021)), and Optuna's implementations of TPE with median stopping (TPE MD) and TPE with Hyperband (TPE HB) (Akiba et al., 2019).\\n\\nTable 5. Overview of the optimizers from widely adopted libraries.\\n\\n| Name  | Model     | Packages version |\\n|-------|-----------|------------------|\\n| RS    | (Bergstra & Bengio, 2012) - | - HPBandster 0.7.4 |\\n| BO GP | (Hutter et al., 2011; Lindauer et al., 2022) | GP SMAC3 1.3.3 |\\n| BO RF | (Hutter et al., 2011) | RF SMAC3 1.3.3 |\\n| BO KDE| (Falkner et al., 2018) | KDE HPBandster 0.7.4 |\\n| DE    | (Storn & Price, 1997; Awad et al., 2020) - | - DEHB git commit |\\n| HB    | (Li et al., 2017) - | - HPBandster 0.7.4 |\\n| BOHB  | (Falkner et al., 2018) | KDE HPBandster 0.7.4 |\\n| DEHB  | (Awad et al., 2021) - | - DEHB git commit |\\n| TPE MD| (Akiba et al., 2019) | TPE Optuna 2.10.0 |\\n| TPE HB| (Akiba et al., 2019) | TPE Optuna 2.10.0 |\"}"}
{"id": "wang23n", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C.1. Black-box Optimizers\\n\\n*RS* (Random search) is a priori-free HPO method, i.e., each step of the search does not exploit the already explored configuration. The random search outperforms the grid search within a small fraction of the computation time.\\n\\n*BO* with a Gaussian process model. *BO* uses a Mat\u00e9rn kernel for continuous hyperparameters, and a hamming kernel for categorical hyperparameters. In addition, the acquisition function is expected improvement (EI).\\n\\n*BO* with a random forest model. We set the hyperparameters of the random forest as follows: the number of trees is 10, the max depth of each tree is 20, and we use the default setting of the minimal samples split, which is 3.\\n\\n*BO* is a Bayesian optimization with kernel density estimators (KDE), which is used in *BOHB* (Falkner et al., 2018). It models objective function as \\\\( \\\\Pr(x|y_{\\\\text{good}}) \\\\) and \\\\( \\\\Pr(x|y_{\\\\text{bad}}) \\\\). We set the hyperparameters for *BO* as follows: the number of samples to optimize EI is 64, and \\\\( \\\\frac{1}{3} \\\\) of purely random configurations are sampled from the prior without the model; the bandwidth factor is 3 to encourage diversity, and the minimum bandwidth is 1e-3 to keep diversity.\\n\\n*DE* uses the evolutionary search approach of Differential Evolution. We set the mutation strategy to *rand1* and the binomial crossover strategy to *bin1*. In addition, we use the default settings for the other hyperparameters of *DE*, where the mutation factor is 0.5, crossover probability is 0.5, and the population size is 20.\\n\\nC.2. Multi-fidelity Optimizers\\n\\n*HB* (Hyperband) is an extension on top of successive halving algorithms for the pure-exploration nonstochastic infinite-armed bandit problem. Hyperband makes a trade-off between the number of hyperparameter configurations and the budget allocated to each hyperparameter configuration. We set \\\\( \\\\eta \\\\) to 3, which means only a fraction of \\\\( \\\\frac{1}{\\\\eta} \\\\) of hyperparameter configurations goes to the next round.\\n\\n*BOHB* combines *HB* with the guidance and guarantees of convergence of Bayesian optimization with kernel density estimators. We set the hyperparameter of the *BO* components and the *HB* components of *BOHB* to be the same as *BO* and *HB* described above, respectively. *DEHB* combines the advantages of the bandit-based method *HB* and the evolutionary search approach of *DE*. The hyperparameter of *DE* components and *BO* components are set to be exactly the same as *DE* and *HB* described above, respectively.\\n\\n*TPE* is implemented in *Optuna* and uses Tree-structured Parzen Estimator (*TPE*) as a sampling algorithm, where on each trial, *TPE* fits two Gaussian Mixture models for each hyperparameter. One is to the set of hyperparameters with the best performance, and the other is to the remaining hyperparameters. In addition, it uses the median stopping rule as a pruner, which means that it will prune if the trial's best intermediate result is worse than the median (*MD*) of intermediate results of previous trials at the same step. We use the default settings for both *TPE* and *MD*.\\n\\n*TPE* is similar to *TPE* described above, which uses *TPE* as a sampling algorithm and *HB* as pruner. We set the reduction factor to 3 for *HB* pruner, and all other settings use the default ones.\\n\\nD. Datasets\\n\\nAs shown in Table 6, we provide a detailed description of the datasets we use in current *HPO-BENCH*. For comprehensiveness, we use 16 FL datasets from 5 domains, including CV, NLP, graph, tabular, and recommendation (Xie et al., 2023; Wang et al., 2022; Eggensperger et al., 2021). Some of them are inherently real-world FL datasets, while others are simulated FL datasets split by the splitter modules of FS. Notably, the name of datasets from OpenML is the ID of the corresponding task.\\n\\n*FEMNIST* is an FL image dataset from LEAF (Caldas et al., 2018), whose task is image classification. Following (Caldas et al., 2018), we use a subsample of FEMNIST with 200 clients, which is around 5%. And we use the default train/valid/test splits for each client, where the ratio is 60% : 20% : 20%.\\n\\n*CIFAR-10* (Krizhevsky, 2009) is from Tiny Images dataset and consists of 60,000 32 \\\\times 32 color images, whose task is...\"}"}
{"id": "wang23n", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Figure 19.\\nMean rank over time on LR benchmark (FedAvg).\\n\\n| Fraction of budget | Mean rank |\\n|--------------------|-----------|\\n| 1e-4               |           |\\n| 1e-3               |           |\\n| 1e-2               |           |\\n| 1e-1               |           |\\n| 1                  |           |\\n| 2                  |           |\\n| 3                  |           |\\n| 4                  |           |\\n| 5                  |           |\\n| 6                  |           |\\n| 7                  |           |\\n| 8                  |           |\\n| 9                  |           |\\n| 10                 |           |\\n\\n(a) ALL\\n\\n(b) BBO\\n\\n(c) MF\\n\\n(d) ALL\\n\\n(e) BBO\\n\\n(f) MF\\n\\n(g) ALL\\n\\n(h) BBO\\n\\n(i) MF\\n\\n(j) ALL\\n\\n(k) BBO\\n\\n(l) MF\"}"}
{"id": "wang23n", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Figure 19. Mean rank over time on LR benchmark (FedAvg). (cont.)\"}"}
{"id": "wang23n", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 20. Mean rank over time on LR benchmark (FedOpt).\"}"}
{"id": "wang23n", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Fraction of budget | Mean rank |\\n|-------------------|-----------|\\n| 1e-4              | 1         |\\n| 1e-3              | 2         |\\n| 1e-2              | 3         |\\n| 1e-1              | 4         |\\n| 1                 | 5         |\\n| 2                 | 6         |\\n| 3                 | 7         |\\n| 4                 | 8         |\\n| 5                 | 9         |\\n| 6                 | 10        |\\n\\n**Figure 20.** Mean rank over time on LR benchmark (FedOpt). (cont.)\"}"}
{"id": "wang23n", "page_num": 41, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 24. Mean rank over time on BERT benchmark under surrogate mode (FedAvg).\"}"}
{"id": "wang23n", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 21. Mean rank over time on MLP benchmark (FedAvg).\\n\\n(a) ALL\\n(b) BBO\\n(c) MF\\n(d) ALL\\n(e) BBO\\n(f) MF\\n(g) ALL\\n(h) BBO\\n(i) MF\\n(j) ALL\\n(k) BBO\\n(l) MF\\n\\nOpenML\"}"}
{"id": "wang23n", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 21. Mean rank over time on MLP benchmark (FedAvg). (cont.)\"}"}
{"id": "wang23n", "page_num": 39, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Figure 22.\\nMean rank over time on MLP benchmark (FedOpt).\\n\\n| Fraction of budget | Mean rank |\\n|-------------------|-----------|\\n| 1e-4              |           |\\n| 1e-3              |           |\\n| 1e-2              |           |\\n| 1e-1              |           |\\n| 1                 |           |\\n\\n- **(a) ALL**\\n- **(b) BBO**\\n- **(c) MF**\\n- **(d) ALL**\\n- **(e) BBO**\\n- **(f) MF**\\n- **(g) ALL**\\n- **(h) BBO**\\n- **(i) MF**\\n- **(j) ALL**\\n- **(k) BBO**\\n- **(l) MF**\"}"}
{"id": "wang23n", "page_num": 40, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 22. Mean rank over time on MLP benchmark (FedOpt). (cont.)\\n\\nFigure 23. Mean rank over time on CNN benchmark under surrogate mode (FedAvg).\"}"}
{"id": "wang23n", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"attackers to assess the Byzantine resilience of FedEx. If a client is an attacker, Gaussian white noise will be injected into the local function evaluation results $f_i(\u03bb(c_i))$, which are to be used by the server for updating the policy $\u03c0$ (recall Fig. 1). Consequently, the learned policy tends to fail in searching for the optimal hyperparameter configuration.\\n\\nResults and Analysis. We present the results in Table 4. Overall, when there is no defense against the attack, almost all FedHPO methods perform worse as the number of attackers increases. The performance of $RS + FedEx$ does not continue to degrade when the number of attackers is increased from 16 to 64. Still, their performance is significantly lower than when there is no attack or 4 attackers. In conclusion, (1) FedHPO-BENCH provides an easy-to-use testbed and baselines for studying Byzantine fault tolerance; (2) the robustness of FedEx against such attacks needs to be improved; (3) Our experimental results encourage researchers to study how to defend against such attacks.\\n\\nTable 4. Compare the different number of attackers: Mean test accuracy (%) \u00b1 standard deviation.\\n\\n| Method      | #Attacker | 0     | 4     | 16    | 64    |\\n|-------------|-----------|-------|-------|-------|-------|\\n| RS + FedEx  | 82.03 \u00b1 2.08 | 79.05\u00b10.67 | 74.21\u00b12.98 | 76.40\u00b12.08 |\\n| BO-GP + FedEx | 83.20 \u00b1 1.24 | 80.52\u00b10.76 | 79.18\u00b11.11 | 76.84\u00b13.10 |\\n| BO-RF + FedEx | 82.20 \u00b1 0.54 | 79.88\u00b11.96 | 79.59\u00b11.23 | 78.17\u00b10.36 |\\n| BO-KDE + FedEx | 82.11 \u00b1 0.46 | 74.27\u00b10.03 | 74.17\u00b13.70 | 74.05\u00b13.20 |\\n| HB + FedEx  | 82.47 \u00b1 0.04 | 79.37\u00b10.98 | 76.58\u00b12.20 | 76.30\u00b12.98 |\\n| BOHB + FedEx | 84.02 \u00b1 0.50 | 80.29\u00b11.27 | 72.40\u00b13.40 | 70.49\u00b11.81 |\\n\\n6. Conclusion and Future Work\\n\\nIn this paper, we first identify the uniqueness of FedHPO, which we ascribe to the distributed nature of FL and its heterogeneous clients. These uniqueness calls for a dedicated FedHPO benchmark for comparing related methods in a fair and reproducible way that would otherwise be infeasible. Hence, we open-source a comprehensive, flexible, and extensible FedHPO benchmark suite, FedHPO-BENCH. We conduct extensive experiments with it, validating its usability and exploring various facets of FedHPO's uniqueness. We believe FedHPO-BENCH can serve as the stepping stone to developing reproducible FedHPO works.\\n\\nIn our next step, we will utilize the flexibility and extensibility of FedHPO-BENCH to incorporate more settings, including federated unsupervised learning and vertical FL. Meanwhile, some very recent research studies the privacy leakage risk of HPO (Koskela & Honkela, 2020), which we will provide related metrics and testbeds.\\n\\nAcknowledgements\\n\\nWe would like to thank the anonymous reviewers for their valuable feedback and constructive suggestions that helped us improve the quality and clarity of our paper.\\n\\nReferences\\n\\nAdriaensen, S., Biedenkapp, A., Shala, G., Awad, N. H., Eimer, T., Lindauer, M. T., and Hutter, F. Automated dynamic algorithm configuration. J. Artif. Intell. Res., 75:1633\u20131699, 2022.\\n\\nAkiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M. Optuna: A next-generation hyperparameter optimization framework. In Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'19), pp. 2623\u20132631, 2019.\\n\\nAsad, M., Moustafa, A., and Ito, T. FedOpt: Towards communication efficiency and privacy preservation in federated learning. Applied Sciences, 10, 2020.\\n\\nAwad, N., Mallik, N., and Hutter, F. Differential evolution for neural architecture search. In Proc. of the International Conference on Learning Representations (ICLR'20), 2020.\\n\\nAwad, N., Mallik, N., and Hutter, F. DEHB: Evolutionary hyperband for scalable, robust and efficient hyperparameter optimization. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI'21), pp. 2147\u20132153, 2021.\\n\\nBennett, J. and Lanning, S. The netflix prize. 2007.\\n\\nBergstra, J. and Bengio, Y. Random search for hyperparameter optimization. J. Mach. Learn. Res., pp. 281\u2013305, 2012.\\n\\nBiedenkapp, A., Bozkurt, H. F., Eimer, T., Hutter, F., and Lindauer, M. T. Dynamic algorithm configuration: Foundation of a new meta-algorithmic framework. In European Conference on Artificial Intelligence, 2020.\\n\\nBischl, B., Casalicchio, G., Feurer, M., Hutter, F., Lang, M., Mantovani, R. G., van Rijn, J. N., and Vanschoren, J. Openml benchmarking suites. arXiv preprint arXiv:1708.03731, 2017.\\n\\nCaldas, S., Duddu, S. M. K., Wu, P., Li, T., Kone \u02c7cn`y, J., McMahan, H. B., Smith, V., and Talwalkar, A. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097, 2018.\\n\\nChen, D., Gao, D., Kuang, W., Li, Y., and Ding, B. pFL-Bench: A comprehensive benchmark for personalized federated learning. In Proc. of the Advances in Neural Information Processing Systems (NeurIPS'22 Datasets and Benchmarks Track), 2022.\\n\\nChen, D., Gao, D., Xie, Y., Pan, X., Li, Z., Li, Y., Ding, B., and Zhou, J. FS-REAL: Towards real-world cross-device federated learning. In Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'23), 2023.\"}"}
{"id": "wang23n", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FEDHP-B: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\nCristescu, C. M. and Knowles, J. Surrogate-based multiobjective optimization: Parego update and test. 2015.\\n\\nDai, Z., Low, B. K. H., and Jaillet, P. Federated bayesian optimization via thompson sampling. In Proc. of the Advances in Neural Information Processing Systems (NeurIPS'20), pp. 9687\u20139699, 2020.\\n\\nDeb, K., Agrawal, S., Pratap, A., and Meyarivan, T. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput., 6:182\u2013197, 2002.\\n\\nDomhan, T., Springenberg, J. T., and Hutter, F. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI'15), 2015.\\n\\nDong, X. and Yang, Y. NAS-Bench-201: Extending the scope of reproducible neural architecture search. In Proc. of the International Conference on Learning Representations (ICLR'20), 2020.\\n\\nDong, X., Liu, L., Musial, K., and Gabrys, B. NATS-Bench: Benchmarking NAS algorithms for architecture topology and size. Proc. of the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI'21), 2021.\\n\\nEggensperger, K., M\u00fcller, P., Mallik, N., Feurer, M., Sass, R., Klein, A., Awad, N., Lindauer, M., and Hutter, F. HPOBench: A collection of reproducible multi-Fidelity benchmark problems for HPO. In Proc. of the Advances in Neural Information Processing Systems (NeurIPS'21 Datasets and Benchmarks Track), 2021.\\n\\nFalkner, S., Klein, A., and Hutter, F. BOHB: Robust and efficient hyperparameter optimization at scale. In Proc. of the International Conference on Machine Learning (ICML'18), 2018.\\n\\nFeurer, M. and Hutter, F. Hyperparameter optimization. In Automated machine learning, pp. 3\u201333. 2019.\\n\\nGijsbers, P., LeDell, E., Poirier, S., Thomas, J., Bischl, B., and Vanschoren, J. An open source autoML benchmark. arXiv preprint arXiv:1907.00909, 2019.\\n\\nGraham, R. L., Knuth, D. E., and Patashnik, O. Concrete Mathematics: A Foundation for Computer Science. Addison-Wesley, 1989.\\n\\nGuo, P., Yang, D., Hatamizadeh, A., Xu, A., Xu, Z., Li, W., Zhao, C., Xu, D., Harmon, S. A., Turkbey, E. B., Turkbey, B. I., Wood, B. J., Patella, F., Stellato, E., Carrafiello, G., Patel, V. M., and Roth, H. R. Auto-FedRL: Federated hyperparameter optimization for multi-institutional medical image segmentation. arXiv preprint arXiv:2203.06338, 2022.\\n\\nHansen, N., Auger, A., Mersmann, O., Tusar, T., and Brockhoff, D. COCO: a platform for comparing continuous optimizers in a black-box setting. Optimization Methods and Software, pp. 114 \u2013 144, 2021.\\n\\nHase, F., Aldeghi, M., Hickman, R. J., Roch, L. M., Christiansen, M., Liles, E., Hein, J. E., and Aspuru-Guzik, A. Olympus: a benchmarking framework for noisy optimization and experiment planning. Machine Learning: Science and Technology, 2021.\\n\\nHern\u00e1ndez, A. M., Nieuwenhuyse, I. V., and Rojas-Gonzalez, S. A survey on multi-objective hyperparameter optimization algorithms for machine learning. arXiv preprint arXiv:2111.13755, 2021.\\n\\nHolly, S., Hiessl, T., Lakani, S. R., Schall, D., Heitzinger, C., and Kemnitz, J. Evaluation of hyperparameter-optimization approaches in an industrial federated learning system. arXiv preprint arXiv:2110.08202, 2021.\\n\\nHuba, D., Nguyen, J., Malik, K., Zhu, R., Rabbat, M., Yousefpour, A., Wu, C.-J., Zhan, H., Ustinov, P., Srinivas, H., et al. Papaya: Practical, private, and scalable federated learning. Proceedings of Machine Learning and Systems, 2022.\\n\\nHutter, F., Hoos, H. H., and Leyton-Brown, K. Sequential model-based optimization for general algorithm configuration. In Proc. of the international conference on learning and intelligent optimization (LION'11), pp. 507\u2013523. Springer, 2011.\\n\\nHutter, F., Hoos, H., and Leyton-Brown, K. Parallel algorithm configuration. pp. 55\u201370, 2012.\\n\\nHutter, F., L\u00f3pez-Ib\u00e1\u00f1ez, M., Fawcett, C., Lindauer, M. T., Hoos, H. H., Leyton-Brown, K., and St\u00fctzle, T. AClib: A benchmark library for algorithm configuration. In Proc. of the international conference on learning and intelligent optimization (LION'14), 2014.\\n\\nJamieson, K. and Talwalkar, A. Non-stochastic best arm identification and hyperparameter optimization. In Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS'16), pp. 240\u2013248, 2016.\\n\\nJones, D. R. A taxonomy of global optimization methods based on response surfaces. Journal of Global Optimization, 21:345\u2013383, 2001.\\n\\nKairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A. N., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al. Advances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.\"}"}
{"id": "wang23n", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Khodak, M., Tu, R., Li, T., Li, L., Balcan, N., Smith, V., and Talwalkar, A. Federated hyperparameter tuning: Challenges, baselines, and connections to weight-sharing. In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W. (eds.), Proc. of the Advances in Neural Information Processing Systems (NeurIPS'21), 2021.\\n\\nKlein, A., Falkner, S., Bartels, S., Hennig, P., and Hutter, F. Fast bayesian optimization of machine learning hyperparameters on large datasets. In Artificial intelligence and statistics, pp. 528\u2013536, 2017.\\n\\nKoskela, A. and Honkela, A. Learning rate adaptation for differentially private learning. In Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS'20), pp. 2465\u20132475, 2020.\\n\\nKrizhevsky, A. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.\\n\\nLai, F., Dai, Y., Singapuram, S. S., Liu, J., Zhu, X., Madhyastha, H. V., and Chowdhury, M. FedScale: Benchmarking model and system performance of federated learning at scale. In Proc. of the International Conference on Machine Learning (ICML'22), 2022.\\n\\nLi, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A. Hyperband: A novel bandit-based approach to hyperparameter optimization. The Journal of Machine Learning Research, pp. 6765\u20136816, 2017.\\n\\nLi, T., Sahu, A. K., Talwalkar, A., and Smith, V. Federated learning: Challenges, methods, and future directions. IEEE Signal Processing Magazine, pp. 50\u201360, 2020a.\\n\\nLi, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V. Federated optimization in heterogeneous networks. Proceedings of Machine Learning and Systems, pp. 429\u2013450, 2020b.\\n\\nLi, T., Hu, S., Beirami, A., and Smith, V. Ditto: Fair and robust federated learning through personalization. In Proc. of the International Conference on Machine Learning (ICML'21), pp. 6357\u20136368, 2021a.\\n\\nLi, X., JIANG, M., Zhang, X., Kamp, M., and Dou, Q. FedBN: Federated learning on non-IID features via local batch normalization. In Proc. of the International Conference on Learning Representations (ICLR'21), 2021b.\\n\\nLi, Z., Ding, B., Zhang, C., Li, N., and Zhou, J. Federated matrix factorization with privacy guarantee. Proc. VLDB Endow., 15:900\u2013913, 2021c.\\n\\nLindauer, M., Eggensperger, K., Feurer, M., Biedenkapp, A., Deng, D., Benjamins, C., Ruhkopf, T., Sass, R., and Hutter, F. SMAC3: A versatile bayesian optimization package for hyperparameter optimization. J. Mach. Learn. Res., pp. 54\u20131, 2022.\\n\\nLiu, H., Simonyan, K., and Yang, Y. DARTS: Differentiable architecture search. In Proc. of the International Conference on Learning Representations (ICLR'19), 2019.\\n\\nMcMahan, B., Moore, E., Ramage, D., Hampson, S., and Arcas, B. A. y. Communication-Efficient Learning of Deep Networks from Decentralized Data. In Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS'17), pp. 1273\u20131282, 2017.\\n\\nMironov, I. R\u00e9nyi differential privacy. In Proc. of IEEE Computer Security Foundations Symposium (CSF'17), pp. 263\u2013275, 2017.\\n\\nMohr, F., Wever, M., Tornede, A., and H\u00fcllermeier, E. Predicting machine learning pipeline runtimes in the context of automated machine learning. Proc. of the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI'21), 43:3055\u20133066, 2021.\\n\\nMostafa, H. Robust federated learning through representation matching and adaptive hyper-parameters, 2020.\\n\\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and \u00c9douard Duchesnay. Scikit-learn: Machine learning in python. Journal of Machine Learning Research, pp. 2825\u20132830, 2011.\\n\\nPetrak, J. Fast subsampling performance estimates for classification algorithm selection. In Proc. of the ECML-00 Workshop on Meta-Learning: Building Automatic Advice Strategies for Model Selection and Method Combination, pp. 3\u201314, 2000.\\n\\nPfisterer, F., Schneider, L., Moosbauer, J., Binder, M., and Bischl, B. YAHPO gym-an efficient multi-objective multi-fidelity benchmark for hyperparameter optimization. In Proc. of the Automated Machine Learning (AutoML'22), 2022.\\n\\nPineda-Arango, S., Jomaa, H. S., Wistuba, M., and Grabocka, J. HPO-B: A large-scale reproducible benchmark for black-box HPO based on openML. Proc. of the Advances in Neural Information Processing Systems (NeurIPS'21 Datasets and Benchmarks Track), 2021.\\n\\nPushak, Y. and Hoos, H. H. Automl loss landscapes. ACM Transactions on Evolutionary Learning and Optimization, 2022.\\n\\nQin, Z., Yao, L., Chen, D., Li, Y., Ding, B., and Cheng, M. Revisiting personalized federated learning: Robustness against backdoor attacks. In Proc. of the ACM SIGKDD, 2021.\"}"}
{"id": "wang23n", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FEDHP BENCH: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\nInternational Conference on Knowledge Discovery and Data Mining (KDD'23), 2023.\\n\\nSen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., and Eliassi-Rad, T. Collective classification in network data. AI magazine, pp. 93\u201393, 2008.\\n\\nShahriari, B., Swersky, K., Wang, Z., Adams, R. P., and de Freitas, N. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, pp. 148\u2013175, 2016.\\n\\nStorn, R. and Price, K. Differential evolution\u2014A simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, pp. 341\u2013359, 1997.\\n\\nSwersky, K., Snoek, J., and Adams, R. P. Multi-task bayesian optimization. Proc. of the Advances in Neural Information Processing Systems (NeurIPS'13), 2013.\\n\\nSwersky, K., Snoek, J., and Adams, R. P. Freeze-thaw bayesian optimization. arXiv preprint arXiv:1406.3896, 2014.\\n\\nTurner, R. and Eriksson, D. Bayesmark: Benchmark framework to easily compare bayesian optimization methods on real machine learning tasks. https://github.com/uber/bayesmark, 2019.\\n\\nWang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. GLUE: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\\n\\nWang, J., Charles, Z., Xu, Z., Joshi, G., McMahan, H. B., Al-Shedivat, M., Andrew, G., Avestimehr, S., Daly, K., Data, D., et al. A field guide to federated optimization. arXiv preprint arXiv:2107.06917, 2021a.\\n\\nWang, Z., Fan, X., Qi, J., Wen, C., Wang, C., and Yu, R. Federated learning with fair averaging. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI'21), pp. 1615\u20131623, 2021b.\\n\\nWang, Z., Kuang, W., Xie, Y., Yao, L., Li, Y., Ding, B., and Zhou, J. FederatedScope-GNN: Towards a unified, comprehensive and efficient package for federated graph learning. In Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'22), pp. 4110\u20134120, 2022.\\n\\nWei, K., Li, J., Ding, M., Ma, C., Yang, H. H., Farokhi, F., Jin, S., Quek, T. Q. S., and Vincent Poor, H. Federated learning with differential privacy: Algorithms and performance analysis. Trans. Info. For. Sec., pp. 3454\u20133469, 2020.\\n\\nXie, Y., Wang, Z., Chen, D., Gao, D., Yao, L., Kuang, W., Li, Y., Ding, B., and Zhou, J. FederatedScope: A flexible federated learning platform for heterogeneity. PVLDB, 2023.\\n\\nYang, Z., Cohen, W., and Salakhudinov, R. Revisiting semi-supervised learning with graph embeddings. In Proc. of the International Conference on Machine Learning (ICML'16), pp. 40\u201348, 2016.\\n\\nYao, L., Gao, D., Wang, Z., Xie, Y., Kuang, W., Chen, D., Wang, H., Dong, C., Ding, B., and Li, Y. A benchmark for federated hetero-task learning. arXiv preprint arXiv:2206.03436, 2022.\\n\\nZhang, H., Zhang, M., Liu, X., Mohapatra, P., and DeLuchi, M. Automatic tuning of federated learning hyperparameters from system perspective. arXiv preprint arXiv:2110.03061, 2021.\\n\\nZhou, Y., Ram, P., Salonidis, T., Baracaldo, N., Samulowitz, H., and Ludwig, H. Flora: Single-shot hyperparameter optimization for federated learning. arXiv preprint arXiv:2112.08524, 2021.\"}"}
{"id": "wang23n", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 6. Statistics of the datasets used in current FEDHPO-BENCH.\\n\\n| Name            | #Client | Subsample | #Instance | #Class | Split by          |\\n|-----------------|---------|-----------|-----------|--------|-------------------|\\n| FMNIST          | 3       | 550       | 5%        | 805    | Writer            |\\n| CIFAR-10        | 5       | 100%      | 60k       | 10     | LDA               |\\n| CoLA            | 5       | 100%      | 10k       | 2      | LDA               |\\n| SST-2           | 5       | 100%      | 70k       | 2      | LDA               |\\n| Cora            | 5       | 100%      | 2k        | 7      | Community         |\\n| CiteSeer        | 5       | 100%      | 4k        | 6      | Community         |\\n| PubMed          | 5       | 100%      | 19k       | 3      | Community         |\\n| Hetero-task     | 5       | 100%      | 6k        | 2~6    | Task              |\\n| credit-g        | 31      | 5%        | 1k        | 2      | LDA               |\\n| vehicle         | 53      | 5%        | 846       | 4      | LDA               |\\n| kc1             | 3917    | 5%        | 2k        | 2      | LDA               |\\n| blood-transf..  | 10101   | 5%        | 748       | 2      | LDA               |\\n| Australian      | 146818  | 5%        | 690       | 2      | LDA               |\\n| car             | 146821  | 5%        | 1k        | 4      | LDA               |\\n| segment         | 146822  | 5%        | 2k        | 7      | LDA               |\\n| FedNetflix      | 480     | 100%      | 1M        | 8      | User              |\\n| Twitter         | 660     | 0.5%      | 1k        | 2      | User              |\\n\\nWe split images into 5 clients by latent Dirichlet allocation (LDA) to produce statistical heterogeneity among these clients. We split the raw training set into training and validation sets with a ratio of 4:1, so that ratio of final train/valid/test splits is 66.7%:16.67%:16.67%.\\n\\nSST-2 is a dataset from GLUE (Wang et al., 2018) benchmark, whose task is binary sentiment classification for sentences. We also split these sentences into 5 clients by LDA. In addition, we use the official train/valid/test splits for SST-2.\\n\\nCoLA is also a dataset from GLUE benchmark, whose task is a binary classification for sentences\u2014whether it is a grammatical English sentence. We exactly follow the experimental setup in SST-2.\\n\\nCora & CiteSeer & PubMed (Sen et al., 2008; Yang et al., 2016) are three widely adopted graph datasets whose tasks are node classification. Following FS-G (Wang et al., 2022), a community splitter is applied to each graph to generate five subgraphs for each client. We also split the nodes into train/valid/test sets, where the ratio is 60%:20%:20%.\\n\\nHetero-task is a graph classification dataset which is constructed referring to Graph-DC (Yao et al., 2022), which contains 5 clients. Each client has a different but similar graph classification task, such as molecular attribute prediction. In addition, we set the ratio of train/valid/test splits to 80%:10%:10%.\\n\\nTabular datasets consist of 7 tabular datasets from OpenML (Bischl et al., 2017), whose task ids (name of source data) are 31 (credit-g), 53 (vehicle), 3917 (kc1), 10101 (blood-transfusion-service-center), 146818 (Australian), 146821 (car) and 146822 (segment). We split each dataset into 5 clients by LDA, respectively. In addition, we set the ratio of train/valid/test splits to 80%:10%:10%.\\n\\nFedNetflix is a recommendation dataset from The Netflix Prize (Bennett & Lanning, 2007), whose task is to predict the ratings between users and movies. Netflix consists of around 100 million ratings between 480,189 users and 171,770 movies. We split the Netflix dataset into 480,189 clients by users. In addition, we set the ratio of train/valid/test splits to 80%:10%:10%.\\n\\nTwitter is a sentiment analysis dataset from LEAF (Caldas et al., 2018), whose task is to determine sentiment of sentences. We use a subsample of Twitter with around 3300 clients. Moreover, we use the train/valid/test splits for each client, where the ratio is 80% : 10% : 10%. It is worth noting that the average number of samples is only 1.94, which means some clients do not have valid split or test split, and we evaluate the performance on a shared test split merged by all clients.\"}"}
{"id": "wang23n", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we will discuss the system model in detail we have proposed and implemented. The total execution time of FL consists of the time consumed by communication and the time consumed by calculation; thus, the system model is as follows:\\n\\n$$T(f, \\\\lambda, b) = I \\\\cdot T_{\\\\text{comm}}(f, \\\\lambda, b) + T_{\\\\text{comp}}(f, \\\\lambda, b),$$\\n\\nwhere\\n\\n$$I$$ indicates whether the communication is needed in this round,\\n\\n$$N$$ denotes the number of clients sampled in this round,\\n\\n$$\\\\alpha(N)$$ denotes the latency, which is an increasing function of $$N$$ but is independent of the message size (contains the time needed to establish the transmission between the server and the clients),\\n\\n$$S(f, \\\\lambda)$$ denotes the download/upload size,\\n\\n$$B$$ denotes the download/upload bandwidth of client,\\n\\n$$T_{\\\\text{server}}(f, \\\\lambda, b)$$ is the time consumed by server-side computation, and\\n\\n$$T_{\\\\text{client}}(f, \\\\lambda, b)$$ denotes the computation time consumed by $$i$$-th client, which is sampled from an exponential distribution with $$c(f, \\\\lambda, b)$$ as its mean. This design intends to simulate the heterogeneity among clients' computational capacity, where the assumed exponential distribution has been widely adopted in system designs (Wang et al., 2021a) and is consistent with real-world applications (Huba et al., 2022).\\n\\nWe provide default parameters of our system model, including $$c(f, \\\\lambda, b)$$, $$B_{\\\\text{up}}$$, $$B_{\\\\text{down}}$$, and $$T_{\\\\text{server}}(f, \\\\lambda, b)$$, based on observations collected from FL trials we have conducted and real-world network bandwidth. Users are allowed to specify these parameters according to their scenarios or other system statistic providers, e.g., estimating the computation time of stragglers by sampling from FedScale (Lai et al., 2022). As for the network bandwidth, we set $$B_{\\\\text{down}} \\\\sim 0.75\\\\text{MB/secs}$$, $$B_{\\\\text{up}} \\\\sim 0.25\\\\text{MB/secs}$$ following (Lai et al., 2022; Wang et al., 2021a). The default value of $$c(f, \\\\lambda, b)$$ is obtained by averaging the recorded client-wise time costs in trials of tabular mode benchmarks. Due to the limit on the number of ports of the server, we set the default value of the maximum number of connections in calculating $$\\\\alpha(N)$$ to 65535. For most FedHPO methods, such as FedEx, we set $$I$$ constant equal to 1. But for some methods that communicate only in specific rounds, such as FLoRA, the value of $$I$$ needs to be configured accordingly.\\n\\nTo implement our system model, we use the following proposition to calculate Eq. 1 analytically, where we use $$c$$ as a shorthand for $$c(f, \\\\lambda, b)$$ to keep clarity.\\n\\n**Proposition E.1.** When the computation time of clients is identically independently distributed, following an exponential distribution $$\\\\text{Exp}(\\\\cdot|1c)$$, then the expected time for the straggler of $$N$$ uniformly sampled clients is $$\\\\mathbb{P}_{\\\\text{min}}\\\\{c_i\\\\}$$.\\n\\nWhat we need to calculate is the expected maximum of i.i.d. exponential random variable. Proposition E.1 states that, for $$N$$ exponential variables independently drawn from $$\\\\text{Exp}(\\\\cdot|1c)$$, the expectation is $$\\\\mathbb{P}_{\\\\text{min}}\\\\{c_i\\\\}$$. There are many ways to prove this useful proposition, and we provide proof starting by studying the minimum of the exponential random variables.\"}"}
{"id": "wang23n", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Proof. At first, the minimum of $N$ such random variables obeys $\\\\text{Exp}(\\\\cdot|Nc)$ (Graham et al., 1989). Denoting the $i$-th minimum of them by $T_i$, $T_1 \\\\sim \\\\text{Exp}(\\\\cdot|Nc)$ and $T_N$ is what we are interested in. Meanwhile, it is well known that exponential distribution is memoryless; namely, $\\\\Pr(X > s + t|X > s) = \\\\Pr(X > t)$. Thus, $T_2 - T_1$ obeys the same distribution as the minimum of $N - 1$ such random variables, that is to say, $T_2 - T_1$ is a random variable drawn from $\\\\text{Exp}(\\\\cdot|N - 1c)$. Similarly, $(T_{i+1} - T_i) \\\\sim \\\\text{Exp}(\\\\cdot|N - i c), i = 1, \\\\ldots, N - 1$. Thus, we have:\\n\\n$$E[T_N] = E[T_1 + N - 1 \\\\sum_{i=1}^{N-1} (T_{i+1} - T_i)] = cN + (N - 1) \\\\sum_{i=1}^{N-1} c = N \\\\sum_{i=1}^{N} c,$$\\n\\nwhich concludes this proof.\\n\\nIt is worth noting that we provide several optional system models. For example, for point-to-point transport protocols, $T_{\\\\text{comm}}$ should contain the time the server sends the model to each client.\\n\\nF. Details of the Implementations of FedEx and FTS\\n\\nWe first present a general algorithmic view in Fig. 6, which unifies several such methods as well as their personalized counterparts. At a high level, a policy $\\\\pi$ for determining the optimal lower-level response $\\\\lambda(c) = \\\\min \\\\lambda(c)f(\\\\lambda(s), \\\\lambda(c))$ is to be federally learned, along with the FL course itself. In the $t$-th communication round: (1) In addition to the model $\\\\theta(t)$, either the policy $\\\\pi(t)$ or its decisions $\\\\lambda(c)$ is also broadcasted. (2) For the $i$-th client, if $\\\\pi(t)$ is received, it needs to synchronize its local policy $\\\\pi(t)$ with this global one and then sample a hyperparameter configuration $\\\\lambda(c)$ from its local policy. (3) Either received or locally sampled, $\\\\lambda(c)$ is used to specify the local update procedure of FL, which results in updated local model $\\\\theta(t+1)$. (4) Then $\\\\theta(t+1)$ is evaluated to provide the result of (client-specific) function evaluation $f(c)\\\\lambda(c)$. (5) For personalized FedHPO methods that maintain a local policy $\\\\pi$, it is updated w.r.t. $(\\\\lambda, f(c))$ to produce $\\\\pi(t+1)$. (6) In addition to the local model $\\\\theta(t+1)$, either the local policy $\\\\pi(t+1)$ or the feedback $\\\\lambda(c), f(c)$ is sent to the server. (7) Finally, the server aggregates $\\\\theta(t+1)$ into $\\\\theta(t+1)$ and $\\\\pi(t+1)$ is/updated to produce $\\\\pi(t+1)$, respectively.\\n\\nIn FedEx (Khodak et al., 2021), $\\\\lambda$ are independently sampled from $\\\\pi$, and the aggregation operator \u201caggr\u201d is exponential gradient descent. In FTS (Dai et al., 2020), the broadcasted policy $\\\\pi(t)$ is the samples drawn from all clients\u2019 posterior beliefs. The synchronous operator \u201csync\u201d can be regarded as mixing Gaussian process (GP) models. The update operator \u201cupdate\u201d corresponds to updating the local GP model. Then a sample drawn from local GP posterior belief is regarded as $\\\\pi(t+1)$ and uploaded. Finally, the aggregation operator \u201caggr\u201d is packing received samples together.\\n\\nG. Studies about the New Fidelity\\n\\nIn FL, a larger client_sample_rate leads to a minor variance of the aggregated model in each round, which is believed to need less #round for convergence and to perform better. Therefore, we tend to set the client_sample_rate as close to 1 as possible. However, according to our system model in Sec. 4.2, a large client_sample_rate leads to an increase in latency ($\\\\alpha(N)$), which makes the communication cost higher. We use tabular mode and study the trade-off between these two fidelity dimensions: client_sample_rate and #round. We simulate two distinct system conditions by specifying different parameters for our system model.\\n\\nProtocol. We compare the performance of HB with different client_sample_rate s to learn a 2-layer CNN with 2,048 hidden units on FEMNIST. To simulate a system condition with bad network status, we set the upload bandwidth $B_{up}$ to 0.25MB/second and the download bandwidth $B_{down}$ to 0.75MB/second (Wang et al., 2021a). As for good network status, we set the upload bandwidth $B_{up}$ to 0.25GB/second and the download bandwidth $B_{down}$ to 0.75GB/second. In both cases, we consider different computation overhead so that it is negligible and significant, respectively. As for the rest settings, we largely follow that in Sec. 5.1.1.\\n\\nResults and Analysis. As shown in Fig. 7, with the same time budget, the FL procedure with a lower client_sample_rate achieves a better result than higher client_sample_rate with the bad network status. In comparison, that with a higher client_sample_rate achieves a better result than lower client_sample_rate in the good network status. In conclusion, this study suggests a best practice of pursuing a more economic accuracy-efficiency trade-off by balancing client_sample_rate.\"}"}
{"id": "wang23n", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7. Performances of different client_sample_rate under different system conditions.\\n\\nWith bad network status\\n\\n(a) With bad network status\\n\\n(b) With good network status\\n\\nH. Details on FedHPO-BENCH\u2019s Benchmarks\\n\\nFedHPO-BENCH consists of several categories of benchmarks on the different datasets (see Appendix D) with three modes. If not specified, we use the model as the name of the benchmark in the cross-silo scenario. In this part, we provide more details about how we construct the FedHPO problems provided by current FedHPO-BENCH and the three modes to interact with them.\\n\\nH.1. Category\\n\\nWe categorize our benchmarks by model types. Each benchmark is designed to solve specific FL HPO problems on its data domain, wherein CNN benchmark on CV, BERT benchmark on NLP, GNN benchmark on the graphs, and LR & MLP benchmark on tabular data. All benchmarks have several hyperparameters on configuration space and two on fidelity space, namely the sample rate of FL and FL round. And the benchmarks support several FL algorithms, such as FedAvg and FedOpt.\\n\\nCNN benchmark learns a two-layer CNN with 2048 hidden units on FEMNIST and 128 hidden units on CIFAR-10 with five hyperparameters on configuration space that tune the batch size of the dataloader, the weight decay, the learning rate, the dropout of the CNN models, and the step size of local training round in client each FL communication round. The tabular and surrogate mode of the CNN benchmark only supports FedAvg due to our limitations in computing resources for now, but we will update FedHPO-BENCH with more results as soon as possible.\\n\\nBERT benchmark fine-tunes a pre-trained language model, BERT-Tiny, which has two layers and 128 hidden units, on CoLA and SST-2. The configuration space of the BERT benchmark also contains five hyperparameters, the same as the CNN benchmark. In addition, the BERT benchmark supports FedAvg and FedOpt with all three modes.\\n\\nGNN benchmark learns a two-layer GCN with 64 hidden units on Cora, CiteSeer, and PubMed. The configuration space of the GNN benchmark contains four hyperparameters that tune the weight decay, the learning rate, the dropout of the GNN models, and the step size of the local training round in client each FL communication round. The GNN benchmark supports FedAvg and FedOpt with all three modes.\\n\\nHetero benchmark learns a two-layer GCN with 64 hidden units as the backbone. The configuration space of the Hetero benchmark contains two hyperparameters that tune the learning rate and the step size of the local training round in each FL communication round client. Each client has a personalized encoder and classifier to handle different tasks. Thus, compared to other benchmarks, the search space of the Hetero benchmark exponentially increases with the number of clients.\\n\\nLR benchmark learns an LR on seven tasks from OpenML, see Appendix D for details. The configuration space of the LR benchmark contains four hyperparameters that tune the batch size of the dataloader, the weight decay, the learning rate, and the step size of the local training round in client each FL communication round. The LR benchmark support FedAvg and FedOpt with all three modes.\"}"}
{"id": "wang23n", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Benchmark Name | Type | Log | #Bins | Range |\\n|----------------|------|-----|-------|-------|\\n| **CNN**        | Client | batch_size | int | \u00d7 | {16, 32, 64} |\\n|                |       | weight_decay | float | \u00d7 | [0, 0.001] |\\n|                |       | dropout      | float | \u00d7 | [0, 0.5] |\\n|                |       | step_size    | int | \u00d7 | [1, 4] |\\n|                |       | learning_rate | float | \u2713 | [0.01, 1.0] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 500] |\\n| **BERT**       | Client | batch_size | int | \u00d7 | {8, 16, 32, 64, 128} |\\n|                |       | weight_decay | float | \u00d7 | [0, 0.001] |\\n|                |       | dropout      | float | \u00d7 | [0, 0.5] |\\n|                |       | step_size    | int | \u00d7 | [1, 4] |\\n|                |       | learning_rate | float | \u2713 | [0.01, 1.0] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 40] |\\n| **GNN**        | Client | weight_decay | float | \u00d7 | [0, 0.001] |\\n|                |       | dropout      | float | \u00d7 | [0, 0.5] |\\n|                |       | step_size    | int | \u00d7 | [1, 8] |\\n|                |       | learning_rate | float | \u2713 | [0.01, 1.0] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 500] |\\n| **Hetero**     | Client | learning_rate | float | \u2713 | [0.001, 0.01] |\\n|                |       | step_size    | int | \u00d7 | [1, 4] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 500] |\\n| **LR**         | Client | batch_size | int | \u2713 | [4, 256] |\\n|                |       | weight_decay | float | \u00d7 | [0, 0.001] |\\n|                |       | step_size    | int | \u00d7 | [1, 4] |\\n|                |       | learning_rate | float | \u2713 | [0.00001, 1.0] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 500] |\\n| **MLP**        | Client | batch_size | int | \u2713 | [4, 256] |\\n|                |       | weight_decay | float | \u00d7 | [0, 0.001] |\\n|                |       | step_size    | int | \u00d7 | [1, 4] |\\n|                |       | learning_rate | float | \u2713 | [0.00001, 1.0] |\\n|                |       | depth        | int | \u00d7 | [1, 3] |\\n|                |       | width        | int | \u2713 | [16, 1024] |\\n| **Server**     |       | momentum     | float | \u00d7 | [0.0, 0.9] |\\n|                |       | learning_rate | float | \u00d7 | [0.1, 1.0] |\\n| **Fidelity**   |       | client_sample_rate | float | \u00d7 | [0.2, 1.0] |\\n|                |       | round        | int | \u00d7 | [1, 500] |\"}"}
{"id": "wang23n", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FEDHPO-BENCH: A Benchmark Suite for Federated Hyperparameter Optimization\\n\\nMLP benchmark's the vast majority of settings are the same as the LR benchmark. But in particular, we add depth and width of the MLP to search space in terms of the model architecture. The MLP benchmark also supports FedAvg and FedOpt with all three modes.\\n\\nCross-device. In cross-device scenarios (Chen et al., 2023), there can be a large number of clients in total, but only a few participate in each communication round. This benchmark contains two datasets, Twitter and FedNetflix. We use a bag of words model with LR and tune the learning_rate, weight_decay, and step_size of the local training round in Twitter. As for FedNetflix, we tune an HMFNet (Li et al., 2021c) in the learning_rate, batch_size, and step_size of local training round. Due to the time limit, the results FedNetflix is incomplete, and we present the ECDF of Twitter in Fig. 8.\\n\\nH.2. Mode Following HPOBench (Eggensperger et al., 2021), FEDHPO-BENCH provides three different modes for function evaluation: the tabular mode, the surrogate mode, and the raw mode. The valid input hyperparameter configurations and the speed of acquiring feedback vary from mode to mode. Users can choose the desired mode according to the purposes of their experiments.\\n\\nTabular mode. The idea is to evaluate the performance of many different hyperparameter configurations in advance so that users can acquire their results immediately. For efficient function evaluation, we implement the tabular mode of FEDHPO-BENCH by running the FL algorithms configured by the grid search space in advance from our original search space (see Table 7). For hyperparameters whose original search space is discrete, we just preserve its original one. As for continuous ones, we discretize them into several bins (also see Table 7 for details). We execute the FL procedure in the Docker container environment to ensure the results are reproducible. Each specific configuration $\\\\lambda$ is repeated three times with different random seeds, and the performances, including loss, accuracy, and f1-score under train/validation/test splits, are averaged and adopted as the results of $f(\\\\lambda)$. Users can choose the desired metric as the output of the black-box function via FEDHPO-BENCH's APIs. Besides, we provide not only the results of $f(\\\\lambda)$ (i.e., that with full-fidelity) but also results of $f(\\\\lambda, b)$, where $b$ is enumerated across different #round and different client_sample_rate. Since executing function evaluation is much more costly in FL than traditional centralized learning, such lookup tables are precious. In creating them, we spent about two months of computation time on six machines, each with four Nvidia V100 GPUs. Now we make them publicly accessible via the tabular mode of FEDHPO-BENCH.\\n\\nSurrogate mode. As tabular mode has discretized the original search space and thus cannot respond to queries other than the grids, we train random forest models on these lookup tables, i.e., $\\\\{(\\\\lambda, b), f(\\\\lambda, b)\\\\}$. These models serve as a surrogate of the functions to be optimized and can answer any query $\\\\lambda$ by simply making an inference. Specifically, we conduct 10-fold cross-validation to train and evaluate random forest models (implemented in scikit-learn (Pedregosa et al., 2011)) on the tabular data. Meanwhile, we search for suitable hyperparameters for the random forest models with the number of trees in {10, 20} and the max depth in {10, 15, 20}. The mean absolute error (MAE) of the surrogate model w.r.t. the true value is within an acceptable threshold. For example, in predicting the true average loss on the CNN benchmark, the surrogate model has a training error of 0.00609 and a testing error of 0.00777. In addition to the off-the-shelf surrogate models we provide,\"}"}
{"id": "wang23n", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FedHPO-BENCH offers tools for users to build brand-new surrogate models. Meanwhile, we notice the recent successes of neural network-based surrogate, e.g., YAHPO Gym (Pfisterer et al., 2022), and we will also try it in the next version of FedHPO-BENCH.\\n\\nRaw mode. Although both of the above modes can respond quickly, they are limited to pre-designed search space. Thus, we introduce raw mode to FedHPO-BENCH, where user-defined search spaces are allowed. Once FedHPO-BENCH\u2019s APIs are called with specific hyperparameters, a containerized and standalone FL procedure (supported by FS) will be launched. It is worth noting that although we use standalone simulation to eliminate the communication cost, the raw mode still consumes much more computation cost than tabular and surrogate modes.\\n\\nH.3. New Hyperparameters\\n\\nThe FL setting introduces new hyperparameters such as server-side learning_rate, momentum for FedOpt (Asad et al., 2020) and client-side #local_update_step. Different FL algorithms have different parameters, which correlate with hyperparameters related to general ML procedures. In this section, we first adopt FedProx (Li et al., 2020b) to study the impact of server-side hyperparameters mu, the coefficient of the regular term, on the results. And then we compare the landscape of federated learning and non-federated methods.\\n\\nFigure 9. Landscape with the hyperparameters of the ML algorithm on FEMNIST.\\n\\n| \u03f5  | learning_rate | weight_decay | dropout | step_size | Test Acc. (%)\\n|----|---------------|--------------|---------|-----------|----------------\\n| 1  | 1.0           | 0.001        | 0.5     | 7         | 63.87 \u00b1 6.38  |\\n| 10 | 0.59948       | 0.0          | 0.5     | 6         | 87.02 \u00b1 1.16  |\\n| 20 | 0.59948       | 0.001        | 0.5     | 6         | 87.30 \u00b1 0.54  |\\n\\nTable 8. Best configuration with different levels of privacy budgets in Cora.\\n\\nH.3.1. Trends with Different Regularity in FedProx\\n\\nTo extend the tabular benchmarks with more FL algorithms, we adopt FedProx (Li et al., 2020b) to the GNN benchmark. Based on Table 7, we tune the server-side hyperparameters mu, the coefficient of the regular term, in {0.1, 1.0, 5.0} to study the trends with different regularity in FedProx. We show the landscape in Fig. 10 with a learning rate in [0.01, 1.0] and mu in [0.1, 5.0], and we observe that when the learning rate is low, the effect of mu has little impact on the accuracy; however, when the learning rate is large, the increase of mu can seriously damage the accuracy.\\n\\n23\"}"}
{"id": "wang23n", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, to study the validation loss landscape of the federated learning method (FedAvg) and non-federated method (Isolated), we consider learning rate and batch size, the hyperparameters of the ML algorithm, as the coordinate axis to build the loss landscapes. We fix other ML-related hyperparameters weight_decay to 0.0, dropout to 0.5 for both FedAvg and Isolated, which is the best configuration chosen from the tabular benchmark <CNN, FEMNIST, FedAvg> under 1.0 client_sample_rate. As the loss landscapes shown in Fig. 9 with learning rate in [0.01, 1.0] and batch size in 16, 32, 64, we observe that the FedAvg with a higher learning rate achieves better results, while the non-federated method (Isolated) prefers a lower learning rate. Their differences suggest the uniqueness of FedHPO\u2019s objective functions.\\n\\nH.4. Data Analytics\\n\\nH.4.1. Trends in Different Privacy Budgets\\nWe extend the tabular benchmarks with different levels of privacy budgets in FEMNIST and Cora. To explore the trends of optimal configurations under different privacy budgets, we adopt NbAFL (Wei et al., 2020) with \\\\( \\\\epsilon \\\\in \\\\{1, 10, 20\\\\} \\\\). We observe that the best configuration varies under different levels of privacy budgets in Cora, as shown in Table 8. Under different privacy budgets, a large step_size all leads to a good performance. However, when the noise is intense, a higher learning_rate is preferred, while a lower learning_rate will perform better when the noise is weak.\\n\\nH.4.2. Errors of Surrogate Benchmarks\\nAs we mentioned in Sec. H.2, we report the regression error of the training surrogate model in Table 9. Meanwhile, we present the mean rank over time of optimizers with surrogate modes in Fig. 23 and Fig. 24. Compared to the results of tabular modes in Fig. 14 and Fig. 15, BO GP shows good performance in both modes, while Random Search does not. This shows the consistent performance of the same optimizer when it interplays with surrogate and tabular benchmarks.\\n\\n| Model    | Dataset | Algo. | Train MAE | Test MAE |\\n|----------|---------|-------|-----------|----------|\\n| CNN      | FEMNIST | FedAvg| 0.00609   | 0.00777  |\\n| BERT     | CoLA    | FedAvg| 0.04724   | 0.05454  |\\n| SST2     | FedAvg  | FedOpt| 0.02426   | 0.02959  |\\n| SST2     | FedAvg  | FedOpt| 0.02597   | 0.03227  |\\n| GNN      | Cora    | FedAvg| 0.04702   | 0.04839  |\\n| CiteSeer | FedAvg  | FedOpt| 0.05703   | 0.05893  |\\n| PubMed   | FedAvg  | FedOpt| 0.04042   | 0.04148  |\\n\\nTable 9. The regression error of surrogate models.\\n\\nH.4.3. Variance of Different Sample Rate\\nAs we build our tabular benchmark from FL courses executed in docker images provided by FS, we can fully reproduce all the results given the same random seed in raw mode. Other than that, to study the noise of different federated optimization, we analyze the variance of validation loss with 500 rounds under different sample rates in FEMNIST. And the average standard deviation validation loss is \\\\{1.945e-2, 1.7e-2, 1.728e-2, 1.715e-2, 1.43e-2\\\\} with sample rate \\\\{0.2, 0.4, 0.6, 0.8, 1.0\\\\}, which shows that the higher sample rate tends to have lower variance. The reason is apparent: the lower the sampling rate, the more inconsistent the set of clients sampled during the training process leads to this error.\\n\\nH.4.4. ECDF with Different Heterogeneity\\nWe extend our LR benchmarks with different heterogeneity settings. As we discussed in Appendix D, we split the tabular dataset with LDA, whose \\\\( \\\\alpha \\\\) is in \\\\{0.1, 0.5, 0.7\\\\} (the smaller the alpha, the more the heterogeneous). We show the ECDF of the normalized regret of evaluated configurations with different \\\\( \\\\alpha \\\\) in Fig. 11, which shows that as the \\\\( \\\\alpha \\\\) decreases, it is harder...\"}"}
{"id": "wang23n", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 10.\\n\\nLandscape with the different regularity of FedProx on Cora.\\n\\nFigure 11.\\n\\nEmpirical Cumulative Distribution Functions with different heterogeneity in LR benchmark.\\n\\nI. More Results\\n\\nIn this section, we show the more detailed experimental results. We first report the details about the sign test for comparing optimizers as mentioned in Sec. 5.1.1. Then, we present the details about the experiment of concurrent exploration. Moreover, we report the averaged best-ever-seen validation loss, from which the mean rank over time for all optimizers can be deduced in Appendix I.3-I.4.\\n\\nI.1. Sign test for comparing optimizers\\n\\nFollowing HPOBench, we use sign tests to judge (1) whether advanced methods outperform their baselines and (2) whether multi-fidelity methods outperform their single-fidelity counterparts. We refer our readers to Appendix C for more details. We consider optimizers' final performances on all the considered FedHPO problems, where one may win, tie, or lose against the other for each pair of optimizers. Then we can conduct sign tests to compare pairs of optimizers, where results are presented in Table 10 and Table 11. Comparing model-based optimizers with their baselines, almost all model-based optimizers have no significant improvement, which is inconsistent with the non-FL setting (Eggensperger et al., 2021). It is worth noting that a similar phenomenon can also be observed for HPO problems in general (Pushak & Hoos, 2022).\"}"}
{"id": "wang23n", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"I.2. Details about concurrent exploration\\n\\nFL allows HPO methods to take advantage of concurrent exploration, which somewhat compensates for the number of function evaluations. We are interested in methods designed regarding these characteristics of FedHPO and design this experiment to see how much concurrent exploration contributes. i.e., FedAvg is applied to learn a 2-layer CNN on FEMNIST for the former FedHPO problem, and FedAvg is applied to learn a 2-layer GNN on PubMed for the latter. As a full-fidelity function evaluation consumes 500 rounds on these datasets, we specify RS, BO, GP, BO, RF, BO, KDE, HB, and BOHB to limit their total budget to $2 \\\\times 500$ (i.e., 5 times budget of a full-fidelity evaluation) in terms of #round. And we get the mean validation cross-entropy loss over budget in FEMNIST in Fig. 12.\\n\\nFollowing the protocol in Sec. 5.1.2, yet focusing on <FedNetflix, MF, FedAvg>, the averaged test MAE (the smaller, the better) is reported in Fig. 12. Compared to Tab. 2 in our paper, the empirical studies on FedNetflix also show that most X+FedEx\u2019s searched configurations show significantly better generalization performances than their wrappers (i.e., $X$ (a traditional optimizer)), strongly confirming the effectiveness of concurrent exploration.\\n\\nI.3. Tabular mode\\n\\nFollowing Sec. 5.1.1, we show the overall mean rank overtime on all FedHPO problems with FedOpt, whose pattern is similar to that of FedAvg in Fig. 4. Then, we report the final results with FedAvg and FedOpt in Table 13 and 14, respectively. Finally, we report the mean rank over time in Fig. 14-22. Due to time and computing resource constraints, the results on the CNN benchmark are incomplete (lacking that with FedOpt), which we will supplement as soon as possible.\\n\\nI.4. Surrogate mode\\n\\nWe report the final results with FedAvg on FEMNIST and BERT benchmarks in Table 15. Then we present the mean rank over time of the optimizers in Fig. 23 and Fig. 24.\\n\\nTable 10. P-value of a sign test for the hypothesis\u2014these advanced methods surpass the baselines.\\n\\n| optimizer | p-value against RS | win-tie-loss |\\n|----------|-------------------|-------------|\\n| BO       | 0.0637            | 13 / 0 / 7  |\\n| GP       | 0.2161            | 12 / 0 / 8  |\\n| BO       | 0.1649            | 7 / 0 / 13  |\\n| RF       | 0.7561            | 11 / 0 / 9  |\\n| KDE      | 0.4523            | 7 / 0 / 13  |\\n| DE       | 0.9854            | 9 / 0 / 11  |\\n| HB       | 0.2942            | 9 / 0 / 11  |\\n| BOHB     | 0.2454            | 9 / 0 / 11  |\\n\\nTable 11. P-values of a sign test for the hypothesis\u2014these advanced methods surpass baseline.\\n\\n| optimizer | p-value against BOHB | win-tie-loss |\\n|----------|-----------------------|-------------|\\n| DE       | 0.7401                | 9 / 0 / 11  |\\n| TPE      | 0.0012                | 11 / 0 / 9  |\\n| HB       | 0.1234                | 11 / 0 / 9  |\\n| TPE      | 0.0012                | 11 / 0 / 9  |\"}"}
{"id": "wang23n", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 11. P-value of a sign test for the hypothesis that MF methods surpass corresponding BBO methods.\\n\\n| Method | HB vs. RS | DEHB vs. DE | BOHB vs. BO |\\n|--------|----------|-------------|-------------|\\n| p-value | 0.1139 | 0.2942 | 0.0106 |\\n| win-tie-loss | 13 / 0 / 7 | 13 / 0 / 7 | 16 / 0 / 4 |\\n\\nTable 12. Compare the searched configurations: Mean absolute error. The upward arrow indicates improvements.\\n\\n| Method | FedNetflix W/O FedEx | W/ FedEx |\\n|--------|----------------------|---------|\\n| RS     | 1.384850             | 1.419744|\\n| BO     | 1.430895             | 1.423417|\\n| GP     | 1.419744             | 1.423417|\\n| BO     | 1.352397             | 1.336225|\\n| RF     | 1.352397             | 1.336225|\\n| KDE    | 1.357617             | 1.346154|\\n| HB     | 1.272980             | 1.232069|\\n| BOHB   | 1.321204             | 1.264139|\\n\\nFigure 13. Mean rank over time on all FedHPO problems (with FedOpt).\\n\\nTable 13. Final results of the optimizers on tabular mode with FedAvg (lower is better).\\n\\n| Benchmark | RS | BO | GP | BO | RF | BO | KDE | HB | BOHB | DEHB | TPE | MD |\\n|-----------|----|----|----|----|----|----|-----|----|------|------|-----|----|\\n| CNN       | 0.4969\u00b10.0054 | 0.4879\u00b10.0051 | 0.4885\u00b10.0065 | 0.5004\u00b10.0068 | 0.4928\u00b10.0054 | 0.4926\u00b10.0052 | 0.4945\u00b10.0059 | 0.498\u00b10.0061 | 0.5163\u00b10.0028 | 0.5148\u00b10.0047 | (c) All |\\n| FEMNIST   | 0.435\u00b10.0142 | 0.4276\u00b10.0082 | 0.4294\u00b10.0071 | 0.4334\u00b10.0081 | 0.437\u00b10.0052 | 0.4311\u00b10.0151 | 0.4504\u00b10.0441 | 0.4319\u00b10.0251 | 0.4341\u00b10.0044 | 0.4251\u00b10.0076 | (c) All |\\n| SST-2     | 0.6151\u00b10.0014 | 0.6148\u00b10.0014 | 0.6141\u00b10.0016 | 0.6133\u00b10.0022 | 0.6143\u00b10.0006 | 0.6143\u00b10.0016 | 0.6168\u00b10.0025 | 0.6178\u00b10.0025 | 0.6158\u00b10.0014 | 0.6146\u00b10.0018 | (c) All |\\n| CoLA      | 0.3265\u00b10.0042 | 0.3258\u00b10.0062 | 0.3260\u00b10.0063 | 0.3347\u00b10.0078 | 0.3267\u00b10.0066 | 0.3324\u00b10.0136 | 0.3288\u00b10.0030 | 0.3225\u00b10.0039 | 0.3241\u00b10.0014 | 0.3249\u00b10.0020 | (c) All |\\n| GNN       | 0.6469\u00b10.0052 | 0.6442\u00b10.0046 | 0.6499\u00b10.0069 | 0.6442\u00b10.0089 | 0.6453\u00b10.0061 | 0.6387\u00b10.0077 | 0.6425\u00b10.0054 | 0.6452\u00b10.0030 | 0.6324\u00b10.0070 | 0.6371\u00b10.0051 | (c) All |\\n| Cora      | 0.5262\u00b10.0167 | 0.5146\u00b10.0136 | 0.5169\u00b10.0193 | 0.5311\u00b10.0110 | 0.5001\u00b10.0082 | 0.5006\u00b10.0144 | 0.5194\u00b10.0212 | 0.4934\u00b10.0010 | 0.5060\u00b10.0179 | 0.5044\u00b10.0150 | (c) All |\\n| PubMed    | 0.6821\u00b10.1299 | 0.6308\u00b10.0292 | 0.6382\u00b10.0435 | 0.6385\u00b10.0459 | 0.667\u00b10.0888 | 0.6492\u00b10.0187 | 0.6461\u00b10.0472 | 0.6145\u00b10.0242 | 0.7228\u00b10.0427 | 0.758\u00b10.0460 | (c) All |\\n| LR        | 1.6297\u00b10.1628 | 1.7288\u00b10.2306 | 1.6116\u00b10.2017 | 1.7142\u00b10.1663 | 1.6062\u00b10.1487 | 1.5765\u00b10.1416 | 1.5634\u00b10.1993 | 1.4755\u00b10.1126 | 1.5506\u00b10.0010 | 1.5506\u00b10.0010 | (c) All |\\n| LR        | 1.8892\u00b10.2647 | 1.7561\u00b10.2538 | 1.7186\u00b10.3562 | 2.4271\u00b11.1596 | 1.7519\u00b10.6093 | 3.948\u00b12.5432 | 1.6384\u00b10.1849 | 3.1183\u00b12.9336 | 2.1344\u00b11.0268 | 2.6576\u00b11.1446 | (c) All |\\n| LR        | 0.548\u00b10.0002  | 0.5483\u00b10.0002 | 0.5482\u00b10.0003 | 0.5487\u00b10.0008 | 0.5481\u00b10.0002 | 0.5504\u00b10.0049 | 0.5505\u00b10.0047 | 0.5516\u00b10.0064 | 0.5483\u00b10.0009 | 0.5487\u00b10.0017 | (c) All |\\n| LR        | 0.5294\u00b10.0006 | 0.5291\u00b10.0002 | 0.5295\u00b10.0006 | 0.5289\u00b10.0004 | 0.5291\u00b10.0007 | 0.5292\u00b10.0008 | 0.529\u00b10.0004 | 0.5293\u00b10.0002 | 0.5328\u00b10.0055 | 0.5387\u00b10.0186 | (c) All |\\n| LR        | 0.4733\u00b10.0025 | 0.464\u00b10.0068  | 0.4722\u00b10.0123 | 0.4843\u00b10.0205 | 0.4971\u00b10.0312 | 0.4678\u00b10.0109 | 0.4747\u00b10.0127 | 0.4707\u00b10.0095 | 0.4792\u00b10.0083 | 0.4688\u00b10.0086 | (c) All |\\n| LR        | 0.4581\u00b10.0202 | 0.4481\u00b10.0102 | 0.4505\u00b10.0182 | 0.4731\u00b10.0197 | 0.4587\u00b10.0118 | 0.4478\u00b10.0122 | 0.4446\u00b10.0066 | 0.4304\u00b10.0071 | 0.4376\u00b10.0071 | 0.4419\u00b10.0089 | (c) All |\\n| MLP       | 0.5899\u00b10.0032 | 0.5891\u00b10.0052 | 0.5808\u00b10.0094 | 0.5904\u00b10.0035 | 0.5925\u00b10.0008 | 0.5921\u00b10.0017 | 0.5929\u00b10.0001 | 0.593\u00b10.0001 | 0.593\u00b10.0000 | 0.593\u00b10.0000 | (c) All |\\n| MLP       | 0.7795\u00b10.0156 | 0.7373\u00b10.0186 | 0.7849\u00b10.0215 | 0.8215\u00b10.1220 | 0.8068\u00b10.0752 | 0.769\u00b10.0226 | 0.7577\u00b10.0222 | 0.8173\u00b10.1407 | 0.9491\u00b10.0951 | 1.0567\u00b10.0158 | (c) All |\\n| MLP       | 0.3863\u00b10.0099 | 0.3937\u00b10.0094 | 0.3858\u00b10.0105 | 0.3958\u00b10.0088 | 0.383\u00b10.0074  | 0.3895\u00b10.0049 | 0.3911\u00b10.0079 | 0.4084\u00b10.0407 | 0.3979\u00b10.0035 | 0.3988\u00b10.0036 | (c) All |\\n| MLP       | 0.4054\u00b10.0113 | 0.4217\u00b10.0065 | 0.4361\u00b10.0124 | 0.4162\u00b10.0154 | 0.418\u00b10.0083  | 0.4137\u00b10.0109 | 0.4152\u00b10.0142 | 0.4102\u00b10.0109 | 0.4522\u00b10.0491 | 0.4352\u00b10.0407 | (c) All |\\n| MLP       | 0.5089\u00b10.0092 | 0.4997\u00b10.0072 | 0.5125\u00b10.0076 | 0.5112\u00b10.0049 | 0.5138\u00b10.0107 | 0.5009\u00b10.0043 | 0.5199\u00b10.0118 | 0.5039\u00b10.0060 | 0.5392\u00b10.0129 | 0.54\u00b10.0197  | (c) All |\\n| MLP       | 0.184\u00b10.0187  | 0.1251\u00b10.0167 | 0.155\u00b10.0183  | 0.1769\u00b10.0410 | 0.1851\u00b10.0236 | 0.1561\u00b10.0279 | 0.1683\u00b10.0291 | 0.1572\u00b10.0305 | 0.1654\u00b10.0422 | 0.1761\u00b10.0409 | (c) All |\\n| MLP       | 0.2839\u00b10.0259 | 0.2892\u00b10.0363 | 0.317\u00b10.0147  | 0.3586\u00b10.0754 | 0.2928\u00b10.0325 | 0.2927\u00b10.0233 | 0.2823\u00b10.0445 | 0.2549\u00b10.0176 | 0.2745\u00b10.0334 | 0.2755\u00b10.0221 | (c) All |\"}"}
{"id": "wang23n", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 14. Final results of the optimizers on tabular mode with FedOpt (lower is better).\\n\\n| benchmark | RS | BO | GP | BO | RF | BO | KDE | DE | HB | BOHB | DEHB | TPE | MD |\\n|-----------|----|----|----|----|----|----|-----|----|----|------|------|-----|----|\\n| BERT      | 0.441 \u00b1 0.0049 | 0.4325 \u00b1 0.0125 | 0.4301 \u00b1 0.0087 | 0.4463 \u00b1 0.0093 | 0.4351 \u00b1 0.0185 | 0.4403 \u00b1 0.0064 | 0.4295 \u00b1 0.0066 | 0.4285 \u00b1 0.0068 | 0.4293 \u00b1 0.0106 | 0.4332 \u00b1 0.0122 |\\n| SST-2     | 0.6160 \u00b1 0.0008 | 0.6160 \u00b1 0.0011 | 0.6141 \u00b1 0.0022 | 0.6137 \u00b1 0.0025 | 0.6159 \u00b1 0.0005 | 0.6154 \u00b1 0.0013 | 0.6157 \u00b1 0.0018 | 0.6176 \u00b1 0.0004 | 0.6172 \u00b1 0.0005 | 0.6168 \u00b1 0.0004 |\\n| GNN       | 0.3264 \u00b1 0.0027 | 0.3235 \u00b1 0.0004 | 0.3268 \u00b1 0.0032 | 0.3322 \u00b1 0.0101 | 0.3256 \u00b1 0.0009 | 0.3245 \u00b1 0.0014 | 0.3347 \u00b1 0.0121 | 0.3254 \u00b1 0.0008 | 0.3405 \u00b1 0.0129 | 0.3361 \u00b1 0.0187 |\\n| Cora      | 0.6483 \u00b1 0.0028 | 0.6517 \u00b1 0.0053 | 0.6497 \u00b1 0.0050 | 0.6535 \u00b1 0.0072 | 0.6458 \u00b1 0.0028 | 0.6442 \u00b1 0.0034 | 0.6543 \u00b1 0.0112 | 0.6463 \u00b1 0.0029 | 0.6488 \u00b1 0.0008 | 0.6495 \u00b1 0.0007 |\\n| PubMed    | 0.4777 \u00b1 0.0118 | 0.4426 \u00b1 0.0132 | 0.4718 \u00b1 0.0204 | 0.4943 \u00b1 0.0359 | 0.4318 \u00b1 0.0001 | 0.4559 \u00b1 0.0135 | 0.4699 \u00b1 0.0248 | 0.4318 \u00b1 0.0001 | 0.4368 \u00b1 0.0098 | 0.4402 \u00b1 0.0167 |\\n| LR        | 0.7358 \u00b1 0.0937 | 0.6831 \u00b1 0.0198 | 0.6849 \u00b1 0.0523 | 0.8152 \u00b1 0.1180 | 0.7085 \u00b1 0.0660 | 0.6772 \u00b1 0.0527 | 0.6877 \u00b1 0.0561 | 0.6385 \u00b1 0.0498 | 0.8652 \u00b1 0.0851 | 0.7044 \u00b1 0.0403 |\\n| 31        | 1.7838 \u00b1 0.2698 | 1.5609 \u00b1 0.1957 | 1.5241 \u00b1 0.0547 | 1.5116 \u00b1 0.0437 | 1.6208 \u00b1 0.3794 | 1.6045 \u00b1 0.2433 | 1.7236 \u00b1 0.4056 | 1.3488 \u00b1 0.1343 | 1.6654 \u00b1 0.2338 | 1.7978 \u00b1 0.2937 |\\n| 53        | 2.254 \u00b1 0.5724 | 2.0316 \u00b1 0.5246 | 2.3952 \u00b1 0.7949 | 1.9788 \u00b1 0.5290 | 2.6261 \u00b1 0.5535 | 2.3472 \u00b1 1.2238 | 2.5452 \u00b1 0.5266 | 2.3144 \u00b1 0.8685 | 3.2131 \u00b1 2.2754 | 2.0291 \u00b1 0.3674 |\\n| 3917      | 0.5533 \u00b1 0.0078 | 0.5500 \u00b1 0.0036 | 0.5505 \u00b1 0.0032 | 0.5509 \u00b1 0.0032 | 0.549 \u00b1 0.0012 | 0.5504 \u00b1 0.0029 | 0.5476 \u00b1 0.0017 | 0.5522 \u00b1 0.0056 | 0.5612 \u00b1 0.0201 | 0.8567 \u00b1 0.6019 |\\n| 10101     | 0.511 \u00b1 0.0099 | 0.506 \u00b1 0.0103 | 0.5034 \u00b1 0.0097 | 0.5133 \u00b1 0.0078 | 0.5007 \u00b1 0.0021 | 0.5032 \u00b1 0.0054 | 0.5086 \u00b1 0.0067 | 0.4974 \u00b1 0.0030 | 0.4983 \u00b1 0.0049 | 0.5104 \u00b1 0.0157 |\\n| 146818    | 0.4943 \u00b1 0.0018 | 0.4913 \u00b1 0.0108 | 0.5022 \u00b1 0.0090 | 0.5023 \u00b1 0.0113 | 0.4884 \u00b1 0.0058 | 0.4995 \u00b1 0.0087 | 0.5046 \u00b1 0.0298 | 0.4921 \u00b1 0.0293 | 0.4978 \u00b1 0.0135 | 0.4861 \u00b1 0.0240 |\\n| 146821    | 0.1169 \u00b1 0.0128 | 0.0836 \u00b1 0.0132 | 0.0915 \u00b1 0.0149 | 0.1674 \u00b1 0.0600 | 0.1079 \u00b1 0.0444 | 0.0891 \u00b1 0.0150 | 0.1389 \u00b1 0.0465 | 0.0838 \u00b1 0.0270 | 0.1051 \u00b1 0.0138 | 0.1194 \u00b1 0.0130 |\\n| 146822    | 0.2963 \u00b1 0.0264 | 0.2914 \u00b1 0.0215 | 0.2705 \u00b1 0.0240 | 0.3025 \u00b1 0.0447 | 0.2779 \u00b1 0.0063 | 0.2759 \u00b1 0.0216 | 0.2621 \u00b1 0.0201 | 0.2549 \u00b1 0.0108 | 0.2570 \u00b1 0.0020 | 0.2518 \u00b1 0.0055 |\\n\\nTable 15. Final results of the optimizers in surrogate mode (lower is better).\\n\\n| benchmark | RS | BO | GP | BO | RF | BO | KDE | DE | HB | BOHB | DEHB | TPE | MD |\\n|-----------|----|----|----|----|----|----|-----|----|----|------|------|-----|----|\\n| CNN       | 0.0508 | 0.0478 | 0.0514 | 0.0492 | 0.0503 | 0.0478 | 0.048 | 0.0469 | 0.0471 | 0.0458 |\\n| BERT      | 0.4909 | 0.4908 | 0.4908 | 0.4908 | 0.4908 | 0.4908 | 0.4908 | 0.4917 | 0.4908 | 0.4908 |\\n| CoLA      | 0.5013 | 0.4371 | 0.4113 | 0.487 | 0.444 | 0.4621 | 0.4232 | 0.4204 | 0.3687 | 0.3955 |\\n\\nFigure 14. Mean rank over time on CNN benchmark (FedAvg).\"}"}
