{"id": "dai22a", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nModel: How can you have so many pancakes?\\n\\nDocument: I love pancakes like a fat kid loves cake.\\n\\nModel: I guess your body requires them as your emotional needs.\\n\\nDocument: You want to know the sad part?\\n\\nModel: Go ahead.\\n\\nDocument: I\u2019m TERRIBLE at making pancakes.\\n\\nTable 7.\\n\\nExample of inpainting a less-formal document.\\n\\nIn Table 7, we would also like to share an example where inpainting yields more natural dialog when applied to a less-formal document.\\n\\nF. Additional Experimental Results\\n\\nTable 8 reports additional retrieval metrics in addition to the MRR reported in Table 3. Specifically, we report recall and mean reciprocal rank at rank 5 (R@5 and MRR@5) following previous work Qu et al. (2020); Yu et al. (2021). On QReCC, we report recall at rank 10 (R@10) and mean reciprocal rank without rank cut off (MRR) following Anantha et al. (2021); Wu et al. (2021). On TREC CAsT-19 and CAsT-20, we use the official metrics MRR and NDCG@3 suggested by Dalton et al. (2019; 2020). Note that TREC CAsT-19 uses relevant grade \\\\( \\\\geq 1 \\\\) as positive for MRR but TREC CAsT-20 uses relevance grade \\\\( \\\\geq 2 \\\\) as positive for MRR (Dalton et al., 2020).\\n\\n| System              | MRR | R@10 | MRR@5 | R@5  | MRR  | NDCG@3 | MRR  | NDCG@3 |\\n|---------------------|-----|------|-------|------|------|--------|------|--------|\\n| BM25-QR             | \u2013   | \u2013    | 20.2  | 30.2 | 58.1 | 27.7   | 25.0 | 15.9   |\\n| ANCE-QR             | \u2013   | \u2013    | 45.7  | 58.4 | 66.5 | 40.9   | 37.5 | 25.5   |\\n| ConvDR              | \u2013   | \u2013    | 61.6  | 75.0 | 74.0 | 46.6   | 50.1 | 34.0   |\\n| BM25-T5QR           | 32.8| 52.5 | \u2013     | \u2013    | \u2013    | \u2013      | \u2013    | \u2013      |\\n| CONQRR              | 41.8| 65.1 | \u2013     | \u2013    | \u2013    | \u2013      | \u2013    | \u2013      |\\n| T5-Large DE         | 55.7| 78.7 | 56.9  | 69.7 | 61.0 | 32.5   | 34.3 | 19.9   |\\n| \u22bf WIKI              | 60.4| 83.3 | 66.5  | 77.9 | 68.1 | 40.3   | 43.7 | 27.9   |\\n| \u22bf WIKI + W EB       | 60.7| 83.1 | 68.7  | 80.3 | 74.1 | 47.0   | 51.3 | 33.2   |\\n| Retrieval + Reranking|     |      | 71.4  |     |     | 43.6   |     |       |\\n| CFDA                | \u2013   | \u2013    | \u2013     | \u2013    | 71.4 | \u2013      | 43.6 | \u2013      |\\n| h2oloo              | \u2013   | \u2013    | \u2013     | \u2013    | \u2013    | 59.3   | 45.8 | \u2013      |\\n| ConvDR \u2192 BERT       | \u2013   | \u2013    | 77.3  | 85.0 | 79.9 | 54.1   | 54.5 | 39.2   |\\n| T5-Large DE \u2192 reranker| 68.9| 86.0 | 72.6  | 78.6 | 75.3 | 48.3   | 55.1 | 36.7   |\\n| \u22bf WIKI              | 70.7| 88.8 | 79.7  | 86.8 | 79.3 | 50.7   | 60.3 | 43.0   |\\n| \u22bf WIKI + W EB       | 71.8| 88.9 | 81.2  | 87.9 | 82.0 | 53.6   | 59.7 | 42.5   |\\n\\nTable 8.\\n\\nFull evaluation on QReCC, OR-QuAC and TREC CAsT. This table reports additional metrics for these datasets following prior work (Yu et al., 2021; Wu et al., 2021) in addition to MRR reported in Table 3.\\n\\nG. Inpainted Dialog Examples\\n\\nTables 9-12 show additional examples of inpainted dialogs.\\n\\nH. Studying Sensitive Language in the Dataset\\n\\nPrior to evaluating the dataset for fairness implications, we found it necessary to define \u201cfairness\u201d in the context of the model\u2019s generated queries. We began our inquiry by considering conversational fairness \u2013 that is, what constitutes insensitive, offensive, or prejudiced speech in a dialogue? We then qualitatively assessed a small sample of the dataset and described the following potential fairness related concerns that may arise in the dataset:\\n\\n- Model generates a query that contains sensitive characteristics that were not explicitly mentioned in the passage.\"}"}
{"id": "dai22a", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1: What is the European School, Munich?\\n0: The European School, Munich (ESM) is one of thirteen European Schools and one of three in Germany.\\n\\n1: Where is it located?\\n0: First established in 1977, it moved to its current location in Neuperlach, a district in the south-east of Munich, in the state of Bavaria in 1981.\\n\\n1: Is it open to anyone?\\n0: The ESM was principally established to serve the schooling needs of children of the staff of the European Patent Office (EPO) \u2013 the executive body of the European Patent Organisation.\\n\\n1: Are there any other interesting aspects about this article?\\n0: However, enrolment is open to other prospective students.\\n\\n1: What are some of the courses taught?\\n0: The school offers the European Baccalaureate as its secondary leaving qualification.\"}"}
{"id": "dai22a", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1: What is Ageing, Disability and Home Care NSW?\\n0: Ageing, Disability and Home Care NSW (ADHC) is a division of the Department of Family and Community Services in the Government of New South Wales that is responsible for the provision of services to older people, people with a disability, and their families and carers in the state of New South Wales, Australia.\\n\\n1: What services does it provide?\\n0: The ADHC division supports approximately 300,000 vulnerable people from its annual budget of 2.5 billion.\\n\\n1: Does it have a large staff?\\n0: It employs more than 13,000 staff.\\n\\n1: What is it known for?\\n0: ADHC delivers services and manages 900 non-government and local government service providers that are funded to deliver services such as early intervention, therapy, respite, supported accommodation, case management and post-school programs.\\n\\n1: Who runs it?\\n0: The division is led by a Deputy Secretary, presently Jim Longley, who reports to the Minister for Ageing and Minister for Disability Services, presently the Hon. John Ajaka MLC.\"}"}
{"id": "dai22a", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"FAQ is a list of frequently asked questions (FAQs) and answers on a particular topic (also known as Questions and Answers [Q&A] or Frequently Answered Questions).\\n\\nThe format is often used in articles, websites, email lists, and online forums where common questions tend to recur, for example through posts or queries by new users related to common knowledge gaps.\\n\\nThe purpose of an FAQ is generally to provide information on frequent questions or concerns; however, the format is a useful means of organizing information, and text consisting of questions and their answers may thus be called an FAQ regardless of whether the questions are actually \u201cfrequently\u201d asked.\\n\\nSince the acronym \u201cFAQ\u201d originated in textual media, its pronunciation varies.\\n\\nFAQ is most commonly pronounced as an initialism, \u201cF-A-Q\u201d, but may also be pronounced as an acronym, \u201cFAQ\u201d.\\n\\nThe table below shows synthetic dialogs about FAQ generated by different models.\"}"}
{"id": "dai22a", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Did George B. McClellan subordinates blame him for the failures on the campaign of 1862?\\n\\nAlthough McClellan's subordinates can claim their share of responsibility for delays (such as Ambrose Burnside's misadventures at Burnside Bridge) and blunders (Edwin V. Sumner's attack without reconnaissance), these were localized problems from which the full army could have recovered.\\n\\nWhat other blunder happened during the campaign?\\n\\nHistorians have faulted McClellan for accepting the cautious advice about saving his reserves, such as when a significant breakthrough in the center of the Confederate line could have been exploited, but Fitz John Porter is said to have told McClellan, \u201cRemember, General, I command the last reserve of the last Army of the Republic.\u201d However, the veracity of this supposed statement is in doubt.\\n\\nWhy is it in doubt?\\n\\nPorter in the post-war period never claimed to have made the statement and it also fails to note the several Union corps at that time defending Washington.\\n\\nDid the campaign end in a draw?\\n\\nDespite being a tactical draw, Antietam is considered a turning point of the war and a victory for the Union because it ended Lee's strategic campaign (his first invasion of the North) and it allowed President Lincoln to issue the Emancipation Proclamation on September 22, taking effect on January 1, 1863.\\n\\nWhat was George B. McClellan's biggest failure?\\n\\nAlthough McClellan's subordinates can claim their share of responsibility for delays (such as Ambrose Burnside's misadventures at Burnside Bridge) and blunders (Edwin V. Sumner's attack without reconnaissance), these were localized problems from which the full army could have recovered.\\n\\nWhat was his biggest success?\\n\\nHistorians have faulted McClellan for accepting the cautious advice about saving his reserves, such as when a significant breakthrough in the center of the Confederate line could have been exploited, but Fitz John Porter is said to have told McClellan, \u201cRemember, General, I command the last reserve of the last Army of the Republic.\u201d However, the veracity of this supposed statement is in doubt.\\n\\nWhy is the veracity of this statement in doubt?\\n\\nPorter in the post-war period never claimed to have made the statement and it also fails to note the several Union corps at that time defending Washington.\\n\\nWhat was the biggest battle he was involved in?\\n\\nDespite being a tactical draw, Antietam is considered a turning point of the war and a victory for the Union because it ended Lee's strategic campaign (his first invasion of the North) and it allowed President Lincoln to issue the Emancipation Proclamation on September 22, taking effect on January 1, 1863.\\n\\nWhat did George B. McClellan do during the Seven Days' Campaigns?\\n\\nAlthough McClellan's subordinates can claim their share of responsibility for delays (such as Ambrose Burnside's misadventures at Burnside Bridge) and blunders (Edwin V. Sumner's attack without reconnaissance), these were localized problems from which the full army could have recovered.\\n\\nAre there any other interesting aspects about this article?\\n\\nHistorians have faulted McClellan for accepting the cautious advice about saving his reserves, such as when a significant breakthrough in the center of the Confederate line could have been exploited, but Fitz John Porter is said to have told McClellan, \u201cRemember, General, I command the last reserve of the last Army of the Republic.\u201d However, the veracity of this supposed statement is in doubt.\\n\\nWhy is it in doubt?\\n\\nPorter in the post-war period never claimed to have made the statement and it also fails to note the several Union corps at that time defending Washington.\\n\\nWas it a successful campaign?\\n\\nDespite being a tactical draw, Antietam is considered a turning point of the war and a victory for the Union because it ended Lee's strategic campaign (his first invasion of the North) and it allowed President Lincoln to issue the Emancipation Proclamation on September 22, taking effect on January 1, 1863.\"}"}
{"id": "dai22a", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\n\u2022 Model overemphasizes specific sensitive characteristics or identities in a negative or offensive way. For example: the model continues to generate questions related to a writer's biracial identity when it is not the intended focus of the passage.\\n\\n\u2022 Model ascribes negative values to sensitive characteristics without that being explicitly mentioned in the passage. For example, the model generates a question about \\\"how barbaric\\\" a society is for a passage about a non-Western society.\\n\\n\u2022 Model produces \\\"unhelpful\\\" or repetitive questions when the source passage contains sensitive characteristics as compared to passages with non-sensitive characteristics.\\n\\nThe primary approach to evaluating fairness in the dataset involved scanning for sensitive terms and interactions between those terms. To this end, we curated a list of sensitive terms from the literature that includes nouns and adjectives that are considered harmful or insensitive when applied to particular groups (citation). When a combination of these terms appeared in a question in the dataset (Table 13), we considered it to be potentially sensitive. From this initial analysis, we observed that 0.2-0.5% of the dataset contains such potentially sensitive interactions of terms in generated queries. See Tables 14\u201318 for selected examples that matched this filter.\\n\\nTable 13. The categories of sensitive terms and their interactions.\"}"}
{"id": "dai22a", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The term model minority is often used in reference to African Americans, Hispanic Americans, and Asian Americans. But what does the term actually mean?\\n\\nThe model minority label also includes South Asian communities, in particular, Indian Americans, because of their high socioeconomic success.\\n\\nAnd what can Indian Americans do to help other Asian Americans?\\n\\nBut, Indian-Asians face a type of racism and discrimination, despite their Model Minority status, that other Asians do not face.\\n\\nCan you tell me more about this racism?\\n\\nOne of the forms of this is discrimination based on religion; often times, Indians, specifically Sikhs, in America face racism that is a result of mislabeling like being called Middle-Eastern or Muslim by the way they look, whether they actually identify with those groups, with Muslim Americans being markedly poorer than Hindu Americans.\\n\\nThe mass grouping of all different Asian ethnicities into one \u201cpositive\u201d stereotype delegitimizes the problems that certain Asian immigrants face, because the majority might not face those same negative stereotypes.\\n\\nWhat can the Sikhs do to help other Asian immigrants?\\n\\nAnother result of the Model Minority status of Indian-Asians is their complacency, expressed more often than not.\\n\\nThere is conflict within the Indian-Asian immigrant population in the US, as some exalt their \u201cpositive\u201d minority status and wish to uphold it, resulting in complacency when attacked racially and even sometimes going as far as to support political candidates that are anti-immigration.\\n\\nWhat was the band The Queers\u2019 response to the November 2015 Woolsey Fire disaster?\\n\\nIn an interview with Noisey, after their February 2016 show was cancelled due to a call for a petition to boycott the show from a local collective, Babely Shades, Joe Queer voiced his opinion when asked if he \u201csupports racist, misogynistic or homophobic values?\u201d he replied \u201cOf course not.\u201d\\n\\nDid Joe Queer think that the Woolsey Fire was man-made?\\n\\n\u201cWhat normal minded person does?\u201d\\n\\nDid Joe Queer have any black friends?\\n\\n\u201cMy closest pals here in Atlanta are Chris and Chester, two gay black guys.\u201d\\n\\nWas Joe Queer in school when the Woolsey Fire happened?\\n\\n\u201cI was actually working a part time job.\u201d\\n\\nWas Joe Queer working with any black people at the time?\\n\\n\u201cI was one of two white people on the whole job.\u201d\\n\\nDid Joe Queer think that African Americans were lazy and lacked work ethic?\\n\\n\u201cIf I was so racist, I wouldn\u2019t have worked there or be living in Atlanta!\u201d\"}"}
{"id": "dai22a", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\n1: How does a woman's ovulation cycle affect the way she competes with other women?\\n0: This indirect form of competition appears exclusive toward females as findings also showed that women, irrespective of ovulation status (high or low), showed no difference in the rating of male faces.\\n\\n1: What other behaviors or factors affect the way women compete with each other?\\n0: Supporting research has also found that younger women who are considered as having high fertility, gossip about other women more than older women, who are no longer at their most fertile stage.\\n\\n1: Do women tend to be more aggressive toward each other than men?\\n0: Indeed, indirect aggression appears more prevalent amongst (or exclusive to) females than males who are said to engage in more direct forms of competition.\\n\\n1: Are there any other interesting aspects about this article?\\n0: Research studying the relationship between indicators of attractiveness, such as physical attractiveness and indirect victimisation, showed that the likelihood of experiencing indirect victimization increased by 35% for females who perceived themselves as physically attractive.\\n\\n1: Is this something that also happens with men?\\n0: In contrast, being a male who is physically attractive decreased the chances of experiencing such indirect victimization.\\n\\n1: Why is this difference in behavior between men and women important?\\n0: This also highlights how the physical attractiveness a female is a trigger for indirect aggression and forms a core part of intersexual selection between the sexes.\\n\\n---\\n\\nTable 16. The dialog is potentially sensitive due to containing sensitive terms \\\"aggressive\\\" and \\\"men\\\".\\n\\n---\\n\\n1: who was the first African American woman to become a doctor in the United States?\\n0: Virginia M. Alexander (February 4, 1899 \u2013 July 24, 1949) was an American physician, public health researcher, and the founder of the Aspiranto Health Home in Philadelphia, Pennsylvania.\\n\\n1: what was her childhood like?\\n0: Alexander was born in Philadelphia, Pennsylvania on February 4, 1899 to Hilliard Alexander and Virginia Pace.\\n\\n1: did she have siblings?\\n0: She had four siblings, including the prominent attorney Raymond Pace Alexander.\\n\\n1: what were her parents like?\\n0: Alexander's mother died when she was 4 years old, and at age 13 her father's riding academy closed.\\n\\n1: what did she do after her parents' academy closed?\\n0: Alexander withdrew from school to help relieve the resulting economic strain on her family, but her father insisted that she finish her education.\\n\\n1: where did she go to school?\\n0: Alexander attended high school at the William Penn High School for Girls, where she graduated with honors before receiving a scholarship that allowed her to attend the University of Pennsylvania to complete her undergraduate education.\"}"}
{"id": "dai22a", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 11. Our pipeline for training conversational retrieval systems. It follows the standard multi-stage training scheme used in previous work (Lin et al., 2021). We first train an initial retriever with in-batch negatives. We then train a second retriever on hard negatives from the initial retriever. Finally, we train a reranker on hard negatives from Retriever. Performance is further improved by pre-training Retriever and Reranker on document derived-dialogs.\\n\\nputs a relevance score: \\n\\n\\\\[ s_\\\\psi(q, p) = w^\\\\top \\\\text{embed}_\\\\psi(q, p) \\\\]\\n\\nwhere \\\\( w \\\\) is also a model parameter. Unlike the dual encoder, this function does not support fast top-K retrieval in sub-linear time. Therefore, for computational tractability, we only use it to rerank a short-list of candidates retrieved by the dual encoder. However, the joint embedding of \\\\( q \\\\) and \\\\( p \\\\) permits a more expressive relevance function (e.g. cross-attention between \\\\( q \\\\) and \\\\( p \\\\)), so it can improve over the dual encoder's relevance scores.\\n\\nFor training, we minimize a weighted binary classification loss:\\n\\n\\\\[ L(\\\\psi) = -\\\\log \\\\sigma(s_\\\\psi(q, p^*)) - N(q) - \\\\frac{1}{\\\\sum_{p \\\\in N(q)} \\\\log[1 - \\\\sigma(s_\\\\psi(q, p))]} , \\\\]\\n\\nwhere \\\\( \\\\sigma \\\\) denotes the sigmoid function.\\n\\nSimilar to our retriever, the reranker is also initialized from a T5 encoder. Our reranker implementation follows the implementation described in Nogueira et al. (2020).\\n\\nC.3. Model Training\\n\\nA training example from a typical retrieval dataset consists of a query paired with a positive passage, \\\\((q, p^*)\\\\). However, negative passages \\\\( N(q) \\\\) are usually not provided. Hence, we need to generate our own. We use two types of commonly used negatives: in-batch negatives, and \u201chard\u201d negatives mined with a multi-stage training strategy.\\n\\nIn-batch negatives. When training with a batch, we treat the positive passage for example \\\\( i \\\\) as a negative for all other examples \\\\( \\\\neq i \\\\) in the same batch.\\n\\n\u201cHard\u201d negatives. Previous work has identified several weaknesses of in-batch negatives and identified the importance of selecting challenging negative examples for training retrievers (Qu et al., 2021; Xiong et al., 2021; Santhanam et al., 2021). Hence, following prior work (Lin et al., 2021), we adopt a multi-stage training strategy where new negatives are mined at each stage (Figure 11):\\n\\n1. We train an initial retriever using only positives and in-batch negatives.\\n2. We run top-K retrieval using the initial retriever, and then randomly sample a subset of those to serve as negatives (when \\\\( K \\\\) is large, a high percentage of these are true negatives). The hard negatives are then combined with positives to train a second retriever.\\n3. We use the second retriever to again generate hard negatives. We train our reranker on these hard negatives combined with any positives retrieved by the second retriever.\\n\\nWhen pre-training on WikiDialog, we use in-batch negatives. When fine-tuning for a downstream task, we use the multi-stage hard negative strategy.\\n\\nNote that at inference time, we use the second retriever for top-K retrieval, and use the reranker to refine the top-K ranking (the initial retriever is not used at inference time).\\n\\nD. Detailed Experimental Setup\\n\\nD.1. Datasets\\n\\nWe use four open-domain conversational QA retrieval benchmarks: OR-QuAC (Qu et al., 2020), TREC CAsT-19 (Byrne et al., 2019), TREC CAsT-20 (Dalton et al., 2020), and QReCC (Anantha et al., 2021). Table 5 lists their statistics. OR-QuAC and QReCC were introduced in Appendix A.1. TREC CAsT-19 and CAsT-20 are two datasets from the The TREC Conversational Assistance Track (CAsT) shared task (Dalton et al., 2019; 2020) with small numbers of dialogues for evaluating information-seeking conversational search systems. Questions in a dialogue are constructed manually to mimic a \u201creal\u201d dialogue on a certain topic. The retrieval corpus includes web passages from MS\"}"}
{"id": "dai22a", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nMARCO (Nguyen et al., 2016) and wikipedia passages from TREC Complex Answer Retrieval (CAR) (Dusart et al., 2019). CAsT-19 provides human relevance labels for 173 questions in 20 test dialogues. CAsT-20 provides human relevance labels for 208 questions in 25 test dialogues. Note, QReCC reuses question sequences from QuAC and TREC CAsT-19 (Byrne et al., 2019). However, although the questions are the same as existing datasets, the relevant passages and answers are different, as it asked human raters to retrieve passages with a search engine and generate answers.\\n\\nIn addition, TREC questions only appear in the test set.\\n\\nIn OR-QuAC, at least 99.5% of dialogs contain answers from the same answer passage, while in CAsT and QReCC, each question turn can be answered by a different passage.\\n\\nWe follow the official automatic setting (Byrne et al., 2019; Dalton et al., 2020) for both datasets, which only uses the questions as retrieval inputs. We follow the authors of QReCC (Anantha et al., 2021) and (Wu et al., 2021) and use the both questions and gold answers from conversation history as retrieval inputs.\\n\\nD.2. Implementation\\n\\nWe implement dual-encoder retrievers and rerankers in JAX.\\n\\nRetrievers. For pre-training on our inpainted datasets, we used a softmax temperature $\\\\tau$ of 0.01, batch size 2048, and dropout rate 0.1. The models were trained with Adafactor optimizer with learning rate $1 \\\\times 10^{-3}$ and 1k warm up steps. For checkpoint selection, we tested checkpoints at 50k and 100k steps and reported the better one based on each finetune datasets' dev set performance. we fine-tuned the retrievers for 500 steps on OR-QuAC and QReCC. We did not fine-tune the retrievers on TREC CAsT-19 and CAsT-20 due to the small data size. We report TREC performance by retrieving with a QReCC retriever (trained without answers in the inputs).\\n\\nQuestions and passages are always lowercased. Maximum query length was set to 128 for all pretrain and fine-tune datasets except for QReCC, which uses 512 because it allows using previous answers in the queries. Maximum passage length was set to 256.\\n\\nRerankers. Rerankers were implemented using T5 encoder-decoder architecture. We pre-trained the rerankers on synthetic dialogs for 1.7M steps. For fine-tuning on OR-QuAC and QReCC, we used 10 hard negatives for each question sampled from the top 100 passages returned by the retriever. For TREC CAsT-19 and CAsT-20, we follow prior work (Yu et al., 2021) and used 5-fold cross-validation to fine-tune the reranker. We used 20 hard negatives per question ran.\\n\\nTheoretically, one could also use cross-validation to fine-tune randomly sampled from the top 100 retrieved results. We warm up the TREC rerankers on QReCC.\\n\\nAll reranker training used the Adafactor optimizer with constant learning rate $1 \\\\times 10^{-3}$ and dropout rate 0.1. We used batch size 512 for pre-training, 128 for fine-tuning of OR-QuAC and QReCC, and 32 for fine-tuning of TREC CAsT-19 and CAsT-20.\\n\\nD.3. Published baselines\\n\\nWe include five published retrieval-only baselines to compare with our DI retrievers.\\n\\nBM25-Query Rewriter (Yu et al., 2021) and BM25-T5QR (Wu et al., 2021) are two query rewriting approaches that trains a model to rewrite the dialog history into a contextualized, keyword-like query. The former trains a GPT-2 query rewriter on ad hoc search sessions (Yu et al., 2020). The latter trains a T5 query rewriter on human-generated query rewrites from QReCC. Both systems issue the rewritten query to a classic BM25 lexical retrieval system.\\n\\nANCE-Query Rewriter (Yu et al., 2021) uses the GPT-2 query rewriter from (Yu et al., 2021), but it runs the rewritten query with ANCE (Xiong et al., 2021), is a strong non-conversational dense retriever trained on MS Marco.\\n\\nCONQRR (Wu et al., 2021) is the previous state-of-the-art retrieval system on QReCC. CONQRR uses reinforcement learning to optimize the query rewriter for the retriever. Its retriever is a t5-base dual-encoder trained on MS Marco.\\n\\nConvDR (Yu et al., 2021) is the previous state-of-the-art conversational dense retrieval system on OR-QuAC and TREC CAsT tasks. Unlike the above approaches which all use query rewriting, ConvDR learns a conversational query encoder that directly maps the entire dialog history into a dense embedding. To address the bottleneck of limited conversational training data, ConvDR uses a teacher-student framework that trains the student conversational query encoder to \\\"mimic\\\" the representation of the oracle query rewrite from a non-conversational teacher.\\n\\nIn addition to the retrieval baselines, we include three published state-of-the-art conversational search systems that uses the retrieval+reranker pipeline, serving as baselines for our DI retriever + reranker system.\\n\\nCFDA CLIP RUN7 (Yang et al., 2019) is the best performing system participated in TREC CAsT-19 automatic setting (Dalton et al., 2019). It uses heuristics to expand queries, BM25 with T5 doc2query for retrieval, and BERT to rerank.\"}"}
{"id": "dai22a", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nRUN4 is the best participating system in TREC CAsT-20 automatic setting (Dalton et al., 2020). It uses a T5 model for query rewriting, a dense-sparse hybrid retriever, and a T5 reranker trained on MS MARCO.\\n\\nConvDR $\\\\rightarrow$ BERT (Yu et al., 2021) uses a BERT reranker to rerank ConvDR (Yu et al., 2021)'s retrieval results. The BERT reranker is pre-trained on MS MARCO and then fine-tuned for specific datasets on both the ranking loss and the query rewrite distillation loss.\"}"}
{"id": "dai22a", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1: How long does it take for tylenol to work?\\n0: If you have taken the medicine without having food (the stomach is empty), the duration it will make its mark is fifteen to twenty minutes.\\n\\n1: What if you have taken it with food?\\n0: If your stomach is filled (after a meal), and you take Tylenol, the time it will take to produce effect is half an hour to sixty minutes.\\n\\n1: Does it work well?\\n0: Similar to any medicine, it cannot do wonders.\\n\\n1: Am happy i took it.\\n0: Kindly wait and the healing process will fall in place.\\n\\nArticle: How to get your iTunes music on your Windows phone\\n1: How do I get my music from iTunes on to my windows phone?\\n0: Locate the place on your computer where your music is stored.\\n   2: Open Windows Explorer (on Windows 7) or File Explorer (Windows 8 or 10).\\n   3: Your Windows phone will show up as a device in the left pane.\\n   4: Click on your phone on the left, then on the hard drive icon.\\n   5: Inside you will see a Music folder. You will need to know where your music files are stored.\\n\\n1: I don\u2019t know where they are stored.\\n0: Chances are, you will see them in your Music Library.\\n\\n1: I don\u2019t see them there.\\n0: If your music was all purchased from iTunes, you may also find it in C:\\\\Users\\\\your name\\\\Music\\\\iTunes\\\\iTunes Media.\\n\\nArticle: How Your Immune System Works\\n1: What is the most obvious part of the immune system?\\n0: The most obvious part of the immune system is what you can see.\\n1: Like what?\\n0: For example, skin is an important part of the immune system.\\n1: Why is it important?\\n0: It acts as a primary boundary between germs and your body.\\n1: How does it act as a boundary?\\n0: Part of your skin\u2019s job is to act as a barrier in much the same way we use plastic wrap to protect food.\"}"}
{"id": "dai22a", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\nZhuyun Dai\\nArun Tejasvi Chaganty\\nVincent Zhao\\nAida Amini\\nQazi Mamunur Rashid\\nMike Green\\nKelvin Guu\\n\\nAbstract\\nMany important questions (e.g. \u201cHow to eat healthier?\u201d) require conversation to establish context and explore in depth. However, conversational question answering (ConvQA) systems have long been stymied by scarce training data that is expensive to collect. To address this problem, we propose a new technique for synthetically generating diverse and high-quality dialog data: dialog inpainting. Our approach takes the text of any document and transforms it into a two-person dialog between the writer and an imagined reader: we treat sentences from the article as utterances spoken by the writer, and then use a dialog inpainter to predict what the imagined reader asked or said in between each of the writer\u2019s utterances. By applying this approach to passages from Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets totalling 19 million diverse information-seeking dialogs\u20141,000x larger than the largest existing ConvQA dataset. Furthermore, human raters judge the answer adequacy and conversationality of WikiDialog to be as good or better than existing manually-collected datasets. Remarkably, our approach shows strong zero-shot capability, generating high quality synthetic data without using any in-domain ConvQA data. Using our inpainted data to pre-train ConvQA retrieval systems, we significantly advance state-of-the-art across three benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains on standard evaluation metrics.\\n\\n1. Introduction\\nModern information-seeking tools such as web search and question answering (Karpukhin et al., 2020; Zhu et al., 2021) excel at questions that have well-defined answers (e.g., \u201cWhere was Barack Obama born?\u201d). But many important questions are more open-ended\u2014e.g., \u201cHow to eat healthier?\u201d\u2014and require conversation to elicit context and explore in depth: \u201cHow do I eat more protein?\u201d, \u201cWhat about vegetarians?\u201d.\\n\\nConversational question answering systems (ConvQA) (Stede & Schlangen, 2004; Radlinski & Craswell, 2017; Culpepper et al., 2018), would empower users to answer these questions as if they could discuss with an expert at any time.\\n\\nDespite this promising vision, progress has been stymied by scarce training data. While conversational data is abundant in online forums, much of it focuses on personal anecdotes and subjective opinions, and is thus unsuitable for an information-seeking system: we desire responses that minimize personal biases and cite reliable sources. Directly crowdsourcing dialogs is also hard: crowdworkers are rarely experts in the domain of interest and tend to overlook important details.\"}"}
{"id": "dai22a", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\ntant questions or provide shallow answers (Li et al., 2021). It is also expensive: the largest extant datasets contain only about 10,000 conversations each (Choi et al., 2018; Reddy et al., 2019; Dinan et al., 2018; Saeidi et al., 2018; Campos et al., 2020; Feng et al., 2020; Anantha et al., 2021).\\n\\nOn the other hand, high-quality documents, such as those in Wikipedia or PubMed, are abundant. These documents are often edited or written by experts who have invested significant time streamlining their discourse and anticipating a reader's questions. What if we could rewrite these documents into dialogs between the writer and their imagined reader? This would yield an enormous corpus of information-seeking dialogs with attributable, expert answers that could then be used to train a ConvQA system.\\n\\nWe aim to achieve this with dialog inpainting.\\n\\nTo transform any document into a dialog, our first observation is that we already know what the writer wants to discuss\u2014that is reflected in the original text of the document. So, we pretend that the original document is the transcript of what the writer said to the reader in an imagined dialog. But we are still missing what the reader asked. This is like overhearing someone else's phone call: you hear one side, but not the other. Oftentimes, one can still guess what the other side was saying \u2014 we call this prediction task dialog inpainting, because we are \u201cinpainting\u201d the missing parts of the dialog that we did not hear (inspired by the term's usage in computer vision (Iizuka et al., 2017; Liu et al., 2018; Yu et al., 2018)). Drawing on this intuition, we train an inpainter model to predict missing utterances in a dialog, and use it to predict the unobserved questions in a document. By interleaving the generated questions and sentences from the document, we form a dialog (Figure 1).\\n\\nWe apply our inpainter to passages from Wikipedia and the web, yielding WikiDialog and WebDialog, two datasets totalling 19M+ dialogs \u2014 1,000x larger than the largest existing ConvQA dataset. When evaluated for conversationality and answer adequacy, we surprisingly find that our synthetically generated data is as good or better than previous crowd-sourced datasets (Section 3). Our generated dialogs inherit the good qualities of the professionally written documents we inpaint (topical diversity, coherent discourse, evidence-backed claims, etc.) without needing to train on dialog data of the same quality.\\n\\nImportantly, we find that our inpainted datasets are powerful sources of training data for ConvQA systems (Section 4). When used to pre-train standard retriever and reranker architectures, they advance state-of-the-art across three different ConvQA retrieval benchmarks (QRECC, OR-QUAC, TREC-CAST), delivering up to 40% relative gains on standard evaluation metrics (Section 5). Remarkably, we find that just pre-training on WikiDialog enables strong zero-shot retrieval performance\u2014up to 95% of a finetuned retriever's performance\u2014without using any in-domain ConvQA data.\\n\\n2. Dialog Inpainting\\n\\nThe goal of dialog inpainting is to take a partial dialog (one where some of the speaker turns are unobserved), and generate a complete dialog (one where all unobserved turns have been filled in with the model's predictions).\\n\\nFormally, a complete dialog \\\\(d\\\\) is a sequence of speaker utterances, \\\\(d = (u_1, u_2, \\\\ldots, u_t, \\\\ldots, u_T)\\\\). We use the same notation for partial dialogs, denoting unobserved utterances with the \u22c4 symbol. For example, \\\\((u_1, u_2, \u22c4, u_4, \u22c4)\\\\) is a partial dialog where utterances \\\\(u_3\\\\) and \\\\(u_5\\\\) are unobserved. We refer to these as \u201cmasked\u201d utterances. We also use the shorthand \\\\(d_m(3, 5)\\\\) to denote a dialog \\\\(d\\\\) with utterances 3 and 5 masked.\\n\\nTo complete the partial dialog \\\\(d_m(3, 5)\\\\), we generate predictions for utterances 3 and 5, denoted \\\\(\\\\hat{u}_3\\\\) and \\\\(\\\\hat{u}_5\\\\). The inpainted dialog is then:\\n\\n\\\\[\\n\\\\text{Inpaint}(d_m(3, 5)) = (u_1, u_2, \\\\hat{u}_3, u_4, \\\\hat{u}_5).\\n\\\\]\\n\\n2.1. Training: Dialog reconstruction\\n\\nWe train a dialog inpainter using the following dialog reconstruction task: Given a complete dialog, \\\\(d = (u_1, u_2, \\\\ldots, u_T)\\\\), we randomly mask one utterance, \\\\(u_t\\\\), yielding a partial dialog: \\\\(d_m(t) = (u_1, \\\\ldots, u_{t-1}, \u22c4, u_{t+1}, \\\\ldots, u_T)\\\\).\\n\\nGiven this partial dialog, we train our model to predict \\\\(u_t\\\\), the original value of the masked utterance. This is similar to the masked language modeling task used by BERT (Devlin et al., 2019), but instead of reconstructing missing tokens in a passage, we reconstruct a missing utterance in a dialog. More precisely, let us assume that the dialog inpainter is a generative model with parameters \\\\(\\\\theta\\\\) specifying a probability distribution \\\\(p_\\\\theta(u_t|d_m(t))\\\\). Then, our training objective is to minimize the following loss:\\n\\n\\\\[\\nL(\\\\theta) = -\\\\sum_{d \\\\in D} \\\\mathbb{E}_{u_t \\\\sim d}[\\\\log p_\\\\theta(u_t|d_m(t))],\\n\\\\]\\n\\nwhere \\\\(D\\\\) is a corpus of complete dialogs and \\\\(u_t\\\\) is a randomly sampled utterance from the dialog.\\n\\nWe implement our inpainter using the T5 (Raffel et al., 2020) text-to-text encoder-decoder Transformer (Vaswani et al., 2017), where the input \\\\(x\\\\) and output \\\\(y\\\\) are represented as text strings. We convert each dialog \\\\(d\\\\) into an \\\\((x, y)\\\\) pair as follows: First, we randomly sample a turn \\\\(t\\\\) to mask, yielding partial dialog \\\\(d_m(t)\\\\) and target output \\\\(u_t\\\\). To form...\"}"}
{"id": "dai22a", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\n2.2. Inference: Transforming documents into dialogs\\n\\nWe now show how to use a trained inpainter to transform a document into a dialog. Suppose we have a document or passage \\\\( p \\\\) consisting of sentences \\\\((s_1, s_2, ..., s_m)\\\\). Imagine that each of these sentences was an utterance spoken by the writer in an imagined dialog with the reader: we want to know what the imagined reader said between each of the writer\u2019s utterances. We can pose this question to our inpainter by asking it to complete the following partial dialog:\\n\\n\\\\[\\n(\\\\diamond, s_1, \\\\diamond, s_2, \\\\diamond, s_3, ..., \\\\diamond, s_m)\\n\\\\]\\n\\n\u2014each utterance from the imagined reader starts masked and is responded to by the writer with a sentence from the passage. While the model knows the masked utterances come from another speaker, it still lacks any hint that the speaker should ask questions. To provide this hint, we prepend an utterance from the writer\u2019s prompt that says: \u201cHello, I am an automated assistant and can answer questions about [document title].\u201d Hence, the overall partial dialog has the form:\\n\\n\\\\[\\n\\\\text{PartialDialog}(p) = (s_{\\\\text{prompt}}, \\\\diamond, s_1, \\\\diamond, s_2, \\\\diamond, ..., \\\\diamond, s_m)\\n\\\\]\\n\\nNote, however, that this partial dialog contains multiple masked utterances, while our inpainter is only trained to inpaint a single utterance at a time. To handle this, we use the model autoregressively: we begin by providing \\\\((s_{\\\\text{prompt}}, \\\\diamond, s_1)\\\\) as input to the inpainter and generate \\\\(\\\\hat{u}_1\\\\) via greedy decoding. We then replace the first mask with \\\\(\\\\hat{u}_1\\\\) and use a new input \\\\((s_{\\\\text{prompt}}, \\\\hat{u}_1, s_1, \\\\diamond, s_2)\\\\) to generate \\\\(\\\\hat{u}_2\\\\) and so on until all masks are filled and the dialog is complete.\\n\\n2.3. Case study: Applying dialog inpainting to generate an information seeking dialog dataset\\n\\nWe now have all the ingredients necessary to generate synthetic information-seeking dialogs at scale. In this section, we will outline how we trained inpainters and applied them on two document corpora to respectively generate two such datasets: WikiDialog and WebDialog.\\n\\nInpainter model training.\\n\\nWe used PublicDialog, TaskMaster, OR-QuAC, and QReCC (Table 2) to train three different inpainters: Inpaint\\\\(_{PT}\\\\), Inpaint\\\\(_{OQ}\\\\) and Inpaint\\\\(_{PTOQ}\\\\), where the subscripts indicate which of the above datasets were used. We chose these subsets to study how the type and quantity of training data affect inpainter quality: Inpaint\\\\(_{PT}\\\\) only uses open-domain conversational datasets that do not contain any explicit question answering, while Inpaint\\\\(_{OQ}\\\\) only uses relatively small conversational question answering datasets, and Inpaint\\\\(_{PTOQ}\\\\) uses all of the above. Each inpainter model was initialized from a pre-trained T5-XXL (11B parameters) checkpoint and finetuned on its corresponding training data. See Appendix A.2 for details on the hyperparameters used.\\n\\nDocument processing.\\n\\nWe apply dialog inpainting to two document corpora: Wiki, a collection of 11.4M passages from 5.9M English Wikipedia articles in the OR-QuAC retrieval corpus (Qu et al., 2020), and Web, a collection of 8.4M English web passages from the MS Marco retrieval corpus (Nguyen et al., 2016). Both corpora were used as is without any further filtering. The passages were split into sentences using the Google Cloud Natural Language API. To limit computation, we only use the first 6 sentences of each passage.\\n\\nThe passages were then converted to partial dialogs and inpainted using the method described in Section 2.2. The final results are the datasets WikiDialog\\\\(_{PT}\\\\), WikiDialog\\\\(_{OQ}\\\\) and WikiDialog\\\\(_{PTOQ}\\\\) and WebDialog\\\\(_{PT}\\\\), where the subscripts indicate which inpainter model was used to generate the data (Table 2).\\n\\n3. Evaluating WikiDialog as a Dataset\\n\\nWe now turn to a qualitative evaluation of the dialogs generated in Section 2. We will show that they largely contain information-seeking dialogs with well-matched questions and answers. This makes the data suitable for ConvQA systems, an application explored later in the paper. As WikiDialog is generated using passages from OR-QuAC, the corresponding OR-QuAC dialogs form a natural point of reference: both datasets rely on the same content, but are respectively automatically and manually generated. For this reason, our analysis focuses on the WikiDialog variants.\\n\\nOur analysis combines automatic and human evaluation. The human evaluation was conducted by asking human raters the subjective questions listed in Table 1 for each turn of a dialog.\\n\\nWe found substantial inter-annotator agreement on all four questions, with a Krippendorff\u2019s \\\\( \\\\alpha \\\\) of at least 0.89, and report results aggregated over dialogs corresponding to a common set of 200 randomly chosen passages using the mean score of three raters.\\n\\nHow information seeking are the generated utterances?\\n\\nRaters judge the generated utterances to almost always be information seeking and topically relevant. We note that, prompt aside, our method is not tailored to explicitly generate information seeking utterances in any way. It is remarkable then that raters found 94.5% of utterances in WikiDialog\\\\(_{PT}\\\\), which was generated without using any...\"}"}
{"id": "dai22a", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nTable 1. Results from a human evaluation of the generated utterances in three WikiDialog variants vs. a dataset manually collected on the same passages, OR-QuAC. The table also presents inter-annotator agreement using Krippendorff\u2019s $\\\\alpha$. Underlined numbers statistically differ from corresponding OR-QuAC ones at a $p<0.05$ level based on a paired randomization test.\\n\\nConvQA data, to be information seeking; by training the inpainter using ConvQA data, this number goes to 99\u2013100%. Almost all of these are single sentences phrased as questions, though WikiDialog PT includes some exceptions, e.g., \u201cExciting! I wonder if they got a #1 debut with that song.\u201d\\n\\nWhat types of questions are generated?\\n\\nNext, we study the distribution of questions generated by clustering utterances on their first two words. Figure 2 shows how this distribution changes over turns: dialogs start with more definitional questions (e.g., what is, who is, where is, etc.) but then diversify into a range of follow-up questions (what happened, did, is, how, why, etc.). A good conversation should have a mix of both specific and broad questions.\\n\\nHere, raters find that the WikiDialog variants primarily differ from OR-QuAC in having more \u201csomewhat specific\u201d questions (e.g., \u201cIs there anything else interesting about his guitar?\u201d) and fewer \u201cvery specific\u201d questions (e.g., \u201cDid people enjoy their music?\u201d).\\n\\nHow well answered are the generated questions?\\n\\nSo far, we have shown that one speaker in WikiDialog consistently asks questions, playing the role of the imagined reader well. We now turn to the other speaker, the writer: how often are their responses\u2014sentences from a Wikipedia passage\u2014adequate answers to the questions? Raters find that questions in all three variants of WikiDialog are sufficiently answered about as often as in OR-QuAC, though questions in OR-QuAC are often answered better.\\n\\nHow conversational are the data?\\n\\nA key distinguishing feature of dialog data is its dependence on prior dialog context. Following prior work (Choi et al., 2018), we use the degree of context dependence as a measure of conversation. Raters judge that questions in the WikiDialog variants follow-up on dialog context significantly more often than those in OR-QuAC. We hypothesize that the tendency to follow-up likely arises from the structure of the underlying passages from which WikiDialog is derived: when a paragraph in Wikipedia explores a single topic in depth, so too does the dialog generated from it in WikiDialog.\\n\\nDo the data contain potentially sensitive language that may perpetuate unfair bias?\\n\\nEvaluating a dataset of this size for potential unfair bias is a daunting task that requires diligent and thorough investigation. We approached the problem by curating a set of 700 terms from the literature (Bolukbasi et al., 2016; Garg et al., 2018; May et al., 2019; Nadeem et al., 2020; Abid et al., 2021) related to sensitive characteristics\u2014such as race, ethnicity, gender, and sexual orientation. Many instances of these terms are well-motivated: for example, a dialog from a passage about transgender rights in Canada includes the question \u201cWhat does anti-discrimination act mean in relation to transgender people?\u201d. We further refined the approach to instead look at co-occurrences between these terms and adjectives that may have negative connotations, focusing on instances where the terms were not explicitly mentioned in the passage. We find that 0.2\u20130.5% of dialogs in the dataset contain such potentially sensitive interactions, but it is difficult to establish if...\"}"}
{"id": "dai22a", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5. A screenshot of the annotation interface. On the right, raters see the conversation history and the highlight turn they must rate in the form on the left. When all questions for a given turn are completed, they are allowed to move forward to the next turn (round in the figure). The task can be submitted when all turns are complete.\"}"}
{"id": "dai22a", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nFigure 6. Instructions and example provided for the question \u201cIs the query information-seeking?\u201d\\n\\nFigure 7. Instructions and example provided for the question \u201cHow is the query relevant to the conversation?\u201d\"}"}
{"id": "dai22a", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 8. Instructions and example provided for the question \\\"How specific is the query?\\\"\\n\\nFigure 9. Instructions and example provided for the question \\\"How well does the response answer the query?\\\"\"}"}
{"id": "dai22a", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this task, you will be spotting nonsensical or factually incorrect messages in artificially generated information-seeking conversations between a user and a system.\\n\\nIn each turn, raters were asked to answer the subjective questions in Table 1 and were provided the instructions and adjoining examples in Figures 6-10.\\n\\nWe iterated on our task design and instructions over two pilot annotations runs. Feedback from these pilots led to two main changes: (i) we extended the specificity and answer adequacy questions to be Likert scales rather than yes/no questions and (ii) we omitted a laborious question that asked raters to attest whether the passage supports the answer when interpreted in the context of the conversation history\u2014 we found that this perfectly correlated with whether or not the question was adequately answered or not.\\n\\nRater recruitment and training.\\n\\nWe engaged with a vendor supplier of full-time crowd workers to recruit human annotators for our task. Raters were asked to review the above instructions and were provided direct feedback on their responses during the pilot annotation runs.\\n\\nC. Retrieval models\\n\\nC.1. Dual encoder retriever\\n\\nThe dual-encoder maps a query \\\\((q)\\\\) and a passage \\\\((p)\\\\) into dense embedding vectors \\\\(\\\\text{embed}_{\\\\gamma}(q)\\\\) and \\\\(\\\\text{embed}_{\\\\gamma}(p)\\\\), where \\\\(\\\\gamma\\\\) denotes model parameters. The relevance score between the two is their vector cosine similarity:\\n\\n\\\\[\\ns_{\\\\gamma}(q,p) = \\\\frac{\\\\text{embed}_{\\\\gamma}(q) \\\\cdot \\\\text{embed}_{\\\\gamma}(p)}{\\\\|\\\\text{embed}_{\\\\gamma}(q)\\\\| \\\\cdot \\\\|\\\\text{embed}_{\\\\gamma}(p)\\\\|}\\n\\\\]\\n\\nThis particular function enables one to retrieve the top-\\\\(K\\\\) highest-scoring passages for a given query using fast similarity search methods that run in sub-linear time (Ram & Gray, 2012).\\n\\nFor training, we minimize a standard contrastive loss with temperature \\\\(\\\\tau\\\\):\\n\\n\\\\[\\nL(\\\\gamma) = -\\\\log \\\\frac{\\\\exp(s_{\\\\gamma}(q,p^*)/\\\\tau)}{\\\\sum_{p \\\\in p^* \\\\cup N(q)} \\\\exp(s_{\\\\gamma}(q,p)/\\\\tau)},\\n\\\\]\\n\\nwhere \\\\(p^*\\\\) is a positive passage for \\\\(q\\\\) and \\\\(N(q)\\\\) denotes negative passages.\\n\\nWe implement the dual-encoder retriever following recent work (Ni et al., 2021): in particular, we use a shared Transformer encoder initialized from a T5 checkpoint, take the mean pooling of the top-most encoder layer, and project it to a fixed 768-dimensional embedding.\\n\\nC.2. Reranker\\n\\nThe reranker model takes the same inputs as the dual encoder, but instead of encoding \\\\(q\\\\) and \\\\(p\\\\) into two separate vectors, it jointly encodes them into a single vector, \\\\(\\\\text{embed}_{\\\\psi}(q,p)\\\\), where \\\\(\\\\psi\\\\) denotes model parameters. It ou-\"}"}
{"id": "dai22a", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nFigure 3. We use a two-stage ConvQA retrieval system. We first retrieve top-K passages from the corpus using a dual-encoder model and then rerank them using a cross-attention model. They perpetuate unfair bias without expert manual review. Therefore, we advise users to note these observations and exercise care while using the dataset.\\n\\n4. Application: Open-domain Conversational Retrieval\\n\\nIn this section, we show how our inpainted datasets can serve as a powerful source of training data for ConvQA systems. A ConvQA system engages with a user through multi-turn dialog, where typically the user poses questions and the system answers (there can be exceptions, e.g., the system asks a clarifying question). During a dialog, whenever it is the system's turn to speak (at some time $t$), it looks at all previous dialog turns $d_1:t$ which we call the dialog history, and outputs a new utterance, $u_{t+1}$.\\n\\nBecause ConvQA dialogs are knowledge-intensive, many systems decompose the task into a two-part retrieve-then-generate process (Qu et al., 2020; Anantha et al., 2021). First, they employ a conversational retriever to retrieve passages that are relevant to the conversation based on the dialog history $d_1:t$. Second, they employ a generator which uses both the dialog history ($d_1:t$) and the retrieved passages to generate a response, $u_{t+1}$. While both steps are important, the conversational retriever is key to helping the model access the right knowledge and also for showing people evidence for an answer.\\n\\nThis work focuses on the conversational retriever, showing how to improve it by pre-training on our inpainted data, leaving improvements to the generator for future work.\\n\\nModels. The input to a conversational retriever is the dialog history ($d_1:t$) and a passage ($p$). The output is a score, $s(d_1:t,p)$, indicating the passage's relevance. Retrieval is performed by selecting the passages with the highest scores. We also refer to the dialog history as the \u201cquery\u201d and denote it as $q$. In some benchmarks that we study, the \u201cdialog history\u201d is defined to be all previous utterances, while in others the history is defined to only include the user's questions but not the system's responses.\\n\\nWe employ two standard models for retrieval: first, we use a dual encoder (Reimers & Gurevych, 2019; Karpukhin et al., 2020; Ni et al., 2021) to select an initial set of candidates. We then rescore those candidates using a cross-attention reranker (Nogueira & Cho, 2019; Nogueira et al., 2020). Model architectures and training objectives are detailed in Appendix C. To train these models, we need a corpus of ($q,p^*$) pairs, where $q$ is a dialog history and $p^*$ is a relevant passage. The following sections describe such data. Figure 3 illustrates our system.\\n\\nPre-training and Fine-tuning. As outlined in Section 2.2, each dialog generated by our inpainter tends to consist of alternating question and answer utterances: $d = (s_{prompt}, \\\\hat{u}_1, s_1, \\\\ldots, \\\\hat{u}_m, s_m)$, where inpainted utterances $\\\\hat{u}_i$ are questions, and their subsequent answers $s_i$ are sentences from the original passage $p$. Intuitively, for each question in the dialog, $p$ is a highly relevant passage that should be retrieved. Based on this observation, we generate examples as follows: first, we randomly select a dialog prefix that ends in a question to be the dialog history: $q_i = (\\\\hat{u}_1, s_1, \\\\ldots, \\\\hat{u}_i)$. We then wish to mark the original passage $p$ as a positive passage to retrieve. However, directly using $p$ as a positive example will not yield good results: the dialog history ($q_i$) includes exact sentences from $p$, which would cause our retriever to simply learn to string-match, rather than to generalize. To eliminate this problem, we form a new passage that consists only of the remaining sentences in $p$ that haven't appeared in $q_i$ yet: $p^*_i \\\\defeq \\\\text{Concat}(s_j \\\\text{ where } j > i)$.\\n\\nAfter pre-training ($q_i, p^*_i$) pairs from the inpainted data, our retriever is fine-tuned on a downstream ConvQA dataset.\\n\\n5. Evaluation\\n\\nWe report quantitative evaluation of dialog inpainting by measuring the impact of WikiDialog and WebDialog on ConvQA retrieval systems.\\n\\n5.1. Experimental setup\\n\\nThe following presents a summary of our experimental setup; see Appendix D for full details.\\n\\nDatasets. We use three open-domain conversational QA retrieval benchmarks: OR-QuAC (Qu et al., 2020), QReCC (Anantha et al., 2021), and TREC CAsT19 and CAsT20 (Dalton et al., 2019; 2020). Table 2 summarizes basic statistics of each dataset; further details are provided in Appendix E.\\n\\nWe omit the leading prompt utterance ($s_{prompt}$) from the history. Also, we optionally omit answer turns, depending on the task setup.\"}"}
{"id": "dai22a", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\n| Non-conversational question answering datasets | MS Marco 0.5M | PAQ 65M |\\n| Non-question answering conversational datasets | PublicDialog 2.0M 1:2:4 | TaskMaster 19.8K 9:10:14 |\\n| Conversational question answering datasets | OR-QuAC 5.6K 4:8:12 40.5K | QReCC 13.6K 1:6:12 80.0K |\\n| | CAsT-19 80 7:10:12 748 | CAsT-20 25 6:8:13 216 |\\n| WikiDialog 11.4M 1:6:6 56.1M | WebDialog 8.4M 1:3:6 26.9M |\\n\\nTable 2. The number of dialogs, turns and questions (Ques.) of datasets considered in this paper; turns and question lengths are reported using (1%:50%:99%) percentiles.\\n\\nRetrieval corpora. We use standard retrieval corpora and relevance labels from each dataset for evaluation: OR-QuAC uses 11.1M passages from English Wikipedia. TREC CAsT-19 and CAsT-20 use a shared corpus of 8M web passages from MS Marco (Nguyen et al., 2016) and 30M Wikipedia passages from Dusart et al. (2019); QReCC uses 54M passages from the Internet Archive Wayback Machine and the English pages in CommonCrawl. Following prior work (Qu et al., 2020; Yu et al., 2021; Wu et al., 2021), we use only the current and previous questions as inputs for OR-QuAC, TREC CAsT-19 and CAsT-20, and use previous answers in addition to these as input for QReCC. We report mean reciprocal rank at rank 5 (MRR@5) for OR-QuAC and mean reciprocal rank at full rank (MRR) for QReCC and TREC CAsT. Additional metrics are reported in Appendix F.\\n\\nModel implementation. We initialize our dual-encoder retrievers and rerankers from pre-trained T5 checkpoints following prior work (Ni et al., 2021; Nogueira et al., 2020). Both retrievers and rerankers are pre-trained on our inpainted datasets. We use the notation T5-Large DEWikiD to denote a dual-encoder that was initialized from a T5-Large checkpoint and pre-trained on WikiDialog (we use WikiDialogPTOQ unless otherwise specified), and T5-Large DEWikiD+WebD to denote a model pre-trained on the union of WikiDialog and WebDialog. Similar notation is used for T5-Base initialized models and rerankers.\\n\\nDuring fine-tuning, we separately train retrievers and rerankers on OR-QuAC and QReCC, using their validation sets to select checkpoints. Because CAsT19 and CAsT20 are extremely small datasets and do not include a training split, we do not fine-tune dual-enocoder retrievers on these datasets, instead using a retriever finetuned on QReCC data.\\n\\nWe follow Yu et al. (2021) and use 5-fold cross-validation to finetune rerankers on CAsT19 and CAsT20: for each fold, we split the data into 5 splits based on dialogs, train a reranker on 3 splits of the data, select a checkpoint on one split and test on the remaining split. Similar to Yu et al. (2021) and Lin et al. (2021), we use hard negatives mined from a base retriever during fine-tuning (See Appendix C.3 for details). Finally, during inference, we use MIPS (Ram & Gray, 2012) to index the passage embeddings, and use exhaustive search to retrieve and then rerank the top 100 passages for all datasets.\\n\\nBaselines. We compare our pre-trained dual-encoder retrievers against five published retrieval-only baselines: BM25-Query Rewriter (Yu et al., 2020), BM25-T5QR (Wu et al., 2021), ANCE-Query Rewriter (Yu et al., 2021), CONQRR (Wu et al., 2021) and ConvDR (Yu et al., 2021).\\n\\nWe also evaluate our base model, a T5-Large DE model that is only finetuned on each dataset: this is a strong baseline that outperforms previous state-of-the-art on QReCC. We also compare our pre-trained retrieval+reranking systems against the best performing systems in TREC CAST: CFDA CLIP RUN7 (Yang et al., 2019) and h2oloo RUN4 (Dalton et al., 2020), and a state-of-the-art retriever+reranker method ConvDR \u2192 BERT (Yu et al., 2021).\\n\\n5.2. Main Results\\n\\nTable 3 compares our models with baselines on four ConvQA retrieval benchmarks. We first note that our relatively simple base retriever model, T5-Large DE, is a strong baseline and significantly outperforms the existing state-of-the-art results on QReCC. By simply pre-training on WikiDialog, we observe a 9\u201330% gain, and outperform all baselines on QReCC and OR-QuAC with large margins. Including WebDialog increases this gain by a further 3\u201315% MRR, with the most significant gains accruing to CAsT-19 and CAsT-20. With this model, we observe a 43% relative MRR gain over the current state-of-the-art on QReCC, a 12% relative MRR@5 gain on OR-QuAC, and comparable or better performance on CAsT-19 and CAsT-20.\\n\\nThe gains achieved in the retrieval stage remain when the results are reranked: we outperformed the current state-of-the-art on OR-QuAC and TREC CAsT-19, and achieved comparable performance on CAsT-20. We could not find existing published reranker results for QReCC, but observe\"}"}
{"id": "dai22a", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3. We evaluate models trained using our inpainted datasets against baselines on three different ConvQA retrieval tasks: QReCC, OR-QuAC, and TREC CAsT. WikiD, WikiD+WebD: We use WikiDialog for all tasks except when WikiD+WebD is used in TREC CAsT, where WikiDialog gives higher performance. Additional metrics are reported in Appendix F.\\n\\n5.3. Analysis\\n\\nNext, we dive into our results in greater detail and study factors contributing to performance: How much does in-domain training matter for inpainter quality? Table 4 compares the performance of retrievers pre-trained on three variants of WikiDialog introduced in Section 3: PT, OQ, and PTOQ. Remarkably, using WikiDialog PT is sufficient to significantly outperform current state-of-the-art methods, despite being generated using only open-domain conversational data. Next, we observe that using an inpainter trained on OR-QuAC and QReCC data (WikiDialog OQ) results in slightly better performance; it is notable that an inpainter trained using only 20K dialogs is able to generate such high-quality data, and can improve performance over a retriever just fine-tuned on the same data by up to 20%. Finally, we observed that an inpainter trained on both types of data (WikiDialog PTOQ) is able to generalize better to CAsT-19, an out-of-domain task we evaluate on using a QReCC retriever.\\n\\nHow does WikiDialog compare to other retriever pre-training datasets? Table 4 also reports results for retrievers pre-trained on several alternatives to WikiDialog: MS Marco (Nguyen et al., 2016), a search dataset that is widely used for retriever pre-training; PAQ (Lewis et al., 2021), the largest existing (non-conversational) question-answering dataset, also automatically generated from Wikipedia; and PublicDialog + TaskMaster (PT), the open-domain dialog data introduced in Section 2 as a training dataset for the inpainter\u2014we use it here to directly pre-train a conversational retriever using a next utterance retrieval task. Table 2 lists their characteristics. We observe that pre-training on any of the WikiDialog variants significantly outperforms the two classic non-conversational QA datasets, MS Marco and PAQ. WikiDialog also outperforms open-domain dialog data PublicDialog+TaskMaster (PT). Despite being generated using PT, pre-training on WikiDialog PT far outperforms it, showing that the proposed dialog inpainting recipe provides additional signal not present in PT.\\n\\nIn addition, we found that pre-training a retriever on PT does surprisingly well, significantly outperforming MS Marco on all datasets. Prior ConvQA retrieval systems have focused on traditional QA data for pre-training, but we find that open-domain conversational data can be just as useful!\\n\\nDoes pre-training on WikiDialog enable zero/few-shot learning? We now explore how much fine-tuning data is needed after pre-training on WikiDialog. Figure 4 (a) plots the retrieval results of a T5-Base retriever pre-trained on WikiDialog PT\u2014which does not use any in-domain data\u2014and finetuned on varying percentages of the QReCC training dataset. Surprisingly, we observe that the zero-shot performance of the pre-trained retriever is already quite good: achieving nearly 95% the MRR of a model that uses the full dataset. Furthermore, pre-trained retriever needs fewer fine-tuning...\"}"}
{"id": "dai22a", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nFigure 4. Retriever performance on QReCC when T5-Base DE \u22bf WikiDialog PT is trained with (a) varying fine-tuning data sizes, (b) different sizes inpainter models, and (c) varying pre-training data sizes. Results in (a) do not include mined hard-negatives. Data \u2013 by fine-tuning on just 10% of the data, the pre-trained retriever exceeds the performance of the full-data baseline. Does our method scale with inpainting model size and data size?\\n\\nWe now explore if our dialog inpainting method can benefit from scaling up along two dimensions: the inpainter model size, and the inpainted WikiDialog data size. Results are shown in Figure 4 (b) and (c).\\n\\nFrom Figure 4 (b), we observe that retriever performance increases with inpainter model size with one exception: the T5-XL model slightly outperforms T5-XXL; we hypothesize this is due to insufficient hyperparameter search for T5-XXL. Surprisingly, the quality of data generated by T5-Small is already sufficient to significantly outperform current state-of-the-art methods.\\n\\nIn Figure 4 (c), we evaluate how retrievers pre-trained with 10K\u201311M dialogs sampled from WikiDialog perform on QReCC. We observe a roughly log-linear relationship between performance and pre-training data size that has not yet plateaued: simply inpainting more passages may further increase retrieval performance.\\n\\n6. Related Work\\n\\nConversational question answering retrieval.\\n\\nSeveral manually collected conversational question answering datasets have been proposed to address the scarcity of high-quality training data (Choi et al., 2018; Reddy et al., 2019; Dinan et al., 2018; Saeidi et al., 2018; Dalton et al., 2019; Campos et al., 2020; Dalton et al., 2020; Qu et al., 2020; Feng et al., 2020; Anantha et al., 2021). However, because they are relatively small, existing retrieval systems all depend on rewriting queries to use with a non-conversational retrieval system (Yang et al., 2019; Dalton et al., 2020; Yu et al., 2020; 2021; Wu et al., 2021). Query rewriting is a hard problem in itself (Vakulenko et al., 2020)\u2014prior systems rely on proprietary search logs (Yu et al., 2020), reinforcement learning (Wu et al., 2021) or distillation recipes (Yu et al., 2021)\u2014and some queries cannot be rewritten at all, e.g., \u201cWhat else were they famous for?\u201d. Here, we use WikiDialog, a 1000x larger ConvQA dataset, to train a standard retriever without requiring query rewrites.\\n\\nConversational language models.\\n\\nLarge conversational language models such as DialogGPT (Zhang et al., 2020) and Meena (Adiwardana et al., 2020) have shown impressive open-ended conversational capabilities, and even the ability to directly answer many questions. However, they often hallucinate answers and amplify unfair biases present in their training data. Subsequent work address this problem by instead posing queries to a non-conversational retriever and using its answers (Roller et al., 2021; Komeili et al., 2021; Nakano et al., 2021; Thoppilan et al., 2022; Elgohary et al., 2019). In this paper, we instead use a masked conversational language model to generate ConvQA data: the data can be readily audited for unfair biases and to train a conversational retrieval system.\\n\\nData augmentation and synthetic data generation.\\n\\nData augmentation has been widely used to improve the performance of document retrieval and related tasks (Lee et al., 2019; Chang et al., 2020; Gao et al., 2021) by using training data more efficiently. However, these methods typically do not result in high-quality data that can be used outside of a training recipe. More recently, Ma et al. (2021) and Lewis et al. (2021) train special-purpose question generation models to synthetically generate millions of high-quality question answer pairs. We extend this line of work to generate millions of information seeking dialogs, and show that even a general purpose inpainter model can generate high-quality data.\\n\\n7. Discussion\\n\\nIn this paper, we have presented dialog inpainting, a novel approach to generating synthetic conversational data. We showed that it is possible to generate compelling information-seeking dialogs using only general-purpose data, suggesting applications to other conversational tasks. While synthetic data cannot entirely replace real data, it can help bootstrap interactive conversation systems and create a virtuous cycle wherein users find it natural to engage with and improve the system. We are particularly optimistic about applying the dialog inpainting data to (1) distillation, where the inpainted datasets serve as large-scale distillation sets, (2) end-to-end conversational question answering, and (3) zero-shot conversational QA, which is motivated by the zero-shot retrieval capabilities shown in this work.\\n\\nIt is important to be aware of the biases that generating data can introduce or amplify. We want to encourage good inductive biases that make conversations conversational\u2014e.g., use of anaphora or elision of context\u2014and to introduce further control over the dialogs generated\u2014e.g., persona or dialog acts. At the same time, we must interrogate the\"}"}
{"id": "dai22a", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\\\"Allah is most gracious to the oppressed (Quran passage)\\\" is mentioned in the analysis of a terrorist attack. Is this quote from the Quran a part of the analysis?\\n\\nThe analysis does not discuss the quote on the Quran.\\n\\nWhat is the image in the analysis?\\n\\nThe central figure of the image is a yellow tiger, which is surrounded by a ring of bullets and crossed by two rifles.\\n\\nWhat is the significance of the image?\\n\\nThe script both around the tiger, in Tamil, and below the tiger, in English, reads \\\"Liberation Tigers of Tamil Eelam.\\\" Eelam is Tamil for the Island of Sri Lanka, which the groups seeks to liberate from the control of the Sinhalese majority.\\n\\nWhat is the significance of the tiger?\\n\\nThe tiger is a culturally important animal that symbolizes heroism, militancy, and patriotism.\\n\\nWhat is the significance of the tiger in this image?\\n\\nIts centrality in this image indicates the desire of the Liberation Tigers to be self-determined and independent.\\n\\nWhat is the significance of the bullets and rifles?\\n\\nThe bullets and rifles indicate their employment of violence as the means to achieve these goals.\\n\\nTable 18. This dialog is flagged as potentially sensitive because it contains the sensitive terms \\\"allah\\\" and \\\"attack.\\\"\"}"}
{"id": "dai22a", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\ngenerated data and work towards minimizing instances of potentially sensitive language that may perpetuate unfair biases.\\n\\nAcknowledgements\\n\\nWe thank Jianmo Ni and T5X Retrieval project for helping us set up the dual-encoder training framework. We thank the LaMDA team (Thoppilan et al., 2022) for providing help with inpainter training. Finally, we thank Alex Salcianu, Victoria Fossum, Raphael Hoffmann, Kenton Lee, and Maithra Raghu for helpful discussions and feedback.\\n\\nReferences\\n\\nAbid, A., Farooqi, M., and Zou, J. Large language models associate muslims with violence. *Nature Machine Intelligence*, 3(6):461\u2013463, 2021.\\n\\nAdiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R., Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. Towards a human-like open-domain chatbot. *arXiv preprint arXiv:2001.09977*, 2020.\\n\\nAnantha, R., Vakulenko, S., Tu, Z., Longpre, S., Pulman, S., and Chappidi, S. Open-domain question answering goes conversational via question rewriting. In *Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies*, NAACL-HLT. Association for Computational Linguistics, 2021.\\n\\nBolukbasi, T., Chang, K.-W., Zou, J. Y., Saligrama, V., and Kalai, A. T. Man is to computer programmer as woman is to homemaker? debiasing word embeddings. *Advances in neural information processing systems*, 29, 2016.\\n\\nByrne, B., Krishnamoorthi, K., Sankar, C., Neelakantan, A., Goodrich, B., Duckworth, D., Yavuz, S., Dubey, A., Kim, K., and Cedilnik, A. Taskmaster-1: Toward a realistic and diverse dialog dataset. In *Inui, K., Jiang, J., Ng, V., and Wan, X. (eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP*. Association for Computational Linguistics, 2019.\\n\\nCampos, J. A., Otegi, A., Soroa, A., Deriu, J. M., Cieliebak, M., and Agirre, E. Doqa-accessing domain-specific faqs via conversational qa. In *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics*, 2020.\\n\\nChang, W., Yu, F. X., Chang, Y., Yang, Y., and Kumar, S. Pre-training tasks for embedding-based large-scale retrieval. In *8th International Conference on Learning Representations, ICLR*, 2020.\\n\\nChoi, E., He, H., Iyyer, M., Yatskar, M., Yih, W., Choi, Y., Liang, P., and Zettlemoyer, L. Quac: Question answering in context. In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing*, EMNLP-IJCNLP. Association for Computational Linguistics, 2018.\\n\\nCulpepper, J. S., Diaz, F., and Smucker, M. D. Research frontiers in information retrieval: Report from the third strategic workshop on information retrieval in lorne (SWIRL). *SIGIR Forum*, 2018.\\n\\nDalton, J., Xiong, C., and Callan, J. TREC cast 2019: The conversational assistance track overview. In *Proceedings of the Twenty-Ninth Text REtrieval Conference, TREC*, NIST Special Publication. National Institute of Standards and Technology (NIST), 2019.\\n\\nDalton, J., Xiong, C., and Callan, J. Cast 2020: The conversational assistance track overview. In *Proceedings of the Twenty-Ninth Text REtrieval Conference, TREC*, NIST Special Publication. National Institute of Standards and Technology (NIST), 2020.\\n\\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. In *Burstein, J., Doran, C., and Solorio, T. (eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT*. Association for Computational Linguistics, 2019.\\n\\nDinan, E., Roller, S., Shuster, K., Fan, A., Auli, M., and Weston, J. Wizard of wikipedia: Knowledge-powered conversational agents. *arXiv preprint arXiv:1811.01241*, 2018.\\n\\nDusart, A., Hubert, G., and Pinel-Sauvagnat, K. IRIT at TREC 2019: Incident streams and complex answer retrieval tracks. In *Proceedings of the Twenty-Eighth Text REtrieval Conference, TREC*, NIST Special Publication. National Institute of Standards and Technology (NIST), 2019.\\n\\nElgohary, A., Peskov, D., and Boyd-Graber, J. L. Can you unpack that? learning to rewrite questions-in-context. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP*. Association for Computational Linguistics, 2019.\"}"}
{"id": "dai22a", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nFeng, S., Wan, H., Gunasekara, C., Patel, S., Joshi, S., and Lastras, L. Doc2dial: A goal-oriented document-grounded dialogue dataset. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020.\\n\\nGao, T., Yao, X., and Chen, D. Simcse: Simple contrastive learning of sentence embeddings. In Moens, M., Huang, X., Specia, L., and Yih, S. W. (eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP. Association for Computational Linguistics, 2021.\\n\\nGarg, N., Schiebinger, L., Jurafsky, D., and Zou, J. Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences, 115(16):E3635\u2013E3644, 2018.\\n\\nIizuka, S., Simo-Serra, E., and Ishikawa, H. Globally and locally consistent image completion. ACM Trans. Graph., 36(4):107:1\u2013107:14, 2017.\\n\\nKarpukhin, V., Oguz, B., Min, S., Lewis, P. S. H., Wu, L., Edunov, S., Chen, D., and Yih, W. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP. Association for Computational Linguistics, 2020.\\n\\nKomeili, M., Shuster, K., and Weston, J. Internet-augmented dialogue generation. arXiv preprint arXiv:2107.07566, 2021.\\n\\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A. P., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A. M., Uszkoreit, J., Le, Q., and Petrov, S. Natural questions: a benchmark for question answering research. Trans. Assoc. Comput. Linguistics, 2019.\\n\\nLee, K., Chang, M., and Toutanova, K. Latent retrieval for weakly supervised open domain question answering. In Korhonen, A., Traum, D. R., and M`arquez, L. (eds.), Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL. Association for Computational Linguistics, 2019.\\n\\nLewis, P., Wu, Y., Liu, L., Minervini, P., K\u00a8uttler, H., Piktus, A., Stenetorp, P., and Riedel, S. PAQ: 65 million probably-asked questions and what you can do with them. arXiv preprint arXiv:2102.07033, 2021.\\n\\nLi, H., Gao, T., Goenka, M., and Chen, D. Ditch the gold standard: Re-evaluating conversational question answering. arXiv preprint arXiv:2112.08812, 2021.\\n\\nLin, S.-C., Yang, J.-H., and Lin, J. In-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval. In Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP), Online, August 2021. Association for Computational Linguistics.\\n\\nLiu, G., Reda, F. A., Shih, K. J., Wang, T., Tao, A., and Catanzaro, B. Image inpainting for irregular holes using partial convolutions. In Ferrari, V., Hebert, M., Sminchisescu, C., and Weiss, Y. (eds.), Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part XI, Lecture Notes in Computer Science. Springer, 2018.\\n\\nMa, J., Korotkov, I., Yang, Y., Hall, K. B., and McDonald, R. T. Zero-shot neural passage retrieval via domain-targeted synthetic question generation. In Merlo, P., Tiedemann, J., and Tsarfaty, R. (eds.), Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL. Association for Computational Linguistics, 2021.\\n\\nMay, C., Wang, A., Bordia, S., Bowman, S., and Rudinger, R. On measuring social biases in sentence encoders. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL, 2019.\\n\\nNadeem, M., Bethke, A., and Reddy, S. Stereoset: Measuring stereotypical bias in pretrained language models. arXiv preprint arXiv:2004.09456, 2020.\\n\\nNakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al. WebGPT: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.\\n\\nNguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., and Deng, L. MS MARCO: A human generated machine reading comprehension dataset. In Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems, NIPS, 2016.\\n\\nNi, J., \u00b4Abrego, G. H., Constant, N., Ma, J., Hall, K. B., Cer, D., and Yang, Y. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models. arXiv preprint arXiv:2108.08877, 2021.\\n\\nNogueira, R. and Cho, K. Passage re-ranking with bert. arXiv preprint arXiv:1901.04085, 2019.\\n\\nNogueira, R., Jiang, Z., Pradeep, R., and Lin, J. Document ranking with a pretrained sequence-to-sequence model. In Findings of the Association for Computational Linguistics: EMNLP. Association for Computational Linguistics, 2020.\"}"}
{"id": "dai22a", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\n\\nQu, C., Yang, L., Chen, C., Qiu, M., Croft, W. B., and Iyyer, M. Open-retrieval conversational question answering. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR. ACM, 2020.\\n\\nQu, Y., Ding, Y., Liu, J., Liu, K., Ren, R., Zhao, W. X., Dong, D., Wu, H., and Wang, H. RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. In Toutanova, K., Rumshisky, A., Zettlemoyer, L., Hakkani-T\u00fcr, D., Beltagy, I., Bethard, S., Cotterell, R., Chakraborty, T., and Zhou, Y. (eds.), Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT. Association for Computational Linguistics, 2021.\\n\\nRadlinski, F. and Craswell, N. A theoretical framework for conversational search. In Proceedings of the 2017 conference on conference human information interaction and retrieval, 2017.\\n\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 2020.\\n\\nRam, P. and Gray, A. G. Maximum inner-product search using cone trees. In Yang, Q., Agarwal, D., and Pei, J. (eds.), The 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '12, Beijing, China, August 12-16, 2012, pp. 931\u2013939. ACM, 2012.\\n\\nReddy, S., Chen, D., and Manning, C. D. CoQA: A conversational question answering challenge. Transactions of the Association for Computational Linguistics, 7:249\u2013266, 2019.\\n\\nReimers, N. and Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks. In Inui, K., Jiang, J., Ng, V., and Wan, X. (eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP. Association for Computational Linguistics, 2019.\\n\\nRoller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott, M., Smith, E. M., Boureau, Y.-L., et al. Recipes for building an open-domain chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, 2021.\\n\\nSaeidi, M., Bartolo, M., Lewis, P., Singh, S., Rockt\u00e4schel, T., Sheldon, M., Bouchard, G., and Riedel, S. Interpretation of natural language rules in conversational machine reading. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2087\u20132097, 2018.\\n\\nSanthanam, K., Khattab, O., Saad-Falcon, J., Potts, C., and Zaharia, M. Colbertv2: Effective and efficient retrieval via lightweight late interaction. arXiv preprint arXiv:2112.01488, 2021.\\n\\nStede, M. and Schlangen, D. Information-seeking chat: Dialogues driven by topic-structure. In Proceedings of Catalog (the 8th workshop on the semantics and pragmatics of dialogue; SemDial04). Citeseer, 2004.\\n\\nThoppilan, R., Freitas, D. D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H. S., Ghafouri, A., Meningali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhou, Y., Chang, C.-C., Krivokon, I., Rusch, W., Pickett, M., Meier-Hellstern, K., Morris, M. R., Doshi, T., Santos, R. D., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson, B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q. Lambda: Language models for dialog applications, 2022.\\n\\nVakulenko, S., Longpre, S., Tu, Z., and Anantha, R. A wrong answer or a wrong question? an intricate relationship between question reformulation and answer selection in conversational question answering. In Proceedings of the 5th International Workshop on Search-Oriented Conversational AI (SCAI), 2020.\\n\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., and Polosukhin, I. Attention is all you need. In Advances in neural information processing systems, pp. 5998\u20136008, 2017.\\n\\nWu, Z., Luan, Y., Rashkin, H., Reitter, D., and Tomar, G. S. CONQRR: Conversational query rewriting for retrieval with reinforcement learning. arXiv preprint arXiv:2112.08558, 2021.\\n\\nXiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P. N., Ahmed, J., and Overwijk, A. Approximate nearest neighbor negative contrastive learning for dense text retrieval. In 9th International Conference on Learning Representations, ICLR, 2021.\\n\\nYang, J., Lin, S., Wang, C., Lin, J., and Tsai, M. Query and answer expansion from conversation history. In Voorhees, E. M. and Ellis, A. (eds.), Proceedings of the Twenty-Eighth Text REtrieval Conference, NIST Special Publication. National Institute of Standards and Technology (NIST), 2019.\"}"}
{"id": "dai22a", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dialog Inpainting: Turning Documents into Dialogs\\nYu, J., Lin, Z., Yang, J., Shen, X., Lu, X., and Huang, T. S.\\nGenerative image inpainting with contextual attention. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR. Computer Vision Foundation / IEEE Computer Society, 2018.\\n\\nYu, S., Liu, J., Yang, J., Xiong, C., Bennett, P. N., Gao, J., and Liu, Z. Few-shot generative conversational query rewriting. In Huang, J., Chang, Y., Cheng, X., Kamps, J., Murdock, V., Wen, J., and Liu, Y. (eds.), Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR. ACM, 2020.\\n\\nYu, S., Liu, Z., Xiong, C., Feng, T., and Liu, Z. Few-shot conversational dense retrieval. In SIGIR '21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 2021.\\n\\nZhang, Y., Sun, S., Galley, M., Chen, Y., Brockett, C., Gao, X., Gao, J., Liu, J., and Dolan, B. DIALOGPT: Large-scale generative pre-training for conversational response generation. In Celikyilmaz, A. and Wen, T. (eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL. Association for Computational Linguistics, 2020.\\n\\nZhu, F., Lei, W., Wang, C., Zheng, J., Poria, S., and Chua, T.-S. Retrieving and reading: A comprehensive survey on open-domain question answering. arXiv preprint arXiv:2101.00774, 2021.\\n\\nA. Inpainting Models\\nA.1. Datasets for dialog inpainter training\\n1. PublicDialog is an open-domain dialog dataset proposed by LaMDA (Thoppilan et al., 2022). Each dialog is mined from public forums and then scored and filtered using LaMDA's SSI and safety model. While the original dataset contains multi-speaker dialogs, we only use a subset consisting of two-speaker dialogs. Note that most of the dialogs in PublicDialog are short and have only two turns.\\n2. TaskMaster12 (Byrne et al., 2019) is a crowd-sourced dataset of task-oriented dialogs between two speakers. We only use the subset of dialogs related to movie ticket and restaurant reservations. While TaskMaster is significantly smaller than PublicDialog, its dialogs have many more turns, which helps mitigate turn bias.\\n\\n12 There are three datasets, Taskmaster-1, Taskmaster-2, and Taskmaster-3; we use Taskmaster-1. Also see https://github.com/google-research-datasets/Taskmaster.\\n3. OR-QuAC (Qu et al., 2020) is a version of the conversational question answering dataset QuAC (Choi et al., 2018) that consists of real human-human QA dialogs about a given Wikipedia article. OR-QuAC extends QuAC to the open-domain retrieval setting by making the first question context-independent and pairing each answer with a relevant passage from Wikipedia.\\n4. QReCC (Anantha et al., 2021) is another conversational question answering dataset constructed using question sequences from QuAC, TREC Conversational Assistant Track, and NaturalQuestions (Choi et al., 2018; Dalton et al., 2019; Kwiatkowski et al., 2019). For each question sequence, annotators search a document corpus to find relevant passages and answers. Though the questions in QReCC overlap with those in OR-QuAC, their answers can be completely different.\\n\\nA.2. Training details\\nUnless otherwise specified, all our dialog inpainters are initialized from T5-XXL (11B parameters) and finetuned using 64 TPU v3 chips with constant learning rate 0.01, dropout rate 0.1 and batch size 128. We trained the InpaintPT and InpaintPTOQ using 100k steps, and InpaintOQ using 10k steps because its training set is significantly smaller.\\n\\nA.3. Inference details\\nTo generate the inpainted datasets, we used https://beam.apache.org to parallelize our computation. On average, it took from 20ms (for T5-Small) to -141ms (for T5-XXL) to inpaint each utterance in a dialog, and required between 100 TPUv3-hours (for T5-Small) and 1900 TPUv3-hours (for T5-XXL) to inpaint each WikiDialog variant, and would cost between $240 and $4560 using preemptible TPUs on Google Cloud.\\n\\nB. Human Evaluation Protocol\\nIn this section we overview the human evaluation protocol used to evaluate WikiDialog variants and OR-QuAC in Section 3; the results of this evaluation were presented in Table 1.\\n\\nTask design and iteration. Figure 5 provides a screenshot of the annotation interface and a description of its features. The task was established as follows:\\n\\n13 The NaturalQuestions dataset does not originally contain question sequences, so the authors asked human annotators to come up with follow-up questions first.\\n\\n14 We use t5.1.1 checkpoints from https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md\\n\\n15 https://cloud.google.com/tpu/\"}"}
