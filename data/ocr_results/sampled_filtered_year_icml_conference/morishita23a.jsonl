{"id": "morishita23a", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nFigure E.6: An example of the template rule file for arguments used by the proof tree generator. Paraphrases of logical statements collected from human annotators. RT.BE is classified into \u201cmore\u201d since it is completely human-made and includes various paraphrases. For FLD corpora, \u201cless\u201d means that we used only one natural language template for each logical statement and limited vocabulary (sized 100) for each POS. For \u201cmore\u201d, we used several (up to five) natural language templates for each logical statement, and a large vocabulary (sized 5000) for each POS. Note that since the templates can be nested such as:\\n\\n$$(A \\\\land B) \\\\to C$$: \u201cIf $$(A \\\\land B)$$, then C.\u201d\\n\\nThus, the number of resulting patterns is combinatorially large.\\n\\nFormula Complexity: For FLD corpora that have formula complexity \u201csimple\u201d, we assign each compound formula such as $F$ and $G$ only a single atomic component as $F = A$ and $G = B$. For \u201ccomplex\u201d, we used compound formulas randomly constructed from atomic formulas with logical operators, such as $F = (A \\\\land B)$, $F = \\\\neg(A \\\\lor \\\\neg B)$, in addition to the \u201csimple\u201d formulas. RuleTaker corpora use \u201ccomplex\u201d formula.\\n\\nTree Depth: The tree depth of \u201ccritical thinking\u201d is limited to one because the critical thinking arguments have high-granularity, and thus cannot be easily combined to form multistep deductions.\\n\\nTree Depth Distribution: We have two types of tree depth distribution: skewed and uniform. The skewed distribution is biased toward lower depths. This distribution comes from the distribution of RT(D0-D3). The uniform distribution is uniform over the depths.\\n\\nF.2. Prover Training and Performance Measurement\\n\\nWe detail the prover training and performance measurements on the benchmarks. This experimental setting is basically the same as Yang et al. (2022). Thus, please refer to the study when necessary.\\n\\nF.2.1. THE PROVER MODEL\\n\\nWe added a slight modification to the original model for simplicity as follows. While the original model predicted an answer label (i.e., proved, disproved, or unknown) of a given instance on the basis of the log-likelihood of the augmented proof sequences, we predict the answer label by forcing the prover to generate the label token (\u201c__PROVED__\u201d, \u201c__DISPROVED__\u201d or \u201c__UNKNOWN__\u201d) at the end of proof sequences.\\n\\nF.2.2. FEW-SHOT TRANSFER TO SYNTHETIC DATA\\n\\nWe first train a prover on the training split of a corpus in Table 2. Then, we train the prover on a training split of another corpus in few-shot, and after that, we measured its performance on the test split. We used validation split for tuning hyperparameters. We adopted T5-base for prover LM for computational efficiency. Table F.11 shows the hyperparameters. For the \u201cfully-fine-tuning\u201d setting used in Section 5 and Appendix G, we trained a prover using all the dataset instances for 20k steps.\\n\\nWe run the experiments for one seed for computational reasons. Training on a source corpus takes about ten hours on a single NVIDIA A100 (48GB) GPU. Training on a target corpus takes a few hours on the same GPU.\\n\\nF.2.3. TRANSFER TO ENTAILMENT BANK\\n\\nWe first train a prover on the training split of a corpus from Table 2. Then, we train the prover on the training split of each EntailmentBank corpus. We adopted T5-large for prover LM following Yang et al. (2022). The hyperparameters are basically the same as Yang et al. (2022).\"}"}
{"id": "morishita23a", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For each formula, we have several templates. A template can be nested (redirected to other templates), as shown.\\n\\nThe final natural language templates of logical phrases.\\n\\nFigure E.7: An example the template file of the natural language assigner\\n\\nTable F.11: The hyperparameters of prover training in the transfer experiments among deduction corpora. See (Yang et al., 2022) or the code for other parameters.\\n\\n| Source corpus | Target corpus |\\n|---------------|--------------|\\n| transformer model | T5-base | T5-base |\\n| # dataset instances | 30000 | 300 |\\n| steps | 20000 | 2000 |\\n| learning rate | 1e-4 | 1e-4 |\\n| learning rate scheduler | AdamW | AdamW |\\n| warmup steps | 1000 | 500 |\\n| batch size | 64 | 64 |\\n| gradient clipping | 0.5 | 0.5 |\\n\\nFor training the verifier, we used exactly the same setting as Yang et al. (2022).\\n\\nFor the EB scorer, we used the same version as Yang et al. (2022), that is, version v3 that was released on May 28, 2022.\\n\\nWe run the experiments for six seeds. Training on a source synthetic deduction corpus takes about one day on a single NVIDIA A100 (48GB) GPU. Training on a target EB corpus takes about one day on the same GPU.\\n\\nTable F.12: The hyperparameters of prover training in the transfer experiments from deduction corpora to Entailment-Bank. See (Yang et al., 2022) or the code for other parameters.\\n\\n| Source synthetic corpus | Target EB corpus |\\n|-------------------------|------------------|\\n| transformer model | T5-large | T5-large |\\n| # dataset instances | 30000 | 1313 |\\n| steps | 10000 | 10000 |\\n| learning rate | 1e-4 | 5e-5 (task1), 2.5e-5 (task2) |\\n| learning rate scheduler | AdamW | AdamW |\\n| warmup steps | 1000 (task1), 3000 (task2) | |\\n| batch size | 64 | 64 |\\n| gradient clipping | 0.5 | 0.5 |\\n\\nF.3. License of used Datasets.\\n\\nAll the datasets used in this paper are publicly available: RuleTaker (Clark et al., 2021; Tafjord et al., 2021), EntailmentBank (Mishra et al., 2022) and FLD (will be publicly available).\"}"}
{"id": "morishita23a", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We analyze the challengingness of each corpus in detail by using Table G.13.\\n\\nFirst, we look into the results on skewed depth distribution corpora. As seen, sFLD-impl is more challenging than RuleTaker corpora. Since the corpus design in relevant aspects is aligned between RuleTaker and sFLD-impl as in Table 2, the difference should come from the other implementation details. For example, the distractors of FLD are designed to be easily confused with positive facts (Section 3.2), and natural language assignments are extremely diverse due to the random statement generation (Section 3.3).\\n\\nFLD-impl.0 is more challenging than sFLD-impl even though they use the same arguments. This should be because FLD-impl.0 has \\\"uniform\\\" tree depth distribution and thus includes a higher depth tree than sFLD-impl do (Appendix F.1).\\n\\nThe reason that FLD.2 is more challenging than FLD-impl.0 should be as follows. First, since a proof tree is constructed from the combination of arguments chosen at each level of the tree, the number of possible proof tree patterns can be estimated (very roughly) as $O(A^d)$, where $A$ is the number of argument choices at each level and $d$ is the depth of the proof tree. Next, while FLD-impl.0 uses only a few arguments ($A = 2$) of implication type shown in Figure B.3b, FLD.2 uses various arguments ($A \\\\sim 10$) of the axioms shown in Figure B.3a. Thus, FLD.2 includes exponentially more diverse patterns of proof trees than RuleTaker. This makes FLD.2 more challenging than FLD-impl.0.\\n\\nFLD.3 is the linguistically diverse version of FLD.2. The challengingness of FLD.3 remains almost the same as that of FLD.2 provably because LMs can solve the linguistic aspects such as paraphrasing, as discussed in Section 7.2.\\n\\nFLD.4 is the higher-depth ($d$ up to 8) version of FLD.3. This corpus is the most challenging provably due to the exponentially combinatorially more diverse patterns proof trees coming from $O(A^d)$.\\n\\n### G.1. Answer Accuracies on Transfer Experiments among Deduction Corpora\\n\\nBelow, we show the results of transfer among synthetic corpora measured by the other metric of answer accuracy. However, notice that, as stated in Section 4.2, due to biases in fact sets, answers can be guessed without considering proofs to some extent, as found in Tafjord et al. (2021) where answer accuracy exceeds proof accuracy. Thus, the answer accuracy is not appropriate for measuring the logical deductive reasoning ability explicitly.\\n\\nTable G.14: Answer accuracy of a prover fully fine-tuned using all the dataset instances on each corpus.\\n\\n| Source Corpus     | RT   | RT.PR | sFLD-impl | FLD-impl.0 | FLD.2 | FLD.3 | FLD.4 |\\n|-------------------|------|-------|-----------|------------|-------|-------|-------|\\n|                   | 95.2 | 95.8  | 96.1      | 94.9       | 88.3  | 87.7  | 68.1  |\\n\\nTable G.15: Few-shot answer accuracies of provers transferred among corpora that differ in arguments.\\n\\n| Source Corpus | RT   | RT.PR | sFLD-impl | sFLD-crit | sFLD-RT    |\\n|---------------|------|-------|-----------|-----------|------------|\\n|               | 80.7 | 95.2  | 93.7      | 83.6      | 83.2       |\\n|               | 78.4 | 93.0  | 95.8      | 82.5      | 79.7       |\\n|               | 56.2 | 88.3  | 88.2      | 75.2      | 79.4       |\\n| FLD (RT)      | 78.3 | 83.1  | 83.3      | 96.1      | 86.0       |\\n| FLD (AA)      | 84.9 | 85.5  | 84.5      | 91.7      | 95.2       |\\n| FLD (axiom)   | 79.0 | 76.9  | 76.9      | 87.3      | 85.7       |\\n| avg.          | 76.3 | 87.0  | 87.1      | 86.1      | 84.9       |\\n\\nTable G.16: The depth-wise answer accuracies of the provers.\\n\\n#### (a) Target corpus is FLD-impl.1.\\n\\n| Source Corpus | T5 | FLD-impl.0 | FLD-impl.1 |\\n|---------------|----|------------|------------|\\n|               | 0  | 50.0       | 91.7       |\\n|               | 1  | 96.8       | 98.4       |\\n|               | 2  | 88.0       | 97.0       |\\n|               | 3  | 90.0       | 93.8       |\\n|               | 4  | 88.9       | 93.3       |\\n|               | 5  | 72.6       | 90.5       |\\n|               | 6  | 78.7       | 89.3       |\\n|               | 7  | 84.0       | 90.6       |\\n|               | 8  | 82.0       | 90.2       |\\n| avg.          | 81.2 | 92.8       | 93.5       |\\n\\n#### (b) Target corpus is FLD.4.\\n\\n| Source Corpus | T5 | FLD.3 | FLD.4 |\\n|---------------|----|-------|-------|\\n|               | 75.0 | 100.0 | 100.0 |\\n|               | 82.4 | 98.6  | 95.9  |\\n|               | 77.3 | 89.8  | 91.5  |\\n|               | 78.9 | 84.2  | 78.9  |\\n|               | 76.7 | 79.5  | 71.2  |\\n|               | 70.4 | 65.7  | 60.6  |\\n|               | 70.6 | 63.5  | 51.8  |\\n|               | 77.1 | 52.9  | 47.1  |\\n|               | 71.1 | 47.0  | 45.2  |\\n|               | 75.5 | 75.7  | 71.4  |\\n\\nTable G.17: Few-shot answer accuracies of provers transferred among corpora that differ in the diversity of linguistic expressions.\\n\\n| Source Corpus | T5 | RT | RT.PR | FLD.2 | FLD.3 |\\n|---------------|----|----|-------|-------|-------|\\n|               | RT | 80.7 | 95.2 | 93.7  | 85.2  |\\n|               | RT.PR | 78.4 | 93.0 | 95.8  | 80.8  |\\n|               | FLD.2 | 72.1 | 72.1 | 71.3  | 88.3  |\\n|               | FLD.3 | 68.2 | 68.0 | 67.7  | 86.7  |\\n| avg.          |     | 74.9 | 82.1 | 82.1  | 85.3  |\\n\\n19\"}"}
{"id": "morishita23a", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nTable G.18: Few-shot answer accuracies of provers transferred among corpora that differ in the complexity of formulas.\\n\\n|          | T5 | FLD.1 | FLD.2 |\\n|----------|----|-------|-------|\\n| FLD.1    | 77.9 | 96.5  | 91.6  |\\n| FLD.2    | 72.1 | 77.8  | 88.3  |\\n\\nTable G.19: Few-shot answer accuracies of provers transferred among corpora that differ in the number of distractors.\\n\\n|          | T5 | FLD.0 | FLD.2 |\\n|----------|----|-------|-------|\\n| FLD.0    | 77.7 | 95.8  | 93.4  |\\n| FLD.2    | 72.1 | 83.1  | 88.3  |\\n\\nG.2. Results of Other Metrics on EntailmentBank\\n\\nWe show the results of other metrics on EntailmentBank in Tables G.20 to G.22.\\n\\nG.3. Case Study on EntailmentBank\\n\\nTable G.23 shows some cases where the error of the baseline prover (T5) is fixed by the training on a deduction corpus (FLD.D5).\\n\\nAs seen from \\\"T5 error fixed by FLD.D5\\\" column, typical error of T5 is such as follows: (i) T5 misses some of the premises required to derive the required conclusion, or, simply choose wrong premises. (ii) T5 overclaims, that is, included in the generated conclusion such information that does not logically follow from the chosen premises. It is also suggested that T5 does not understand the rules of logical operators such as negation $\\\\neg$ and conjunction $\\\\land$.\\n\\nIn contrast, the prover trained on FLD.D5 captured the fundamentals of deduction rules better than the baseline: (i) it chose correct premises necessary and sufficient to derive the next conclusion, (ii) it included in a conclusion only such information that logically follows from the chosen premises, and (iii) it correctly used the rules of logical operators.\"}"}
{"id": "morishita23a", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"can make an instance of any answer label as follows. For answer label \u201cproved\u201d, (i) we use the root node as the hypothesis, (ii) we use the leaf nodes of the proof tree and the distractors as the fact set, and (iii) we use the internal nodes of the proof tree as the proof sequence. For answer label \u201cdisproved\u201d, we use the negated statement of the root node as the hypothesis so that the hypothesis is disproved by the proof sequence. For answer label \u201cunknown\u201d, we randomly drop some of the leaf nodes so that the hypothesis cannot be proved or disproved by the proof sequence.\\n\\n4. Experiments\\n\\nWe conducted experiments to verify the effectiveness of FLD, and to identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs. To this end, we examined various deduction corpora shown in Table 2. We trained LMs on the deduction corpora and measured their performance on relevant benchmarks. For reference, we also measured the performance of a LM (T5) without training on the deduction corpora. We used two types of benchmarks: deduction corpora themselves and human-authored EntailmentBank (Dalvi et al., 2021). We briefly explain the setup. See Appendix F for the details.\\n\\n4.1. Prover Model\\n\\nAll the experiments involve generating a proof sequence to (dis-)prove a given hypothesis from a given set of facts. To tackle the task of this type, we adopt the stepwise prover model from Yang et al. (2022). This prover is a generative model based on T5 (Raffel et al., 2020), which generates one proof step at a time. A proof step represents the chosen premises and the derived (generated) conclusion, such as \u201cfact1 & fact3 -> The Earth has seasons\u201d. The prover continues the generation until the given hypothesis is (dis-)proved.\\n\\n4.2. Few-shot Transfer to Synthetic Deduction Corpora\\n\\nThe first benchmark is the deduction corpora, which measure rigid logical reasoning ability. We trained prover LM on a corpus and measured its performance on another corpus. If LMs have acquired robust deductive reasoning ability, they should transfer well with a small number of examples. To see this, we used few-shot setting.\\n\\nWe trained prover LM (T5-base) on the training split of each source corpus for 20k steps with a batch size of 64 and learning rate of 1e-4. Then we fine-tuned the prover LM on 1% subset (300 instances) of the training split of the target corpus. Finally, we measure the performance of the prover on the test split of the target corpus by using proof accuracy (Saha et al., 2020), which measures whether the generated proofs match the gold proofs.\\n\\n4.3. Transfer to EntailmentBank\\n\\nEntailmentBank (EB) (Dalvi et al., 2021) is a recently proposed challenging benchmark. The proof trees in the EB dataset are human-authored rather than synthetically generated. Further, each proof step can be rough entailment instead of a rigid logical step. Thus, EB measures logical reasoning ability in a more real-world scenario.\\n\\nWe used all the three tasks of EB, which differ in the property of a given fact set: Task1 does not include distractors, Task2 includes distractors, and Task3 includes sentences retrieved from worldTree V2 (Xie et al., 2020).\\n\\nAs stated above, the nature of proof steps in EB differs much from the nature of those in deduction corpora. Thus, it is difficult for prover LMs trained on deduction corpora to transfer to EB with a small number of examples. Thus, we fine-tuned the provers using all the EB instances.\\n\\nWe trained a prover LM (T5-large) on a source deduction corpus for 10k steps and fine-tuned it on each EB corpus for 10k steps. For all the training, the batch size was 64 and the learning rate was 5e-5, except EB-task2 where the learning rate of 2.5e-5 was used. For EB-task3, we used the prover trained on task2, following Dalvi et al. (2021). Given the challengingness of EB, we used the additional RoBERTa (Liu et al., 2019) based proof step verifier proposed in Yang et al. (2022). We measured the performance of the provers on the test split of EB by the official metric of \u201cAllCorrect\u201d proof accuracy (Dalvi et al., 2021).\\n\\n5. How Well do LMs Solve Logic?\\n\\nTable 3: Proof accuracy of a prover fully fine-tuned using all the dataset instances on each corpus.\\n\\n| RuleTaker | FLD | RT | RT.PR |\\n|-----------|-----|----|--------|\\n| 92.4      | 93.9| 66.4| 37.7   |\\n\\nFirst, we show how well LMs solve logic of each deduction corpus (Table 3). As shown, while the fully fine-tuned provers performed well on RuleTaker, they performed poorer on FLD. One possible reason is as follows. First, since a proof tree is constructed from the combination of\"}"}
{"id": "morishita23a", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nTable 2: The corpora examined in this paper. For RuleTaker (\\\"RT\\\"), we used the OW A version introduced by Tafjord et al. (2021). To align conditions as closely as possible across the corpora being compared, we (i) generated multiple FLD corpora using the options and template files and (ii) added several preprocessings to RuleTaker. See Appendix F.1 for details.\\n\\n| name arguments (deduction rules) | distractors (up to) | linguistic diversity | formula complexity | tree depth distribution | # train examples |\\n|---------------------------------|---------------------|---------------------|--------------------|------------------------|-----------------|\\n| RT (\\\"D0-D3\\\") implication       | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| RT.PR (\\\"ParaRules\\\") implication | \u223c20                 | more complex        | 1\u20135                | skewed                 | 30k             |\\n| RT.BE (\\\"Birds-Electricity\\\") implication | \u223c20             | more complex        | 1\u20133                | - (test only)         |                 |\\n| sFLD-impl implication           | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| sFLD-crit critical thinking     | \u223c20                 | less complex        | 1\u20131                | skewed                 | 30k             |\\n| sFLD-axiom (SFLD) the axioms    | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| RT.D5 (\\\"D0-D5\\\") implication    | \u223c20                 | less complex        | 1\u20135                | uniform               | 30k             |\\n| FLD.D5 the axioms               | \u223c20                 | less complex        | 1\u20135                | uniform               | 30k             |\\n| FLD-impl.0 implication          | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| FLD-impl.1 implication          | \u223c20                 | less complex        | 1\u20138                | skewed                 | 30k             |\\n| FLD.0 the axioms                | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| FLD.1 the axioms                | \u223c20                 | less complex        | 1\u20133                | skewed                 | 30k             |\\n| FLD.2 the axioms                | \u223c20                 | more complex        | 1\u20133                | skewed                 | 30k             |\\n| FLD.3 (FLD) the axioms          | \u223c20                 | more complex        | 1\u20133                | skewed                 | 30k             |\\n| FLD.4 (FLD \u22c6) the axioms        | \u223c20                 | more complex        | 1\u20138                | skewed                 | 30k             |\\n\\n6. How Effective is Formal Logic Deduction?\\n\\n6.1. Benchmarking by Deduction Corpora\\n\\nTable 4: Few-shot proof accuracies of provers transferred among SFLD and baseline corpora. For fair comparison, all the corpora have the same depth distribution (except sFLD-crit that cannot form multistep easily, see Appendix F.1)\\n\\n| Source corpus | Target corpus | T5 | RT | RT.PR | sFLD-impl | sFLD-crit | sFLD |\\n|---------------|--------------|----|----|-------|-----------|----------|------|\\n| T5            | RT           | 70.1 | 92.4 | 91.3 | 76.2 | 74.4 | 76.7 |\\n| RT            | RT           | 64.3 | 91.3 | 93.9 | 73.4 | 67.5 | 72.9 |\\n| RT            | RT.PR       | 56.1 | 88.3 | 88.2 | 75.2 | 79.4 | 85.0 |\\n| RT            | sFLD-impl   | 58.4 | 66.7 | 65.9 | 82.2 | 67.3 | 80.7 |\\n| RT            | sFLD-crit   | 71.9 | 77.7 | 77.2 | 87.8 | 94.0 | 93.6 |\\n| RT            | sFLD        | 54.7 | 54.5 | 54.5 | 67.9 | 63.7 | 79.1 |\\n| avg.          |              | 62.6 | 78.5 | 78.5 | 77.1 | 74.4 | 81.3 |\\n\\nWe trained a prover on a deduction corpus (\\\"source corpus\\\") and measured its performance on other corpora (\\\"target corpus\\\") (Table 4). The prover trained on SFLD performed the best on average, and as seen from the corpus-wise results, the prover transferred the most robustly to the other corpora while the provers trained on the other corpora did not exhibit this level of robustness. Since the corpora used in Table 4 differ in the set of arguments (deduction rules) used in proofs, this result suggests that the prover trained SFLD generalized the most to other arguments.\\n\\nThe reason for this strongest generalizability should be the following. (SFLD) corpora teach LMs how to construct multistep deductions using the axioms. Thanks to the completeness, the axioms can express multistep deductions constructed from any other arguments (including the ones used in the other corpora, as exemplified in Figure B.4). Thus, mastering the axioms leads to mastering various other arguments. On the other hand, the sets of arguments used in the other corpora do not have such a property and thus cannot generalize to other arguments.\\n\\nSince mastering various arguments is the most important in deductive reasoning, this generalizability to arguments obtained from FLD corpora is vital.\\n\\n6.2. Benchmarking by EntailmentBank\\n\\nTable 5: The proof accuracy of provers on EntailmentBank. See Appendix G.2 for the results of other metrics.\\n\\n| EntailmentBank | Task1 | Task2 | Task3 |\\n|----------------|-------|-------|-------|\\n| Source corpus  | T5    | RT    | FLD.D5 |\\n| EntailmentBank | 36.8\u00b10.9 | 31.2\u00b10.7 | 6.2\u00b10.9 |\\n| EntailmentBank | 39.4\u00b10.9 | 32.0\u00b10.8 | 8.2\u00b10.8 |\\n| EntailmentBank | 39.2\u00b11.2 | 32.6\u00b11.0 | 8.3\u00b10.7 |\\n\\nTable 5 shows the results on EntailmentBank (EB). Since EB trees have high-depth (majority up to five), we used the high-depth versions of deduction corpora as source corpus. First, as seen, the provers trained on both deduction corpora (RT.D5, FLD.D5) performed better than the baseline prover without such training (T5). This suggests that the\"}"}
{"id": "morishita23a", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\ndeductive reasoning ability acquired by synthetic deduction corpora generalizes to more complex real-world deductive reasoning. We showcase some examples in Appendix G.3, where the error of the baseline prover is fixed by training on a deduction corpus (FLD.D5). As seen, the prover captured the fundamentals of deduction rules better than the baseline as follows: (i) it chose the correct premises necessary and sufficient to derive the next conclusion, (ii) it included only such information that logically follows from the chosen premises into a conclusion, and (iii) and it correctly used the rules of logical operators.\\n\\nLooking at the results of deduction corpora closely, the prover trained on FLD.D5 performed on par with the prover trained on RT.D5, even though it had mastered various deduction rules better, as shown in Section 6.1. We consider a possible reason as follows. Firstly, real-world reasoning can require more coarse-grained deduction rules than those required by deduction corpora. For expressing such coarse-grained deduction rules by the most fine-grained axioms, many steps are required, as in Figure 2. However, the prover trained on FLD still struggles with constructing many-step proofs using the axioms (detailed in Section 7.1). In this sense, the prover could have failed to exploit the axioms' potential fully. We will discuss future directions to tackle this challenge in Section 8.\\n\\n7. On What Aspects are Synthetic Deduction Corpora Beneficial?\\n\\nA deduction corpus in Table 2 emphasizes a specific aspect different from those emphasized by the other corpora. For each corpus (each aspect), we investigate whether the LM trained on that corpus outperforms the LM trained on the other corpus that does not emphasize the aspect. If it does, we interpret it as meaning that the supervision from deduction corpus on that aspect is beneficial for LMs.\\n\\n7.1. Ability to Solve Complex Proof Trees\\n\\nTable 6: The depth-wise proof accuracies of the provers.\\n\\n| Source corpus | Target corpus is FLD-impl.1 | Target corpus is FLD.4 |\\n|---------------|----------------------------|-----------------------|\\n| T5            | FLD-impl.0                 | FLD-impl.1             |\\n|               | 41.7                       | 83.3                  |\\n|               | 77.4                       | 88.7                  |\\n|               | 38.0                       | 56.0                  |\\n|               | 33.8                       | 50.0                  |\\n|               | 36.7                       | 51.1                  |\\n|               | 21.4                       | 42.9                  |\\n|               | 22.7                       | 38.7                  |\\n|               | 25.5                       | 38.7                  |\\n|               | 23.0                       | 36.1                  |\\n|               | avg.                       | 35.6                  |\\n\\nTable 6 shows the depth-wise performances of provers. The corpora in Table 6a use the implication arguments. The prover trained on the corpus of shallower (~3) trees (FLD-impl.0) generalizes to deeper (~4~8) trees to some extent, and performs similarly to the prover trained on the corpus of deeper trees (FLD-impl.1). This generalization to deeper trees coincides with previous findings (Tafjord et al., 2021; Sanyal et al., 2022). However, as Table 6b shows, when the corpora use the axioms, neither the provers trained on the shallower tree corpus (FLD.3) nor deeper tree corpus (FLD.4) failed in solving deeper trees.\\n\\nWe can interpret this seemingly contradictory result as follows. As discussed in Section 5, the number of possible proof tree patterns can be estimated (very roughly) as $O(A^d)$. When a prover tries to solve a deduction instance, it has to choose and generate exactly the one gold proof tree from these possible negative proof trees. This should be very difficult for large $d$ with large $A$. Now, while the corpora in Table 6a use a few arguments ($A = 2$) of implication type, corpora in Table 6b use various arguments ($A \\\\sim 10$) of the axioms. This made it very difficult to solve large-depth deduction instances of these corpora, which lead the provers to fail in solving large-depth proof trees in Table 6b.\\n\\nOverall, for solving complex trees, the supervision from deduction corpora can be necessary but not sufficient alone.\\n\\n7.2. Understanding of Diverse Linguistic Expressions\\n\\nTable 7: Few-shot proof accuracies of provers transferred among corpora that differ in the diversity of linguistic expressions.\\n\\n| Source corpus | RuleTaker FLD | T5 | RT | RT.PR | FLD.2 | FLD.3 |\\n|---------------|--------------|----|----|-------|-------|-------|\\n| Target corpus | RT           | 70.1| 92.4| 91.3  | 78.3  | 76.6  |\\n|               | RT.BE        | 64.3| 91.3| 93.9  | 71.3  | 73.4  |\\n|               | FLD.2        | 31.0| 34.2| 34.7  | 66.8  | 66.2  |\\n|               | FLD.3        | 24.8| 28.7| 27.5  | 65.3  | 66.4  |\\n| avg.          |              | 47.6| 61.6| 61.8  | 70.4  | 70.7  |\\n\\nTable 7 shows that a prover trained on a corpus with less linguistic diversity (i.e., RT and FLD.2) performed as well as the prover trained on the linguistically diverse counterpart of that corpus (i.e., RT.PR and FLD.3, respectively). This suggests that LMs are self-sufficient on the linguistic aspect, and thus additional supervision from deduction corpora is not that important.\\n\\nIndeed, this result coincides with the previous findings (Clark et al., 2021; Tafjord et al., 2021) and can be intuitively understood: since the pre-training corpora of LMs are huge and linguistically diverse, they should have given LMs many chances to learn linguistic of logical statements such as that \\\"If A, then B\\\" paraphrases to \\\"A leads to B\\\".\\n\\n7.3. Understanding of Complex Formulas\\n\\nTable 8 shows that while the prover trained on the corpus with simple formulas (FLD.1) performed poorly on the corpus with complex formulas (FLD.2), the prover trained\"}"}
{"id": "morishita23a", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nTable 8: Few-shot proof accuracies of provers transferred among corpora that differ in the complexity of formulas.\\n\\n| Source corpus | T5 | FLD.1 | FLD.2 |\\n|---------------|----|-------|-------|\\n| Target corpus | FLD.1 | 43.1  | 77.9  |\\n|               | FLD.2 | 31.0  | 46.0  |\\n\\nFLD.2 performed well on both corpora. Thus, deduction corpora are beneficial for mastering complex formulas.\\n\\nWe can interpret this result as follows. The complex formulas included in FLD.2 are formed by modifying atomic formulas with logical operators $\\\\neg$, $\\\\land$, $\\\\lor$. The semantics of these logical operators, such that \u201ca sentence with negation $\\\\neg$ have the opposite meaning of that sentence without negation\u201d, and that \u201cA $\\\\lor$ B does not necessarily imply A\u201d, are seldom written explicitly by humans. Thus, the pre-training corpora gave LMs too few chances for learning these semantics. This result is enhanced by the previous findings that LMs fail to understand the semantics of negation (Naik et al., 2018; Hossain et al., 2020; Kassner & Sch\u00fctze, 2020).\\n\\n7.4. Robustness to Distractive Facts\\n\\nTable 9: Few-shot proof accuracies of provers transferred among corpora that differ in the number of distractors.\\n\\n| Source corpus | T5 | FLD.0 | FLD.2 |\\n|---------------|----|-------|-------|\\n| Target corpus | FLD.0 | 38.9  | 76.4  |\\n|               | FLD.2 | 31.0  | 56.7  |\\n\\nTable 9 shows that, while the prover trained on the corpus without distractors (FLD.0) performed poorly on the corpus with distractors (FLD.2), the prover trained on FLD.2 performed well on both corpora. Thus, synthetic distractors are beneficial for acquiring the robustness to distractive facts. This result is intuitive: since the human-written text should not include the facts irrelevant to the content, the pre-training corpora should not have given LMs a chance to acquire robustness to irrelevant facts.\\n\\n8. Discussions and Future Directions\\n\\nSo far, we have investigated each aspect of deductive reasoning. We summarize the results and discuss future directions.\\n\\nMastery on Various Deduction Rules:\\nMastery on various deduction rules is the most important in deductive reasoning. We showed that FLD corpora teach LMs various arguments the most effectively (Section 6.1). This should be because that FLD adopts the axioms of first-order predicate logic system, which can derive any valid deduction rules in this system. The next step will be to examine the axioms of other logic systems, such as linear and modal logic systems, which are also important in real-world reasoning.\\n\\nAbility to Solve Complex Proof Trees:\\nWe have shown that solving a many-step proof tree is still challenging for LMs even after training on deduction corpora (Section 7.1). The possible reason is that they have to choose and generate a gold proof from a large number of possible trees. To solve this problem, inventing smarter and strategic search methods on possible generation space, such as Li et al. (2016); Negrinho et al. (2018); Picco et al. (2021); Welleck et al. (2022), could be a promising direction.\\n\\nUnderstanding of Complex Formulas:\\nWe have shown that deduction corpora are effective for LMs to understand the semantics of logical operators such as $\\\\neg$, $\\\\land$, $\\\\lor$ (Sections 6.2 and 7.3). It could be even more effective to incorporate the recent learning methodological approaches for making LMs understand negation (Pr\u00f6llochs et al., 2019; Hosseini et al., 2021) into the learning on deduction corpora.\\n\\nRobustness to Distractive Facts:\\nWe have shown that the synthetic distractors can make LMs robust to distractive facts (Section 7.4). In a real scenario of logical reasoning, the facts have to be collected by possibly incomplete retrieval systems. The distractors that imitate ones appearing in such a scenario could be more effective. We can generate such distractors as follows: (i) We build a database of synthetic facts. (ii) For a given deduction instance, we collect facts from the database by actual retrieval systems.\\n\\nGeneralization to Real-World Reasoning Tasks:\\nWe have shown that the training on deduction corpora is even useful for deductive reasoning in a more real-world setting (Section 6.2). However, the LMs trained on FLD could not fully utilize the potential of the axioms, as they failed in constructing many-step proofs to express coarse-grained deduction rules, which could be required in real-world reasoning (Sections 6.2 and 7.1). We discussed future directions to solve such many-step proofs above.\\n\\nFurther, LMs may need additional training to utilize deduction rules well in a realistic context. For example, the LMs could have to combine deduction rules with common sense knowledge, use multiple deduction rules at once to jump to the next conclusion, and judge the validity of a proof step considering the overall context. Recently, Wei et al. (2022); Kojima et al. (2022) showed that large LMs can utilize deduction rules in a realistic context, given appropriate prompts. It could be promising to integrate this approach and deduction corpora training.\\n\\nPursuing further real-world scenarios, we have to tackle tasks of other settings. One is deductive reasoning that requires us to collect relevant facts by ourselves. For this, we could exploit factual knowledge implicitly embedded in LMs (Petroni et al., 2019; Davison et al., 2019; Talmor et al., 2020), or use retrieval systems. For the latter, we could train LM-based retrievers (Karpukhin et al., 2020; Guu et al., 2020) using synthetic deduction instances and fact database. Abductive reasoning (Bhagavatula et al., 2019) is\"}"}
{"id": "morishita23a", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nWe study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name FLD (Formal Logic Deduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.\\n\\n1. Introduction\\n\\nBuilding a machine that logically reasons step by step has been the Holy Grail since the early era of artificial intelligence (McCarthy, 1959). Such a machine will solve complex real-world problems in a very explainable and transparent way. Toward this goal, various benchmarks for measuring logical reasoning ability have recently been proposed (Weston et al., 2015; Habernal et al., 2018; Niven & Kao, 2019; Richardson et al., 2020). Usually, researchers tackle these benchmarks using state-of-the-art language models (LMs) expecting their remarkable linguistic understanding ability. Yet still, even such powerful LMs struggle with these benchmarks, showing their limited logical reasoning ability (Askell, 2020; Rae et al., 2021; Yang et al., 2022). LMs have acquired their linguistic understanding ability inductively from a lot of high-quality examples in human-written texts (Devlin et al., 2019). Conversely, their poor logical reasoning ability suggests the lack of high-quality examples of logical reasoning. This is not a surprise given that humans usually think reflexively rather than logically step by step (Kahneman, 2011). The consideration here suggests a straightforward strategy to equip LMs with logical reasoning ability: create corpora that include many examples of valid logical reasoning and train LMs on them.\\n\\nFor this purpose, we can use the recently proposed RuleTaker (Clark et al., 2021). RuleTaker is a benchmark composed of many synthetically generated multistep deductive proofs written in natural languages. Each deductive proof (dis-)proves a hypothesis by applying deduction rules multiple times to a given set of facts (the same as \u201cDeduction Instance\u201d in Figure 1). RuleTaker adopted the deduction rules of the implication kind, such as $\\\\forall x F(x) \\\\rightarrow G(x)$, $F(a) \\\\vdash G(a)$ (here, $\\\\vdash$ means \u201cderives\u201d). Artificial Argument Corpus (AACorpus) (Betz et al., 2021) is another corpus composed of synthetically generated single-step deductive proofs. AACorpus adopted hand-selected deduction rules useful for critical thinking, such as contraposition $F \\\\rightarrow G \\\\vdash \\\\neg G \\\\rightarrow \\\\neg F$. All these corpora could offer LMs opportunities to acquire logical deductive reasoning ability, one of the most important and universally used logical reasoning abilities.\\n\\nHowever, it is still an open question whether this research direction will genuinely lead to the improvement of deductive reasoning ability. First, the deduction rules used in the previous corpora were limited or otherwise arbitrary. This can limit the generalizability of the acquired deductive reasoning ability since complex real-world reasoning can require various deduction rules. Second, it has not yet been studied on what aspect of deductive reasoning ability deduction corpora can enhance LMs. Such aspects will include, in addition to the mastery of deduction rules, the ability to solve complex deductive proofs, understanding of diverse linguistic expressions of logical statements, robustness to distractive facts, and understanding of complex formulas.\"}"}
{"id": "morishita23a", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nArguments\\n\\n\u25c6 tree depth = 3\\n\u25c6 # of branches = 5\\n\u25c6 formula complexity\\n\\n\u27a2 up to 2 propositions with $\\\\land$, $\\\\lor$, $\\\\neg$\\n\\nNL templates\\n\\n\u25c6 Vocab=100000\\n\\nFacts:\\n1. The Earth revolves around the sun and the Earth's axis is tilted.\\n2. ...\\n3. If the Earth revolves around the sun and the Earth's axis is tilted, then the Earth has seasons.\\n4. ...\\n5. That the Earth has seasons results in that climate changes throughout a year, and crops grow in abundance.\\n\\nHypothesis:\\nClimate changes throughout a year.\\n\\nProof:\\nfact1 & fact3 $\\\\rightarrow$ int1: the Earth has seasons.\\nfact5 $\\\\rightarrow$ int2: that the Earth has seasons results in that climate changes throughout a year.\\nInt1 & int2 $\\\\rightarrow$ climate changes throughout a year.\\n\\nAnswer: proved\\n\\n\u2026\\n\\n\u2192 introduction\\n\u2026\\n\\n\u2227 elimination\\n\\nProof\\n\\nTree Generator\\n\\nModus ponens $\\\\mathcal{F} \\\\mathcal{F} \\\\rightarrow \\\\mathcal{G}$\\n\\nNatural Language Assigner\\n\\nFactual Distractor Generator\\n\\n(\\\\( A \\\\land C \\\\)) $\\\\rightarrow$ \\\\( B \\\\)\\n\\n\\\\( C \\\\) $\\\\rightarrow$ (\\\\( D \\\\lor E \\\\))\\n\\n(\u2026)\\n\\nFactual Distractors\\n\\nNL assignments\\n\\n\\\\( A \\\\): The Earth revolves around the sun.\\n\\\\( B \\\\): The Earth's axis is tilted.\\n\\\\( C \\\\): The Earth has seasons.\\n\\\\( D \\\\): Crops grow in abundance.\\n\\\\( E \\\\): Climate changes throughout a year.\\n\\n\\\\( A \\\\land B \\\\): The Earth revolves around the sun and the Earth's axis is tilted.\\n\\n\\\\( A \\\\land B \\\\rightarrow C \\\\): If the Earth revolves around the sun and the Earth's axis is tilted, then the Earth has seasons.\\n\\n\\\\( C \\\\rightarrow E \\\\land D \\\\): That the Earth has seasons results in that climate changes throughout a year, and crops grow in abundance.\\n\\nDeduction Instance Converter\\n\\n\u25c6 \\\\{\\\\( A \\\\}\\\\} $\\\\rightarrow$ \\\\{\\\\( B \\\\}\\\\}:\\n\\n\u27a2 \\\"if \\\\{\\\\( A \\\\}\\\\}, then \\\\{B\\\\}\\\"\\n\\n\u27a2 \\\\{\\\\( A \\\\}\\\\} results in \\\\{\\\\( B \\\\}\\\\}\\n\\n\u25c6 $\\\\forall x \\\\{\\\\( A \\\\}\\\\} x \\\\rightarrow \\\\{\\\\( B \\\\}\\\\} (x)$:\\n\\n\u27a2 \\\"if something is \\\\{\\\\( A \\\\}\\\\}, then it is also \\\\{\\\\( B \\\\}\\\\}\\\"\\n\\n\u27a2 \\\\{\\\\( A \\\\}\\\\} things are \\\\{\\\\( B \\\\}\\\\}\\\"\\n\\nFigure 1: An overview of the proposed framework FLD, which aims to generate logical deduction instances constructed from the axioms of first-order predicate logic. FLD is modular, and the modules are made as flexible as possible by options or external template files. This enables us to generate various patterns of corpora for analysis. This investigation is essential to discuss the future directions on deductive reasoning: for the aspects for which deduction corpora are beneficial, we can advance by inventing better deduction corpora. However, for the other aspects, we should take other approaches. This paper aims to answer these questions. First, we rethink the choice of deduction rules. To this end, we leverage the formal logic theory (Section 2). According to formal logic, there are infinite valid deduction rules, including but not limited to the ones used in the previous corpora. However, among them, there is a set of atomic deduction rules called the axioms, and any other valid deduction rules can be derived by multistep deductions constructed from the axioms (completeness). As a consequence, multistep deductions constructed from the axioms can express multistep deductions constructed from any other deduction rules. The sets of deduction rules used in the previous corpora do not have this property and thus cannot express other various deduction rules. To revise this point, we propose a deduction corpus generation framework named FLD (Formal Logic Deduction), which adopts the axioms. Using the corpora generated by FLD, we aim to teach LMs how to construct multistep deductions by using the axioms.\\n\\nTo show that the training on FLD is indeed effective, we measured the performance of LMs trained on FLD corpora on two types of deductive reasoning benchmarks (Section 6). One benchmark is deduction corpora themselves, which requires rigid logical reasoning, and the other is human-authored EntailmentBank (EB) (Dalvi et al., 2021), which requires more complex real-world reasoning. We obtained promising results: LMs trained on FLD outperform baselines on both benchmarks, showing their better generalizability. Nevertheless, LMs still fail to fully utilize the potential of the axioms as it struggles to construct many-step proofs. Next, we identify the aspects of deductive reasoning ability on which deduction corpora are beneficial (Section 7). To analyze each aspect separately, we employed various options of FLD and generated a comprehensive set of \\\"ablation corpora\\\", where one corpus emphasizes a specific aspect different from those emphasized by the other corpora. Then, for each corpus (aspect), we investigated whether the LM trained on that corpus outperformed the LM without this training. If it did, we concluded that the supervision from deduction corpus on that aspect is beneficial for LMs. The results suggest that deduction corpora are beneficial on almost all the aspects. However, for some aspects, deduction corpora alone are not enough, and thus other approaches, such as advanced models and learning methods, could be required. Finally, on the basis of the results, we discuss the future directions for applying deduction corpora or other approaches for each aspect (Section 8).\\n\\nWe summarize our contributions as follows:\\n\\n\u2022 To teach LMs deductive reasoning, we propose a deduction corpus generation framework FLD (Section 3).\\n  \u2013 FLD is the first to leverage formal logic theory: it adopts a well-grounded set of deduction rules that can derive any other deduction rules when combined in multistep deductions.\\n  \u2013 FLD highly flexibly generates various patterns of corpora for analysis (Table 1).\\n  \u2013 Accordingly, we release challenging FLD corpora, the code, and the fine-tuned models.\\n\\n\u2022 We empirically verify that LMs trained on FLD corpora acquire more generalizable deductive reasoning ability than the baselines without such training (Section 6).\\n\\n\u2022 We analyze each aspect of deductive reasoning and 2\"}"}
{"id": "morishita23a", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"provide the future directions for applying deduction corpora or other approaches for them (Sections 7 and 8).\\n\\n2. Preliminaries: Formal Logic\\n\\nLet us consider the following single-step deductive reasoning:\\n\\nThe Earth revolves around the sun\\n\\nIf the Earth revolves around the sun, the Earth has seasons.\\n\\nThe Earth has seasons.\\n\\n(1)\\n\\nThis deduction step derives the conclusion, written under the bar, from the two premises. Next, consider another step:\\n\\nThe Earth revolves around the sun\\n\\nIf the Earth revolves around the sun, the Earth does not have seasons.\\n\\nThe Earth does not have seasons.\\n\\n(2)\\n\\nIn this step, one of the premises (i.e., \u201cIf the Earth revolves around the sun, the Earth does not have seasons\u201d) is false. However, if the premise had been true, we can still derive the conclusion. Thus, in formal logic, this step is still valid the same as (1). We can abstract (1) and (2) using symbols as:\\n\\n\\\\[ F \\\\rightarrow (F \\\\rightarrow G) \\\\]\\n\\nThis deduction step is called modus ponens.\\n\\nWhile modus ponens is the most intuitive deduction step, many others exist. For example, a famous syllogism is:\\n\\n\\\\[ (F \\\\rightarrow G) \\\\land (G \\\\rightarrow H) \\\\rightarrow (F \\\\rightarrow H) \\\\]\\n\\n(4)\\n\\nThe other example below defines the meaning of \\\\( \\\\land \\\\) formally:\\n\\n\\\\[ (F \\\\land G) \\\\rightarrow F \\\\]\\n\\n(5)\\n\\nOf course, we can consider invalid steps such as:\\n\\n\\\\[ F \\\\land G \\\\]\\n\\n(6)\\n\\nNow, from these examples, we obtain some important points of deductive reasoning. First, deductive reasoning can be defined as a form of thought in which a conclusion is derived from a set of premises following specific rules. In formal logic, such deduction rules are called arguments.\\n\\nThus, (1) to (6) all are formal logic arguments. Second, whether an argument is valid or not does not depend on the contents of symbols but only on the superficial form of the symbolic sequence composed of the premises to the conclusion. For example, as stated above, (3) is valid regardless of the actual content of \\\\( G \\\\), such as \\\\( G = \\\\text{(. . . ), the Earth has seasons.} \\\\) in (1) and \\\\( G = \\\\text{(. . . ), the Earth does not have seasons.} \\\\) in (2).\\n\\nThis enables us to regard all arguments simply as symbolic rules such as (3) to (6). Third and as one conclusion of:\\n\\nA deduction step (an argument) is invalid when for some truth value assignments, the conclusion is false (=0) even if all the premises are true (=1). See Table B.10b.\\n\\nNext, we consider multistep deductions. Figure 2 shows that syllogism argument can be derived by the multistep deduction constructed from other \u201catomic\u201d arguments. (For other examples, Figure B.4 shows the derivations of the arguments used in the previous corpora.) Indeed, in formal logic, there is a set of atomic arguments called the axioms (listed in Figure B.3a), and the following is known:\\n\\nTheorem 2.1 (Completeness of first-order predicate logic (G\u00f6del, 1930)).\\n\\nAny valid argument is derivable by multi-step deduction constructed from the axioms. Furthermore, any argument derivable by multi-step deduction constructed from the axioms is valid.\\n\\nHere we have come to the core of formal logic: multi-step deduction constructed from the axioms. Thanks to the completeness, all valid arguments can be derived in this way, and all (infinite) arguments derived in this way are valid. As a consequence, multi-step deduction constructed from the axioms can express multi-step deduction constructed from any other arguments, as illustrated in Figure 2 (right).\\n\\n3. Generating Formal Logic Deduction Corpus\\n\\nThe previous deduction corpora (Clark et al., 2021; Betz et al., 2021) used limited or arbitrary sets of deduction rules. However, as we saw in Section 2, the axioms should be the most generalizable to various deduction rules. Thus, we propose a framework named FLD (Formal Logic Deduction), which generates examples of multi-step deduction constructed from the axioms. We designed FLD to be highly flexible, i.e., configurable and/or extensible by options or external template files as in Table 1, so that we can generate and analyze various patterns of corpora.\\n\\n3 We limit our focus to first-order predicate logic in this paper.\\n\\n4 An argument is valid when for all truth value assignments, the conclusion is true (=1) if all the premises are true. See Table B.10a.\"}"}
{"id": "morishita23a", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: A comparison of FLD with the previous studies.\\n\\n| Deduction Rules | Proof Tree | Depth (upto) | Proof Tree Branches | Formula Complexity | # of Distractors (up to) | Linguistic Diversity | Proof Labels |\\n|----------------|------------|--------------|---------------------|--------------------|-------------------------|---------------------|--------------|\\n| RuleTaker (Clark et al., 2021) | implication | 5 | A few complex | \u223c20 less (RuleTaker) / more (ParaRules) | provable / disprovable / unknown | | |\\n| AACorpus (Betz et al., 2021) | \u2713 (default = critical thinking) | 1 | 1 | \u2713 (simple / complex) | \u2713 (default = less) | \u2713 (provable / disprovable) | |\\n| FLD | \u2713 (default = the axioms) | \u2713 (can be any) | \u2713 (can be any) | \u2713 (can be any) | \u2713 (default = more) | \u2713 (can choose any) | |\\n\\nWe show examples of generated instances in Figure C.5. Below, we overview each module. For intuitive understanding, refer to the corresponding part of Figure 1. For the detailed implementations, refer to Appendix E.\\n\\n3.1. Proof Tree Generation via Random Forward-/Backward-Deduction\\n\\nRuleTaker (Clark et al., 2021) generates deductive proof trees by first randomly generating various formulas and second running a logical solver library on them to find occasionally emerged deductive relationships among them. However, since we rely on an external solver, we cannot specify the set of arguments used in proof trees (and thus we cannot specify the axioms, especially.). Further, since we rely on the randomness, we cannot control the complexity of a proof tree, i.e., the depth and the number of leaves. Thus, we decided to take another approach. We invented a module (\\\"Proof Tree Generator\\\" in Figure 1) that generates a proof tree through a random deduction process by using a set of arguments specified by a user. A user can specify the arguments in a template rule file, as exemplified in Figure E.6. At each forward- or backward- deduction step, the module randomly chooses one argument and joints it to the current proof tree (\\\"forward\\\" and \\\"backward\\\" in the figure). The numbers of forward- and backward- steps control the tree's depth and number of leaves, respectively. Once the structure of the proof tree is constructed, we construct the compound formulas at the tree nodes, such as $F$, $G$.\\n\\nSince these formulas are arbitrary (Section 2), we randomly combine atomic formulas such as $A$ and $B$ using logical operators $\\\\land$, $\\\\lor$, $\\\\neg$. To avoid over complications, we limit the number of atomic formulas in each compound formula up to three. The resulting formulas are like $F = (\\\\neg A \\\\land B)$.\\n\\n3.2. Factual Distractor Generation\\n\\nIn a realistic scenario of logical reasoning, since the facts are collected by possibly incomplete retrieval systems rather than given, LMs have to correctly choose only the relevant facts under the existence of many irrelevant facts. To imitate this scenario, we add distractor facts to each deduction instance (\\\"Factual Distractor Generator\\\" in Figure 1). The distractor facts are formulas that are similar to the gold facts in their logical form. For example, for the gold fact $(A \\\\land B) \\\\rightarrow C$, formulas such as $(A \\\\land C) \\\\rightarrow B$ can be distractors. We also implemented several other types of distractors and use the mixture of them.\\n\\n3.3. Natural Language Assignment\\n\\nWe assign one natural language sequence to each formula of tree nodes and of distractors (\\\"Natural Language Assigner\\\" in Figure 1). Inspired by Betz et al. (2021), we take a template based approach. For each formula, we prepare several templates via an external template file (exemplified in Figure E.7) such as follows:\\n\\n- $A \\\\rightarrow B$: \\\"If A, then B.\\\"\\n- $F(a) \\\\rightarrow G(b)$: \\\"If a F, then b G.\\\"\\n\\nThen, we randomly choose one from them. Note that since the templates can be nested, the number of resulting patterns are combinatorially diverse.\\n\\nNext, we assign natural language statements to atomic components such as $A$, $B$, $F$, $G$, $a$, $b$. Here, we come back to the important point in deductive reasoning discussed in Section 2: that the validity of deduction does not depend on contents of formulas, or in other words, the same deduction can be conducted on the same formulas regardless of their contents. To reflect this point, we assign a random statement constructed (under a certain grammatical constraint) from a full vocabulary to each atomic component; for example:\\n\\n- $A$: \\\"an Earthquake occurs\\\"\\n- $B$: \\\"the year ends\\\"\\n- $F$: \\\"run\\\"\\n- $G$: \\\"answer\\\"\\n- $a$: \\\"the hamburger\\\"\\n- $b$: \\\"Peter\\\"\\n\\nThese random and diverse statements constructed from a large vocabulary (about 20k words) are another major difference from the previous studies (Tafjord et al., 2021; Betz et al., 2021), which used limited statements constructed from a limited vocabulary (a few dozen of words).\\n\\n3.4. Deduction Instance Conversion\\n\\nWe finally make a deductive reasoning instance from the outputs of the previous modules (\\\"Deduction Instance Converter\\\" in Figure 1). A deduction instance is composed of a set of facts, a hypothesis, a proof sequence, and an answer (\\\"proved\\\", \\\"disproved\\\", or \\\"unknown\\\"). This module\"}"}
{"id": "morishita23a", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A. Related Work\\n\\nA.1. Synthetic Corpus for Acquiring Deductive Reasoning Ability\\n\\nA synthetic deduction corpus can be one promising approach for language models (LMs) to acquire logical deductive reasoning ability. The automatic (programmatic) generation ensures the validity of the resulting deductive proof instances. Further, since we can bypass high-cost human annotations we can generate many instances, which should be required by LMs to learn deductive reasoning inductively.\\n\\nRuleTaker (Clark et al., 2021) proposed a deduction corpus composed of synthetically generated multistep deductive proofs written in natural languages. Each deductive proof (dis-)proves a hypothesis by applying deduction rules multiple times to a given set of facts. As the deduction rules, rules of the implication kind were used. They showed that Transformer (Vaswani et al., 2017) LMs can solve these problems in the sense that they can predict the final answer (i.e., \u201cproved\u201d, \u201cdisproved\u201d, or \u201cunknown\u201d) of each deductive proof given the fact set. Later studies (Saha et al., 2020; Dalvi et al., 2021; Tafjord et al., 2021; Sanyal et al., 2022) showed that generative LMs can generate even the intermediate proofs as well as the final answer.\\n\\nArtificial Argument Corpus (Betz et al., 2021) is another corpus composed of synthetically generated single-step deductive proofs. As the deduction rules, hand-selected rules useful for critical thinking were used. They showed that the LMs trained on this corpus not only solve the task of this corpus itself but generalize to other NLI tasks from GLUE benchmark (Wang et al., 2018). However, at the same time, they showed that such LMs do not generalize well to more challenging logical reasoning tasks such as ARC (Habernal et al., 2018) and LogiQA (Liu et al., 2020).\\n\\nGontier et al. (2020) investigated the deductive reasoning ability of LMs on a corpus, which is composed of a specific type of multistep inference: kinship relationship on synthetic kinship graphs. They found that LMs can solve this task when the number of proof steps is not large, but it is difficult for them to generalize to longer-than-training proofs.\\n\\nBostrom et al. (2021) studied how we can create realistic natural language expressions that represent deduction rules. To this end, they scraped sentences from Wikipedia by a template-based method and paraphrased them. They showed that training on this corpus is helpful for solving real-world deductive reasoning such as EntailmentBank (Dalvi et al., 2021).\\n\\nWhile all these corpora focused on specific sets of deduction rules, we focus on the theoretically well-grounded set of deduction rules that can derive any other deduction rules. Further, we analyze each aspect of deductive reasoning using corpora of various patterns to advance the research direction of deductive reasoning.\\n\\nA.2. Benchmarks for Deductive Reasoning\\n\\nMany benchmarks of single-step logical reasoning using specific reasoning rules have been proposed: bAbI (Weston et al., 2015), QuaRTz (Tafjord et al., 2019), ROPES (Lin et al., 2019) and Richardson et al. (2020). For multistep deductive reasoning, FOLIO (Han et al., 2022) is a human-authored benchmark of the SAT (i.e., satisfiability) problem. Given a set of facts and hypotheses, which are created by a human referencing a specific page of Wikipedia, we are required to assign a truth value to each hypothesis. This requires (implicitly) conducting multistep deductive reasoning using high-granularity deduction rules.\\n\\nRuleTaker (Clark et al., 2021; Tafjord et al., 2021) can work as a benchmark as well as a synthetic training corpus. RuleTaker focuses on multistep deductive reasoning constructed from implication rules. Since RuleTaker requires generating all the intermediate steps as well as the final prediction on the hypothesis, it is suitable for measuring deductive reasoning ability explicitly and transparently. Further, it includes many irrelevant facts so that the model has to choose only relevant facts under these noises. This makes the task challenging. LogicNLI (Tian et al., 2021) can be considered as an extension of RuleTaker, where additional logical operators such as \u201c\u2261\u201d are used. Additionally, the instances of LogicNLI are checked manually by humans to ensure their quality.\\n\\nEntailmentBank (EB) (Dalvi et al., 2021) is the same type of task as RuleTaker, but is even more challenging. The proof trees in EB dataset are human-authored rather than synthetically generated. Further, each proof step can be a rough entailment instead of a rigid logical step. Thus, EB measures logical reasoning ability in a more real-world setting.\\n\\nA.3. Proof Generation Models\\n\\nEarlier work (Saha et al., 2020; Gontier et al., 2020; Dalvi et al., 2021; Sun et al., 2021) generated proof sequences at once by LMs. Later work (Tafjord et al., 2021; Bostrom et al., 2022; Sanyal et al., 2022; Yang et al., 2022) generated proofs step-wisely one by one. The stepwise methods are more faithful and robustly generalize to longer proofs. Recently, Wei et al. (2022); Kojima et al. (2022) showed that large language models (LLMs) perform well on multi-hop inference tasks provided appropriate prompts. However, Yang et al. (2022) showed that LLMs given few-shot examples perform poorer than fine-tuned smaller LMs.\\n\\n7 We do not compare our method with this study directly because the code and corpora are not publicly available and the paper does not clarify the exact rules used.\"}"}
{"id": "morishita23a", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nTable B.10: Truth values of the premises ($P_i$) and the conclusion ($C$) of the two arguments. Blue shows truth value assignments where both the premises and the conclusion are true (=1). Red shows truth value assignments where the conclusion is false even if all the premises are true.\\n\\n(a) The valid argument (4) (syllogism).\\n\\n$$P_1 = (F \\\\rightarrow G) \\\\land (G \\\\rightarrow H),$$\\n\\n$$C = F \\\\rightarrow H.$$\\n\\n| F | G | H | $P_1$ | C |\\n|---|---|---|------|---|\\n| 1 | 1 | 1 | 1    | 1 |\\n| 1 | 1 | 0 | 0    | 0 |\\n| 1 | 0 | 1 | 0    | 0 |\\n| 1 | 0 | 0 | 0    | 0 |\\n| 0 | 1 | 1 | 1    | 1 |\\n| 0 | 1 | 0 | 0    | 1 |\\n| 0 | 0 | 1 | 0    | 1 |\\n| 0 | 0 | 0 | 0    | 1 |\\n\\n(b) The invalid argument (6).\\n\\n$$P_1 = F,$$\\n\\n$$P_2 = F \\\\lor G,$$\\n\\n$$C = G.$$\\n\\n| F | G | $P_1$ | $P_2$ | C |\\n|---|---|------|------|---|\\n| 1 | 1 | 1    | 1    | 1 |\\n| 1 | 0 | 1    | 1    | 0 |\\n| 0 | 1 | 0    | 1    | 1 |\\n| 0 | 0 | 0    | 0    | 0 |\\n\\nThe synthetic corpora approach examined in this paper could potentially help all these models to acquire better deductive reasoning ability.\\n\\nB. Limitations\\n\\nThe study has the following limitations:\\n\\n\u2022 We examined only a kind of logical reasoning: deductive reasoning with a given set of facts. As stated in Section 8, we have other types of logical reasoning to be solved in the future.\\n\\n\u2022 We examined only the first-order predicate logic system, while there are other logic systems useful for real-world reasoning to be tackled in the future, as stated in Section 8.\\n\\nC. Ethics and Social Impacts\\n\\nThe ultimate goal of the direction of this study is to make an artificial intelligence (AI) that reasons logically step by step. If AI can make a decision by showing logical steps one by one, it will be highly explainable and transparent to users. Furthermore, a user will be able to trace the error of AI. Thus, we think this study makes steps towards AI that will positively impact society.\\n\\nD. Formal Logic\\n\\nD.1. Definition of Validity of an Argument\\n\\nAn argument is valid when for all truth value assignments, the conclusion is always true (=1) if all the premises are true (=1). This is exemplified in Table B.10a.\\n\\nAn argument is invalid when for some truth value assignments, the conclusion is false (=0) even if all the premises are true (=1). This is exemplified in Table B.10b.\\n\\nD.2. Arguments used in Relevant Corpora\\n\\nFigure B.3a shows the axioms of first-order predicate logic.\\n\\nFigure B.3b shows the arguments of implication type used in RuleTaker (Clark et al., 2021). For the arguments used in AACorpus, see Figure 1 in Betz et al. (2021).\\n\\nD.3. Examples of Multistep Deduction constructed from the Axioms\\n\\nFigure B.4a shows the derivation of an argument of implication type used in RuleTaker. Figure B.4b shows the derivation of the contraposition argument used in AACorpus.\\n\\nE. Corpus Generation based on Formal Logic Deduction\\n\\nWe show the examples of FLD instance in Figure C.5. Below, we show additional details of each module of FLD.\\n\\nPlease refer to Figure 1 on intuitive understanding.\\n\\nE.1. Proof Tree Generation\\n\\nAs stated in Section 3.1, the generator module generates a proof tree by forward- and backward random deduction, using the arguments specified by a user. A user can specify arguments via a template file as exemplified in Figure E.6.\\n\\nThe forward random deduction is done as follows. The generator first chooses an argument randomly and forms the initial tree where the root node is the conclusion of the chosen argument and the child nodes are the premises of the chosen argument. The generator next randomly chooses another argument that can be \u201cjointed\u201d to the root note of the tree. An argument can be jointed to the root node of a tree if one of the premises of that argument can be identified with the root node. Then, the generator updates the tree by jointing this chosen argument. The generator continues this step multiple times until the tree achieves the required depth.\\n\\nThe backward random deduction is done as follows. For each step, the generator randomly chooses a leaf node of the tree. Then, the generator randomly chooses an argument that can be jointed to the leaf node. Here, an argument can be jointed to the leaf node if the argument\u2019s conclusion can be identified with the leaf node. Then, the generator updates the tree by jointing this chosen argument. The generator continues this step multiple times until the complexity of branches achieves the required level.\"}"}
{"id": "morishita23a", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\n\\\\( F \\\\to G \\\\)\\n\\n\\\\( G \\\\)\\n\\n\\\\( F \\\\land G \\\\)\\n\\n\\\\( F \\\\to G \\\\land H \\\\)\\n\\n\\\\( G \\\\)\\n\\n\\\\( F \\\\lor G \\\\)\\n\\n\\\\( H \\\\)\\n\\n\\\\( F \\\\lor H \\\\)\\n\\n\\\\( H \\\\)\\n\\n\\\\( \\\\exists x F(x) \\\\)\\n\\n\\\\( a \\\\)\\n\\n\\\\( F(a) \\\\)\\n\\n\\\\( G(b) \\\\)\\n\\n\\\\( F \\\\to G(b) \\\\)\\n\\n\\\\( F(a) \\\\)\\n\\n\\\\( \\\\forall x F(x) \\\\)\\n\\n\\\\( a \\\\to G(x) \\\\)\\n\\n\\\\( F(a) \\\\)\\n\\n\\\\( \\\\exists x F(x) \\\\)\\n\\n\\\\( G(x) \\\\)\\n\\n\\\\( \\\\lnot F \\\\)\\n\\n\\\\( \\\\lnot F \\\\)\\n\\n(a) The axioms of first-order predicate logic used in FLD.\\n\\n(b) The arguments of the implication type used in RuleTaker (Clark et al., 2021).\\n\\nFigure B.3: We show the arguments used in relevant corpora. For the \\\"critical thinking\\\" arguments used in AACorpus (Betz et al., 2021), please refer to Figure 1 in Betz et al. (2021).\\n\\nE.2. Factual Distractor Generation\\n\\nWe implemented three types of distractors. For a deductive instance, we use the random mixture of these distractors. Below, we detail each type of distractor.\\n\\nLogical Distractor:\\nWe construct a distractive formula the form of which is similar to a gold formula. For example, if a gold formula is \\\\((A \\\\land B) \\\\to C\\\\), then the following formula can be a distractor: \\\\((\\\\lnot A \\\\land B) \\\\to C\\\\). The aim of this type of distractor is to generate negative facts in a logic sense.\\n\\nLinguistic Distractor:\\nWe construct a distractive sentence by randomly flipping a word in a gold sentence into another word. For example, if a gold sentence is \\\"If it is not the fact that a sun rises, then (. . . )\\\", then the following sentence can be a distractor: \\\"If it is not the lion that a sun rises, (. . . )\\\". We considered grammatical constraints (e.g., part-of-speech) when flipping a word. Note that these distractors are made after the natural languages are assigned to gold formulas. The aim of this type of distractor is to generate negative facts in a linguistic sense.\\n\\nNegative Tree Distractor:\\nWe create another proof tree irrelevant to the gold proof tree and use its leaf nodes as distractors. If a prover chooses these distractors as the starting point of the proof, then it will reach a conclusion that is irrelevant to the given hypothesis. Thus, this type of distractor measures the prover's look-ahead ability.\\n\\nE.3. Natural Language Assignment\\n\\nWe show an example of the natural language template file in Figure E.6. When we assign natural language statements to each atomic component such as \\(A, B, F, G, H, I, a, b\\), we used grammatical heuristics as exemplified as follows: (i) Atomic propositions like \\\\(A\\\\) and \\\\(B\\\\) are converted into complete-sentence statement like \\\"[NOUN] is [ADJ]\\\", \\\"[NOUN] [VERB]\\\" and \\\"[NOUN] occurs\\\". (ii) (Logical) predicates like \\\\(F\\\\) and \\\\(G\\\\) are converted into predicate phrases such as \\\"[VERB]\\\", \\\"is [ADJ]\\\" and \\\"is [NOUN]\\\". (iii) Constants like \\\\(a\\\\) are converted into entity-like phrases such as \\\"[NOUN]\\\".\"}"}
{"id": "morishita23a", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\n(a) An example where the proof by contradiction is used. (b) An example that can test the semantics of logical conjunction $\\\\land$.\\n\\nFigure C.5: Examples of FLD instances.\\n\\nF. Details of Experiments\\n\\nF.1. Corpora\\n\\nAs shown in Table 2, we generated multiple corpora to align conditions as closely as possible across the corpora being compared. Below, we detail each aspect.\\n\\nPreprocessing on RuleTaker:\\n\\nWe sub-sampled the instances so that the number of instances in the training split becomes 30k and that the answer label distribution (over \\\"proved\\\", \\\"disproved\\\", and \\\"unknown\\\") becomes uniform.\\n\\nDataset Size:\\n\\nAll the corpora have the training split of 30k instances. FLD corpora have validation and test split of 1k instances. For RuleTaker, see (Tafjord et al., 2021).\\n\\nLabel Distribution:\\n\\nAll the corpora have a uniform distribution over answer labels, i.e., over \\\"proved\\\", \\\"disproved\\\", and \\\"unknown\\\".\\n\\nArguments:\\n\\n\\\"Implication\\\" arguments are shown in Figure B.3b. Complicated formula versions such as $F_1(a) \\\\land F_2(a) \\\\rightarrow G(b)$ are also used. For \\\"critical thinking\\\", we used the ones listed in Figure 1 in Betz et al. (2021). For \\\"axioms\\\", we used the axioms of first-order predicate logic shown in Figure B.3a.\\n\\nLinguistic Diversity:\\n\\nFirst, we detail the linguistic diversity of RuleTaker corpora. RT is classified into \\\"less\\\" since it uses only few templates for each logical statement. RT.PR is classified into \\\"more\\\" since it includes various\"}"}
{"id": "morishita23a", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nanother kind of real-world logical reasoning with which we derive hidden premises from a conclusion and other visible premises. Synthetic corpora for abduction based on formal logic can be generated similarly to as done in this study.\\n\\n9. Conclusion\\nTo teach language models deductive reasoning, we proposed a synthetic corpus based on formal logic theory and verified its effectiveness empirically. Further, we analyzed each aspect of deductive reasoning and provided future directions on each. We will advance on the basis of these directions.\\n\\nAcknowledgement\\nWe thank the three anonymous reviewers and the meta-reviewer, who gave us insightful comments and suggestions. Computational resources of AI Bridging Cloud Infrastructure (ABCI) provided by the National Institute of Advanced Industrial Science and Technology (AIST) were used. We thank Dr. Masaaki Shimizu at Hitachi for the convenience of additional computational resources. We thank Dr. Naoaki Okazaki, professor at Tokyo Institute of Technology, for the keen comments.\\n\\nReferences\\nAskell, A. Gpt-3: Towards renaissance models. Daily Nous Blog: Philosophers On GPT-3, 2020.\\nBetz, G., Voigt, C., and Richardson, K. Critical thinking for language models. In Proceedings of the 14th International Conference on Computational Semantics (IWCS), pp. 63\u201375, Groningen, The Netherlands (online), June 2021. Association for Computational Linguistics. URL https://aclanthology.org/2021.iwcs-1.7.\\nBhagavatula, C., Bras, R. L., Malaviya, C., Sakaguchi, K., Holtzman, A., Rashkin, H., Downey, D., Yih, S. W.-t., and Choi, Y. Abductive commonsense reasoning. arXiv preprint arXiv:1908.05739, 2019.\\nBostrom, K., Zhao, X., Chaudhuri, S., and Durrett, G. Flexible generation of natural language deductions. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 6266\u20136278, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.506. URL https://aclanthology.org/2021.emnlp-main.506.\\nBostrom, K., Sprague, Z., Chaudhuri, S., and Durrett, G. Natural language deduction through search over state compositions. CoRR, abs/2201.06028, 2022. URL https://arxiv.org/abs/2201.06028.\\nClark, P., Tafjord, O., and Richardson, K. Transformers as soft reasoners over language. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, pp. 3882\u20133890, 2021.\\nDalvi, B., Jansen, P., Tafjord, O., Xie, Z., Smith, H., Piptanangkura, L., and Clark, P. Explaining answers with entailment trees. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 7358\u20137370, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.585. URL https://aclanthology.org/2021.emnlp-main.585.\\nDavison, J., Feldman, J., and Rush, A. Commonsense knowledge mining from pretrained models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 1173\u20131178, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1109. URL https://aclanthology.org/D19-1109.\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171\u20134186, 2019.\\nG\u00f6del, K. \u00dcber die vollst\u00e4ndigkeit des logikkalk\u00fcls. PhD thesis, Ph. D. dissertation, University of Vienna, 1930.\\nGontier, N., Sinha, K., Reddy, S., and Pal, C. Measuring systematic generalization in neural proof generation with transformers. Advances in Neural Information Processing Systems, 33:22231\u201322242, 2020.\\nGuu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. Retrieval augmented language model pre-training. In International Conference on Machine Learning, pp. 3929\u20133938. PMLR, 2020.\\nHabernal, I., Wachsmuth, H., Gurevych, I., and Stein, B. The argument reasoning comprehension task: Identification and reconstruction of implicit warrants. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 1930\u20131940, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1175. URL https://aclanthology.org/N18-1175.\"}"}
{"id": "morishita23a", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nHan, S., Schoelkopf, H., Zhao, Y., Qi, Z., Riddell, M., Benson, L., Sun, L., Zubova, E., Qiao, Y., Burtell, M., Peng, D., Fan, J., Liu, Y., Wong, B., Sailor, M., Ni, A., Nan, L., Kasai, J., Yu, T., Zhang, R., Joty, S., Fabbri, A. R., Kryscinski, W., Lin, X. V., Xiong, C., and Radev, D. Folio: Natural language reasoning with first-order logic, 2022. URL https://arxiv.org/abs/2209.00840.\\n\\nHossain, M. M., Kovatchev, V., Dutta, P., Kao, T., Wei, E., and Blanco, E. An analysis of natural language inference benchmarks through the lens of negation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 9106\u20139118, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.732. URL https://aclanthology.org/2020.emnlp-main.732.\\n\\nHosseini, A., Reddy, S., Bahdanau, D., Hjelm, R. D., Sordoni, A., and Courville, A. Understanding by understanding not: Modeling negation in language models. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1301\u20131312, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.102. URL https://aclanthology.org/2021.naacl-main.102.\\n\\nKahneman, D. Thinking, fast and slow. Macmillan, 2011.\\n\\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6769\u20136781, 2020.\\n\\nKassner, N. and Sch\u00fctze, H. Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7811\u20137818, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.698. URL https://aclanthology.org/2020.acl-main.698.\\n\\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners, 2022. URL https://arxiv.org/abs/2205.11916.\\n\\nLi, J., Monroe, W., Ritter, A., Jurafsky, D., Galley, M., and Gao, J. Deep reinforcement learning for dialogue generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 1192\u20131202, 2016.\\n\\nLin, K., Tafjord, O., Clark, P., and Gardner, M. Reasoning over paragraph effects in situations. In Proceedings of the 2nd Workshop on Machine Reading for Question Answering, pp. 58\u201362, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-5808. URL https://aclanthology.org/D19-5808.\\n\\nLiu, J., Cui, L., Liu, H., Huang, D., Wang, Y., and Zhang, Y. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In Bessiere, C. (ed.), Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pp. 3622\u20133628. International Joint Conferences on Artificial Intelligence Organization, 7 2020. doi: 10.24963/ijcai.2020/501. URL https://doi.org/10.24963/ijcai.2020/501. Main track.\\n\\nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\\n\\nMcCarthy, J. W. Programs with common sense. In Proc. Tedding Conf. on the Mechanization of Thought Processes, pp. 75\u201391, 1959.\\n\\nMishra, B. D., Tafjord, O., and Clark, P. Towards teachable reasoning systems: Using a dynamic memory of user feedback for continual system improvement, 2022. URL https://arxiv.org/abs/2204.13074.\\n\\nNaik, A., Ravichander, A., Sadeh, N., Rose, C., and Neubig, G. Stress test evaluation for natural language inference. In Proceedings of the 27th International Conference on Computational Linguistics, pp. 2340\u20132353, Santa Fe, New Mexico, USA, August 2018. Association for Computational Linguistics. URL https://aclanthology.org/C18-1198.\\n\\nNegrinho, R., Gormley, M., and Gordon, G. J. Learning beam search policies via imitation learning. Advances in Neural Information Processing Systems, 31, 2018.\\n\\nNiven, T. and Kao, H.-Y. Probing neural network comprehension of natural language arguments. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4658\u20134664, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1459. URL https://aclanthology.org/P19-1459.\\n\\nPetroni, F., Rockt\u00e4schel, T., Riedel, S., Lewis, P., Bakhtin, A., Wu, Y., and Miller, A. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and 10th Joint Conference on Lexical and Computational Semantics, pp. 2758\u20132766, Barcelona, Spain, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1317. URL https://aclanthology.org/D19-1317.\"}"}
{"id": "morishita23a", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "morishita23a", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\\n\\nWelleck, S., Liu, J., Lu, X., Hajishirzi, H., and Choi, Y.\\n\\nNaturalprover: Grounded mathematical proof generation with language models. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=rhdfTOiXBng.\\n\\nWeston, J., Bordes, A., Chopra, S., Rush, A. M., Van Merri\u00ebnboer, B., Joulin, A., and Mikolov, T. Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698, 2015.\\n\\nXie, Z., Thiem, S., Martin, J., Wainwright, E., Marmorstein, S., and Jansen, P. WorldTree v2: A corpus of science-domain structured explanations and inference patterns supporting multi-hop inference. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pp. 5456\u20135473, Marseille, France, May 2020. European Language Resources Association. ISBN 979-10-95546-34-4. URL https://aclanthology.org/2020.lrec-1.671.\\n\\nYang, K., Deng, J., and Chen, D. Generating natural language proofs with verifier-guided search. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022.\"}"}
{"id": "morishita23a", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table G.20: The results of all the metrics on EntailmentBank Task1. For the details of these metrics, refer to Dalvi et al. (2021).\\n\\n| Task Leaves | Steps Intermediates | Overall |\\n|-------------|---------------------|---------|\\n| F1          | AllCorrect          | F1      | AllCorrect | F1 | AllCorrect | AllCorrect |\\n| T5          | 98.2                | 90.6    | 53.8       | 40.3        | 72.1  | 39.7       | 36.8       |\\n| RT.D5       | 98.2                | 88.6    | 56.0       | 42.7        | 72.8  | 41.6       | 39.4       |\\n| FLD.D5      | 99.0                | 92.7    | 55.5       | 42.2        | 73.4  | 41.3       | 39.2       |\\n\\nTable G.21: The results of all the metrics on EntailmentBank Task2. For the details of these metrics, refer to Dalvi et al. (2021).\\n\\n| Task Leaves | Steps Intermediates | Overall |\\n|-------------|---------------------|---------|\\n| F1          | AllCorrect          | F1      | AllCorrect | F1 | AllCorrect | AllCorrect |\\n| T5          | 88.1                | 52.1    | 45.9       | 33.2        | 68.6  | 36.2       | 31.2       |\\n| RT.D5       | 88.6                | 53.1    | 45.6       | 32.7        | 68.4  | 36.1       | 32.0       |\\n| FLD.D5      | 88.4                | 53.6    | 45.6       | 33.8        | 67.9  | 36.1       | 32.6       |\\n\\nTable G.22: The results of all the metrics on EntailmentBank Task3. For the details of these metrics, refer to Dalvi et al. (2021).\\n\\n| Task Leaves | Steps Intermediates | Overall |\\n|-------------|---------------------|---------|\\n| F1          | AllCorrect          | F1      | AllCorrect | F1 | AllCorrect | AllCorrect |\\n| T5          | 43.7                | 8.2     | 10.7       | 6.5          | 42.2  | 16.8       | 6.2        |\\n| RT.D5       | 43.1                | 10.0    | 13.1       | 8.2          | 41.7  | 17.3       | 8.2        |\\n| FLD.D5      | 43.6                | 9.7     | 12.1       | 8.3          | 43.0  | 20.1       | 8.3        |\\n\\nTable G.23: Cases where baseline (T5) error on a proof step is fixed by the training on FLD.D5.\\nA proof step is composed of a set of chosen premises and a derived conclusion. A derived conclusion is either a sequence generated by the prover model when the step is an intermediate step of the proof or is (fixed to) the hypothesis given to the model when the step is the final step of the proof (marked as [hypothesis]). Thus, in the final step, the task of the prover model is just to choose the right premises that can derive the hypothesis.\\n\\n| chosen premises | derived conclusion | T5 error | fixed by FLD.D5 |\\n|-----------------|--------------------|----------|----------------|\\n| force causes the speed of an object to increase / to decrease | force causes the speed of an object to change [hypothesis] | 1. | The chosen premises are not sufficient, possibly happened because T5 do not understand the rule of conjunction (\\\\(\\\\land\\\\)). |\\n| an increase is a kind of change | force causes the speed of an object to change [hypothesis] | 2. | |\\n| a decrease is a kind of change | force causes the speed of an object to change [hypothesis] | 3. | |\\n| the milky way is made of stars | light year can be used to measure the distance between the stars in milky way | T5 overclaimed, that is, included in the conclusion such information that does not logically follow from the chosen premises. (a.k.a \u201challucination\u201d) | 4. | |\\n| fossils are formed by the remains of living things | rock is a kind of nonliving thing rocks cannot form fossils | T5 missed a premise to choose wrong one, possibly because T5 do not understand the semantics of negation (\\\\(\\\\neg\\\\)) at \u201cnon\u201d. | 5. | |\\n| the first quarter phase of the moon occurs after the new moon | the first quarter phase of the moon will occur one week after the new moon [hypothesis] | T5 chose wrong premises. | 6. | |\\n| a different moon phase occurs approximately once per week | the first quarter phase of the moon will occur one week after the new moon [hypothesis] | 7. | |\\n| cutting down trees has a negative impact on an environment | decreasing the amount of trees cut has a positive impact on the environment | T5 generation was merely a repetition (a.k.a \u201crepetition\u201d) | 8. | |\\n| creating paper requires cutting down trees | cutting down trees has a negative impact on the environment | 9. | |\\n| the heart is situated in the chest | the abdomen does not contain the heart [hypothesis] | T5 chose wrong premises. | 10. | |\\n| if something does not contain something else then that something lacks that something else | the abdomen does not contain the heart [hypothesis] | 11. | |\"}"}
