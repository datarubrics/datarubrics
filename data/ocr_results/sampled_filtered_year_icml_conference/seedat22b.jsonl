{"id": "seedat22b", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Forecasting at Additional Time Horizons\\n\\nFigure 11 (a)-(c) below shows further results for forecasting at additional time horizons. The results demonstrate the same relative performance of different methods as was shown in the main paper.\\n\\n(a) Horizon = $t_k + 3$\\n\\n(b) Horizon = $t_k + 4$\\n\\n(c) Horizon = $t_k + 5$\\n\\nFigure 11: Results for counterfactual estimation at additional forecasting time horizons\"}"}
{"id": "seedat22b", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nA. Notation Summary\\n\\n| Notation | Explanation |\\n|----------|-------------|\\n| X        | Covariate process |\\n| A        | Treatment process |\\n| Y        | Outcome path |\\n| Y(\\\\(A=a\\\\)) | Potential outcome of Y |\\n| t        | Time t |\\n| N        | Counting Process |\\n| F_t      | Filtration |\\n| \\\\(\\\\lambda\\\\) | Intensity process |\\n| Z        | Latent path |\\n| \\\\(f_\\\\theta\\\\) | Encoder latent vector field |\\n| \\\\(f_\\\\phi\\\\) | Decoder latent vector field |\\n| X_t      | Covariates at time t |\\n| A_t      | Treatment at time t |\\n| Y_t      | Outcome at time t |\\n| h_v      | Outcome prediction network |\\n| h_a      | Treatment prediction network |\\n| \\\\(\\\\mu\\\\) | Parameter controlling the trade-off between treatment and outcome prediction |\\n| L(\\\\(a\\\\)) | Outcome loss |\\n| L(\\\\(a\\\\)) | Treatment loss |\\n\\nNotation for the tumor growth dynamics can be found in Appendix C.1\\n\\nB. Extended Related Work\\n\\nTreatment effect estimation with static data.\\n\\nA large body of work has proposed causal inference methods applied to observational data in the static setting. The methods can be grouped as: (a) Representation learning (Johansson et al., 2016; Shalit et al., 2017; Yoon et al., 2018; Li & Fu, 2017; Yao et al., 2018), (b) Matching and Re-weighting (Rosenbaum & Rubin, 1983) and (c) Tree-based (Hill, 2011; Wager & Athey, 2018).\\n\\nWhile the aforementioned methods showed good performance, the static setting has two properties that simplify the estimation, namely (1) the treatment is allocated only once and does not change over time, and (2) the confounders and the outcomes are static variables rather than time series. Additionally, the static setting does not naturally apply to the medical studies based on longitudinal data (e.g. EHRs), where the treatments, confounders and outcomes are all time-varying (Hern\u00e1n et al., 2000; Schisterman et al., 2009; Mansournia et al., 2012). The wealth of information being routinely collected as a part of the electronic health record (EHR) provides an unprecedented opportunity to discover appropriate clinical recommendations for patients given\\n\\nTreatment effect estimation with longitudinal, time-varying data.\\n\\nA number of methods have been proposed for estimating the effect of time-varying exposures in the presence of time-dependent confounding, including \\\\(g\\\\)-computation (Robins, 1986), Structural Nested Models (Robins, 1994), and Marginal Structural Models (MSMs) (Robins et al., 2000). However, MSMs are sensitive to model mis-specification, when computing the propensity weights and hence when estimating outcomes.\\n\\nMethods for the longitudinal setting with temporal confounding such as Marginal Structural Models (MSMs) (Robins et al., 2000), have thus been extended to address some of these issues. The Recurrent Marginal Structural Model (RMSN) (Lim et al., 2018) aimed to reduce variance in the weights using recurrent neural networks to estimate the propensity weights and to build the outcome model.\"}"}
{"id": "seedat22b", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nRecently, the Counterfactual Recurrent Network (CRN) (Bica et al., 2020b) combined a RNN architecture with adversarial training to balance the covariate distributions in different treatment regimes. That said, the aforementioned methods applied to longitudinal, time-varying data make unrealistic assumptions that the measurements are made at regular intervals, fully aligned across all patients, or do not contain missing values.\\n\\nThe Counterfactual Gaussian Process (CGP) (Schulam & Saria, 2017) made no such assumptions on data sampling using a generative model to jointly model the outcome and the treatment allocation. However, CGP makes strong assumptions about model structure by using Bayesian non-parametric methods, which makes them unsuitable to handle heterogeneous treatment effects arising from baseline variables or settings with multiple treatment outcomes. In addition, CGP does not directly address the issue of time-dependent confounding.\\n\\nWhile in this work we assume no hidden confounding, we do note a body of work such as Wang & Blei (2019) and Bica et al. (2020a) exists which attempts to adjust for hidden confounders in observational data.\\n\\nNeural differential equations.\\n\\nWe consider the trajectory a patient undergoing treatment as a dynamical system. Neural ordinary differential equations (Neural ODEs) and extensions have been shown to successfully model the continuous-time evolution of dynamical systems with differential equations learned by neural networks (Chen et al., 2018; Rubanova et al., 2019; De Brouwer et al., 2019). However, a key limitation of Neural ODE approaches is that the entire trajectory is determined by the initial condition at $t=0$ and the equation does not account for any information available at $t>0$.\\n\\nRecent works on neural controlled differential equations (Neural CDE) (Kidger et al., 2020; Morrill et al., 2021) address this shortcoming by allowing incoming information to modulate the dynamics. This ability is naturally useful in a clinical setting, as not only can we model the continuous-time latent state evolution of a patient trajectory, but also we account for incoming data (e.g. treatment changes) that modulate the dynamics of system.\\n\\nAs was discussed in the main paper, (Gwak et al., 2020) and (Bellot & van der Schaar, 2021) have used neural differential equations for intervention modeling. While somewhat related by virtue of using neural differential equations, these works are not applicable to our setting.\\n\\n(Gwak et al., 2020) used two separate neural ODEs to model the intervention and outcome processes. That said, the method is not applicable to treatment effect estimation in clinical settings as it does not integrate time-varying covariates or adjust for confounding.\\n\\nOn the other hand (Bellot & van der Schaar, 2021) proposed to model treatment effects in continuous-time in the context of synthetic controls. The setting however, is completely different as it only considered a single intervention and the synthetic control approach is not applicable more generally.\\n\\nAs a consequence, to the best of our knowledge TE-CDE is the first method for counterfactual estimation and treatment effects to leverage the mathematics of neural differential equations and more specifically neural controlled differential equations.\"}"}
{"id": "seedat22b", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nC. Simulation Environment\\n\\nC.1. Pharmacokinetic-Pharmacodynamic Model\\n\\nPharmacokinetic-Pharmacodynamic models are bio-mathematical models which represent dose-response relationships. This enables clinicians to understand possible patient response and hence propose optimal treatments.\\n\\nIn our setting we wish to estimate counterfactual outcomes. Since counterfactuals do not exist in practice, we make use of a synthetic data generated via a PK-PD model. In particular, we use a state-of-the-art bio-mathematical by (Geng et al., 2017).\\n\\nThe PK-PD model is used to model lung cancer tumor growth under effects of chemotherapy and radiotherapy. For evaluation of counterfactuals such a model allows us to generate data of patient tumor volume outcomes under different possible treatments.\\n\\nModel of tumor growth\\n\\nThe tumor volume at time $t$ after diagnosis is modeled as follows:\\n\\n$$\\n\\\\frac{dV(t)}{dt} = (\\\\rho \\\\log(V(t))) - \\\\beta_c C(t) - \\\\alpha_r C(t) + \\\\beta_r C(t)^2 + \\\\epsilon(t),\\n$$\\n\\nThe parameters $K, \\\\rho, \\\\beta_c$ for each simulated patient are sampled from the prior distributions described in (Geng et al., 2017) and details are outlined in Table 3 below. We include $\\\\epsilon(t) \\\\sim N(0, 0.01^2)$ as random noise to account for randomness in the tumor growth.\\n\\nTable 4: Outline of different parameters used in the PK-PD Model\\n\\n| Model Variable     | Parameter     | Distribution | Parameter Value $(\\\\mu, \\\\sigma)$ |\\n|--------------------|---------------|--------------|---------------------------------|\\n| Tumor growth       | Growth parameter $\\\\rho$ | Normal | $7.00 \\\\times 10^{-5}, 7.23 \\\\times 10^{-3}$ |\\n|                    | Carrying capacity $K$ | Constant | $30$ |\\n| Radiotherapy       | Radio cell kill $\\\\alpha_r$ | Normal | $0.0398, 0.168$ |\\n|                    | Radio cell kill $\\\\beta_r$ | $-\\\\text{s.t. } \\\\alpha/\\\\beta = 10$ |\\n| Chemotherapy       | Chemo cell kill $\\\\beta_c$ | Normal | $0.028, 0.0007$ |\\n\\nHeterogeneous responses.\\n\\nIn the simulation we wish to incorporate heterogeneity among patient responses to match the real-world where individualized treatment effect can vary due to factors such as gender or genetics (Bartsch et al., 2007). Similar to (Bica et al., 2020b) and (Lim et al., 2018), the means are adjusted for $\\\\beta_c$ and $\\\\alpha_r$ by creating three groups of patients (i.e. to represent three types of patients with heterogeneity in treatment response).\\n\\nFor patient group 1, we update the mean of $\\\\alpha_r$ such that $\\\\mu(\\\\alpha_r) = 1.1 \\\\times \\\\mu(\\\\alpha_r)$ and for patient group 3, we update the mean of $\\\\alpha_c$ such that $\\\\mu(\\\\alpha_c) = 1.1 \\\\times \\\\mu(\\\\alpha_c)$.\\n\\nDrug concentrations ($C(t)$ and $d(t)$).\\n\\nThe chemotherapy drug concentration $C(t)$ follows an exponential decay relationship with a half life of one day:\\n\\n$$\\nC(t) = \\\\tilde{C}(t) + \\\\frac{C(t-1)}{2},\\n$$\\n\\nwhere $\\\\tilde{C}(t)$ represents a $5.0 \\\\text{ mg/m}^3$ dosage of Vinblastine given at time $t$. The radiotherapy concentration $d(t)$ represents $2.0 \\\\text{ Gy}$ fractions of radiotherapy given at timestep $t$, where Gy is the Gray ionizing radiation dose.\"}"}
{"id": "seedat22b", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nTime-dependent confounding. We incorporate time-dependent confounding into the data generating process by modeling chemotherapy and radiotherapy assignment as Bernoulli random variables, with probabilities $p_c$ and $p_r$ which depend on tumor diameter:\\n\\n$$p_c(t) = \\\\sigma(\\\\gamma_c D_{\\\\text{max}}(\\\\bar{D}(t) - \\\\delta_c))$$\\n$$p_r(t) = \\\\sigma(\\\\gamma_r D_{\\\\text{max}}(\\\\bar{D}(t) - \\\\delta_r)),$$\\n\\n(14)\\n\\nwhere $D_{\\\\text{max}} = 13\\\\text{ cm}$ is the maximum tumor diameter, $\\\\theta_c = \\\\theta_r = D_{\\\\text{max}}/2$ and $\\\\bar{D}(t)$ is the average tumor diameter. The degree of time-dependent confounding is controlled by $\\\\gamma_c$ and $\\\\gamma_r$, where increasing $\\\\gamma \\\\{c,r\\\\}$ increases the amount of the time-dependent confounding.\\n\\nC.2. Cancer Staging\\n\\nAs described previously, patient outcomes can evolve through different states of disease over the course of their observational trajectory. These different states correspond to clinical guidelines used to grade cancer stages. In clinical settings, patient monitoring or observation frequency often varies for different clinical stages. For example, patients in more severe states with greater tumor volume are monitored more frequently and hence have a greater degree of sampling. However, as the patient's state/condition improves the measurements reduce in frequency (i.e. routine and less frequent follow-ups).\\n\\nThus, in the simulated data, the observational sampling rates closely follow this pattern to reflect healthcare data, shown in Figures 6 and 7. This induces sampling irregularity both within a trajectory as the patient state changes over time as well as irregularity between different patient trajectories. This irregularity is modeled via a Hawkes process as discussed in the main paper. Note, however, that $\\\\alpha/\\\\beta < 1$ in the Hawkes process, thereby ensuring local stationarity of the Hawkes process (Roueff et al., 2016).\\n\\nWe categorize tumor stages as per the American Joint Committee on Cancer (AJCC) Tumor, Node, Metastasis (TNM) staging system (Gershenwald et al., 2017):\\n\\n- Stage 0: No cancer\\n- Stage 1A: $0\\\\text{ cm} < \\\\text{tumor} \\\\leq 3\\\\text{ cm}$\\n- Stage 1B: $3\\\\text{ cm} < \\\\text{tumor} \\\\leq 4\\\\text{ cm}$\\n- Stage 2: $4\\\\text{ cm} < \\\\text{tumor} \\\\leq 5\\\\text{ cm}$\\n- Stage 3 & 4: $\\\\text{tumor} > 5\\\\text{ cm}$\\n\\nThe observational outcome is the volume of the lung cancer tumor, however the classification of stage is based on tumor diameter. Hence, we assume that the tumor has a perfectly spherical tumor shape similar to (Tatekawa et al., 2014) and hence can compute the diameter as per Equation 15.\\n\\n$$\\\\text{volume} = \\\\pi/6 \\\\times (\\\\text{diameter})^3$$\\n\\n(15)\\n\\nWe group these stages as stage 4 simply refers to the tumor invading a specific structure or anatomical space.\"}"}
{"id": "seedat22b", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nNabeel Seedat 1\\nFergus Imrie 2\\nAlexis Bellot 3\\nZhaozhi Qian 1\\nMihaela van der Schaar 1, 2, 4\\n\\nAbstract\\n\\nEstimating counterfactual outcomes over time has the potential to unlock personalized healthcare by assisting decision-makers to answer \u201cwhat-if\u201d questions. Existing causal inference approaches typically consider regular, discrete-time intervals between observations and treatment decisions and hence are unable to naturally model irregularly sampled data, which is the common setting in practice. To handle arbitrary observation patterns, we interpret the data as samples from an underlying continuous-time process and propose to model its latent trajectory explicitly using the mathematics of controlled differential equations. This leads to a new approach, the Treatment Effect Neural Controlled Differential Equation (TE-CDE), that allows the potential outcomes to be evaluated at any time point. In addition, adversarial training is used to adjust for time-dependent confounding which is critical in longitudinal settings and is an added challenge not encountered in conventional time-series. To assess solutions to this problem, we propose a controllable simulation environment based on a model of tumor growth for a range of scenarios with irregular sampling reflective of a variety of clinical scenarios. TE-CDE consistently outperforms existing approaches in all simulated scenarios with irregular sampling.\\n\\n1. Introduction\\n\\nDecision-makers must answer several critical questions before taking an action. In the clinical setting, before a treatment is given, clinicians must evaluate whether a treatment should be given and, if so, both what treatment is best for their patient and when the treatment should be administered. Answering such questions requires reliably estimating the effect of a treatment or sequence of treatments. While from a causal inference perspective, clinical trials represent the gold standard to answer these questions, it is highly desirable to estimate treatment effects from observational data. This is due to the significant expense, relatively small sample sizes, and narrow inclusion criteria of clinical trials. There are several causal inference methods proposed in the static setting (e.g. Shalit et al., 2017; Alaa & van der Schaar, 2017; Yoon et al., 2018). However, estimating the effects of treatments over time is of paramount importance for real-world administration of complex treatment plans and personalized healthcare. Only in the longitudinal setting can we understand how diseases evolve under different treatment plans, how individual patients respond to treatment over time, or the optimal timing for treatment.\\n\\nHowever, estimating counterfactual outcomes in the longitudinal setting introduces additional challenges, the most significant of which is that the observed treatment assignment may depend on confounding variables that vary over time (time-dependent confounding, Platt et al., 2009). For example, not all cancer patients are equally likely to be offered the same chemotherapy regimen. In particular, the history of patients\u2019 covariates and their response to past treatments affects future treatments (Bica et al., 2021). This can introduce bias in causal effects and variance in the estimation of counterfactuals due to the systematic differences in the distribution of confounding variables between any two sets of treatments over time.\\n\\nThis issue of time-dependent confounding and distribution shift is the primary challenge of causal inference over time, not encountered in standard time-series. Hence, conventional time-series models are not applicable to our setting as they do not adjust for bias introduced by time-varying confounders and hence are sensitive to the policy in the observational data (Schulam & Saria, 2017).\\n\\nWhile prior work in causal inference has sought to mitigate such confounding bias (Robins et al., 2000; Lim et al., 2018; Bica et al., 2020b), the setting considered is overly restrictive...\"}"}
{"id": "seedat22b", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nFigure 1: Illustration of the different paradigms of longitudinal data processing. We contrast the regular sampled setting (left) which RNN-based methods assume vs the irregularly sampled setting (right) which TE-CDE addresses, where data can be observed and evaluations carried out at any time-step.\\n\\nIn particular, previous work assumes that data is regular and arrives at fixed, evenly spaced time intervals and that the sampling times perfectly coincide between different individuals. However, neither is true in practice, significantly limiting the practical use of such methods.\\n\\nDiscretizing the patient\u2019s evolution over time, an inherently continuous process, has significant limitations, both when learning from historical data and for prospective clinical use. From a learning perspective, observational data is typically not sampled regularly. Indeed, irregularity in observational data can manifest for simple reasons, such as scheduling, a patient missing an appointment, or a healthcare practitioner not capturing the observation, to more complex considerations, for example more severe cases are often observed more frequently while different treatments can require different monitoring.\\n\\nProspective use cases raise similar issues surrounding mismatches between the discretization scheme and desired evaluation times that means the chosen discretization may not be applicable. As a result, for real-world applications where data is sampled irregularly, we believe that treatment effects over time should be modeled in a continuous manner.\\n\\nContributions.\\nIn this paper, we address the realistic but understudied problem of counterfactual estimation in the irregularly sampled setting with time-dependent confounding; a significantly more complex setting for counterfactual estimation than the standard regular, discrete setting.\\n\\nTo do so, we depart from existing methods based on recurrent neural networks (RNNs) and propose a novel alternative inspired by recent breakthroughs in neural controlled differential equations (CDEs) (Kidger et al., 2020), which we call the Treatment Effect Neural Controlled Differential Equation (TE-CDE).\\n\\nTo model the observation histories, we learn a continuous latent representation of the patient state as the solution to a CDE. To the best of our knowledge, this is the first work to frame the evolution of a patient\u2019s latent state as the solution to a CDE. This framing enables TE-CDE to learn from arbitrary historical observation patterns and allows potential outcomes to be evaluated at any point in time.\\n\\nIn addition, we introduce a controllable simulation environment based on a realistic model for tumor growth to generate irregularly sampled observational data. We demonstrate that the unrealistic assumptions imposed by existing state-of-the-art models lead to reduced performance in a range of irregularly sampled scenarios, and that TE-CDE outperforms these methods across all scenarios with irregularly sampled observation histories.\\n\\n2. Related Work\\nThis paper primarily engages with the literature on treatment effect estimation with time-varying covariates, treatments, and outcomes, but also draws on insights from causality in dynamical systems and recent work on modeling controlled differential equations. We explicitly note the difference between causal inference over time and conventional time series modeling as outlined in Section 1 and hence do not focus on recent advances in time series models. An extended discussion of related work can be found in Appendix B. In Table 1, we contrast the problem setting and assumptions of TE-CDE to other related work.\\n\\nWe argue for modeling the underlying continuous-time processes that give rise to the discrete observational data, which may itself be highly irregular. We contrast this approach with discrete-time methods that use a common discretization for all time series and are forced to interpolate and impute before model fitting. These methods also differ by how they adjust for confounding and for differences in covariate distributions in different treatment regimes. Marginal Structural Models (MSMs) are linear in treatment and covariate effect,\"}"}
{"id": "seedat22b", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nTable 1: Comparison of problem setting and assumptions. TE-CDE allows irregularly observed data and treatment plans defined in continuous time. Its assumptions are the continuous-time generalization of the standard assumptions in causal inference. The notations are defined in Section 3.\\n\\n| Observation Time | Treatment Plan | Overlap |\\n|------------------|----------------|---------|\\n| Static setting   | 1\\\\{0,1\\\\} \\\\(\\\\lambda(t,F_{i,t}) > 0\\\\) |         |\\n| CRN/RMSN         | \\\\(t^{i,0},...,t^{i,m} \\\\in \\\\mathbb{N}^{+}\\\\{t+1,\\\\ldots,t+k\\\\} \\\\rightarrow \\\\{0,1\\\\}\\\\) \\\\(\\\\lambda(t,F_{i,t}) > 0\\\\) |         |\\n| TE-CDE           | \\\\(t^{i,0},...,t^{i,m} \\\\in \\\\mathbb{R}^{\\\\mathbb{R}}\\\\{t,t'\\\\} \\\\rightarrow \\\\{0,1\\\\}\\\\) \\\\(\\\\lambda(t,F_{i,t}) > 0\\\\) |         |\\n\\nand create a pseudo-population using inverse probability of treatment weighting, such that the probability of treatment does not depend on the time-varying confounders and thus effectively controlling for confounding bias (Robins et al., 2000). Lim et al. (2018) proposed a semi-parametric alternative to MSMs using recurrent neural networks to estimate propensity weights. The Counterfactual Recurrent Network (CRN, Bica et al., 2020b) uses a similar architecture but instead uses adversarial training to balance differences in covariate distributions in different treatment regimes. However, both assume data to be regularly sampled and fully observed at all time points, which is unrealistic in practice. Gaussian process-based approaches such as Schulam & Saria (2017) are applicable to longitudinal data and take a continuous-time approach but in contrast, make strong assumptions about the model structure that is dependent on a particular application and prior knowledge of the form of the processes involved. Closer to the proposed approach, neural ordinary differential equations (ODE, Chen et al., 2018; Rubanova et al., 2019) and extensions (Kidger et al., 2020; Morrill et al., 2021) have been considered for modeling irregular time series data. However, neural ODE type methods are conventional time series models, which do not account for issues such as time-dependent confounding. In the context of intervention modeling, Gwak et al. (2020) proposed to use separate ODEs for interventions and outcome processes. However, they did so for systems with deterministic dynamics without integrating time-varying covariates and without addressing confounding. As a result, their approach is not applicable to treatment effect estimation in healthcare. Related is also Bellot & van der Schaar (2021) that proposed to model treatment effects in continuous time in the context of synthetic controls; however, contrasting our setting where there could be interventions over time, they only consider a single intervention at a particular time point and the approach is not applicable more generally to address multiple treatments.\\n\\n3. Problem Formulation\\n\\nWe consider \\\\(n\\\\) i.i.d. individuals over a study period \\\\([0,T]\\\\). Each individual is represented by a \\\\(d\\\\)-dimensional path \\\\(X: [0,T] \\\\rightarrow \\\\mathbb{R}^d\\\\), that defines the trajectory of patient covariates over time (and can include static covariates defined to be constant over time), a treatment process \\\\(A: [0,T] \\\\rightarrow \\\\{0,1\\\\}\\\\) is a discrete path indicating treatment at each time \\\\(t \\\\in [0,T]\\\\), i.e. \\\\(A_t = a\\\\), where \\\\(a \\\\in \\\\{0,1\\\\}\\\\) and a counting process \\\\(N: [0,T] \\\\rightarrow \\\\mathbb{N}\\\\) to denote the treatment assignment pattern of a single treatment over time, e.g. the number of treatments administered up to a given time \\\\(t\\\\). These processes are assumed to control or modulate an outcome of interest \\\\(Y: [0,T] \\\\rightarrow \\\\mathbb{R}\\\\), e.g. the tumor size of cancer patients over time, and we will distinguish between potential outcomes of \\\\(Y\\\\), denoted \\\\(Y(A=a)\\\\) or \\\\(Y(a)\\\\) for simplicity, to define the potential outcome trajectory of patient \\\\(i\\\\) had it been given a treatment path defined by \\\\(A=a\\\\).\\n\\nIn the context of electronic health records (EHRs) and most practical applications, the latent paths \\\\(X\\\\) are only partially-observed through \\\\(m\\\\) irregular observations, \\\\(\\\\{(t_0, X_{t_0}), (t_1, X_{t_1}), \\\\ldots, (t_m, X_{t_m})\\\\}\\\\), with each \\\\(t_j \\\\in \\\\mathbb{R}\\\\) the timestamp of the observation \\\\(X_{t_j} \\\\in \\\\mathbb{R}^d\\\\). To avoid notation clutter, we use the time subscript to refer to function evaluation. The same observations apply to paths \\\\(A\\\\) and \\\\(Y\\\\). The case where each \\\\(i\\\\)-th patient observation sequence has its own \\\\(m_i\\\\) irregular time stamps \\\\(t_{i,0},...,t_{i,m_i}\\\\), thus differences in sampling intensity within a patient's trajectory and between different patients can be considered without modification of any part of the exposition. Indeed, analyzing time series data with such a complex pattern of observation is the central motivation of this work.\\n\\nLet \\\\(F_t\\\\) denote the filtration that is generated by all the observable events for a given individual up to time \\\\(t\\\\), including observations of \\\\(X_s, A_s\\\\) and \\\\(Y_s\\\\) for \\\\(s \\\\leq t\\\\). Our goal is to derive unbiased estimates of the potential outcomes at a given time \\\\(t'\\\\):\\n\\n\\\\[\\n\\\\mathbb{E}\\\\left[Y_{t'}(A=a) | F_t\\\\right],\\n\\\\]\\n\\nfor any value of time in the future \\\\(t' > t\\\\), hypothesized discrete treatment path \\\\(A: [t,t'] \\\\rightarrow \\\\{0,1\\\\}\\\\) with values \\\\(a\\\\), given past observations up to time \\\\(t\\\\), \\\\(F_t\\\\). However, with observational data only...\"}"}
{"id": "seedat22b", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nOne of these potential outcomes trajectories is observed for each unit depending on the treatment assignment. We refer to the unobserved potential outcomes as counterfactuals. Potential outcomes processes are identifiable with respect to the filtration generated by the observed data under the following three assumptions. These three assumptions are the standard causal inference assumptions.\\n\\nAssumption 1 (Consistency). For an observed treatment process $A = a$, the potential outcome under this treatment trajectory is the same as the factual outcome $Y(a) = Y$.\\n\\nAssumption 2 (Overlap). The intensity process $\\\\lambda(t | F_t)$ is not deterministic given any filtration $F_t$ and time point $t \\\\in [0, T]$, i.e.\\n\\n$$0 < \\\\lambda(t | F_t) = \\\\lim_{\\\\delta t \\\\to 0} P(A_{t+\\\\delta t} - A_t = 1 | F_t) \\\\delta t < 1.$$  \\\\hspace{1cm} (1)\\n\\nOverlap means that there is some positive probability of treatment assignment at any point along a patient's trajectory over the time interval. It can be understood as a direct extension to the more familiar overlap assumption in the static context,\\n\\n$$0 < P(Treatment = 1 | x) < 1.$$  \\\\hspace{1cm} (2)\\n\\nThe last assumption extends unconfoundedness, or strong ignorability given a patient's trajectory, to ensure that it is sufficient to condition on the observed trajectory up to time $t$ to block all backdoor paths, i.e. spurious correlation not part of the direct causal effect of interest, to the potential outcome at any time in the future. Similar to Assumption 2, unconfoundedness has previously been extended to the continuous-time domain for stochastic processes by Lok (2008); Saarela & Liu (2016); Ryalen et al. (2019).\\n\\nAssumption 3 (Continuous-time sequential randomization). The intensity process $\\\\lambda(t | F_t)$ with respect to the filtration $F_t$ is equal to the intensity process generated by the filtration $F_t \\\\cup \\\\{\\\\sigma(Y_s) : s > t\\\\}$ that includes the $\\\\sigma$-algebras generated by future outcomes $\\\\{\\\\sigma(Y_s) : s > t\\\\}$.\\n\\nIt is worth mentioning that the intensity process plays the same role as propensity scores in discrete-time models (Robins, 1997), modeling the switching of the treatment process. Assumption 3 can thus be thought of as formalizing sequential randomization in the continuous-time model by stating that the intensity process does not depend on future potential outcomes, i.e. the current information is enough to estimate counterfactuals in the future without bias.\\n\\n4. Treatment Effect Controlled Differential Equation\\n\\nTE-CDE frames the latent trajectory of a patient's state, as a response to a controlled differential equation (CDE), driven by covariate, treatment, and outcome processes (Fig. 2), which to the best of our knowledge is the first to do so. This formulation using a CDE permits to account for information available at $t > 0$ (rather than just initial value $t = 0$). In particular, neural controlled differential equations (Kidger et al., 2020; Morrill et al., 2021) allow incoming information to modulate the dynamics. This ability is natural in a clinical setting, as not only can we model the continuous-time latent state evolution of a patient trajectory, but also we account for incoming data (e.g. treatment changes) that modulate the dynamics of the system.\\n\\nWe now present key components needed to facilitate the modeling of counterfactual outcomes in continuous time. Additional properties of TE-CDE are discussed in Appendix D. The key components are as follows:\\n\\n1. TE-CDE's encoder learns a representation that is defined continuously in time (i.e. a continuous latent path), rather than only at discrete time steps.\\n2. The latent path trajectory evolves as a response of a Neural Controlled Differential Equation (CDE).\\n3. Decoding and prediction are in continuous-time.\\n4. TE-CDE uses domain adversarial training to learn a representation that adjusts for time-dependent confounding and hence is suitable for causal estimation.\\n\\nEncoding the latent path $Z$.\\n\\nTE-CDE's encoder ingests historical observations $F_t$ up to time $t$ and learns a latent path $Z : [t_0, t] \\\\to \\\\mathbb{R}^l$ continuously over time that will be designed to be both predictive of the factual outcomes and agnostic of the observed assigned treatment. An explicit continuous-time representation allows us to process measurements with arbitrary observation patterns. We assume the initial state of the path $Z_{t_0}$ to be parameterized by a neural network $g_\\\\eta : \\\\mathbb{R}^{d+1} \\\\to \\\\mathbb{R}^l$ embeds the initial outcome, covariate and treatment observations into a $l$-dimensional latent state which can be expressed as the solution to a CDE,\\n\\n$$Z_{t_0} = g_\\\\eta(X_{t_0}, A_{t_0}, Y_{t_0}),$$  \\\\hspace{1cm} (2)\\n\\n$$Z_t = Z_{t_0} + \\\\int_{t_0}^t f_\\\\theta(Z_s) ds ds,$$  \\\\hspace{1cm} (3)\\n\\nfor $t \\\\in (t_0, T]$ which denotes the present time, up to which observations of all processes are available. The dynamics of potential outcomes when controlled by the covariate and treatment process take the form of a CDE (Lyons et al., 2007). Hence, the solution $Z$ is said to be the response of a Neural CDE (Kidger et al., 2020) driven or controlled by the covariate, treatment and outcome processes (concatenated into a vector $[X_t, A_t, Y_t] \\\\in \\\\mathbb{R}^{d+1}$). In this sense, Neural CDEs are a family of continuous-time models that explicitly define the latent vector field $f_\\\\theta : \\\\mathbb{R}^l \\\\to \\\\mathbb{R}^{d+1 \\\\times l}$ by a neural network parameterized by $\\\\theta$, and the dynamics are modulated by the values of an auxiliary path over time. We computationally obtain the latent path up to $t$ from $F_t$ by...\"}"}
{"id": "seedat22b", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nFigure 6: Illustrations of different potential sampling patterns\\n\\nFigure 7: Illustration that tumor diameter can oscillate and even increase over a trajectory - for example due to non-response to treatment.\"}"}
{"id": "seedat22b", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we highlight some theoretical nuances and explanations of TE-CDE not captured in the main paper, as well as outlining further implementation details.\\n\\nD.1. Additional Methodological Details\\n\\nTE-CDE latent path construction:\\n\\nIn order to construct the neural controlled differential equation a control path $X_t$ must be defined. The vector field trajectory is driven by (i.e. controlled) by the time-varying $X_t$. Recall we have an observational time series of multi-dimensional data points $((x_{t_0}, a_{t_0}, y_{t_0}), (x_{t_1}, a_{t_1}, y_{t_1}), ..., (x_{t_k}, a_{t_k}, y_{t_k}))$. The control path $X_t$ is then a continuous approximation of these values, which can be obtained through interpolation (choice of interpolation is discussed later).\\n\\nThe latent state $z_t$ is then the solution of a CDE, controlled by $X_t$ described formally by Equation 5 and 6 below.\\n\\n$$\\nZ_{t_0} = g_{\\\\eta}(X_{t_0}, A_{t_0}, Y_{t_0}), \\\\quad (16)\\n$$\\n\\n$$\\nZ_t = Z_{t_0} + \\\\int_{t_0}^t f_{\\\\theta}(Z_s) d\\\\left\\\\{X_s, A_s, Y_s\\\\right\\\\} ds, \\\\quad (17)\\n$$\\n\\nwhere the integral is a Riemann-Stieltjes integral.\\n\\nDifferences between Neural CDEs and Neural ODEs:\\nThe primary difference between a Neural CDE and a Neural ODE lies with the control path $X_t$. The control path addresses a shortcoming of a neural ODE, where the latent state $z_t$ in an ODE is decided by $z_{t_0}$, hence is unsuitable to adapt to incoming data due to reliance on the initial value. Instead, neural CDEs have a latent state $z_t$ controlled by another time series $X_t$. That said, Neural CDEs can be thought of as a generalization of a neural ODE, as neural CDEs can reduce to neural ODEs for the specific case where $X_t = t$.\\n\\nTraining efficiency:\\n\\nTE-CDE and neural CDEs in general make use of the adjoint backpropagation method. This means that the memory requirements when training TE-CDE is $O(T + V)$ where $T = t_1 - t_0$ (time spacing) and $V$ is the size of the vector field.\\n\\nSelecting an interpolation method:\\n\\nSince we are performing counterfactual estimation, we thus need to retain a causal interpretation from TE-CDE. When constructing the continuous control path $X_t$, we need to be careful as all interpolation methods except Linear and Rectilinear are non-causal in nature. i.e. other interpolation methods need future points in time to approximate the signal. This means that when using Neural CDEs in scenarios that require causal interpretations, such as TE-CDE, linear or rectilinear interpolation must be used.\\n\\nTE-CDE solves a well-posed problem:\\n\\nWe highlight that TE-CDE solves a well-posed problem. It was shown by (Lyons et al., 2007) that CDEs solve a well-posed problem under the condition of Lipschitz continuity. We aim to show that TE-CDE still fits the well-posed paradigm. In our architecture we make use of ReLU and softmax activations as well as common neural network layers such as dropout which are Lipschitz constant. Thus, the Lipschitz conditions still hold which means that TE-CDE fulfills the following conditions of a well-posed problem: (1) a solution exists, (2) the solution is unique, (3) the behaviour of the solution changes continuously based on the input data. By virtue of TE-CDE solving a well-posed problem, we note that the training of TE-CDE is thus theoretically stable.\\n\\nRepresenting data continuously:\\n\\nTE-CDE requires a continuous-time embedding of the observational data. Whilst this has numerous benefits, it also introduces challenges. The benefit is firstly it allows us to naturally handle irregularly sampled data and secondly, TE-CDE produces a solution (i.e. the latent state $z_t$) defined at all points in time (i.e. continuously).\"}"}
{"id": "seedat22b", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nThe challenge, however, is that there may be discontinuities in \\\\( A \\\\leq t \\\\) (e.g. treatment is applied in discrete stages). This results in a piecewise smooth control path (not smooth due to linear interpolation). Thus, in our case when using an adaptive solver with a piecewise smooth control path, we then need to explicitly inform the solver about the jumps between pieces so that its integration steps may align with them. This can be achieved using the \\\\texttt{jump} argument in the CDE solver (Chen et al., 2018; Kidger et al., 2020).\\n\\nIf this is not done the adjoint backpropagation method with an adaptive ODE solver can be numerically and computationally expensive (i.e. slower), as the solver must then locate the discontinuities and then slow down to resolve them.\\n\\nD.2. TE-CDE Implementation Details\\n\\nWe discuss the implementation details for TE-CDE in terms of encoder-decoder architecture, optimization and general comments about training.\\n\\nEncoder-Decoder Architecture:\\nThe encoder and decoder of TE-CDE both use Neural CDEs with the same architectures - the difference being the observations for the encoder and decoder (i.e. different inputs). The integrand of the neural CDE (i.e. \\\\( f \\\\)) is a 2-layer neural network with hidden states of size=128. The dimensionality of the latent state \\\\( z \\\\) is 8. We use linear interpolation when defining the control path \\\\( X_t \\\\).\\n\\nOptimization:\\nWe make use of Stochastic Gradient Descent (SGD) as implemented in the Pytorch framework. The ODE solver used to extrapolate the latent state \\\\( z_t \\\\) is an adaptive step size solver namely the Dormand\u2013Prince (\\\\texttt{dopri5}) method, which is a member of the Runga-Kutta family of ODE Solvers. We make use of the \\\\texttt{torchcde} package with \\\\texttt{torchdiffeq} backend. As discussed to account for the discontinuities and piecewise smooth control path we make use of the \\\\texttt{jump} argument.\\n\\nGeneral comments:\\nBoth encoder and decoder are trained for 100 epochs each. That said we also include early stopping in the training protocol based on the validation loss, with patience=5. When MC Dropout is included, we use a dropout probability=0.1. The model was implemented with Pytorch and TorchCDE and was trained and evaluated on a single Nvidia P100 or T4 GPU. We did not explicitly tune hyperparameters (activation function, ODE Solver) for performance. Further tuning could be done for these aspects based on a validation set. However, we did tune the learning rate (\\\\( \\\\text{lr} = 1e^{-3}, 1e^{-4} \\\\times 1e^{-5}, 1e^{-6} \\\\)) based on performance on the validation set.\"}"}
{"id": "seedat22b", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nDue to the underlying usage of Recurrent Neural Networks (RNNs) both CRN and RMSN rely on the assumption of regularly sampled data. Thus, for the irregularly sampled data setting, which effectively means un-observed data samples for different discrete time steps, as is commonly done we include a pre-processing step for RNN-based models, where we divide the timeline equally, interpolate and impute the \\\"un-observed\\\" observations.\\n\\nE.1. Counterfactual Recurrent Network (CRN)\\nWe benchmark CRN using the Tensorflow implementation of (Bica et al., 2020b) as per 7. We pre-process the data for the irregularly sampled setting as described.\\n\\nE.2. Recurrent Marginal Structural Network (RMSN)\\nWe benchmark RMSN using the Tensorflow implementation of (Lim et al., 2018) as per 8. We pre-process the data for the irregularly sampled setting as described. We tune parameters as described by the authors in their repo.\\n\\nE.3. Gaussian Process (GP)\\nThe Gaussian Process (GP) model is evaluated as a continuous-time comparison and is inspired by (Schulam & Saria, 2017). The method however, like prior works using GPs including (Schulam & Saria, 2017) does not account for time-dependent confounding. Similar to (Schulam & Saria, 2017), we use a Matern 3/2 kernel with variance=0.22 and lengthscale=8.0. The benchmark algorithm is implemented using GPy (GPy, since 2012).\\n\\n7 https://github.com/ioanabica/Counterfactual-Recurrent-Network\\n8 https://github.com/sjblim/rmsn_nips_2018\"}"}
{"id": "seedat22b", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nFigure 2: An illustration of TE-CDE. We learn a continuous latent path $Z_t$ as the solution to a CDE by encoding historical observations. At future time points, we decode (hypothetical) future treatments to determine the latent state and use this to predict counterfactual outcomes.\\n\\nSolving the above initial value problem (IVP):\\n\\n$$\\\\forall s \\\\in [t_0, t], z_s = \\\\text{ODESolve}(f_\\\\theta, Z_{t_0}, X \\\\leq t, A \\\\leq t, Y \\\\leq t),$$\\n\\nwhere ODESolve denotes a numerical ODE solver as proposed by Kidger et al. (2020).\\n\\nIn practice, we have access to observations at certain (irregular) time points. Thus, we define an interpolation of the data with piece-wise continuous derivatives that serves as an approximation of the underlying paths.\\n\\nDecoding and prediction. After the encoder processes all the observations up to the present time $t$, TE-CDE starts to decode and predict the potential outcomes up to some time $t'$ in the future for a hypothetical treatment schedule defined by the user. At this point, the latent path $Z$ potentially changes as a result of the chosen treatment schedule, which can similarly be formalized using a second controlled differential equation such that,\\n\\n$$Z_{t'} = Z_t + \\\\int_{t'}^t f_{\\\\phi}(Z_s) \\\\, dA_s \\\\, ds,$$\\n\\nwhere $t'$ denotes a desired time horizon, $Z_t$ is the latent state of $Z$ at time $t$ which encodes the patient's history, and $A_s$ represents the hypothetical treatment schedule for $t < s < t'$.\\n\\n$f_{\\\\phi}: \\\\mathbb{R}_l^{+1} \\\\rightarrow \\\\mathbb{R}_l$ is a feed-forward neural network with trainable weights $\\\\phi$. As before, the decoded path can be obtained by solving the IVP:\\n\\n$$Z_s = \\\\text{ODESolve}(f_{\\\\phi}, Z_t, A_t \\\\leq t').$$\\n\\nDomain adversarial training for counterfactual estimation. The covariates $X$ are time-dependent confounders, which can increase variance in the estimation of counterfactuals if the treatment distribution is not properly balanced given a patient's trajectory (Mansournia et al., 2017). While unbiased by Assumption 3, counterfactual estimates may have lower variance given patient trajectories frequently observed in the data but higher variance for infrequently observed patient trajectories with consequences for performance generalization of the treatment effect as demonstrated by Shalit et al. (2017). To mitigate this confounding bias, we ensure the latent representation $Z_t$ is not predictive of the observed treatment assignment pattern (Shalit et al., 2017; Bica et al., 2020b) which effectively induces representations that are balanced with respect to treatment assignment over time. The treatment invariance breaks the association between time-dependent confounders $X_t$ and current treatment $A_t$.\\n\\nAt each time $t$, the $j$ different treatments $A \\\\in \\\\{A_1, ..., A_j\\\\}$ represent our domains. We then require at each timestep $t$, that the latent path $Z_t$ be invariant across treatments options:\\n\\n$$P(Z_t | A_t = 0) = P(Z_t | A_t = 1)$$\\n\\nand more generally equal across any two values in the domain of treatment options. In this context, distributions of the latent state differ across treatment groups if a classifier trained as a function $Z_t$ to predict treatment assignment accurately separates the two groups. Such representations are called balancing representations as it balances the probability of the predicted treatment process $p(A_t = 1 | Z_t) = 0$, i.e. minimizing the distributional variance between treatment groups in the representation space (Johansson et al., 2020).\\n\\nWe use two neural networks $h_\\\\nu: \\\\mathbb{R}_l \\\\rightarrow \\\\mathbb{R}_d$ and $h_\\\\alpha: \\\\mathbb{R}_l \\\\rightarrow [0, 1]$ to predict the outcome and treatment:\\n\\n$$\\\\hat{y}_s = h_\\\\nu(z_s),$$\\n\\n$$\\\\hat{p}_s := \\\\hat{p}(a_s = 1) = h_\\\\alpha(z_s).$$\"}"}
{"id": "seedat22b", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\n\\\\[ t, t' \\\\]\\n\\nwith observation times \\\\((t_1, \\\\ldots, t_k)\\\\). The mean square error (MSE) of outcome prediction is defined as\\n\\n\\\\[ L(y) = \\\\frac{1}{k} \\\\sum_{j=1}^{k} (y_{t_j} - \\\\hat{y}_{t_j})^2. \\\\]\\n\\nThe cross entropy loss of treatment prediction is defined as:\\n\\n\\\\[ L(a) = -\\\\frac{1}{k} \\\\sum_{j=1}^{k} a_{t_j} \\\\log(\\\\hat{p}_{t_j}) + (1 - a_{t_j}) \\\\log(1 - \\\\hat{p}_{t_j}). \\\\]\\n\\nWe minimize the following loss function, enforcing simultaneous outcome prediction and balanced representations:\\n\\n\\\\[ L = \\\\frac{1}{n} \\\\sum_{i=1}^{n} (L(y)_i - \\\\mu L(a)_i), \\\\]\\n\\nwhere \\\\(\\\\mu > 0\\\\) is a hyper-parameter controlling the trade-off between treatment and outcome prediction. Note that the minus sign before \\\\(L(a)\\\\) would effectively maximize the treatment prediction loss and ensure that \\\\(z_t\\\\) is not predictive of treatment assignment \\\\(A_t\\\\). This leads to balancing representations, which remove bias introduced by time-dependent confounders and allow for reliable counterfactual estimates.\\n\\nRemarks on invariant representations. As shown by Johansson et al. (2019), invertible transformations \\\\((\\\\varphi)\\\\) are necessary for consistency of domain invariant representations \\\\((Z)\\\\). We include for completeness that if \\\\(\\\\varphi\\\\) is non-invertible there is information loss, which leads to unobservable error \\\\((\\\\eta)\\\\). Thus, we desire an invertible \\\\(\\\\varphi\\\\), which ensures \\\\(\\\\eta = 0\\\\).\\n\\nThis highlights an important strength of TE-CDE, where by properties of ODEs/CDEs (Zhang et al., 2020), the representations from TE-CDE have guaranteed invertibility, since integration backward in time is always possible or we can alternatively integrate:\\n\\n\\\\[ -f_{\\\\varphi}(Z_s). \\\\]\\n\\nIntensity of sampling. It is well-known for EHR data that sampling frequency and observations (or lack thereof) carry information about the patient's health status (Alaa et al., 2017). In such cases, we can replace each observed tuple \\\\((x_{t_j}, a_{t_j}, y_{t_j})\\\\) with \\\\((x_{t_j}, a_{t_j}, y_{t_j}, c_{t_j})\\\\) where \\\\(c_{t_j} \\\\in \\\\mathbb{R}^{d+1}\\\\) counts the number of times each one of the dimensions of \\\\(X\\\\), \\\\(A\\\\) and \\\\(Y\\\\) have been observed up to time \\\\(t_j\\\\). The extended tuple is fed into the encoder to inform it about the sampling.\\n\\n5. Experiments\\n\\nIn this section, we validate the ability of TE-CDE to estimate counterfactual outcomes from irregularly sampled observational data. Since counterfactual outcomes are not known for real-world data, it is necessary to use synthetic or semi-synthetic data for empirical evaluation. First, we describe a simulation environment based on a Pharmacokinetic-Pharmacodynamic (PK-PD) model of lung cancer tumor growth (Geng et al., 2017), which allows counterfactuals to be calculated at any time point for arbitrary treatment plans. Furthermore, we introduce a continuous-time observation process based on Hawkes processes. The controllable nature of the observation process allows us to simulate irregularly sampled observational data for a range of different observation process parameterizations, which are motivated by common healthcare scenarios.\\n\\n5.1. Modeling tumor growth under general observation patterns\\n\\nTumor growth dynamics. We use a well-established mathematical PK-PD model for tumor growth in lung cancer patients that includes the effects of chemotherapy and radiotherapy (Geng et al., 2017). The PK-PD model is representative of the true underlying physiological process with responses to interventions. Hence, results using the model should be closely representative of reality. Additionally, the same underlying model was also used by Lim et al. (2018) and Bica et al. (2020b). We briefly describe it below and refer the reader to Appendix C for more details. The tumor volume at time \\\\(t\\\\) after diagnosis is modeled as follows:\\n\\n\\\\[\\ndV(t) = (\\\\rho \\\\log(KV(t))) - \\\\beta C(t) - (\\\\alpha r d(t) + \\\\beta r d(t)^2) + e_t V(t),\\n\\\\]\\n\\nwhere chemotherapy concentration \\\\(C(t)\\\\) and radiotherapy dose \\\\(d(t)\\\\) are defined by their own equations (see Appendix C.1), \\\\(K, \\\\beta_c, \\\\alpha_r, \\\\beta_r\\\\) are effect parameters, and \\\\(e_t\\\\) accounts for randomness in tumor growth (Geng et al., 2017).\\n\\nWe consider four treatment options: no treatment, chemotherapy, radiotherapy, and combined chemotherapy and radiotherapy. The assignment of chemotherapy and radiotherapy are modeled as Bernoulli random variables with probabilities \\\\(p_c\\\\) and \\\\(p_r\\\\), respectively, that depend on tumor diameter as follows:\\n\\n\\\\[\\np_c(t) = \\\\sigma(\\\\gamma_c D_{\\\\text{max}}(\\\\bar{D}(t) - \\\\theta_c)),\\n\\\\]\\n\\n\\\\[\\np_r(t) = \\\\sigma(\\\\gamma_r D_{\\\\text{max}}(\\\\bar{D}(t) - \\\\theta_r)),\\n\\\\]\\n\\nwhere \\\\(D_{\\\\text{max}} = 13\\\\) cm is the maximum tumor diameter, \\\\(\\\\theta_c = \\\\theta_r = D_{\\\\text{max}}/2\\\\) and \\\\(\\\\bar{D}(t)\\\\) is the average tumor diameter.\\n\\nThe degree of time-dependent confounding is controlled by \\\\(\\\\gamma_c\\\\) and \\\\(\\\\gamma_r\\\\), where increasing \\\\(\\\\gamma\\\\{c, r\\\\}\\\\) increases the probability that observational treatment assignment is based on tumor diameter (For more details see Appendix C.1).\\n\\nObservation process. As discussed in Section 1, in real-world clinical settings, patients are rarely observed at fixed, regular time intervals. Instead, they are observed irregularly, with observations often a consequence of clinical factors, e.g. severity of illness, treatment regimen, or medical policy. To simulate such nuances, we augment the simulation environment.\"}"}
{"id": "seedat22b", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nFigure 3: Counterfactual predictions for varying time-varying confounding $\\\\gamma$. Additionally, various values of $\\\\kappa$ are illustrated which controls the intensity of sampling varying over a trajectory based on clinical stage.\\n\\nRonald A. Coifman and Yonina C. Eldar\\n\\nA Hawkes process is a flexible point process with temporal dependencies. Indeed, since clinicians are not memoryless and the times when they make observations often depend on past observations, the Hawkes process appears a sensible parameterization of such an observation process. This is especially true since it captures time-varying sampling intensity that depends on both patient history and clinical state.\\n\\nThese properties have been leveraged by both Bao et al. (2017) and Alaa et al. (2017), who used a Hawkes process to model different types of observational healthcare data, further justifying its applicability to healthcare and its use in our simulations. In addition, the success of both methods applying Hawkes processes to EHR data (which is often high-dimensional data), underlines the applicability to high-dimensional scenarios. From an experimental perspective, the Hawkes process is readily parameterized to simulate different clinical observation scenarios/regimes (i.e. a test bed to simulate different clinical scenarios).\\n\\nFormally, the observation process $\\\\{t_m\\\\}_{m \\\\in \\\\mathbb{N}}$ is modeled as a univariate Hawkes process with a self-exciting intensity function and exponential kernel function (Lee et al., 2016):\\n\\n$$\\\\lambda(t, s_t) = \\\\lambda_0 + \\\\sum_{\\\\tau < t} e^{-2(t - t_m)}$$\\n\\nwhere $s_t$ represents the clinical state of the patient at time $t$ and $\\\\tau$ represents the time of the previous change of state, i.e. $\\\\tau = \\\\max\\\\{t' < t: s_{t'} = s_t, s_{t'} \\\\neq s_t\\\\}$. We define the clinical state using the American Joint Committee on Cancer staging system (Gershenwald et al., 2017). We convert the clinical stages $\\\\{S_1A, S_1B, S_2, S_3\\\\}$ to stages $s_t = \\\\{0, 1, 2, 3\\\\}$ (see Appendix C.2 for further details).\\n\\nWhile in state $s_t = i$, the base observation intensity is given by $\\\\lambda_0 = 0.01\\\\kappa_i$, where $\\\\kappa \\\\geq 1$ controls the change of base sampling intensity between cancer stages, resulting in a higher base sampling intensity for patients with more advanced cancer, emulating real-world observation patterns. Note that further control over the sampling process is possible, either by introducing additional states $s_t$ or varying $\\\\kappa$ based on, for example, treatment. Examples of observation trajectories can be found in Appendix C.2.\\n\\nBenchmarks. We compare TE-CDE with state-of-the-art methods for counterfactual estimation over time CRN (Bica et al., 2020b) and RMSN (Lim et al., 2018) in different irregular sampling scenarios. Both CRN and RMSN rely on the assumption of regularly sampled data. Thus, for the irregular setting of interest, we divide the timeline equally, interpolate and impute the \u201cun-observed\u201d observations. We also evaluate a Gaussian Process (GP) based model for continuous-time, similar to Schulam & Saria (2017). However, the model performance is poor for larger values of time-dependent confounding, and the results are included together with additional experiments in Appendix F. For domain adversarial training, we use the standard procedure (Ganin et al., 2016), with an initial $\\\\mu = 0$ that follows an exponentially increasing schedule per epoch of training for the range $[0, 1]$. In addition, we assess the impact of the adversarial training procedure in TE-CDE by training a version of our method without domain adversarial training, i.e. constant $\\\\mu = 0$ in the loss function (Eq. 9).\\n\\nExperimental details. Implementation details, including hyper-parameters, can be found in Appendix E. Unless otherwise stated, each experiment is run with 10,000 patients for training, 1,000 for validation and 10,000 for testing.\"}"}
{"id": "seedat22b", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\ntime-dependent confounding on counterfactual estimation. We measure performance via normalized RMSE, where the RMSE is normalized by the maximum tumor volume $V_{\\\\text{max}} = 1150 \\\\text{ cm}^3$. As discussed, time-dependent confounding is controlled by parameters $\\\\gamma_c, \\\\gamma_r$ in the treatment assignment policies. We evaluate the benchmarks under increasing degrees of time-dependent confounding by setting $\\\\gamma_c = \\\\gamma_r = \\\\gamma = \\\\{2, 4, 6, 8, 10\\\\}$.\\n\\nAs previously discussed, a patient's condition often affects the frequency of observation. The state-based variability in sampling intensity based on the clinical state is controlled by $\\\\kappa$ in the simulation environment. We repeat the experiment for multiple values of the scaling factor $\\\\kappa = \\\\{1, 5, 10\\\\}$.\\n\\nFigure 3 shows the results for counterfactual estimation for different levels of sampling intensity $\\\\kappa$. As expected, the performance of all models degrades with increasing time-dependent confounding. However, TE-CDE achieves the lowest counterfactual estimation RMSE for all values of sampling intensity $\\\\kappa$ and across all values of time-dependent confounding $\\\\gamma$. The divergence is most pronounced for increasing $\\\\gamma$, with $\\\\gamma = 10$ leading to a 36% decrease in RMSE for TE-CDE compared to CRN, the next best performing method. The superior performance of TE-CDE in all settings highlights the benefit of the continuous-time approach adopted compared to RNN-based approaches.\\n\\nComparing the RNN-based models, CRN outperforms RMSN, matching the conclusions in the regularly sampled setting reported in Bica et al. (2020b). Overall, however, the results highlight the limitation of RNN-based models in the irregularly sampled setting.\\n\\nFinally, we characterize the value of domain adversarial training in TE-CDE by comparing it to the case when $\\\\mu = 0$ (i.e. no domain adversarial training). TE-CDE suffers significant performance degradation with a higher RMSE in all scenarios that grows as the degree of time-dependent confounding increases. This clearly demonstrates the practical benefit of the adversarial training approach to learning balancing representations.\\n\\n5.3. Treatment-conditioned sampling\\n\\nIn the previous section, we consider the realistic scenario where the severity of the patients' condition governs the intensity of the observation process, i.e. sicker patients with higher stages are observed more frequently. In addition, the treatment regimen itself will often also influence the observation pattern of the patient, i.e. patients undergoing different treatments are monitored differently.\\n\\nTo simulate this phenomenon, we adjust the base sampling intensity $\\\\kappa$ depending on whether the patient is treated or untreated, thereby altering the state-dependent sampling variability between the two treatment groups. We set $\\\\kappa = 10$ for treated patients and $\\\\kappa = 1$ for untreated patients. We fix the time-dependent confounding as $\\\\gamma = 4$.\\n\\nConsistent with the previous experiment, TE-CDE significantly outperforms the benchmark models (Table 2). There is a divergence in performance between the treated and untreated populations. This is largely explained by differences in the severity of the clinical condition between the two populations: the majority of untreated patients ($77\\\\%$) remain in cancer stage S1A (i.e. $s_{\\\\text{max}} = 0$). Due to the reduced state transition, these patients naturally have lower variability in tumor volume over the trajectory, leading to lower error for all methods. Overall, TE-CDE outperforms all methods globally and for treated and untreated patients.\\n\\nTable 2: Normalized RMSE (%) for counterfactual estimation with $\\\\kappa$ conditioned on treatment, where $\\\\kappa_{\\\\text{treated}} = 10$ and $\\\\kappa_{\\\\text{untreated}} = 1$.\\n\\n| Model       | Overall | Treated | Untreated |\\n|-------------|---------|---------|-----------|\\n| TE-CDE      | 1.18 \u00b1 0.05 | 1.56 \u00b1 0.06 | 0.22 \u00b1 0.02 |\\n| CRN         | 1.57 \u00b1 0.06 | 1.97 \u00b1 0.05 | 0.64 \u00b1 0.08 |\\n| RMSN        | 3.06 \u00b1 0.09 | 3.12 \u00b1 0.07 | 2.83 \u00b1 0.08 |\\n\\n5.4. Forecasting at additional time horizons\\n\\nWe have assessed the ability to estimate counterfactual outcomes at the subsequent observation time determined by the Hawkes process described in Section 5.1. To further validate our method, we assess counterfactual estimation at subsequent observation times that are further in the future. As an illustrative example, we evaluate counterfactual estimation at time $t_{k+n}$, i.e. estimate tumor volume $y_{t_{k+n}}$. Similar to other experiments, we vary the degree of time-dependent confounding $\\\\gamma = \\\\{2, 4, 6, 8, 10\\\\}$, fix $\\\\kappa = 10$, and set the forecasting horizon $n = 5$ (see Appendix F.8 for other time horizons). As expected, it is more challenging to estimate counterfactuals further in the future. As shown in Figure 4, similar trends are observed as the setting of Section 5.2 (Figure 3). TE-CDE outperforms both CRN and RMSN for all $\\\\gamma$, with a greater performance differential as the degree time-dependent confounding increases. For $\\\\gamma = 10$, there is a 40% reduction in RMSE for TE-CDE.\\n\\n5.5. Treatment selection\\n\\nTo demonstrate how models such as TE-CDE could be used in decision support and the potential impact assisting clinical decision makers, we must assess performance in ways beyond counterfactual estimation. One such clinically relevant evaluation is whether the best treatment was selected. This is important since reduced error in counterfactual estimation\"}"}
{"id": "seedat22b", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nFigure 4: Counterfactual estimation at time $t + n$ ($n = 5$) for varying levels of time-dependent confounding $\\\\gamma$.\\n\\nWe define the \u201ccorrect\u201d treatment selection as the treatment that minimizes the tumor volume at time $t + n$ (i.e. $y_{t + n}$).\\n\\nWe adopt the same experimental setup as Section 5.4 and set the forecasting horizon $n = 5$, sampling intensity $\\\\kappa = 10$, and vary time-dependent confounding $\\\\gamma = \\\\{2, 4, 6, 8, 10\\\\}$.\\n\\nFigure 5 shows decreasing accuracy for all methods as time-dependent confounding increases. However, for all values of $\\\\gamma$, TE-CDE outperforms both CRN and RMSN, more frequently selecting the optimal treatment. Similar to the other experiments, as $\\\\gamma$ increases, the performance gap between TE-CDE and both CRN and RMSN increases, with a 4% difference in absolute treatment selection accuracy at $\\\\gamma = 4$ increasing to a 10% difference at $\\\\gamma = 10$. This experiment emphasizes that differences in counterfactual estimation result in meaningful differences in treatment selection accuracy.\\n\\nFigure 5: Treatment accuracy under varying degrees of time-dependent confounding $\\\\gamma$.\\n\\n5.6. Additional experiments\\n\\nWe perform a number of additional experiments to further validate TE-CDE. In Appendix F.1, we show how uncertainty estimates can be obtained from TE-CDE and then used to rank counterfactual estimates such that uncertain samples can be deferred to clinicians to improve outcomes. Appendix F.2 compares the data efficiency of the different methods, which is useful in clinical settings with limited labeled data. In Appendix F.3, we explore the latent representation of TE-CDE over time to: (1) highlight that the latent states $z_t$ learned by TE-CDE indeed are treatment-invariant representations and (2) investigate clinical insights that can be ascertained from the latent representations.\\n\\n6. Conclusion\\n\\nState-of-the-art methods for counterfactual estimation are predicated on the assumption of regular and evenly spaced data sampling. However, real-world clinical time series are often irregular. To address this challenge, we introduce TE-CDE, a model that learns to perform counterfactual estimation in continuous time from irregularly sampled observational data with time-dependent confounding. Additionally, we propose a controlled simulation environment for medically realistic irregularly sampled time series. In experiments in a variety of irregular settings, we demonstrate that TE-CDE provides improvements over current state-of-the-art methods.\\n\\nCounterfactual estimation has the potential to assist clinicians with \u201cwhat-if\u201d decision-making. However, when deploying such models in healthcare settings, there are risks, e.g. inaccurate predictions. Furthermore, trade-offs between outcomes and possible treatment side effects are not accounted for by such models. To mitigate possible adverse effects, counterfactual estimates should be part of a \u201chuman-in-the-loop\u201d paradigm, allowing experts to complement predictions with domain knowledge to improve patient outcomes.\\n\\nWe also note that while some aspects of irregularly sampled data are naturally addressed through our formulation, this work is simply a step in the right direction and our proposed solution only partially addresses the complexities of irregular sampling. In particular more is needed to address a number of aspects, such as informative sampling, that are widely prevalent in healthcare. We hope that this serves as a motivation for future work.\\n\\nAcknowledgements\\n\\nThe authors are grateful to Alicia Curth and the 3 anonymous ICML reviewers for their useful comments & feedback on an earlier manuscript. Nabeel Seedat is funded by the Cystic Fibrosis Trust, Fergus Imrie by the National Science Foundation (NSF), grant number 1722516, and both Zhaozhi Qian and Mihaela van der Schaar by the Office of Naval Research (ONR).\"}"}
{"id": "seedat22b", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\nAlaa, A. M. and van der Schaar, M. Bayesian inference of individualized treatment effects using multi-task gaussian processes. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 3427\u20133435, 2017.\\n\\nAlaa, A. M., Hu, S., and Schaar, M. Learning from clinical judgments: Semi-markov-modulated marked hawkes processes for risk prognosis. In International Conference on Machine Learning, pp. 60\u201369. PMLR, 2017.\\n\\nBao, Y., Kuang, Z., Peissig, P., Page, D., and Willett, R. Hawkes process modeling of adverse drug reactions with longitudinal observational data. In Machine learning for healthcare conference, pp. 177\u2013190. PMLR, 2017.\\n\\nBartsch, H., Dally, H., Popanda, O., Risch, A., and Schmezer, P. Genetic risk profiles for cancer susceptibility and therapy response. Cancer Prevention, pp. 19\u201336, 2007.\\n\\nBellot, A. and van der Schaar, M. Policy analysis using synthetic controls in continuous-time. In Proceedings of 38th International Conference on Machine Learning (ICML 2021), 2021.\\n\\nBica, I., Alaa, A., and Van Der Schaar, M. Time series deconfounder: Estimating treatment effects over time in the presence of hidden confounders. In Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research. PMLR, 2020a.\\n\\nBica, I., Alaa, A. M., Jordon, J., and van der Schaar, M. Estimating counterfactual treatment outcomes over time through adversarially balanced representations. In Proceedings of 8th International Conference on Learning Representations (ICLR 2020), 2020b.\\n\\nBica, I., Alaa, A. M., Lambert, C., and Van Der Schaar, M. From real-world patient data to individualized treatment effects using machine learning: current and future methods to address underlying challenges. Clinical Pharmacology & Therapeutics, 109(1):87\u2013100, 2021.\\n\\nChen, R. T., Rubanova, Y., Bettencourt, J., and Duvenaud, D. Neural ordinary differential equations. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6572\u20136583, 2018.\\n\\nDe Brouwer, E., Simm, J., Arany, A., and Moreau, Y. Gru-ode-bayes: Continuous modeling of sporadically-observed time series. In 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), 2019.\\n\\nGal, Y. and Ghahramani, Z. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pp. 1050\u20131059. PMLR, 2016.\\n\\nGanin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., and Lempitsky, V. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096\u20132030, 2016.\\n\\nGeng, C., Paganetti, H., and Grassberger, C. Prediction of treatment response for combined chemo-and radiation therapy for non-small cell lung cancer patients using a bio-mathematical model. Scientific reports, 7(1):1\u201312, 2017.\\n\\nGershenwald, J. E., Scolyer, R. A., Hess, K. R., Sondak, V. K., Long, G. V., Ross, M. I., Lazar, A. J., Faries, M. B., Kirkwood, J. M., McArthur, G. A., et al. Melanoma staging: evidence-based changes in the american joint committee on cancer eighth edition cancer staging manual. CA: a cancer journal for clinicians, 67(6):472\u2013492, 2017.\\n\\nGPy. GPy: A gaussian process framework in python. http://github.com/SheffieldML/GPy, since 2012.\\n\\nGwak, D., Sim, G., Poli, M., Massaroli, S., Choo, J., and Choi, E. Neural ordinary differential equations for intervention modeling. arXiv preprint arXiv:2010.08304, 2020.\\n\\nHawkes, A. G. Spectra of some self-exciting and mutually exciting point processes. Biometrika, 58(1):83\u201390, 04 1971. doi: 10.1093/biomet/58.1.83. URL https://doi.org/10.1093/biomet/58.1.83.\\n\\nHawkes, A. G. and Oakes, D. A cluster process representation of a self-exciting process. Journal of Applied Probability, 11(3):493\u2013503, 1974.\\n\\nHern\u00e1ndez, M. A., Brumback, B., and Robins, J. M. Marginal structural models to estimate the causal effect of zidovudine on the survival of hiv-positive men. Epidemiology, pp. 561\u2013570, 2000.\\n\\nHill, J. L. Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics, 20(1):217\u2013240, 2011.\\n\\nIlg, E., Cicek, O., Galesso, S., Klein, A., Makansi, O., Hutter, F., and Brox, T. Uncertainty estimates and multi-hypotheses networks for optical flow. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 652\u2013667, 2018.\"}"}
{"id": "seedat22b", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nJesson, A., Mindermann, S., Shalit, U., and Gal, Y. \\nIdentifying causal-effect inference failure with uncertainty-aware models. \\nAdvances in Neural Information Processing Systems, 33, 2020.\\n\\nJohansson, F., Shalit, U., and Sontag, D. \\nLearning representations for counterfactual inference. In International conference on machine learning, pp. 3020\u20133029. PMLR, 2016.\\n\\nJohansson, F. D., Sontag, D., and Ranganath, R. \\nSupport and invertibility in domain-invariant representations. In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 527\u2013536. PMLR, 2019.\\n\\nJohansson, F. D., Shalit, U., Kallus, N., and Sontag, D. \\nGeneralization bounds and representation learning for estimation of potential outcomes and causal effects. arXiv preprint arXiv:2001.07426, 2020.\\n\\nKidger, P., Morrill, J., Foster, J., and Lyons, T. \\nNeural controlled differential equations for irregular time series. 34th Conference on Neural Information Processing Systems (NeurIPS 2020), 2020.\\n\\nLee, Y., Lim, K. W., and Ong, C. S. \\nHawkes processes with stochastic excitations. In International Conference on Machine Learning, pp. 79\u201388. PMLR, 2016.\\n\\nLi, S. and Fu, Y. \\nMatching on balanced nonlinear representations for treatment effects estimation. In NIPS, 2017.\\n\\nLim, B., Alaa, A. M., and van der Schaar, M. \\nForecasting treatment responses over time using recurrent marginal structural networks. NeurIPS, 18:7483\u20137493, 2018.\\n\\nLok, J. \\nStatistical modeling of causal effects in continuous time. Annals of statistics, 36(3):1464\u20131507, 2008.\\n\\nLyons, T. J., Caruana, M., and L\u00e9vy, T. \\nDifferential equations driven by rough paths. Springer, 2007.\\n\\nMansournia, M. A., Danaei, G., Forouzanfar, M. H., Mahmoodi, M., Jamali, M., Mansournia, N., and Mohammad, K. \\nEffect of physical activity on functional performance and knee pain in patients with osteoarthritis: analysis with marginal structural models. Epidemiology, pp. 631\u2013640, 2012.\\n\\nMansournia, M. A., Etminan, M., Danaei, G., Kaufman, J. S., and Collins, G. \\nHandling time varying confounding in observational research. bmj, 359, 2017.\\n\\nMorrill, J., Kidger, P., Yang, L., and Lyons, T. \\nNeural controlled differential equations for online prediction tasks. arXiv preprint arXiv:2106.11028, 2021.\\n\\nPlatt, R. W., Schisterman, E. F., and Cole, S. R. \\nTime-modified confounding. American journal of epidemiology, 170(6):687\u2013694, 2009.\\n\\nRobins, J. \\nA new approach to causal inference in mortality studies with a sustained exposure period\u2014application to control of the healthy worker survivor effect. Mathematical modelling, 7(9-12):1393\u20131512, 1986.\\n\\nRobins, J., Hern\u00e1n, M., and Brumback, B. \\nMarginal structural models and causal inference in epidemiology. Epidemiology (Cambridge, Mass.), 11(5):550\u2013560, 2000.\\n\\nRobins, J. M. \\nCorrecting for non-compliance in randomized trials using structural nested mean models. Communications in Statistics-Theory and methods, 23(8):2379\u20132412, 1994.\\n\\nRobins, J. M. \\nCausal inference from complex longitudinal data. In Latent variable modeling and applications to causality, pp. 69\u2013117. Springer, 1997.\\n\\nRosenbaum, P. R. and Rubin, D. B. \\nThe central role of the propensity score in observational studies for causal effects. Biometrika, 70(1):41\u201355, 1983.\\n\\nRoueff, F., von Sachs, R., and Sansonnet, L. \\nLocally stationary hawkes processes. Stochastic Processes and their Applications, 126(6):1710\u20131743, 2016.\\n\\nRubanova, Y., Chen, R. T., and Duvenaud, D. \\nLatent ODEs for irregularly-sampled time series. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 5320\u20135330, 2019.\\n\\nRyalen, P. C., Stensrud, M. J., and R\u00f8ysland, K. \\nThe additive hazard estimator is consistent for continuous-time marginal structural models. Lifetime data analysis, 25(4):611\u2013638, 2019.\\n\\nSaarela, O. and Liu, Z. \\nA flexible parametric approach for estimating continuous-time inverse probability of treatment and censoring weights. Statistics in medicine, 35(23):4238\u20134251, 2016.\\n\\nSchisterman, E. F., Cole, S. R., and Platt, R. W. \\nOveradjustment bias and unnecessary adjustment in epidemiologic studies. Epidemiology (Cambridge, Mass.), 20(4):488, 2009.\\n\\nSchulam, P. and Saria, S. \\nReliable decision support using counterfactual models. Advances in Neural Information Processing Systems, 30:1697\u20131708, 2017.\\n\\nShalit, U., Johansson, F. D., and Sontag, D. \\nEstimating individual treatment effect: generalization bounds and algorithms. In International Conference on Machine Learning, pp. 3076\u20133085. PMLR, 2017.\"}"}
{"id": "seedat22b", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nTatekawa, K., Iwata, H., Kawaguchi, T., Ishikura, S., Baba, F., Otsuka, S., Miyakawa, A., Iwana, M., and Shibamoto, Y. Changes in volume of stage I non-small-cell lung cancer during stereotactic body radiotherapy. Radiation Oncology, 9(1):1\u20135, 2014.\\n\\nVan der Maaten, L. and Hinton, G. Visualizing data using t-SNE. Journal of Machine Learning Research, 9(11), 2008.\\n\\nWager, S. and Athey, S. Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523):1228\u20131242, 2018.\\n\\nWang, Y. and Blei, D. M. The blessings of multiple causes. Journal of the American Statistical Association, 114(528):1574\u20131596, 2019.\\n\\nYao, L., Li, S., Li, Y., Huai, M., Gao, J., and Zhang, A. Representation learning for treatment effect estimation from observational data. Advances in Neural Information Processing Systems, 31, 2018.\\n\\nYoon, J., Jordon, J., and Van Der Schaar, M. Ganite: Estimation of individualized treatment effects using generative adversarial nets. In International Conference on Learning Representations, 2018.\\n\\nZhang, H., Gao, X., Unterman, J., and Arodz, T. Approximation capabilities of neural ODEs and invertible residual networks. In International Conference on Machine Learning, pp. 11086\u201311095. PMLR, 2020.\"}"}
{"id": "seedat22b", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Additional Experiments\\n\\nUncertainty Based Exclusion of Estimates\\n\\nUncertainty concerning the counterfactual estimates is an important problem to consider as estimation errors can lead to harmful decisions being taken based on the incorrect estimates. Whilst (Jesson et al., 2020) have examined uncertainty in the static setting, this area is under-studied in longitudinal setting. We aim to illustrate how uncertainty can be modeled within the TE-CDE framework. We then evaluate the utility of the uncertainty estimates to (a) improve model outcomes and counterfactual estimates and (b) examine how uncertainty could be utilized in clinical workflows such that uncertain cases can be flagged and deferred to a clinician.\\n\\nBayesian methods such as variational inference or MCMC can be computationally intensive. Hence, we propose to augment and re-train our TE-CDE model with MC-Dropout (Gal & Ghahramani, 2016). This then allows us to sample $N$ counterfactual outputs $y(i)$, where each dropout mask corresponds to a sample from the approximate posterior distribution $q(\\\\theta)$. The variance of these samples is then representative of the epistemic uncertainty (model uncertainty) in counterfactual estimation.\\n\\n$$\\\\tilde{y} = \\\\frac{1}{N} \\\\sum_{i=1}^{N} y(i)$$\\n\\nEpistemic uncertainty $\\\\sigma^2 = \\\\text{var}(y)$ (18)\\n\\nWe highlight the utility of the uncertainty estimates of TE-CDE to improve model outcomes and counterfactual estimates, by deferring uncertain samples. As discussed, the uncertainty is quantified by the variance of the MC-Sampled counterfactual estimates (epistemic uncertainty). The uncertainty over the trajectory at every timestep is then averaged with the uncertainty estimates represented as $u_{all} = (u_1, u_2, u_3, ..., u_n)$. The $u_{all}$ across all patients is then rank sorted based on the uncertainty metric.\\n\\nAs an illustrative example, we evaluate the quality of TE-CDE's uncertainty estimates by modeling how the RMSE varies as a function of the proportion of \u201cuncertain\u201d data excluded. We posit that a useful measure of uncertainty should lead to a lower RMSE on the retained subset with highest confidence. Hence, we define a meaningful representation of uncertainty as one where the error curve decreases for increasing exclusion of uncertain data. Such a measure could then be used to improve clinical workflows by deferring uncertain estimates to clinicians.\\n\\nThe aforementioned test ascertains if the uncertainty estimate can correctly order the counterfactual estimates. However, a limitation as a result of MC Dropout is the coupling with the model which introduces an implicit dependency on the model that generates the prediction's and uncertainty estimates. Hence, we cannot directly compare different approaches. To address the coupling we utilize the concept of Sparsification from (Ilg et al., 2018). This is a novel application from optical flow to causal inference. We define an Oracle ($u_{oracle} = (u_1, u_2, u_3, ..., u_n)$). The oracle has the best possible ordering of samples, with bounds based on knowing the ground truth and thereby ordering by magnitude of the true error. Thus, the oracle is the lower bound on performance. We can then compute the difference between uncertainty based exclusion and the oracle exclusion given by Equation 8. The oracle is model dependant and by computing the difference we marginalize out the impact of the oracle. Hence, we can then use the sparsification error to directly compare different uncertainty estimates.\\n\\n$$\\\\text{Sparsification error} = \\\\sum_{i=1}^{n} u_{a_i} - u_{o_i}$$ (19)\\n\\nIn order, to produce a single comparative metric to compare models, the area under the sparsification error curve (AUSE) can be used to compare the different models and uncertainty measures. Smaller values correspond to better performance as the measure would then be closer to the oracle lower bound (i.e. closer to ground truth).\\n\\nBaseline: We use two baselines to validate the utility of TE-CDE's uncertainty estimates: (1) Oracle: best possible exclusion and (2) Random: randomly exclude a proportion of samples. Random exclusion should not result in a reduction in RMSE.\\n\\nResults: The exclusion curves are illustrated in Figure 8. (a) demonstrates a decreasing curve for sorting by variance/epistemic uncertainty. This suggests TE-CDE can be used to produce a useful ranking by uncertainty and performs better than the random baseline. This is corroborated by the Sparsification curve and AUSE (Figure 8 (b)).\"}"}
{"id": "seedat22b", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nWhen comparing exclusion methods it highlights that ordering by the variance/epistemic uncertainty significantly outperforms random exclusion. Moreover, performance is close to the oracle, thereby suggesting TE-CDE can be used to obtain a useful measure of uncertainty. This can then be used to exclude uncertain samples and improve performance. An important observation from a clinical perspective is that a small percentage (<10%) of samples are responsible for the majority of the overall estimation error. This highlights the utility that by deferring uncertain samples to clinicians we could significantly improve overall predictive and patient outcomes.\\n\\n(a) Exclusion based on uncertainty: decreased error as more uncertain samples are excluded. The result highlights that a small proportion of samples are responsible for most of the error.\\n\\n(b) Sparsification curve with AUSE\\n\\nFigure 8: Evaluation of the uncertainty representations for TE-CDE based on exclusions and sparsification\\n\\nF.2. Data Efficiency Benchmark for Different Methods\\n\\nData efficiency is critical in clinical scenarios, where we may not have large datasets. Hence, we wish to quantify the sensitivity of the different methods to the size of the training set.\\n\\nWe contrast the RMSE for counterfactual estimation of TE-CDE, CRN and RMSN for varying amounts of training data, \\\\(n = 1000\\\\), \\\\(5000\\\\) relative to \\\\(n = 10000\\\\). We fix the level of time-varying confounding as \\\\(\\\\gamma = 2\\\\) and \\\\(\\\\kappa = 10\\\\).\\n\\nThe results in Table 5 highlight that TE-CDE achieves the lowest RMSE percentage drop-off for all amounts of training data. Whilst, all methods demonstrate reduced performance as the amount of training data decreases, the performance degradation is less severe for TE-CDE compared to CRN and more so when compared to RMSN. This demonstrates that TE-CDE is more data efficient, which is valuable in clinical settings where the data volume may be limited.\\n\\nWe posit the reason for this phenomenon is that since TE-CDE operates in continuous-time and has a \\\\(z_t\\\\) defined over all time points, that less data is required to learn the underlying dynamics. Whereas, both CRN and RMSN in the discrete paradigm would need more \\\"discrete\\\" examples in order to learn the underlying dynamics for different time steps.\\n\\nTable 5: Data efficiency of models trained on varying amounts of training samples for fixed \\\\(\\\\gamma = 2\\\\)\\n\\n| Train samples | Model          | 10000 train samples (lower better) |\\n|---------------|----------------|------------------------------------|\\n| 5000          | TE-CDE         | 4.8%                               |\\n|               | CRN            | 6.4%                               |\\n|               | RMSN           | 25.6%                              |\\n| 1000          | TE-CDE         | 17.1%                              |\\n|               | CRN            | 18.9%                              |\\n|               | RMSN           | 57.2%                              |\"}"}
{"id": "seedat22b", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We wish to evaluate whether the latent representation $z_t$ over time has indeed learnt treatment invariant representations. Figure 9 illustrates via low dimensional T-SNE embeddings that the TE-CDE latent state learns treatment invariant representations for different treatments over different time periods i.e. with no treatment, chemotherapy, radiotherapy, combined chemotherapy and radiotherapy.\\n\\nFigure 10: T-SNE of the latent representation for both certain (blue) and uncertain (orange) samples\"}"}
{"id": "seedat22b", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations\\n\\nF.4. Linear $f$ and $g$\\n\\nWe conduct an ablation where $f$ and $g$ are linear instead of neural networks. We then assess performance for different amounts of time-dependent confounding ($\\\\gamma = 2, 4, 6, 8, 10$). In terms of performance, we note a drop in RMSE of approximately $0.093 \\\\pm 0.056$. This of course highlights the importance of the neural network to performance. However, the model still retains performant properties suggesting the main source of performance gain is indeed from the CDE component.\\n\\nF.5. Other assessment\\n\\nWe perform an added experiment based on the MIMIC-III ICU dataset (Johansson et al., 2016). Please note the caveat we list below. Similar to Bica et al. (2020b), we predict white blood cell count in response to antibiotic treatment. Consequently, we follow the related work and test on factuals. The results show similar performance for TE-CDE and CRN ($\\\\Delta 0.01$ normalized RMSE), with both models predicting factuals with high accuracy. Note such experiments shouldn't be used to compare models for counterfactual prediction. As for the task on real data, we do not observe counterfactuals, rather only factuals. Hence, as discussed in Section 1, this is more a time-series evaluation rather than a counterfactual outcomes evaluation; which is the focus of this paper.\\n\\nF.6. Impact of Time-Dependent Confounding Across Varying Sampling Intensities\\n\\nTable 6 shows detailed results for the counterfactual predictions under varying sampling intensity ($\\\\kappa$), across various levels of time-dependent confounding ($\\\\gamma$). We compare TE-CDE to CRN, RMSN and also highlight results for the GP.\\n\\n| Sampling intensity $\\\\kappa$ | Model | $\\\\gamma = 2$ | $\\\\gamma = 4$ | $\\\\gamma = 6$ | $\\\\gamma = 8$ | $\\\\gamma = 10$ |\\n|----------------------------|-------|--------------|--------------|--------------|--------------|--------------|\\n| $\\\\kappa = 1$               | TE-CDE| 0.96 \u00b1 0.01  | 1.55 \u00b1 0.02  | 1.83 \u00b1 0.08  | 2.26 \u00b1 0.06  | 3.07 \u00b1 0.35  |\\n|                            | CRN   | 1.07 \u00b1 0.09  | 1.63 \u00b1 0.10  | 2.11 \u00b1 0.29  | 3.23 \u00b1 0.36  | 4.49 \u00b1 0.38  |\\n|                            | RMSN  | 1.92 \u00b1 0.07  | 2.42 \u00b1 0.11  | 2.66 \u00b1 0.15  | 4.00 \u00b1 0.12  | 4.16 \u00b1 0.11  |\\n|                            | TE-CDE ($\\\\mu = 0$) | 1.04 \u00b1 0.16  | 1.77 \u00b1 0.11  | 2.14 \u00b1 0.34  | 3.00 \u00b1 0.21  | 4.26 \u00b1 0.51  |\\n|                            | GP    | 1.74 \u00b1 0.76  | 2.80 \u00b1 0.93  | 3.74 \u00b1 0.40  | 6.15 \u00b1 1.14  | 6.97 \u00b1 1.02  |\\n| $\\\\kappa = 5$               | TE-CDE| 0.88 \u00b1 0.01  | 1.31 \u00b1 0.02  | 2.32 \u00b1 0.08  | 2.62 \u00b1 0.06  | 3.02 \u00b1 0.35  |\\n|                            | CRN   | 1.27 \u00b1 0.15  | 1.78 \u00b1 0.14  | 3.08 \u00b1 0.21  | 4.11 \u00b1 0.38  | 4.90 \u00b1 0.31  |\\n|                            | RMSN  | 2.69 \u00b1 0.12  | 2.92 \u00b1 0.24  | 3.16 \u00b1 0.18  | 4.26 \u00b1 0.13  | 5.40 \u00b1 0.16  |\\n|                            | TE-CDE ($\\\\mu = 0$) | 0.88 \u00b1 0.07  | 1.68 \u00b1 0.05  | 2.97 \u00b1 0.20  | 4.00 \u00b1 0.22  | 4.64 \u00b1 0.59  |\\n|                            | GP    | 9.08 \u00b1 1.53  | 14.19 \u00b1 1.73 | 24.47 \u00b1 2.89 | 39.89 \u00b1 1.02 | 42.99 \u00b1 2.76 |\\n| $\\\\kappa = 10$              | TE-CDE| 0.78 \u00b1 0.01  | 1.16 \u00b1 0.02  | 1.93 \u00b1 0.08  | 2.67 \u00b1 0.06  | 3.03 \u00b1 0.35  |\\n|                            | CRN   | 1.31 \u00b1 0.10  | 1.51 \u00b1 0.11  | 3.10 \u00b1 0.26  | 4.28 \u00b1 0.29  | 4.84 \u00b1 0.31  |\\n|                            | RMSN  | 1.60 \u00b1 0.11  | 2.04 \u00b1 0.12  | 3.67 \u00b1 0.22  | 4.62 \u00b1 0.27  | 5.41 \u00b1 0.31  |\\n|                            | TE-CDE ($\\\\mu = 0$) | 0.85 \u00b1 0.06  | 1.23 \u00b1 0.07  | 2.48 \u00b1 0.06  | 3.49 \u00b1 0.51  | 4.94 \u00b1 0.59  |\\n|                            | GP    | 9.41 \u00b1 0.98  | 14.43 \u00b1 0.95 | 24.74 \u00b1 1.97 | 40.21 \u00b1 0.93 | 43.78 \u00b1 3.11 |\\n\\nF.7. Treatment-Conditioned Sampling\\n\\nTable 7 shows detailed results for counterfactual estimation for treatment conditioned sampling (including results for the GP). Sampling intensity $\\\\kappa$ is conditioned on treatment such that $\\\\kappa_{\\\\text{treated}} = 10$ and $\\\\kappa_{\\\\text{untreated}} = 1$ and $\\\\gamma = 4$.\\n\\n| Model | Overall | Treated | Untreated |\\n|-------|---------|---------|-----------|\\n| TE-CDE | 1.18 \u00b1 0.05 | 1.56 \u00b1 0.06 | 0.22 \u00b1 0.02 |\\n| CRN   | 1.57 \u00b1 0.06 | 1.97 \u00b1 0.05 | 0.64 \u00b1 0.08 |\\n| RMSN  | 3.06 \u00b1 0.09 | 3.12 \u00b1 0.07 | 2.83 \u00b1 0.08 |\\n| GP    | 11.05 \u00b1 0.23 | 16.05 \u00b1 0.54 | 5.66 \u00b1 0.45 |\"}"}
