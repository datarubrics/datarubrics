{"id": "3AuoStfUIH", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nKe Xue\\n\\nRong-Xi Tan\\n\\nXiaobin Huang\\n\\nChao Qian\\n\\nAbstract\\n\\nOffline optimization aims to maximize a black-box objective function with a static dataset and has wide applications. In addition to the objective function being black-box and expensive to evaluate, numerous complex real-world problems entail optimizing multiple conflicting objectives, i.e., multi-objective optimization (MOO). Nevertheless, offline MOO has not progressed as much as offline single-objective optimization (SOO), mainly due to the lack of benchmarks like DesignBench for SOO. To bridge this gap, we propose a first benchmark for offline MOO, covering a range of problems from synthetic to real-world tasks. This benchmark provides tasks, datasets, and open-source examples, which can serve as a foundation for method comparisons and advancements in offline MOO. Furthermore, we analyze how the current related methods can be adapted to offline MOO from four fundamental perspectives, including data, model architecture, learning algorithm, and search algorithm. Empirical results show improvements over the best value of the training set, demonstrating the effectiveness of offline MOO methods. As no particular method stands out significantly, there is still an open challenge in further enhancing the effectiveness of offline MOO. We finally discuss future challenges for offline MOO, with the hope of shedding some light on this emerging field. Our code is available at https://github.com/lambda-bbo/offline-moo.\\n\\n1. Introduction\\n\\nCreating new designs to optimize specific properties is a widespread challenge, encompassing various domains such as real-world engineering design (Tanabe & Ishibuchi, 2020), protein design (Khan et al., 2023), and molecule design (Stanton et al., 2022). Many methods generate new designs by iteratively querying an unknown objective function that maps a design to its property score. However, in real-world situations, evaluating the objective function can be time-consuming, costly, or even dangerous (Dara et al., 2022). To optimize for the next candidate design based on accumulated data, a rational approach prefers to build a model, use it to guide the search, and select a suitable candidate for the evaluation. This approach is known as offline model-based optimization (Trabucco et al., 2022).\\n\\nOffline model-based optimization solely permits access to an offline dataset and does not permit iterative online evaluation (i.e., only one batch of real evaluations), which presents notable challenges in comparison to more commonly studied online optimization. A common approach is to train a deep neural network (DNN) model $f_{\\\\theta}(\\\\cdot)$ on a static dataset and use the trained DNN as a proxy (also known as a surrogate model). The DNN proxy enables gradient descent on existing designs, which can result in an improved solution that is even better than the previously seen best one sometimes. However, this approach has a drawback: the trained proxy is prone to out-of-distribution problems, i.e., it makes inaccurate predictions when applied to data points that deviate significantly from the training distribution. Besides, in some cases, the learned proxy has a non-smooth landscape, posing challenges to optimize in it. Many recent studies try to address these issues from different perspectives, e.g., COMs (Trabucco et al., 2021) uses adversarial training to create a smooth proxy; RoMA (Yu et al., 2021) employs a local smoothness prior to alleviate the fragility of the proxy and achieves robust estimation by model adaptation; Tri-Mentoring (Chen et al., 2023a) effectively utilizes weak ranking supervision signals among proxies and achieves a robust ensemble of proxies by an adaptive soft-labeling module; just to name a few.\\n\\nIn addition to the objective function being black-box and the evaluations being costly, numerous complex real-world problems entail optimizing multiple objectives, frequently with conflicting requirements, which can be formulated as multi-objective optimization (MOO) problems (Miettinen, 1998; Ehrgott, 2005). The goal of MOO is to find a set of solutions that represent the optimal trade-offs among...\"}"}
{"id": "3AuoStfUIH", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nthe various objectives, thereby significantly augmenting the complexity of the problem compared to single-objective optimization (SOO) which aims to obtain a single optimal solution. Indeed, MOO is a more prevalent problem than SOO. Many single-objective problems are essentially multi-objective in nature, but they are often converted into a single objective by assigning weights to multiple objectives, primarily due to the challenges associated with solving MOO (Stanton et al., 2022; Chen & Li, 2023).\\n\\nRecently, researchers have recognized the significance of directly modeling MOO problems (Deb et al., 2002a; Daulton et al., 2020). The demand for offline MOO is also gradually increasing. However, the progress of offline MOO is far behind compared to offline SOO. Thanks to the remarkable benchmark Design-Bench (Trabucco et al., 2022), several advanced offline SOO algorithms have been proposed, which can perform well even in high-dimensional and complex search spaces (Chen et al., 2022; Qi et al., 2022; Yuan et al., 2023; Chen et al., 2023a; Krishnamoorthy et al., 2023; Kim et al., 2023; Chemingui et al., 2024; Yu et al., 2024; Uehara et al., 2024). Unfortunately, there has been no such benchmark available for offline MOO, which hinders its progress. Even for online MOO, most works conduct evaluations on synthetic functions with a few exceptions that include real-world applications. This calls for a much-needed push towards more challenging benchmarks for reliable evaluation of MOO, especially in the offline setting.\\n\\nIn this paper, we propose a first benchmark for offline MOO, where the tasks range from synthetic functions to real-world science and engineering problems, as shown in Figure 1. To facilitate future research, we release our benchmark tasks and datasets with a comprehensive evaluation of different approaches and open-source examples. Specifically, we analyze an offline MOO method from four fundamental perspectives including data, model architecture, learning algorithm, and search algorithm, and propose two types of potential methods, i.e., DNN-based and Gaussian process-based offline MOO, by learning techniques from related areas such as offline SOO and multi-objective Bayesian optimization. Experimental results show that the proposed methods can achieve better results than the optimal ones in the training set. However, as no single method stands out significantly, how to enhance the effectiveness of offline MOO remains open. Our work serves as a starting point for offline MOO, and we hope it can encourage more explorations in this emerging area.\\n\\nOur contributions can be summarized as follows:\\n\\n\u2022 We propose a first benchmark for offline MOO, providing not only a large amount of offline data but also commonly used MOO interfaces. This facilitates the integration of a wider range of problems and algorithms.\\n\\n\u2022 We analyze an offline MOO method from four fundamental perspectives, including data, model architecture, learning algorithm, and search algorithm, and compare various implementations within a unified framework, making it convenient for researchers to compare their performance in a clear manner.\\n\\n\u2022 We provide extensive empirical studies, and also discuss challenges and future directions of offline MOO.\\n\\n2. Background\\n\\n2.1. Offline Optimization\\n\\nGiven an offline-collected static dataset \\\\( D = \\\\{ (x_i, y_i) \\\\}_{i=1}^N \\\\), offline model-based optimization aims to find an optimal solution (also called \u201cdesign\u201d in many scenarios) \\\\( x^* \\\\) that minimizes the black-box objective function \\\\( f(\\\\cdot) \\\\), i.e.,\\n\\n\\\\[\\nx^* = \\\\arg \\\\min_{x \\\\in X} f(x).\\n\\\\]\\n\\nA common approach for solving offline optimization problems is approximating the black-box objective function \\\\( f(\\\\cdot) \\\\) using a surrogate model, e.g., DNN. The parameters of DNN can be trained by minimizing the mean squared error between the predictions and the true scores. After that, the trained DNN model is used as a surrogate evaluator to optimize using a search algorithm, e.g., gradient descent.\"}"}
{"id": "3AuoStfUIH", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nDaulton, S., Balandat, M., and Bakshy, E. Hypervolume knowledge gradient: A lookahead approach for multi-objective Bayesian optimization with partial information. In Proceedings of the 40th International Conference on Machine Learning (ICML), pp. 7167\u20137204, Honolulu, HI, 2023.\\n\\nDeb, K. Multi-objective optimization using evolutionary algorithms. Wiley, 2001.\\n\\nDeb, K. and Jain, H. An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: Solving problems with box constraints. IEEE Transactions on Evolutionary Computation, 18(4):577\u2013601, 2013.\\n\\nDeb, K. and Tiwari, S. Omni-optimizer: A generic evolutionary algorithm for single and multi-objective optimization. European Journal of Operational Research, 185(3):1062\u20131087, 2008.\\n\\nDeb, K., Agrawal, S., Pratap, A., and Meyarivan, T. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2):182\u2013197, 2002a.\\n\\nDeb, K., Thiele, L., Laumanns, M., and Zitzler, E. Scalable multi-objective optimization test problems. In Proceedings of the Congress on Evolutionary Computation (CEC), pp. 825\u2013830, 2002b.\\n\\nDeshwal, A., Belakaria, S., Doppa, J. R., and Kim, D. H. Bayesian optimization over permutation spaces. In Proceedings of 36th AAAI Conference on Artificial Intelligence (AAAI), pp. 6515\u20136523, Virtual, 2022.\\n\\nDong, X. and Yang, Y. NAS-Bench-201: Extending the scope of reproducible neural architecture search. In Proceedings of the 8th International Conference on Learning Representations (ICLR), Addis Ababa, Ethiopia, 2020.\\n\\nDong, X., Liu, L., Musial, K., and Gabrys, B. NATS-Bench: Benchmarking NAS algorithms for architecture topology and size. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(7):3634\u20133646, 2021.\\n\\nEhrgott, M. Multicriteria Optimization. Springer, 2005.\\n\\nEmmerich, M. T., Giannakoglou, K. C., and Naujoks, B. Single-and multiobjective evolutionary optimization assisted by Gaussian random field metamodels. IEEE Transactions on Evolutionary Computation, 10(4):421\u2013439, 2006.\\n\\nFabozzi, F. J., Markowitz, H. M., and Gupta, F. Portfolio selection. Handbook of Finance, 7(1):77, 2008.\\n\\nFu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S. D4RL: Datasets for deep data-driven reinforcement learning. arXiv:2004.07219, 2020.\\n\\nGoh, C. K. and Tan, K. C. An investigation on noisy environments in evolutionary multiobjective optimization. IEEE Transactions on Evolutionary Computation, 11(3):354\u2013381, 2007.\\n\\nHernandez-Lobato, D., Hernandez-Lobato, J., Shah, A., and Adams, R. Predictive entropy search for multi-objective Bayesian optimization. In Proceedings of the 33rd International Conference on Machine Learning (ICML), pp. 1492\u20131501, New York City, NY, 2016.\\n\\nHvarfner, C., Hutter, F., and Nardi, L. Joint entropy search for maximally-informed Bayesian optimization. In Advances in Neural Information Processing Systems 35 (NeurIPS), pp. 11494\u201311506, New Orleans, LA, 2022.\\n\\nIshibuchi, H., Akedo, N., and Nojima, Y. Behavior of multiobjective evolutionary algorithms on many-objective knapsack problems. IEEE Transactions on Evolutionary Computation, 19(2):264\u2013283, 2014.\\n\\nIshibuchi, H., Imada, R., Setoguchi, Y., and Nojima, Y. How to specify a reference point in hypervolume calculation for fair performance comparison. Evolutionary Computation, 26:411\u2013440, 2018.\\n\\nIshibuchi, H., Pang, L. M., and Shang, K. Difficulties in fair performance comparison of multi-objective evolutionary algorithms. IEEE Computational Intelligence Magazine, 17(1):86\u2013101, 2022.\\n\\nJain, M., Raparthy, S. C., Hernandez-Garcia, A., Rector-Brooks, J., Bengio, Y., Miret, S., and Bengio, E. Multi-Objective GFlowNets. In Proceedings of the 40th International Conference on Machine Learning (ICML), pp. 14631\u201314653, Honolulu, HI, 2023.\\n\\nJin, W., Barzilay, R., and Jaakkola, T. S. Hierarchical generation of molecular graphs using structural motifs. In Proceedings of the 37th International Conference on Machine Learning (ICML), pp. 4839\u20134848, Virtual, 2020.\\n\\nJin, Y., Wang, H., Chugh, T., Guo, D., and Miettinen, K. Data-driven evolutionary optimization: An overview and case studies. IEEE Transactions on Evolutionary Computation, 23(3):442\u2013458, 2019.\\n\\nKhan, A., Cowen-Rivers, A. I., Grosnit, A., Robert, P. A., Greiff, V., Smorodina, E., Rawat, P., Akbar, R., Dreczkowski, K., Tutunov, R., et al. Toward real-world automated antibody design with combinatorial Bayesian optimization. Cell Reports Methods, 3(1), 2023.\"}"}
{"id": "3AuoStfUIH", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nKim, M., Berto, F., Ahn, S., and Park, J. Bootstrapped training of score-conditioned generator for offline design of biological sequences. In Advances in Neural Information Processing Systems 36 (NeurIPS), pp. 67643\u201367661, New Orleans, LA, 2023.\\n\\nKnowles, J. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1):50\u201366, 2006.\\n\\nKonakovic Lukovic, M., Tian, Y., and Matusik, W. Diversity-guided multi-objective Bayesian optimization with batch evaluations. In Advances in Neural Information Processing Systems 33 (NeurIPS), pp. 17708\u201317720, Virtual, 2020.\\n\\nKrishnamoorthy, S., Mashkaria, S. M., and Grover, A. Diffusion models for black-box optimization. In Proceedings of the 40th International Conference on Machine Learning (ICML), pp. 17842\u201317857, Honolulu, HI, 2023.\\n\\nKrizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Handbook of Systemic Autoimmune Diseases, 1(4), 2009.\\n\\nKumar, A. and Levine, S. Model inversion networks for model-based optimization. In Advances in Neural Information Processing Systems 33 (NeurIPS), Virtual, 2020.\\n\\nLi, C., Yu, Z., Fu, Y., Zhang, Y., Zhao, Y., You, H., Yu, Q., Wang, Y., Hao, C., and Lin, Y. HW-NAS-Bench: Hardware-aware neural architecture search benchmark. In Proceedings of the 9th International Conference on Learning Representations (ICLR), Virtual, 2021.\\n\\nLin, X., Yang, Z., Zhang, X., and Zhang, Q. Pareto set learning for expensive multi-objective optimization. In Advances in Neural Information Processing Systems 35 (NeurIPS), New Orleans, LA, 2022.\\n\\nLu, Z., Cheng, R., Jin, Y., Tan, K. C., and Deb, K. Neural architecture search as multiobjective optimization benchmarks: Problem formulation and performance assessment. IEEE Transactions on Evolutionary Computation, 28:328\u2013337, 2023.\\n\\nLust, T. and Teghem, J. The multiobjective traveling salesman problem: A survey and a new approach. In Advances in Multi-Objective Nature Inspired Computing, pp. 119\u2013141. Springer, 2010.\\n\\nMiettinen, K. Nonlinear Multiobjective Optimization. Kluwer, 1998.\\n\\nParia, B., Kandasamy, K., and P\u00f3czos, B. A flexible framework for multi-objective Bayesian optimization using random scalarizations. In Proceedings of the 35th Conference on Uncertainty in Artificial Intelligence (UAI), pp. 766\u2013776, Toronto, Canada, 2020.\\n\\nQi, H., Su, Y., Kumar, A., and Levine, S. Data-driven offline decision-making via invariant representation learning. In Advances in Neural Information Processing Systems 35 (NeurIPS), pp. 13226\u201313237, New Orleans, LA, 2022.\\n\\nQian, C., Yu, Y., and Zhou, Z. An analysis on recombination in multi-objective evolutionary optimization. Artificial Intelligence, 204:99\u2013119, 2013.\\n\\nQian, C., Yu, Y., and Zhou, Z. Analyzing evolutionary optimization in noisy environments. Evolutionary Computation, 26(1), 2018.\\n\\nQin, R., Zhang, X., Gao, S., Chen, X., Li, Z., Zhang, W., and Yu, Y. NeoRL: A near real-world benchmark for offline reinforcement learning. In Advances in Neural Information Processing Systems 35 (NeurIPS), New Orleans, LA, 2022.\\n\\nQing, J., Moss, H. B., Dhaene, T., and Couckuyt, I. PF2ES: Parallel feasible Pareto frontier entropy search for multi-objective Bayesian optimization. In Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS), pp. 2565\u20132588, Valencia, Spain, 2023.\\n\\nRasmussen, C. E. and Williams, C. K. I. Gaussian Processes for Machine Learning. The MIT Press, Cambridge, MA, 2006.\\n\\nSong, L., Xue, K., Huang, X., and Qian, C. Monte Carlo tree search based variable selection for high dimensional Bayesian optimization. In Advances in Neural Information Processing Systems 35 (NeurIPS), New Orleans, LA, 2022.\\n\\nStanton, S., Maddox, W. J., Gruver, N., Maffettone, P., Dealaney, E., Greenside, P., and Wilson, A. G. Accelerating Bayesian optimization for biological sequence design with denoising autoencoders. In Proceedings of the 39th International Conference on Machine Learning (ICML), pp. 20459\u201320478, Baltimore, MD, 2022.\\n\\nSuzuki, S., Takeno, S., Tamura, T., Shitara, K., and Karasuyama, M. Multi-objective Bayesian optimization using Pareto-frontier entropy. In Proceedings of the 37th International Conference on Machine Learning (ICML), pp. 9279\u20139288, Virtual, 2020.\\n\\nTanabe, R. and Ishibuchi, H. An easy-to-use real-world multi-objective optimization problem suite. Applied Soft Computing, 89:106078, 2020.\"}"}
{"id": "3AuoStfUIH", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thebelt, A., Tsay, C., Lee, R. M., Sudermann-Merx, N., Walz, D., Shafei, B., and Misener, R. Tree ensemble kernels for Bayesian optimization with known constraints over mixed-feature spaces. In *Advances in Neural Information Processing Systems 35 (NeurIPS)*, New Orleans, LA, 2022.\\n\\nTodorov, E., Erez, T., and Tassa, Y. MuJoCo: A physics engine for model-based control. In *IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, pp. 5026\u20135033, Vilamoura, Portugal, 2012.\\n\\nTrabucco, B., Kumar, A., Geng, X., and Levine, S. Conservative objective models for effective offline model-based optimization. In *Proceedings of the 38th International Conference on Machine Learning (ICML)*, pp. 10358\u201310368, Virtual, 2021.\\n\\nTrabucco, B., Geng, X., Kumar, A., and Levine, S. Design-Bench: Benchmarks for data-driven offline model-based optimization. In *Proceedings of the 39th International Conference on Machine Learning (ICML)*, pp. 21658\u201321676, Baltimore, MD, 2022.\\n\\nUehara, M., Zhao, Y., Hajiramezanali, E., Scalia, G., Eraslan, G., Lal, A., Levine, S., and Biancalani, T. Bridging model-based optimization and generative modeling via conservative fine-tuning of diffusion models. *arXiv:2405.19673*, 2024.\\n\\nVan Veldhuizen, D. A. and Lamont, G. B. Multiobjective evolutionary algorithm test suites. In *Proceedings of the 1999 ACM Symposium on Applied Computing*, pp. 351\u2013357, 1999.\\n\\nWang, Z., Hutter, F., Zoghi, M., Matheson, D., and de Feitas, N. Bayesian optimization in a billion dimensions via random embeddings. *Journal of Artificial Intelligence Research*, 55(1):361\u2013387, 2016.\\n\\nWistuba, M. and Grabocka, J. Few-shot Bayesian optimization with deep kernel surrogates. In *Proceedings of the 9th International Conference on Learning Representations (ICLR)*, Virtual, 2021.\\n\\nXu, J., Tian, Y., Ma, P., Rus, D., Sueda, S., and Matusik, W. Prediction-guided multi-objective reinforcement learning for continuous robot control. In *Proceedings of the 37th International Conference on Machine Learning (ICML)*, pp. 10607\u201310616, Virtual, 2020.\\n\\nYing, C., Klein, A., Christiansen, E., Real, E., Murphy, K., and Hutter, F. NAS-Bench-101: Towards reproducible neural architecture search. In *Proceedings of the 36th International Conference on Machine Learning (ICML)*, pp. 7105\u20137114, Long Beach, CA, 2019.\\n\\nYu, P., Zhang, D., He, H., Ma, X., Miao, R., Lu, Y., Zhang, Y., Kong, D., Gao, R., Xie, J., et al. Latent energy-based odyssey: Black-box optimization via expanded exploration in the energy-based latent space. *arXiv:2405.16730*, 2024.\\n\\nYu, S., Ahn, S., Song, L., and Shin, J. RoMA: Robust model adaptation for offline model-based optimization. In *Advances in Neural Information Processing Systems 34 (NeurIPS)*, pp. 4619\u20134631, Virtual, 2021.\\n\\nYu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and Finn, C. Gradient surgery for multi-task learning. In *Advances in Neural Information Processing Systems 33 (NeurIPS)*, Virtual, 2020.\\n\\nYuan, Y., Chen, C., Liu, Z., Neiswanger, W., and Liu, X. Importance-aware co-teaching for offline model-based optimization. In *Advances in Neural Information Processing Systems 36 (NeurIPS)*, New Orleans, LA, 2023.\\n\\nZajac, S. and Huber, S. Objectives and methods in multiobjective routing problems: A survey and classification scheme. *European Journal of Operational Research*, 290(1):1\u201325, 2021.\\n\\nZela, A., Siems, J., Zimmer, L., Lukasik, J., Keuper, M., and Hutter, F. Surrogate NAS benchmarks: Going beyond the limited search spaces of tabular NAS benchmarks. *arXiv:2008.09777*, 2020.\\n\\nZhang, Q. and Li, H. MOEA/D: A multiobjective evolutionary algorithm based on decomposition. *IEEE Transactions on Evolutionary Computation*, 11(6):712\u2013731, 2007.\\n\\nZhang, Q., Liu, W., Tsang, E., and Virginas, B. Expensive multiobjective optimization by MOEA/D with Gaussian process model. *IEEE Transactions on Evolutionary Computation*, 14(3):456\u2013474, 2009.\\n\\nZhang, R. and Golovin, D. Random hypervolume scalarizations for provable multi-objective black box optimization. In *Proceedings of the 37th International Conference on Machine Learning (ICML)*, pp. 11096\u201311105, Virtual, 2020.\\n\\nZhang, X., Lin, X., Xue, B., Chen, Y., and Zhang, Q. Hypervolume maximization: A geometric view of Pareto set learning. In *Advances in Neural Information Processing Systems 36 (NeurIPS)*, New Orleans, LA, 2023.\\n\\nZhang, Y. and Yang, Q. A survey on multi-task learning. *IEEE Transactions on Knowledge and Data Engineering*, 34(12):5586\u20135609, 2022.\"}"}
{"id": "3AuoStfUIH", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nZhao, Y., Wang, L., Yang, K., Zhang, T., Guo, T., and Tian, Y. Multi-objective optimization by learning space partitions. In \\\\textit{Proceedings of the 10th International Conference on Learning Representations (ICLR)}, Virtual, 2022.\\n\\nZhou, Z.-H., Yu, Y., and Qian, C. \\\\textit{Evolutionary Learning: Advances in Theories and Algorithms}. Springer, 2019.\\n\\nZhu, B., Dang, M., and Grover, A. Scaling Pareto-efficient decision making via offline multi-objective RL. In \\\\textit{Proceedings of the 11th International Conference on Learning Representations (ICLR)}, Kigali, Rwanda, 2023.\\n\\nZitzler, E. and Thiele, L. Multiobjective optimization using evolutionary algorithms: A comparative case study. In \\\\textit{Proceedings of the 5th International Conference on Parallel Problem Solving from Nature (PPSN)}, pp. 292\u2013304, Amsterdam, The Netherlands, 1998.\\n\\nZitzler, E., Deb, K., and Thiele, L. Comparison of multiobjective evolutionary algorithms: Empirical results. \\\\textit{Evolutionary Computation}, 8(2):173\u2013195, 2000.\"}"}
{"id": "3AuoStfUIH", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nA. Detailed settings\\n\\nIn this section, we provide detailed settings of Off-MOO-Bench regarding data collection, training set formulation, and default settings of offline MOO methods.\\n\\nA.1. Dataset Collection\\n\\nAs discussed in Section 3.2, only using the expert MOEAs, i.e., NSGA-II, MOEA/D, and NSGA-III, may result in obtaining solutions with good quality, which generates a significant difference between data distribution and diverse reality distribution. Inspired by (Zhu et al., 2023), we propose an amateur survival operator for MOEAs. We first use the expert MOEAs to perform generic mating and generate offspring. Assume that the current population has $\\\\mu$ individuals and the offspring population has $k$ individuals. With a given probability $p$, we choose the $\\\\mu$ among $(\\\\mu + k)$ individuals according to non-dominated sorting of NSGA-II (Deb et al., 2002a) to form the next population. Otherwise, with probability $1 - p$, we survive the $\\\\mu$ best-non-dominated individuals, as the Survival operator in NSGA-II. After a small amount of number of generations (e.g., 1 or 5), we collect the current population to form the final dataset. Typically, we use NSGA-II with the amateur survival operator as the amateur collection algorithm for all tasks of synthetic functions, MOCO, scientific design, and most tasks of RE, except for RE34, where we use NSGA-III due to its better performance in obtaining dataset with diversity.\\n\\nFor NAS-Bench 201 (Dong & Yang, 2020) and NARTS (Dong et al., 2021) in MO-NAS, since the size of their search space is limited (i.e., 15625 for NAS-Bench 201 and 32678 for NARTS), we directly iterate the whole search space and collect query-answers of MO-NAS-Bench (Lu et al., 2023). For MORL tasks, since our goal is to learn directly from policies to rewards, the algorithm for data collection proposed by D4MORL (Zhu et al., 2023) is not suitable for us. Thus, we run the SOTA MORL algorithm PGMORL (Xu et al., 2020) with 100 different seeds and collect the policies. For the tasks of scientific design, we use the Amateur-NSGA-II (as discussed above) to collect part of the dataset, and randomly sample over the whole search space to form the other part.\\n\\nA.2. Training Set Construction\\n\\nIn realistic scientific and industrial scenarios, we usually hope to use offline collected dataset to obtain better designs than offline ones. Thus, similar to (Trabucco et al., 2022), we remove the top solutions sorted by NSGA-II ranking with a given percentile $K$, where $K$ varies according to different tasks and is usually set 40%, except for Molecule with 1.2%, RFP and Regex with 20%, and MO-CVRP with 55%. Besides, we perform normalization within each objective of each problem because different objectives can have different scales, which may result in imbalanced model update.\\n\\nA.3. Training Details\\n\\nFor NN-based model, similar to Design-Bench (Trabucco et al., 2022), the End-to-End network structure is:\\n\\n\\\\[\\n\\\\text{input} \\\\rightarrow \\\\text{MLP}(2048) \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP}(2048) \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP} \\\\left( \\\\text{number of objectives} \\\\right).\\n\\\\]\\n\\nThe Multi-Head model is constructed by two parts of neural networks, feature extractor and task head. For feature extractor, the structure is:\\n\\n\\\\[\\n\\\\text{input} \\\\rightarrow \\\\text{MLP}(2048) \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP}(2048).\\n\\\\]\\n\\nFor task head, the structure is:\\n\\n\\\\[\\n\\\\text{features with 2048 dimensions} \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP}(1).\\n\\\\]\\n\\nThe network structure of multiple models is:\\n\\n\\\\[\\n\\\\text{input} \\\\rightarrow \\\\text{MLP}(2048) \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP}(2048) \\\\rightarrow \\\\text{relu} \\\\rightarrow \\\\text{MLP}(1).\\n\\\\]\\n\\nWe use MSE as loss function and optimize by Adam with learning rate $\\\\eta = 0.001$ and learning-rate decay $\\\\gamma = 0.98$. The DNN model is trained w.r.t. offline dataset for 200 epochs with a batch size of 32.\\n\\nFor the End-to-End + GradNorm method, we perform gradient normalization on the last MLP layer. For the Multi-Head + GradNorm method, we perform gradient normalization on the last MLP layer of the feature extractor, as in MTL (Chen et al., 2018).\"}"}
{"id": "3AuoStfUIH", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nFor GP-based methods, we choose the top 100 solutions by NSGA-II ranking to initialize the GP model. Since the performance of a GP model is sensitive to the number of initialized points, we conduct ablation studies in Figure 4. Among all tasks in Off-MOO-Bench, Molecule and MOCO have constraints. For Molecule, since we optimize in the latent space following Zhao et al. (2022), we cannot judge if a solution is feasible in the latent space. Thus, we first obtain a batch of 256 solutions generated by the algorithm and then filter out the infeasible ones during evaluation. For MOCO tasks, since we use the Start-From-Zero repair operator, the constraint is avoided.\\n\\nA.4. MOO Settings\\n\\nFor DNN-based surrogate models, after the model is trained, we use multi-objective evolutionary algorithms (MOEAs) to optimize inside the trained model. To obtain $K$ (approximately) Pareto-optimal solutions, we set the size of population to $K$ and initialize the population with $K$ non-dominated solutions in the offline dataset, and the algorithm searches for 50 generations. We use different genetic operators for different types of tasks. Specifically, for continuous tasks (i.e., synthetic functions, RE, NAS-Bench-201-Test, MO-Portfolio, MORL, and Molecule), we use the default genetic operators of NSGA-II implemented in PyMOO (Blank & Deb, 2020), i.e., Simulated Binary Crossover (SBX) and Polynomial Mutation (PM). For discrete tasks in MOCO (i.e., MO-TSP, MO-CVRP, and MO-KP), since the search space is combinatorial, where each solution in the three problems can be represented as a permutation, we use Order-Crossover as the crossover operator, Inversion-Mutation as the mutation operator, and for MO-TSP and MO-CVRP problems, we utilize the Start-From-Zero repair operator to make sure that the salesman starts from the deposit. For C-10/MOP and IN-1K/MOP test suites in MO-NAS, we use the suggested genetic operators from the source code of Lu et al. (2023), i.e., PM for integer with $\\\\eta = 20$ and SBX for integer with $\\\\eta = 30$. For Regex, ZINC, and RFP tasks, we use the local mutation operator implemented by LaMBO (Stanton et al., 2022), and SBX for integer as in Stanton et al. (2022).\\n\\nFor GP-based surrogate models, we use different methods to optimize the acquisition function for different types of tasks. Specifically, for continuous tasks (i.e., synthetic functions, RE, NAS-Bench-201-Test, MO-Portfolio, MORL, and Molecule), we use gradient-based methods (i.e., L-BFGS-B (Byrd et al., 1995)) to optimize the acquisition function, which is the default acquisition function optimization method implemented in BoTorch (Balandat et al., 2020). For discrete tasks, we use MOEAs to optimize the acquisition function. Our default MOBO employs NSGA-II (Deb et al., 2002a) to generate a batch of solutions that minimize the lower confidence bound of GP, where we set the size of population to $K$ and initialize the population with $K$ non-dominated solutions in the offline dataset, and the algorithm searches for 500 generations with SBX crossover and PM mutation to obtain the final solutions. For MOBO-\\\\(q\\\\)ParEGO, we use single-objective evolutionary algorithms to optimize the acquisition function. Specifically, we first initialize the population with 50 randomly sampled points, and then search for 500 generations to obtain the best solution for each scalarized single-objective problem. The genetic operators for discrete spaces are as same as the ones in evolutionary search algorithms inside DNN-based surrogate models. Note that MOBO-JES cannot run in discrete tasks, since it requires a stationary kernel and thus Kendall kernel and transformed overlap kernels cannot be utilized.\\n\\nThe implementations of NSGA-II, MOEA/D, and NSGA-III are from the open-source repository PyMOO (Blank & Deb, 2020). The implementation of MOBO is inherited from BoTorch (Balandat et al., 2020).\\n\\nB. Detailed Tasks\\n\\nIn this section, we provide details of different MOO tasks adopted in our experiments. Notably, certain maximization tasks undergo transformation into minimization problems through the multiplication of $-1$. The reference points $r_i$ for majority of tasks are set in such a way that $(r_i - z_{i\\\\text{min}})/(z_{i\\\\text{max}} - z_{i\\\\text{min}}) = 1$, except that for MORL tasks, $(r_i - z_{i\\\\text{min}})/(z_{i\\\\text{max}} - z_{i\\\\text{min}}) = 2.0$, where $r_i$ denotes the value on the $i$-th dimension of the reference point $r$, and $z_{i\\\\text{max}}$ and $z_{i\\\\text{min}}$ are the maximum value and minimum value of the $i$-th objective in the collected data, respectively. It means that after normalization, the reference point becomes $(1.1, \\\\ldots, 1.1)$ or $(2.0, \\\\ldots, 2.0)$.\\n\\nB.1. Synthetic Function\\n\\nVarious widely-used synthetic functions in MOO literature are employed to evaluate the algorithms. Specifically, the following benchmark problems are used: DTLZ1-7 (Deb et al., 2002b), ZDT1-4, ZDT6 (Zitzler et al., 2000), Omni-test (Deb & Tiwari, 2008) and VLMOP1-3 (Van Veldhuizen & Lamont, 1999). The solution spaces for all synthetic problems are continuous. The detailed problem information, Pareto front shape and reference point can be found in Table 3. Note\"}"}
{"id": "3AuoStfUIH", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nthat the concave (2d) Pareto front for DTLZ5 and DTLZ6 indicates that the Pareto front takes the form of a degenerated 2-dimensional curve within a 3-dimensional objective space.\\n\\nTable 3. Problem information and reference point for synthetic functions.\\n\\n| Name        | D  | m  | Type  | Pareto Front Shape | Reference Point            |\\n|-------------|----|----|-------|--------------------|---------------------------|\\n| DTLZ1       | 7  | 3  | Continuous | Linear             | (558.21, 552.30, 568.36)  |\\n| DTLZ2       | 10 | 3  | Continuous | Concave            | (2.77, 2.78, 2.93)        |\\n| DTLZ3       | 10 | 3  | Continuous | Concave            | (1703.72, 1605.54, 1670.48) |\\n| DTLZ4       | 10 | 3  | Continuous | Concave            | (3.03, 2.83, 2.78)        |\\n| DTLZ5       | 10 | 3  | Continuous | Concave (2d)       | (2.65, 2.61, 2.70)        |\\n| DTLZ6       | 10 | 3  | Continuous | Concave            | (9.80, 9.78, 9.78)        |\\n| DTLZ7       | 10 | 3  | Continuous | Disconnected       | (1.10, 1.10, 33.43)       |\\n| ZDT1        | 30 | 2  | Continuous | Convex             | (1.10, 8.58)              |\\n| ZDT2        | 30 | 2  | Continuous | Concave            | (1.10, 9.59)              |\\n| ZDT3        | 30 | 2  | Continuous | Disconnected       | (1.10, 8.74)              |\\n| ZDT4        | 10 | 2  | Continuous | Convex             | (1.10, 300.42)            |\\n| ZDT6        | 10 | 2  | Continuous | Concave            | (1.07, 10.27)             |\\n| Omnittest   | 2  | 2  | Continuous | Convex             | (2.40, 2.40)              |\\n| VLMOP1      | 6  | 2  | Continuous | Concave            | (1.10, 1.10)              |\\n| VLMOP2      | 2  | 3  | Continuous | Disconnected       | (9.07, 66.62, 0.23)       |\\n\\nB.2. MO-NAS\\n\\nMO-NAS (Lu et al., 2023) automates the exploration of optimal neural network architectures to enhance multiple model metrics for specific tasks. In our experiments, we conduct a toy example, named NAS-Bench-201-Test, to optimize three objectives: prediction error, number of parameters, and edge GPU latency, on the CIFAR-10 dataset (Krizhevsky & Hinton, 2009). The prediction error metric primarily assesses the model's performance, the number of parameters gauges the model's scale, and the GPU latency is a hardware metric evaluating the efficiency of GPU during model execution. The search space is from Dong & Yang (2020). Given a macro skeleton of the neural network and a directed acyclic graph structure for each cell, our objective is to explore the operations (edges) within the cell. Each cell contains 6 edges, and there are 5 predefined operation options for each edge (zeroize, skip-connect, \\\\(1 \\\\times 1\\\\) convolution, \\\\(3 \\\\times 3\\\\) convolution, and \\\\(3 \\\\times 3\\\\) average pool). Consequently, the search space is a 6-dimensional discrete space, where each dimension can take 5 values, resulting in a total of \\\\(5^6 = 15625\\\\) possible solutions. The data of NAS-Bench-201-Test, corresponding error and number of parameters are sourced from Dong & Yang (2020). Additionally, the edge GPU latency data is obtained from Li et al. (2021). The reference point is \\\\(r = (98.48, 1.68, 12.81)\\\\).\\n\\nFurthermore, we consider two test suites from Lu et al. (2023), i.e., C-10/MOP and IN-1K/MOP, which contain 18 tasks. The search spaces of these test suites vary from micro search spaces to macro search spaces. Specifically, micro search spaces are used to create a basic building block, often called a cell, which is used repeatedly to build a full deep neural network (DNN) based on a set pattern; macro search spaces are used to design the overall structure of the network, while the individual layers are designed using well-established methods. Micro search spaces include NAS-Bench-101 (Ying et al., 2019), NAS-Bench-201 (Dong & Yang, 2020), and DARTS (Zela et al., 2020). Macro search spaces include NATS (Dong et al., 2021), ResNet50 (Cai et al., 2019), Transformer (Chen et al., 2021), and MNV3 (Cai et al., 2019). Detailed information of these search spaces can be found in Table 4. The detailed problem information and reference point of C-10/MOP1-9 and IN-1K/MOP1-9 tasks can be found in Table 5. Note that we transform the discrete search space of NAS-Bench-201-Test into a continuous logit space, which is the strategy in Design-Bench (Trabucco et al., 2022) for handling discrete categorical tasks. However, it cannot be applied to all tasks in MO-NAS, since it requires that all dimensions have the same number of categories, while the number of categories in most tasks of MO-NAS differ from dimensions.\"}"}
{"id": "3AuoStfUIH", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 4.\\n**An overview of the search spaces in MO-NAS tasks.**\\n\\n| Search space | Type | $|X|$ | $\\\\text{Type}|X|$ |\\n|--------------|------|------|------|\\n| NAS-Bench-101 micro | 26 | 423K |\\n| NAS-Bench-201 micro | 6 | 15.6K |\\n| NATS macro | 5 | 32.8K |\\n| DARTS micro | 32 | \u223c $10^{21}$ |\\n| ResNet50 macro | 25 | \u223c $10^{14}$ |\\n| Transformer macro | 34 | \u223c $10^{14}$ |\\n| MNV3 macro | 21 | \u223c $10^{20}$ |\\n\\n### Table 5.\\n**Problem information and reference point for C-10/MOP1-9 and IN-1K/MOP1-9 tasks.**\\n\\n| Problem | Search space | $X$ | $D$ | $m$ | Reference Point |\\n|---------|--------------|-----|-----|-----|-----------------|\\n| C-10/MOP1 | NAS-Bench-101 | 26 | 423K | | (3.49 \u00d7 10^{-1}, 3.14 \u00d7 10^{7}) |\\n| C-10/MOP2 | NAS-Bench-101 | 26 | 423K | | (9.05 \u00d7 10^{-1}, 3.05 \u00d7 10^{7}, 8.97 \u00d7 10^{9}) |\\n| C-10/MOP3 | NATS | 5 | | | (2.31 \u00d7 10^{1}, 7.14 \u00d7 10^{-1}, 2.74 \u00d7 10^{2}) |\\n| C-10/MOP4 | NATS | 5 | | | (2.31 \u00d7 10^{1}, 7.14 \u00d7 10^{-1}, 2.74 \u00d7 10^{2}, 2.12 \u00d7 10^{-2}) |\\n| C-10/MOP5 | NAS-Bench-201 | 6 | 15.6K | | (9.03 \u00d7 10^{1}, 1.53 \u00d7 10^{0}, 2.20 \u00d7 10^{2}, 1.17 \u00d7 10^{1}, 4.88 \u00d7 10^{1}) |\\n| C-10/MOP6 | NAS-Bench-201 | 6 | 15.6K | | (9.03 \u00d7 10^{1}, 1.53 \u00d7 10^{0}, 2.20 \u00d7 10^{2}, 1.05 \u00d7 10^{1}, 2.12 \u00d7 10^{-2}) |\\n| C-10/MOP7 | NAS-Bench-201 | 6 | 15.6K | | (9.03 \u00d7 10^{1}, 1.53 \u00d7 10^{0}, 2.20 \u00d7 10^{2}, 1.17 \u00d7 10^{1}, 4.88 \u00d7 10^{1}) |\\n| C-10/MOP8 | DARTS | 32 | | | (2.61 \u00d7 10^{-1}, 1.55 \u00d7 10^{-6}) |\\n| C-10/MOP9 | DARTS | 32 | | | (4.85 \u00d7 10^{-2}, 3.92 \u00d7 10^{-5}) |\\n| IN-1K/MOP1 | ResNet50 | 25 | | | (2.81 \u00d7 10^{-1}, 3.95 \u00d7 10^{7}) |\\n| IN-1K/MOP2 | ResNet50 | 25 | | | (2.80 \u00d7 10^{-1}, 1.15 \u00d7 10^{10}) |\\n| IN-1K/MOP3 | ResNet50 | 25 | | | (2.81 \u00d7 10^{-1}, 3.87 \u00d7 10^{7}, 1.26 \u00d7 10^{10}) |\\n| IN-1K/MOP4 | Transformer | 34 | | | (1.83 \u00d7 10^{1}, 7.25 \u00d7 10^{7}) |\\n| IN-1K/MOP5 | Transformer | 34 | | | (1.83 \u00d7 10^{1}, 1.49 \u00d7 10^{10}) |\\n| IN-1K/MOP6 | Transformer | 34 | | | (1.83 \u00d7 10^{1}, 7.10 \u00d7 10^{7}, 1.48 \u00d7 10^{10}) |\\n| IN-1K/MOP7 | MNV3 | 21 | | | (2.64 \u00d7 10^{-1}, 9.98 \u00d7 10^{6}) |\\n| IN-1K/MOP8 | MNV3 | 21 | | | (2.65 \u00d7 10^{-1}, 1.00 \u00d7 10^{7}, 1.34 \u00d7 10^{9}) |\\n| IN-1K/MOP9 | MNV3 | 21 | | | (2.65 \u00d7 10^{-1}, 1.03 \u00d7 10^{7}, 1.31 \u00d7 10^{9}, 6.30 \u00d7 10^{1}) |\"}"}
{"id": "3AuoStfUIH", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Since offline optimization does not allow iterative real evaluations, the algorithm is expected to output a proper solution that is better than the best solution seen in the dataset. However, in practice, producing a single better design entirely from offline data is very difficult, so offline optimization methods are more commonly evaluated in terms of \\\"P percentile of top K\\\" performance (Kumar & Levine, 2020), where the algorithm produces K candidates and the P percentile objective value determines the final performance.\\n\\nMany real-world tasks are inherently multi-objective, but they are usually simplified and formulated as single-objective problems. For example, neural architecture search (NAS) should not only maximize accuracy, but also minimize the scale of the model (Lu et al., 2023); protein design should take efficacy, toxicity, and yield into consideration simultaneously (Stanton et al., 2022). In this paper, we aim to highlight the importance and challenges of offline MOO, and provide a benchmark and comprehensive empirical studies on it.\\n\\n2.2. Multi-Objective Optimization\\n\\nFirst, we give a brief introduction to multi-objective optimization problems, which can be defined as\\n\\n$$\\\\min_{x \\\\in X} f(x) = (f_1(x), \\\\ldots, f_m(x)),$$\\n\\nwhere $x = (x_1, \\\\ldots, x_D)$ is a solution, $f: X \\\\rightarrow \\\\mathbb{R}^m$ constitutes $m$ objective functions, $X$ is the solution space, and $\\\\mathbb{R}^m$ is the objective space. For a non-trivial problem, no single solution can optimize all objectives at the same time, and we have to make a trade-off among them (Qian et al., 2013; Bian et al., 2023).\\n\\nDefinition 2.1. A solution $x^*$ is Pareto-optimal with respect to Eq. (1), if $\\\\nexists x \\\\in X$ such that $\\\\forall i: f_i(x) \\\\leq f_i(x^*)$ and $\\\\exists i: f_i(x) < f_i(x^*)$. The set of all Pareto-optimal solutions is called Pareto-optimal set (PS). The set of the corresponding objective vectors of PS, i.e., $\\\\{f(x) | x \\\\in PS\\\\}$, is called Pareto front (PF).\\n\\nInstead of focusing on a single optimal solution in SOO, the goal of MOO is to find a set of solutions that can approximate the PF well. Next, we will briefly introduce two main kinds of methods for solving MOO problems.\\n\\nMulti-objective evolutionary algorithm (MOEA). Evolutionary algorithms (B\\\"ack, 1996; Zhou et al., 2019) have demonstrated their effectiveness in solving MOO problems. MOEA follows the population-based search by iterative parent selection, reproduction, and survivor selection, which can approximate the Pareto optimal solutions within one execution, with each solution in the population representing a unique trade-off among the objectives (Deb, 2001). Over the last decades, there have been a lot of well-known MOEAs developed (Coello et al., 2007). NSGA-II (Deb et al., 2002a) is a typical Pareto dominance-based MOEA, using fast non-dominated sorting for selecting solutions. MOEA/D (Zhang & Li, 2007) is a decomposition-based MOEA, converting an MOO problem into multiple SOO sub-problems through a number of weights, where neighboring solutions work cooperatively for the optimal solutions of the single-objective sub-problems. NSGA-III (Deb & Jain, 2013) is proposed to handle MOO problems with many objectives (having four or more objectives), by using reference points to assist the selection within non-dominated solutions.\\n\\nMulti-objective Bayesian optimization (MOBO). Many real-world MOO tasks are expensive to evaluate. MOBO is suitable for these tasks due to its high sample-efficiency. Based on the observed data, MOBO learns a surrogate model, e.g., Gaussian process (GP) (Rasmussen & Williams, 2006), searches for new promising candidates based on an acquisition function built on the surrogate model, and queries the quality of these candidates with the ground truth black-box objectives. Existing MOBO methods mainly fall into the following three types. Hypervolume based methods consider the widely-used hypervolume metrics in acquisition function (Emmerich et al., 2006; Konakovic Lukovic et al., 2020; Daulton et al., 2021; 2023). Scalaraization based methods reduce the MO acquisition function into one or multiple SO problems via scalarization (Knowles, 2006; Zhang et al., 2009; Paria et al., 2020; Zhang & Golovin, 2020). Information-theoretic methods select points to reduce the uncertainty of the unknown Pareto front (Hernandez-Lobato et al., 2016; Suzuki et al., 2020; Hvarfner et al., 2022; Qing et al., 2023). Besides these methods, there are also works addressing MOBO in other scenarios, such as high-dimensional space (Zhao et al., 2022) and sequence space (Stanton et al., 2022).\\n\\nWhile MOO has made significant progress, most existing methods either use handcrafted mechanism and lack a learning mechanism (e.g., MOEA) or are unable to leverage a large amount of offline data for scalable learning (e.g., MOBO), restricting their applications in offline MOO tasks. Additionally, there is a lack of benchmark for offline MOO. Note that a good benchmark plays a crucial role in the advancement of a research field and the development of state-of-the-art algorithms, such as NASBench (Ying et al., 2019) and HPO-B (Arango et al., 2021) for BBO, D4RL (Fu et al., 2020) and NeoRL (Qin et al., 2022) for offline RL, and Design-bench (Trabucco et al., 2022) for offline SOO.\\n\\nIn the following, we will propose the problem of offline MOO and provide a large-scale benchmark, covering a wide range of tasks and methods.\"}"}
{"id": "3AuoStfUIH", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization (Off-MOO-Bench) in Section 3.2. We will introduce the tasks and methods in our benchmark in Sections 4 and 5, respectively.\\n\\n3.1. Offline MOO\\n\\nGiven an offline-collected static dataset \\\\( D = \\\\{ (x_i, y_i) \\\\}_{i=1}^N \\\\), where \\\\( x_i \\\\) and \\\\( y_i \\\\) denote a solution and its objective vector, respectively, offline MOO aims to find a set of solutions to approximate the Pareto front of the MOO problem in Eq. (1). Similar to offline SOO, offline MOO only allows access to the offline dataset and does not permit iterative online evaluation. Besides, the MOO nature makes offline MOO more challenging.\\n\\nDue to the goal of finding a set of solutions rather than a single solution, the commonly used measure \u201c\\\\( \\\\text{P} \\\\) percentile of top \\\\( K \\\\)\u201d in offline SOO cannot be directly applied for offline MOO. In our experiments, each offline MOO algorithm first outputs a certain number of solutions (e.g., 256 and 32) to be evaluated. To report the \u201c\\\\( \\\\text{P} \\\\) percentile\u201d measure, we use the NSGA-II selection procedure (i.e., first applying non-dominated sorting then selecting the top solutions) (Deb et al., 2002a) to eliminate the top \\\\( 1-\\\\text{P}\\\\% \\\\) of solutions and report the remaining solutions\u2019 metrics as the evaluation results. There are two commonly used metrics in MOO, i.e., inverted generational distance (IGD) (Bosman & Thierens, 2003), which measures the distance between a solution set and the true Pareto front, and hypervolume (HV) (Zitzler & Thiele, 1998), which measures the volume of the objective space between a reference point and the objective vectors of a solution set, reflecting both convergence and diversity of the solution set. Because the calculation of IGD requires knowing the true Pareto front, which cannot be obtained in real-world tasks, we use HV as the metric in our benchmark. The reference point required to calculate HV is set to the nadir point, each dimension of which corresponds to the worst value of one objective. Details are provided in Appendix A.\\n\\n3.2. Dataset Collection\\n\\nWe use three representative MOEAs, i.e., NSGA-II, MOEA/D, and NSGA-III, introduced in Section 2.2 to collect the data for all the tasks. For each problem, we run these three expert algorithms independently and collect the data as our dataset. However, only using the expert algorithms may result in a significant difference between our data distribution and diverse reality distribution. Thus, we introduce a probability of accepting inferior solutions during the survivor selection process of the expert algorithms. In addition, to solve problems with different search spaces, we also employ various types of evolutionary operators. Detailed settings are provided in Appendix A.\\n\\nThe complex objective space of real-world problems presents significant challenges for offline MOO. We provide the visualizations of the objective space in Appendix C. Compared to Design-Bench for offline SOO, our benchmark includes more data due to the inherent challenge of MOO. Additionally, our framework presents many easy-to-use interfaces to facilitate the integration with other algorithm implementations, including sub-problem generation, weight decomposition, HV evaluation, etc.\\n\\n4. Tasks\\n\\nIn this section, we describe the set of tasks included in our benchmark. An overview of the tasks is provided in Table 1. Each task in our benchmark suite comes with a dataset \\\\( D \\\\), along with a ground-truth oracle objective function \\\\( f \\\\) that can be used for evaluation. An offline algorithm should not query the ground-truth oracle function during training, even for hyperparameter tuning. We first discuss the tasks in our benchmark. Detailed information about these tasks are provided in Appendix B due to space limitation.\\n\\n4.1. Synthetic Function\\n\\nWe first use various synthetic functions as our tasks, which encompass several popular MOO problem sets, i.e., DTLZ (Deb et al., 2002b), ZDT (Zitzler et al., 2000), Omni-test (Deb & Tiwari, 2008), and VLMOP (Van Veldhuizen & Lamont, 1999). The search space is continuous, and the objectives are predetermined by the function designers. Although these synthetic functions may not be considered \u201crealistic\u201d, they possess certain advantages and are worth considering for the following reasons: a) Their analytical expressions are known, allowing us to obtain the actual Pareto front for better understanding the problem\u2019s characteristic and the algorithm\u2019s behavior; b) They can be easily configured to any input dimension and any number of objectives, making them suitable for testing large-scale and many-objective optimization algorithms; c) They are computationally efficient to evaluate, enabling us to collect lots of data and assess the scalability of offline MOO algorithms. We implement these synthetic functions and collect the data.\\n\\n4.2. Multi-Objective Neural Architecture Search\\n\\nNAS has paved a promising path towards alleviating the unsustainable process of designing DNN architectures by automating the pipeline. Apart from the prediction error, recent NAS works also consider other objectives, e.g., the number of parameters. These NAS tasks are intrinsically MOO problems, aiming to achieve trade-offs of the multiple design criteria (Lu et al., 2023). We provide a toy example named NAS-Bench-201-Test, which uses a categorical cell-based search space (Dong & Yang, 2020). Besides, C-10/MOP and IN-1K/MOP from Lu et al. (2023) are also included, where both micro and macro search spaces are\\n\\n4\"}"}
{"id": "3AuoStfUIH", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1. Properties of the tasks in offline MOO Benchmark.\\n\\n| Task Name   | Dataset size | Dimensions | # Objectives | Search space |\\n|-------------|--------------|------------|--------------|--------------|\\n| Synthetic Function | 60000 | 2-30 | 2-3 | Continuous |\\n| MO-NAS      | 9735-60000   | 5-34       | 2-3          | Categorical |\\n| MO-Swimmer  | 8571         | 9734       | 2            | Continuous  |\\n| MO-Hopper   | 4500         | 10184      | 2            | Continuous  |\\n| MO-TSP      | 60000        | 20-500     | 2-3          | Permutation |\\n| MO-CVRP     | 60000        | 20-100     | 2-3          | Permutation |\\n| MO-KP       | 60000        | 50-200     | 2-3          | Permutation |\\n| MO-Portfolio | 60000       | 20         | 2            | Continuous  |\\n| Molecule    | 49001        | 32         | 3            | Continuous  |\\n| Regex       | 42048        | 4          | 2            | Sequence    |\\n| RFP         | 4937         | 4          | 2            | Sequence    |\\n| ZINC        | 48000        | 4          | 2            | Sequence    |\\n\\nReal-world Application\\n\\nused. For these tasks, there are three objectives to be minimized, i.e., error, number of parameters and edge GPU latency, which measure the model's performance, scale, and the GPU's efficiency during model execution, respectively. The data is from Lu et al. (2023). Detailed information about tasks is provided in Appendix B.2.\\n\\n4.3. Multi-Objective Reinforcement Learning\\n\\nDecision making in practical applications usually involves reasoning about multiple, often conflicting, objectives (Zhu et al., 2023). For example, when designing a control policy for a running quadruped robot, we need to consider two conflicting objectives: running speed and energy efficiency. Multi-objective reinforcement learning (MORL) aims to learn agents that can handle such a challenging task. We consider two locomotion tasks in the popular MORL benchmark MuJoCo (Todorov et al., 2012), i.e., MO-Swimmer and MO-Hopper. Their search space is the parameters of an agent, which is much larger than other tasks. The two objectives in MO-Swimmer are speed and energy efficiency, and MO-Hopper considers two objectives related to running and jumping. The data is collected by us via running PG-MORL (Xu et al., 2020).\\n\\n4.4. Multi-Objective Combinatorial Optimization\\n\\nMulti-objective combinatorial optimization (MOCO) commonly exists in industries, such as transportation, manufacturing, energy, and telecommunication (Chen et al., 2023b). We consider three typical MOCO problems that are commonly studied, i.e., multi-objective traveling salesman problem (MO-TSP), multi-objective capacitated vehicle routing problem (MO-CVRP), and multi-objective knapsack problem (MO-KP), and a multi-objective portfolio allocation (MO-Portfolio) problem.\\n\\nMO-TSP has $n$ nodes, where each node has two sets of 2-dimensional coordinates. There are two objectives, each of which corresponds to the travel cost calculated using one set of 2-dimensional coordinates of all nodes.\\n\\nMO-CVRP has $n$ customer nodes and a depot node, with each node featured by a 2-dimensional coordinate and each customer node associated with a demand. Following the common practice, we consider two objectives, i.e., the total tour length and the longest length of the route.\\n\\nMO-KP has $n$ items, with each taking a weight and two separate values. The goal is to maximize the sum of their 2-dimensional objective vectors (corresponding to two objectives) under the constraint that the sum of weights does not exceed a capacity. The search space of these problems is a permutation space, and we use the corresponding operator in MOEA to search in it. The MO-Portfolio task is continuous and it is based on the Markowitz Mean-Variance Portfolio Theory (Fabozzi et al., 2008), where the two objectives, i.e., expected returns and variance of returns, are used to illustrate the relations between beliefs and choice of portfolio. The data is collected by us.\\n\\n4.5. Scientific Design\\n\\nMany real-world scientific problems also involve MOO. We consider molecule design and protein design, which are two important sequence optimization problems. The data of these tasks is collected by us.\\n\\nMolecule design is critical to pharmaceutical drug discovery (Dara et al., 2022). Previous research has typically required the generated molecules to fulfill several objectives, e.g., new drugs should generally be non-toxic and ideally easy-to-synthesize, in addition to their primary purpose. In this task, we consider two objectives based on prior work in molecular design (Zhao et al., 2022), i.e., activity against biological targets GSK3\u03b2 and JNK3, respectively. The solution is optimized in a pretrained 32-dimensional continuous latent space (Jin et al., 2020), which is then decoded into...\"}"}
{"id": "3AuoStfUIH", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nmolecular strings and fed into the property evaluators.\\n\\nProtein design is the process of creating new or improved protein structures for use as biomarkers, therapeutics, etc. We consider the following three tasks. Regex is a basic task (around 32 tokens) for protein design, where the objectives are to maximize the counts of multiple bigrams. ZINC is a small scale task (around 128 tokens) to optimize the chemical properties of a small molecule. The two objectives are to maximizing the logP (the octanol-water partition coefficient) and QED (quantitative estimate of druglikeness). RFP is a large-scale task (around 200 tokens) designed to simulate searching for improved red fluorescent protein (RFP) variants, a problem of significant interest to biomedical researchers. The two objectives are maximizing the solvent-accessible surface area and the stability of RFP, respectively.\\n\\n4.6. Real-World Application\\n\\nMOO has applications in many real-world tasks. We select several real-world multi-objective engineering design problems from RE suite (Tanabe & Ishibuchi, 2020), including four bar truss design, pressure vessel design, disc brake design, vehicle crashworthiness design, rocket injector design, etc. These tasks provide various challenges for offline MOO, e.g., they have different number of objectives and different types of variables. We use the evaluation interface from RE and collect the data ourselves.\\n\\n5. Offline MOO Method\\n\\nThis section introduces the approaches for offline MOO. Though no specific approach has yet been developed to address offline MOO problems, we can adapt the techniques from other related topics, such as offline SOO, MOBO, and surrogate-assisted evolutionary algorithm (SAEA) (Jin et al., 2019). All of these methods use a surrogate model and conduct searches within it. Offline SOO uses a neural network to build a surrogate model, while MOBO typically uses a Gaussian process (GP). SAEA may use both, with a focus on \\\"How to properly use the surrogate during the iterative search process\\\", which, however, is not consistent with offline settings that do not support iterative search. As a result, we consider modifying offline SOO and MOBO methods to address offline MOO tasks, by using the DNN-based and GP-based surrogate models, respectively. We will consider four fundamental components of an offline MOO method: data, model architecture, learning algorithm, and search algorithm, which are shown below.\\n\\n5.1. DNN-Based Offline MOO Method\\n\\nDNN-based methods (Yu et al., 2021; Trabucco et al., 2021; 2022; Chen et al., 2023a) have shown impressive performance in offline SOO due to its ability to learn from a large amount of historical data, while also being able to perform search using gradient ascent within it. Model architecture design is a key aspect in this kind of method, especially for offline MOO. We consider the following three models.\\n\\nEnd-to-end model is a straightforward approach, using a DNN to learn an approximation of $m$ objectives simultaneously, where the model takes $x$ as input and outputs an $m$-dimensional objective vector directly.\\n\\nMultiple models maintains $m$ independent surrogate models for an $m$-objective problem, which is a common practice in MOBO. Each individual model learns an objective function independently, allowing for the natural use of offline SOO techniques such as COMs (Trabucco et al., 2021), RoMA (Yu et al., 2021), IOM (Qi et al., 2022), ICT (Yuan et al., 2023), and Tri-Mentoring (Chen et al., 2023a).\\n\\nMulti-head models. We observe that learning multiple objective functions simultaneously is similar to multi-task learning (MTL) (Zhang & Yang, 2022), whose aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. As a commonly used model in MTL, multi-head models can also serve as a fundamental model for offline MOO. Furthermore, we propose utilizing training techniques (e.g., GradNorm (Chen et al., 2018) and Pc-Grad (Yu et al., 2020)) from MTL to assist model training of offline MOO.\\n\\nData pruning. During the training process, we find that using all the data for model training results in a significant inferior performance: the search algorithm can only obtain few solutions. This phenomenon occurs across all model structures, which may be attributed to the training data quality. Thus, we use data pruning, i.e., selecting some solutions with better scores for training. The corresponding experimental validation will be presented in Section 6.3.\\n\\nSearch algorithm. After training the surrogate model, various methods can be used to obtain the final solution set. We default to using the popular NSGA-II (Deb et al., 2002a) as the search algorithm. Additionally, we also consider employing other MOO algorithms, such as MOEA/D (Zhang & Li, 2007), NSGA-III (Deb & Jain, 2013), and MOBO (Daulton et al., 2021).\\n\\n5.2. GP-Based Offline MOO Method\\n\\nGP-based methods, often used in MOBO, are also promising for solving offline MOO problems. However, GP has a much higher computational complexity compared to DNN. Specifically, the computational complexity of learning a GP model is $O(N^3 + N^2D)$ (Rasmussen & Williams, 2006),\"}"}
{"id": "3AuoStfUIH", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"MORL is an approach where the training of an agent focuses on simultaneously maximizing multiple cumulative rewards in some control environment. The primary purpose of proposing the MORL problem in our benchmark is to examine the performance of offline MOO in high-dimensional continuous spaces. Different from the D4MORL benchmark (Zhu et al., 2023), we focus on direct policy parameter search, ignoring some properties of MDP. Note that using numerous neural network parameters as a search space for black-box optimization presents a significant optimization challenge, which is profoundly significant for offline MOO itself. In our experiments, we consider two locomotion tasks namely MO-Swimmer and MO-Hopper, within the widely used MuJoCo benchmark (Todorov et al., 2012). The search space consists of the parameters of the policy network for each environment as defined in (Xu et al., 2020), whose dimension is much higher than other tasks.\\n\\n**MO-Swimmer.** This is a two-objective task with an eight-dimensional state space and a two-dimensional action space. The two objectives are forward speed and energy efficiency, denoted as $R = [R_s, R_e]$. The search space is the 9734-dimensional policy network for MO-Swimmer. At time $t$, the agent is at position $(x_t, y_t)$ and takes an action $a_t$. Then, the instantaneous rewards at time $t$ are defined as:\\n\\n$$R_s = \\\\frac{(x_t - x_{t-1} - 1) \\\\times 0.05}{0}.$$  \\n$$R_e = 0.3 - 0.15 \\\\times X_k \\\\cdot a^2_k,$$\\n\\nwhere $X_k = \\\\{0, \\\\ldots, 9\\\\}$ and $a$ is the action. The reference point $r = (267.67, 99.05)$ after multiplying $-1$. The formulation is a non-linear optimization problem.\\n\\n**MO-Hopper.** This is a two-objective task with an eleven-dimensional state space and a three-dimensional action space. The two objectives are forward speed and jumping height, denoted as $R = [R_s, R_j]$. The search space is the 10184-dimensional policy network for MO-Hopper. At time $t$, the agent is at position $(x_t, h_t)$ and takes an action $a_t$. Then, the instantaneous rewards at time $t$ are defined as:\\n\\n$$R_s = 1.5 \\\\times \\\\frac{(x_t - x_{t-1} - 1) / 0.01 + 1}{2 - 10^{-4} \\\\cdot X_k \\\\cdot a^2_k},$$  \\n$$R_j = 12 \\\\times \\\\frac{(h_t - h_0) / 0.01 + 1}{2 - 10^{-4} \\\\cdot X_k \\\\cdot a^2_k},$$\\n\\nwhere $h_0 = 1.25$ is the initial height. The reference points $r = (1489.01, 4734.48)$ after multiplying $-1$. The formulation is a non-linear optimization problem.\\n\\n**B.4. MOCO**\\n\\nWe evaluate the algorithms on three typical discrete MOCO problems, i.e., the multi-objective traveling salesman problem (MO-TSP) (Lust & Teghem, 2010), multi-objective capacitated vehicle routing problem (MO-CVRP) (Zajac & Huber, 2021) and multi-objective knapsack problem (MO-KP) (Ishibuchi et al., 2014), and one continuous MOCO problem, i.e., multi-objective portfolio problem (MO-Portfolio). The search spaces for the three discrete problems are formulated as permutation spaces, where the parameters of problem instance are randomly generated similar to (Chen et al., 2023b). Additional, for the MO-TSP problem, we also consider its tri-objective variant, as in (Chen et al., 2023b). The MO-Portfolio problem has a continuous search space, i.e., $[0, 1]^n$, to represent the weights of portfolio allocation. Historical stock prices data of each portfolio is provided by Blank & Deb (2020).\\n\\n**MO-TSP** has $n = 500, 100, 50, 20$ nodes, and each node has two sets of two-dimensional coordinates, where the $i$-th objective value of the solution is calculated with respect to the $i$-th set of coordinates. The coordinates are generated uniformly from $[0, 1]^2$. Hence, this is an $n$-dimensional two-objective permutation optimization problem. The reference point is $r = (255.18, 248.44)$.\\n\\n**MO-CVRP** has $n = 100, 50, 20$ customer nodes and a depot node, with each node featured by a two-dimensional coordinate and each customer node associated with a demand. Following the common practice, we consider two objectives, i.e., the total tour length and the longest length of the route. The coordinates and demands are generated uniformly from $[0, 1]^2$ and $\\\\{0, \\\\ldots, 9\\\\}$, respectively. The capacity of vehicle is set to 50. Each solution is represented as an $n$-dimensional permutation.\"}"}
{"id": "3AuoStfUIH", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nThe vehicle then continues from the depot, following the point after the last visited customer in the permutation. This process continues until completion. This is a $n$-dimensional two-objective permutation optimization problem. The reference point is $r = (49.19, 9.58)$.\\n\\n$\\\\text{MO-KP}$ has $n = 200, 100, 50$ items, with each taking a weight and two separate values. The $i$-th objective is to maximize the sum of the $i$-th values under the constraint of not exceeding the knapsack capacity. The weight and value of each item are generated uniformly from $[0, 1]$. The capacity is set to 25. Each solution is represented as a $200$-dimensional permutation. For the evaluation of each solution (permutation), we put the first $k$ items in the permutation into the knapsack, such that including the $(k + 1)$-th item exceeds the knapsack capacity, while the first $k$ items remain within the capacity limit. This is a $n$-dimensional two-objective permutation optimization problem. The reference point is $r = (-7.85, -8.99)$ after multiplying $-1.1$.\\n\\n$\\\\text{MO-Portfolio}$ has $n = 20$ types of portfolios, with each taking an input as its corresponding weight. Here we consider the portfolio allocation problem based on the Markowitz Mean-Variance Portfolio Theory (Fabozzi et al., 2008) with two objectives, where the overall performance of a portfolio can be assessed through the expected return and overall risk of its assets. Geometrically, the expected return of a portfolio is defined as the average return of its assets and the risk is defined as the standard deviation. Additionally, in order to ensure that portfolio allocations are valid, we provide a repair operator that modifies the portfolio weights to ensure that they sum to 1 (as a common constraint in portfolio optimization) and no weights are smaller than a threshold $\\\\theta = 0.001$. The reference point is $r = (0.29, -0.13)$.\\n\\n**B.5. Scientific Design**\\n\\n**Molecule design.** This is a two-objective molecular generation task (Zhao et al., 2022). The task is to optimize the activity against biological targets GSK3$\\\\beta$ and JNK3. The search space is a $32$-dimensional continuous latent space. The solutions in the latent space will be decoded into molecular strings and evaluated by a pre-trained decoder from Jin et al. (2020). The reference point is $r = (0.09, 0.04)$.\\n\\n**Protein design.** We have incorporated two protein sequence design challenges outlined in (Stanton et al., 2022). The sequence optimization task starts with a base sequence pool $\\\\mathcal{P}$ of initial sequences, which are modified to produce new candidate sequences. The optimization problem is restructured into the following nested decisions: 1) Choose a base sequence from the pool; 2) Choose which positions on the sequence to change; 3) Choose the operations to change the token at those positions; 4) If the operation is substitution or insertion, then select the tokens to substitute or insert. Hence, the search space can be formalized as a four-dimensional space, encompassing choices for the base sequence, sequence positions, operations, and tokens.\\n\\nFor $\\\\text{Regex}$, there are $16$ base sequences, $73$ sequence positions, $20$ types of tokens, and $3$ operations (substitution, deletion or insertion). So the search space has a size of $|X| = 16 \\\\times 72 \\\\times 20 \\\\times 3 = 69,120$. The goal is to maximize the counts of three predetermined bigrams. The reference point is $r = (1.11, 1.25, 1.21)$.\\n\\nFor $\\\\text{ZINC}$, there are $16$ base sequences, $257$ sequence positions, $106$ types of tokens, and $3$ operations (substitution, deletion or insertion). So the search space has a size of $|X| = 16 \\\\times 257 \\\\times 106 \\\\times 3 = 1,307,616$. The goal is to maximize the octanol-water partition coefficient (logP) and QED (quantitative estimate of druglikeness). The reference point is $r = (1.36, 2.25)$.\\n\\nFor $\\\\text{RFP}$, there are $43$ base sequences, $489$ sequence positions, $20$ types of tokens, and $1$ operation (substitution). So the search space has a size of $|X| = 43 \\\\times 489 \\\\times 20 \\\\times 1 = 420,540$. The goal is to maximize the solvent-accessible surface area (SASA) and the stability of the RFP. The reference point is $r = (4.80, 4.54)$.\\n\\n**B.6. RE**\\n\\nWe also conduct experiments on seven real-world multi-objective engineering design problems adopted from RE suite (Tanabe & Ishibuchi, 2020). These problems serve as practical application in various fields. The search spaces for the problems are continuous except for $\\\\text{RE23}$, which has a mixed solution space (2 variables as integers and 2 as continuous values). The detailed problem information and reference points can be found in Table 6.\"}"}
{"id": "3AuoStfUIH", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6. Problem information and reference point for RE problems.\\n\\n| Name                        | D   | m  | Type | Pareto Front Shape          | Reference Point         |\\n|-----------------------------|-----|----|------|-----------------------------|-------------------------|\\n| RE21 (Four bar truss design) | 4   | 2  | Continuous | Convex | (3144.44, 0.05)  |\\n| RE22 (Reinforced concrete beam design) | 3   | 2  | Mixed | Mixed                        | (829.08, 2407217.25) |\\n| RE23 (Pressure vessel design) | 4   | 2  | Mixed | Mixed, Disconnected         | (713710.88, 1288669.78) |\\n| RE24 (Hatch cover design)   | 2   | 2  | Continuous | Convex | (5997.83, 43.67)   |\\n| RE25 (Coil compression spring design) | 3   | 2  | Mixed | Mixed, Disconnected         | (124.79, 10038735.00) |\\n| RE31 (Two bar truss design)  | 3   | 3  | Continuous | Unknown | (808.85, 6893375.82, 6793450.00) |\\n| RE32 (Welded beam design)   | 4   | 3  | Continuous | Unknown | (290.66, 16552.46, 388265024.00) |\\n| RE33 (Disc brake design)    | 4   | 3  | Continuous | Unknown | (8.01, 8.84, 2343.30) |\\n| RE34 (Vehicle crashworthiness design) | 5   | 3  | Continuous | Unknown | (1702.52, 11.68, 0.26) |\\n| RE35 (Speed reducer design) | 7   | 3  | Mixed | Unknown                       | (7050.79, 1696.67, 397.83) |\\n| RE36 (Gear train design)    | 4   | 3  | Integer | Concave, Disconnected       | (10.21, 60.00 , 0.97) |\\n| RE37 (Rocket injector design) | 4   | 3  | Continuous | Unknown | (0.99, 0.96, 0.99) |\\n| RE41 (Car side impact design) | 7   | 4  | Continuous | Unknown | (42.65, 4.43, 13.08, 13.45) |\\n| RE42 (Conceptual marine design) | 6   | 4  | Continuous | Unknown | (-26.39, 19904.90, 28546.79, 14.98) |\\n\\nTable 7. Average rank of Multi-Head and Multiple Models w/ and w/o data pruning on each type of task in Off-MOO-Bench.\\n\\n| Methods                      | Synthetic MO-NAS | MORL | MOCO | Sci-Design | RE |\\n|------------------------------|------------------|------|------|------------|----|\\n| D (best)                     | 4.34 \u00b1 0.03      | 4.74 \u00b1 0.21 | 2.75 \u00b1 1.25 | 1.21 \u00b1 0.14 | 3.12 \u00b1 0.12 |\\n| Multi-Head                   | 2.66 \u00b1 0.16      | 2.66 \u00b1 0.24 | 2.25 \u00b1 0.75 | 3.71 \u00b1 0.00 | 3.38 \u00b1 0.00 | 2.73 \u00b1 0.00 | 2.90 \u00b1 0.12 |\\n| Multi-Head + Data Pruning    | 3.25 \u00b1 0.12      | 2.16 \u00b1 0.00 | 4.00 \u00b1 1.00 | 3.31 \u00b1 0.08 | 2.38 \u00b1 0.25 | 3.12 \u00b1 0.12 | 2.90 \u00b1 0.02 |\\n| Multiple Models              | 2.12 \u00b1 0.06      | 2.61 \u00b1 0.08 | 3.25 \u00b1 0.25 | 3.07 \u00b1 0.29 | 2.00 \u00b1 0.25 | 1.90 \u00b1 0.03 | 2.41 \u00b1 0.09 |\\n| Multiple Models + Data Pruning | 2.62 \u00b1 0.06     | 2.84 \u00b1 0.11 | 2.75 \u00b1 0.25 | 3.54 \u00b1 0.23 | 3.83 \u00b1 0.17 | 2.85 \u00b1 0.00 | 2.94 \u00b1 0.10 |\\n\\nAnalysis on data pruning. We first conduct ablation studies of data pruning on the Multi-Head model, as shown in Table 7. Although data pruning can alleviate the issue of model collapse in some problems, it does not consistently lead to improvements in all cases. Due to the severe impact of model collapse (sometimes resulting in only one solution), we default to using data pruning for all advanced methods. As mentioned in the main paper, exploring methods to mitigate model collapse is an important future direction in offline MOO.\\n\\nAnalysis of the volume of data needed for MOBO. As we discussed before, the number of data points for GP is important due to the complexity of learning a GP. Here, we test the influence of the different number of data points, i.e., 50, 100, 200, and 400, on six randomly selected tasks. As shown in Figure 4 (a), 100 is a proper value. Thus, we use 100 for MOBO in our experiments on all the tasks.\\n\\nInfluence of the search algorithms. We compare four search algorithms on seven tasks, i.e., NSGA-II, MOEA/D, NSGA-III, and MOBO, as shown in Figure 4 (b). Their average ranks are 3.28, 2.07, 2.64, and 2.00, respectively. Although NSGA-II has the worst average ranking, we choose to use it as the default search algorithm due to its ease of use and popularity. These results also show that if a search algorithm specifically designed for offline MOO is implemented, the performance can be further improved, which is an interesting future work.\\n\\nC.2. Detailed Results\\n\\nHere, we provide the detailed results on different tasks. We provide results for each type of task with 256 solutions and 100th percentile evaluations. Additionally, we provide results for each type of task with 256 solutions and 50th percentile evaluations to demonstrate the robustness of the algorithms, and results with 32 solutions and 50th percentile evaluations to show the performance under the low-budget settings. Considering the three settings, Multiple Models + IOM, Multiple Models, and Multi-head Model are the top three performing algorithms, with average rankings of 4.91, 5.25, and 7.16, respectively. Note that D (best) achieves the best average rank on MORL, MOCO, and Sci-Design tasks on the 256 solutions.\"}"}
{"id": "3AuoStfUIH", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 9.\\n\\nThe average rank is calculated as follows: For each type of task (e.g., synthetic functions), we first determine the rankings. Then, algorithms within one standard deviation of having the highest performance are bolded.\\n\\n#### Hypervolume Results for MO-NAS with 256 Solutions and 100th Percentile Evaluations\\n\\nFor each task, algorithms within one standard deviation of having the highest performance are bolded.\\n\\n| Methods | Hypervolume Results |\\n|---------|---------------------|\\n| ParEGO  | 4.39                |\\n| \u00b5MOBO   | 4.83                |\\n| \u00b5MOBO-  | 4.84                |\\n| \u00b5MOBO+  | 4.82                |\\n| \u03b1MOBO   | 4.85                |\\n\\n#### End-to-End + PcGrad\\n\\n| Methods | Hypervolume Results |\\n|---------|---------------------|\\n| Multiple Models + Tri-Mentoring | 0.01 |\\n| Multiple Models + RoMA | 0.01 |\\n| MOBO- | 0.02 |\\n| Multi-Head + GradNorm | 0.00 |\\n| Multiple Models + ICT | 0.00 |\\n| Multiple Models + COMs | 0.00 |\\n\\nAdditional Visualization Results\\n\\nC.3. Additional Visualization Results\"}"}
{"id": "3AuoStfUIH", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Methods                  | D (best) | \u00b10.01 | \u00b10.11 | \u00b10.20 | \u00b10.30 | \u00b10.40 | \u00b10.50 | \u00b10.60 | \u00b10.70 | \u00b10.80 | \u00b10.90 | \u00b11.00 |\\n|--------------------------|----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\\n| MOBO                     |          |       |       |       |       |       |       |       |       |       |       |       |\\n| MOBO-JES                 |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models          |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + ICT    |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + Tri-Mentoring | |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + IOM    |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + RoMA   |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + COMs   |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head               |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm    |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + IOM         |          |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad      |          |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End               |          |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm    |          |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + PcGrad      |          |       |       |       |       |       |       |       |       |       |       |       |\"}"}
{"id": "3AuoStfUIH", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 15\\n\\n| Methods                     | 4.76  | 4.65  | 4.91  | 4.92  | 4.94  | 4.91  | 4.57  | 4.81  | 4.84  | 4.84  | 4.84  | 4.79  |\\n|-----------------------------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\\n| Multiple Models + Tri-Mentoring |      |       |       |       |       |       |       |       |       |       |       |       |\\n| Multiple Models + ICT       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| ParEGO                      |       |       |       |       |       |       |       |       |       |       |       |       |\\n| MOBO-JES                    |       |       |       |       |       |       |       |       |       |       |       |       |\\n| MOBO                        |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + PcGrad         |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| Multi-Head + GradNorm       |       |       |       |       |       |       |       |       |       |       |       |       |\\n| End-to-End                  |       |       |       |       |       |       |       |       |       |       |       |       |\"}"}
{"id": "3AuoStfUIH", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Method                        | Hypervolume (best) | Hypervolume | Hypervolume | Hypervolume | Hypervolume | Hypervolume | Hypervolume |\\n|------------------------------|--------------------|-------------|-------------|-------------|-------------|-------------|-------------|\\n| Offline Multi-Objective     | 0.01 1.49 \u00b1 0.02   | 0.01 2.38   | 0.07 2.69   | 0.01 2.05   | 0.07 2.89   | 0.01 1.71   | 0.07 3.17   |\\n| Offline MOBO-JES             | 0.00 N/A 2.18      | 0.00 N/A    | 0.12 0.24   | 0.00 N/A    | 0.04 N/A    | 0.00 N/A    | 0.03 N/A    |\\n| Online Multiple Models       | 0.07 2.14 \u00b1 0.02   | 0.07 2.42   | 0.16 2.69   | 0.01 1.49   | 0.07 2.89   | 0.01 1.71   | 0.07 3.17   |\\n| Online MOBO-JES              | 0.00 N/A 2.18      | 0.00 N/A    | 0.12 0.24   | 0.00 N/A    | 0.04 N/A    | 0.00 N/A    | 0.03 N/A    |\\n| Online MOBO                 | 0.00 N/A 2.18      | 0.00 N/A    | 0.12 0.24   | 0.00 N/A    | 0.04 N/A    | 0.00 N/A    | 0.03 N/A    |\\n\\nTable 18. Hypervolume results for scientific design with 256 solutions and 50th percentile evaluations. For each task, algorithms within one standard deviation of having the highest performance are bolded.\"}"}
{"id": "3AuoStfUIH", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Method                  | Average Rank | Table 21 | Table 22 | Table 23 |\\n|------------------------|--------------|----------|----------|----------|\\n| MOBO                   | 6.56         | 9.06     | 4.78     | \u00b10.00    |\\n| MOBO-JES               | 11.25        | 11.50    | 5.03     | \u00b10.30    |\\n| N/A                    | 8.74         | 4.77     | 4.73     | \u00b10.29    |\\n| N/A                    | 5.74         | 4.93     | 4.84     | \u00b10.03    |\\n| N/A                    | 8.71         | 4.81     | 4.18     | \u00b10.01    |\\n| N/A                    | 4.61         | 3.89     | 4.93     | \u00b10.05    |\\n| Multiple Models        | 10.61        | 10.49    | 10.63    | \u00b10.00    |\\n| Multiple Models + ICT  | 10.61        | \u00b10.00    | \u00b10.01    | \u00b10.00    |\\n| Multiple Models + RoMA | 10.37        | \u00b10.00    | \u00b10.01    | \u00b10.00    |\\n| Multiple Models + IOM  | 10.65        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| Multi-Head + PcGrad    | 10.67        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| End-to-End + PcGrad    | 10.61        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| End-to-End + ICT       | 10.61        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| End-to-End + RoMA      | 10.61        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| End-to-End + IOM       | 10.61        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n| End-to-End + Multi-Head| 10.61        | \u00b10.00    | \u00b10.00    | \u00b10.00    |\\n\\nNote: Bolded values indicate the best performance for each method.\"}"}
{"id": "3AuoStfUIH", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nwhere $N$ is the number of data points and $D$ is the dimension of search space. Thus, directly using GP to offline MOO is not realistic, and data pruning is required. Similar to the data pruning approach in DNN-based methods, we use the non-dominated sorting in NSGA-II (Deb et al., 2002a) to select $K$ data points at the front layers for learning. We will examine the impact of hyper-parameter $K$ on the performance in Figure 4 of Appendix C. We use three mainstream MOBO frameworks for comparison: 1) Hypervolume-based method $q$NEHVI (Daulton et al., 2021) selects solutions that can maximize the expected improvement in hypervolume, which is our default MOBO. 2) Scalarization-based method $q$ParEGO (Daulton et al., 2020) randomly samples $q$ weight vectors to scalarize the objectives into single-objective problems and uses expected improvement to select points within each single-objective problem. 3) Information-theoretic-based method JES (Hvarfner et al., 2022) considers the information gain that maximally reduces the uncertainty in both the input and output spaces. On the special discrete tasks, we use Kendall kernel (Deshwal et al., 2022) and transformed overlap kernel (Khan et al., 2023) as the kernel function of GP for permutation and sequence space, respectively. MOBO employs NSGA-II (Deb et al., 2002a) to generate a batch of solutions. MOBO-$q$ParEGO uses a single-objective genetic algorithm with specific operators to optimize the $q$ single-objective problem. MOBO-JES requires a stationary kernel, therefore Kendall kernel (Deshwal et al., 2022) and transformed overlap kernel (Khan et al., 2023) cannot be utilized. Details are provided in Appendix A.4.\\n\\n6. Experiment\\n\\nIn this section, we empirically examine the performance of different methods on our benchmark. We first introduce the experimental settings, and then report the main results on all the tasks. We also conduct additional experiments to show the challenges of offline MOO, compare training curves, study the effectiveness of data pruning, analyze the volume of data needed for MOBO, and investigate the influence of the search algorithm.\\n\\n6.1. Experimental Settings\\n\\nThe compared methods are introduced as follows. For NN-based methods, we consider the three types of models discussed in Section 5.1. 1) End-to-End models, including End-to-End, End-to-End + GradNorm (Chen et al., 2018), and End-to-End + PcGrad (Yu et al., 2020). 2) Multi-Head models, including Multi-Head, Multi-Head + GradNorm, and Multi-Head + PcGrad. 3) Multiple models, including Multiple Models, Multiple Models + COMs (Trabucco et al., 2021), Multiple Models + RoMA (Yu et al., 2021), Multiple Models + IOM (Qi et al., 2022), Multiple Models + ICT (Yuan et al., 2023), and Multiple Models + Tri-Mentoring (Chen et al., 2023a). For GP-based methods, we use the three main types, including MOBO (i.e., $q$NEHVI (Daulton et al., 2021)), MOBO-$q$ParEGO (Knowles, 2006), and MOBO-JES (Hvarfner et al., 2022). All the advanced methods use data pruning by default. After training the model, a search algorithm (which is NSGA-II (Deb et al., 2002a) by default) is run in the model to generate a set of 256 solutions, which are then conducted by one batched evaluation and used to calculate the HV value (i.e., 100th percentile evaluations). The results of other settings, including 256 solutions with 50th percentile evaluations and 32 solutions with 100th percentile evaluations are provided in Appendix C. The model architecture and hyperparameters are consistently maintained across all tasks. Different operators are used for different search spaces, while the operator remains the same within the same search space across all the methods. We report the mean performance and standard deviation over five identical seeds (1000, 2000, ..., 5000) for all algorithms on all the tasks. Note that not all methods can be applied to every task in Off-MOO-Bench due to the long running time and high computational resource cost (for example, running out of GPU memory due to the high complexity), and we indicate this with \\\"N/A\\\". Detailed experimental settings are provided in Appendix A.\\n\\n6.2. Main Results\\n\\nTable 2 shows the average rank of all the compared methods on each type of task. Note that $D$(best) denotes the best solution set (having the largest HV value) in the training set. Based on the average rank of all tasks (i.e., the last column of the table), we can observe that all the NN-based offline MOO methods outperform the best solution set in the training set, i.e., $D$(best), showcasing the feasibility and effectiveness of offline MOO. Multiple Models + IOM is the generally the best method (i.e., winner of Tables 2 and 21, runner-up of Table 14), demonstrating the effectiveness of advanced offline SOO techniques. However, optimizing in a discrete space can indeed be challenging, e.g., no method can achieve a better rank than $D$(best) on MOCO, whose search space is a permutation space. This is primarily due to the complexity of modeling the discrete space in the surrogate model, which is also a significant challenge in offline SOO (Kim et al., 2023). Although GP-based methods can be applied to offline MOO by setting the number of iterations to 1 with a large batch size, their performance remains unsatisfactory. MOBO achieves only an average ranking of 8.64, while MOBO-$q$ParEGO and MOBO-JES perform even worse than $D$(best). Targeted MOBO algorithms for offline MOO, such as selecting training data more effectively based on the statistics of the offline dataset and designing improved kernel functions, can be proposed based...\"}"}
{"id": "3AuoStfUIH", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2. Average rank of different offline MOO methods on each type of task in Off-MOO-Bench, where the best and runner-up ranks are bolded and underlined, respectively. Note that $D_{(\\\\text{best})}$ denotes the best set in the training dataset, and the last column reports the average rank of each method on all the tasks.\\n\\n| Methods | Synthetic MO-NAS | MORL | MOCO | Sci-Design | RE | Average Rank |\\n|---------|-----------------|------|------|------------|----|--------------|\\n|         | 12.17 \u00b1 0.27    | 12.11 \u00b1 0.05 | 9.00 \u00b1 0.50 | 2.00 \u00b1 0.14 | 8.38 \u00b1 0.38 | 13.13 \u00b1 0.07 |\\n| $D_{(\\\\text{best})}$ | 10.03 \u00b1 0.07    |      |      |            |    |              |\\n| End-to-End | 6.91 \u00b1 0.03    | 8.37 \u00b1 0.05 | 7.50 \u00b1 2.00 | 6.75 \u00b1 0.46 | 6.75 \u00b1 1.12 | 7.50 \u00b1 0.57 |\\n| End-to-End + GradNorm | 8.25 \u00b1 0.56    | 7.71 \u00b1 0.08 | 4.50 \u00b1 1.00 | 7.61 \u00b1 0.18 | 8.62 \u00b1 0.50 | 10.53 \u00b1 0.07 |\\n| End-to-End + PcGrad | 7.88 \u00b1 0.06    | 7.18 \u00b1 0.39 | 10.50 \u00b1 1.50 | 6.07 \u00b1 0.64 | 8.69 \u00b1 2.69 | 8.23 \u00b1 0.17 |\\n| Multi-Head | 6.38 \u00b1 0.50    | 5.37 \u00b1 0.37 | 6.25 \u00b1 2.25 | 8.29 \u00b1 0.21 | 9.19 \u00b1 0.44 | 8.33 \u00b1 0.40 |\\n| Multi-Head + GradNorm | 7.78 \u00b1 0.53    | 10.20 \u00b1 0.04 | 11.00 \u00b1 3.00 | 9.98 \u00b1 0.30 | 9.06 \u00b1 1.19 | 10.63 \u00b1 0.17 |\\n| Multi-Head + PcGrad | 8.61 \u00b1 0.14    | 6.92 \u00b1 0.55 | 10.50 \u00b1 3.50 | 8.21 \u00b1 0.36 | 9.38 \u00b1 0.50 | 8.50 \u00b1 0.17 |\\n| Multiple Models | 4.05 \u00b1 0.11    | 4.93 \u00b1 0.28 | 9.75 \u00b1 0.75 | 6.34 \u00b1 0.27 | 5.62 \u00b1 0.75 | 4.50 \u00b1 0.10 |\\n| Multiple Models + COMs | 9.81 \u00b1 0.31    | 5.92 \u00b1 0.34 | 7.00 \u00b1 2.00 | 6.36 \u00b1 0.50 | 8.38 \u00b1 2.00 | 10.50 \u00b1 0.50 |\\n| Multiple Models + RoMA | 8.95 \u00b1 0.05    | 5.00 \u00b1 0.00 | 4.75 \u00b1 2.25 | 8.14 \u00b1 0.21 | 8.00 \u00b1 1.38 | 6.30 \u00b1 0.10 |\\n| Multiple Models + IOM | 6.11 \u00b1 0.36    | 4.34 \u00b1 0.34 | 3.75 \u00b1 2.75 | 4.25 \u00b1 0.04 | 7.19 \u00b1 0.44 | 3.23 \u00b1 0.03 |\\n| Multiple Models + ICT | 9.11 \u00b1 0.27    | 11.92 \u00b1 0.29 | 4.75 \u00b1 0.25 | 9.89 \u00b1 0.46 | 8.62 \u00b1 0.75 | 8.43 \u00b1 0.30 |\\n| Multiple Models + Tri-Mentoring | 7.83 \u00b1 0.05 | 11.37 \u00b1 0.47 | 5.25 \u00b1 2.75 | 9.50 \u00b1 0.00 | 9.38 \u00b1 1.00 | 6.73 \u00b1 0.20 |\\n| MOBO | 9.09 \u00b1 0.47    | 7.18 \u00b1 0.55 | 10.50 \u00b1 0.00 | 13.69 \u00b1 0.08 | 5.44 \u00b1 0.56 | 6.11 \u00b1 0.29 |\\n| MOBO-ParEGO | 10.27 \u00b1 0.23   | 11.47 \u00b1 0.32 | N/A | 13.62 \u00b1 0.04 | 9.44 \u00b1 0.44 | 12.71 \u00b1 0.33 |\\n| MOBO-JES | 12.48 \u00b1 0.05   | 16.00 \u00b1 0.00 | N/A | 3.00 \u00b1 0.00 | 7.50 \u00b1 6.50 | 8.04 \u00b1 0.37 |\\n\\nOn our benchmark, which represents an interesting direction for future research. We can also find that no single method demonstrates a significant advantage, and even the best-performing method only has an average rank of 4.61. These findings indicate that there is still an ongoing challenge to further enhance the effectiveness of offline MOO.\\n\\n6.3. Additional Results\\n\\nIn this section, we mainly aim to answer the question: What matters to the performance of offline MOO methods? Other results, including the analysis of data pruning, and the analysis on the influence of number of initial points of MOBO and the search algorithms, are provided in Appendix C due to space limitation.\\n\\nA key challenge of offline MOO is that an inaccurate surrogate model will destroy the final performance. The output of offline MOO is a set of solutions that are non-dominated to each other. If the surrogate model is inaccurate, the Pareto-dominance relationship will be largely influenced. For example, if the model wrongly predicts that one solution is very good, then the solution will dominate all the other solutions, resulting in only few solutions in the final solution set and an extremely low HV value. In our experiments, we have found that the main reason of inaccurate surrogate model lies in the poor performance of learning those solutions with better objective values, i.e., elites. To address this issue, we use data pruning to remove the solutions with worse objective values, allowing the model to focus more on learning from good regions and then obtaining a more accurate model. This will lead to a better final performance, as shown in Figure 2. The left and right columns denote the Multi-Head model without and with data pruning on the task of RE21, respectively. The upper-row shows the search process in the objective space of the surrogate model (i.e., proxy objective space), and the bottom-row shows their mapping in the real oracle objective space. We can observe that the model without data pruning has a phenomenon we discussed before, i.e., there are only two solutions in the final solution set. The model with data pruning performs much better, but still exhibits a certain degree of over-estimation which is also quite common in offline SOO (Trabucco et al., 2021). Thus, finding ways to mitigate such phenomenon is an important future direction in offline MOO. Detailed experiments and discussions about model collapse and data pruning are provided in Appendix C.1.\\n\\nLearning curves. Based on the above analysis, we have found that the prediction quality of elites has a significant impact on the final performance. To verify this, we compare the vanilla Multi-Head model with the Multi-Head model with GradNorm on two tasks, namely DTLZ1 (from synthetic function) and MO-NAS. Figure 3 shows the changes of the elites loss during the training phase and the visualization of the final solution set in the objective space. It can be clearly observed from the upper subfigures that GradNorm achieves smaller elites loss than vanilla Multi-Head. As a result, the solution set obtained by GradNorm has a generally better distribution, as shown in the bottom subfigures, and also has a better HV value.\\n\\n7. Discussion\\n\\nConclusion. In this paper, we emphasize the significance of offline MOO and provide the first benchmark that encompasses a range of crucial offline MOO tasks, from synthetic functions to real-world applications. Additionally, we introduce a framework of offline MOO methods.\"}"}
{"id": "3AuoStfUIH", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We will incorporate more analysis (e.g., the influence of Future works of offline MOO.) into our benchmark. offline SOO algorithms (e.g., LEO (Yu et al., 2024), and MO-GFlowNets (Jain et al., 2023)), and more advanced Pareto set learning (Lin et al., 2022; Zhang et al., 2023) manding tasks (e.g., DNA sequence designs and industrial reference points (Ishibuchi et al., 2018; 2022)), more de-\\nments validate the efficacy of these methods. In the future, and analyze the different components. Extensive experi-\\nizations of the final solution set (bottom), for Vanilla Multi-head search algorithm.\\n\\nElites loss changes (upper) and objective space visual-\\n1\\n2\\n\\nObjective space visualization of Multi-Head model with-\\\\n\\nWycoff, 2022). Our experimental results indicate that\\n\\nSome application scenarios\\n\\n1. Constrained optimization.\\n2. Noisy optimization.\\n3. Few-shot optimization.\\n\\nMany real-world MOO\\n\\ntions to adapt the surrogate model is indeed a\\n\\ndirectly discards solutions that do not satisfy the con-\\n\\nMany real-world MOO\\n\\nIn the best value of the training set on MOCO. Explor-\\n\\non large-scale problems, e.g., no method surpasses\\n\\nThe\\n\\nhigh-dimensionality of the search space is a com-\\n\\nsurrogate models.\\n\\nfor offline MOO, especially in constructing accurate\\n\\nproblems are either continuous or discrete. However, in\\n\\nMost search spaces of the current\\n\\nproblems.\\n\\nThe\\n\\nmon challenge of black-box optimization (Binois &\\n\\nThe\"}"}
{"id": "3AuoStfUIH", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgements\\n\\nThe authors want to thank the anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Science and Technology Major Project (2022ZD0116600) and National Science Foundation of China (62276124).\\n\\nReferences\\n\\nAfshari, H., Hare, W., and Tesfamariam, S. Constrained multi-objective optimization algorithms: Review and comparison with application in reinforced concrete structures. Applied Soft Computing, 83:105631, 2019.\\n\\nArango, S. P., Jomaa, H. S., Wistuba, M., and Grabocka, J. HPO-B: A large-scale reproducible benchmark for black-box HPO based on OpenML. In Proceedings of 35th Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2021.\\n\\nB\u00e4ck, T. Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms. Oxford University Press., 1996.\\n\\nBalandat, M., Karrer, B., Jiang, D. R., Daulton, S., Letham, B., Wilson, A. G., and Bakshy, E. BoTorch: A Framework for efficient Monte-Carlo Bayesian optimization. In Advances in Neural Information Processing Systems 33 (NeurIPS), Virtual, 2020.\\n\\nBian, C., Zhou, Y., Li, M., and Qian, C. Stochastic population update can provably be helpful in multi-objective evolutionary algorithms. In Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI), pp. 5513\u20135521, Macao, SAR, China, 2023.\\n\\nBinois, M. and Wycoff, N. A survey on high-dimensional Gaussian process modeling with application to Bayesian optimization. ACM Transactions on Evolutionary Learning and Optimization, 2(2):1\u201326, 2022.\\n\\nBlank, J. and Deb, K. pymoo: Multi-objective optimization in Python. IEEE Access, 8:89497\u201389509, 2020.\\n\\nBosman, P. A. N. and Thierens, D. The balance between proximity and diversity in multiobjective evolutionary algorithms. IEEE Transactions on Evolutionary Computation, 7(2):174\u2013188, 2003.\\n\\nByrd, R. H., Lu, P., Nocedal, J., and Zhu, C. A limited memory algorithm for bound constrained optimization. SIAM Journal on Scientific Computing, 16(5):1190\u20131208, 1995.\\n\\nCai, H., Gan, C., Wang, T., Zhang, Z., and Han, S. Once-for-all: Train one network and specialize it for efficient deployment. arXiv:1908.09791, 2019.\\n\\nChemingui, Y., Deshwal, A., Hoang, T. N., and Doppa, J. R. Offline model-based optimization via policy-guided gradient search. In Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI), pp. 11230\u201311239, Vancouver, Canada, 2024.\\n\\nChen, C., Zhang, Y., Fu, J., Liu, X. S., and Coates, M. Bidirectional learning for offline infinite-width model-based optimization. In Advances in Neural Information Processing Systems 35 (NeurIPS), New Orleans, LA, 2022.\\n\\nChen, C., Beckham, C., Liu, Z., Liu, X., and Pal, C. Parallel-mentoring for offline model-based optimization. In Advances in Neural Information Processing Systems 36 (NeurIPS), New Orleans, LA, 2023a.\\n\\nChen, J., Zhang, Z., Cao, Z., Wu, Y., Ma, Y., Ye, T., and Wang, J. Neural multi-objective combinatorial optimization with diversity enhancement. In Advances in Neural Information Processing Systems 36 (NeurIPS), pp. 39176\u201339188, New Orleans, LA, 2023b.\\n\\nChen, M., Peng, H., Fu, J., and Ling, H. Autoformer: Searching transformers for visual recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 12270\u201312280, Virtual, 2021.\\n\\nChen, T. and Li, M. The weights can be harmful: Pareto search versus weighted search in multi-objective search-based software engineering. ACM Transactions on Software Engineering and Methodology, 32(1):5:1\u20135:40, 2023.\\n\\nChen, Z., Badrinarayanan, V., Lee, C., and Rabinovich, A. GradNorm: Gradient normalization for adaptive loss balancing in deep multitask networks. In Proceedings of the 35th International Conference on Machine Learning (ICML), pp. 793\u2013802, Stockholm, Sweden, 2018.\\n\\nCoello, C. A. C., Lamont, G. B., and Veldhuizen, D. A. V. Evolutionary Algorithms for Solving Multi-objective Problems. Springer, 2007.\\n\\nDara, S., Dhamercherla, S., Jadav, S. S., Babu, C. M., and Ahsan, M. J. Machine learning in drug discovery: A review. Artificial Intelligence Review, 55(3):1947\u20131999, 2022.\\n\\nDaulton, S., Balandat, M., and Bakshy, E. Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. Advances in Neural Information Processing Systems 33 (NeurIPS), pp. 9851\u20139864, 2020.\\n\\nDaulton, S., Balandat, M., and Bakshy, E. Parallel Bayesian optimization of multiple noisy objectives with expected hypervolume improvement. In Advances in Neural Information Processing Systems 34 (NeurIPS), pp. 2187\u20132200, Virtual, 2021.\"}"}
{"id": "3AuoStfUIH", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Methods                      | D (best) | 1.95  | 2.65  | 1.04  | 1.84  | 2.03  | 3.95  | 3.81  | 2.12  | 2.26  | 3.05  | 3.75  | 4.06  | 3.70  | N/A   | N/A   | 1.05  | 3.71  | 1.06  | 4.42  | 1.72  | 4.21  | 2.16  |\\n|-----------------------------|----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\\n\\n| Methods                      | Hypervolume | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-M\u0435\u043d\u0442oring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri-Mentoring | Multiple Models + ICT | Multi-Head + GradNorm | End-to-End + GradNorm | Multiple Models + IOM | Multiple Models + COMs | Multi-Head | End-to-End | Methods | MOBO-JES | MOBO | Multiple Models + Tri"}
{"id": "3AuoStfUIH", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 27. Hypervolume results for RE with 32 solutions and 100th percentile evaluations. For each task, algorithms within one standard deviation of having the highest performance are bolded.\\n\\n| Methods                  | RE21  | RE22  | RE23  | RE24  | RE25  | RE31  | RE32  | RE33  | RE34  | RE35  | RE36  | RE37  | RE41  | RE42  | RE61  | End-to-End  | End-to-End + GradNorm | End-to-End + PcGrad | Multiple Models  | Multiple Models + COMs | Multiple Models + RoMA | Multiple Models + IOM | Multiple Models + ICT | Multiple Models + Tri-Mentoring |\\n|--------------------------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|----------------------|--------------------------|----------------------|----------------------|------------------------|------------------------|----------------------|-----------------------------|\\n|                          | 4.23  | 4.78  | 4.75  | 4.59  | 4.79  | 10.23 | 10.53 | 10.59 | 48.06 | 10.96 | 7.57 | 4.72 | 36.17 | 12.53 | 135.87 |                      |                        |                      |                      |                        |                        |                      |                             |\\n| D (best)                 | 4.42  | \u00b10.00 | 4.84  | \u00b10.00 | 4.84  | \u00b10.00 | 4.84  | \u00b10.00 | 4.38  | \u00b10.00 | 4.82  | \u00b10.02 | 10.58 | \u00b10.03 | 10.56 | \u00b10.08 | 10.68  | \u00b10.00 | 52.82  | \u00b10.05 | 11.61  | \u00b10.01 | 8.24  | \u00b10.00 | 6.20  | \u00b10.00 | 42.53  | \u00b10.05 | 17.09  | \u00b12.14 | 140.13 | \u00b11.42 |                      |\\n| End-to-End               | 4.81  | \u00b10.01 | 4.84  | \u00b10.00 | 2.64  | \u00b10.00 | 4.38  | \u00b10.00 | 4.84  | \u00b10.00 | 10.65 | \u00b10.00 | 10.63 | \u00b10.00 | 9.90  | \u00b10.00 | 51.98  | \u00b10.63  | 11.51  | \u00b10.00 | 8.63  | \u00b10.71 | 6.11  | \u00b10.00 | 39.21  | \u00b10.12 | 13.46  | \u00b10.00 | 140.24 | \u00b10.25 |                      |\\n| End-to-End + GradNorm    | 4.86  | \u00b10.01 | 4.84  | \u00b10.00 | 4.84  | \u00b10.00 | 4.40  | \u00b10.00 | 4.35  | \u00b10.00 | 10.65 | \u00b10.00 | 10.41 | \u00b10.07 | 52.78 | \u00b10.04 | 11.66  | \u00b10.00 | 9.76  | \u00b10.11 | 5.52  | \u00b10.00 | 41.64  | \u00b10.31 | 15.92  | \u00b11.75 | 139.60 | \u00b10.28 |                      |\\n| End-to-End + PcGrad      | 4.61  | \u00b10.13 | 4.84  | \u00b10.00 | 4.70  | \u00b10.04 | 4.78  | \u00b10.00 | 4.35  | \u00b10.00 | 10.65 | \u00b10.00 | 10.64 | \u00b10.00 | 10.65 | \u00b10.01 | 52.63  | \u00b10.22  | 11.70  | \u00b10.00 | 6.76  | \u00b10.00 | 5.72  | \u00b10.00 | 42.45  | \u00b10.40  | 19.30  | \u00b10.32 | 141.50 | \u00b10.03 |                      |\\n| MOBO                     | 4.49  | \u00b10.07 | 4.84  | \u00b10.00 | 4.84  | \u00b10.00 | 4.81  | \u00b10.01 | 4.84  | \u00b10.00 | 9.50  | \u00b10.00 | 10.63 | \u00b10.00 | 10.69 | \u00b10.00 | 51.79  | \u00b10.00  | 11.61  | \u00b10.02 | 0.00  | \u00b10.00 | 6.50  | \u00b10.00 | 51.83  | \u00b10.12 | 13.77  | \u00b10.13 | N/A |                     |\\n| MOBO-q ParEGO            | 4.67  | \u00b10.06 | 4.84  | \u00b10.00 | 4.84  | \u00b10.00 | 4.82  | \u00b10.00 | 4.84  | \u00b10.00 | 10.64 | \u00b10.01 | 10.18 | \u00b10.05 | 10.61 | \u00b10.00 | 47.81  | \u00b11.93  | 11.60  | \u00b10.00 | 10.19 | \u00b10.23 | 5.81  | \u00b10.11 | N/A | N/A |                     |\\n| MOBO-JES                 | 4.85  | \u00b10.03 | 4.84  | \u00b10.00 | 4.83  | \u00b10.00 | 4.82  | \u00b10.00 | 4.84  | \u00b10.00 | 10.28 | \u00b10.00 | 10.65 | \u00b10.00 | 10.61 | \u00b10.03 | 50.30  | \u00b10.00  | 11.59  | \u00b10.02 | 9.43  | \u00b10.10 | 6.20  | \u00b10.03 | N/A | N/A | N/A |                     |\"}"}
{"id": "3AuoStfUIH", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Offline Multi-Objective Optimization\\n\\nFigure 5. Visualization of datasets in Off-MOO-Bench. Blue points represent the offline dataset, and red points represent the 256 best-non-dominated solutions over the dataset. Note that some red dots are not visible in the graph due to the plot perspective.\"}"}
{"id": "3AuoStfUIH", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 6. represent the reference points (i.e., nadir points) that are set by us manually.\"}"}
