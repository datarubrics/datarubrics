{"id": "yj8h567Ia7", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nYewen Pu\\nSaujas Vaduguru\\nPriyan Vaithilingam\\nElena Glassman\\nDaniel Fried\\n\\nAbstract\\n\\nThe usage of Rational Speech Acts (RSA) framework has been successful in building pragmatic program synthesizers that return programs which, in addition to being logically consistent with user-generated examples, account for the fact that a user chooses their examples informatively. We present a general method of amortizing the slow, exact RSA synthesizer. Our method first query the exact RSA synthesizer to compile a communication dataset. The dataset contains a number of example-dependent rankings of subsets of programs. It then distills a single global ranking of all programs as an approximation to every ranking in the dataset. This global ranking is then used at inference time to rank multiple logically consistent candidate programs generated from a fast, non-pragmatic synthesizer. Experiments on two program synthesis domains using our ranking method resulted in orders of magnitudes of speed ups compared to the exact RSA synthesizer, while being more accurate than a non-pragmatic synthesizer when communicating with humans. Finally, we prove that in the special case of synthesis from a single example, this approximation is exact.\\n\\n1. Introduction\\n\\nFor intelligent systems to be accessible to end users, it is important that they can infer the user's intent under ambiguity. Imagine a person asking an AI assistant to generate a regular expression that matches the string 123-7890. It would be unhelpful if the AI assistant simply returned the regular expression \\\\( \\\\Sigma^* \\\\) \u2013 the expression that matches all strings \u2013 although it is technically correct. The rational speech acts model (RSA) of pragmatics (Frank & Goodman, 2012) gives an algorithm for resolving ambiguities by modeling the user as a speaker that chooses informative examples for \\\\( * \\\\).\\n\\nEqual contribution\\n\\nAutodesk AI Research\\nCarnegie Mellon University\\nHarvard SEAS. Correspondence to: Yewen Pu <yewen.pu@autodesk.com>.\\n\\nProceedings of the 41st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s).\\n\\nFigure 1. (left) Directly using the exact RSA algorithm in a pragmatic synthesizer \\\\( L_1 \\\\) is slow. (right) Our approach uses RSA to generate a simulated communication dataset between the informative speaker \\\\( S_1 \\\\) and the pragmatic synthesizer \\\\( L_1 \\\\), and stores the responses of \\\\( L_1 \\\\) as example-dependent rankings of subsets of programs. We then distill the dataset into a single example-agnostic global ranking of all programs \\\\( \\\\sigma[w] \\\\). This global ranking is then used to build a fast pragmatic synthesizer \\\\( L_{\\\\sigma} \\\\), by using the examples only to filter out consistent programs, then using the global ranking to sort them. This amortized synthesizer performs similar selections of programs as an exact RSA synthesizer, while being orders of magnitudes faster.\\n\\nThe RSA algorithm marginalizes across all possible examples (e.g. all strings) and programs (e.g. all regexes) multiple times. This makes it difficult to scale RSA to large...\"}"}
{"id": "yj8h567Ia7", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\ndomains, where users expect the system to complete its inference in real-time. Prior works in scaling up RSA computation (Monroe et al., 2017; Andreas & Klein, 2016) have largely focused on sampling and re-ranking, curbing RSA's computation to a small subset of programs and examples. In this work, we show a simple yet effective way of amortizing RSA via a single global ranking of all programs. Rather than using RSA directly at inference time, our method uses it to generate training data in the form example-dependent rankings of subsets of programs. We then distill a global ranking from the training data, amortizing the computation of RSA (Figure 1). At inference time, a fast, non-pragmatic synthesizer is used to propose multiple logically consistent programs, and the global ranking is used to quickly rank them, resulting in a pragmatic yet efficient synthesizer.\\n\\nThis work makes the following contributions.\\n\\n1. We describe a general method of amortizing the RSA algorithm (considered in Cohn-Gordon et al. (2018b); Pu et al. (2020); Vaithilingam et al. (2023)) applicable to any pragmatic program synthesis domains.\\n\\n2. Using global ranking, we scale the model proposed by Vaithilingam et al. (2023) to a larger domain while still allowing for real-time interaction. We conduct a small user study validating that end-users are more accurate communicating with a ranking based program synthesizer compared to a non-pragmatic one (+27%, +41% relative).\\n\\n3. We conduct simulated user studies by replaying the human interactive synthesis data collected from Pu et al. (2020) and Vaithilingam et al. (2023). We confirm that our ranking-based synthesizer retains the communicative accuracy of RSA (55%, 92% respectively), while running orders of magnitudes (over 100 times) faster.\\n\\n4. We prove that in the special case of synthesis from just a single example, RSA single, a setting studied in the original RSA literature (Goodman & Frank, 2016; Vogel et al., 2013; Monroe & Potts, 2015; Smith et al., 2013), the approximation using a global ranking is exact.\\n\\n2. Background on Pragmatic Synthesis\\n\\nIn this section, we provide background on a reference game framework of program synthesis, which affords building a pragmatic synthesizer that can infer a user's intended program from few examples (Pu et al., 2020). We illustrate this framework using a toy example from a small version of the regular expression domain of this work.\\n\\n2.1. Synthesis as a Reference Game\\n\\nConsider the problem where a user gives example strings to a synthesis system, and asks it to find a matching regular expression. This process can be modeled as a reference game (Lewis, 1979), where a speaker (the user) chooses a few utterances (strings) to give to the listener (the synthesizer), with the intention that the listener can infer the correct hypothesis (regular expression). This reference game is characterized by the lexicon $M$, a boolean matrix of 1s and 0s (Figure 2). In $M$, each row corresponds to an utterance/example and each column corresponds to a hypothesis/program, and 1s indicating consistency of its corresponding utterance and a hypothesis: whether the program's output (e.g. deciding whether a regular expression matches a string) is consistent with the example (e.g. the string). As we can see, a given utterance (such as $001$) may be consistent with multiple hypotheses ($0^+{1}$, $0^+{0}^2$, $1^+{0}$, and $0^+1^*$).\\n\\n2.2. A Literal Program Synthesizer\\n\\nHow might we build a system that takes an utterance (say $01$) and produces the intended hypothesis $0^+1$? As $01$ is consistent with multiple hypotheses ($0^+1$ and $0^+1^*$), a naive strategy is to treat all consistent hypotheses as equally likely, scaled by a prior distribution of hypotheses $P(w)$:\\n\\n$$L_0(w | u) \\\\propto P(w) M[u, w]$$\\n\\n$$L_0(w | u) \\\\propto P(w) M[u, w] P(w') M[u, w']$$\\n\\nA synthesizer built this way is a literal listener $L_0$ (Bergen et al., 2016). Assuming the prior $P(w)$ is uniform over programs, we can construct it by normalizing the rows of the matrix $M$, resulting in a probability distribution over hypotheses $W$ given utterances $u$ (Figure 2). As we can see, given the utterance $01$, this listener predicts an equal probability of $0^+1$ and $0^+1^*$ being the intended program.\\n\\n2.3. A Pragmatic Synthesizer from a Single Example\\n\\nA key insight to improving on the literal synthesizer is to consider that a user is cooperatively choosing an utterance to be informative about the intended program to the synthesizer. The Rational Speech Acts (RSA) framework models this...\"}"}
{"id": "yj8h567Ia7", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nA. Code and Assets\\n\\nPlease find all simulation, replay results at this repository https://github.com/evanthebouncy/pragmatic\\n\\nB. Simulated Studies\\n\\nB.1. Ranking Always Exists\\n\\nWe empirically validate that in the case of single utterances, a ranking can always be found. See simulation/single utter/exp orders.py\\n\\nB.2. Stability of Ranks Across RSA Iterations\\n\\nWe've shown that for every $L_0, L_1, \\\\ldots$, there exists a corresponding global, utterance agnostic ranking $\\\\sigma_{L_0}, \\\\sigma_{L_1}, \\\\ldots$. We now explore the relationship between these rankings as a function of the RSA iteration $i$. Specifically, how stable is the relative ranks of $w$ and $w'$ once it is formed?\\n\\nStable Order\\n\\nA pair-wise order between $w$ and $w'$ is stable from iteration $i$ onward if:\\n\\n$$\\\\text{stable}(i, w \\\\succ w') \\\\iff \\\\forall j \\\\in i, i+1, \\\\ldots, \\\\infty, \\\\sigma_{L_j}[w] \\\\succ \\\\sigma_{L_j}[w']$$\\n\\nWhich means the relative ranking of $\\\\sigma_{L_i}[w] \\\\succ \\\\sigma_{L_i}[w']$ holds true for every subsequent iterations until $\\\\sigma_{L_\\\\infty}$. Let the minimal-index of a stable pair-wise ordering be the first iteration $i$ such that $w \\\\succ w'$ becomes stable:\\n\\n$$i_{\\\\min}(w \\\\succ w') = \\\\arg\\\\min_j \\\\text{stable}(j, w \\\\succ w') \\\\quad (6)$$\\n\\nAs $\\\\sigma_{L_1}$ is the first time any ranking can exist ($L_0$ is a uniform distribution over valid hypotheses, i.e. no rankings), we explore the following: For a lexicon $M$, what fraction of stable orderings have a minimal-index of 1?\\n\\n$$\\\\text{frac-stable}_{L_1}(M) = \\\\frac{|\\\\{w \\\\succ w' | i_{\\\\min}(w \\\\succ w') = 1\\\\}|}{|\\\\{w \\\\succ w' | \\\\exists i. \\\\text{stable}(i, w \\\\succ w')\\\\}|} \\\\quad (7)$$\\n\\nSimulation\\n\\nWe measure $\\\\text{stable}_{L_1}(M)$ on a population of sampled random boolean lexicons. We sample square lexicons of size $\\\\text{lexicon size} \\\\in 2 \\\\times 2 \\\\ldots 100 \\\\times 100$. Each lexicon is sampled with $P_{\\\\text{true}} \\\\in \\\\{0.1, 0.2, 0.5\\\\}$, where larger value of $P_{\\\\text{true}}$ makes the lexicon have more 1s. We make sure each sampled lexicon is valid in the following sense: (1) all rows are unique \u2013 every utterance must communicate a unique subset of valid hypotheses (2) all columns are unique \u2013 every hypothesis has a unique set of utterances that can refer to it. For every combination of $(P_{\\\\text{true}}, \\\\text{lexicon size})$ we randomly sample 100 lexicons. As it is infeasible to run RSA until iteration $\\\\infty$, we run RSA for 100 iterations for each lexicon (i.e. $L_{100} \\\\approx L_{\\\\infty}$). We measure $\\\\text{stable}_{L_1}$ for each sampled lexicon. The result is shown in 9. As we can see, of all the stable pair-wise orderings, a large fraction ($> 0.8$) are formed during $\\\\sigma_{L_1}$, this is increasingly true as we (1) increase $P_{\\\\text{true}}$, making the boolean lexicons having more number of 1s \u2013 i.e. the lexicon is more ambiguous for a literal speaker and listener and (2) increase $\\\\text{lexicon size}$. We suspect this is due to faster \\\"mixing time\\\" of the RSA algorithm under these conditions, but this is just a guess.\\n\\nTakeaway\\n\\nThis study may provide an alternative explanation as to why humans do not perform RSA for more than few iterations (Franke & Degen, 2016). In addition to it being computationally expensive, it is also not necessary as the majority of top-$k$ orderings becomes available at $\\\\sigma_{L_1}$, and remains stable for all subsequent iterations of the RSA algorithm. In another word, $L_{\\\\text{top} - k_{1}} \\\\approx L_{\\\\text{top} - k_{i}>1}$. Code in simulation/single utter/C.\\n\\nAnimals domain\\n\\nIn the Animals domain, a program is a pattern on a grid formed from a set of objects. These objects may be a colourless pebble, or a chicken or pig that may be red, green or blue. An utterance reveals one square on the grid, and the speaker has to communicate the pattern by choosing which square to reveal. The pattern is formed according to rules specified in the domain-specific language in Figure 10. Examples of programs shown in Figure 11. The description of the domain-specific language and the examples are due to Vaduguru et al. (2022).\"}"}
{"id": "yj8h567Ia7", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nFigure 9. Fraction of stable orders that were formed in $\\\\sigma_{L_1}$ as a function of increasing lexicon size. Points are raw samples ($n=100$ per lexicon size and $P_{true}$), bars are 95% bootstrapped CI ($n_{boot} = 1000$). Overall, increasing $P_{true}$ and lexicon size increases the fraction of stable orders that were formed in $\\\\sigma_{L_1}$.\\n\\nD. Human study interface\\n\\nThe interface for the human study on regular expression programs is shown in Figure 12.\\n\\nE. Neural model\\n\\nThe neural scoring model maps from the program to a real number. The program is input as vector encoding the productions of the grammar that produce the program. That is, we construct a vector of the index of the production that is used to expand each non-terminal in the DSL grammar. We then convert this vector to a one-hot matrix. There are 12 rules, with any single rule having at most 7 possible expansions resulting in an input vector of dimension $12 \\\\times 7 = 84$. The input is then passed through 3 hidden layers of size 128, each of which has as ReLU activation, and then mapped to a scalar output with a linear layer.\\n\\nThe model is trained on a dataset of rankings of the form $D = (w, u, \\\\tilde{\\\\sigma}_u)$. For each program $w$, we sample a pair of programs from the inferred ranking $\\\\tilde{\\\\sigma}_u$ and use this pair to compute the loss function for this sample. We train the model for a maximum of 20 epochs, where one epoch of training corresponds to presenting the model with every element in $D$ once.\\n\\nWe train with a batch size of 32 using the Adam optimizer. We use a validation set generated similarly to $D$ (on a disjoint set of programs) to perform validation, choosing the model that results in the highest synthesis accuracy on this validation dataset with synthetically produced examples (from the $S_1$ speaker model).\\n\\nWe train an ensemble of 10 models. For each model, we normalize the scores to be of zero mean and unit variance based on the empirical mean and standard deviation computed on the validation set. We then average the scores for the 10 models at inference time.\"}"}
{"id": "yj8h567Ia7", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nProgram \\\\(\\\\langle\\\\text{Shape, Colour}\\\\rangle\\\\)\\n\\n\\\\text{Shape} \\\\rightarrow \\\\text{Box}(\\\\text{Left, Right, Top, Bottom, Thickness, Outside, Inside})\\n\\n\\\\text{Left} \\\\rightarrow 0 | 1 | 2 | 3 | ... | 6\\n\\n\\\\text{Right} \\\\rightarrow 0 | 1 | 2 | 3 | ... | 6\\n\\n\\\\text{Top} \\\\rightarrow 0 | 1 | 2 | 3 | ... | 6\\n\\n\\\\text{Bottom} \\\\rightarrow 0 | 1 | 2 | 3 | ... | 6\\n\\n\\\\text{Thickness} \\\\rightarrow 1 | 2 | 3\\n\\n\\\\text{O} \\\\rightarrow \\\\text{chicken} | \\\\text{pig}\\n\\n\\\\text{I} \\\\rightarrow \\\\text{chicken} | \\\\text{pig} | \\\\text{pebble}\\n\\n\\\\text{Colour} \\\\rightarrow [\\\\text{red, green, blue}]\\n\\n\\\\text{A}\\\\text{1} \\\\rightarrow x | y | x + y\\n\\n\\\\text{A}\\\\text{2} \\\\rightarrow \\\\lambda z : 0 | \\\\lambda z : 1 | \\\\lambda z : 2 | \\\\lambda z : z \\\\% 2 | \\\\lambda z : z \\\\% 2 + 1 | \\\\lambda z : 2 * (z \\\\% 2)\\n\\nFigure 10. Grammar of the DSL\\n\\n(a) \\n(b)\\n\\nFigure 11. Two patterns in our layout domain and their corresponding programs, represented as a sequence of production rules: \\\\(\\\\text{Program}, \\\\text{Shape}, \\\\text{Left}, \\\\text{Right}, \\\\text{Top}, \\\\text{Bottom}, \\\\text{Thickness}, \\\\text{O}, \\\\text{I}, \\\\text{Colour}, \\\\text{A}\\\\text{1}, \\\\text{A}\\\\text{2}\\\\). The symbol \\\\(\\\\cdot\\\\) indicates rules which only have 1 choice of expansion (Program, Shape, and Colour). The rules where these two programs differ are marked with a box.\"}"}
{"id": "yj8h567Ia7", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nFigure 12. User interface for the regex domain\"}"}
{"id": "yj8h567Ia7", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nDomain 1: Animals\\nPu et al. (2020) used a domain of grid patterns generated by an underlying domain-specific language (see Appendix for the grammar of the DSL and semantics). The space contains 17,976 semantically distinct programs and 343 possible examples, where a user uses a sequence of multiple examples to communicate a target program. They conducted a study with 48 human subjects, collecting data for 10 programs (10 distinct grid patterns). The data includes interactions between humans and both a literal synthesizer \\\\( H_0 - L_0 \\\\) and a pragmatic synthesizer \\\\( H_1 - L_1 \\\\). In total, there are 254 interactions from \\\\( H_0 - L_0 \\\\) and 291 interactions from \\\\( H_1 - L_1 \\\\), where each interaction consists of multiple turns until either the target program is successfully communicated or the user gives up.\\n\\nDomain 2: Regular expressions\\nVaithilingam et al. (2023) studied the usability of pragmatic program synthesizers in the domain of binary regular expressions. The space contains 350 distinct regular expressions. A sample of 2000 strings was used to compute the \\\\( S_1 \\\\) and \\\\( L_1 \\\\) distributions. Their study included 30 participants interacting with both \\\\( L_0 \\\\) and \\\\( L_1 \\\\) models. In total, there are 60 interactions from \\\\( H_0 - L_0 \\\\) and 60 interactions from \\\\( H_1 - L_1 \\\\), where each consisting of multiple turns.\\n\\nResult: rank-based synthesizers are comparable to \\\\( L_1 \\\\) in terms of communication accuracy with simulated users (Q1) The replay study results are shown in Figure 6 (animals domain) and Figure 7 (regex domain). For either domain, there is a rank-based synthesizer that vastly outperforms the literal synthesizer \\\\( L_0 \\\\), and is close to performance to the pragmatic synthesizer \\\\( L_1 \\\\) derived from RSA.\\n\\nThe existence of a rank-based synthesizer (be it \\\\( L_{anneal} \\\\) or \\\\( L_{neural} \\\\)) that matches the performance of \\\\( L_1 \\\\) entails that there exists some ranking of programs that effectively amortizes \\\\( L_1 \\\\) for either domain. For the animals domain, \\\\( L_{neural} \\\\) is better able to discover an effective ranking, while \\\\( L_{anneal} \\\\) is more effective at discovering the ranking for the regex domain. This is likely due to the differences of the sizes of the communicative datasets for the two domains \u2014 17,976 programs for the animals domain vs 350 for the animals domain, which makes it more feasible to learn a generalizable neural scoring function for the animals domain.\\n\\nResult: rank-based synthesizers are orders of magnitudes faster than \\\\( L_1 \\\\) (Q2) For both domains, the ranking-based synthesizer is much faster than \\\\( L_1 \\\\), requiring approximately the same time as \\\\( L_0 \\\\) (Figure 8). This implies that most of the computation cost of a ranking-based synthesizer lies in coming up with consistent programs \u2014 the primary challenge of program synthesis \u2014 while the computation for ranking the top-\\\\( k \\\\) programs can be made negligible in comparison (Q2).\\n\\nIn this section, we prove a strong approximation result for a special case of RSA, RSA single, where only a single example is used to communicate. In accordance with the terminologies of Goodman & Frank (2016); Vogel et al. (2013); Monroe & Potts (2015); Smith et al. (2013) and Franke & Degen (2016), we'll use the term \\\"hypothesis\\\" instead of \\\"program\\\". We prove that a global pragmatic ranking of hypotheses must exist for any listeners \\\\( L_0, L_1, \\\\ldots \\\\) resulting from the RSA single algorithm. In other words, the rankings over consistent hypotheses in these listeners are example-agnostic.\\n\\nTheorem: For a sequence of listeners in the RSA algorithm \\\\( L_0, L_1, \\\\ldots \\\\) over a boolean-valued lexicon \\\\( M \\\\), there exists a sequence of global pragmatic rankings \\\\( \\\\sigma_{L_0}, \\\\sigma_{L_1}, \\\\ldots \\\\) such that:\\n\\n\\\\[\\n\\\\forall w, w', u. \\\\quad \\\\text{if } L_i(w|u) > 0 \\\\land L_i(w'|u) > 0,\\n\\\\]\\n\\nthen \\\\( L_i(w|u) > L_i(w'|u) \\\\iff \\\\sigma_{L_i}[w] \\\\succ \\\\sigma_{L_i}[w'] \\\\) (4)\\n\\nThis means the partial rankings produced by any \\\\( L_i \\\\) over consistent hypotheses are example-agnostic, where a global ranking preferring certain hypotheses unconditionally over others (e.g. a convention) is sufficient to explain the relative rankings of \\\\( L_i \\\\) resulting from RSA single.\\n\\nProof: Let \\\\( M \\\\) be a boolean lexicon of size \\\\( m \\\\times n \\\\). Let \\\\( r_0 = r_1 = \\\\ldots r_m \\\\) be the row-normalizing vector such that \\\\( r_j = \\\\left( \\\\sum L_0[j,:] \\\\right)^{-1} \\\\), which is to say, each element \\\\( r_j \\\\) is the normalization term for row \\\\( j \\\\) of \\\\( L_0 \\\\). Let \\\\( * \\\\leftrightarrow \\\\) denotes row-wise multiplication:\\n\\n\\\\[\\nL_0 = M * \\\\leftrightarrow r_0\\n\\\\]\\n\\nWhich is to say, starting from \\\\( M \\\\), \\\\( L_0 \\\\) can be obtained by scaling each row \\\\( j \\\\) by their respective normalization constant \\\\( r_j \\\\). Let \\\\( c_1 = c_1^1 \\\\ldots c_1^n \\\\) be the col-normalizing vector such that \\\\( c_j = \\\\left( \\\\sum L_0[:,j] \\\\right)^{-1} \\\\), which is to say, each element \\\\( c_j \\\\) is the normalization term for column \\\\( j \\\\) of \\\\( S_1 \\\\). Similarly, let \\\\( * \\\\uparrow \\\\downarrow \\\\) denotes column-wise multiplication:\\n\\n\\\\[\\nS_1 = L_0 * \\\\uparrow \\\\downarrow c_1\\n\\\\]\\n\\nComputing \\\\( L_i \\\\) under RSA amounts to applying row and column normalization alternatively multiple times:\\n\\n\\\\[\\nL_i = M * \\\\leftrightarrow r_0 * \\\\uparrow \\\\downarrow c_1 * \\\\ldots * \\\\uparrow \\\\downarrow c_{i-1} * \\\\leftrightarrow r_i\\n\\\\]\\n\\nLet \\\\( * \\\\) be element-wise multiplication, let \\\\( \\\\otimes \\\\) be outer-product, we can rearrange the terms:\\n\\n\\\\[\\nL_i = M * (r_0 \\\\ast \\\\ldots \\\\ast r_i) \\\\otimes (c_1 \\\\ast \\\\ldots \\\\ast c_{i-1})\\n\\\\]\"}"}
{"id": "yj8h567Ia7", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nHere, \\\\( r_0 \\\\ldots i = \\\\prod r_i \\\\) is a vector of size \\\\( m \\\\), and \\\\( c_1 \\\\ldots i - 1 = \\\\prod c_i \\\\) is a vector of size \\\\( n \\\\). As we can see, following the RSA algorithm, \\\\( L_i \\\\) can be decomposed into multiplication of 2 parts: the lexicon \\\\( M \\\\), and a matrix that is formed by the outer product \\\\( r_0 \\\\ldots i \\\\otimes c_1 \\\\ldots i - 1 \\\\).\\n\\nClaim:\\nThe ordered indexes of \\\\( c_1 \\\\ldots i - 1 \\\\) is the global pragmatic ranking \\\\( \\\\sigma_{L_i} \\\\):\\n\\n\\\\[\\n\\\\sigma_{L_i}[w] > \\\\sigma_{L_i}[w'] \\\\iff c_1 \\\\ldots i - 1[w] > c_1 \\\\ldots i - 1[w']\\n\\\\]\\n\\nProof:\\nWe show both sides of the \\\\( \\\\iff \\\\). Suppose that for some \\\\( w, w', u \\\\), both \\\\( L_i(w|u) > 0 \\\\) and \\\\( L_i(w'|u) > 0 \\\\), (i.e. \\\\( M[u, w] = M[u, w'] = 1 \\\\)).\\n\\n(1) Show \\\\( \\\\Rightarrow \\\\): Suppose \\\\( L_i(w|u) > L_i(w'|u) \\\\).\\n\\nWe have\\n\\n\\\\[\\nL_i(w|u) = L_i[u, w] = r_0 \\\\ldots i[u] \\\\ast c_1 \\\\ldots i - 1[w] \\\\\\\\\\nL_i(w'|u) = L_i[u, w'] = r_0 \\\\ldots i[u] \\\\ast c_1 \\\\ldots i - 1[w']\\n\\\\]\\n\\nAs \\\\( r_0 \\\\ldots i[u] \\\\) is a constant, we have\\n\\n\\\\[\\nL_i(w|u) > L_i(w'|u) \\\\Rightarrow c_1 \\\\ldots i - 1[w] > c_1 \\\\ldots i - 1[w']\\n\\\\]\\n\\n\u25a1\\n\\n(2) Show \\\\( \\\\Leftarrow \\\\): Suppose \\\\( c_1 \\\\ldots i - 1[w] > c_1 \\\\ldots i - 1[w'] \\\\).\\n\\n\\\\[\\nc_1 \\\\ldots i - 1[w] > c_1 \\\\ldots i - 1[w'] \\\\]\\n\\n\\\\[\\nM[u, w] \\\\ast r_0 \\\\ldots i[u] \\\\ast c_1 \\\\ldots i - 1[w] > M[u, w'] \\\\ast r_0 \\\\ldots i[u] \\\\ast c_1 \\\\ldots i - 1[w']\\n\\\\]\\n\\n\\\\[\\nL_i(u|w) > L_i(u|w')\\n\\\\]\\n\\n\u25a1\\n\\nThus, \\\\( c_1 \\\\ldots i - 1 \\\\) is the global ranking \\\\( \\\\sigma_{L_i} \\\\) as claimed.\\n\\nWe check the our proof using simulations on 10,000 randomly generated boolean lexicons size ranging from \\\\( 10 \\\\times 10 \\\\) to \\\\( 20 \\\\times 20 \\\\), and running a chain of 100 listeners on top. A total ordering can be found for all of them (Appendix B.1).\\n\\nWe further study the stability of these ranks as they are formed, finding that the formed rankings tend to be stable across different RSA iterations (Appendix B.2).\\n\\n7. Related Works\\n\\nScaling RSA without Global Ranking\\n\\nPrior work such as that by Monroe et al. (2017) and Andreas & Klein (2016) has largely focused on sample and re-rank as a way of scaling RSA, making the example-dependent ranking function \\\\( S_1 \\\\) more efficient at a cost of accuracy. Recent work by Key et al. (2022) and Vaduguru et al. (2024) apply the sample and re-rank approach to program synthesis, resulting in neural program synthesizers that also rank programs in an example-dependent way. Our work enables a different note that any prior over hypotheses and utterance can be similarly absorbed into these outer products terms kind of synthesis algorithm altogether \u2014 that of a distilled pragmatic ranking that ranks consistent programs agnostic to examples given. We view these works as complementary, able to efficiently produce a simulated communication dataset \\\\( D \\\\) which our approach can distill from.\\n\\nScaling RSA with Human Data\\n\\nRSA has been applied to improve the performance of language interfaces in a variety of other domains, such as image description (Andreas & Klein, 2016; Cohn-Gordon et al., 2018a;b), instruction generation and interpretation (Fried et al., 2018a;b), and grounded interaction (Fried et al., 2021; Lin et al., 2022). These works all use speaker models trained on labeled data from people. Our approach requires no human-produced data, and can be run entirely from the lexicon \\\\( M \\\\) of the synthesis problem. On the other hand, we can easily integrate human data within our approach by training similar speaker models on the collected interactive data.\\n\\nRanking Functions in Synthesis\\n\\nPrior works on resolving ambiguity in program synthesis have relied on example-agnostic ranking functions. Works such as Singh & Gulwani (2015); Polozov & Gulwani (2015) use scoring functions to penalize certain properties of programs (e.g. discouraging the use of constants), effectively inducing a global ranking over all programs; Ellis & Gulwani (2017) uses a set of hand-crafted features to learn a naturalistic ranking from data. Synthesis algorithms that use a large neural code model to sample a large number of programs (Chen et al., 2021; Li et al., 2022) implicitly rank the programs based on their naturalistic distributions in its training data. Our work is unique in that (1) the learned ranking is rooted in efficient communication rather than hand-crafted features and (2) our approach does not require human annotated data.\\n\\nOther Theoretical Works on Ranking\\n\\nRecent work by Muggleton FREng (2023) shows that in the case of single-example, the MAP estimate of the learner can be completely ranked by \\\\( \\\\text{sz}(H) + \\\\ln g(H) \\\\) an example-agnostic global ranking. Our work can be viewed as a strict generalization in the following sense: They consider the chain of recursive bayesian reasoners of the form \\\\( M \\\\rightarrow S_0 \\\\rightarrow L_1 \\\\), whereas our result applies to any alternating chains speakers and listeners of arbitrary depth. Their notion of \u201cspecificity\u201d and \u201cprogram length\u201d also has direct analogies to the normalization terms in Equation (5), except these analogies do not carry over to deeper recursive depths.\\n\\n8. Conclusion\\n\\nWe present a way of amortizing the expensive RSA algorithm by an example-agnostic global ranking. We have shown this amortization interacts well with humans when applied to two program synthesis domains. We have further proved...\"}"}
{"id": "yj8h567Ia7", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nThis amortization is exact in the case of communication with a single example. In addition of being a practical method for scaling up RSA, these findings may provide an alternative account for pragmatic behaviour in humans \u2013 one rooted in relative rankings of hypotheses (e.g. a pragmatic prior), perhaps distilled from the expensive RSA computation over time.\\n\\n8.1. Limitation and Future Directions\\n\\nThe limitation of our approach is two-fold: First, whether an optimal global ranking exists for the multi-example PBE setting; Second, whether our distillation algorithm can find this optimal ranking.\\n\\nExistence of an effective global ranking\\n\\nThe effectiveness of a global ranking is upper-bounded by the amount of cycles that exists in the communicative dataset of example-dependent rankings of subsets of programs. A cycle exists if under one ranking we have $w_a \\\\succ w_b$, and under a different one we have $w_b \\\\succ w_a$, which no single ranking can approximate exactly. Forecasting the number of cycles from the meaning matrix $M$ is an exciting future work.\\n\\nEffectiveness of distilling an effective global ranking\\n\\nOur experiments have shown that given a communicative dataset, both the annealing (in the case of a small dataset) and neural scoring (in the case of a larger dataset) have their merits in deriving a ranking. Thus, running the slow RSA in the dataset generation itself is the likely bottleneck. We believe recent works by Key et al. (2022) and Vaduguru et al. (2024) using sample-and-rerank may be used in generating the communicative dataset instead of the exact RSA algorithm.\\n\\nImpact Statement\\n\\nThis work builds a system where end-users may use examples to generate programs. While the proposed method is more intuitive to use by humans, it is possible that for some interactions, it may generate unexpected programs. Therefore, it could be of potential danger when humans do not manually verify the generated program, as it may have unintended outcomes when executed.\\n\\nAcknowledgements\\n\\nThe authors would like to thank Kevin Ellis, Pei Wang, and Jesse Wang for preliminary explorations in this direction and insights to the proof. SV was partially supported by a gift from Autodesk Research. This material is based upon work supported by the NSF under Grant Nos. CCF-2123965 and IIS-2107391. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the NSF.\\n\\nReferences\\n\\nAndreas, J. and Klein, D. Reasoning about pragmatics with neural listeners and speakers. arXiv preprint arXiv:1604.00562, 2016.\\n\\nBalog, M., Gaunt, A. L., Brockschmidt, M., Nowozin, S., and Tarlow, D. Deepcoder: Learning to write programs. ICLR, 2016.\\n\\nBergen, L., Levy, R., and Goodman, N. Pragmatic reasoning through semantic inference. Semantics and Pragmatics, 9:ACCESS\u2013ACCESS, 2016.\\n\\nBradley, R. A. and Terry, M. E. Rank analysis of incomplete block designs: I. the method of paired comparisons. Biometrika, 39(3/4):324\u2013345, 1952. ISSN 00063444. URL http://www.jstor.org/stable/2334029.\\n\\nChen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavaridian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code, 2021.\\n\\nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., and Amodei, D. Deep reinforcement learning from human preferences. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R. (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf.\\n\\nCohn-Gordon, R., Goodman, N., and Potts, C. Pragmatically informative image captioning with character-level inference. arXiv preprint arXiv:1804.05417, 2018a.\\n\\nCohn-Gordon, R., Goodman, N. D., and Potts, C. An incremental iterated response model of pragmatics. arXiv preprint arXiv:1810.00367, 2018b.\\n\\nEllis, K. and Gulwani, S. Learning to learn programs from examples: Going beyond program structure. IJCAI, 2017.\"}"}
{"id": "yj8h567Ia7", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yj8h567Ia7", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\ninformative choice of utterances using recursive Bayesian reasoning (Frank & Goodman, 2012). By reasoning about why a speaker (user) might have chosen a particular utterance (examples), rather than possible alternatives, the listener (synthesizer) can disambiguate the hypothesis (program) to which the speaker was referring to. Formally, the RSA framework produces a chain of alternating listeners and speakers beginning with the $L_0$ model above.\\n\\n$S_1(u|w) \\\\propto L_0(w|u) = L_0(w|u)P_{u'}L_0(w|u')$\\n\\nApplying this framework amounts to normalizing the columns of the $L_0$ matrix to obtain a pragmatic speaker distribution $S_1$, then normalizing the rows of $S_1$ to obtain a pragmatic listener (synthesizer), $L_1$ (Figure 2). As we can see, given the utterance $01$, this listener prefers $0+1$ over $0+1^*$, reflecting the reasoning that if the user wanted to refer to $0+1^*$, they might have provided an example that highlights the possibility of no 1s in the string. In this paper, we shall call this algorithm RSA single. As this algorithm only depends on $M$, it is applicable to all program synthesis domains where programs and examples can be effectively enumerated.\\n\\n2.4. A Pragmatic Synthesizer from Multiple Examples\\n\\nFigure 3. In the case of incremental RSA, the meaning matrix becomes smaller as more utterances are given, as each utterance rules out hypotheses that are inconsistent with it. RSA single is capable of producing a program synthesis algorithm from a single example. However, the users will typically have to clarify their intent interactively, by giving a sequence of multiple utterances $u = u_1, u_2, \\\\ldots, u_n$. The synthesizer must infer the intended program after every turn. With each new utterance, the meaning matrix $M$ becomes smaller, as hypotheses inconsistent with the new utterance are ruled out (Figure 3). This is an instance of incremental RSA (Cohn-Gordon et al., 2018b), which models the informative speaker $S_1$ generating utterances auto-regressively:\\n\\n$S_1(u|w) = S_1(u_1, u_2, \\\\ldots, u_n|w) = \\\\sum_{i=1}^{n} S_1(u_i|w, u_1, \\\\ldots, u_{i-1}) = \\\\sum_{i=1}^{n} L_0(w|u_1, \\\\ldots, u_i)P_{w'}L_0(w'|u_1, \\\\ldots, u_i)$\\n\\nIn essence, the $S_1$ is the product of multiple single-utterance $S_1$ computed on separate meaning matrixes (like those in Figure 3). The synthesizer $L_1(w|u)$ is defined recursively on top of $S_1$, $L_1(w|u) \\\\propto S_1(u|w)$.\\n\\nPu et al. (2020) builds on top of the incremental RSA algorithm with additional memoization strategies. In this work, we shall call their algorithm RSA. Similar to RSA single, this algorithm is applicable to enumerative program synthesis domains such as Feser et al. (2015); Solar-Lezama (2008); Gulwani (2011).\\n\\n2.5. Exact RSA is Slow\\n\\nIn practice, it is infeasible to explicitly store the matrices $M$, $L_0$, $S_1$, $L_1$. Instead, computing $L_1$ using RSA requires $O(|W|)$ calls to $S_1$. Each call to compute $S_1$ requires $O(|U|)$ calls to $L_0$, which in turn requires $O(|W|)$ operations to determine a set of consistent programs. In practice, the pragmatic synthesizer $L_1$ runs in $O(|W|^{2|U|})$ time. In the incremental RSA setting with multiple (say $\\\\ell$) utterances, the runtime of $L_1$ is $O(|W|^{2|U|}\\\\ell)$. As the number of hypotheses and utterances becomes large in a program synthesis domain, it becomes infeasible to compute $L_1$ at a speed required for end-user interactions.\\n\\n3. Amortizing RSA with Rankings\\n\\nWe explain how the pragmatic listener $L_1$, derived from the RSA algorithm can be amortized using a single global ranking of programs.\\n\\nFinding Consistent Programs\\n\\nFinding correct programs given a sequence of examples $u = u_1, u_2, \\\\ldots$ is the primary challenge of program synthesis, with solutions ranging from enumeration (Feser et al., 2015), constraint solving (Solar-Lezama et al., 2006), neuro-symbolic (Polosukhin & Skidanov, 2018; Balog et al., 2016), and using large language models for code (Li et al., 2022). In this work, we assume the a set of $k$ consistent programs $w_1, w_2, \\\\ldots, w_k$ can be found using any of these techniques.\\n\\nRanking Consistent Programs with a Prior\\n\\nA global ranking $\\\\sigma$ is an un-normalized prior (a score) over all programs. The global ranking is example-agnostic: given two programs $w_a$ and $w_b$, either $\\\\sigma[w_a] \\\\succ \\\\sigma[w_b]$ or $\\\\sigma[w_a] \\\\prec \\\\sigma[w_b]$.\"}"}
{"id": "yj8h567Ia7", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\n\\\\[ \\\\sigma[w], \\\\text{irrespective of the given examples } u. \\\\]\\n\\n\\\\[ L_\\\\sigma(w|u) \\\\propto \\\\sigma[w] M[u, w] \\\\]\\n\\nAs we can see, ranking the consistent programs under \\\\( \\\\sigma[w] \\\\) can be very efficient. In practice, efficient synthesis algorithms are built using either domain-specific heuristics for rankings (Singh & Gulwani, 2015; Polozov & Gulwani, 2015), or a learned prior from a code corpus (Li et al., 2022).\\n\\nRanking with \\\\( L_1 \\\\) Rather than relying on heuristics or learning from a large corpus, RSA automatically derives a ranked synthesizer \\\\( L_1(w|u) \\\\):\\n\\n\\\\[ L_1(w|u) \\\\propto S_1(u|w) M[u, w] \\\\]\\n\\nTo rank the consistent programs, \\\\( L_1 \\\\) uses \\\\( S_1(u|w) \\\\), an example-dependent ranking function, that ranks the satisfying programs differently depending on the sequences of examples \\\\( u \\\\) given. In this setting with multiple examples, there could be cycles where a pair of satisfying programs \\\\( w_a \\\\) and \\\\( w_b \\\\), which is ranked \\\\( S_1(u_1|w_a) > S_1(u_1|w_b) \\\\) under some examples \\\\( u_1 \\\\) and ranked \\\\( S_1(u_2|w_a) < S_1(u_2|w_b) \\\\) given different examples \\\\( u_2 \\\\). In this work, we assume that \\\\( S_1 \\\\) can be tractably computed at non-interactive speed.\\n\\nAmortizing \\\\( L_1 \\\\) with a Ranking\\n\\nIn this work, we explore whether the example-dependent ranking of \\\\( S_1(u|w) \\\\) can be approximated \u2014 to have similar top-\\( k \\\\) responses \u2014 with an example-agnostic ranking function \\\\( \\\\sigma[w] \\\\). Note that due to the existence of cycles, it may be impossible to find a global ranking that is consistent with all example-dependent rankings. Our key findings are as follows:\\n\\n**Key Finding 1**: One can distill a pragmatic ranking \\\\( \\\\sigma \\\\) from \\\\( L_1 \\\\). While this is an approximation, it nonetheless retains much of the \\\\( L_1 \\\\)'s communicative accuracy when interacting with end-users, and running orders of magnitude faster.\\n\\n**Key Finding 2**: In the special case where only a single example is used, RSA single, the approximation can be made exact: There exists a global ranking \\\\( \\\\sigma^* \\\\) that perfectly matches the top-\\( k \\\\) responses of \\\\( L_1 \\\\) over any example \\\\( u \\\\).\\n\\n### 4. Distilling \\\\( L_1 \\\\) of RSA to a Global Ranking\\n\\nDistilling the example-dependent \\\\( L_1 \\\\) rankings into a global ranking has two stages. First, we generate a dataset of \\\\( D = \\\\{ (w, u, \\\\tilde{\\\\sigma}_u), \\\\ldots \\\\} \\\\), where \\\\( w \\\\) is a program, \\\\( u \\\\) is a specification (sequence of examples) used to describe \\\\( w \\\\), and \\\\( \\\\tilde{\\\\sigma}_u = [w_1, w_2, \\\\ldots, w_k] \\\\) are the \\\\( k \\\\) example-dependent rankings of consistent programs given \\\\( u \\\\).\\n\\n#### 4.1. Dataset Generation via Simulated Communications\\n\\nThe pragmatic listener \\\\( L_1 \\\\) can generate a partial ranking of consistent programs for any sequences of examples \\\\( u \\\\). As arbitrary examples \\\\( u \\\\) are unlikely to reflect what a user might give at inference time, we use the informative speaker \\\\( S_1 \\\\) as a \u201cstand-in\u201d. Specifically, we generate \\\\( D \\\\) in a form of simulated interactions between the pragmatic speaker \\\\( S_1 \\\\) and the pragmatic listener \\\\( L_1 \\\\). We enumerate over the set of programs \\\\( w \\\\in W \\\\), then use the pragmatic speaker to sample the most likely specifications (sequence of examples) \\\\( u \\\\sim \\\\text{top}^{-1} S_1(\\\\cdot|w) \\\\) of length 1 to length \\\\( N \\\\). For each specification, we query \\\\( L_1 \\\\) for a partial ranking \\\\( \\\\tilde{\\\\sigma}_u \\\\) of consistent programs, and add it to the dataset \\\\( D \\\\) (Algorithm 1).\\n\\n**Algorithm 1**\\n\\nAlgorithm to obtain a dataset of simulated interactions between a speaker \\\\( S \\\\) and listener \\\\( L \\\\). For each turn of each interaction, a ranking of programs is obtained.\\n\\n```plaintext\\nRequire:\\nSet of programs \\\\( W \\\\)\\nRequire:\\nLength of specification to generate \\\\( N \\\\)\\nRequire:\\nSpeaker model \\\\( S(u|w, u) \\\\)\\nRequire:\\nListener model \\\\( L(w|u) \\\\)\\nRequire:\\nFunction \\\\( \\\\text{MAKE RANKING} \\\\) that ranks samples from a distribution based on the probability\\n```\\n\\n```plaintext\\nD \u2190 {}\\nfor \\\\( w \\\\) in \\\\( W \\\\) do\\n  \\\\( u \\\\) \u2190 []\\n  for \\\\( i = 1 \\\\) to \\\\( N \\\\) do\\n    \\\\( u_{next} \\\\) \u2190 \\\\( \\\\text{arg max}_{u} S(u|w, u) \\\\)\\n    \\\\( u \\\\) \u2190 \\\\( u + [u_{next}] \\\\)\\n    \\\\( \\\\tilde{\\\\sigma}_u \\\\) \u2190 \\\\( \\\\text{MAKE RANKING}(L(\\\\cdot|u)) \\\\)\\n    \\\\( D \\\\) \u2190 \\\\( D \\\\cup \\\\{(w, u, \\\\tilde{\\\\sigma}_u)\\\\} \\\\)\\n  end for\\nend for\\n```\\n\\n#### 4.2. Distillation via Annealing\\n\\nThe most straightforward representation of a ranking is as an explicit list of programs \\\\( \\\\sigma_\\\\text{global} = [w_1, w_2, \\\\ldots, w_n] \\\\). We describe a process of finding an approximate global ranking using annealing. We repeatedly sample example-dependent rankings \\\\( \\\\tilde{\\\\sigma}_u \\\\) from \\\\( D \\\\), and update the global ranking \\\\( \\\\sigma_\\\\text{global} \\\\) to match \\\\( \\\\tilde{\\\\sigma}_u \\\\) for a single pair of programs sampled from \\\\( \\\\tilde{\\\\sigma}_u \\\\).\\n\\nSince cycles exist in example-dependent rankings, we terminate the annealing procedure once the number of swaps in a sliding window has stabilized (Algorithm 2). The resulting \\\\( \\\\sigma_\\\\text{global} \\\\) is then used at inference time.\\n\\n**Algorithm 2**\\n\\nAlgorithm to perform annealing for finding an approximate global ranking.\\n\\n```plaintext\\nwhile True do\\n  \\\\( \\\\tilde{\\\\sigma}_u \\\\) \u2190 \\\\( \\\\text{sample from } D \\\\)\\n  \\\\( (w_a, w_b) \\\\) \u2190 \\\\( \\\\text{sample from } \\\\tilde{\\\\sigma}_u \\\\)\\n  \\\\( \\\\sigma_\\\\text{global} \\\\) \u2190 \\\\( \\\\sigma_\\\\text{global} \\\\) \\\\( \\\\rightarrow \\\\) \\\\( \\\\sigma_\\\\text{global} \\\\) \\\\( \\\\oplus \\\\) \\\\( \\\\sigma_\\\\text{global} \\\\) \\\\( \\\\rightarrow \\\\) \\\\( \\\\sigma_\\\\text{global} \\\\)\\n  \\\\( \\\\text{Update number of swaps in sliding window} \\\\)\\n  if \\\\( \\\\text{number of swaps has stabilized} \\\\) then\\n    break\\n  end if\\nend while\\n```\\n\\nThe resulting \\\\( \\\\sigma_\\\\text{global} \\\\) is then used at inference time.\"}"}
{"id": "yj8h567Ia7", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 2\\nAlgorithm to infer a global order $\\\\sigma$ based on a dataset of simulated interactions, that terminates based on a validation criterion determined by the validation frequency $V$, patience $t$ and convergence threshold $T$.\\n\\nRequire:\\n- Dataset of simulated interactions $D$\\n\\n$\\\\sigma \\\\leftarrow$ randomly initialized ranking\\n$\\\\text{converged} \\\\leftarrow \\\\text{FALSE}$\\n\\n$n_{\\\\text{swaps}} \\\\leftarrow \\\\left\\\\lfloor \\\\frac{\\\\text{max} \\\\, N_{\\\\text{swaps}}[\u2212t]}{\\\\text{min} \\\\, N_{\\\\text{swaps}}[\u2212t]} \\\\right\\\\rfloor$\\n\\n$n_{\\\\text{swaps}} \\\\leftarrow 0$\\n$i \\\\leftarrow 0$\\n\\nwhile not converged do\\n\\n$(p, \\\\tilde{\\\\sigma}, u) \\\\sim D$\\n\\nSample programs $p_1, p_2$ in $\\\\tilde{\\\\sigma}$\\n\\nif $\\\\tilde{\\\\sigma}[p_1] \\\\succ \\\\tilde{\\\\sigma}[p_2]$ and $\\\\sigma[p_1] \\\\prec \\\\sigma[p_2]$ then\\n\\nSwap $\\\\sigma[p_1], \\\\sigma[p_2]$\\n\\n$n_{\\\\text{swaps}} \\\\leftarrow n_{\\\\text{swaps}} + 1$\\n\\nend if\\n\\n$i \\\\leftarrow i + 1$\\n\\nif $i \\\\equiv 0 \\\\mod V$ then\\n\\n$N_{\\\\text{swaps}} \\\\leftarrow N_{\\\\text{swaps}} + n_{\\\\text{swaps}}$\\n\\n$n_{\\\\text{swaps}} \\\\leftarrow 0$\\n\\nif $\\\\max N_{\\\\text{swaps}}[\u2212t] : \\\\min N_{\\\\text{swaps}}[\u2212t] < T$ then\\n\\n$\\\\text{converged} \\\\leftarrow \\\\text{TRUE}$\\n\\nend if\\n\\nend if\\n\\nend while\\n\\nreturn $\\\\sigma$\\n\\nFigure 4.\\nGrammar for the regex domain\\n\\n$S \\\\rightarrow RP | S \\\\, RP$\\n\\n$RP \\\\rightarrow '[01]' \\\\, OP | '0' \\\\, OP | '1' \\\\, OP$\\n\\n$OP \\\\rightarrow '*' | '+' | '{1}' | '{2}'$\\n\\n4.3. Distillation via Learning a Score Function\\nAn alternative method to distill $D$ is to train a score function $s_\\\\theta : w \\\\rightarrow R$ that determines a score for a program $w$ that is independent of the specifications $u$. We can optimize $\\\\theta$ to minimize disagreement with the generated dataset of example-dependent rankings, by minimizing the loss $L(\\\\theta) = \\\\mathbb{E}_{\\\\tilde{\\\\sigma}, u \\\\sim D} w_1, w_2 \\\\sim \\\\tilde{\\\\sigma} u : \\\\tilde{\\\\sigma} u[w_1] \\\\succ \\\\tilde{\\\\sigma} u[w_2] - \\\\log(\\\\text{sig}(s_\\\\theta(w_1) - s_\\\\theta(w_2)))$ where $\\\\text{sig}$ is the sigmoid function. This follows estimating a score function from a set of pairwise preferences (Bradley & Terry, 1952; Christiano et al., 2017). We parametrize $s_\\\\theta$ as a small neural network that scores programs. To reduce variance, we fit an ensemble of score functions and use their average to rank the consistent programs at inference time (Christiano et al., 2017). Details of the neural models are in Appendix E.\\n\\nFigure 5.\\nSuccess rate of the literal $L_0$ and ranking-based $L_{\\\\text{anneal}}$ synthesizers inferring the correct regex as a function of numbers of examples given (turn). $L_{\\\\text{anneal}}$ achieves a success rate of 93.75%, $L_0$ achieves only 65.63%. The ranking-based synthesizer also achieves higher success with fewer utterances. Bands indicate 95% CI over 24 regexes for each condition.\\n\\n5. Experiments\\nTo validate the accuracy and run-time of an approximate ranking listener, we perform two sets of experiments. First, we conduct a small ($n = 8$) human experiment by building a ranking-based synthesizer in a regular expression synthesis domain where it is infeasible to run the RSA algorithm $L_1$ at interaction time. Second, we conduct two replay studies by simulating virtual users giving examples one after another using human interaction data collected from prior works. We seek to answer the following questions: (Q1) Can ranking based synthesizers accurately infer programs from humans (both in live interaction and in simulated replays)? (Q2) Are ranking-based synthesizers fast to run when compared to $L_0$ and $L_{\\\\text{anneal}}$?\\n\\nMetrics\\nIn our experiments, the users (real or simulated) will be given a target program, and attempt to communicate it to the synthesizers using examples. The synthesizers will be measured on their communication accuracy \u2014 whether the synthesizers can infer the target program from the examples given. A synthesizer is better than another if it can recover the target program using fewer examples.\\n\\n5.1. Interactive User Study\\nWe conduct a user study where people interacted with both the ranking-based synthesizer distilled with annealing $L_{\\\\text{anneal}}$ and the literal synthesizer $L_0$ on the domain of regular expression synthesis.\\n\\nThe Regex Domain\\nThe regex domain is a scaled up version of Vaithilingam et al. (2023), which has a total of 350 regular expressions from their grammar (Figure 4. For this study, we expanded the space of programs to 3500 regular expressions from the same grammar \u2013 a setting that would make live interaction infeasible running $L_1$ with RSA.\"}"}
{"id": "yj8h567Ia7", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Amortizing Pragmatic Program Synthesis with Rankings\\n\\nFigure 6. Animal domain replay results. Fraction of successfully communicated target programs (success) vs number of examples (turn). Bands are 95% confidence interval across interactions (254 for H\u2080 and 291 for H\u2081). Two kinds of simulated speakers: H\u2080\u2014replaying the interactions where participants communicated with a literal L\u2080 synthesizer from the original study; H\u2081\u2014with a pragmatic L\u2081 synthesizer. On H\u2080 replay, L\u2080 performs worst (63.78%), and Lanneal (71.65%), L\u2081 (74.80%), Lneural (78.34%) performing similarly to each other. On H\u2081 replay, L\u2080 (15.46%) performs worst, with Lanneal (49.82%) in the middle, while L\u2081 (91.75%) and Lneural (86.94%) perform best.\\n\\nProcedure\\nWe recruited 8 participants from our institution. Each participant was given a short tutorial on how to use the interface, then attempted to communicate a total of 4 regexes using examples. For each regex, the participant communicated with both the literal synthesizer L\u2080 and the ranking synthesizer L\u2081, anonymized as simply a \u201cgreen robot\u201d and a \u201cblue robot\u201d in randomized order. The participants gave example strings one at a time until the regex is recovered by the synthesizer, or they may give up early. The communication is interactive: When the participant added a new example, they were immediately shown the current top-1 guess of the synthesizer, which allowed them to choose the next example accordingly.\\n\\nResults: end-users interact well with an amortized ranking synthesizer (Q1)\\nFigure 5 shows the communication success rate over numbers of given examples (turns) for both the literal and ranking-based synthesizers. We can see that (1) Lanneal has a higher overall success rate with humans, and (2) It also achieves a higher success rate with fewer number of examples (Q1).\\n\\n5.2. Simulated User Studies Using Replays\\nWe evaluate the ranking-based synthesizers by replaying the interaction data collected from Vaithilingam et al. (2023) and Pu et al. (2020) \u2013 small pragmatic program synthesis domains where it is feasible to run L\u2081 with RSA.\\n\\nReplay Data\\nIn the human studies by Vaithilingam et al. (2023) and Pu et al. (2020), a human H is given a target program w, and attempt to get the synthesizer (L\u2080 or L\u2081) to infer the target using a sequence of examples u\u2081, u\u2082, . . . . Thus, two sets of data are generated, one where the human is interacting with the literal synthesizer L\u2080, which\\n\\nFigure 8. The wall clock time for each synthesizer given different numbers of examples (turn). We see that L\u2081 is consistently much slower than either Lanneal or L\u2080 in both domains. Note that time is on a logarithmic scale for the animals domain. The difference slopes for L\u2081 (trending up for regex and trending down for animals) is due to an optimization of the L\u2081 synthesizer for the animals domain, which filters out invalid programs as a pre-processing step using L\u2080, making it having to rank fewer programs over turns we term H\u2080, and one where the human is interacting with the pragmatic synthesizer L\u2081, which we term H\u2081. Specifically, from each domain we extract the following dataset { (w, u\u2081, u\u2082, j, i) | w \u2208 W\u209b, j \u2208 P, i \u2208 {0, 1} }. Here, W\u209b are the set of programs used for the human study (the stimuli), P is the set of participants, and i indicates if the participant is communicating with L\u2080 or L\u2081.\\n\\nExperiment Setup\\nWe can simulate an user interaction by using the replay data. Given a datapoint w, u\u2081, u\u2082, . . . , we create a simulated user that iteratively gives the examples u\u2081, u\u2082, . . . in multiple turns to communicate a given target program w. At every turn, the synthesizer returns the top-1 responses, L\u2081(u\u2081), L\u2081(u\u2081, u\u2082), . . . , and we can check if any of them matches the target program w. If they do, we mark the communication as successful and stop early. Otherwise, we keep adding examples until the u runs out, and we mark the communication as unsuccessful. Note that our evaluation cannot account for a user adapting their choice of examples to L, as the simulated user can only give scripted examples according to the replay data.\\n\\n6\"}"}
