{"id": "krylov23a", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nWe propose to select the lexicographically best training-set circuit that meets the threshold\\n\\\\[ \\\\bar{D}^*_{0} = \\\\{(x, y) | y \\\\in D_0, x = \\\\arg\\\\max F(y; D_0)\\\\}, \\\\]\\nwhere we select for \\\\( x \\\\) a single representative \\\\((x, y')\\\\) of \\\\( F(y)\\\\) that maximizes \\\\( y' \\\\) lexicographically. In the notation \\\\( \\\\bar{D}^*_{0}\\\\), the bar denotes feasibility of \\\\( x \\\\) for \\\\( y \\\\) and the star denotes selection of the best representative.\\n\\nWe note that, by definition, all members of \\\\( F(y)\\\\) have good circuit parameters that meet the threshold \\\\( y\\\\). However, adding all of them to our training set, similar to the method proposed by Lourenc \\\\( \\\\circ \\\\) et al. (2018), would create conflicts where the same network input \\\\( y \\\\) is mapped to different outputs. By breaking \\\"ties\\\" in a consistent way \u2014 and in accordance with user-specified preference over metrics \u2014 we create a dataset more conducive of learning. The new dataset \\\\( \\\\bar{D}^*_{0}\\\\) has the same size as the simulation dataset \\\\( D_0\\\\) and the same set of performance vectors. The circuit parameter vectors in \\\\( \\\\bar{D}^*_{0}\\\\) are those that define its Pareto frontier, that is, for which no other simulated circuit is better in all performance metrics. Thus, \\\\( \\\\bar{D}^*_{0}\\\\) consistently maps feasible performance vectors to frontier circuits.\\n\\n4.3.1. Threshold Queries\\nIn Section 2.2, we discussed how performance metrics measured in simulation are perturbed to generate threshold queries (Eq. (3)). We denote thus perturbed data by\\n\\\\[ D_\\\\epsilon = \\\\{(x, (1-\\\\epsilon \\\\lambda u)y) | (x, y) \\\\in D_0, u \\\\sim U_k \\\\text{i.i.d}\\\\} \\\\]\\nNote that the distribution of threshold queries \\\\( y \\\\sim D_\\\\epsilon\\\\) is different than the distribution of simulated metrics vectors \\\\( y \\\\sim \\\\bar{D}^*_{0}\\\\). To avoid a mismatch of the training and test distributions, we combine the filters to form a dataset of threshold queries with a principled selection of target circuits:\\n\\\\[ \\\\bar{D}^*_{\\\\epsilon} = \\\\{(x, \\\\tilde{y}) | \\\\tilde{y} \\\\in D_\\\\epsilon, x = \\\\arg\\\\max F(\\\\tilde{y}; D_0)\\\\} \\\\]\\n\\\\( \\\\bar{D}^*_{\\\\epsilon}\\\\) is a dataset mapping \\\\( \\\\epsilon\\\\)-perturbed metrics vectors \\\\( \\\\tilde{y}\\\\) to circuits whose (unperturbed) simulated metrics are feasible for the threshold query \\\\( \\\\tilde{y}\\\\), selecting the lexicographically best such circuit.\\n\\n4.3.2. Baseline and Ablation\\nWe compare our dataset construction methods, \\\\( \\\\bar{D}^*_{0}\\\\) and \\\\( \\\\bar{D}^*_{\\\\epsilon}\\\\), with a baseline that closely follows Lourenc \\\\( \\\\circ \\\\) et al. (2018). We define \\\\( D_m_\\\\epsilon\\\\) as the union of \\\\( m\\\\) i.i.d. samples of \\\\( D_\\\\epsilon\\\\):\\n\\\\[ D_m_\\\\epsilon = \\\\left\\\\{(x, y_t) | y_t \\\\in D_\\\\epsilon, u_t \\\\sim U_k \\\\text{i.i.d}\\\\right\\\\} \\\\]\\nIn our experiments, \\\\( m = 20\\\\). The reasons are that by construction, in each \\\\((x, \\\\tilde{y}) \\\\in D_m_\\\\epsilon\\\\) the circuit \\\\( x\\\\) is feasible for the threshold query \\\\( \\\\tilde{y}\\\\), i.e. \\\\( \\\\lambda f(x) \\\\geq \\\\lambda \\\\tilde{y}\\\\); and that the training distribution \\\\( \\\\tilde{y} \\\\sim D_m_\\\\epsilon\\\\) is identical to our evaluation distribution \\\\( \\\\tilde{y} \\\\sim D_\\\\epsilon\\\\). Note that, in contrast to most of the literature on analog circuit design automation via supervised learning, which employs a simulation dataset akin to \\\\( D_0\\\\), \\\\( D_m_\\\\epsilon\\\\) is suited for the threshold specification problem (Lourenc \\\\( \\\\circ \\\\) et al., 2018).\\n\\nUnfortunately, the dataset \\\\( D_m_\\\\epsilon\\\\) can be very confusing to learn from. Because the simulator function \\\\( f\\\\) is not necessarily injective, there may exist multiple circuits with similar performance vectors. Moreover, such vectors have overlapping supports of their perturbation distributions. The result is that \\\\( D_m_\\\\epsilon\\\\) will tend to have similar threshold queries mapped to vastly different circuit parameters, rendering their prediction difficult.\\n\\nWe propose an ablation that more directly demonstrates this issue. In \\\\( \\\\bar{D}_m_\\\\epsilon\\\\), we select for each \\\\( \\\\tilde{y} \\\\in D_\\\\epsilon\\\\) the \\\\( m\\\\) lexicographically-best feasible circuits, rather than only the single best in \\\\( \\\\bar{D}^*_{\\\\epsilon}\\\\) (Eq. (7)):\\n\\\\[ \\\\bar{D}_m_\\\\epsilon = \\\\{(x, \\\\tilde{y}) | \\\\tilde{y} \\\\in D_\\\\epsilon, x \\\\in \\\\text{top}_m F(\\\\tilde{y}; D_0)\\\\} \\\\]\\nWe expect this method to perform suboptimally, more similarly to \\\\( D_m_\\\\epsilon\\\\) than to \\\\( \\\\bar{D}^*_{\\\\epsilon}\\\\). This would provide evidence that the main aspect impacting the prior method, compared with the novel one, is the existence of multiple targets for each query, rather than the other differences \u2014 namely, the selection of circuits from the feasible set \\\\( F(y)\\\\), or the preference of lexicographically better circuits.\\n\\nTo summarize, we consider six datasets: (1) \\\\( D_0\\\\) is the simulation data; (2) \\\\( D_\\\\epsilon\\\\) has perturbed performance metrics that resemble the threshold query distribution, and is used for method evaluation; (3) \\\\( \\\\bar{D}^*_{0}\\\\) and (4) \\\\( \\\\bar{D}^*_{\\\\epsilon}\\\\) are our proposed methods, without and with perturbation to match the test distribution; (5) \\\\( D_m_\\\\epsilon\\\\) is a baseline similar to Lourenc \\\\( \\\\circ \\\\) et al. (2018); and (6) \\\\( \\\\bar{D}_m_\\\\epsilon\\\\) is an ablation study.\\n\\n5. Experiments\\nWe experiment with our methods on a diverse group of seven circuit topologies, detailed below. Best practices in circuit design suggest that circuit parameters are chosen based on their impact on performance metrics (Bandler & Chen, 1988; Hassan et al., 2016; Bandler & Rayas-S\u00e1nchez, 2023). Only these parameters are used to optimize performance for each circuit. We simulate each circuit in a parameter grid consisting of approximately 4000 points, except for the simplest two-stage amplifier with around 600 points, as presented in Table 6 in Appendix A.5. A schematic of each circuit shows the range and step size of each variable parameter, as well as color-coded tags illustrating the diversity of the circuits to which our method applies. To facilitate result reproduction, the code and data used in our experiments\"}"}
{"id": "krylov23a", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nVariable: resistance\\n\\n\\\\[620\u03a9 :5\u03a9:1450\u03a9\\\\]\\n\\nVariable: width\\n\\n\\\\[2.88 \\\\text{mm}:0.2 \\\\text{mm},6.63 \\\\text{mm}\\\\]\\n\\nV\\\\text{DD}\\n\\nV\\\\text{in}\\n\\nR\\\\text{D}\\n\\nM\\\\text{1}\\n\\nV\\\\text{out}\\n\\nC\\\\text{L}\\n\\nV\\\\text{in}\\n\\nV\\\\text{out}\\n\\nR\\\\text{D}\\n\\nM\\\\text{2}\\n\\nM\\\\text{1}\\n\\nVariable: width\\n\\n\\\\[2 \\\\text{mm}:0.2 \\\\text{mm},5 \\\\text{mm}:11.5 \\\\text{mm}\\\\]\\n\\nVariable: resistance\\n\\n\\\\[9K\u03a9:125\u03a9:11K\u03a9\\\\]\\n\\nVariable: width\\n\\n\\\\[8 \\\\text{mm}:0.25 \\\\text{mm},11.5 \\\\text{mm}\\\\]\\n\\n(a)\\n\\n(b)\\n\\nGain\\n\\nGain-power tradeoff\\n\\nGain-bandwidth tradeoff\\n\\nGain-swing tradeoff\\n\\nNonlinear\\n\\nNoise-bandwidth tradeoff\\n\\nGain-power tradeoff\\n\\nGain-swing tradeoff\\n\\nFigure 3.\\n\\nSchematics of analog voltage amplifiers: (a) common source (CS) amplifier; (b) cascode amplifier. Color-coded tags show circuit characteristics. Ranges and step sizes are marked near each circuit parameter.\\n\\nThe supplementary details of the circuits employed in our experiments can be found in Tables 8, 9, and 10 in Appendix A.5.\\n\\nOur main method uses the \\\\(\\\\bar{D}^*\\\\epsilon\\\\) dataset to train a neural network and evaluate its success rate in 10-fold cross-validation. For each circuit topology, we perform three comparisons of this method. First, we compare the main method with the five other data construction methods described in the previous section. Second, we compare the gradient-based learning algorithm with Random Forests and a simple lookup method (Section 4.2). Third, we study the sensitivity to the amount of training data by varying it. We compare the success rate of 10-fold cross validation, which uses 90% of the data for training each fold, with using 5%, 10%, 20%, and 50% of the data for training. We do this by randomly splitting the data into (respectively) 20, 10, 5, and 2 disjoint subsets, training on one subset, testing on the rest, and then averaging the result across the splits.\\n\\nIn all plots in this section, the solid curve is the average over 10 runs of data splitting and training, and the shaded area is the standard-error of the mean (SEM) over those runs.\\n\\n5.1. Analog Voltage Amplifiers\\n\\n5.1.1. Common Source (CS) Amplifier\\n\\nDue to its simplicity, the common source (CS) amplifier (Figure 3(a)) is among the most popular amplifier configurations using a CMOS transistor. As design variables, we consider the width of the transistor and the resistance of the load resistor \\\\(R_D\\\\). The target performance metrics, in decreasing importance are: bandwidth, voltage gain, and power consumption.\\n\\nAs shown in Figure 4(a), our model achieves near-perfect success at 5% error margin on the exact specification problem (Section 2.1), even while using 6 times less data than the best previous work (Devi et al., 2021). In the threshold specification problem (Section 2.2), our model trained on the \\\\(\\\\bar{D}^*\\\\epsilon\\\\) dataset also achieves perfect success at 5% error margin, whereas training on the na\\\"\u00efve \\\\(D_0\\\\) baseline dataset only achieves 85% success. Note, however, that all other data processing methods also achieve perfect success on this simple circuit. Further results appear in Appendix A.2.\\n\\n5.1.2. Cascode Amplifier\\n\\nThe CS amplifier has limited gain and exhibits a trade-off between critical performance metrics. The cascode amplifier shown in Figure 3(b) enhances the amplification bandwidth compared with a CS stage (Ko & Lin, 2006).\\n\\nAs illustrated in Figure 5, this more challenging circuit shows more sensitivity to the amount of training data, both in (a) the exact specification and (b) the threshold specification, comparing: (b) different data sizes of the \\\\(\\\\bar{D}^*\\\\epsilon\\\\) dataset; (c) different datasets; and (d) different agent models.\"}"}
{"id": "krylov23a", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nFigure 6. Schematic of a two-stage amplifier.\\n\\n5.1.3. Two-Stage Amplifier\\n\\nThe circuits of Figure 3 both suffer from limited gain. Two-stage amplifiers, as shown in Figure 6, are excellent replacements of single-stage amplifiers and in particular allow simultaneously achieving higher gain and voltage swing (Gray & Meyer, 1982).\\n\\nOwing to their widespread use, two-stage amplifiers have been among the most popular benchmark circuit configurations examined in prior automation work (Mina et al., 2022; Settaluri et al., 2020). Other than the baseline dataset \\\\( D_m \\\\) and ablation dataset \\\\( \\\\bar{D}_m \\\\), all other datasets achieve perfect success on this relatively easy circuit (Figure 7(a)), using 10 times less data than in the best previous work (Fukuda et al., 2017b; Wang et al., 2018b; Lourenc\u00b8o et al., 2018; M.V. & Harish, 2020b). The underperformance of the \\\"non-injective\\\" datasets supports our hypothesis that a systematic selection of representative circuits for similar performance levels is needed to facilitate learning of circuit design agents for threshold specification.\\n\\n5.2. (Non)-Linear Radio Frequency Circuits\\n\\n5.2.1. Low-Noise Amplifier (LNA)\\n\\nThe cascode low-noise amplifier (LNA) with inductive degeneration is a popular configuration to design an LNA for an RF receiver (Lerdworatawee & Namgoong, 2005). The circuit, depicted in Figure 8(a), can obtain a high gain and minimal loss of input power across a large bandwidth without suffering from additive noise of circuit components (mainly transistors). This circuit has four parameters (three inductor values and one cascode transistor width) and three metrics: the noise figure (signal-to-noise ratio between the input and output), the return loss, and the power gain.\\n\\nOur findings indicate that the LNA simulation function has a smooth surface, making it easy to invert for all methods, including the baseline, and resulting in perfect success even at very low error margins (Figure 7(b)). Only the ablation method \\\\( \\\\bar{D}_m \\\\) performs suboptimally, suggesting that it is even more prone to inconsistencies than the baseline \\\\( D_m \\\\).\\n\\n5.2.2. Power Amplifier (PA)\\n\\nA wireless communication transmitter requires a power amplifier to amplify the transmitted signal and deliver more power to the antenna, in order to mitigate the propagation loss of the electromagnetic waves and cover a longer operational distance (Niknejad et al., 2012). An efficient design of a two-stage differential cascode amplifier (Abbasi et al., 2010) that can provide sufficient power gain, while showing efficiency in terms of power consumption, may depend on multiple design parameters (Figure 9(a)).\\n\\nSimilar to LNA, nearly all data filtering methods performed well for the PA circuit, although with higher cross-run variance, with the exception of the baseline \\\\( D_m \\\\) and the ablation \\\\( \\\\bar{D}_m \\\\) (Figure 7(c)). We conclude that both LNA and PA \u2014 highly non-linear circuits with intricate tradeoffs, whose design has never before been automated \u2014 are easily learned within the operational range tested in this work.\\n\\n5.2.3. Mixer\\n\\nAn essential component in frequency conversion of modern radio-frequency and millimeter-wave circuits is a mixer. Given two input signals at frequencies \\\\( f_1 \\\\) and \\\\( f_2 \\\\), a mixer can generate desired signals at subtraction and summation frequencies, i.e.,\\n\\n\\\\[\\n\\\\begin{align*}\\n    f_{\\\\Delta} &= |f_1 - f_2| \\\\\\\\\\n    f_{\\\\Sigma} &= f_1 + f_2\\n\\\\end{align*}\\n\\\\]\\n\\nShown in Figure 8(b) is a common schematic for mixers known as a Gilbert Cell (Gilbert, 1968). This circuit operates by having radio frequency (RF) and local oscillation (LO) signals as the inputs and multiplying them to generate a signal with the summation or subtraction frequencies.\\n\\nThe mixer is a sufficiently complex circuit that different data filtering methods achieve different performance when learning to design it (Figure 7(d)). Our proposed method, \\\\( \\\\bar{D}_m^* \\\\), achieves near-perfect success even at very low error margins, and only our other method, \\\\( \\\\bar{D}_m^0 \\\\), matches it at 5% error. Interestingly, the na\u00a8\u0131ve perturbed dataset \\\\( D_\\\\epsilon \\\\) also performs much better than the baseline and ablation methods.\"}"}
{"id": "krylov23a", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nFigure 7. Comparing success rate in the threshold specification problem for different training datasets in five circuits: (a) two-stage; (b) low-noise amplifier (LNA); (c) power amplifier (PA); (d) mixer; (e) voltage-controlled oscillator (VCO).\\n\\nV\\\\textsubscript{in} \\\\quad V\\\\textsubscript{out}\\n\\nVariable: \\\\( L \\\\)\\n[9.4\\\\,\\\\text{nH}:0.2\\\\,\\\\text{nH}:10.8\\\\,\\\\text{nH}]  \\nVariable: width of \\\\( M_{1,2} \\\\)\\n[73\\\\,\\\\text{mm}:0.5\\\\,\\\\text{mm}:76.5\\\\,\\\\text{mm}]  \\nVariable: \\\\( L_s \\\\)\\n[747\\\\,\\\\text{pH}:1\\\\,\\\\text{pH}:754\\\\,\\\\text{pH}]  \\nVariable: \\\\( L_d \\\\)\\n[3.7\\\\,\\\\text{nH}:0.1\\\\,\\\\text{nH}:4.4\\\\,\\\\text{nH}]  \\n\\nV\\\\textsubscript{DD}\\n\\nM\\\\textsubscript{1}\\nM\\\\textsubscript{T}\\n\\nFigure 8. Schematics of: (a) low noise amplifier (LNA); (b) mixer.\\n\\nVariable: \\\\( V_{b1} \\\\)\\n[785\\\\,\\\\text{mV}:5\\\\,\\\\text{mV}:815\\\\,\\\\text{mV}]  \\nVariable: Width of \\\\( M_{1,2,3,4} \\\\)\\n[18\\\\,\\\\text{mm}:0.5\\\\,\\\\text{mm}:22\\\\,\\\\text{mm}]  \\nVariable: Width of \\\\( M_{5,6,7,8} \\\\)\\n[27\\\\,\\\\text{mm}:1\\\\,\\\\text{mm}:34.5\\\\,\\\\text{mm}]  \\n\\nV\\\\textsubscript{in+} \\\\quad \\\\overline{V\\\\text{out}}\\n\\nGain-power tradeoff\\nGain-bandwidth tradeoff\\nNonlinear\\nNoise-bandwidth tradeoff\\n\\nM\\\\textsubscript{1} \\nM\\\\textsubscript{T}\\n\\nFigure 9. Schematic of a power amplifier (PA).\\n\\n5.2.4. VOLTAGE-CONTROLLED OSCILLATORS (VCO)\\n\\nA critical circuit block in RF applications is the oscillator, specifically voltage-controlled versions with frequency tuning capability (Dai & Harjani, 2003), which is responsible for generating a sustainable periodic output autonomously. Shown in Figure 10 is a CMOS cross-coupled VCO (Hajimiri & Lee, 1999). VCO's desired behavior is to vary output frequency within a required tuning range with control voltage variation (Razavi, 2012). The transistors consume DC power to compensate for any physical losses while the electromagnetic energy exchange among the capacitors and the inductors leads to a sustainable oscillation.\\n\\nAutomatically designing a VCO circuit proved a challenging task for all of the tested method (Figure 7(e)). The order of relative performance was similar to the mixer, with our proposed method, \\\\( \\\\bar{D}^* \\\\), outperforming the others with 83.5% success rate at 5% error margin. Achieving near-perfect success on this circuit therefore remains an open challenge for future research.\\n\\n5.3. Clustering Effect Analysis\\n\\nSince our approach involves the replacement of circuit parameters with alternative parameters within the parameter space that yield improved performance, fewer distinct parameters remain after filtering than initially simulated. In situations where multiple performance metrics are mapped to the same parameter vector, it becomes intriguing to investigate the potential impact of this clustering on the performance of our algorithm. After constructing our dataset, we count the number of unique remaining parameters and the perplexity of the resulting dataset. The resulting perplexity is defined as\\n\\n\\\\[ P \\\\left( p \\\\right) = 2^H \\\\left( p \\\\right) \\\\]\\n\\nwhere entropy is estimated over the constructed dataset based on the counts of the unique parameters. In the majority of circuits, only approximately 3-12% of the original data points remain unchanged. In the case of the Cascode circuit, we observe 12% of the data points being unique, while the entropy of the resulting dataset is 8.16 and the perplexity is 286. For more advanced circuits like Mixer and VCO, we observe 2-3% of the unique data points after dataset construction, with the resulting perplexity of 45 for Mixer and 68 for VCO. However, even in extreme cases, such as CS Amplifier with an unchanged rate of nearly 50% of the original parameters,\"}"}
{"id": "krylov23a", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nwe observe an entropy of 13.12 and perplexity of 8913, or in the case of PA circuits with an unchanged rate of almost 0.01%, our algorithm consistently outperforms alternative methods. Hence, clustering does not significantly affect the performance of our algorithm.\\n\\n5.4. Performance Metric Ordering Variations\\n\\nIn our study, we subjected the LNA circuit to an assessment using two distinct orders of performance metrics: Order A (Power Gain, $S_{11}$, NF), and Order B ($S_{11}$, NF, Power Gain). We optimized for maximizing Power Gain and minimizing $S_{11}$ and NF in both orders. Notably, the circuits generated by Order A showcased an average Power Gain that was larger (thus better) by 0.84 dB compared to those generated by Order B. Additionally, these circuits exhibited an average $S_{11}$ that was higher (thus worse) by 0.53 dB in comparison. We conducted a similar analysis for the Common Source Amplifier, Cascode Amplifier, and Two-Stage circuits. By prioritizing the order of the bandwidth during dataset construction, we observed circuits with higher average bandwidth. Similarly, with regards to power consumption, which we aimed to minimize, assigning the highest priority to power consumption led to the production of circuits with lower power consumption. We conclude that the user-specified order of performance metrics effectively creates the desired preference over them.\\n\\n6. Conclusion\\n\\nWe present a data filtering pipeline that can generate, from a circuit simulation dataset, a training dataset for supervised learning of a circuit design agent for threshold specification. In extensive experiments with several baselines on a variety of linear, nonlinear, and autonomous analog and radio-frequency circuits, we find that our proposed method performs near-perfectly in all but the hardest circuit. This supports our hypothesis that a systematic selection of representative circuits can alleviate the \\\"non-injective\\\" property of the simulator function, which is vastly exacerbated by the threshold specification setting. The results also show the sample efficiency of our method. While not directly comparable with previous work, we often use a number of simulations an order of magnitude or more smaller than ever before, and learning from even 5% of this data is often highly successful as well. Lastly, we also show that our method is, to some extent, model agnostic by training with different machine learning methods and comparing their performance. To the best of our knowledge, this is the first time that a wide collection of analog circuits at various frequencies and of varied operations have been extensively examined and shown capable of being automatically designed. We believe that the methods and results of this work can help the growth of the circuit design industry by addressing the rapidly increasing demand for advanced electronic chipsets.\\n\\nAcknowledgements\\n\\nRoy Fox is partly supported by the Hasso Plattner Foundation.\\n\\nReferences\\n\\nAbbasi, M., Kjellberg, T., de Graauw, A., van der Heijden, E., Roovers, R., and Zirath, H. A broadband differential cascode power amplifier in 45 nm cmos for high-speed 60 ghz system-on-chip. In 2010 IEEE Radio Frequency Integrated Circuits Symposium, pp. 533\u2013536. IEEE, 2010.\\n\\nAfacan, E., Lourenc \u00b8o, N., Martins, R., and D\u00a8undar, G. Machine learning techniques in analog/rf integrated circuit design, synthesis, layout, and test. Integration, 77:113\u2013130, 2021.\\n\\nBandler, J. and Chen, S. Circuit optimization: the state of the art. IEEE Transactions on Microwave Theory and Techniques, 36(2):424\u2013443, 1988. doi: 10.1109/22.3532.\\n\\nBandler, J. W. and Rayas-S\u00b4anchez, J. E. An early history of optimization technology for automated design of microwave circuits. IEEE Journal of Microwaves, 3(1):319\u2013337, 2023. doi: 10.1109/JMW.2022.3225012.\\n\\nBoyd, S. P., Kim, S.-J., Patil, D. D., and Horowitz, M. A. Digital circuit optimization via geometric programming. Operations research, 53(6):899\u2013932, 2005.\\n\\nBreiman, L. Random forests. Machine learning, 45(1):5\u201332, 2001.\\n\\nBrunvand, E. Digital VLSI chip design with Cadence and Synopsys CAD tools. Addison-Wesley New York, 2010.\\n\\nDai, L. and Harjani, R. Design of high-performance CMOS voltage-controlled oscillators. Springer Science & Business Media, 2003.\\n\\nDevi, S., Tilwankar, G., and Zele, R. Automated design of analog circuits using machine learning techniques. In 2021 25th International Symposium on VLSI Design and Test (VDAT), pp. 1\u20136, 2021. doi: 10.1109/VDAT53777.2021.9601131.\\n\\nDumesnil, E., Nabki, F., and Boukadoum, M. Rf-lna circuit synthesis by genetic algorithm-specified artificial neural network. In 2014 21st IEEE International Conference on Electronics, Circuits and Systems (ICECS), pp. 758\u2013761, 2014. doi: 10.1109/ICECS.2014.7050096.\\n\\nFukuda, M., Ishii, T., and Takai, N. Op-amp sizing by inference of element values using machine learning. In 2017 9\"}"}
{"id": "krylov23a", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "krylov23a", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nM.V. and Harish, B. P. Artificial neural network model for design optimization of 2-stage op-amp. In 2020 24th International Symposium on VLSI Design and Test (VDAT), pp. 1\u20135, 2020. doi: 10.1109/VDAT50263.2020.9190315.\\n\\nNenzi, P. and Vogt, H. Ngspice users manual version 23, 2011.\\n\\nNiknejad, A. M., Chowdhury, D., and Chen, J. Design of CMOS power amplifiers. IEEE Transactions on Microwave Theory and Techniques, 60(6):1784\u20131796, 2012.\\n\\nRazavi, B. RF microelectronics, volume 2. Prentice hall New York, 2012.\\n\\nRenner, G. and Ek\u00b4art, A. Genetic algorithms in computer aided design. Computer-aided design, 35(8):709\u2013726, 2003.\\n\\nSettaluri, K., Haj-Ali, A., Huang, Q., Hakhamaneshi, K., and Nikolic, B. Autockt: Deep reinforcement learning of analog circuit designs. In 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 490\u2013495. IEEE, 2020.\\n\\nVural, R., Kahraman, N., Erkmen, B., and Yildirim, T. Process independent automated sizing methodology for current steering DAC. International Journal of Electronics, 102(10):1713\u20131734, 2015.\\n\\nWang, H., Yang, J., Lee, H.-S., and Han, S. Learning to design circuits. arXiv preprint arXiv:1812.02734, 2018a.\\n\\nWang, Z., Luo, X., and Gong, Z. Application of deep learning in analog circuit sizing. In Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence, CSAI '18, pp. 571\u2013575, New York, NY, USA, 2018b. Association for Computing Machinery. ISBN 9781450366069. doi: 10.1145/3297156.3297160. URL https://doi.org/10.1145/3297156.3297160.\"}"}
{"id": "krylov23a", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nA. Appendix\\n\\nA.1. Model Architecture\\n\\nIn this work, we propose a Multi-layer perceptron (MLP) architecture with seven layers for the task at hand. The first layer takes in a vector of size equal to the number of performance metrics for the circuit and outputs a vector of length 200. The last layer takes in a vector of length 200 and outputs the same number of parameters as in the circuit. The middle five layers are constant across all circuits and have the following [input, output] size configurations: [200, 300], [300, 500], [500, 500], [500, 300], [300, 200]. Each layer is separated by the Rectified Linear Unit (ReLU) activation function. We trained each MLP model for 100 epochs using the Adam optimizer (Kingma & Ba, 2015) with a default learning rate of 0.001. Additionally, we also trained a Random Forest (RF) model with the default number of trees (100) and default arguments.\\n\\nA.2. Comparing Methods\\n\\nFigure 11. Comparing different ML methods in three circuits: (a) cascode; (b) low-noise amplifier; (c) voltage-controlled oscillator.\\n\\nFigure 12. Comparing different ML methods in three circuits: (a) two stage; (b) mixer; and (c) power amplifier.\\n\\nWe compared the performance of three different machine learning methods: Neural Network (NN), Random Forest (RF), and Lookup Table (LT) using a ten-fold cross-validation setup with 90% of the data used for training. The purpose of this work was to demonstrate that our method is model-agnostic, and thus, we did not attempt to fine-tune the NN or RF models. The lookup table approach was implemented by searching for the circuit with the lowest error in the training dataset for a given testing circuit. The NN and RF models were trained as specified in Section A.1. The results in Table 1 suggest that all three methods perform similarly, with most of the circuits achieving 95-100% accuracy and a margin of 1%. This suggests that even a simple model like RF can produce good results. The detailed plots are presented in 12.\\n\\n| Circuit Method Comparison at 1% |\\n|-------------------------------|\\n| ML/Circuit | CS | Cascode | Two Stage | LNA | PA | Mixer | VCO |\\n| Lookup | 0.94\u00b10.005 | 0.888\u00b10.005 | 0.961\u00b10.011 | 0.998\u00b10.001 | 0.958\u00b10.004 | 0.997\u00b10.001 | 0.833\u00b10.015 |\\n| NN | 0.854\u00b10.023 | 0.971\u00b10.004 | 0.964\u00b10.02 | 0.998\u00b10.0 | 0.945\u00b10.005 | 0.994\u00b10.001 | 0.847\u00b10.022 |\\n| RF | 0.953\u00b10.004 | 0.944\u00b10.005 | 1.0\u00b10.0 | 0.995\u00b10.001 | 0.95\u00b10.005 | 0.996\u00b10.001 | 0.853\u00b10.024 |\"}"}
{"id": "krylov23a", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 2. Circuit Data Size Comparison for $D_0$ at 1%/\\n\\n| Circuit      | 5%       | 10%      | 20%      | 50%      | 90%      |\\n|--------------|----------|----------|----------|----------|----------|\\n| CS           |          |          |          |          |          |\\n| Cascode      |          |          |          |          |          |\\n| Two Stage LNA|          |          |          |          |          |\\n| PA           |          |          |          |          |          |\\n| Mixer        |          |          |          |          |          |\\n| VCO          |          |          |          |          |          |\\n\\n### Table 3. Circuit Data Size Comparison for $\\\\bar{D}_0^* \\\\epsilon$ at 1%/\\n\\n| Circuit      | 5%       | 10%      | 20%      | 50%      | 90%      |\\n|--------------|----------|----------|----------|----------|----------|\\n| CS           |          |          |          |          |          |\\n| Cascode      |          |          |          |          |          |\\n| Two Stage LNA|          |          |          |          |          |\\n| PA           |          |          |          |          |          |\\n| Mixer        |          |          |          |          |          |\\n| VCO          |          |          |          |          |          |\\n\\n#### Figure 13.\\nComparing different datasizes for $D_0$ in circuits: (a) cascode; (b) low-noise amplifier (LNA); (c) voltage-controlled oscillator (VCO); (d) mixer.\\n\\n#### Figure 14.\\nComparing different datasizes for $D_0$ in circuits: (a) common source amplifier (CS); (b) two-stage; (c) power amplifier (PA).\\n\\n### A.3. Comparing Datasizes\\n\\nIn this study, we assess the performance of various circuits by utilizing subsamples of varying sizes, including 5%, 10%, 20%, 50%, and 90% of the data. The 90% subsample corresponds to a range of 2700-3600 points, while the 5% subsample corresponds to approximately 150-200 points. Results indicate that the accuracy of the Two Stage circuit linearly increases from 56% to 93% as the subsample size increases from 5% to 90%. Similarly, for the $\\\\bar{D}_0^* \\\\epsilon$ method, accuracy increases from 81% to 97%. Notably, all circuits exhibit an accuracy higher than 80%, even when using only 5% of the data. However, the accuracy of the $D_0$ circuit is observed to drop to 20% for certain subsamples.\\n\\n### A.4. Comparing Datasets\\n\\nIn addition to our previous results, we present a table of circuit evaluations for each method at a 1% margin. It can be observed that the Power Amplifier, VCO, and Mixer circuits achieve the highest scores when utilizing our method. However, for less complex circuits such as the Common Source Amplifier, the $D_0^* \\\\epsilon$ method yields a 2% higher score compared to our method.\"}"}
{"id": "krylov23a", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 4. Circuit Comparison Info at 1%\\n\\n| Circuit | CS | Cascode | Two Stage | LNA | PA | Mixer | VCO |\\n|---------|----|---------|-----------|-----|----|-------|-----|\\n| D       | 0.7\u00b10.036 | 0.519\u00b10.043 | 0.985\u00b10.01 | 0.996\u00b10.001 | 0.945\u00b10.005 | 0.486\u00b10.06 | 0.378\u00b10.054 |\\n| D\u0304       | 0.957\u00b10.009 | 0.921\u00b10.033 | 0.990\u00b10.004 | 0.999\u00b10.0 | 0.970\u00b10.002 | 0.824\u00b10.019 | 0.713\u00b10.016 |\\n| D\u0304\u0304      | 0.542\u00b10.014 | 0.435\u00b10.026 | 0.877\u00b10.033 | 0.976\u00b10.003 | 0.370\u00b10.048 | 0.320\u00b10.011 | 0.540\u00b10.021 |\\n| D\u0306\u0306\u0306\u0306      | 0.801\u00b10.038 | 0.578\u00b10.033 | 0.518\u00b10.048 | 0.80\u00b10.024 | 0.768\u00b10.092 | 0.401\u00b10.022 | 0.501\u00b10.015 |\\n| D\u0306\u0306\u0306\u0306\u0306\u0306      | 0.847\u00b10.021 | 0.947\u00b10.019 | 0.984\u00b10.011 | 0.997\u00b10.001 | 0.943\u00b10.004 | 0.858\u00b10.025 | 0.827\u00b10.019 |\\n| D\u0306\u0306\u0306\u0306\u0306\u0306\u0306      | 0.936\u00b10.012 | 0.962\u00b10.007 | 0.981\u00b10.012 | 0.998\u00b10.001 | 0.948\u00b10.005 | 0.995\u00b10.001 | 0.835\u00b10.016 |\\n\\n**A.5. Comparing Circuits**\\n\\nAs seen in Table 7, a comparison of our proposed method is conducted against previous methods. However, due to the lack of standard benchmarks for circuits and limited data availability for many circuits, it should be noted that this comparison should be viewed as a general guide rather than a comprehensive evaluation. Nonetheless, it can be observed that our method demonstrates superior performance in comparison to previous methods, while also maintaining a small data size.\\n\\nFor each circuit, we also provide the following additional information:\\n\\n1. The size of the train dataset, number of parameters, number of points per parameter in Table 6,\\n2. Average performance error across all the circuits in Table 5,\\n3. Performance metric range for every circuit in Table 8,9,\\n4. Parameters range for every circuit in Table 10.\\n\\n### Table 5. Average performance error % for every circuit using $\\\\bar{D}^*$\\n\\n| Circuit | CS | Cascode | Two Stage | LNA | PA | Mixer | VCO |\\n|---------|----|---------|-----------|-----|----|-------|-----|\\n| Mean Error | 0.06\u00b10.0 | 0.04\u00b10.0 | 0.03\u00b10.0 | 0.0 | 1.29\u00b10.002 | 0.01\u00b10.0 | 1.13\u00b10.002 |\"}"}
{"id": "krylov23a", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 7. Comparing Results with the previous work\\n\\n| Performance Metric | This Work (%) | Best Reported (%) | Related Works |\\n|--------------------|---------------|-------------------|---------------|\\n| CS Gain            | 0.135 \u00b1 0.035 | < 2.6            | Devi et al. (2021) |\\n|                    |               |                   |               |\\n| Bandwidth          | 0.048 \u00b1 0.12  |                   |               |\\n| Power Consumption  | 0.0044 \u00b1 0.002|                   |               |\\n| Cascode Gain       | 0.0471 \u00b1 0.02 | \u2248 1              | Lourenc\u00b8o et al. (2019) |\\n|                    |               |                   | Mina et al. (2022) |\\n| Bandwidth          | 0.0433 \u00b1 0.01 |                   |               |\\n| Power Consumption  | 0.0222 \u00b1 0.007|                   |               |\\n| 2-Stage Gain       | 0.0226 \u00b1 0.018| 1.1              | Fukuda et al. (2017a) |\\n|                    |               |                   | M.V. & Harish (2020a) |\\n| Bandwidth          | 0.00001 \u00b1 0.000003 | NA          |               |\\n| Power Consumption  | 0.0716 \u00b1 0.031 | 3.7              |               |\\n| LNA Gain G          | 0.0028 \u00b1 0.001 | < 5              | Dumesnil et al. (2014) |\\n| NF                 | 0.007 \u00b1 0.001 |                   |               |\\n| PA Power Gain       | 1.207 \u00b1 0.14  | NA               |               |\\n| Drain Efficiency   | 1.361 \u00b1 0.2  |                   |               |\\n| PAE                | 1.30 \u00b1 0.19   | NA               |               |\\n| Mixer Conversion Gain | 0.005 \u00b1 0.0035 | NA          |               |\\n| Power Consumption  | 0.86 \u00b1 0.002 |                   |               |\\n| Swing              | 0.66 \u00b1 0.005 |                   |               |\\n| VCO Power Consumption | 0.017 \u00b1 0.1423 | NA          |               |\\n| Output Power       |                   |                   |               |\\n| Tuning Range       | 3.226 \u00b1 0.6293 |                   |               |\"}"}
{"id": "krylov23a", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 8. Range of Analog Voltage Amplifiers Performance Metrics\\n\\n| Performance Metric | CS Min | CS Max | Cascode Min | Cascode Max | Two-Stage Min | Two-Stage Max |\\n|--------------------|--------|--------|-------------|-------------|---------------|---------------|\\n| Gain (dB)          | 5.25   | 15.14  | 20.94       | 28.23       | 41.28         | 73.82         |\\n| Bandwidth (Hz)     |        |        | 8.5G        | 12.1M       | 1.01G         |\\n| Power Consumption (mW) | 0.57  | 1.34  | 0.38        | 0.56        | 1.32          | 2.00          |\\n\\n### Table 9. Range of Non-linear Circuits Performance Metrics\\n\\n| Circuit      | Power Gain (dB) | S | NF (dB) | Drain Efficiency (%) | PAE (%) | Conversion Gain | Power Consumption (mW) | Swing (mV) | Power Consumption (mW) | Output Power (mW) | Tuning Range (Hz) |\\n|--------------|-----------------|---|--------|----------------------|---------|----------------|------------------------|------------|------------------------|------------------|-------------------|\\n| LNA          | 12.76           | -25x-74 | -19.1 | -17.3 | 9.39 | 33.92 | 0.61 | 7.32 | 0.61 | 5.95 | 451K | 440M |\\n| PA           | 5.165           |         | 2.154 | 2.39 | 3.79 | 28.67 | 0.11 | 7.32 | 0.11 | 7.32 | 0.11 | 7.32 |\\n| Mixer        | 0.61            |         | 2.154 | 2.39 | 3.79 | 28.67 | 0.11 | 7.32 | 0.11 | 7.32 | 0.11 | 7.32 |\\n| VCO          | 3.9             |         | 2.154 | 2.39 | 3.79 | 28.67 | 0.11 | 7.32 | 0.11 | 7.32 | 0.11 | 7.32 |\\n\\n### Table 10. Design Parameters and Range of Variations\\n\\n| Circuit   | Variable | Start | Step | End |\\n|-----------|----------|-------|------|-----|\\n| CS        | M        | 1     | 0.2um | 6.6um |\\n|           | R        | 620   | 5    | 1450 |\\n| Cascode   | M        | 1     | 0.25um | 11.5um |\\n|           | M        | 2     | 0.2um | 5um |\\n|           | R        | 9k    | 125  | 11k |\\n| Two-Stage | M        | 1     | 0.5um | 30um |\\n|           | M        | 2     | 0.5um | 55.5um |\\n|           | M        | 4     | 0.5um | 9um |\\n| LNA       | M        | 1, 2  | 0.5um | 76.5um |\\n|           | L        | 9.4nH | 0.2nH | 10.8nH |\\n|           | L        | 747pH | 1pH  | 754pH |\\n|           | L        | 3.7nH | 0.1nH | 4.4nH |\\n| PA        | M        | 1, 2, 3, 4, 5, 6, 7, 8 | 0.5um | 22um |\\n|           | V        | 785mV | 5mV  | 815mV |\\n|           | V        | 760mV | 5mV  | 790mV |\\n| Mixer     | M        | 1     | 0.45um | 11.7um |\\n|           | M        | 17.1um | 0.9um | 23.4um |\\n|           | V        | 630mV | 30mV | 810mV |\\n| VCO       | M        | 1     | 0.45um | 11.7um |\\n|           | M        | 145um | 2um  | 159um |\\n|           | L        | 73um  | 2um  | 87um  |\\n|           | L        | 3.6nH | 0.1nH | 4.3nH |\"}"}
{"id": "krylov23a", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nAutomated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design. It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters. However, it is more common for a user to have threshold performance criteria rather than an exact target vector of feasible performance measures. In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications. We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90% at 5% error margin, while also improving data efficiency by upward of an order of magnitude. A demo of this system is available at circuits.streamlit.app\\n\\n1. Introduction\\n\\nOwing to the immense growth of consumer electronics over the last few decades, integrated circuitry using commercial CMOS/BiCMOS chip technologies has become a major sector of the semiconductor industry (Kamal, 2022). More specifically, fast innovation and skyrocketing demand in several industry segments, such as wireless communication and high-resolution imaging systems, has been driving interest in analog, radio-frequency, and millimeter-wave circuits and systems (Kamal, 2022). Despite the economic and technological importance of these types of circuits, contemporary design in research and industry is still predominantly manual, using advanced electronic design automation tools such as the Cadence Virtuoso (Martin, 2002) and the Keysight ADS (Kouhalvandi et al., 2018) circuit simulators. This heavy reliance on human design slows down and raises the costs of the development of future generations of electronic systems and should inevitably shift toward a more interactive design approach where humans and machines co-design analog circuits substantially faster.\\n\\nA recent growing literature on automated circuit design has considered the problem of finding the parameters of components in a given circuit that would induce a desired set of performance metrics (Mina et al., 2022). Learning to output such circuit parameters is typically framed in the supervised learning setting, where a model in a given model class \u2014 often a neural network \u2014 is trained on a dataset of simulated parameter\u2013metrics pairs to solve the inverse problem of mapping target performance metrics to circuit parameters that meet these requirements. A limiting factor in this approach is the large number of times that the circuit needs to be simulated to collect enough data for accurate learning. As we aim to support larger and more intricate circuits, precise simulation becomes slow, and data efficiency requisite.\\n\\nWe address two inverse problems. For the simpler one, described above and formalized in Section 2.1, a dataset is created by simulating a circuit with parameter values on a grid that covers a user-specified range. A neural network is then trained on this data to predict circuit parameters that would induce a desired performance vector. We evaluate this approach on a much larger variety of useful circuit topologies than has previously been done, and show that this inverse function is smooth and regular enough to be approximated from a much smaller number of examples than achieved before, namely around 600\u20134000 points, depending on circuit complexity, compared with 10,000 to 40,000 points in prior work (Fukuda et al., 2017b; Wang et al., 2018b; Lourenc\u00b8o et al., 2018; M.V . & Harish, 2020b). However, this approach has severely limited usability, because it requires the user to make a rather precise guess of a\"}"}
{"id": "krylov23a", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nfeasible combination of performance metrics for the model to recover. As the number of metrics of interest grows, in more complex circuits, the task of precisely specifying all metrics becomes daunting. We instead envision an interface for a user to specify a vector of performance thresholds, and propose a second inverse problem of mapping these thresholds into circuit parameters that satisfy them (Section 2.2).\\n\\nWhile this problem is natural for reinforcement learning algorithms (Settaluri et al., 2020), we propose a novel supervised learning method for constructing, from the same simulation data as in the simpler problem, a dataset for training and evaluating a model that predicts threshold-satisfying parameters. We show that training a neural network on this dataset solves this harder inverse problem an order of magnitude more efficiently than existing reinforcement learning methods, the latter using between 5500 and 40,000 simulations (Wang et al., 2018a; Settaluri et al., 2020).\\n\\nThis work contributes: (1) a novel and vastly more data-efficient method for generating, from circuit simulation data, a dataset for supervised learning of circuit design agents for the threshold specification problem; and (2) the to-date most extensive evaluation of automated circuit design methods on a diverse set of analog and radio frequency circuits, demonstrating the success of the method while also identifying a challenging circuit topology for future research. A demo of our proposed system is available at circuits.streamlit.app.\\n\\n2. Problem Statement\\n\\nHuman design through the use of advanced electronic design automation (EDA) tools (Afacan et al., 2021) is currently the primary method for designing electronic circuits. However, human-led design is a slow process and is falling behind the human\u2013computer co-design processes for digital circuits (Renner & Ek\u00b4art, 2003). In order to bridge the gap and allow for faster design of analog circuits, we aim to facilitate a system that can automatically generate the parameters of an analog circuit to meet a set of performance requirements.\\n\\nA good system should be able to function with good accuracy across a variety of different circuit topologies. In this paper, we therefore examine the problem of designing a diverse group of analog circuits, including single-stage amplifiers, multi-stage operational amplifiers, power amplifiers, low-noise amplifiers, nonlinear circuits such as mixers, and autonomous circuits such as voltage-controlled oscillators. It is noteworthy that the selected performance metrics, them- selves diverse across the various circuits, exhibit different kinds of correlations and tradeoffs.\\n\\n2.1. Exact Specification\\n\\nFor a specified circuit topology, let $n$ be the number of component parameters, such as resistances, transistor widths, and voltages. Let $X_1, \\\\ldots, X_n$ be the operational ranges of each of these parameters, and $X = \\\\times_{i=1}^n X_i$ the design space. We assume the availability of a simulator $f: X \\\\to Y$, where $Y = R^k_+$ is the positive orthant of the real vector space of $k$ performance metrics of interest.\\n\\nThe problem of design from exact specification is that of finding a function $g \\\\approx f^{-1}: Y \\\\to X$ such that, when a user specifies target performance $y \\\\in Y$, the system can suggest a design $\\\\hat{x} = g(y)$. Upon suggesting $\\\\hat{x}$, it can be simulated to measure its performance $\\\\hat{y} = f(\\\\hat{x})$. The error of the system is measured by the relative difference in its performance metrics $\\\\delta_i = |y_i - \\\\hat{y}_i|/y_i$. (1)\\n\\nFor evaluation, the relative error is averaged across multiple test points as well as across the $k$ metrics. We also measure the success rate as the fraction of test points with relative error within a given margin.\\n\\nWe note that, in a real-world system, users can input a target performance vector $y$ for which no circuit exists with low error. The system can use the simulator to check that the predicted circuit $g(y)$ is incorrect, but it is a hard problem to determine whether another circuit would be correct, particularly if the instance is out-of-distribution for the data used to train the system. We therefore focus on evaluating the system on in-distribution data $y \\\\in f(X)$, and leave the challenging and interesting question of out-of-distribution generalization to future work.\\n\\n2.2. Threshold Specification\\n\\nWhen manual circuit design is challenging, guessing a feasible performance vector $y \\\\in f(X)$ can be just as challenging, particularly if it consists of many metrics that are subject to intricate tradeoffs. Instead, it would be easier for a user to specify performance thresholds that the designed circuit should meet. We denote by $\\\\lambda_i$ the threshold direction of metric $i$, i.e. $\\\\lambda_i = 1$ or $-1$ respectively whether it is majorative (the more the better) or minorative (the less the better).\\n\\nThe problem of design from threshold specification (Figure 1) is that of finding a function $g: Y \\\\to X$ such that, when a user specifies target performance thresholds $y \\\\in Y$, the system can suggest a design $\\\\hat{x} = g(y)$. Upon suggesting $\\\\hat{x}$, it can be simulated to measure its performance $\\\\hat{y} = f(\\\\hat{x})$. The error of the system is measured by the relative difference in its performance metrics $\\\\delta_i = |y_i - \\\\hat{y}_i|/y_i$. (2)\"}"}
{"id": "krylov23a", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nThe suggested design $\\\\hat{x} = g(y)$ aims to meet the thresholds $y$ by having its simulated performance $\\\\hat{y} = f(\\\\hat{x})$ satisfy $\\\\lambda\\\\hat{y} \\\\geq \\\\lambda y$ element-wise. The error of this system is measured by the relative amount of threshold violation $\\\\delta_i = \\\\max\\\\{\\\\lambda_i(y_i - \\\\hat{y}_i), 0\\\\}$.\\n\\nAs before, we measure success rate by the fraction of test data for which the thresholds for all metrics are met up to a given error margin.\\n\\nTo evaluate a system solving the threshold specification problem, we should use threshold queries that follow a similar distribution to that of real users. Leaving user studies to future work, we approximate this distribution by perturbing simulated performance metrics similarly to Lourenc\u00b8o et al. (2018). Given the measured performance $y = f(x)$ of a simulated circuit $x$, we sample standard uniform perturbations $u \\\\sim U_k$ for the $k$ metrics, independent and identically distributed (i.i.d), and use the perturbed vector $\\\\tilde{y}_i = (1 - \\\\epsilon\\\\lambda_i u_i)y_i$ as the threshold query. Here $\\\\epsilon$ is the perturbation magnitude hyperparameter; in this work we use $\\\\epsilon = 0.2$. Note that, by construction, $\\\\lambda y \\\\geq \\\\lambda \\\\tilde{y}$, so that there always exists a circuit (namely, $x$) that meets the threshold $\\\\tilde{y}$.\\n\\n### 3. Related Work\\n\\n#### 3.1. Digital Circuits vs. Analog Circuits\\n\\nDigital circuit automation and computer-assisted design (CAD) has progressed steadily over the past few decades (Micheli, 1994; Brunvand, 2010). The invariant architecture of the building blocks in digital design allows the application of graph-theoretic approaches that treat the problem of digital circuit design as a graph connectivity problem, which has led to a large body of work in optimization of digital design (Boyd et al., 2005; Kunz & Pradhan, 1994; Grover & Chaudhary, 2014). Analog circuits, on the other hand, involve a set of unique design challenges that are not considered in the digital domain. First, analog circuits have a broad range of architectures, and each building block may be optimized individually with respect to a performance metric before all the blocks are integrated into the circuit. Second, in digital design, there is a small set of critical performance metrics and in most cases only power consumption, area, and speed are considered. In contrast, in the analog domain, a variety of performance metrics are present, and optimization of an analog circuit becomes a higher-dimensional problem. Third, in analog circuits, passive components such as capacitors, inductors, and resistors are also deployed, completely changing the dynamics of the circuit design and weakening the relation between graph-theoretic properties and circuit performance.\\n\\n#### 3.2. Automated Analog Circuit Design\\n\\nAutomating the design of analog circuits has been studied before, particularly in operational amplifiers (op-amps) that are specified by their voltage gain, bandwidth, and power consumption (for a survey, see Mina et al. (2022)). Wang et al. (2018a) propose a reinforcement learning (RL) approach to designing 3-stage amplifier circuits from threshold specification. Similarly, Settaluri et al. (2020) adopt RL to design 2-stage operational amplifiers. While RL is readily amenable to threshold constraints, it suffers from poor data efficiency compared with supervised learning approaches (Mina et al., 2022). Vural et al. (2015) use supervised regression to design another type of circuits, a 4-bit current-steering Digital-to-Analog converters (DAC), from exact specification of the performance metrics. Other works have used supervised learning to design various op-amps (Harsha & Harish, 2020; Lourenc\u00b8o et al., 2018; Murphy & McCarthy, 2021) with varying \u2014 and often incomparable \u2014 data efficiency (Mina et al., 2022).\\n\\nIn this paper, we step beyond the scope of op-amp design to additionally investigate the design of other critical analog circuit blocks, in particular radio-frequency electronic circuits that are commonly used in cellular communication applications (Razavi, 2012). It is noteworthy that some of the selected circuits, e.g., mixers and oscillators, are among the most nonlinear analog circuits with high sensitivity to variations in design parameters. We further show that design agents for amplifiers as well as more intricate circuits can be learned by supervised regression from much smaller datasets than previously accomplished. Finally, we learn to design these circuits from threshold specification, in contrast to most previous supervised learning works. Lourenc\u00b8o et al. (2018) previously considered this setting, and proposed a method that we reproduce in this paper under the name $D_m^\\\\epsilon$. We show that this method can lead to suboptimal performance, analyze the reason through an ablation study, and propose a new method that mitigates this issue.\\n\\n### 4. Method\\n\\nWe use supervised learning to approximate the inverse of the simulator function mapping circuit parameters to performance metrics (Figure 2). We interface an external simulator to generate a dataset $D_0$ consisting of circuit parameter vectors $x \\\\in \\\\mathbb{R}^n$ and their respective measured performance metrics vectors $y \\\\in \\\\mathbb{R}^k$. We (optionally) pass this dataset through a filtering pipeline that prepares it for solving the threshold specification problem (Section 2.2). Finally, we employ a supervised learning algorithm, such as gradient-based optimization, to train a design agent. In this section we describe the system components: the simulator, the agent model, and several alternatives for the filtering pipeline.\"}"}
{"id": "krylov23a", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to Design Analog Circuits to Meet Threshold Specifications\\n\\nFigure 2. Proposed method for automated design from threshold specification. Circuit parameters are sampled within a user-defined range, simulated, and measured. Performance metrics are randomly adjusted to sample threshold queries. A data filtering process then generates training data for supervised learning a circuit design agent that generates circuits to meet threshold requirements.\\n\\n4.1. Simulator\\n\\nIn this work, we use the NgSpice simulator (Nenzi & Vogt, 2011). The circuit topology and its fixed parameters, as well as the simulation parameters, are provided to the simulator via a format called netlist (Lannutti et al., 2012). In addition to the netlist, the simulator loads analysis commands that determine how it measures the performance metrics of interest. For some circuits, multiple analysis commands are given to measure the circuit under distinct conditions.\\n\\nThe external simulator is wrapped by a Python interface to allow easy access to two functionalities. First, to generate simulation data, a user inputs the range and step size of each circuit parameter, and the simulator loops through this grid to output a dataset $D_0$ of parameter\u2013metrics pairs. Second, to evaluate the trained model, predicted circuit parameters are input to the simulator, and the measured performance is compared with the target performance.\\n\\n4.2. Agent Model\\n\\nBefore the raw data from the simulator can be put through the model, we apply a few data pre-processing steps. The different features of the data have vastly different scales. In order to allow the model to learn across such different scales, we first shift and scale all values to the range $[-1, 1]$. This normalization is applied both to the performance metrics before they are fed to the model and to the ground-truth circuit parameters used for training, and an appropriate inverse operator is applied to the model's parameter predictions.\\n\\nIn this work, we experiment with three different agent models. The main model is a neural network with an architecture of a simple multi-layer perceptron, trained with the Adam optimizer (Kingma & Ba, 2015). The network takes in a vector of desired performance metrics and predicts a vector of circuit parameters, which is then compared with the ground-truth parameters using an absolute ($L_1$) loss. The sizes of the first and last layers of the network are adjusted to reflect the number of performance metrics and circuit parameters, respectively, which are different for each experiment described in Section 5. The architecture is otherwise constant across experiments and detailed in Appendix A.1.\\n\\nAn alternative model we consider is ensembles of decision trees trained with the Random Forests algorithm (Breiman, 2001). Finally, to assess the need for any learning at all, we compare with a lookup method that memorizes the training data and selects, for each test performance vector, the training circuit that minimizes the relative performance error.\\n\\n4.3. Filtering Pipeline\\n\\nThe problem of design from exact specification (Section 2.1) can be solved by supervised learning, in which the training set is the simulation dataset $D_0$, inverted so that performance metrics $y$ are inputs and circuit parameters $x$ are outputs. However, this method is unlikely to be sufficient for the threshold specification problem (Section 2.2), in which some threshold vectors are out-of-distribution for $D_0$, because no circuit has them as its exact performance. We therefore propose a filtering pipeline that constructs, from the same $D_0$, a second dataset which, when used for supervised learning, trains a model that predicts circuit parameters from threshold specification.\\n\\nTo prepare a circuit for the threshold specification problem, two properties of the metrics vector need to be provided. First, because some metrics, such as gain or bandwidth, are majorative (the more the better), while others, such as power consumption, are minorative (the less the better), we need to know for each metric $i$ its threshold direction $\\\\lambda_i \\\\in \\\\{-1, 1\\\\}$.\\n\\nSecond, a specification asking for the highest gain at power consumption at most $p$ is different from one asking for the lowest power consumption that achieves gain at least $g$. We may therefore have a preference order over metrics, such that we lexicographically prefer improving $y_i$ over improving $y_j$, whenever $i < j$, as long as all threshold constraints are approximately met. We say that $y$ is lexicographically better than $y'$ if there exists $i$ such that $y_j = y'_j$ for all $j < i$ and $\\\\lambda_i y_i > \\\\lambda_i y'_i$.\\n\\nThe filtering pipeline starts by finding, for each performance vector $y \\\\in D_0$, all feasible performance vectors $y' \\\\in D_0$ that meet the threshold specification $y$, i.e.\\n\\n$$F(y; D_0) = \\\\{(x, y') \\\\in D_0 | \\\\lambda y' \\\\geq \\\\lambda y\\\\}. \\\\quad (4)$$\\n\\nThe design agent needs to map the threshold specification $y$ to one such $x \\\\in F(y)$, but it may not be immediately clear which one. We hypothesize that, crucially to learning with high success rate from small datasets, our training dataset must be systematic in selecting a representative of $F(y)$. This systematicity manifests as a pattern that the learning algorithm can generalize, whereas including the entire $F(y)$ or selecting from it sporadically might lead to conflicts that\"}"}
