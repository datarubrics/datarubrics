{"id": "delvaux22_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"T. B\u00e4nziger, K.R. Scherer, \\\"The role of intonation in emotional expressions\\\", Speech Communication, vol. 46, pp. 252-267, 2005.\\n\\nK. R. Scherer, \\\"Component models of emotion can inform the quest for emotional competence\\\", In G. Matthews, M. Zeidner, & R. D. Roberts (Eds), The science of emotional intelligence: Knows and unknows, New York: Oxford University Press, pp. 101-126, 2007.\\n\\nK. R. Scherer, \\\"Vocal markers of emotion: Comparing induction and acting elicitation\\\", Computer Speech & Language, vol. 27, no. 1, pp. 40\u201358, 2013.\\n\\nJ.A. Singer, P.S. Blagov, \\\"Classification system and scoring manual for self-defining autobiographical memories\\\", Unpubl. Manuscr Conn Coll, 2000.\\n\\nP.S. Blagov, J.A. Singer, \\\"Four dimensions of self-defining memories (specificity, meaning, content, and affect) and their relationships to self-restraint, distress, and repressive defensiveness\\\", J Pers, vol. 72, pp. 481\u2013511, 2004.\\n\\nJ. L. Nandrino, M. C. Gandolphe, \\\"Characterization of Self-Defining Memories in Individuals with Severe Alcohol Use Disorders After Mid-Term Abstinence: The Impact of the Emotional Valence of Memories\\\", Alcohol Clin Exp Res, vol. 41, pp. 1484\u20131491, 2017.\\n\\nB.M. Appelhans, L.J. Luecken, \\\"Heart rate variability as an index of regulated emotional responding\\\", Rev Gen Psychol, vol. 10, pp. 229, 2006.\\n\\nD. Tranel, \\\"Electrodermal activity in cognitive neuroscience: neuroanatomical and neuropsychological correlates\\\", Cogn Neurosci Emot, pp. 192\u2013224, 2000.\\n\\nA. Piolat, R. Bannour, \\\"An example of text analysis software (EMOTAIX-Tropes) use: The influence of anxiety on expressive writing\\\", Current Psychology Letters, vol. 25, Issue 2, 2009.\\n\\nA.B. Warriner, V. Kuperman, M. Brysbaert, \\\"Norms of valence, arousal, and dominance for 13,915 English lemmas\\\", Behavior research methods, vol. 45, no. 4, pp. 1191-1207, 2013.\\n\\nJ. Goldman, \\\"EasyAlign: An automatic phonetic alignment tool under praat\\\". Interspeech'11, 12th annual conference of the international speech communication association, 2011.\\n\\nP. Boersma, D. Weenink, D. \\\"Praat: doing phonetics by computer\\\" [Computer program]. Version 6.0.50, retrieved 31 March 2019 from http://www.praat.org/.\\n\\nA. Lavall\u00e9e, X. Salopp\u00e9, M.C. Gandolphe, L. Ott, T. Pham, J.L. Nandrino (in revision). \\\"What effort for retrieving self-defining memories? Specific autonomic responses for integrative and non-integrative memories\\\".\\n\\nA.R. Sutin, R.W. Robins, \\\"Continuity and correlates of emotions and motives in self-defining memories\\\", J Pers, vol. 73, pp. 793\u2013824, 2005.\\n\\nW. Wood, M. Conway, \\\"Subjective Impact, Meaning Making, and Current and Recalled Emotions for Self-Defining Memories\\\", J Pers, vol. 74, pp. 811\u201346, 2006.\\n\\nM.C. Gandolphe, J.L. Nandrino, G. Delelis, C. Ducro, A. Lavallee, X. Salopp\u00e9, A.A. Moustafa, M. El Haj, \\\"Positive facial expressions during retrieval of self-defining memories\\\", Journal of Integrative Neuroscience, pp. 1\u201310, 2017.\"}"}
{"id": "delvaux22_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Vocal cues in emotion encoding are rarely studied based on real-life, naturalistic emotional speech. In the present study, 20 speakers (10 male, 10 female) aged 25 to 35 were recorded while orally telling 5 successive self-defining autobiographic memories (SDM). By definition, this task is highly emotional, although emotional load and emotion regulation are expected to vary across SDM. Seven acoustic parameters were extracted: MeanF0, MedianF0, StandardDeviationF0, MinF0, MaxF0, Duration and Speech Rate. All SDM were manually transcribed, then their emotional lexicon was analysed using Emotaix.\\n\\nFirst, speech productions were examined in reference with SDM characteristics (specificity, integrative meaning and affective valence) as determined by 3 independent investigators. Results showed that overall the speech parameters did not change over the time course of the experiment, or as a function of integrative meaning. Specific memories were recounted at a higher speech rate and at greater length than non-specific ones. SDM with positive affective valence were shorter and included less variability in fundamental frequency than negative SDM.\\n\\nSecond, emotionally-charged (positive vs. negative; high vs. low arousal) vs. emotionally-neutral utterances as to Emotaix classification were compared over all SDM. Only a few significant effects were observed, which led us to discuss the role of emotion regulation in the SDM task.\\n\\nIndex Terms: emotions, self-defining memories, emotion regulation, emotion encoding, autobiographical memory, speech production.\"}"}
{"id": "delvaux22_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"integration of meaning and affective valence) in order to investigate how vocal cues may reflect some properties of the emotional processes involved in autobiographic memory.\\n\\nSecond, a content analysis of all the SDM was conducted using the Emotaix scenario so as to compare the acoustic parameters of emotionally charged (positive vs. negative; high vs. low arousal) vs. emotionally neutral utterances.\\n\\n2. Material and methods\\n\\n2.1. Task and participants\\n\\nTwenty speakers (10 male, 10 female) aged 25 to 35 participated in the experiment. Of a higher education level, they were recruited through an advertisement on a social network. The participants showed no sign of having any serious psychological disorder or somatic illness, as per an interview with a psychologist.\\n\\nParticipants were asked to orally recount five SDM while their speech productions, facial expressions and psychophysiological parameters were recorded. SDM were elicited following specific instructions: \\\"You are invited to recount five events in your life. These events must be important in defining who you are. In other words, these memories should refer to events that help you to understand who you are as an individual. These events should also be events that you would share with someone if you wanted that person to understand you in a fundamental way. The events may be positive or negative memories; the only important aspect is that they should lead to strong feelings. The memories should be events that you have thought about many times. They should also be familiar to you like a picture you have looked at a lot, or a song you have learned by heart.\\\"\\n\\nSince one participant failed to recall a fifth SDM, the total of collected SDM was 99.\\n\\n2.2. Coding of SDM\\n\\nSDM were coded a posteriori (based on the video recordings) and independently by three investigators using Singer and Blagov's classification system and scoring manual for self-defining autobiographical memories [6]. They were coded as \\\"specific\\\" if they were a memory of a single specific brief event including details, and as \\\"nonspecific\\\" when they referred to a memory of long or repeated events. SDM were considered as \\\"integrative\\\" if memories were directly associated with learning about oneself, others or the environment, and \\\"nonintegrative\\\" if they were pure narratives without integration of the recalled experiences. Finally, SDM affective valence was coded as positive, negative, neutral or mixed (i.e. both negative and positive) based on the emotional vocabulary used by the participant [8]. After some training, interrater agreement proved substantial, as evidenced for by Cohen's kappa (specificity: k=0.79; affective valence: k=0.87; integrative meaning: k=0.8).\\n\\n2.3. Content analysis\\n\\nAll 99 SDM were manually transcribed, for a total of 5 hours 39 minutes of speech and 58956 words. A content analysis was performed using the EMOTAIX-Tropes text analysis software [11], then manually verified by two experts. The software automatically detects and counts emotional items, then classifies them based on their valence. More specifically, EMOTAIX comprises 2x28 basic emotional categories organized into three hierarchical levels on either side of a hedonic axis (positive and negative valence).\\n\\nThe present study is based on the 18 \\\"supercategories\\\" from the EMOTAIX classification, i.e. 9 of negative valence and 9 of positive valence (Table 1). Another, customized regroupment of these 18 categories was made in terms of arousal, i.e. high arousal vs. low arousal. Specifically, all 56 basic emotional categories were assigned an arousal value from 1 (low activation) to 9 (high activation), following norms [12], and the mean score over all relevant descriptors was used to classify each of the 18 supercategories into two groups: High arousal (mean score > 5) vs. Low arousal (mean score < 5).\\n\\nFor example, kindness {goodness, softness, patience, humility} achieved a mean score of 3.96 and was thus classified into the \\\"low arousal\\\" group, whereas happiness {bliss, joy, laughter} achieved a mean score of 6.5, and was thus considered as a \\\"high arousal\\\" emotion.\\n\\nTable 1: Classification of the 18 emotional supercategories identified by Emotaix into two groups based on valence (positive vs. negative) or arousal (high vs.low)\\n\\n| Valence-based classification (Emotaix) | Arousal-based classification (Customized) |\\n|---------------------------------------|----------------------------------------|\\n| Positive affection                     | High affection                          |\\n|                                       | kindness                                |\\n|                                       | happiness                               |\\n|                                       | courage                                 |\\n|                                       | lucidity                                |\\n|                                       | hate                                    |\\n|                                       | spirit                                  |\\n|                                       | aggressiveness                          |\\n|                                       | relief                                  |\\n|                                       | madness                                 |\\n|                                       | satisfaction                            |\\n|                                       | depression                              |\\n|                                       | calm                                    |\\n|                                       | frustration                            |\\n| Negative                              | Low affection                           |\\n|                                       | kindness                                |\\n|                                       | aggressiveness                          |\\n|                                       | lucidity                                |\\n|                                       | suffering                              |\\n|                                       | spirit                                  |\\n|                                       | madness                                 |\\n|                                       | relief                                  |\\n|                                       | depression                              |\\n|                                       | satisfaction                            |\\n|                                       | disorder                                |\\n|                                       | calm                                    |\\n|                                       | frustration                            |\\n|                                       | suffering                              |\\n\\n2.4. Speech analysis\\n\\nOrthographic transcriptions were aligned with speech productions using EasyAlign [13]. Acoustic analyses were carried out with Praat [14]. After basic signal filtering, fundamental frequency was extracted every 5 ms using gender-specific parameters. Seven acoustic parameters were computed: MeanF0, MedianFo, StandardDeviationF0 (SDF0), MinF0, MaxF0, Duration and SpeechRate (in words per second). These parameters were computed (i) over the entire SDM; (ii) separately for each utterance in which an emotional item was identified by EMOTAIX, as well as for the emotionally neutral utterances forming the rest of the SDM.\\n\\nStatistical analyses were performed using SPSS \u00a9 20.\"}"}
{"id": "delvaux22_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The expression of emotions in SDM was studied by analyzing speech productions recorded during a task involving high vs. low arousal emotions, which were expected to elicit different acoustic parameters. The study involved 20 participants who were tasked with recalling emotionally charged memories. The emotional speech utterances, especially those containing a lexical item of negative valence, were longer and included more variability in fundamental frequency than negative SDM.\\n\\nRegarding affective valence, positive SDM proved significantly different from negative SDM in terms of MedianF0, MeanF0, and a significant difference of negligible size in SDF0 or MaxF0. MaxF0 was lower for positive SDM than for negative SDM.\\n\\nFirst, speech productions were examined in reference with nonemotional portions (\\\"EMO\\\" vs. \\\"nonEMO\\\"). D Differences between emotional and nonemotional portions were typically made of several consecutive utterances interspersed with short pauses. Moreover, MinF0 was significantly higher in EMO than in nonEMO samples. In terms of F0, there was no related difference in terms of SDF0 or MaxF0. SDF0 was lower for positive SDM than for negative SDM. In contrast, MeanF0 was higher in EMO than in nonEMO.\\n\\nData were aggregated for each category over the 5 SDM of the experiment. For significant differences between emotional and nonemotional categories, the grouping of emotionally related parameters, i.e. MeanF0, MedianF0, SDF0, and MaxF0, was performed using Wilcoxon signed ranks tests. Second, we compared specific SDM with non-specific SDM (2.7 words/sec). In terms of F0, there was no related difference in terms of SDF0 or MaxF0. SDF0 was lower for positive SDM than for negative SDM. Similarly, for negative SDM (242Hz vs. 279Hz; Z = 3.2), aspects were found higher for negative SDM than for positive SDM.\\n\\nConcerning valence, positive SDM proved significantly different from negative SDM in terms of Integration, where emotional integration was found to be higher in positive SDM than in negative SDM. However, the size of the effect was considerably smaller.\\n\\nAs nonspecific ones, speech rate was found significantly higher for specific SDM (92s vs. 75s; U = 548, p < .001), while MaxF0 was lower for positive SDM than for negative SDM (240s vs. 130s; Z = 3.81, p = .001). Moreover, MinF0 and MaxF0. This was to be expected given the gender related difference in F0 baseline: average MeanF0 was 104Hz for male speakers and 110Hz for female speakers. Gender yielded significant differences in terms of Integration, with Gender as a subject factor, dependent variables were computed over the entire SDM. It revealed that \\\"male\\\" did not allow for significant acoustic differences to emerge; while \\\"female\\\" was significantly lower in EMO than in nonEMO.\\n\\nSecond, we focused on emotionally charged utterances as per the EMOTAIX analysis, i.e. either the emotional portions or the neutral ones. D Data were aggregated for each category over the 5 SDM of the experiment. Using a Wilcoxon signed ranks tests, aspects were carried out in order to test for significant differences between specific vs. non specific SDM (2.7 words/sec): U = 156, p = .051). As to variations between POS and NEG, positive SDM are shown to elicit more related parameters, i.e. MeanF0, MedianF0, SDF0, and MaxF0. This result was unexpected since in a recent related work, integration of meaning did not change over the time course of the experiment, neither its interaction with Gender yielded significant differences. It revealed that \\\"POS\\\" did not allow for significant acoustic differences to emerge while \\\"NEG\\\" was significantly different from neutral utterances.\\n\\nMoreover, MinF0 and MaxF0. This was to be expected given the gender related difference in F0. In contrast, Gender did not allow for significant acoustic differences to emerge. As to variations between POS and NEG, positive SDM are shown to elicit more related parameters, i.e. MeanF0, MedianF0, SDF0, and MaxF0. This result was unexpected since in a recent related work, integration of meaning did not change over the time course of the experiment. Neither its interaction with Gender yielded significant differences.\"}"}
{"id": "delvaux22_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Descriptive statistics. MinF0, MaxF0, MeanF0, MedianFo, SDF0, Duration and SpeechRate (computed over the entire SDM) as a function of SDM characteristics: Integration, Specificity, Valence.\\n\\n| Integration        | Mean | Median | SDF0 | Duration | SpeechRate |\\n|--------------------|------|--------|------|----------|------------|\\n| Integrative        | 105  | 148,8  | 19,7 | 144,5    | 224,6      |\\n| Nonintegrative     | 107,6| 148,1  | 18,6 | 143,8    | 183,4      |\\n\\n| Specificity        | Mean | Median | SDF0 | Duration | SpeechRate |\\n|--------------------|------|--------|------|----------|------------|\\n| Specific           | 103,6| 144,6  | 18,8 | 140,5    | 239,7      |\\n| Nonspecific        | 111,9| 156,9  | 20,1 | 152      | 130,2      |\\n\\n| Valence            | Mean | Median | SDF0 | Duration | SpeechRate |\\n|--------------------|------|--------|------|----------|------------|\\n| Positive           | 103,4| 144,1  | 17   | 140,2    | 138,6      |\\n| Negative           | 112,9| 159,6  | 21,5 | 154,5    | 252,2      |\\n| Neutral            | 114,2| 159,4  | 18,8 | 154,9    | 159,2      |\\n\\nConcerning the task, although retrieving SDM is typically described as a highly emotional task [e.g. 16, 17], it might result in emotional effects that are too weak to be detected in speech, because they are not associated with direct emotional experiences but only with the emotional content of events retrieved from memory. Moreover, as a rule real-life, naturalistic speech tokens do not give direct access to emotions because their expression is controlled in accordance with display rules (e.g. politeness) and strategic concerns [5]. In fact, the originality of the experimental task is that emotion expression in SDM can be attributed to the retrieval of the original emotional experience and/or to the emotional regulation of the retrieved memories [18].\\n\\nFor example, emotional regulation may be responsible for one result that could appear as counter-intuitive on first examination, i.e. the fact that EMO utterances had higher MinF0 and lower MaxF0, thus decreased F0 range, in comparison with nonEMO utterances.\\n\\nIn sum, self-defining memories are particular memories, at the crossroad between cognitive and emotional processes.\\n\\nOther reasons for the limited effects sometimes observed here may regard the way emotionally charged utterances were detected then specified, i.e. via a content analysis supervised by EMOTAIX. A first concern relates to the fact that the EMOTAIX scenario is basically organized across a hedonic axis (positive vs. negative valence), while arousal might be the primary dimension to correlate with F0 and speech rate variations. Note however that we found no difference between high-arousal and low-arousal emotional utterances in the extracted acoustic parameters. More fundamentally, it is possible that EMOTAIX appropriately detect the utterances which could carry emotional effects, without them being actually present every time (due to some of the factors detailed above). In this line of thought, we plan to reverse the perspective on our data: future analyses will entail a \u201cbottom-up strategy\u201d, starting from the distributional properties of the acoustic parameters themselves in order to identify potential emotionally charged utterances in each SDM, then checking whether or not these utterances were indeed more frequently identified by EMOTAIX as emotional speech.\\n\\nAcknowledgements\\n\\nV\u00e9ronique Delvaux is a research associate of the Fund for Scientific Research\u2013FNRS, Belgium. The authors wish to thank the organisms supporting the Memantemo project: the French Agence Nationale de la Recherche (ANR-11-EQPX-0023), the FEDER SCV-IrDIVE European program, the Hauts-de-France Region and the University of Mons. Special thanks to Florian Sanssen for his valuable contribution to data collection.\\n\\nReferences\\n\\n[1] T., Johnstone, K., Scherer, \\\"Vocal communication of emotion\\\". In: Lewis, M., Haviland, J. (Eds.), Handbook of emotion, second ed., New York: Guilford, pp. 220\u2013235, 2000.\\n[2] K.R. Scherer, \\\"Vocal communication of emotion: a review of research paradigms\\\", Speech communication, vol. 40, pp. 227-256, 2003.\"}"}
