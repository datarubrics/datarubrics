{"id": "dineley23_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\n[1] S. Latif, J. Qadir, A. Qayyum, M. Usama, and S. Younis, \u201cSpeech Technology for Healthcare: Opportunities, Challenges, and State of the Art,\u201d IEEE Rev. in Biomed. Eng., vol. 114, pp. 10\u201321, Nov. 2019.\\n\\n[2] E. V. Miley, F. Schaeffler, J. Beck, M. Eichner, and S. Cowen, \u201cAssessing Acoustic Voice Measures,\u201d IEEE J. Sel. Top. Signal Process., vol. 10, no. 4, p. 292, Apr. 2016.\\n\\n[3] S. Jannetts, F. Schaeffler, J. Beck, and S. Cowen, \u201cAssessing Acoustic Voice Measures,\u201d IEEE J. Sel. Top. Signal Process., vol. 10, no. 4, p. 292, Apr. 2016.\\n\\n[4] R. Y. Maryn, F. Ysenbaert, A. Zarowski, and R. Vanspauwen, \u201cExploring the feasibility of smart phone microphone for measurement of acoustic voice parameters,\u201d Proc. INTERSPEECH 2015, 272:11, vol. 272, no. 11, pp. 3391\u20133399, Jul. 2015.\\n\\n[5] P. J. Snyder, N. Cummins, S. Scherer, J. Krajewski, S. Schnieder, and T. F. Quatieri, \u201cDissociating COVID-19 from other respiratory infections based on acoustic voice analysis,\u201d IEEE J. Sel. Top. Signal Process., vol. 13, no. 1, pp. 7217\u20137227, Mar. 2021.\\n\\n[6] S. L. Atif, J. Qadir, A. Qayyum, M. Usama, and S. Younis, \u201cSpeech Technology for Healthcare: Opportunities, Challenges, and State of the Art,\u201d IEEE Rev. in Biomed. Eng., vol. 114, pp. 10\u201321, Nov. 2019.\\n\\n[7] D. M. Low, K. H. Bentley, and S. S. Ghosh, \u201cAutomated voice analysis for Parkinson\u2019s speech analysis,\u201d IEEE J. Sel. Top. Signal Process., vol. 77, pp. 2073\u20132084, Dec. 2021.\\n\\n[8] S. A. Zollinger and H. Brumm, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 14, Jan. 1938.\\n\\n[9] T. Talkar, D. M. Low, A. J. Simpkin, S. Ghosh, D. T. Depypere, and T. F. Quatieri, \u201cA review of depression and suicide risk assessment from speech pattern as an alternative to clinical depression,\u201d J. Telemed. Telecare, vol. 221, Jun. 2018.\\n\\n[10] T. A. Arroyave et al., \u201cNeuroSpeech: An open source tool for analysis of speech for neurological disorder detection,\u201d J. Telemed. Telecare, vol. 221, Jun. 2018.\\n\\n[11] P. Hecker, N. Steckhan, F. Eyben, B. W. Schuller, and B. Schuller et al., \u201cParalinguistics in speech and language processing,\u201d J. Acoust. Soc. Amer., vol. 14, no. 4, p. e29510, Apr. 2022.\\n\\n[12] P. J. Cho et al., \u201cDemographic Imbalances Resulting From the Bring Your Device Study Design,\u201d J. Acoust. Soc. Amer., vol. 14, no. 4, p. e29510, Apr. 2022.\\n\\n[13] B. Schuller et al., \u201cFitting Linear Mixed-Effects Models Using the R Package lme4,\u201d J. Stat. Softw., vol. 61, no. 1, pp. 1\u201325, Jan. 2015.\\n\\n[14] D. Bates, M. M\u00e4chler, B. M. Bolker, and S. Walker, \u201cFitting Linear Mixed-Effects Models Using the R Package lme4,\u201d J. Stat. Softw., vol. 4, no. 1, pp. 1\u201348, May 2009.\\n\\n[15] B. Schuller et al., \u201cParalinguistics in speech and language processing,\u201d J. Acoust. Soc. Amer., vol. 14, no. 4, p. e29510, Apr. 2022.\\n\\n[16] M. M. S. Krichen, \u201cAnomalies Detection through Smartphone Sensors: A Review,\u201d IEEE Sens. J., vol. 21, no. 15, pp. 7237\u20137250, Jul. 2021.\\n\\n[17] A. P. Vogel, P. Maruff, and A. Smith, \u201cStandardization of pitch and fundamental frequency settings in voice acoustic analysis,\u201d Voice Lang. Res., vol. 20, no. 2, pp. 133\u2013141, Apr. 2002.\\n\\n[18] L. G. Johnson, \u201cThe Relevance of Vowel, Gender, Vocal Intensity, and Vocal Coordination, and Phonemic Patterns,\u201d Voice Lang. Res., vol. 20, no. 2, pp. 133\u2013141, Apr. 2002.\\n\\n[19] N. Cummins, A. Baird, and B. W. Schuller, \u201cSpeech analysis and voice pathology screening,\u201d IEEE J. Sel. Top. Signal Process., vol. 11, no. 1, pp. 2377\u20132394, Feb. 2017.\\n\\n[20] M. McAuliffe, M. Socolof, S. Mihuc, M. Wagner, and M. Carding, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 116, Feb. 2000.\\n\\n[21] W. F. Stoddard, \u201cInfluence of Smartphones and Software on Acoustic Voice Measures,\u201d J. Voice, vol. 34, no. 2, pp. 292\u2013298, Apr. 2020.\\n\\n[22] J. H. N. Arroyave et al., \u201cNeuroSpeech: An open source tool for analysis of speech for neurological disorder detection,\u201d J. Telemed. Telecare, vol. 221, Jun. 2018.\\n\\n[23] A. M. Calero, J. K. W. Bouchard, and S. V. J. Al. A. C. Lammert, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 356, 2021 272:11, vol. 272, no. 11, pp. 3391\u20133399, Jul. 2015.\\n\\n[24] B. H. Shin, G. Y. J. Kim, and S. Y. J. Kim, \u201cExploring the feasibility of smart phone microphone for measurement of acoustic voice parameters,\u201d Proc. INTERSPEECH 2015, 272:11, vol. 272, no. 11, pp. 3391\u20133399, Jul. 2015.\\n\\n[25] T. W. Powell, \u201cA comparison of English reading passages for Standard English Passages,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[26] B. J. Denes, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[27] V. S. G. G. C. J. W. Ewing, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[28] S. L. Atif, J. Qadir, A. Qayyum, M. Usama, and S. Younis, \u201cSpeech Technology for Healthcare: Opportunities, Challenges, and State of the Art,\u201d IEEE Rev. in Biomed. Eng., vol. 114, pp. 10\u201321, Nov. 2019.\\n\\n[29] V. Van Heuven, \u201cPRAAT, a system for doing Prosodic, Articulatory, and Acoustic Research on Speech,\u201d J. Acoust. Soc. Amer., vol. 116, Feb. 2000.\\n\\n[30] D. Bates, M. M\u00e4chler, B. M. Bolker, and S. Walker, \u201cFitting Linear Mixed-Effects Models Using the R Package lme4,\u201d J. Stat. Softw., vol. 61, no. 1, pp. 1\u201325, Jan. 2015.\\n\\n[31] M. McAuliffe, M. Socolof, S. Mihuc, M. Wagner, and M. Carding, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 116, Feb. 2000.\\n\\n[32] B. Schuller et al., \u201cParalinguistics in speech and language processing,\u201d J. Acoust. Soc. Amer., vol. 14, no. 4, p. e29510, Apr. 2022.\\n\\n[33] P. Boersma and D. Weenink, \u201cParselmouth: A Python interface to Praat,\u201d J. Acoust. Soc. Amer., vol. 116, Feb. 2000.\\n\\n[34] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[35] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[36] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[37] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[38] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[39] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[40] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[41] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\\n\\n[42] J. M. F. Way, \u201cThe Lombard effect,\u201d J. Acoust. Soc. Amer., vol. 29, no. 1, pp. 713\u2013724, Jan. 1981.\"}"}
{"id": "dineley23_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Towards robust paralinguistic assessment for real-world mobile health (mHealth) monitoring: an initial study of reverberation effects, with collection overseen by a trained researcher. The recording and analysis pipeline is summarized in Figure 1.\\n\\nMethods\\n\\nWe created a new balanced cohort in the short time frame available per the conditions of the participants\u2019 consent. The recording and analysis pipeline is summarized in Figure 1.\\n\\nResults\\n\\nOur first results, with a condenser microphone and three smartphones, have also been demonstrated to contain fundamental frequency (F0) variability in captured speech features, which is more robust to device type and ambient noise. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nConclusion\\n\\nWith no public dataset available, we observe the effects of reverberation on speech features and report two analyses. First, we break down variability in recorded speech signal across different devices, and differences in health features and basic acoustic parameters have also been shown to be affected by recording environment.\\n\\nDevice type has also been shown to affect the signal-to-noise ratio of recorded speech, which may be interpreted as a risking process of the participants\u2019 consent. The recording and analysis pipeline is summarized in Figure 1.\\n\\nVoice quality features such as jitter and shimmer are heavily impacted by recording environment. With no public dataset available, we observe the effects of reverberation on speech features commonly extracted at a suprasegmental level from recordings, a common approach for baseline reasons. To begin, we report two analyses. First, we investigated the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons. Second, we observe the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons.\\n\\nWe assessed voice quality features such as jitter and shimmer, with collection overseen by a trained researcher. The recording and analysis pipeline is summarized in Figure 1.\\n\\nInstitute of Psychiatry, Psychology and Neuroscience, King\u2019s College London, London, UK\\n\\nJudith Dineley\\njudith.dineley@kcl.ac.uk\\n\\nInstitute of Health Informatics, University College London, London, UK\\n\\nEwan Carr\\n\\nSchool of Psychology, University of Sussex, Falmer, UK\\n\\nThomas F. Quatieri\\n\\nSchool of Electrical Engineering and Computer Science, MIT Lincoln Laboratory, Lexington, MA, USA\\n\\nFaith Matcham\\n\\nMIT Lincoln Laboratory, Lexington, MA, USA\\n\\nNicholas Cummins\\nnick.cummins@kcl.ac.uk\\n\\n42 healthy volunteers were recruited for this study of reverberation effects in highly controlled environments with high and low reverberation. With no public dataset available, we observe the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons.\\n\\nOur first results, with a condenser microphone and three smartphones, have also been demonstrated to contain fundamental frequency (F0) variability in captured speech features, which is more robust to device type and ambient noise. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nMethods\\n\\nWe created a new balanced cohort in the short time frame available per the conditions of the participants\u2019 consent. The recording and analysis pipeline is summarized in Figure 1.\\n\\nResults\\n\\nOur first results, with a condenser microphone and three smartphones, have also been demonstrated to contain fundamental frequency (F0) variability in captured speech features, which is more robust to device type and ambient noise. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nConclusion\\n\\nWith no public dataset available, we observe the effects of reverberation on speech features commonly extracted at a suprasegmental level from recordings, a common approach for baseline reasons. To begin, we report two analyses. First, we investigated the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons. Second, we observe the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons.\\n\\nWe assessed voice quality features such as jitter and shimmer, with collection overseen by a trained researcher. The recording and analysis pipeline is summarized in Figure 1.\\n\\nInstitute of Psychiatry, Psychology and Neuroscience, King\u2019s College London, London, UK\\n\\nJudith Dineley\\njudith.dineley@kcl.ac.uk\\n\\nInstitute of Health Informatics, University College London, London, UK\\n\\nEwan Carr\\n\\nSchool of Psychology, University of Sussex, Falmer, UK\\n\\nThomas F. Quatieri\\n\\nSchool of Electrical Engineering and Computer Science, MIT Lincoln Laboratory, Lexington, MA, USA\\n\\nFaith Matcham\\n\\nMIT Lincoln Laboratory, Lexington, MA, USA\\n\\nNicholas Cummins\\nnick.cummins@kcl.ac.uk\\n\\n42 healthy volunteers were recruited for this study of reverberation effects in highly controlled environments with high and low reverberation. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nMethods\\n\\nWe created a new balanced cohort in the short time frame available per the conditions of the participants\u2019 consent. The recording and analysis pipeline is summarized in Figure 1.\\n\\nResults\\n\\nOur first results, with a condenser microphone and three smartphones, have also been demonstrated to contain fundamental frequency (F0) variability in captured speech features, which is more robust to device type and ambient noise. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nConclusion\\n\\nWith no public dataset available, we observe the effects of reverberation on speech features commonly extracted at a suprasegmental level from recordings, a common approach for baseline reasons. To begin, we report two analyses. First, we investigated the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons. Second, we observe the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons.\\n\\nWe assessed voice quality features such as jitter and shimmer, with collection overseen by a trained researcher. The recording and analysis pipeline is summarized in Figure 1.\\n\\nInstitute of Psychiatry, Psychology and Neuroscience, King\u2019s College London, London, UK\\n\\nJudith Dineley\\njudith.dineley@kcl.ac.uk\\n\\nInstitute of Health Informatics, University College London, London, UK\\n\\nEwan Carr\\n\\nSchool of Psychology, University of Sussex, Falmer, UK\\n\\nThomas F. Quatieri\\n\\nSchool of Electrical Engineering and Computer Science, MIT Lincoln Laboratory, Lexington, MA, USA\\n\\nFaith Matcham\\n\\nMIT Lincoln Laboratory, Lexington, MA, USA\\n\\nNicholas Cummins\\nnick.cummins@kcl.ac.uk\\n\\n42 healthy volunteers were recruited for this study of reverberation effects in highly controlled environments with high and low reverberation. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nMethods\\n\\nWe created a new balanced cohort in the short time frame available per the conditions of the participants\u2019 consent. The recording and analysis pipeline is summarized in Figure 1.\\n\\nResults\\n\\nOur first results, with a condenser microphone and three smartphones, have also been demonstrated to contain fundamental frequency (F0) variability in captured speech features, which is more robust to device type and ambient noise. With no public dataset available, we investigated the implications of room reverberation for mHealth applications.\\n\\nConclusion\\n\\nWith no public dataset available, we observe the effects of reverberation on speech features commonly extracted at a suprasegmental level from recordings, a common approach for baseline reasons. To begin, we report two analyses. First, we investigated the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons. Second, we observe the effects of reverberation on speech features extracted at a suprasegmental level from recordings, a common approach for baseline reasons.\\n\\nWe assessed voice quality features such as jitter and shimmer, with collection overseen by a trained researcher. The recording and analysis pipeline is summarized in Figure 1.\"}"}
{"id": "dineley23_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2.1 Data Collection\\n\\nParticipant recruitment: This project received approval from the Research Ethics Committee of King's College London. Forty-two volunteers were recruited by word-of-mouth, social media and the institute's participant recruitment website and e-newsletter. Exclusion criteria included dyslexia, being a smoker, being under 16, ongoing treatment for a mental health disorder, and having any other kind of neurological, respiratory or other health issue that may affect the participant's speech.\\n\\nVolunteers whose first language was not English were required to have a sufficient level of reading ability and spoken English to read aloud two easy-intermediate texts and describe an everyday scene. Enrolment questionnaires recorded participants' age, sex, height, whether English was their first language and, if not, their level of English according to the Common European Framework of Reference for Languages. For analysis, all participant data was saved and labelled only with a non-personally identifiable ID number.\\n\\nSpeech Recording: Participants were recorded in Summer 2022 in two small, neighboring, identical, windowless electroencephalogram test rooms with low ceilings in the basement of a university building where there was no ambient noise. Room 1 was fitted with acoustic foam and soft furnishings and Room 2 was empty, leaving only hard plaster and wooden surfaces, except for carpet tiles on the floor. Thus, we had recording spaces with low and high reverberation, respectively. In a single session, we recorded a participant consecutively in each room, alternating the room order between participants to avoid introducing bias between rooms. Participants read aloud the full version of The Rainbow Passage to elicit consistent speech across the cohort with minimal training. The reading provides variety and versatility for analysis, with high phonetic balance and full phonetic coverage, and structural and lexical complexity appropriate for our healthy, educated cohort.\\n\\nEach participant reading was recorded simultaneously with a Samsung Galaxy S20 FE 5G (released 2020), as a representative non-budget Android smartphone; a Motorola G6 Play (released 2018), as a representative budget Android smartphone; an Apple iPhone 11 (released 2019) and an Audio-Technica AT2020USB+ condenser microphone with a cardioid pickup area, providing a higher quality recording from a non-mobile device within the budget constraints of our pilot study. The condenser microphone was fitted with a Rycote InVision shock mount and foam pop filter on a tabletop microphone stand and operated using Audacity open-source software (v.3.3.3). The smartphones were positioned directly adjacent to the pop filter with their primary microphones at the height of the center of the condenser microphone diaphragm. Participants were instructed to stand in front of and facing the pop filter. The height of the smartphones and condenser microphone was adjusted to be approximately level with the participant's mouth. Immediately prior to recording, the participant was positioned 30 cm from the condenser microphone, the distance at which its frequency response is specified.\\n\\nUpon completion of recording, audio files were saved and transferred to a secure cloud storage service. As with all participant data, recordings were labelled only with the participant's non-personally identifiable ID number.\\n\\n2.2 Feature extraction and analysis\\n\\nFeature extraction: We extracted 13 exemplar features commonly used in speech-health research that represent the basic speech production characteristics of timing, prosody, quality and articulation. These were speaking rate; articulation rate; number of pauses; mean fundamental frequency, ($F_0$ mean); standard deviation ($F_0$ standard deviation); intensity; first formant mean frequency, ($F_1$ mean); second formant mean frequency, ($F_2$ mean); spectral slope; spectral tilt; jitter; shimmer; and cepstral peak prominence, ($CPP$).\\n\\nFirst, we converted all audio files to single channel 16 kHz Waveform Audio File Format (WAV) files. Audio files were then automatically transcribed, using the base Open AI Whisper model (v.20230117), choosing automated analysis over manual transcription as a more realistic solution for a real-world mHealth pipeline. We aligned transcripts with the reading text with the Montreal Forced Aligner and English MFA acoustic model V2.0.0a to extract the three timing features for the entire reading.\\n\\nFigure 1: Data pipeline for investigation of room reverberation effects on 13 exemplar timing and acoustic speech features extracted from smartphone recordings. Forced alignment provides information for timing feature extraction.\"}"}
{"id": "dineley23_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acoustic features were extracted at two levels: (1) suprasegmentally, at the level of the entire reading, and (2) at the vowel level, for /a/ vowel occurrences. A median of 5 /a/ sounds were detected for each room, with jitter, shimmer and CPP as established tools. The /a/ sound has been recommended as more reliable for jitter and shimmer measurements. We undertook a suprasegmental approach to the vowel level, for /a/ occurrences. The open vowel, whispered, Montreal Forced Aligner and Praat default Praat settings, were used for R packages, with the multi-qualities of the entire reading. An open vowel, sounds removes variability due to the diverse linguistic content calculation of timing features. In contrast, analysis of /a/ vowel occurrences is consistent with neurological speech studies. There are small offsets in all three smartphones. The consistent negative differences reported in the suprasegmental analysis of the Motorola, iPhone and the condenser microphone are not present in the LME /a/ analysis. The voice quality features of the Motorola, iPhone and the condenser microphone are affected by reverberation; the Lombard effect may amplify existing concerns about the robustness and validity of voice quality features. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interection of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of feature value state. We observe mean feature values were higher in the presence of reverberation than other speech features. The Lombard effect may raise concerns about the robustness and validity of acoustic features associated with changes in reverberation. The t tests, LME models were considered a single speech feature as the F0 mean = 0; standard deviation = 1 for room 1, Room 2, voice quality features are significantly different for all phones. We plan to compare devices formally in future work due to the reduction in linguistic variability. Interektion of reverberation and room recording order was a source of variability in multiple features. The consistent negative differences (and corresponding 95% confidence intervals) in timing feature estimates closer to zero and narrow confidence intervals. We observe no clear differences between smartphones, amplifying existing concerns about the robustness and validity of acoustic features associated with changes in reverberation effects using a processing pipeline which followed the standard deviations of 0.4.1 extraction of"}
{"id": "dineley23_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our study has several limitations. First, it was conducted in healthy volunteers. This was a design choice to begin to investigate reverberation effects while minimizing variability due to pathology and to pilot data collection procedures for future larger studies. Second, our experimental setup likely represents the upper extreme of reverberation levels in the wild and consequently overestimates the effects; however, our results still highlight reliability concerns.\\n\\nThird, we have a limited age range. Fourth, we did not collect sustained vowels as part of our protocol; this might have allowed more reliable extraction of voice quality features. Fifth, we did not compare the effect of different processing tools and algorithm settings. Sixth, our analysis is not a formal comparison of mobile devices. We are planning a larger study to address these.\\n\\n4. Conclusion\\n\\nOur findings on the effects of reverberation complement observations in the literature on ambient noise and device choice \\\\cite{12, 13}. The speech processing community cannot ignore these sources of variability and expect to develop robust and reliable models for health assessment; otherwise, differences in recording conditions may be attributed to different health states. Instead, we must address the question of how we best record speech in the wild that is both robust to variations in recording parameters but still captures salient indicators of an individual's health state. Signal processing and machine learning solutions must also be explored. This could include impulse response estimation techniques and adversarial learning \\\\cite{31, 32}. These are vital steps in the development of transparent, reliable, valid and reproducible tools for health state assessment.\\n\\n5. Acknowledgements\\n\\nWe thank our participants for their support and the KCL Department of Psychology for the use of their test rooms. This work was supported by the MRC Impact Acceleration Account (IAA) King's College London 2021 (MR/X502923/1) and the EPSRC IAA King's College London 2022 (EP/X525571/1). This paper also represents independent research part funded by the National Institute for Health Research (NIHR) Maudsley Biomedical Research Centre at South London and Maudsley NHS Foundation Trust and King's College London and supported by the National Institute for Health and Care Research University College London Hospitals Biomedical Research Centre. Views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Dept. of Health and Social Care. For T.F. Quatieri: Material is approved for public release, distribution is unlimited, and is based upon work supported by the Under Secretary of Defense for Research and Engineering under Air Force Contract No. FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Under Secretary of Defense for Research and Engineering.\"}"}
