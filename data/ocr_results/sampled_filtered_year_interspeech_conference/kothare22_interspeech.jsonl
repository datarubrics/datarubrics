{"id": "kothare22_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"E. R. Dorsey, R. Constantinescu, J. Thompson, K. Biglan, R. Holloway, K. Kieburtz, F. Marshall, B. Ravina, G. Schifitto, A. Siderowf et al., \u201cProjected number of people with parkinson disease in the most populous nations, 2005 through 2030,\u201d *Neurology*, vol. 68, no. 5, pp. 384\u2013386, 2007.\\n\\nJ. R. Duffy, *Motor speech disorders e-book: Substrates, differential diagnosis, and management*. Elsevier Health Sciences, 2019.\\n\\nK. Tjaden, \u201cSpeech and swallowing in parkinson\u2019s disease,\u201d *Topics in geriatric rehabilitation*, vol. 24, no. 2, p. 115, 2008.\\n\\nB. T. Harel, M. S. Cannizzaro, H. Cohen, N. Reilly, and P. J. Snyder, \u201cAcoustic characteristics of parkinsonian speech: a potential biomarker of early disease progression and treatment,\u201d *Journal of Neurolinguistics*, vol. 17, no. 6, pp. 439\u2013453, 2004.\\n\\nA. Tsanas, M. A. Little, P. E. McSharry, J. Spielman, and L. O. Ramig, \u201cNovel speech signal processing algorithms for high-accuracy classification of parkinson\u2019s disease,\u201d *IEEE transactions on biomedical engineering*, vol. 59, no. 5, pp. 1264\u20131271, 2012.\\n\\nJ. Godino-Llorente, S. Shattuck-Hufnagel, J. Choi, L. Morov\u00e9lazquez, and J. G\u00f3mez-Garc\u00eda, \u201cTowards the identification of idiopathic parkinson\u2019s disease from the speech. New articulatory kinetic biomarkers,\u201d *PloS one*, vol. 12, no. 12, p. e0189583, 2017.\\n\\nP. G\u00f3mez, J. Mekyska, A. G\u00f3mez, D. Palacios, V. Rodellar, and A. \u00c1lvarez, \u201cCharacterization of parkinson\u2019s disease dysarthria in terms of speech articulation kinematics,\u201d *Biomedical Signal Processing and Control*, vol. 52, pp. 312\u2013320, 2019.\\n\\nD. L. Guarin, A. Dempster, A. Bandini, Y. Yunusova, and B. Taati, \u201cEstimation of orofacial kinematics in parkinson\u2019s disease: Comparison of 2d and 3d markerless systems for motion tracking,\u201d in *2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)*. IEEE, 2020, pp. 540\u2013543.\\n\\nJ. C. V\u00e1squez-Correa, T. Arias-Vergara, J. R. Orozco-Arroyave, B. Eskofier, J. Klucken, and E. N\u00f6th, \u201cMultimodal assessment of parkinson\u2019s disease: a deep learning approach,\u201d *IEEE journal of biomedical and health informatics*, vol. 23, no. 4, pp. 1618\u20131630, 2018.\\n\\nV. Ramanarayanan, A. C. Lammert, H. P. Rowe, T. F. Quatieri, and J. R. Green, \u201cSpeech as a biomarker: Opportunities, interpretability, and challenges,\u201d *Perspectives of the ASHA Special Interest Groups*, pp. 1\u20138, 2022.\\n\\nK. L. Stipancic, Y. Yunusova, J. D. Berry, and J. R. Green, \u201cMinimally detectable change and minimal clinically important difference of a decline in sentence intelligibility and speaking rate for individuals with amyotrophic lateral sclerosis,\u201d *Journal of Speech, Language, and Hearing Research*, vol. 61, no. 11, pp. 2757\u20132771, 2018.\\n\\nD. Suendermann-Oeft, A. Robinson, A. Cornish, D. Habberstad, D. Pautler, D. Schnelle-Walka, F. Haller, J. Liscombe, M. Neuemann, M. Merrill, O. Roesler, and R. Geffarth, \u201cNemsi: A multimodal dialog system for screening of neurological or mental conditions,\u201d in *Proceedings of ACM International Conference on Intelligent Virtual Agents (IVA)*, Paris, France, July 2019.\\n\\nZ. S. Nasreddine, N. A. Phillips, V. B\u00e9dirian, S. Charbonneau, V. Whitehead, I. Collin, J. L. Cummings, and H. Chertkow, \u201cThe montreal cognitive assessment, moca: a brief screening tool for mild cognitive impairment,\u201d *Journal of the American Geriatrics Society*, vol. 53, no. 4, pp. 695\u2013699, 2005.\\n\\nV. Peto, C. Jenkinson, R. Fitzpatrick, and R. Greenhall, \u201cThe development and validation of a short measure of functioning and well being for individuals with parkinson\u2019s disease,\u201d *Quality of life research*, vol. 4, no. 3, pp. 241\u2013248, 1995.\\n\\nC. Baylor, K. Yorkston, T. Eadie, J. Kim, H. Chung, and D. Amtmann, \u201cThe communicative participation item bank (cpib): Item bank calibration and development of a disorder-generic short form,\u201d 2013.\\n\\nP. Boersma and V. Van Heuven, \u201cSpeak and unspeak with praat,\u201d *Glot International*, vol. 5, no. 9/10, pp. 341\u2013347, 2001.\\n\\nM. McAuliffe, M. Socolof, S. Mihuc, M. Wagner, and M. Sondereregger, \u201cMontreal forced aligner: Trainable text-speech alignment using kaldi.\u201d in *Interspeech*, vol. 2017, 2017, pp. 498\u2013502.\\n\\nW. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg, \u201cSsd: Single shot multibox detector,\u201d in *Proceedings of the European Conference on Computer Vision (ECCV)*, 2016, pp. 21\u201337.\\n\\nV. Kazemi and J. Sullivan, \u201cOne millisecond face alignment with an ensemble of regression trees,\u201d in *IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, Columbus, USA, June 2014.\\n\\nM. Neumann, O. Roesler, D. Suendermann-Oeft, and V. Ramanarayanan, \u201cOn the utility of audiovisual dialog technologies and signal analytics for real-time remote monitoring of depression biomarkers,\u201d in *1st Workshop on NLP for Medical Conversations at ACL 2020*, Seattle, US, July 2020.\\n\\nY. Benjamini and Y. Hochberg, \u201cControlling the false discovery rate: a practical and powerful approach to multiple testing,\u201d *Journal of the Royal statistical society: series B (Methodological)*, vol. 57, no. 1, pp. 289\u2013300, 1995.\\n\\nH. Beckerman, M. Roebroeck, G. Lankhorst, J. Becher, P. D. Bezemer, and A. Verbeek, \u201cSmallest real difference, a link between reproducibility and responsiveness,\u201d *Quality of Life Research*, vol. 10, no. 7, pp. 571\u2013578, 2001.\\n\\nS. M. Haley and M. A. Fragala-Pinkham, \u201cInterpreting change scores of tests and measures used in physical therapy,\u201d *Physical therapy*, vol. 86, no. 5, pp. 735\u2013743, 2006.\\n\\nH. C. de Vet, C. B. Terwee, R. W. Ostelo, H. Beckerman, D. L. Knol, and L. M. Bouter, \u201cMinimal changes in health status questionnaires: distinction between minimally detectable change and minimally important change,\u201d *Health and quality of life outcomes*, vol. 4, no. 1, pp. 1\u20135, 2006.\\n\\nX. Robin, N. Turck, A. Hainard, N. Tiberti, F. Lisacek, J.-C. Sanchez, and M. M\u00fcller, \u201cproc: An open-source package for r and s+ to analyze and compare roc curves,\u201d *BMC Bioinformatics*, vol. 12, p. 77, 2011.\\n\\nT. Sing, O. Sander, N. Beerenwinkel, and T. Lengauer, \u201cRocr: visualizing classifier performance in r,\u201d *Bioinformatics*, vol. 21, no. 20, p. 7881, 2005. [Online]. Available: http://rocr.bioinf.mpi-sb.mpg.de\\n\\nM. L\u00f3pez-Rat\u00f3n, M. X. Rodr\u00edguez-\u00c1lvarez, C. C. Su\u00e1rez, and F. G. Sampedro, \u201cOptimalCutpoints: An R package for selecting optimal cutpoints in diagnostic tests,\u201d *Journal of Statistical Software*, vol. 61, no. 8, pp. 1\u201336, 2014.\\n\\nR Core Team, *R: A Language and Environment for Statistical Computing*, R Foundation for Statistical Computing, Vienna, Austria, 2021. [Online]. Available: https://www.R-project.org/\"}"}
{"id": "kothare22_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Statistical and clinical utility of multimodal dialogue-based speech and facial metrics for Parkinson's disease assessment\\n\\nHardik Kothare 1, Michael Neumann 1, Jackson Liscombe 1, Oliver Roesler 1, William Burke 1, Andrew Exner 2, Sandy Snyder 2, Andrew Cornish 1, Doug Habberstad 1, David Pautler 1, David Suendermann-Oeft 1, Jessica E. Huber 2 and Vikram Ramanarayanan 1, 3\\n\\n1 Modality.AI, Inc., San Francisco, CA, USA\\n2 Purdue University, West Lafayette, IN, USA\\n3 University of California, San Francisco, CA, USA\\n\\nAbstract\\nWe present a framework for characterising the statistical and clinical relevance of speech and facial metrics in Parkinson's disease (PD) extracted by a multimodal conversational platform. 38 people with PD (pPD) and 22 controls were recruited in an ongoing study and were asked to complete four interactive sessions, a week apart from each other. In each session, a virtual conversational agent, Tina, guided participants through a battery of standard tasks designed to elicit speech and facial behaviours. Speech and facial metrics were automatically extracted in real time, several of which showed statistically significant differences between pPD and controls. We explored which of these differences were greater than measurement error, a threshold defined as the minimally detectable change (MDC). Furthermore, we computed the minimal clinically important difference (MCID) with respect to the Communicative Participation Item Bank short form (CPIB-S) scale for these select metrics. Our results show that differences in metrics like duration and fundamental frequency (F0) of speech are captured beyond measurement error. We also discuss several confounding factors that need to be taken into consideration before making any clinical interpretation of changes in these metrics.\\n\\nIndex Terms: multimodal dialogue system, audiovisual analytics, parkinson's disease, remote patient monitoring, minimal detectable change, minimal clinically important difference.\\n\\n1. Introduction\\nRemote patient monitoring is witnessing a growing demand in the field of neurological and psychiatric diseases due to limited access to specialist care [1], significant technological breakthroughs [2] and the ongoing COVID-19 pandemic [3]. Apart from improving ease and frequency of access, the rich data captured in the natural environment of patients' homes can enhance our understanding of the patients' conditions and tailor their treatment to suit their disease progression [4, 5]. This could improve outcomes for individual patients while substantially decreasing healthcare costs. The number of pPD over the age of 50 is projected to be 8.7 million in Western Europe\u2019s 5 most and the world\u2019s 10 most populous nations by the year 2030 [6], underscoring the need to develop and adopt digital aids for PD care and management.\\n\\nMotor speech is severely impacted in PD with up to 90% of patients exhibiting dysarthria at some point during the course of the disease [7, 8]. This has a direct and indirect impact on quality of life in pPD. It is therefore important to track deterioration in speech production due to disease progression and any improvement due to speech therapy or breathing exercises. Current practice requires pPD to seek specialist care on a periodic basis which comes with geographic, economic and logistical constraints. Remote patient monitoring has the potential to break these barriers.\\n\\nPrevious work has shown that acoustic characteristics of Parkinsonian speech are distinct enough to be used as digital biomarkers [9, 10]. The articulatory and orofacial kinematics that cause these acoustic consequences also have tremendous potential as biomarkers [11, 12, 13]. It has become increasingly important to approach remote patient monitoring from a multimodal perspective as it provides more information than a biosignal from a single modality [14, 15].\\n\\nIn this paper, we present one such remote patient monitoring study that utilises a cloud-based multimodal dialogue platform with a virtual conversational agent, Tina, who walks participants through on-demand interview sessions. Participants engage in a variety of standard speaking exercises in each session. Audiovisual frames are recorded and speech and facial metrics are extracted automatically in real time. We aim to answer the following questions about the statistical and clinical importance of these metrics:\\n\\n1. Which metrics from which speaking exercises show significant differences between pPD and controls and how reliable are these metrics? What is the detected difference in median values between the two cohorts?\\n2. For metrics that show differences, what value represents a difference or change above and beyond any measurement errors (minimally detectable change (MDC) / statistical utility)?\\n3. For metrics that show differences, what value might represent an actual clinical change tied to physiological manifestations of PD (minimal clinically important difference (MCID) / clinical utility)?\\n\\nTo the best of our knowledge, questions 2 and 3 above have not been previously explored in the context of PD, although prior work has talked about MDC and MCID in dysarthric speakers with Amyotrophic Lateral Sclerosis (ALS) [16].\\n\\n2. System\\nThe virtual conversational agent, Tina, was developed on the Modality platform, a cloud-based multimodal dialogue system [2, 17]. Tina can conduct customised dialogue-based interviews based on standard tasks used in the clinic to assess neurological and mental health. Audiovisual metrics, answers to survey...\"}"}
{"id": "kothare22_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"questionnaires and other meta information related to the session can all be accessed by a clinician on a dashboard which is designed to provide a high-level overview of the session as well as a breakdown of recordings and metrics per interaction turn.\\n\\n3. Data\\n\\nParticipants were recruited through the Purdue Motor Speech Lab at Purdue University. After explaining the nature of the study and what it involved, informed consent was obtained from participants. The Montreal Cognitive Assessment (MoCA) [18] was administered to every participant to test for cognitive impairment. Inclusion criteria for pPD were: between 30 and 85 years of age, a diagnosis of idiopathic PD, availability of a device with a microphone and a camera, internet access, no hearing and vision loss (self-reported) and fluency in English. Exclusion criteria were: diagnosis of a neurological disease other than PD; a history of head and neck cancer / surgery, voice disorder, pulmonary disease, smoking (in the past 5 years), more than moderate cognitive impairment (MoCA score < 10).\\n\\nControls were age-matched and sex-matched. This study includes data from 60 participants (see Table 1) collected between November 2020 and January 2022. Participants were asked to complete four sessions, a week apart from each other. Some participants completed fewer or more than the suggested number of sessions, resulting in a total of 243 sessions.\\n\\nThe conversational callflow required participants to do the following speaking exercises: (a) sustained vowel (held steady /A/, up-or-down pitch glide /i/), (b) read speech: speech intelligibility test (SIT) sentences, sentences that elicited variation in intonational prosody, rainbow passage, (c) story retells and (d) spontaneous speech (Spont) on any topic of their choice with a few topics suggested on the screen. At the end of each session, participants filled out the Parkinson's Disease Questionnaire (PDQ-39) [19] and the Communicative Participation Item Bank short form (CPIB-S) [20].\\n\\n4. Methods & Results\\n\\n4.1. Extraction of metrics\\n\\nSpeech duration metrics such as speaking duration (s), articulation duration (s) and percent pause time (%) were extracted using Praat [21]. Speaking rate and articulation rate (words per minute) were calculated by dividing the number of expected words in the reading exercises by the duration. Canonical timing agreement (CTA, %) was computed for SIT using the Montreal Forced Aligner [22]; CTA measures how similar the temporal structure of the participant's utterance was as compared to Tina's. Praat algorithms were also used to calculate spectral metrics: fundamental frequency (F0, Hz), jitter (%), formant frequencies for F1, F2 and F3 (Hz), F2 slope (Hz/s), cepstral peak prominence (CPP, dB) and harmonics-to-noise ratio (HNR, dB); energy-related metrics: shimmer (%), signal-to-noise ratio (SNR, dB) and articulation intensity (dB). Facial metrics were extracted using the face detector in the dnn module of OpenCV [23]. Facial landmark extraction was done using the Dlib facial landmark detector [24]. To account for differences in camera distances, intra-participant facial normalisation was done by dividing facial metrics in pixels by the inter-caruncular distance between the participant's eyes in pixels. More details about metric extraction can be found in [25].\\n\\n4.2. Effect sizes\\n\\nSpeech and facial metrics were z-scored by sex to account for sex-specific differences. For every metric, non-parametric Kruskal-Wallis tests were performed at \\\\( \\\\alpha = 0.001 \\\\). Metrics that showed significant differences between pPD and controls and survived Benjamini-Hochberg correction [26] to control for false discovery rate are shown in Figure 1.\\n\\npPD exhibited greater SNR than controls in terms of intensity during various tasks. They also had greater values of minimum fundamental frequency (F0) during spontaneous speech, formant frequency of the second formant (F2) during sustained phonation of /A/, upward jaw velocity and acceleration while reading the rainbow passage. On the other hand, the average values of higher order jaw kinematic metrics like velocity, acceleration and jerk were smaller in pPD than controls during spontaneous speech (maximum upward and downward kinematics also showed differences but were excluded from the plot to avoid redundancy) and downward pitch glide of the sustained vowel /i/. pPD also displayed shorter articulation duration while sustaining phonation of the vowel /i/ with an upward pitch glide, shorter articulation and speaking duration during spontaneous speech, and lower CTA with the SIT prompts as determined by the Montreal Forced Aligner. The test-retest reliability coefficient of these metrics was calculated as the average absolute Pearson's correlation coefficient between sessions 1 and 2, sessions 2 and 3 and sessions 3 and 4 (displayed in parentheses in Figure 1). Speech metrics showed better test-retest reliability than facial metrics.\\n\\nFigure 1: Effect sizes of speech and facial metrics that show statistically significant differences between controls and pPD at \\\\( \\\\alpha = 0.001 \\\\). Test-retest reliability reported in parentheses.\\n\\nSpont: Spontaneous Speech, SNR : signal-to-noise ratio, F0 : fundamental frequency, F2 : second formant frequency, SIT : sentence intelligibility test, CTA : Canonical Timing Agreement\\n\\n4.3. MDC\\n\\nThe MDC has been widely used in the fields of physical therapy, occupational therapy, rehabilitation and health care to...\"}"}
{"id": "kothare22_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Participant demographics: Age, MoCA scores and years since diagnosis are presented as: median; mean (standard deviation)\\n\\n| Group   | Sex   | Age (years) | MoCA score | Years since diagnosis |\\n|---------|-------|-------------|------------|-----------------------|\\n| Controls | 18F/4M | 65; 63.46 (11.08) | 28; 27.55 (1.92) | - |\\n| pPD     | 19F/19M | 71; 67.48 (9.30) | 27; 26.06 (3.63) | 5; 7.89 (6.16) |\\n\\nIn recent work [16], the authors extended the concept of MDC to speech outcomes to monitor dysarthria progression in ALS. MDC at 95% confidence level is defined in equation 1 below:\\n\\n$$MDC_{95} = 1.96 \\\\times \\\\sqrt{2 \\\\times SEM}$$  \\n\\n(1)\\n\\nSEM is the standard error of measurement for a particular metric calculated from all participants across their four sessions and is calculated using equation 2 below:\\n\\n$$SEM = \\\\sigma \\\\times \\\\sqrt{1 - \\\\rho}$$  \\n\\n(2)\\n\\nwhere \\\\(\\\\sigma\\\\) is the standard deviation of the distribution of the metric and \\\\(\\\\rho\\\\) is the average absolute Pearson's correlation coefficient, annotated in parentheses in Figure 1. Using this method, an MDC value was calculated for every speech and facial metric. Figure 2 shows those metrics for whom the detected difference between the two cohorts (calculated as the difference in median values) was greater than the MDC value for that particular metric. To enable displaying all metrics in the same plot, we expressed MDC and detected differences as a percentage of the range of values detected across pPD and controls.\\n\\n### 4.4. MCID\\n\\nThe MCID is defined as the smallest change in a domain that is thought to be clinically relevant or has an impact on patients, clinicians or caregivers [16, 29]. MCID can be considered as a threshold for a change that would be treated as an improvement or deterioration in function. The MCID estimate must be larger than the MDC value for a particular metric for it to have any clinical utility. To tie MCID to clinical meaningfulness, it requires an external anchor in the form of a clinical gold standard assessment. In most cases, this is a survey instrument used by clinicians. In this study, we used changes in a participant's CPIB-S T score (on a logit scale) [20] from session 1 to session 4 which would be indicative of a deterioration in motor speech function that impacted communicative speech participation. Previous work [16] in ALS has considered one question pertaining to speech as an external anchor to calculate MCID. We explored the possibility of using question 34 of the PDQ-39 scale (\u201cDue to having Parkinson\u2019s disease, how often during the last month have you had difficulty with your speech?\u201d) as an external anchor. However, only 4 pPD showed a change in their score that signified worsening from session 1 to session 4. For MCID, we only considered metrics for pPD because any changes in metrics for controls are not likely to have any clinical significance. Figure 3 represents a histogram of these changes for all pPD who had CPIB-S T scores for sessions 1 and 4. The standard error of the mean of this distribution was 0.74.\\n\\nA subset of pPD were classified into two sub-cohorts based on their change in CPIB-S T score:\\n\\n1. No change: Change in CPIB-S T score = 0 (\\\\(n = 8\\\\))\\n2. Decline: Deterioration in CPIB-S T score < -0.74 or more than the standard error of the mean of the distribution (\\\\(n = 13\\\\))\\n\\nNext, in order to calculate the MCID value for each metric that showed a detected difference greater than MDC in Figure 2, we used receiver operating characteristic (ROC) curves of a simple binary classifier to determine how well the changes in each metric differentiated between the two sub-cohorts defined above. These analyses were performed using the pROC [30], ROCR [31] and OptimalCutpoints [32] packages in R [33]. The optimal cutpoints, or MCID, for the metrics in Figure 2 were the points on the ROC curves that represented maximum sensitivity and maximum specificity (top left point on the ROC curve) of the classifier. MCID values were then expressed as a percentage of the observed range to allow comparison with MDC and detected difference values.\\n\\n### 5. Discussion\\n\\nTo the best of our knowledge, the current study is the first that attempts to define a framework for MDC and MCID of motor speech outcomes in PD.\\n\\nWe first investigated which speech and facial metrics extracted by the remote patient monitoring platform showed differences between pPD and controls. Next, we determined MDC values for all metrics; six speech metrics related to duration and fundamental frequency of speech showed differences between the two cohorts that were greater than the MDC. This suggests that differences in these metrics are beyond any measurement errors. An important point to consider here is that since MDC is a function of the distribution of data (as seen in equation 1), larger datasets would provide an even better estimate for each metric's MDC value because the distribution will tend to be normal per the Central Limit Theorem [34]. No facial metric appears in Figure 2, perhaps because they have a larger range making their MDC values much larger than any detected differences. Another possible explanation for the absence of facial metrics in Figure 2 is poorer reliability numbers for these metrics as compared to speech metrics seen in Figure 1.\\n\\nThe MCID values for the metrics in Figure 2 were not larger than their MDC values. One reason for this could be that changes in the external anchor or CPIB-S T scores may be affected by perceived changes in communicative participation by individuals which are not accurately captured by the objective speech and facial metrics considered in this study. A fusion of subjective and objective changes could be considered while tracking clinical outcomes or disease progression.\\n\\nAnother alternative explanation could be that participant-reported survey instruments in general and the CPIB-S in particular are inadequate in capturing all aspects of expressive communication.\\n\\nA third possibility could be that since PD is not a rapidly progressing disease, changes in metrics and survey scores over a span of 4 weeks may not represent the ground truth of disease progression like it does in other fast-progressing neurological disorders like ALS. Indeed not all pPD showed a change in metrics in the same direction despite a deterioration in their...\"}"}
{"id": "kothare22_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Metrics with detected differences between the median values of the two cohorts (pPD and controls) greater than MDC.\\n\\nFigure 3: Histogram of changes in CPIB-S T scores from session 1 to session 4.\\n\\nCPIB-S T scores. Relatedly, most of the pPD in this study may not be severely impacted by dysarthria. What exactly does an increase in spontaneous speech articulation duration indicate? Does it mean the participant feels well enough to speak for a longer duration or does it indicate that the articulation rate for the participant has dropped due to dysarthria? In future work, we plan to look at articulation rate in spontaneous speech based on transcriptions of user turns. Would combinations of metrics provide a better perspective when it comes to MCID? A study with a larger, more heterogeneous cohort could also be useful towards defining MDC and MCID values in PD.\\n\\nLastly, all pPD took part in this study during the on-state of PD medication. The effects of this medication in conjunction with other interventions like speech therapy, breathing and other vocal or non-vocal exercises need to be factored in for accurate estimation of the statistical and clinical utility of speech and facial metrics.\\n\\n6. Conclusions\\n\\nIn conclusion, we attempted to define a framework for MDC and MCID in Parkinson's disease. With the current data, we were unable to obtain MCID values that were greater than the MDC values. MDC is a function of the SEM or the distribution of the data. The MDCs in this study may have been larger because of a relatively smaller sample size. Future work should focus on what SEM or sample size is needed to obtain MDC and MCID values that would prove useful to clinicians, patients and caregivers.\\n\\n7. Acknowledgements\\n\\nThe authors would like to thank Kaila Stipancic and Jordan Green for their help and advice.\\n\\n8. References\\n\\n[1] M. Achey, J. L. Aldred, N. Aljehani, B. R. Bloem, K. M. Biglan, P. Chan, E. Cubo, E. Ray Dorsey, C. G. Goetz, M. Guttman et al., \u201cThe past, present, and future of telemedicine for parkinson\u2019s disease,\u201d Movement disorders, vol. 29, no. 7, pp. 871\u2013883, 2014.\\n\\n[2] V. Ramanarayanan, O. Roesler, M. Neumann, D. Pautler, D. Habberstad, A. Cornish, H. Kothare, V. Murali, J. Liscombe, D. Schnelle-Walka et al., \u201cToward remote patient monitoring of speech, video, cognitive and respiratory biomarkers using multimodal dialog technology.\u201d in INTERSPEECH, 2020, pp. 492\u2013493.\\n\\n[3] F. Motolese, A. Magliozzi, F. Puttini, M. Rossi, F. Capone, K. Karlinski, A. Stark-Inbar, Z. Yekutieli, V. Di Lazzaro, and M. Marano, \u201cParkinson\u2019s disease remote patient monitoring during the covid-19 lockdown,\u201d Frontiers in neurology, vol. 11, 2020.\\n\\n[4] S. Papapetropoulos, G. Mitsi, and A. J. Espay, \u201cDigital health revolution: is it time for affordable remote monitoring for parkinson\u2019s disease?\u201d Frontiers in neurology, vol. 6, p. 34, 2015.\\n\\n[5] L. P. Malasinghe, N. Ramzan, and K. Dahal, \u201cRemote patient monitoring: a comprehensive study,\u201d Journal of Ambient Intelligence and Humanized Computing, vol. 10, no. 1, pp. 57\u201376, 2019.\"}"}
