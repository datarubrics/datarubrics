{"id": "simantiraki23_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The effect of masking noise on listeners' spectral tilt preferences\\n\\nOlympia Simantiraki1, Yannis Pantazis1, Martin Cooke2\\n\\n1Institute of Applied and Computational Mathematics, FORTH, Greece\\n2Ikerbasque (Basque Science Foundation), Spain\\n\\nAbstract\\n\\nSpeech enhancement algorithms often focus on optimizing intelligibility while neglecting other aspects of speech such as naturalness, quality and listening effort which may affect a listener's experience. This paper investigates the impact of spectral tilt on listeners' preferences, using a new corpus of Greek utterances. Participants adjusted spectral tilt with real-time feedback to select their preferred tilt in quiet and in the presence of speech-shaped noise at eight signal-to-noise ratios. Listeners displayed distinct preferences, with a tendency to select flatter tilts with increasing noise. Preferences were not random even for constant intelligibility, indicating that their adjustments were influenced by factors beyond the need to maintain comprehensibility. These findings have the potential to inform the design of speech enhancement algorithms that jointly optimise intelligibility and a listener's overall experience.\\n\\nIndex Terms: listener preferences, SPEECH ADJUSTER, spectral energy reallocation, glimpses profile\\n\\n1. Introduction\\n\\nListeners routinely encounter pre-recorded or synthetic speech. While speech enhancement techniques have been used to improve intelligibility in potentially challenging listening conditions, these approaches typically do not account for aspects such as naturalness and quality that may also affect a listener's experience. Speech quality can have a significant impact on cognitive effort during listening tasks, even when word recognition is held constant. Synthetic voices can require increased effort compared to natural speech [1, 2, 3]. Increasing spectral resolution in a cochlear implant simulation reduced listening effort during a dual-task paradigm [4], while attending to clear (as opposed to plain) speech in the presence of babble noise resulted in lower cognitive effort [5]. Consequently, it is of interest to study listeners' preferences for features such as spectral tilt which talkers adjust naturally (resulting in a flatter spectrum) when speaking in noisy conditions (i.e. Lombard speech).\\n\\nListener preferences provide insight into listeners' overall experience with speech, taking into account factors such as naturalness, pleasantness, and loudness. One approach to studying listener preferences is through real-time auditory feedback, where listeners can modify speech characteristics until they reach their preferred settings. Previous studies have used this method to investigate preferences for formant frequency/fundamental frequency relationships [6], speech rate [7, 8], speech level [9], and local SNR [9]. Spectral modifications have been explored in studies involving individuals with hearing loss, with investigations into preferences for broadband, low-, and high-frequency gain [10] and degree of spectral tilt [11]. Our study builds on recent work into spectral tilt preferences [12], but instead of using a small set of noise levels and tilt adjustments, here we examine preferences across a broad range of SNRs and for a different target language. These aspects of the current study highlight the novelty of our approach which ought to contribute to a better understanding of the effects of spectral modifications in noisy conditions.\\n\\nThis study has two objectives (i) to provide a better understanding of the impact of masking noise on listeners' preferences for spectral tilt; (ii) to predict listener preferences. The latter objective is motivated by the fact that, while subjective evaluation of speech enhancement algorithms is generally considered more reliable than prediction, it can be impractical, time-consuming, and rules out using evaluation outcomes to optimise modification techniques. A large-scale validation study demonstrated that commonly-used measures of listening effort are not consistently or strongly intercorrelated [13]; other studies have shown that subjective measures are correlated with task performance [14, 15].\\n\\nAutomatic prediction of speech characteristics beyond intelligibility can be a valuable tool for developing speech enhancement algorithms. A DNN-based listening effort predictor, quantified via the degradation of phoneme posteriorgrams, and not requiring prior knowledge of the processed speech, was proposed in [16]. Another model to predict preferences [12] used an objective measure of energetic masking to capture intelligibility and a further Gaussian component to model supra-intelligibility factors.\\n\\nIn the current study participants were given the ability to adjust the spectral tilt of speech in quiet and in 8 levels of speech-shaped noise. The main questions addressed are: do listener preferences show a pattern different from intelligibility, and can the spectral profile of the masked speech signal be used to predict listener preferences?\"}"}
{"id": "simantiraki23_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"I will cut the fruit into three equal pieces.\\n\\n2.3. Speech material\\nA 31-year-old native Greek male talker was recruited to read the complete corpus. The talker was asked to read each sentence at a normal speaking rate and was able to repeat any utterance if necessary. Recording took place in a sound studio at the Speech Signal Processing Laboratory at the University of Crete (Heraklion, Greece) using Pro Tools 12 software with an RME Fireface 400 recorder. A Neumann KMS104 handheld vocal condenser microphone (cardioid directional polar pattern) was placed on a desktop microphone stand on a table at a fixed distance of 15 cm from the talker's mouth. Recordings were made at a sampling rate of 44.1 kHz. Sentences were segmented using a custom amplitude-based pause detector based on the normalised envelope of the signal. The algorithm's effectiveness and the quality of the recordings were screened manually: signals were checked for clipping, correct utterance segmentation, and common speaking style. Where necessary, recordings were repeated. Sentences had a mean duration of 2.8 s (S.D. 0.3 s).\\n\\nFor the experiment, phrases were downsampled to 16 kHz, a 20 ms half-Hamming ramp was applied at the beginning and end of each recording, and each stimulus was normalised to a common root-mean-square level.\\n\\n2.4. Stimuli\\nStimulus design was informed by findings in [12], whose listeners did not select extremely steep spectral tilts in any condition and in the most challenging condition may have preferred even flatter spectral tilts had they been available. Changes in spectral tilt were achieved by filtering the speech signal with a digital filter twice (filter function in Matlab 2016b) to produce a \\\\( |H(\\\\omega)|^2 \\\\) system. The rational transfer function for pre-emphasis was \\\\( H(z) = 1 - \\\\lambda z^{-1} \\\\) and for de-emphasis \\\\( H(z) = \\\\frac{1}{1 - \\\\lambda z^{-1}} \\\\), with \\\\( \\\\lambda \\\\) drawn linearly from the range \\\\([-0.16, 0.80]\\\\), where positive and negative values correspond to pre-emphasis and de-emphasis respectively. In total 25 modification levels were constructed (4 with spectral tilt steeper than the original, 1 with the original spectral tilt, and 20 with flatter than the original) corresponding to tilts in the range \\\\([-4.40, 2.66] \\\\) dB/octave.\\n\\nStimuli were presented in quiet and in speech-shaped noise (SSN) at 8 SNRs: -7.5, -6, -4.5, -3, -1.5, 0, +3, and +6 dB. The masker was generated as in [12] by filtering random uniform noise with the long-term spectrum of the 700 concatenated sentences of the female talker in the Sharvard corpus [19], without gaps. The desired SNRs were obtained by rescaling the noise. The amplitude of each sentence was normalized using a fixed root-mean-square criterion.\\n\\n2.5. Procedure\\nThe experiment consisted of 5 trials in each of 9 conditions (quiet + 8 SNRs), split into 3 blocks of 15 trials in a random order. Each trial consisted of an adjustment phase followed by a test phase. In the adjustment phase, sentences were presented randomly, starting at a random feature value, with a 0.5 s gap between sentences. Participants were required to listen to at least 5 s of speech before moving on to the test phase, but they could listen to as much speech as desired during the adjustment phase. In this phase, a total of 250 unique sentences were presented. Once all 250 sentences were heard, they were shuffled and were available for presentation. This process was repeated until the experiment was completed. The test phase evaluated intelligibility via a speech perception task using the feature's value chosen at the end of the adjustment phase. Participants were presented with a sequence of two sentences and asked to type what they heard into an on-screen text box after each sentence presentation. All the sentences in the test phase were unique.\\n\\nParticipants underwent a task familiarization phase consisting of three trials (in quiet and at -7.5 dB and +6 dB SNR). Participants modified spectral tilt in real-time using SPEECH DJUSTER [20], receiving the instruction to adjust the speech in order to recognise as many words as possible. Adjustments were made using up/down keys on a computer keyboard. Stimuli were presented at a fixed presentation level over Sennheiser HD380 headphones. Listeners were seated in a sound-attenuating booth located in the Speech Signal Processing Laboratory at the University of Crete.\\n\\nIntelligibility scores were based on the number of keywords correctly recalled in each trial (2 test phrases x 5 keywords per phrase). Written responses were post processed to remove accents over vowels and replace letter/diphthongs with the same pronunciation with a unique letter.\\n\\n3. Results\\nListeners preferred progressively flatter spectral tilts (all flatter than the original) as SNRs decreased (Fig. 1, top). A linear mixed effects model (lmer function from the lme4 package in R) with SNR as ordered factor (the quiet condition excluded from the analysis) and participant as a random effect, indicated that SNR had a significant effect on preferences \\\\( F(7, 1142) = 25.34, p < .001 \\\\). The ability of linear, quadratic, cubic, and reciprocal models in predicting tilt were evaluated using leave-one-out cross-validation. The average variance of the mean spectral tilts across the 8 iterations of the cross-validation method was 0.173. Reciprocal and quadratic models predict the mean listener preferences with similar accuracy (Fig. 2).\\n\\n![Figure 1](image-url)\\n\\nTop: listeners' preferred spectral tilt relative to unmodified speech (horizontal line); middle: mean number of correctly identified keywords; lower: time spent in the adjustment phase. Q denotes the quiet condition. Error bars represent \u00b1 one standard error.\"}"}
{"id": "simantiraki23_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Listeners' tilt preferences permitted them to maintain high intelligibility (Fig. 1, middle) even in challenging levels of noise with scores of 93% at -4.5 dB SNR, dropping to 85% in the most adverse condition. A linear mixed-effects model with SNR as a fixed effect and participant as a random intercept indicated a significant main effect of SNR on intelligibility \\\\([F(8, 1234)] = 16.72, p < .001\\\\). Post-hoc tests with Tukey corrections demonstrated that there was no significant intelligibility differences between SNRs of -4.5 dB and higher.\\n\\nThe increase in noise level led to an increase in the time required by listeners to finalise their tilt preferences (Fig. 1, lower). A linear mixed-effects model with SNR as a fixed effect and participant as the random intercept indicated a significant effect of SNR on adjustment time \\\\([F(8, 1234)] = 31.04, p < .001\\\\). Post-hoc tests with Tukey correction indicated no significant differences in adjustment time between SNRs of -1.5 dB and higher, nor between SNRs of -4.5 dB and lower.\\n\\nListener preference distributions plotted alongside intelligibility (Fig. 3, left column) show distinct preferences even when intelligibility is effectively constant, with the distributional mass shifting from steeper to flatter spectral tilts with increasing noise level. Two-sample Kolmogorov-Smirnov tests \\\\([ks2samp\\\\text{ in } scipy.stats\\\\) of Python] confirmed the non-uniformity of preference distributions at all SNRs \\\\([all \\\\ p<.001\\\\).\\n\\nThe impact of spectral tilt modifications on audibility was evaluated using an energetic masking model, the Extended Glimpse Proportion metric \\\\([21\\\\). The right column of Fig. 3 shows the proportion of glimpses of the target speech at each frequency as a function of tilt. Listeners appear to adjust spectral tilt to ensure that glimpses are available across a wide range of frequencies. This observation motivated the construction of a model to predict listener preferences as detailed below.\\n\\n### 4. Predicting listener preferences\\n\\nWe propose a model that estimates the probability of the spectral tilt of a speech signal being the most preferred. Mathematically, this probability is described by\\n\\n\\\\[\\np(y^* | x)\\n\\\\]\\n\\nwhere \\\\(y\\\\) denotes the spectral tilt variable while \\\\(y^*\\\\) is the most preferred spectral tilt, conditioned on the glimpse profile (denoted by \\\\(x\\\\)) which serves as a predictive indicator of listener preferences. By Bayes' theorem, the posterior probability\\n\\n\\\\[\\np(y^* | x) = \\\\frac{p(x | y^*) p(y^*)}{p(x)}\\n\\\\]\\n\\nwhere \\\\(p(x)\\\\) corresponds to the evidence which is independent of the spectral tilt \\\\(y\\\\), while the prior distribution \\\\(p(y^*)\\\\) is assumed to be uniform (i.e., uninformative) hence also independent of \\\\(y\\\\). Therefore, Bayes' theorem states that\\n\\n\\\\[\\np(y^* | x) \\\\propto p(x | y^*)\\n\\\\]\\n\\nwith the latter being the likelihood.\\n\\nWe modelled the proportion of glimpses over 33 frequency bands, i.e., the likelihood, using a multivariate Gaussian distribution. The first band was excluded from the likelihood calculation due to the negligible number of glimpses observed in that band (Fig. 3 right column) which can lead to numerical instability. The use of the multivariate Gaussian process allowed us to capture inter-dependencies between the proportion of glimpses in different frequency bands, resulting in a more realistic model.\"}"}
{"id": "simantiraki23_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Symmetric KLD between the proposed model and actual preferences for Greek (2nd col.) and Spanish (3rd col.). The 4th column corresponds to the results from the model proposed in [12] (which tested only 3 SNRs). Lower sKLD values indicate more similar distributions.\\n\\n| SNR | sKLD (Gr) | sKLD (Sp) | sKLD (Sp) [12] |\\n|-----|-----------|-----------|----------------|\\n| +6  | 0.09      | -         | -              |\\n| +3  | 0.17      | -         | -              |\\n| 0   | 0.12      | 0.57      | 0.08           |\\n| -1.5| 0.20      | -         | -              |\\n| -3  | 0.06      | 0.27      | 0.13           |\\n| -4.5| 0.24      | -         | -              |\\n| -6  | 0.25      | -         | -              |\\n| -7.5| 0.57      | -         | -              |\\n\\nTable 4: As for Table 3 (left) but for the data of [12].\\n\\n**PDF**\\n\\n- **0 dB quiet**\\n- **-3 dB**\\n- **-6 dB**\\n\\nFigure 4: Glimpsing analysis suggested that listeners employed a consistent goal in tilt adjustment, aiming to ensure the availability of speech glimpses across a wide frequency range. Based on these findings, we proposed a model to predict listener's tilt preferences.\\n\\nListeners' adjustments were effective in maintaining intelligibility down to an SNR of nearly -5 dB. Longer adjustment times were needed for the -4.5 dB and -3 dB SNRs compared to less noisy conditions. The longer adjustment time required may indicate an increase in the cognitive effort required to process speech in noise, or the difficulty in finding an effective compromise between choosing a signal that sounds natural (i.e., with tilt close to the original) or one that preserves audibility across as much of the spectrum as possible. Data in noise is lacking, but Moore and Tan [23] found that in quiet, spectral tilt modifications have a negative impact on naturalness, particularly when applied over the entire frequency range.\\n\\nBased on our observations of how listeners tend to choose spectral tilt in noise, we proposed a model to estimate the likelihood of a speech signal being preferred. An alternative approach for predicting listener preferences was suggested in [12], which involved computing glimpses for each preference level using the extended glimpse proportion metric [21] and fitting the derived distribution to the listener preferences distribution. One distribution was fit in each different noise condition. However, this approach has a limitation in predicting preferences for unseen SNRs or spectral tilts. In contrast, our model is not tailored to specific listener preference distributions, making it more capable of generalisation, as demonstrated for the Spanish data of [12]. While a comparison of columns 3 and 4 of Table 1 indicates that the current model performed slightly worse than that reported in [12], a fairer comparison would involve training the model used in the Spanish experiment with Greek data and then comparing the predicted listener preferences with the actual Spanish listener preferences. Further research is necessary to assess the generalisability of the current model.\"}"}
{"id": "simantiraki23_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. References\\n\\n[1] C. Delogu, S. Conte, and C. Sementina, \u201cCognitive factors in the evaluation of synthetic speech,\u201d *Speech Communication*, vol. 24, no. 2, pp. 153\u2013168, 1998.\\n\\n[2] A. Govender and S. King, \u201cUsing pupillometry to measure the cognitive load of synthetic speech,\u201d in *Proc. Interspeech*, 2018, pp. 2838\u20132842.\\n\\n[3] O. Simantiraki, M. Cooke, and S. King, \u201cImpact of different speech types on listening effort,\u201d in *Proc. Interspeech*, 2018, pp. 2267\u20132271.\\n\\n[4] C. Pals, A. Sarampalis, and D. Baskent, \u201cListening effort with cochlear implant simulations,\u201d *J. Speech Hearing Language Res.*, vol. 56, pp. 1075\u20131084, 2013.\\n\\n[5] G. Borghini and V. Hazan, \u201cEffects of acoustic and semantic cues on listening effort during native and non-native speech perception,\u201d *The Journal of the Acoustical Society of America*, vol. 147, no. 6, pp. 3783\u20133794, 2020.\\n\\n[6] P. F. Assmann and T. M. Nearey, \u201cRelationship between fundamental and formant frequencies in voice preference,\u201d *The Journal of the Acoustical Society of America*, vol. 122, no. 2, pp. EL35\u2013EL43, 2007.\\n\\n[7] J. S. Novak and R. V. Kenyon, \u201cEffects of user controlled speech rate on intelligibility in noisy environments,\u201d in *Proc. Interspeech*, 2018, pp. 1853\u20131857.\\n\\n[8] O. Simantiraki and M. Cooke, \u201cExploring listeners\u2019 speech rate preferences,\u201d in *Proc. Interspeech*, 2020, pp. 1346\u20131350.\\n\\n[9] M. Torcoli, A. Freke-Morin, J. Paulus, C. Simon, and B. Shirley, \u201cPreferred levels for background ducking to produce esthetically pleasing audio for tv with clear speech,\u201d *J Audio Eng Soc.*, vol. 67, no. 12, pp. 1003\u20131011, 2019.\\n\\n[10] A. Boothroyd and C. Mackersie, \u201cA \u201cGoldilocks\u201d Approach to Hearing-Aid Self-Fitting: User Interactions,\u201d *American Journal of Audiology*, vol. 26, no. 3S, pp. 430\u2013435, 2017.\\n\\n[11] A. T. Sabin, D. J. V. Tasell, B. Rabinowitz, and S. Dhar, \u201cValidation of a Self-Fitting Method for Over-the-Counter Hearing Aids,\u201d *Trends in Hearing*, vol. 24, p. 2331216519900589, 2020.\\n\\n[12] O. Simantiraki, M. Cooke, and Y. Pantazis, \u201cEffects of Spectral Tilt on Listeners\u2019 Preferences And Intelligibility,\u201d in *IEEE International Conference on Acoustics, Speech and Signal Processing*, 2020, pp. 6254\u20136258.\\n\\n[13] J. F. Strand, V. A. Brown, M. B. Merchant, H. E. Brown, and J. Smith, \u201cMeasuring Listening Effort: Convergent Validity, Sensitivity, and Links With Cognitive and Personality Measures,\u201d *Journal of Speech, Language, and Hearing Research*, vol. 61, no. 6, pp. 1463\u20131486, 2018.\\n\\n[14] J. Johnson, J. Xu, R. Cox, and P. Pendergraft, \u201cA Comparison of Two Methods for Measuring Listening Effort As Part of an Audiologic Test Battery,\u201d *American Journal of Audiology*, vol. 24, no. 3, pp. 419\u2013431, 2015.\\n\\n[15] S. Seeman and R. Sims, \u201cComparison of Psychophysiological and Dual-Task Measures of Listening Effort,\u201d *Journal of Speech, Language, and Hearing Research*, vol. 58, no. 6, pp. 1781\u20131792, 2015.\\n\\n[16] R. Huber, M. Kr\u00fcger, and B. T. Meyer, \u201cSingle-ended prediction of listening effort using deep neural networks,\u201d *Hearing Research*, vol. 359, pp. 40\u201349, 2018.\\n\\n[17] A. Sfakianaki, \u201cDesigning a Modern Greek sentence corpus for audiological and speech technology research,\u201d in *Proc. of the 14th International Conference on Greek Linguistics*, 2019.\\n\\n[18] E. H. Rothauser, W. D. Chapman, N. Guttman, H. R. Silbiger, M. H. L. Hecker, G. E. Urbanek, K. S. Nordby, and M. Weinstock, \u201cIEEE recommended practice for speech quality measurements,\u201d *IEEE Transactions on Audio and Electroacoustics*, vol. 17, pp. 225\u2013246, 1969.\\n\\n[19] V. Aubanel, M. Garc\u00eda Lecumberri, and M. Cooke, \u201cThe Sharvard Corpus: A phonemically-balanced Spanish sentence resource for audiology,\u201d *International Journal of Audiology*, vol. 53, no. 9, pp. 633\u2013638, 2014.\\n\\n[20] O. Simantiraki and M. Cooke, \u201cSpeechAdjuster: A Tool for Investigating Listener Preferences and Speech Intelligibility,\u201d in *Proc. Interspeech 2021*, 2021, pp. 1718\u20131722.\\n\\n[21] Y. Tang and M. Cooke, \u201cGlimpse-Based Metrics for Predicting Speech Intelligibility in Additive Noise Conditions,\u201d in *Interspeech 2016*, 2016, pp. 2488\u20132492.\\n\\n[22] Y. Lu and M. Cooke, \u201cSpeech production modifications produced by competing talkers, babble, and stationary noise,\u201d *The Journal of the Acoustical Society of America*, vol. 124, no. 5, pp. 3261\u20133275, 2008.\\n\\n[23] B. C. J. Moore and C.-T. Tan, \u201cPerceived naturalness of spectrally distorted speech and music,\u201d *The Journal of the Acoustical Society of America*, vol. 114, no. 1, pp. 408\u2013419, 2003.\"}"}
