{"id": "yang22i_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. References\\n\\n[1] E. Lombard, \u201cLe signe de l'elevation de la voix,\u201d Ann. Mal. de L'Oreille et du Larynx, pp. 101\u2013119, 1911.\\n\\n[2] S. Uma Maheswari, A. Shahina, and A. Nayeemulla Khan, \u201cUnderstanding lombard speech: a review of compensation techniques towards improving speech based recognition systems,\u201d Artificial Intelligence Review, vol. 54, no. 4, pp. 2495\u20132523, 2021.\\n\\n[3] V. C. Tartter, H. Gomes, and E. Litwin, \u201cSome acoustic effects of listening to noise on speech production,\u201d The Journal of the Acoustical Society of America, vol. 94, no. 4, pp. 2437\u20132440, 1993.\\n\\n[4] Y. Lu and M. Cooke, \u201cSpeech production modifications produced by competing talkers, babble, and stationary noise,\u201d The Journal of the Acoustical Society of America, vol. 124, no. 5, pp. 3261\u20133275, 2008.\\n\\n[5] H. Bo\u02c7ril and J. H. Hansen, \u201cUt-scope: Towards lvcsr under lombard effect induced by varying types and levels of noisy background,\u201d in 2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2011, pp. 4472\u20134475.\\n\\n[6] J. H. Hansen and V. Varadarajan, \u201cAnalysis and compensation of lombard speech across noise type and levels with application to in-set/out-of-set speaker recognition,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 17, no. 2, pp. 366\u2013378, 2009.\\n\\n[7] G. Bapineedu, \u201cAnalysis of lombard effect speech and its application in speaker verification for imposter detection,\u201d Ph.D. dissertation, Citeseer, 2010.\\n\\n[8] M. Vainio, D. Aalto, A. Suni, A. Arnhold, T. Raitio, H. Seijo, J. J\u00e4rvikivi, and P. Alku, \u201cEffect of noise type and level on focus related fundamental frequency changes,\u201d in Thirteenth Annual Conference of the International Speech Communication Association, 2012.\\n\\n[9] N. Alghamdi, S. Maddock, R. Marxer, J. Barker, and G. J. Brown, \u201cA corpus of audio-visual lombard speech with frontal and profile views,\u201d The Journal of the Acoustical Society of America, vol. 143, no. 6, pp. EL523\u2013EL529, 2018.\\n\\n[10] V. Hazan and R. Baker, \u201cAcoustic-phonetic characteristics of speech produced with communicative intent to counter adverse listening conditions,\u201d The Journal of the Acoustical Society of America, vol. 130, no. 4, pp. 2139\u20132152, 2011.\\n\\n[11] J. H. Hansen and V. Varadarajan, \u201cAnalysis and compensation of lombard speech across noise type and levels with application to in-set/out-of-set speaker recognition,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 17, no. 2, pp. 366\u2013378, 2009.\\n\\n[12] J. E. Huber and B. Chandrasekaran, \u201cEffects of increasing sound pressure level on lip and jaw movement parameters and consistency in young adults,\u201d 2006.\\n\\n[13] Y. Zhao and D. Jurafsky, \u201cThe effect of lexical frequency and lombard reflex on tone hyperarticulation,\u201d Journal of Phonetics, vol. 37, no. 2, pp. 231\u2013247, 2009.\\n\\n[14] C. H. Taal, R. C. Hendriks, R. Heusdens, and J. Jensen, \u201cAn algorithm for intelligibility prediction of time\u2013frequency weighted noisy speech,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 7, pp. 2125\u20132136, 2011.\\n\\n[15] M. Cooke, J. Barker, S. Cunningham, and X. Shao, \u201cAn audio-visual corpus for speech perception and automatic speech recognition,\u201d The Journal of the Acoustical Society of America, vol. 120, no. 5, pp. 2421\u20132424, 2006.\\n\\n[16] Philips, \u201cHear better with philips hearing solutions,\u201d https://www.hearingsolutions.philips.com.cn/hearing-loss/hearing-test, accessed: 2021-11-28.\\n\\n[17] P. Demonte, \u201cSpeech shaped noise master audio-HARVARD speech corpus,\u201d 2019. [Online]. Available: https://salford.figshare.com/articles/Speech_shaped_noise_master_audio_HARVARD_speech_corpus/9988655/1\\n\\n[18] S. Y. Won, J. Berger, and M. Slaney, \u201cSimulation of one's own voice in a two-parameter model,\u201d in Proc Int Conf Music Percept Cogn, 2014.\\n\\n[19] M. McAuliffe, M. Socolof, S. Mihuc, M. Wagner, and M. Sonderegger, \u201cMontreal forced aligner: Trainable text-speech alignment using kaldi.\u201d in Interspeech, vol. 2017, 2017, pp. 498\u2013502.\\n\\n[20] D. W. Paul Boersma, \u201cPraat: doing phonetics by computer,\u201d https://www.fon.hum.uva.nl/praat/, accessed: 2021-11-28.\\n\\n[21] F. Eyben, M. W\u00f6llmer, and B. Schuller, \u201cOpensmile: the munich versatile and fast open-source audio feature extractor,\u201d in Proceedings of the 18th ACM international conference on Multimedia, 2010, pp. 1459\u20131462.\\n\\n[22] F. Eyben, K. R. Scherer, B. W. Schuller, J. Sundberg, E. Andr\u00e9, C. Busso, L. Y. Devillers, J. Epps, P. Laukka, S. S. Narayanan et al., \u201cThe geneva minimalistic acoustic parameter set (gemaps) for voice research and affective computing,\u201d IEEE transactions on affective computing, vol. 7, no. 2, pp. 190\u2013202, 2015.\\n\\n[23] J. Sundberg and M. Nordenberg, \u201cEffects of vocal loudness variation on spectrum balance as reflected by the alpha measure of long-term-average spectra of speech,\u201d The Journal of the Acoustical Society of America, vol. 120, no. 1, pp. 453\u2013457, 2006.\"}"}
{"id": "yang22i_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Mandarin Lombard Grid: A Noise Induced Lombard-Grid-Like Corpus of Standard Chinese\\n\\nYuhong Yang1,2,\u2217, Xufeng Chen1, Qingmu Liu1, Weiping Tu1,2, Hongyang Chen1, Linjun Cai1\\n\\n1National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China\\n2Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan, China\\nyangyuhong, luizzz@whu.edu.cn\\n\\nAbstract\\nThe Lombard effect is natural, whereby speakers automatically adjust the vocal effort to facilitate speech understanding in noise. Since real-world applications are generally involved in noisy environments, the Lombard effect of highly variable speech features due to changing background noise is one of those challenges to match these real scenarios. Existing Lombard corpora show variations in the background noise level, ranging from 35 to 96 dB sound pressure level (SPL). However, it remains unclear if we need to collect all SPLs to build a comprehensive Lombard corpus. And most existing Lombard corpora are built for English; however, Mandarin and English are different in pronunciation. This paper describes our effort to build the first open-source Lombard corpus of standard Chinese, the Mandarin Lombard Grid. The effort involves three steps: (1) Classify Mandarin Lombard styles according to different background noise levels. (2) Create the corpus containing each style. (3) Analyze Mandarin Lombard effects showing their differences from English. We found three critical Lombard styles ranging from 30 dB to 85 dB-SPL and built the corpus containing the three Lombard styles and one reference plain style. Lombard effect analyses on this corpus showed consistency and some differences with the English Lombard Grid corpus.\\n\\nIndex Terms: Mandarin speech corpus, Lombard effect, Lombard style classification\\n\\n1. Introduction\\nLombard effect is a natural process in which the speaker automatically adjusts the vocal efforts to facilitate speech comprehension in noise [1] [2]. Lombard effects are common since speech communication in the wild is generally involved in noisy environments. The Lombard effect of highly variable speech features is challenging to match these real scenarios due to changing background noise.\\n\\nResearchers have developed over 40 Lombard corpora for analyzing and processing Lombard speech to improve the performance of various speech processing applications [2]. These corpora show the variations in the background noise level, ranging from 35 to 96 dB sound pressure levels (SPLs). The sample study include 35, 60, 80 dB [3], 82, 89, 96 dB [4], 65 to 90 dB in step of 5 dB [5] [6], 45 to 70 dB in step of 5 dB [7], 60, 70, 80 dB [8], 80 dB [9]. However, it remains unclear if all these SPLs associated with different Lombard styles. Lombard speech collection stresses the ears and vocal effort, and might impose hearing damage or auditory fatigue. Do we need to collect all the SPLs to build a comprehensive Lombard corpus? Therefore, there is a pressing need to identify critical Lombard styles based on a fundamental unit in background noise levels. The unit is the critical interval, a background noise level interval that varies according to its representative level, presumed to represent the same critical Lombard style.\\n\\nResearchers build over 20 Lombard corpora for English [2, 10\u201312], and there is only one non-open-source Cantonese (a Chinese dialect) Lombard corpus [13], eliciting Lombard effect with isolated monosyllables. However, there is no collection of Mandarin Lombard corpus. Mandarin and English are different in pronunciation. For example, Mandarin is a tonal language, using a phoneme sound\u2019s pitch (highness or lowness) to distinguish a word. In contrast, English uses changes in pitch to emphasize or express emotion. We still need to know about the Lombard effect on continuous speech in Mandarin. If Lombard effect plays a universal role in increasing vocal effort, we would expect to see similar Lombard effects in Mandarin. Or, if Lombard effect plays its role in a more complex way, we might get some different effects in Mandarin.\\n\\nTo handle the above limitations, we summarize our main contributions as follows:\\n\\n\u2022 We employed the popular Short-Time Objective Intelligibility (STOI) [14] score to evaluate speech intelligibility which is more in line with speech understanding. We proposed an STOI-based measure in the auditory self-feedback space to check the significant difference between two sets of Lombard speech utterances recorded at different background noise levels. We are the first to classify the critical Lombard styles ranging from 30 to 85 dB-SPL.\\n\\n\u2022 We built the first Mandarin Lombard corpus that covered each critical Lombard style resulting from the previous classification plus a reference plain style. The corpus is being made freely available for download under a Creative Commons Attribution International license. Our corpus is available at https://github.com/ASP-WHU/Mandarin-Lombard-Grid.\\n\\n\u2022 We followed the Lombard Grid corpus [9], the only publicly available English Lombard corpus with parallel plain speech and Lombard speech utterances, which were well facilitated with Lombard effect analysis. We also extracted acoustic parameters such as a fundamental frequency (F0), a signal energy (Loudness), a tilt of the speech spectrum (Alpha ratio) and four parameters to characterize the vowels: a vowel duration, a vowel to utterance ratio, and the first and second formant frequencies (F1 and F2) to compare the Lombard effect between the Mandarin and English Lombard corpus. We found Mandarin indeed show consistency and some differences compared with English when speaking in a 80 dB-SPL.\"}"}
{"id": "yang22i_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2. Lombard Style Classification\\n\\n2.1. Lombard speech collection\\n\\n2.1.1. Sentence selection\\nFollowing [9] [15], we structured the sentences in the corpus in a 'Grid'-like format. Sentences were made up of five components, which were name, verb, classifier, adjective and noun in order. Each component had 20 phoneme-balance candidate words that were chosen randomly to build sentences. We created a unique set of 30 \u201cgrid\u201d-like sentences for each speaker, grouped into three long sets of 10 sentences each.\\n\\n2.1.2. Speaker recruitment\\nWe recruited four speakers (two female speakers and two male speakers) to read the sentences. All participants were native Mandarin speakers who have no or only a faint accent. Subjects were required to take an online hearing test on the official Philips hearing test website [16]. They put on headphones and set the volume level to 50% while ensuring there were no distracting sounds around them. Then four situational questions were asked to ensure they have no hearing impairment. We paid all participants for their contributions.\\n\\n2.1.3. Recording setup\\nWe performed the audio recording process in the anechoic chamber of 3-D Audio Lab with less than 21 dB (A-weighted) background noise at Wuhan University. Digital signals were recorded by a computer configured with an RME sound card and interface ADA8200. The sampling rate was 48 kHz; the quantization bit depth was 32 bits (We employed the high-quality setting for future extension regardless of the analog-to-digital limitation of microphones). The microphone used for recording was audio-technica AT2020USB, placed approximately 0.3 m in front of the speaker\u2019s mouth. We set the microphone\u2019s recording volume as follows. We adjusted the recording volume of microphone to make sure that the loudest male speaker\u2019s Lombard speech didn\u2019t get clipped when speaking with 80 dB SPL of background noise. The speaker and dummy head wore Sennheiser HD 8 DJ headphones.\\n\\nFollowing the study [9], we used speech-shaped noise (SSN) to stimulate the Lombard effect. In this study, SSN was obtained from Speech shaped noise master audio - harvard speech corpus [17], which was generated by 52nd order linear predictive coding. We set SSN to 12 levels from 30 to 85 dB at 5 dB intervals, and presented the 12 decibel levels in order. As shown in Figure 2, we used one computer to collect noise and Lombard speech simultaneously and another computer to control the same noise played in headphones worn on the speaker and dummy head. The noise had been adjusted to correspond to the SPL in advance by a ONOSOKKI LA-440 sound pressure meter. Speakers were inside the anechoic chamber, while the dummy head and researcher were outside. The researcher communicated with speakers by video through the iPad, acting as a listener.\\n\\nResearchers first configured the devices and adjusted the background noise (SPL). Subjects entered the anechoic chamber and put on headphones speaking at will to adapt to the current noise stimulation. Each speaker read a set of 30 speech sentences in each noise SPL, respectively. Speakers informed the researcher outside the anechoic chamber of their sentence group number before starting and speaking after receiving the okay gesture from the researcher. After reading the group, the subject could take a short break while the researcher checked the recording for errors. If there were errors, the speaker needed to re-record the group.\\n\\n2.2. Self-feedback voice model\\nTo simulate the mixed-signal perceived by the human ear, we employed a two-parameter self-feedback voice model involving both air-conducted and bone-conducted pathway [18]. The speech recorded by the microphone was transmitted through this two-parameter model to obtain the self-hearing sound.\\n\\n2.3. STOI-based significance test\\nWe conducted a paired sample \\\\( t \\\\)-test to find out whether there was a significant difference in intelligibility at two different noise SPLs. We added both the paired Lombard speech collections with the background noise with relative higher SPL; calculated the STOI score for each merged group (10 sentences each) pair, and conducted a significant difference test to identify whether there was a critical interval in background noise SPLs.\\n\\n2.4. SPL-based Lombard style classification\\nThe results are shown in Table 1. There were significant differences between 30 dB and 45 dB, 45 dB and 70 dB, 70 dB and 85 dB.\"}"}
{"id": "yang22i_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Based on the results, we determined the critical interval of Lombard style as [30 dB, 40 dB], [45 dB, 65 dB], [70 dB, 70 dB] and [75 dB, 85 dB]. We chose 30 dB as plain style, and 55 dB, 70 dB, and 80 dB to represent each critical Lombard style associated with each critical interval. These dB-SPLs were used to guide the subsequent corpus collection.\\n\\nTable 1: T-test results of STOI measure scores between different levels (* indicates p < 0.05, referring to a significant difference)\\n\\n| SPL (dB) | t Stat | p    |\\n|---------|--------|------|\\n| 30/35   | 0.766  | 0.452|\\n| 30/40   | -0.024 | 0.981|\\n| 30/45   | -2.370 | 0.028*|\\n| 30/50   | 0.213  | 0.833|\\n| 30/55   | 0.311  | 0.759|\\n| 30/60   | -0.203 | 0.841|\\n| 45/40   | -1.628 | 0.119|\\n| 45/45   | 2.427  | 0.024*|\\n| 45/50   | 0.213  | 0.833|\\n| 45/55   | -0.311 | 0.759|\\n| 45/60   | 0.667  | 0.512|\\n\\n3. Mandarin Lombard Corpus\\n\\nThe corpus followed the sentence selection, speaker recruitment, and recording setup of the previous section. The Lombard speech data was obtained from 28 native Mandarin speakers (14 male speakers and 14 female speakers). They were students at Wuhan University in the 20-25 year age range, who had no or only a faint accent. We employed SSN at 55, 70, 80 dB-SPL to induce Lombard speech and SSN at 30 dB-SPL to include plain speech. The four levels of noise were presented from low to high. We created a unique set of 100 'Grid'-like sentences for each speaker. We used the Montreal Forced Aligner [19] to produce phonetic transcriptions in TextGrid format, which contained word and phoneme boundaries. For each speaker, the corpus contained the following data:\\n\\n\u2022 Speech recordings: 100 utterances of Grid like sentences at each dB-SPL, with four parallel sets of 100 utterances;\\n\u2022 Word and phoneme level transcriptions: orthographic transcription and forced-aligned word and phoneme boundaries for each sentence.\\n\\n4. Analysis of Lombard Effect\\n\\nWe extracted vowel, formant, and acoustic parameters from the plain speech and the Lombard speech at three noise levels to investigate the Lombard effect [9]. We calculated the average vowel duration, and the ratio of total vowel duration to utterance duration to characterize the vowels. As for formant parameters, we employed Praat [20] to estimate the first and second formant frequencies (F1 and F2). The openSMILE [21] tools were used to extract three acoustic parameters from the Geneva Minimalistic Acoustic Parameter Set (GeMAPS) [22]. These acoustic parameters included a fundamental frequency related parameter (F0), the F0 mean; an energy-related parameter, the loudness mean; and a spectral parameter, the alpha ratio mean [23] (energy ratio between 50-1000 Hz and 1-15 kHz).\\n\\nBased on the above seven acoustic parameters, we conducted two Lombard effect analyses as follows:\\n\\n4.1. Lombard effect analysis of the Mandarin Corpus\\n\\nFigure 3 shows the speakers' means in plain (30 dB) and 80 dB Lombard style for each of the seven parameters. Although all speakers showed almost the same variation trend, the range of variation still differed. Table 2 summarizes the subjects' means and standard deviation under each noise SPL for each of the seven parameters. Paired-samples t-tests were employed to determine the significance of differences between the cross-speaker means, cross-female-speaker means, and cross-male-speaker means in two adjacent noise conditions. We also summarized the results of statistical analysis in Table 2.\\n\\n- Both vowel duration and F2 frequency show a non-significant overall increased for all adjacent pairs. All parameters, except for F1 frequency, showed a non-significant overall increase between 30 and 55 dB-SPLs.\\n- The frequency of F1 showed a significant overall increase for all adjacent pairs. We verified a significant difference for all the classified Lombard styles.\\n- The Vowel-to-utterance ratio, F0 frequency, loudness and alpha ratio altogether showed significant overall increase between two higher adjacent pairs (55 vs. 70, 70 vs. 80), and showed non-significant overall increase between 30 and 50 dB-SPLs. These might suggest highly variable speech feature for Lombard styles at higher dB-SPLs.\\n\\n4.2. Lombard effect comparison between the Mandarin and English corpus\\n\\nWe observed the adaptation of Lombard speech vs. the plain speech of this corpus, and compare it with the reported study in the English Lombard grid [9]. As shown in Table 3, both corpora included speech-shaped noise (SSN) at 80 dB-SPL to induce Lombard speech for a fair comparison between Mandarin and English. All parameters, except for F2 frequency, showed...\"}"}
{"id": "yang22i_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 2: The mean and SD (M \u00b1 SD) of parameters of all speakers, female speakers (F) and male speakers (M). The \\\"t\\\" columns summarize the results of statistical analyses (t-tests) between two adjacent dB-SPL conditions. Symbols: increase \u2191, decrease \u2193. (* indicates \\\\( p < 0.001 \\\\), referring to a significant difference)\\n\\n|                        | SPL (dB) | 30   | 55   | 70   | 80   |\\n|------------------------|----------|------|------|------|------|\\n| Vowel duration (ms)    |          |      |      |      |      |\\n| All                    |          | 121\u00b124 | 126\u00b125 | 130\u00b125 | 132\u00b125 |\\n| F                      |          | 124\u00b123 | 125\u00b125 | 130\u00b123 | 132\u00b125 |\\n| M                      |          | 117\u00b124 | 126\u00b125 | 129\u00b125 | 132\u00b125 |\\n| Vowel to utterance ratio |          | 0.4605\u00b10.078 | 0.4778\u00b10.079 | 0.4949\u00b10.075 | 0.5086\u00b10.080 |\\n| All                    |          | 0.4605\u00b10.078 | 0.4778\u00b10.079 | 0.4949\u00b10.075 | 0.5086\u00b10.080 |\\n| F                      |          | 0.4597\u00b10.076 | 0.4691\u00b10.080 | 0.4916\u00b10.067 | 0.5000\u00b10.068 |\\n| M                      |          | 0.4613\u00b10.081 | 0.4865\u00b10.078 | 0.4981\u00b10.082 | 0.5043\u00b10.074 |\\n| Vowel F1 (Hz)          |          | 542\u00b1184 | 563\u00b1188 | 590\u00b1191 | 608\u00b1191 |\\n| All                    |          | 542\u00b1184 | 563\u00b1188 | 590\u00b1191 | 608\u00b1191 |\\n| F                      |          | 588\u00b1199 | 610\u00b1203 | 643\u00b1202 | 662\u00b1196 |\\n| M                      |          | 495\u00b1155 | 516\u00b1158 | 538\u00b1164 | 554\u00b1168 |\\n| Vowel F2 (Hz)          |          | 1640\u00b1429 | 1642\u00b1420 | 1642\u00b1413 | 1645\u00b1405 |\\n| All                    |          | 1640\u00b1429 | 1642\u00b1420 | 1642\u00b1413 | 1645\u00b1405 |\\n| F                      |          | 1752\u00b1443 | 1756\u00b1433 | 1747\u00b1420 | 1752\u00b1412 |\\n| M                      |          | 1528\u00b1382 | 1528\u00b1373 | 1536\u00b1377 | 1538\u00b1369 |\\n| F0                     |          | 32.3\u00b15.3 | 32.6\u00b15.3 | 33.2\u00b15.2 | 34.0\u00b15.0 |\\n| All                    |          | 32.3\u00b15.3 | 32.6\u00b15.3 | 33.2\u00b15.2 | 34.0\u00b15.0 |\\n| F                      |          | 37.1\u00b12.2 | 37.4\u00b12.0 | 37.9\u00b12.0 | 38.5\u00b11.9 |\\n| M                      |          | 27.5\u00b12.2 | 27.7\u00b12.3 | 28.5\u00b12.4 | 29.4\u00b12.3 |\\n| Loudness               |          | 0.108\u00b10.045 | 0.118\u00b10.047 | 0.154\u00b10.052 | 0.195\u00b10.067 |\\n| All                    |          | 0.108\u00b10.045 | 0.118\u00b10.047 | 0.154\u00b10.052 | 0.195\u00b10.067 |\\n| F                      |          | 0.115\u00b10.038 | 0.116\u00b10.038 | 0.152\u00b10.037 | 0.196\u00b10.053 |\\n| M                      |          | 0.102\u00b10.051 | 0.120\u00b10.054 | 0.156\u00b10.063 | 0.195\u00b10.078 |\\n| Alpha ratio            |          | -13.98\u00b13.85 | -12.75\u00b13.84 | -10.61\u00b13.38 | -9.01\u00b13.13 |\\n| All                    |          | -13.98\u00b13.85 | -12.75\u00b13.84 | -10.61\u00b13.38 | -9.01\u00b13.13 |\\n| F                      |          | -14.62\u00b13.90 | -13.59\u00b13.99 | -10.64\u00b13.29 | -8.93\u00b13.20 |\\n| M                      |          | -13.33\u00b13.69 | -11.91\u00b13.48 | -10.58\u00b13.47 | -9.10\u00b13.06 |\\n\\nA significant overall increase; and F2 frequency showed a non-significant difference between 30 dB and 80 dB-SPLs for both languages. We also identified some differences between these two languages as follows:\\n\\n- Chinese speakers showed more increases in vowel-to-utterance ratio, which was linked to fuller realization of vowels compared with English speakers. While Chinese speakers showed less increases in vowel duration, probably due to gradual familiarization with the text content.\\n- Chinese speakers showed more increases in F1 frequency, which was associate with a greater change in tongue downward position, while English speakers showed more increases in loudness.\\n- Female speakers showed more rise in alpha ratio than males in Mandarin. In contrast, female speakers and male speakers showed the same increase in alpha ratio in English.\\n\\nThis differences may indicate that Chinese and English speakers respond differently to the auditory feedback of the Lombard effect.\\n\\n### Table 3: Comparison of parameters with Lombard Grid. The \\\"t\\\" columns summarize the results of statistical analyses (t-tests) between plain and Lombard conditions. Symbols: increase \u2191, decrease \u2193. (* indicates \\\\( p < 0.001 \\\\), referring to a significant difference)\\n\\n|                        | SPL (dB) | 30   | 80   |\\n|------------------------|----------|------|------|\\n| Mandarin/English [9]   |          |      |      |\\n| Vowel duration (ms)    |          |      |      |\\n| All                    |          | 121\u00b124 | 132\u00b125 |\\n| F                      |          | 124\u00b123 | 132\u00b125 |\\n| M                      |          | 117\u00b124 | 132\u00b125 |\\n| Vowel to utterance ratio |          | 0.4605\u00b10.078 | 0.5086\u00b10.080 |\\n| All                    |          | 0.4605\u00b10.078 | 0.5086\u00b10.080 |\\n| F                      |          | 0.4597\u00b10.076 | 0.5000\u00b10.068 |\\n| M                      |          | 0.4613\u00b10.081 | 0.5043\u00b10.074 |\\n| Vowel F1 (Hz)          |          | 542\u00b1184 | 608\u00b1191 |\\n| All                    |          | 542\u00b1184 | 608\u00b1191 |\\n| F                      |          | 588\u00b1199 | 662\u00b1196 |\\n| M                      |          | 495\u00b1155 | 554\u00b1168 |\\n| Vowel F2 (Hz)          |          | 1640\u00b1429 | 1645\u00b1405 |\\n| All                    |          | 1640\u00b1429 | 1645\u00b1405 |\\n| F                      |          | 1752\u00b1443 | 1752\u00b1412 |\\n| M                      |          | 1528\u00b1382 | 1538\u00b1369 |\\n| F0                     |          | 32.3\u00b15.3 | 34.0\u00b15.0 |\\n| All                    |          | 32.3\u00b15.3 | 34.0\u00b15.0 |\\n| F                      |          | 37.1\u00b12.2 | 38.5\u00b11.9 |\\n| M                      |          | 27.5\u00b12.2 | 29.4\u00b12.3 |\\n| Loudness               |          | 0.108\u00b10.045 | 0.195\u00b10.067 |\\n| All                    |          | 0.108\u00b10.045 | 0.195\u00b10.067 |\\n| F                      |          | 0.115\u00b10.038 | 0.196\u00b10.053 |\\n| M                      |          | 0.102\u00b10.051 | 0.195\u00b10.078 |\\n| Alpha ratio            |          | -13.98\u00b13.85 | -9.01\u00b13.13 |\\n| All                    |          | -13.98\u00b13.85 | -9.01\u00b13.13 |\\n| F                      |          | -14.62\u00b13.90 | -8.93\u00b13.20 |\\n| M                      |          | -13.33\u00b13.69 | -9.10\u00b13.06 |\"}"}
