{"id": "thithuuyen22_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBert: Pre-training of deep bidirectional transformers for language understanding,\u201d in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019, pp. 4171\u20134186.\\n\\nN. Anh Tu, H. Thi Thu Uyen, T. Minh Phuong, and N. Xuan Bach, \u201cAnalyzing Vietnamese legal questions using deep neural networks with biaffine classifiers,\u201d in International Conference on Neural Information Processing. Springer, 2021, pp. 513\u2013525.\\n\\nO. T. Tran et al., \u201cPunctuation prediction in Vietnamese ASR using transformer-based models,\u201d in Pacific Rim International Conference on Artificial Intelligence. Springer, 2021, pp. 191\u2013204.\\n\\nQ. T. Nguyen, T. L. Nguyen, N. H. Luong, and Q. H. Ngo, \u201cFine-tuning Bert for sentiment analysis of Vietnamese reviews,\u201d in 2020 7th NAFOSTED Conference on Information and Computer Science (NICS). IEEE, 2020, pp. 302\u2013307.\\n\\nT. O. Tran, P. Le Hong et al., \u201cImproving sequence tagging for Vietnamese text using transformer-based neural models,\u201d in Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation, 2020, pp. 13\u201320.\\n\\nM. Federico, S. Stuker, L. Bentivogli, M. Paul, M. Cettolo, T. Hermann, J. Niehues, and G. Moretti, \u201cThe IWSLT 2011 evaluation campaign on automatic talk translation,\u201d in International Conference on Language Resources and Evaluation (LREC), 2012, pp. 3543\u20133550.\\n\\nA. Gravano, M. Jansche, and M. Bacchiani, \u201cRestoring punctuation and capitalization in transcribed speech,\u201d in 2009 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2009, pp. 4741\u20134744.\\n\\nX. Wang, H. T. Ng, and K. C. Sim, \u201cDynamic conditional random fields for joint sentence boundary and punctuation prediction,\u201d in Thirteenth Annual Conference of the International Speech Communication Association, 2012.\\n\\nT. T. H. Nguyen, T. B. Nguyen, N. P. Pham, Q. Truong, T. L. Le, and C. M. Luong, \u201cToward human-friendly ASR systems: Recovering capitalization and punctuation for Vietnamese text,\u201d IEICE TRANSACTIONS on Information and Systems, vol. 104, no. 8, pp. 1195\u20131203, 2021.\\n\\nB. Nguyen, V. B. H. Nguyen, H. Nguyen, P. N. Phuong, T.-L. Nguyen, Q. T. Do, and L. C. Mai, \u201cFast and accurate capitalization and punctuation for automatic speech recognition using transformer and chunk merging,\u201d in 2019 22nd Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA). IEEE, 2019, pp. 1\u20135.\\n\\nV. Pahuja, A. Laha, S. Mirkin, V. Raykar, L. Kotlerman, and G. Lev, \u201cJoint learning of correlated sequence labeling tasks using bidirectional recurrent neural networks, IBM Research,\u201d INTERSPEECH 2017. http://dx.doi.org/10.21437/Interspeech, vol. 1247, 2017.\\n\\nM. S. S. R. K. Dixit and S. B. K. Kirchhoff, \u201cRobust prediction of punctuation and truecasing for medical ASR,\u201d ACL 2020, p. 53, 2020.\\n\\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances in neural information processing systems, 2017, pp. 5998\u20136008.\\n\\nY. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \u201cRoberta: A robustly optimized bert pretraining approach,\u201d arXiv preprint arXiv:1907.11692, 2019.\\n\\nK. Clark, M.-T. Luong, Q. V. Le, and C. D. Manning, \u201cElecTRA: Pre-training text encoders as discriminators rather than generators,\u201d in ICLR, 2020.\\n\\nA. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzm\u00e1n, \u00b4E. Grave, M. Ott, L. Zettlemoyer, and V. Stoyanov, \u201cUnsupervised cross-lingual representation learning at scale,\u201d in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 8440\u20138451.\\n\\nA. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., \u201cPyTorch: An imperative style, high-performance deep learning library,\u201d Advances in neural information processing systems, vol. 32, pp. 8026\u20138037, 2019.\\n\\nT. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. Le Scao, S. Gugger, M. Drame, Q. Lhoest, and A. Rush, \u201cTransformers: State-of-the-art natural language processing,\u201d in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics, Oct. 2020, pp. 38\u201345. [Online]. Available: https://aclanthology.org/2020.emnlp-demos.6\\n\\nI. Loshchilov and F. Hutter, \u201cDecoupled weight decay regularization,\u201d in International Conference on Learning Representations, 2018.\\n\\nH. Tran, C. V. Dinh, Q. Pham, and B. T. Nguyen, \u201cAn efficient transformer-based model for Vietnamese punctuation prediction,\u201d in International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Springer, 2021, pp. 47\u201358.\\n\\nP. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, \u201cEnriching word vectors with subword information,\u201d in Transactions of the Association for Computational Linguistics, vol. 5, pp. 135\u2013146, 2017.\\n\\nT. Mikolov, K. Chen, G. S. Corrado, and J. Dean, \u201cEfficient estimation of word representations in vector space,\u201d in ICLR, 2013.\"}"}
{"id": "thithuuyen22_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Vietnamese Capitalization and Punctuation Recovery Models\\nHoang Thi Thu Uyen1, Nguyen Anh Tu1, Ta Duc Huy2\\n1Posts and Telecommunications Institute of Technology, Hanoi, Vietnam\\n2Independent Researcher, Ho Chi Minh City, Vietnam\\n{thuuyenptit, anhtunguyen446, tdh512194}@gmail.com\\n\\nAbstract\\nDespite the rise of recent performant methods in Automatic Speech Recognition (ASR), such methods do not ensure proper casing and punctuation for their outputs. This problem has a significant impact on the comprehension of both Natural Language Processing (NLP) algorithms and human to process. Capitalization and punctuation restoration is imperative in pre-processing pipelines for raw textual inputs. For low-resource languages like Vietnamese, public datasets for this task are scarce. In this paper, we contribute a public dataset for capitalization and punctuation recovery for Vietnamese; and propose a joint model for both tasks named JointCapPunc. Experimental results on the Vietnamese dataset show the effectiveness of our joint model compared to single model and previous joint learning model. We publicly release our dataset and the implementation of our model at https://github.com/anhtunguyen98/JointCapPunc.\\n\\nIndex Terms\\nPunctuation prediction, Capitalization prediction, Text normalization, Joint learning,\\n\\n1. Introduction\\nGeneric ASR systems only transcribe audio input to raw textual output of single-lowercase word sequences. For a given output sequence of an ASR system:\\n'hi uyen how are you', the properly capitalized and punctuation recovered output would be: 'Hi Uyen, how are you?'. Restoring punctuation and capitalization enormously improves the readability of ASR output. This step also improves the results for common subsequent tasks in NLP like Named entity recognition, Intent classification, etc. [1, 2, 3]\\n\\nData resources for Vietnamese capitalization and punctuation recovery is limited. There are only two public datasets [4] for punctuation prediction and no available dataset for capitalization restoration. These two datasets are aggregated from news articles and novels, which do not contain more context on spoken language, thus do not generalize well enough for applications in ASR systems.\\n\\nIn this work, we aim to apply capitalization and punctuation recovering to ASR systems in the medical domain. Our method can enhance the readability of ASR-transcribed records of the conversations between COVID-19 patients and doctors.\\n\\nWe present a large-scale public dataset for Vietnamese capitalization and punctuation recovering focus on the medical domain. The dataset contains context on spoken language that consists of thousands of question and answer pairs that crawled from healthcare websites. We consider common punctuation marks and capitalization types presented in section 3.\\n\\nTraditional methods often solve these tasks independently as two sequence labeling models. These methods exploit probabilistic graphical models like conditional random fields (CRFs) [5] [6] [7] and combine with common neural networks such as CNNs and LSTM [8] [4] [9]. For Vietnamese, recently pretrained language models [10] have made breakthroughs in various Vietnamese NLP tasks and applications including analyzing questions [11], punctuation prediction [12], sentiment analysis [13], sequence tagging [14]. In this paper, we proposed a new joint learning model that based on pretrained transformers language models and extend with a capitalization prediction layer to produce the soft capitalization features to combine with contextual features for the punctuation prediction layer. Our contributions are summarized as follows:\\n\\n\u2022 We introduce a Vietnamese public capitalization and punctuation recovery dataset\u2014named ViCapPunc.\\n\u2022 We proposed a capitalization and punctuation recovery model named JointCapPunc. Experimental results on our dataset show the benefits of joint learning over learning the model separately on each task.\\n\\n2. Related Work\\nIn addition to IQ2 [1], IWSLT 2011 [15] are common datasets which used for capitalization and punctuation prediction in English. All of these text are the transcripts of the conversations that contain spoken language. To our knowledge, there are two public datasets et al [4] for punctuation prediction task which on news domain and novels domain in Vietnamese. However two Vietnamese dataset do not focus on spoken language domain that make improvement for ASR system. Besides, these dataset do not consist annotation for capitalization prediction task.\\n\\nEarly approaches to solve the two tasks are using single sequence labeling model including n-gram language model [16], conditional random fields model [7] [17], deep neural models [4], [12]. Recently, there are some studies proposed to solve the two tasks simultaneously following two strategies. The first strategy is combining annotations of capitalization and punctuation task and formulate the task as sequence labeling [18] or sequence to sequence models [19]. The second strategy is to jointly learn a model for both tasks, which performs better than its single counterpart. [20] employs bidirectional recurrent neural networks and two independent prediction layers, which does not leverage capitalization features for punctuation prediction tasks. Monica et al [21] proposed a method that conditions truecasing prediction on punctuation output. They concatenate the softmax probabilities of punctuation output with BERT encoder's outputs and feed to a linear to predict truecasing. Our method is similar to this work but we use the output probability of capitalization head to produce soft capitalization features. We then combine these features with the contextual word features to predict punctuation marks. Besides, to improve performance of punctuation task, we extend model with conditional random field layer. This model is presented in detail in section 4.\"}"}
{"id": "thithuuyen22_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: The format of the dataset.\\n\\n| Text     | Cap label | Punctuation label |\\n|----------|-----------|-------------------|\\n| ch`ao    | 1         | O                 |\\n| uy\u02c6en    | 1         | COMMA             |\\n| ba.n     | 0         | O                 |\\n| c\u00b4o      | 0         | O                 |\\n| khoe     |            |                   |\\n| kh\u02c6ong   |            | QMARK             |\\n\\nTable 2: Statistics of ViCapPunc dataset.\\n\\n| Punctuation | Train      | Validation | Test       |\\n|-------------|------------|------------|------------|\\n| COMMA       | 228,495    | 92,026     | 137,865    |\\n| PERIOD      | 184,383    | 74,097     | 111,717    |\\n| QMARK       | 27,448     | 10,987     | 16718      |\\n| Capitalization | 318,654  | 127,222    | 191,767    |\\n| ALL-CAP     | 37,542     | 14,582     | 23,173     |\\n| Sentences   | 211,831    | 85,084     | 128,435    |\\n\\n3. ViCapPunc Dataset\\n\\nTo investigate the two tasks for Vietnamese, we build a large-scale dataset namely ViCapPunc that contains spoken language from the medical domain. We first crawl 50,000 question and answer pairs from the reputable Vietnamese healthcare sites online including Vinmec, Alobacsi, and ISOFHCARE. There are 425,350 sentences in the ViCapPunc dataset. We define two types of label for the capitalization prediction task including: word with the first character capitalized (CAP), word with all capitalized characters (ALL-CAP) and three common punctuation marks for the punctuation prediction task including the comma(,), the period(.) and the question mark (?).\\n\\nWe split 50,000 question and answer pairs into training, validation and test sets randomly with the ratio 50%, 20%, 30% respectively. For pre-processing steps, we converted all data into lower case, removed the special characters and punctuation marks, keeping commas, periods and question marks. Finally, we label the dataset following the format in Table 1 that consists of three columns. Column 1 is the lower case text of input sentences. Column 2 is the capitalization label, where 0 denotes non-capitalized word, 1 is CAP and 2 is ALL-CAP. Columns 3 is the punctuation label where O indicates that a word is not followed by any punctuation. Following the strategy in Thuy et al. [4] where the maximum length of a question and answer is 150 words, we do not segment data into paragraphs. Instead, we decided to split the data into segments of length equal to 150 and made sure that the last word of a segment input is the last word of a sentence. Table 2 shows the statistics of our dataset.\\n\\n4. JointCapPunc\\n\\nFigure 1 illustrates the architecture of our joint model\u2014named JointCapPunc, which consists of three layers including: an encoding layer (i.e. encoder), and two decoding layers of capitalization prediction and punctuation prediction.\\n\\n**Encoding layer:**\\n\\nGiven an input sentences consist of \\\\( w_1, w_2, \\\\ldots, w_n \\\\). The encoding layer employs a pre-trained language model based on Transformers encoder like RoBERTa, Electra. Because RoBERTa, Electra segments the input sentence to sub-words which enables the encoding of rare words with appropriate sub-words. We re-combined sub-word representation after encoding layer into word representation using sum operation. The \\\\( i \\\\)th word \\\\( w_i \\\\) is represented by vector \\\\( e_i \\\\) as follows:\\n\\n\\\\[\\ne_i = \\\\text{PretrainedLM}(w_1:n, i)\\n\\\\]\\n\\n**Capitalization prediction layer:**\\n\\nFollowing the common approached when fine-tuning a pre-trained language model for token classification task [10], the punctuation prediction layer is a linear prediction layer which is added on the top of encoder layer. In particular, we used word vector representation \\\\( e_i \\\\) that is fed into feed-forward network layer (\\\\( \\\\text{FFN}^{\\\\text{cap}} \\\\)) followed by softmax predictor for capitalization prediction.\\n\\n\\\\[\\np_i = \\\\text{softmax}(\\\\text{FFN}^{\\\\text{cap}}(e_i)),\\n\\\\]\\n\\nwhere the output size of \\\\( \\\\text{FFN}^{\\\\text{cap}} \\\\) is 3, including non-capitalized words, words with first character capitalized, words with all capitalized characters. The cross entropy loss function \\\\( L^{\\\\text{cap}} \\\\) is used to optimize capitalization prediction.\\n\\n**Punctuation prediction layer:**\\n\\nThe punctuation prediction task is formulated as sequence labeling problem. First, we create a sequence of vector \\\\( x_1:n \\\\) in which \\\\( x_i \\\\) is the concatenation of the word representation \\\\( e_i \\\\) and the soft capitalization embedding \\\\( c_i \\\\).\\n\\n\\\\[\\nx_i = e_i \\\\oplus c_i,\\n\\\\]\\n\\nwhere the soft capitalization embedding is computed by multiplying the weight matrix \\\\( W \\\\) with the corresponding output probability vector \\\\( p_i \\\\).\\n\\n\\\\[\\nc_i = Wp_i.\\n\\\\]\\n\\nThen each vector \\\\( x_i \\\\) is fed into the \\\\( \\\\text{FFN}^{\\\\text{punc}} \\\\) layer:\\n\\n\\\\[\\ns_i = \\\\text{FFN}^{\\\\text{punc}}(x_i),\\n\\\\]\\n\\nwhere the output size of \\\\( \\\\text{FFN}^{\\\\text{punc}} \\\\) layer is the number of punctuation label. The punctuation prediction layer feeds output vector \\\\( s_i \\\\) into a conditional random field layer [5]. Negative log likelihood loss \\\\( L^{\\\\text{punc}} \\\\) is used for punctuation prediction task optimization.\\n\\n**Joint training:**\\n\\nThe final training objective loss \\\\( L \\\\) of our proposed JointCapPunc model is the weighted sum of the capitalization prediction loss \\\\( L^{\\\\text{cap}} \\\\) and punctuation prediction loss \\\\( L^{\\\\text{punc}} \\\\):\\n\\n\\\\[\\nL = \\\\lambda L^{\\\\text{cap}} + (1 - \\\\lambda) L^{\\\\text{punc}}\\n\\\\]\\n\\n5. Experiments\\n\\n5.1. Evaluation metrics\\n\\nThe performance of our model is evaluated by using precision, recall and f1-score for both task.\\n\\n\\\\[\\n\\\\text{precision} = \\\\frac{TP}{TP + FP},\\n\\\\]\\n\\n\\\\[\\n\\\\text{recall} = \\\\frac{TP}{TP + FN},\\n\\\\]\\n\\n\\\\[\\nF_1 = \\\\frac{2 \\\\times \\\\text{precision} \\\\times \\\\text{recall}}{\\\\text{precision} + \\\\text{recall}},\\n\\\\]\\n\\nwhere \\\\( TP \\\\) (true positive) is the number of punctuation mark / capitalization mark correct predictions. \\\\( FP \\\\) (false positive) is the number of punctuation mark / capitalization mark that are falsely predicted. \\\\( FN \\\\) (false negative) is the number of punctuation marks / capitalization marks that are not identified.\"}"}
{"id": "thithuuyen22_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We conduct experiments on our ViCapPunc dataset to study the effectiveness of joint training model. Here, we employ XLM-R [25] is pre-trained on a 2.5TB multilingual dataset that contains 137 GB Vietnamese text and vELECTRA [14], a monolingual variant of ELECTRA for Vietnamese, is pre-trained on 10GB of Vietnamese text.\\n\\nOur models were implemented in PyTorch [26] using Huggingface's Transformers [27]. Both single-task learning models and jointly learning model were trained using the AdamW optimizer [28] and set the batch size to 32. We set the epsilon and weight decay to default value in PyTorch, i.e. 1e\u207b\u2078, the soft capitalization embedding dim is 256. The learning rate and mixture weight \u03bb were tuned in \\\\{1e\u207b\u2075, 2e\u207b\u2075, 3e\u207b\u2075, 4e\u207b\u2075, 5e\u207b\u2075\\\\} and \\\\{0.05, 0.1, 0.15 ... 0.95\\\\} respectively. The best learning rate and mixture weight value was 5e\u207b\u2075 and 0.15 respectively. We train for 10 epochs and calculate the average score of the F\u2081-score for capitalization prediction and punctuation prediction after each training epoch on validation set and selected version that obtained the highest average score on the validation set to apply to the test set.\\n\\nTable 3 shows results obtain for our JointCapPunc model compares with baseline model of single task training and joint model Monica et al [21]. For single task training model: Following common strategy when fine-tuning a pre-trained language model for token classification task [10]. We append a linear prediction layer on the top of pre-trained language models as briefly described in Section 4 which is applied for the capitalization prediction task. For punctuation prediction task, we use a punctuation restore model for Vietnamese [29] that append a CRF prediction layer on top of pre-trained language models. The single training strategy based on the XLM-R and vELECTRA In each setting, JointCapPunc model performs better than single training approach and joint model Monica et al [21] on both task. Here, the highest improvements are accounted for the punctuation F\u2081 (ie., 78.65% \u2192 79.33% \u2192 80.10%) and the capitalization F\u2081 (ie., 83.55% \u2192 84.16% \u2192 86.75%). Thus showing that our joint training model and soft capitalization features helps to better exploit the relationship between the two tasks. Besides, vELECTRA outperforms XLM-R (punctuation micro-F\u2081: 80.10% vs 78.74%, capitalization micro-F\u2081: 86.75% vs 85.39%).\"}"}
{"id": "thithuuyen22_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Experimental result (in %) on testset\\n\\n| Encoder       | Model       | Capitalization | Punctuation | Precision | Recall | F1   | Precision | Recall | F1   |\\n|---------------|-------------|----------------|-------------|-----------|--------|------|-----------|--------|------|\\n| XLM-R         | Single-task | 84.14          | 82.98       | 83.55     | 79.00  | 77.96 | 78.48     |        |      |\\n|               | Monica et al [21] | 84.84          | 83.36       | 84.10     | 78.97  | 78.25 | 78.58     |        |      |\\n| JointCapPunc  |             | 85.66          | 85.12       | 85.39     | 79.02  | 78.45 | 78.74     |        |      |\\n| vELECTRA      | Single-task | 83.97          | 83.10       | 83.53     | 79.35  | 77.96 | 78.65     |        |      |\\n|               | Monica et al [21] | 84.67          | 83.65       | 84.16     | 79.36  | 79.31 | 79.33     |        |      |\\n| JointCapPunc  |             | 86.55          | 86.95       | 86.75     | 80.79  | 79.43 | 80.10     |        |      |\\n\\nTable 4: Ablation study (in %) on testset (the decrease in the F1 score of the modified models is indicated in bold)\\n\\n| Component              | Modification      | Capitalization | Punctuation | Precision | Recall | F1   | Precision | Recall | F1   |\\n|------------------------|-------------------|----------------|-------------|-----------|--------|------|-----------|--------|------|\\n| Full                   | None              | 86.55          | 86.95       | 86.75     | 80.79  | 79.43 | 80.10     |        |      |\\n| Capitalization feature | Removal           | 85.40          | 80.99       | 83.13     | 80.52  | 77.80 | 79.13     | 3.62   | 0.97 |\\n| CRF layer              | Softmax           | 86.24          | 81.93       | 83.98     | 79.42  | 78.00 | 78.71     | 2.77   | 1.39 |\\n| Contextual embedding   | Fasttext          | 79.72          | 49.05       | 60.73     | 62.30  | 41.03 | 49.47     | 26.02  | 30.63 |\\n\\nexperiment, we use Fasttext [30], a variant of Word2Vec [31] which solved unknown words problem by using sub-word models.\\n\\n\u2022 Capitalization feature: We remove the capitalization feature and only use contextual embedding to predict punctuation mark.\\n\\n\u2022 Conditional random fields: We replace the CRF layer by softmax function for inferencing punctuation mark.\\n\\nTable 4 shows the impact of all component that contributed to the success of our joint learning model. The performance of the system degrades when we modified or removed a component. While the full model got capitalization F1 of 86.75% and punctuation F1 of 80.10%, the capitalization F1 and punctuation F1 reduced to 83.13%, 79.13% respectively when we remove capitalization feature and only use contextual embedding to prediction punctuation mark. The F1 score of capitalization prediction task and punctuation prediction task are only 83.98%, 78.71% respectively when we replaced the CRF layer by softmax function. Finally, we find that replacing contextual embeddings by independent word embedding (Fasttext) leads to the biggest decrease 23.43% capitalization F1 and 29.86% punctuation F1.\\n\\n6. Conclusions\\n\\nIn this paper, we presented the public dataset for Vietnamese capitalization and punctuation recovery. ViCapPunc dataset can be utilized to develop a text normalization module for ASR systems focus on medical domain which used to record the conversation between doctors and COVID-19 patient. In addition, we also proposed an effective model, namely JointCapPunc, for jointly learning capitalization and punctuation recovery. In particular, JointCapPunc based on transformers based pre-trained language models to learn essential words in the sentences. Soft capitalization embedding combined with word representation can produce useful features for punctuation prediction task. Therefore our model are able to capture the relationship between the two tasks. We conduct experiments and error analysis on our dataset and the results show that jointly learning model is more effective than baseline models (ie., single training approach, joint model Monica et al [21]). However, our model is based on transformers pre-trained language models that has a giant parameters scale, which might face difficulties in ASR pipeline due to the increase of latency. For future work, we plan to optimize our model to smaller size for faster and lighter footprint.\\n\\n7. Acknowledgements\\n\\nWe would like to thank AIC Technology Group, Hanoi, Vietnam for financial support which made this work possible.\\n\\n8. References\\n\\n[1] E. Cho, J. Niehues, and A. Waibel, \u201cSegmentation and punctuation prediction in speech language translation using a monolingual translation system,\u201d in Proceedings of the 9th International Workshop on Spoken Language Translation: Papers, 2012.\\n\\n[2] T. B. Nguyen, Q. M. Nguyen, T. T. H. Nguyen, Q. T. Do, and C. M. Luong, \u201cImproving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models,\u201d in Proc. Interspeech 2020, 2020, pp. 4263\u20134267.\\n\\n[3] M. Tkachenko and A. Simanovsky, \u201cNamed entity recognition: Exploring features,\u201d in 11th Conference on Natural Language Processing, KONVENS 2012: Empirical Methods in Natural Language Processing-Proceedings of the Conference on Natural Language Processing 2012, 2012, pp. 118\u2013127.\\n\\n[4] T. Pham, N. Nguyen, Q. Pham, H. Cao, and B. Nguyen, \u201cVietnamese punctuation prediction using deep neural networks,\u201d in International Conference on Current Trends in Theory and Practice of Informatics. Springer, 2020, pp. 388\u2013400.\\n\\n[5] J. D. Lafferty, A. McCallum, and F. C. N. Pereira, \u201cConditional random fields: Probabilistic models for segmenting and labeling sequence data,\u201d in Proceedings of the Eighteenth International Conference on Machine Learning, ser. ICML \u201901. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2001, p. 282\u2013289.\\n\\n[6] W. Wang, K. Knight, and D. Marcu, \u201cCapitalizing machine translation,\u201d in Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, 2006, pp. 1\u20138.\\n\\n[7] Q. H. Pham, B. T. Nguyen, and N. V. Cuong, \u201cPunctuation prediction for vietnamese texts using conditional random fields,\u201d in Proceedings of the Tenth International Symposium on Information and Communication Technology, 2019, pp. 322\u2013327.\\n\\n[8] P. \u02d9Zelasko, P. Szyma\u00b4nski, J. Mizgajski, A. Szymczak, Y . Carmiel, and N. Dehak, \u201cPunctuation prediction model for conversational speech,\u201d in INTERSPEECH, 2018.\\n\\n[9] O. T. Tran and V . T. Bui, \u201cNeural text normalization in speech-to-text systems with rich features,\u201d Applied Artificial Intelligence, vol. 35, no. 3, pp. 193\u2013205, 2021.\"}"}
