{"id": "adigwe24_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nConversational agents are becoming increasingly popular, prompting the need for text-to-speech (TTS) systems that sound conversational. Previous research has focused on training TTS models on elicited or found conversational speech then measuring an improved listener preference. Preference ratings cannot pinpoint why TTS voices fall short of conversational expectations, underscoring our limited understanding of conversational speaking styles. In this pilot study, we conduct interviews with naive listeners who evaluate if speech was taken from a conversation or not, then give their explanation. Our results indicate that listeners are capable of distinguishing conversational utterances from read speech from acoustic features alone. While listeners' explanations vary, they generally allude to pronunciation, rhythmic organisation, and inappropriate prosody. Using targeted prosodic modifications to synthesise speech, we shed light on the complexity of evaluating conversational style.\\n\\nIndex Terms: speech synthesis evaluation, prosody, speaking styles\\n\\n1. Introduction\\n\\nText-to-Speech (TTS) has achieved parity in naturalness with human speech, and is nearly capable of generating expressive speech with diverse emotions and speaking styles. There has long been interest in TTS for conversational settings but, despite significant progress made through data- and model-driven approaches for conversational speech synthesis, achieving synthetic speech that listeners perceive as naturally conversational remains elusive. We believe that a contributing factor to this challenge is the lack of a concrete understanding of what constitutes \\\"conversational\\\" as a speaking style. Specifically, we know very little about what listeners are actually perceiving and evaluating when they listen to speech in conversation. This gap in understanding hampers our ability to create TTS voices that effectively capture the pragmatic, affective, interpersonal, and even aesthetic nuances inherent in conversational speech.\\n\\nThere are broadly three approaches to building conversational TTS. The first, and most obvious, uses either elicited [1] or found [2] conversational speech as training data. The second uses style transfer to convert read speech (or a TTS model trained on read speech) to a target conversational style [3]. The third approach considers dialogue context when synthesising the current utterance, using lexical and acoustic information from the dialogue history [1]. These approaches target quite different goals, which in turn influences how they are typically evaluated with listeners. Whilst all approaches appear successful in the sense of achieving higher listener ratings or preferences, the underlying factors in the speech that influenced the listeners' judgements are not well understood. In other words, we do not really know why the approaches work, or in what ways they could be improved.\\n\\nTowards the goal of understanding what listeners consider to be conversational speech, in this work, we aim to identify the effect of acoustic realisation on listeners' judgements of conversationality, and which dimensions they rely on. Drawing inspiration from [4], we use an interview-based descriptive task to uncover what listeners attend to when listening to conversational English speech. Qualitative evaluation in TTS research is much less common than quantitative methods. Although a qualitative approach will not provide precise, neatly organised numerical data, it allows us to uncover deeper insights into how listeners judge speech.\\n\\nSince there is no established qualitative methodology for synthetic speech evaluation, we undertook a preliminary exploratory study (Sec. \u00a73) which informed the design of the main experimental tasks. In Experimental Task 1, we asked listeners to discriminate between pairs of natural speech stimuli, one extracted from a real conversation and the other a read-aloud version from the same speaker (Sec. \u00a75). In Experimental Task 2, using a subset of the acoustic features that convey prosody in conversational speech [5, 6, 7], we generated prosodically-varied synthetic samples, and asked listeners to evaluate whether each was taken from a conversation (Sec. \u00a76).\\n\\n2. Background\\n\\nDefinitions of speaking styles, particularly conversational speaking style, have led to considerable debate, making it difficult to establish clear parameters for discussion. For example, it has been suggested that various speaking styles may emerge across individual conversations [8], indicating that there is no single, definitive conversational style. Nevertheless, the mode of speech production is known to influence acoustic realisation; for example, [9] shows that speaking mode influences the demarcation of information status.\\n\\n2.1. Prosody of Spontaneous Speech\\n\\nThe distinction between read and spontaneous speech has been extensively studied. Spontaneous speech is typically characterised by reduced pronunciation, increased speaking rate, fewer pauses, and greater pitch and tonal variability in comparison to read speech [6, 7, 10]. Perception studies show that listeners are capable of recognising speech from either speaking style [11]. They are sensitive to changes in prosody, but no one dimension solely determines the perceived speaking style [12]. Prosody plays a crucial communicative role in helping signal making parenthetical comments, turn-taking behaviour, topic shift and so on [13].\"}"}
{"id": "adigwe24_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2.2. Subjective evaluation of conversational TTS\\n\\nTo focus listeners' attention on specific high-level qualities of conversational text-to-speech (TTS), various suggestions have been made for phrasing the instructions, including rating the suitability given a communicative situation [14], appropriateness given a context [15], naturalness in a conversation [16] or naturalness within dialogue context [1]. Interpersonal attributes such as engagement and authenticity have also been suggested [2]. Evaluations have most often been conducted using linear scales or by pairwise comparison, but the limitations of such paradigms have been widely discussed [17, 18, 19]. Specifically, the paucity of information that can be obtained from mere ratings has always been a bottleneck: ratings don't tell us how to improve TTS. This is now particularly acute for conversational speech synthesis, where we are even less sure of what listeners want than for 'general TTS'.\\n\\nRapid improvement in TTS [18] has increased the urgency for newer \u2013 and more informative \u2013 evaluation paradigms [20].\\n\\n3. Preliminary Study\\n\\nTo understand the acoustic cues that listeners use to identify conversational speech beyond rating-based paradigms, we propose taking a semi-structured interview approach. However, the effect of presentation format for such methods is unknown. As such, we began by piloting a number of interview approaches. Preliminary interviews took place in a one-on-one setting with each participant. They listened to the speech stimuli played aloud and were then asked, \u201cDoes this sound like it\u2019s part of a conversation? If so, why?\u201d The stimuli used for the preliminary study was synthesised using the methodology described in Sec. \u00a76.1. With five participants, we presented speech stimuli as either isolated utterances or grouped into multiple renditions of the same text. We found participants relied heavily on imagined conversational contexts to rate utterance style. Comparative presentation yielded similar findings; although listeners typically preferred one version over another, they could often envision either stimuli fitting within a different conversational context. This reliance on context is informative: it reveals which style might be preferred under certain conditions. However, it leaves open the question of which acoustic dimensions are most important. As such, we design our experiments to explore how acoustic cues affect judgements independently of context.\\n\\nAs an alternative, we experimented with adding conversational context to the stimuli, providing conversational history in text or audio format. Audio context constrained the interpretation space and introduced the possibility of vocal entrainment i.e. picking a rendition based on how similar the prosody was to the previous speaker. When only text was given, participants' responses were still shaped by their own interpretations of how the context might sound; some participants enacted contexts aloud, demonstrating the influence of their imagination on their judgements. These initial interviews confirm the large effect of context on listener judgements.\\n\\n4. Main Experimental Setup\\n\\nOur preliminary study demonstrated that context has a significant effect on the perception of conversational style. However, our goal is to understand whether conversational style is conveyed by the acoustic realisation of an utterance itself. To this end, we designed two main tasks; tasks are introduced in Sections 5 and 6. After obtaining ethical approval, we recruited 16 native English speakers from the University of Edinburgh for a 25-30 minute interview, compensating them \u00a35 each for both listening tasks. Each session was recorded with the participant's consent. The one-on-one interview took place in an open location where both the participant and interviewer could listen to audio samples together. Participants had the option to request as many replays of the samples as they needed. The semi-structured format encouraged open discussion about the samples, focusing especially on prosody. The interviewer sometimes probed participants to concentrate on specific prosodic attributes like rhythm or parts of the utterance, and at times were asked to produce the utterance aloud as if they were in a conversation. This method enabled another layer of analysis regarding factors that influenced their perceptions.\\n\\n5. Task 1: Natural Speech Discrimination\\n\\nWe begin by asking whether listeners can identify conversational speaking style in human speech, and which factors they report as important in their decisions. We chose a forced-choice paradigm, in which participants were asked to distinguish between pairs of samples: one sample from a conversation and the other not.\\n\\n5.1. Data\\n\\nWe create stimuli from a parallel corpus of utterances taken from a spontaneous conversation and their read counterparts [16]. Importantly, all utterances are from the same British English Female speaker, thus controlling for this potential effect on listener decisions. We randomly selected ten utterance pairs; durations varied from 1 to 4 seconds (5 to 20 words).\\n\\n5.2. Experimental Setup\\n\\nEach participant was presented with all ten utterance pairs. The instructions were as follows: \u201cYou will listen to a total of twenty audio samples, all voiced by the same speaker, a British female speaker. I will present these samples to you in pairs. Out of the pair, one of them is taken from an actual conversation the speaker had with another person, while the other one was not. Your task is to determine which sample in each pair is the conversational speech and which one is the read-aloud speech and comment on what in the speech led to your choice.\u201d\\n\\n5.3. Quantitative Results\\n\\nParticipants were capable of differentiating between conversational and read speech: they correctly identified the conversational sample 87.3% of the time (Fleiss' kappa inter-participant agreement 0.74). This is consistent with prior work finding 82% accuracy from individual utterance judgements [11].\\n\\n5.4. Qualitative Results: Perceptual Dimensions\\n\\nParticipants noted that conversational speech is broadly characterised by its fluidity, variability, and natural flow. We performed a thematic analysis of the participants' explanations, summarising the common themes that emerged from the semi-structured interviews reported above, with the most frequently used first.\\n\\nRhythm\\nParticipants often mentioned rhythm, pacing, and speaking rate. These were often cited as key contributors to the\"}"}
{"id": "adigwe24_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"a \u201cnatural flow\u201d or fluidity inherent in conversational speech. Faster pace, less pausing between words, and dynamic speaking rate were identified as factors that made speech more conversational. Interestingly, there was a general preference for faster speaking rates, even when participants found it harder to understand the words.\\n\\n\u201dless space between the words and the timing sounds far natural . . . varied spaces between the words - bigger shorter, bigger shorter\u201d (P002)\\n\\n\u201dless clearer but flows better \u201d (P003)\\n\\nProsody or Tone\\nParticipants noted distinct tonal variations and changes in inflection, highlighting a contrast to the monotone and flat prosody used to describe read samples. Also, instances where the speech had a lower pitch or deeper tone were perceived by listeners as more informal and conversational. Conversely, a higher pitch was interpreted as the speaker trying to \u201cpush her voice higher to project.\u201d [p002] Moreover, listeners noted the presence and realisation of stress in speech. This includes both the placement of stress and where they felt it sounded exaggerated, which contributed to the perception of samples as overly performed therefore read-aloud.\\n\\nread-aloud: \u201ccarefully posed as a question, the inflection went up at the end in a much clearer way\u201d (P009)\\n\\nconversational: \u201cless inflection and probably monotone but in conversation some things are monotone and the content of the utterance sounds like something that should be\u201d (P014)\\n\\nSpontaneity\\nParticipants noted the delivery of impromptu versus prepared speech. They alluded to a speaker trying to formulate their thoughts on the spot. Some cues that signalled these were pauses, indicating hesitation and vaguely put \u201cnatural intonation\u201d. On the other hand, read samples were noted to sound more formal and well-pronounced, akin to someone reading from a script, indicating a level of preparation or rehearsal. Participants mentioned that with prepared speech, there seemed to be an adherence to grammatical punctuation, like pausing at commas or changing intonation at question marks, such that it sounded like they were reading from text.\\n\\n\u201dnatural intonation that it feel more impromptu like it is coming from your head . . . curve to the tongue\u201d (P002)\\n\\n\u201dsounds like a throwaway comment like she doesn\u2019t know what she\u2019s going to say next. \u201d (P016)\\n\\nLocal Context\\nParticipants tend to pay attention to how an utterance starts and ends as this suggests whether the utterance was said in isolation or as a part of ongoing discourse. Their observations touched upon how prosody could signal the speaker\u2019s intentions, such as concluding their turn, linking/adding to a previous statement, or eliciting a response. They discussed how boundary tones, final syllable lengthening and elision of syllables could signal some of the speaker\u2019s intentions.\\n\\n\u201dthe hard \u2018T\u2019 at the end sounds like they have finished talking\u201d (P011)\\n\\n\u201dthe end of it was kind of truncated. . . almost in anticipation of something else coming after, whereas (the read sample) felt like more definitive. \u201d (P015)\\n\\nInterpersonal/Affect\\nListeners\u2019 perception were influenced by the emotions they sensed from the speaker\u2019s affect and emotion, as well as any implied persona. Speech that was delivered with emotional depth or suggested a specific role such as person in authority, tour guide, parent etc was often deemed more conversational. When rating isolated utterances, as in Task 2 (Sec. \u00a76), this becomes an even more significant factor if the content appeared to evoke emotion.\\n\\n\u201d more casual, like the cadence . . . I can imagine a friend just sharing that with me \u201c (P011)\\n\\n\u201dmore emotion sounds like a happy voice\u201d (P008)\\n\\nPropositional\\nParticipants frequently tried to deduce the speaker\u2019s underlying purpose or attitude from their speech and used these inferences to explain the observed prosodic characteristics as part of the dialogue context.\\n\\n\u201dsounds explanatory, as to imply \u2018don\u2019t you know what i mean\u2019\u201d (P005)\\n\\n\u201dsounds like a little addition, sounds like a context clue and it\u2019s almost providing more information and it feels like the listener is having to infer. \u201c (P015)\\n\\nDisfluency\\nHesitation and pauses are often cited as markers of spontaneous speech. In one of the sentence pairs from Task 1, a notable disfluency, characterised by a mid-sentence pause, led to a strong polarity in the ratings amongst participants. Many were split on whether this pause felt natural enough to occur in an actual conversation and that took precedence over the remaining prosodic aspects of the sentence. Many participants remarked on the unnaturalness of these pauses, as indicated by their ratings.\\n\\n\u201dpause felt very exaggerated almost like you are trying to emphasise sporty for no apparent reason\u201d (p002)\\n\\n\u201dpauses, like she\u2019s thinking about what to say\u201d (P006)\\n\\n6. Task 2: Effect of Prosodic Manipulations\\nTask 1 confirmed that listeners can detect whether an utterance was spoken in conversation or read aloud, relying solely on changes to its acoustic realisation, and provided insight into what factors affected their judgements. In Task 2, we investigate these factors from another perspective. We use a TTS system to apply systematic prosodic modifications to read speech and examine their effect on listeners\u2019 judgements of conversationality.\\n\\n6.1. Data\\nWe trained a modified FastSpeech2 TTS model [21]. We implemented a prosody control architecture similar to [21], enabling utterance-level control over $F_0$ mean, $F_0$ range, phone duration, energy, and spectral tilt in order to generate varied prosody. During training, normalised utterance-level values for each feature are embedded and summed to the encoder output and passed to the variance predictor and decoder blocks. The model was trained on LJ Speech. We used a speaker-specific, pretrained checkpoint of Nvidia\u2019s WaveGlow vocoder for waveform generation.\\n\\nFor test utterances, we came up with eight texts that are intended primarily to convey information (I-type), rather than display affect (A-type) [22]. Different realisations of the text were synthesised using eight predefined sets of feature values to control the sentence-level prosody (Table 1 shows the manipulations labelled Variations A-G), 64 samples in total. These values\\n\\n1github.com/ming024/FastSpeech2\\n2keithito.com/LJ-Speech-Dataset\\n3https://bit.ly/LJWaveGlow\"}"}
{"id": "adigwe24_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Percentage of Stimuli rated as \u201cConversational\u201d across Prosodic Variation Types were selected by expert listening because they result in perceptually distinct renditions. In our study, we eliminated samples with artefacts and carefully selected twenty distinct samples of the variation types C, D, E, G, H as a conservative representation of the prosodic space.\\n\\nTable 1: Relative control values for prosodic variations used in Task 2\\n\\n| Variation Type | $F_0$ Mean | $F_0$ Range | Phone Duration | Energy Spectral Tilt |\\n|----------------|------------|-------------|----------------|---------------------|\\n| A              | high       | high        | long           | mid                 |\\n| B              | high       | mid         | long           | low                 |\\n| C              | high       | low         | short          | mid                 |\\n| D              | low        | high        | long           | low                 |\\n| E              | low        | high        | short          | mid                 |\\n| F              | low        | low         | short          | mid                 |\\n| G              | mid        | mid         | short          | high                |\\n| H              | mid        | high        | long           | high                |\\n\\n6.2. Experimental Setup\\n\\nAfter completing Task 1, the participant was informed that the speaker in Task 2 would change and provided new instructions for individual utterances \u201cRate whether the given utterance sounds like it was said in a conversation, and why?\u201d Each participant was presented with a total of 20 synthetic samples with various renditions of the same text randomly interspersed throughout the task. We chose not to inform listeners that the stimuli were synthetic, and although some suspected this, their suspicions were not addressed during their interview.\\n\\n6.3. Results\\n\\nFigure 1 shows the effect of each prosodic modification on conversational ratings. We find that even relatively simple targeted modifications by a TTS model trained only on read speech can increase the perception of conversationality of utterances. Notably, samples generated with prosodic variation E\u2014a combination of short phone duration, wide $F_0$ range, and low mean $F_0$\u2014were judged as conversational 64% of the time. However, the effect of prosodic variation is highly dependent on the underlying text. For instance, different utterances under variation G were perceived as 86% and 7% conversational. Listeners also often commented on the conversationality of the lexical content alone. This highlights the complex joint effects of prosodic realisation and lexical content [23].\\n\\nAlthough participants commented on the naturalness of the voice (terms included \u2018robotic\u2019 and \u2018artificial\u2019), they cited many of the same factors described in Section 5.4 as factors affecting their judgements. Importantly, numerous listeners noted that rating conversationality for isolated utterances was more challenging than pairwise comparisons. As Task 2 progressed, some participants began to rate utterances relative to previous ones. Similar to the preliminary study, some often described an imagined context for the utterance as a means to evaluate it.\\n\\n7. Discussion\\n\\nIn Task 1, listeners pointed out cues like speech rate, rhythm, lower pitch and hypo-articulation as key to their relatively accurate judgements of conversational speech. However, when some of these aspects were modified in synthesised speech for Task 2, the results demonstrated the complexity of these judgements. Although we show that, even using a relatively simple prosody-controllable TTS model, targeted manipulations produce samples convincingly conversational over thirty percent of the time, these modifications did not affect listeners\u2019 perception of conversationality consistently. These findings suggest that minimal cues might significantly influence listeners\u2019 perception of conversationality in synthetic speech. At the same time, manipulating prosodic features alone is insufficient to guarantee a perception of conversational speaking style among listeners.\\n\\nThe evaluation paradigm for rating conversational speech matters to listeners and could influence evaluation results. Comparative evaluation is much easier when rating samples in the absence of conversational context, as the listeners can focus on the prosodic aspects of the speech, minimising the influence of the lexical content on their perception. Perhaps using a sample with prosodic profile of Variation E may serve as a lower bound of conversational speech for comparison. The instructions posed to listeners also affect their response. For our task, we directed participants to \u201cjudge the sample on whether they believe it was spoken in a conversational context.\u201d The follow-up interviews revealed that listeners base their judgements on various aspects of natural conversations from spontaneity, notions regarding the speaker\u2019s intent, lexical content, local context and more. This suggests evaluating conversational speech solely in terms of contextual appropriateness [1] or naturalness [3] may lead listeners to overlook other aspects of conversational speech. The interview-based approach to evaluating speech has its challenges. Specifically, we noticed that participants sometimes struggled to describe the prosodic aspects of speech clearly, and the descriptive terms used by participants lacked uniformity.\\n\\n8. Conclusion\\n\\nIn this study, we use a less popular yet arguably richer evaluation paradigm to understand how listeners perceive conversational speech. We conducted in-person qualitative interviews that elicited participants\u2019 notion of conversational speech. We demonstrate that listeners can differentiate between conversational and read utterances of identical lexical content with high accuracy, indicating that conversational style is being conveyed through the acoustic cues of the isolated utterances. Our qualitative results demonstrate that rhythm, articulation, tonal variation are salient cues listeners often rely on. Next, using speech synthesis as a tool, we explore the perceptual space of conversational speech and show that relatively simple targeted prosodic manipulations can moderately affect listeners\u2019 judgements of the conversationality of synthetic speech. However, these results highlight the complex interactions between different acoustic features, as well as with lexical content in driving conversationality. This has important implications for TTS evaluation and modelling speaking styles.\"}"}
{"id": "adigwe24_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgements\\n\\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No 859588.\\n\\nReferences\\n\\n[1] H. Guo, S. Zhang, F. K. Soong, L. He, and L. Xie, \\\"Conversational end-to-end tts for voice agents,\\\" in 2021 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2021, pp. 403\u2013409.\\n\\n[2] \u00b4E. Sz\u00e9kely, G. E. Henter, J. Beskow, and J. Gustafson, \\\"Spontaneous conversational speech synthesis from found data.\\\" in Proc. Interspeech 2019, 2019, pp. 4435\u20134439.\\n\\n[3] R. Fernandez, D. Haws, G. Lorberbom, S. Shechtman, and A. Sorin, \\\"Transplantation of Conversational Speaking Style with Interjections in Sequence-to-Sequence Speech Synthesis,\\\" in Proc. Interspeech 2022, 2022, pp. 5488\u20135492.\\n\\n[4] Z. Hodari, C. Lai, and S. King, \\\"Perception of prosodic variation for speech synthesis using an unsupervised discrete representation of F0,\\\" in Proc. Speech Prosody 2020, 2020, pp. 965\u2013969.\\n\\n[5] M. Eskenazi, \\\"Changing speech styles: Strategies in read speech and casual and careful spontaneous speech.\\\" in Proceedings of the International Conference on Spoken Language Processing 1992, 1992, pp. 755\u2013758.\\n\\n[6] B. Elenora, \\\"Phonetic differences between read and spontaneous speech,\\\" in Proc. ICASSP-92, 1992.\\n\\n[7] P. Howell and K. Kadi-Hanifi, \\\"Comparison of prosodic properties between read and spontaneous speech material,\\\" Speech communication, vol. 10, no. 2, pp. 163\u2013169, 1991.\\n\\n[8] M. Eskenazi, \\\"Trends in speaking styles research,\\\" in Proc. 3rd European Conference on Speech Communication and Technology (Eurospeech 1993), 1993, pp. 501\u2013509.\\n\\n[9] L. E. De Ruiter, \\\"Information status marking in spontaneous vs. read speech in story-telling tasks\u2013evidence from intonation analysis using gtobi,\\\" Journal of Phonetics, vol. 48, pp. 29\u201344, 2015.\\n\\n[10] M. Nakamura, S. Furui, and K. Iwano, \\\"Acoustic and linguistic characterization of spontaneous speech,\\\" in Speech Recognition and Intrinsic Variation Workshop, 2006.\\n\\n[11] E. Blaauw, \\\"Phonetic characteristics of spontaneous and read-aloud speech,\\\" in Proc. ESCA Workshop on Phonetics and Phonology of Speaking Styles, 1991, pp. 12\u20131 \u2013 12\u20135.\\n\\n[12] G. P. Laan, \\\"The contribution of intonation, segmental durations, and spectral features to the perception of a spontaneous and a read speaking style,\\\" Speech Communication, vol. 22, no. 1, pp. 43\u201365, 1997.\\n\\n[13] J. Hirschberg, \\\"Communication and prosody: Functional aspects of prosody,\\\" Speech Communication, vol. 36, no. 1-2, pp. 31\u201343, 2002.\\n\\n[14] H. Lameris, A. Kirkland, J. Gustafson, and E. Szekely, \\\"Situating speech synthesis: Investigating contextual factors in the evaluation of conversational tts,\\\" in 12th Speech Synthesis Workshop (SSW) 2023, 2023.\\n\\n[15] R. Clark, H. Silen, T. Kenter, and R. Leith, \\\"Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences and Paragraphs,\\\" in Proc. 10th ISCA Workshop on Speech Synthesis (SSW 10), 2019, pp. 99\u2013104.\\n\\n[16] R. Dall, \\\"Statistical parametric speech synthesis using conversational data and phenomena,\\\" Ph.D. dissertation, The University of Edinburgh, Edinburgh, UK, 2017.\\n\\n[17] R. C. Streijl, S. Winkler, and D. S. Hands, \\\"Mean opinion score (mos) revisited: methods and applications, limitations and alternatives,\\\" Multimedia Systems, vol. 22, no. 2, pp. 213\u2013227, 2016.\\n\\n[18] S. Le Maguer, S. King, and N. Harte, \\\"The limits of the mean opinion score for speech synthesis evaluation,\\\" Computer Speech & Language, vol. 84, p. 101577, 2024.\\n\\n[19] A. Rosenberg and B. Ramabhadran, \\\"Bias and Statistical Significance in Evaluating Speech Synthesis with Mean Opinion Scores,\\\" in Proc. Interspeech 2017, 2017, pp. 3976\u20133980.\\n\\n[20] P. Wagner, J. Beskow, S. Betz, J. Edlund, J. Gustafson, G. Eje Henter, S. Le Maguer, Z. Malisz, \u00b4E. Sz\u00b4ekely, C. T\u02daannander et al., \\\"Speech synthesis evaluation\u2014state-of-the-art assessment and suggestion for a novel research program,\\\" in Proceedings of the 10th Speech Synthesis Workshop (SSW10), 2019.\\n\\n[21] Y. Ren, C. Hu, X. Tan, T. Qin, S. Zhao, Z. Zhao, and T. Liu, \\\"Fastspeech 2: Fast and high-quality end-to-end text to speech,\\\" in 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. [Online]. Available: https://openreview.net/forum?id=piLPYqxtWuA\\n\\n[22] N. Campbell, \\\"Developments in corpus-based speech synthesis: Approaching natural conversational speech,\\\" IEICE transactions on information and systems, vol. 88, no. 3, pp. 376\u2013383, 2005.\\n\\n[23] S. Wallbridge, P. Bell, and C. Lai, \\\"It's Not What You Said, it's How You Said it: Discriminative Perception of Speech as a Multichannel Communication System,\\\" in Proc. Interspeech 2021, 2021, pp. 2386\u20132390.\"}"}
