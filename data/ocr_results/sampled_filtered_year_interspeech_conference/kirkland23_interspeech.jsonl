{"id": "kirkland23_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Pardon my disfluency: The impact of disfluency effects on the perception of speaker competence and confidence\\n\\nAmbika Kirkland\\nJoakim Gustafson\\n\u00c9va Sz\u00e9kely\\n\\nDivision of Speech, Music & Hearing, KTH Royal Institute of Technology, Stockholm, Sweden\\nkirkland@kth.se, jkgu@kth.se, szekely@kth.se\\n\\nAbstract\\nDisfluencies are a hallmark of spontaneous speech and play an important role in conversation, yet have been shown to negatively impact judgments about speakers. We explored the role of disfluencies in the perception of competence, sincerity and confidence in public speaking contexts, using synthesized spontaneous speech. In one experiment, listeners rated 30-40-second clips which varied in terms of whether they contained filled pauses, as well as the number and types of repetition. Both the overall number of disfluencies and the repetition type had an impact on competence and confidence, and disfluent speech was also rated as less sincere. In the second experiment, the negative effects of repetition type on competence were attenuated when participants attributed disfluency to anxiety.\\n\\nIndex Terms: speech perception, speech synthesis, public speaking, spontaneous speech, disfluencies\\n\\n1. Introduction\\n1.1. Disfluencies in spontaneous speech\\nDisfluency is a hallmark of spontaneous speech. Rather than delivering completely well-formed utterances, speakers frequently hesitate, repeat themselves, and perform self-repairs. Although some perspectives (e.g., [1]) might view disfluencies as errors or deficits in realizing fluent speech, they are more than mere noise in the speech signal. They index underlying cognitive processes such as lexical retrieval and speech planning [2, 3, 4], telegraph information about upcoming delays [5] and give listeners insight into what Brennan and Williams refer to as the feeling of another's knowing [6], allowing for the coordination of mental states during conversation.\\n\\nAlthough disfluencies serve a functional role in speech and can convey friendliness [7] or spontaneity [8], most prior evidence suggests a negative impact of disfluencies on judgments about speakers. More disfluent speakers can appear more anxious [9] and less confident [10, 11], competent and dynamic [12, 7]. Disfluency can unfavorably affect a range of trait judgments related to social desirability [13, 14] as well as secondary judgments based on speaker's statements [7].\\n\\nMoreover, the type and location of disfluencies, as well as the context in which they occur, can reflect different cognitive processes and speaker strategies for maintaining continuity during speech planning [2, 4] and impact processing fluency to different degrees. For example, filled pauses (FPs) make it easier for listeners to integrate words into their contexts [15], which is not the case for repetitions [16], and false starts increase word monitoring latency relative to simple repetitions [17].\\n\\nIt is still unclear, however, whether these differences translate to different effects on judgments about a speaker. In addition to a general link between the processing burden imposed by disfluency and its impact on evaluations [18, 19], recent research has shown that the type and location of disfluencies play a role in their effect on perceived competence [12] and confidence [10]. These findings are consistent with the notion that more severe processing disruptions might more negatively affect judgments, but relatively little is known about how variations within a disfluency type (for example, the syntactic context of disfluent repetitions) or interactions between commonly co-occurring disfluencies (such as repetitions and FPs) impact evaluations. Addressing these questions might shed light on how listeners perceive subtly \\\"atypical\\\" use of disfluencies, displayed for example by some second-language speakers or women and girls with autism spectrum disorders [20, 21, 22].\\n\\nAnother consideration is that listeners' theories about the cause of disfluencies may shape their judgments. Disfluency can trigger negative evaluations when listeners assume a disfluent speaker is not willing or able to communicate effectively [18] but it has been shown in non-speech contexts that providing an obvious explanation for disfluency can attenuate its effect [19], a phenomenon known as discounting [23]. If discounting effects apply to speech disfluencies as well, this could give speakers a concrete tool for potentially mitigating the effects of disfluency on how listeners perceive them.\\n\\n1.2. Methods for studying disfluencies in speech\\nIn order to measure the effect of disfluencies on listener judgments we need to create speech stimuli with varying levels of disfluency. This is no trivial task and previous studies have used different methods to address this challenge. One method (used for example by [12] and [7]) is to ask voice actors to produce fluent and disfluent versions of a script. A limitation of this approach is that read or acted speech and spontaneous speech vary on a number of dimensions and are perceived differently by listeners [24, 25, 26], so this type of stimuli not be well suited for studying characteristics of spontaneous speech.\\n\\nAnother approach is to begin with disfluent natural speech and then excise disfluencies, as used, e.g., in [13] and [9]. This approach is suitable for evaluating how accurately listeners can infer ground-truth speaker states or characteristics from speech but affords little control over the content of the utterances or the exact placement or types of disfluencies. Furthermore, FPs are often cliticized onto the previous word to form phonological words [5] (for example \\\"we um\\\" might be realized as \\\"we.yum\\\") which means that some FPs cannot be removed without cutting off part of the adjacent word.\\n\\nOur approach is to create stimuli using a neural text-to-speech (TTS) system trained on spontaneous speech. The use of neural TTS for studying speech perception was suggested by [27] some years ago, and has become an increasingly viable...\"}"}
{"id": "kirkland23_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"option as the quality and naturalness of synthesized speech improves. Neural TTS has been used recently to investigate the effect of filled pause location and prosodic features on perceptions of speaker confidence [28] and the impact of disfluencies on ratings of personality traits in the context of different speaking styles [8]. This method provides control over both the content and prosodic aspects of utterances and allows for the creation of stimuli with the characteristics of spontaneous speech.\\n\\n1.3. Research questions and hypotheses\\n\\nIn the present work we sought to better understand how disfluencies affect listeners' evaluations on five different dimensions: general competence, task-specific competence, confidence, sincerity and friendliness. We included competence and confidence since the impact of disfluency on these dimensions has been investigated previously [12, 7] but the importance of specific characteristics of disfluencies is underexplored. Friendliness and sincerity were included to gain more insight into how speech disfluencies impact the perception of positive traits.\\n\\nWe used a TTS system trained on spontaneous speech to synthesize stimuli with different types and numbers of disfluencies. According to [4] speakers repeat certain words in certain contexts more often because those repetitions best facilitate smooth and timely communication. We therefore reasoned that more \u201ctypical\u201d repetitions, i.e. words that are repeated more often relative to the overall frequency of that word in a given context, would have less of an impact on judgments because they are more expected and less disruptive. The repetitions used in the experiments are summarized in Table 1. We also explored whether discounting effects might mitigate negative impacts of disfluency on evaluations by carrying out an experiment in which participants had the opportunity to attribute disfluency to anxiety. We propose the following hypotheses:\\n\\nH1: Perceived competence and confidence will decrease as the overall number of disfluencies increases.\\n\\nH2: The effect of FPs and repetitions should not be directly additive because FPs often occur with repetitions and give listeners a \u201cheads up\u201d about delays [4].\\n\\nH3: Repetitions that are less common in spontaneous speech will have a greater impact on competence and confidence.\\n\\nH4: More disfluent speech will be rated as friendlier and more sincere.\\n\\nH5: If listeners are able to attribute disfluency to anxiety, the effects of disfluency on competence will be reduced.\\n\\n2. Data and Synthesis\\n\\nFor the synthesis of the samples we use a TTS model built on the ThinkComputers Corpus (TCC), described in [29]. The corpus is created from recordings of a podcast which is available in the public domain.\\n\\nIn the podcast, two male speakers of American English discuss technology news and review computer hardware and software. Their speaking style can be described as extemporaneous, as they speak freely around a prepared outline. As a result, the corpus naturally contains disfluencies. The corpus includes 9 hours of speech from one of the speakers. To improve audio quality, the utterances in the corpus were processed using the Adobe Podcast enhance function.\\n\\nThe TTS system was trained using a modification of a PyTorch implementation of the sequence-to-sequence neural TTS engine Tacotron 2 [30]. To control the level of fluency specifically with regard to filled pauses (FPs), the corpus is divided into two parts: utterances that contain FPs, and utterances that do not. An 8-dimensional speaker style embedding is added to the Tacotron 2 (the implementation closely following [31]), and each utterance in the training data is given one of two speaker IDs. One is reserved for utterances without filled pauses (1436 out of the 4906 samples), which we refer to as ID-noFP, while training samples with at least one FP (\u2018uh\u2019 or \u2018um\u2019) receive the other, which we call ID-FP. Both speaker embeddings include data containing repetitions. In parallel to the embedding, we introduce an utterance-level prosody control, similar to [32]. Mean f0 and speech rate at the utterance level are added to the training. Both speaker embedding and prosodic features are added to a model, transfer learned on a model trained on the same corpus on a base Tacotron 2 architecture for 92.5k iterations. To allow for the additional features the relevant input dimensions to the attention, LSTM, projection and gate layers are padded with zeros. These additions increase the number of parameters to 28.28M from 28.19M in the base model. The model with embedding and prosodic features is trained for an additional 45k iterations on 4 GPUs with 28 batch size.\\n\\n3. Perception experiments\\n\\n3.1. Experiment 1\\n\\nThe first experiment investigated whether the number and type of disfluencies affect ratings of a speaker's competence, confidence, sincerity and friendliness. We varied the number and type of repetitions as well as the presence or absence of FPs in 14 different public speaking scenarios to create audio clips of 30-40-seconds in length. In half of the scenarios (the \u201clecture\u201d context) the speaker explained scientific concepts, such as how scientists measure the expansion of the universe. In the other half (the \u201cinstruction\u201d context) the speaker gave instructions about outdoor skills, such as how to build a shelter. The category and number of repetitions were varied by repeating words at locations that were consistent across stimuli, resulting in three different repetition versions. Version A contained four repetitions and versions B and C contained these same four repetitions plus four additional repetitions, for a total\\n\\nTable 1: Repetitions with frequencies per 1000 occurrences\\n\\n| freq. examples                     | condition A  | condition B  | condition C  |\\n|------------------------------------|--------------|--------------|--------------|\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how  |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |              |              |              |\\n| contraction 33.2 we'll              |              |              |              |\\n| relative pronoun 37.7 what         |              |              |              |\\n| conjunction 30.8 and               |              |              |              |\\n| determiner 28.8 some                |              |              |              |\\n| preposition 14.3 in, between        |              |              |              |\\n| misc. function words 22.3 by, how   |             "}
{"id": "kirkland23_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of eight each. The difference between version B and C is that the unique repetitions in version B were less common repetitions, while those unique to version C were more common. The repetitions used in each version and their frequency per thousand occurrences as reported by [4] are shown in Table 1.\\n\\nWe also varied whether or not FPs were present. Stimuli with FPs were created by synthesizing utterances with the filler \\\"um\\\" between repeated words using the ID-FP embedding (see Section 2). Utterances without FPs were synthesized with the non-hesitant version of the TTS system (ID-noFP). This resulted in six disfluent versions of each utterance: three repetition versions with FPs and three repetition versions without FPs. Figure 2 shows an example of these variations. Audio samples are available on the demo page 4.\\n\\nFluent: Good morning everyone and welcome to the first lecture of Understanding the Early Universe. In this lecture we'll discuss how scientists can measure the echoes of the distant past. Let's start by learning the definitions of some important terms. The number that helps us estimate how fast the universe is expanding is called the Hubble constant. What this constant tells us is that there's a direct relationship between a galaxy's distance and how quickly it's moving away from us.\\n\\nA: In this lecture we'll [um] we'll discuss how scientists can measure the echoes of the distant past.\\nB: In [um] in this lecture we'll [um] we'll discuss how scientists can measure the echoes of the distant past.\\nC: In this lecture we'll [um] we'll discuss how scientists can measure the [um] the echoes of the distant past.\\n\\nFigure 2: Examples of experimental stimuli. To create the disfluent versions, the highlighted words were repeated with or without FPs (blue in version A, red and blue in version B, green and blue in version C).\\n\\nTwenty self-reported native speakers of English were recruited via the crowdsourcing platform Prolific 5 and participated in a web-based experiment on cognition.run. Half of participants identified as male and half as female. They listened to and rated 14 audio clips in random order. Each participant heard stimuli from every condition, but heard only one version of each scenario. They were randomly assigned a unique combination of scenarios and conditions. The number of times a particular version of a scenario was presented was balanced across participants. Participants could listen to the stimuli as many times as needed, and rated the speaker from 1 to 7 on how competent, confident, sincere and friendly they sounded, and how much they would rely on the speaker to teach them something new.\\n\\nTable 2: ANOVA results summary with F scores and p values. Significant effects are marked with an asterisk (*).\\n\\n| Rep. type | Filled pause Rep | Rep * FP |\\n|-----------|-----------------|----------|\\n| Competence (general) | 15.99 < .001* | 2.841 0.11 0.38 0.68 |\\n| Competence (task-related) | 13.99 < .001* | 9.96 < .01* 3.26 < .05* |\\n| Confidence | 34.11 < .001* | 5.86 < .05* 1.34 0.27 |\\n| Sincerity | 3.71 < .05* | 5.11 < .05* 0.95 5.11 |\\n\\n3.1.1. Experiment 1 results\\nWe carried out a 3 (repetition type: A, B, C) x 2 (FP, no FP) x 2 (context: lecture, instructions) repeated measures ANOVA on each measure, with post-hoc Holm-Bonferroni tests. Significant effects are summarized in Table 2. As shown in Figure 1, participants rated speakers higher on both confidence and task-specific competence when the utterances contained few disfluencies (condition A), but between the two conditions with eight disfluencies, those with more uncommon disfluencies (B) were rated less competent and confident than those with more common disfluencies (C). There was no effect of FPs on general competence, but utterances with FPs were rated less confident and lower on task-related competence. Sincerity was affected by the number but not the type of repetitions. Condition C was rated as more sincere than both A and B, which were not significantly different from one another. Though there was no main effect of FPs on sincerity, the effects of repetition on sincerity were only significant for utterances with FPs. There were no effects of any of the manipulations on perceived friendliness, and the effect of context was not significant for any measure.\\n\\n3.2. Experiment 2\\nThe second experiment explored whether the effects of repetition type and frequency on perceived competence would be attenuated if participants attributed the disfluency to anxiety. Disfluency is associated with state anxiety [9] so this provides a realistic alternative explanation. Half of participants (the \\\"control\\\" condition) listened to an unmodified subset of the stimuli from Experiment 1. Four versions of each of four randomly chosen lecture scenarios without FPs (one fluent, one with each set of repetitions) were used in this condition. The other half of the participants (the \\\"anxiety attribution\\\" condition) received the same stimuli but with a small modification: Each clip included a short apology for being anxious, synthesized with the same voice. The utterances were otherwise identical to those used in the control version and in Experiment 1.\\n\\nThirty-two self-reported native speakers of English were recruited...\"}"}
{"id": "kirkland23_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"cruited via Prolific and randomly assigned to either the \\\"con-\\ntrol\\\" condition or the \\\"anxiety attribution\\\" condition (16 per\\ncondition). The task followed a similar procedure to Experi-\\nment 1, but each participant rated only 5 stimulus items. Con-\\ntrol participants rated the speaker's general and task-specific\\ncompetence, as in Experiment 1, while participants in the other\\ngroup also rated how anxious the speaker sounded.\\n\\n3.2.1. Experiment 2 results\\n\\nA 4 (repetition type) x 2 (condition) mixed factorial ANOV A\\nshowed a significant main effect of repetition type on both gen-\\neral competence, \\\\( F(3) = 10.77, p < .001 \\\\) and task-related com-\\npetence \\\\( F(3) = 18.77, p < .001 \\\\) as well as a significant inter-\\naction between condition and repetition for both general\\n\\\\( F(3) = 9.74, p < .001 \\\\) and task-related competence\\n\\\\( F(3) = 9.57, p < .001 \\\\). The simple main effect of general competence was sig-\\nnificant only in the control condition, and post-hoc tests show\\nthat all differences between levels of repetition (shown in Ta-\\nble 3) were significant in the control group. The simple main\\neffect of task competence was significant in both conditions, but\\nonly the difference between fluent utterances and repetition type\\nC was significant in the anxiety attribution condition, while in\\nthe control condition all means except repetition type A and C\\nwere significantly different. There was no main effect of condi-\\ntion. Because we purposely did not mention anxiety to the con-\\ntrol group, we cannot compare anxiety ratings between groups.\\n\\nHowever, a one-sample t-test showed that the mean anxiety rat-\\ning of 4.69 was significantly higher than the middle value of 4\\non the scale, \\\\( t = 3.92, p < .001 \\\\).\\n\\n4. Discussion\\n\\nOur results confirm hypothesis \\\\( H1 \\\\), that disfluencies negatively\\nimpact perceived competence and confidence. However, gen-\\neral competence was affected only by repetitions, while task-\\nspecific competence was also impacted by FPs. In\\n\\\\( H2 \\\\) we pre-\\ndicted that a combination of FPs and repetitions would not be\\nstrictly additive. This seems to be true for general competence,\\nwhere no interaction was found between repetitions and FPs,\\nbut for task-related competence, the effect of repetitions was\\nstronger when FPs were present. This may be due to how we\\noperationalized task-related competence, by asking participants\\nif they would rely on the speaker to teach them something new.\\nTeaching ability depends on not only competence, but also fac-\\ntors such as how engaging a speaker is, so this question may\\nhave captured dimensions that we did not intend to measure.\\n\\nWe confirmed the hypothesis \\\\( H3 \\\\) that less typical repetitions\\n(those found by \\\\[4\\\\] to occur less often in spontaneous speech)\\nwith the same number of repetitions, those with more uncom-\\nmon repetitions were rated less competent and confident. This\\npattern only held for general competence in Experiment 1, but\\naffected both measures of competence in Experiment 2. It may\\nbe that the smaller number of stimuli in Experiment 2 made\\nsubtle differences more salient. Although we have shown that\\nthe type of repetition does matter, we cannot be certain why\\nless common repetitions had a stronger impact on evaluations.\\nThese repetitions differ in a number of ways from more com-\\nmon repetitions: they tend to be lower-frequency words, are a\\nmore diverse category, and tend to disrupt larger syntactic con-\\nstituents. One approach in future work could be to repeat the\\nsame lexical item in different syntactic contexts.\\n\\nDespite previous findings that disfluencies can make speak-\\ners seem more friendly \\\\[7\\\\], \\\\( H4 \\\\) was not confirmed. There was\\nno effect of disfluency on perceived friendliness, and more rep-\\netitions (combined with FPs) made speakers seem less sincere.\\nThis may be because listeners did not find judgments about\\nfriendliness or sincerity pertinent to delivering a lecture or in-\\nstructions. Sincerity ratings may have been affected by the gen-\\neral negative impression of disfluencies, whereas participants\\nmay not have felt that they had enough information to judge\\nfriendliness. Future work could explore this further by includ-\\ning scenarios where friendliness or sincerity are more relevant.\\n\\nThe second experiment provided additional confirmation of\\n\\\\( H3 \\\\), and also supports \\\\( H5 \\\\). When participants heard that the\\nspeaker was anxious about giving a lecture, the effect of repeti-\\ntions on competence was eliminated (and it is also worth noting\\nthat the \\\"anxious\\\" voices were not rated as sounding less com-\\npetent overall). Presumably, in line with \\\\[19\\\\], this represents a\\ndiscounting effect: listeners may have concluded that the repe-\\ntitions were unrelated to the speaker's competence because they\\nwere offered a better explanation. One of the participants com-\\nmented that admitting to anxiety was a \\\"classic public speaking\\nmistake\\\" but our results suggest otherwise. On the contrary,\\nwhen speakers anticipate that they will be disfluent (whether\\nbecause they really are nervous or because they are unfamiliar\\nwith the material they need to present) an excuse might lessen\\nthe impact of a halting delivery. Another implication of these\\nfindings is that listeners actually seem to attribute states, such\\nas anxiety, to \\\"speakers\\\" they know are not real people.\\n\\n5. Conclusions\\n\\nOur results show that the characteristics of different types of\\ndisfluencies and the contexts in which they appear may play a\\nrole in how they impact evaluations. We found that both the\\nnumber and type of speech disfluencies affect perceived com-\\npetence, sincerity and confidence. The effects on competence\\nare attenuated by discounting effects, so asking listeners to par-\\ndon our disfluencies may be an effective way to reduce their\\nimpact how we are perceived. This may be particularly rele-\\nvant for speakers who use disfluencies atypically, such as some\\nL2 speakers or women with ASD. Future studies could also ex-\\namine how speaker characteristics such as gender or age may\\nmoderate the effects of disfluencies on evaluations.\\n\\n6. Acknowledgements\\n\\nThis work is supported by the Swedish Research Council\\nproject Perception of speaker stance (VR-2020-02396), and the\\nRiksbankens Jubileumsfond project CAPTivating \u2013 Compar-\\native Analysis of Public speaking with Text-to-speech (P20-\\n0298).\"}"}
{"id": "kirkland23_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. References\\n\\n[1] N. Chomsky, Aspects of the Theory of Syntax. MIT press, 2014, vol. 11.\\n\\n[2] P. Howell and S. Sackin, \\\"Function word repetitions emerge when speakers are operantly conditioned to reduce frequency of silent pauses,\\\" Journal of Psycholinguistic Research, vol. 30, no. 5, pp. 457\u2013474, 2001.\\n\\n[3] C. Bazzanella, \\\"Redundancy, repetition, and intensity in discourse,\\\" Language sciences, vol. 33, no. 2, pp. 243\u2013254, 2011.\\n\\n[4] H. H. Clark and T. Wasow, \\\"Repeating words in spontaneous speech,\\\" Cognitive Psychology, vol. 37, no. 3, pp. 201\u2013242, 1998.\\n\\n[5] H. H. Clark and J. E. F. Tree, \\\"Using uh and um in spontaneous speaking,\\\" Cognition, vol. 84, no. 1, pp. 73\u2013111, 2002.\\n\\n[6] S. E. Brennan and M. Williams, \\\"The feeling of another's knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers,\\\" Journal of Memory and Language, vol. 34, no. 3, pp. 383\u2013398, 1995.\\n\\n[7] J. K. Barge, D. W. Schlueter, and A. Pritchard, \\\"The effects of nonverbal communication and gender on impression formation in opening statements,\\\" Southern Communication Journal, vol. 54, no. 4, pp. 330\u2013349, 1989.\\n\\n[8] J. Gustafson, J. Beskow, and \u00b4E. Sz\u00b4ekely, \\\"Personality in the mix \u2013 investigating the contribution of fillers and speaking style to the perception of spontaneous speech synthesis,\\\" Proc. SSW, pp. 48\u201353, 2021.\\n\\n[9] J. A. Harrigan, I. Suarez, and J. S. Hartman, \\\"Effect of speech errors on observers' judgments of anxious and defensive individuals,\\\" Journal of Research in Personality, vol. 28, no. 4, pp. 505\u2013529, 1994.\\n\\n[10] A. Kirkland, M. W\u0142odarczak, J. Gustafson, and \u00b4E. Sz\u00b4ekely, \\\"Perception of smiling voice in spontaneous speech synthesis,\\\" in Proc. SSW, 2021, pp. 26\u201328.\\n\\n[11] \u00b4E. Sz\u00b4ekely, J. Mendelson, and J. Gustafson, \\\"Synthesising uncertainty: The interplay of vocal effort and hesitation disfluencies.\\\" in Proc. Interspeech, 2017, pp. 804\u2013808.\\n\\n[12] G. R. Miller and M. A. Hewgill, \\\"The effect of variations in non-fluency on audience ratings of source credibility,\\\" Quarterly Journal of Speech, vol. 50, no. 1, pp. 36\u201344, 1964.\\n\\n[13] C. H. Lay and B. F. Burron, \\\"Perception of the personality of the hesitant speaker,\\\" Perceptual and Motor Skills, vol. 26, no. 3, pp. 951\u2013956, 1968.\\n\\n[14] M. Wester, M. Aylett, M. Tomalin, and R. Dall, \\\"Artificial personality and disfluency,\\\" in Proc. Interspeech, 2015.\\n\\n[15] M. Corley, L. J. MacGregor, and D. I. Donaldson, \\\"It's the way that you, er, say it: Hesitations in speech affect language comprehension,\\\" Cognition, vol. 105, no. 3, pp. 658\u2013668, 2007.\\n\\n[16] L. J. MacGregor, M. Corley, and D. I. Donaldson, \\\"Not all disfluencies are equal: The effects of disfluent repetitions on language comprehension,\\\" Brain and Language, vol. 111, no. 1, pp. 36\u201345, 2009.\\n\\n[17] J. E. F. Tree, \\\"The effects of false starts and repetitions on the processing of subsequent words in spontaneous speech,\\\" Journal of Memory and Language, vol. 34, no. 6, pp. 709\u2013738, 1995.\\n\\n[18] M. Dragojevic and H. Giles, \\\"I don't like you because you're hard to understand: The role of processing fluency in the language attitudes process,\\\" Human Communication Research, vol. 42, no. 3, pp. 396\u2013420, 2016.\\n\\n[19] D. M. Oppenheimer, \\\"Consequences of erudite vernacular utilized irrespective of necessity: Problems with using long words needlessly,\\\" Applied Cognitive Psychology: The Official Journal of the Society for Applied Research in Memory and Cognition, vol. 20, no. 2, pp. 139\u2013156, 2006.\\n\\n[20] J. Cenoz, \\\"Pauses and communication strategies in second language speech.\\\" ERIC Document ED 426630, 1998.\\n\\n[21] J. Parish-Morris, M. Y. Liberman, C. Cieri, J. D. Herrington, B. E. Yerys, L. Bateman, J. Donaher, E. Ferguson, J. Pandey, and R. T. Schultz, \\\"Linguistic camouflage in girls with autism spectrum disorder,\\\" Molecular Autism, vol. 8, no. 1, pp. 1\u201312, 2017.\\n\\n[22] J. K. Lake, K. R. Humphreys, and S. Cardy, \\\"Listener vs. speaker-oriented aspects of speech: Studying the disfluencies of individuals with autism spectrum disorders,\\\" Psychonomic Bulletin & Review, vol. 18, pp. 135\u2013140, 2011.\\n\\n[23] R. F. Bornstein and P. R. D'Agostino, \\\"The attribution and discounting of perceptual fluency: Preliminary tests of a perceptual fluency/attributional model of the mere exposure effect,\\\" Social Cognition, vol. 12, no. 2, pp. 103\u2013128, 1994.\\n\\n[24] C. Aruffo, \\\"Reading scripted dialogue: Pretending to take turns,\\\" Discourse Processes, vol. 57, no. 3, pp. 242\u2013258, 2020.\\n\\n[25] G. P. Laan, \\\"The contribution of intonation, segmental durations, and spectral features to the perception of a spontaneous and a read speaking style,\\\" Speech Communication, vol. 22, no. 1, pp. 43\u201365, 1997.\\n\\n[26] P. Wagner and A. Windmann, \\\"Re-enacted and spontaneous conversational prosody \u2013 How different?\\\" Proc. of Speech Prosody, pp. 518\u2013522, 2016.\\n\\n[27] S. King, \\\"A reading list of recent advances in speech synthesis,\\\" in Proc. ICPHS, 2015.\\n\\n[28] A. Kirkland, H. Lameris, \u00b4E. Sz\u00b4ekely, and J. Gustafson, \\\"Where's the uh, hesitation? The interplay between filled pause location, speech rate and fundamental frequency in perception of confidence,\\\" in Proc. Interspeech, 2022, pp. 18\u201322.\\n\\n[29] \u00b4E. Sz \u00b4ekely, G. E. Henter, and J. Gustafson, \\\"Casting to corpus: Segmenting and selecting spontaneous dialogue for TTS with a CNN-LSTM speaker-dependent breath detector,\\\" in Proc. ICASSP, 2019, pp. 6925\u20136929.\\n\\n[30] J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen, Y. Zhang, Y. Wang, R. Skerrv-Ryan et al. \\\"Natural TTS synthesis by conditioning wavenet on mel spectrogram predictions,\\\" in Proc. ICASSP, 2018, pp. 4779\u20134783.\\n\\n[31] R. Valle, J. Li, R. Prenger, and B. Catanzaro, \\\"Mellotron: Multispeaker expressive voice synthesis by conditioning on rhythm, pitch and global style tokens,\\\" in Proc. ICASSP, 2020, pp. 6189\u20136193.\\n\\n[32] T. Raitio, R. Rasipuram, and D. Castellani, \\\"Controllable neural text-to-speech synthesis using intuitive prosodic features,\\\" Proc. Interspeech, pp. 4432\u20134436, 2020.\"}"}
