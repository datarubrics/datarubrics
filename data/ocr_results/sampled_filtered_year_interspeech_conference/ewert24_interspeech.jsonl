{"id": "ewert24_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"6. Acknowledgements\\n\\nThis research is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy (University Allowance, EXC 2077, University of Bremen).\\n\\n7. References\\n\\n[1] E. C. Cherry, \u201cSome experiments on the recognition of speech, with one and with two ears,\u201d *The Journal of the Acoustical Society of America*, vol. 25, no. 5, pp. 975\u2013979, 1953.\\n\\n[2] J. R. Hershey, Z. Chen, J. L. Roux, and S. Watanabe, \u201cDeep clustering: Discriminative embeddings for segmentation and separation,\u201d in *ICASSP*, 2016, pp. 31\u201335.\\n\\n[3] M. Kolb\u00e6k, D. Yu, Z.-H. Tan, and J. Jensen, \u201cMultitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks,\u201d *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, vol. 25, no. 10, pp. 1901\u20131913, 2017.\\n\\n[4] D. Yu, M. Kolb\u00e6k, Z.-H. Tan, and J. Jensen, \u201cPermutation invariant training of deep models for speaker-independent multi-talker speech separation,\u201d in *ICASSP*, 2017, pp. 241\u2013245.\\n\\n[5] Y. Luo and N. Mesgarani, \u201cConv-TasNet: Surpassing ideal time\u2013frequency magnitude masking for speech separation,\u201d *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, vol. 27, no. 8, pp. 1256\u20131266, 2019.\\n\\n[6] Y. Luo, Z. Chen, and T. Yoshioka, \u201cDual-path RNN: Efficient long sequence modeling for time-domain single-channel speech separation,\u201d in *ICASSP*, 2020, pp. 46\u201350.\\n\\n[7] C. Subakan, M. Ravanelli, S. Cornell, M. Bronzi, and J. Zhong, \u201cAttention is all you need in speech separation,\u201d in *ICASSP*, 2021, pp. 21\u201325.\\n\\n[8] M. Delcroix, K. Zmolikova, T. Ochiai, K. Kinoshita, S. Araki, and T. Nakatani, \u201cCompact network for speakerbeam target speaker extraction,\u201d in *ICASSP*, 2019, pp. 6965\u20136969.\\n\\n[9] M. Ge, C. Xu, L. Wang, E. S. Chng, J. Dang, and H. Li, \u201cSpEx+: A complete time domain speaker extraction network,\u201d in *INTER-SPEECH*, 2020, pp. 1406\u20131410.\\n\\n[10] J. Zhang, C. Zoril \u02d8a, R. Doddipatla, and J. Barker, \u201cTime-domain speech extraction with spatial information and multi speaker conditioning mechanism,\u201d in *ICASSP*, 2021, pp. 6084\u20136088.\\n\\n[11] C. Xu, W. Rao, X. Xiao, E. S. Chng, and H. Li, \u201cSingle channel speech separation with constrained utterance level permutation invariant training using grid LSTM,\u201d in *ICASSP*, 2018, pp. 6\u201310.\\n\\n[12] E. Godoy, M. Koutsogiannaki, and Y. Stylianou, \u201cApproaching speech intelligibility enhancement with inspiration from lombard and clear speaking styles,\u201d in *Computer Speech & Language*, vol. 28, no. 2, pp. 629\u2013647, 2014.\\n\\n[13] E. Lombard, \u201cLe signe de l'\u00e9l\u00e8vation de la voix (translated from french),\u201d *Ann. des Mal. l'oreille du larynx*, vol. 37, no. 2, pp. 101\u2013119, 1911.\\n\\n[14] J.-C. Junqua, \u201cThe Lombard reflex and its role on human listeners and automatic speech recognizers,\u201d *The Journal of the Acoustical Society of America*, vol. 93, no. 1, pp. 510\u2013524, 1993.\\n\\n[15] W. V. Summers, D. B. Pisoni, R. H. Bernacki, R. I. Pedlow, and M. A. Stokes, \u201cEffects of noise on speech production: Acoustic and perceptual analyses,\u201d *The Journal of the Acoustical Society of America*, vol. 84, no. 3, pp. 917\u2013928, 1988.\\n\\n[16] Y. Lu and M. Cooke, \u201cSpeech production modifications produced by competing talkers, babble, and stationary noise,\u201d *The Journal of the Acoustical Society of America*, vol. 124, no. 5, pp. 3261\u20133275, 2008.\\n\\n[17] G. Wichern, J. Antognini, M. Flynn, L. R. Zhu, E. McQuinn, D. Crow, E. Manilow, and J. L. Roux, \u201cWHAM!: Extending speech separation to noisy environments,\u201d in *INTERSPEECH*, 2019, pp. 1368\u20131372.\\n\\n[18] J. Cosentino, M. Pariente, S. Cornell, A. Deleforge, and E. Vincent, \u201cLibrimix: An open-source dataset for generalizable speech separation,\u201d *arXiv preprint arXiv:2005.11262v1*, 2020.\\n\\n[19] R. Marxer, J. Barker, N. Alghamdi, and S. Maddock, \u201cThe impact of the Lombard effect on audio and visual speech recognition systems,\u201d *Speech Communication*, vol. 100, pp. 58\u201368, 2018.\\n\\n[20] P. Ma, S. Petridis, and M. Pantic, \u201cInvestigating the Lombard effect influence on end-to-end audio-visual speech recognition,\u201d in *INTERSPEECH*, 2019, pp. 4090\u20134094.\\n\\n[21] S. U. Maheswari, A. Shahina, and A. N. Khan, \u201cUnderstanding Lombard speech: a review of compensation techniques towards improving speech based recognition systems,\u201d *Artificial Intelligence Review*, vol. 54, no. 4, pp. 2495\u20132523, 2020.\\n\\n[22] D. Michelsanti, Z.-H. Tan, S. Sigurdsson, and J. Jensen, \u201cDeep-learning-based audio-visual speech enhancement in presence of Lombard effect,\u201d *Speech Communication*, vol. 115, pp. 38\u201350, Dec 2019.\\n\\n[23] D. Michelsanti, Z.-H. Tan, S. Sigurdsson, and J. Jensen, \u201cEffects of Lombard reflex on the performance of deep-learning-based audio-visual speech enhancement systems,\u201d in *ICASSP*, 2019, pp. 6615\u20136619.\\n\\n[24] S. A. Nossier, J. Wall, M. Moniri, C. Glackin, and N. Cannings, \u201cAn experimental analysis of deep learning architectures for supervised speech enhancement,\u201d *Electronics*, vol. 10, no. 1, p. 17, 2020.\\n\\n[25] N. Alghamdi, S. Maddock, R. Marxer, J. Barker, and G. J. Brown, \u201cA corpus of audio-visual Lombard speech with frontal and profile views,\u201d *The Journal of the Acoustical Society of America*, vol. 143, no. 6, pp. EL523\u2013EL529, 2018.\\n\\n[26] M. Cooke, J. Barker, S. Cunningham, and X. Shao, \u201cAn audio-visual corpus for speech perception and automatic speech recognition,\u201d *The Journal of the Acoustical Society of America*, vol. 120, no. 5, pp. 2421\u20132424, 2006.\\n\\n[27] Y. Isik, J. Roux, S. Chen, and J. Hershey, \u201cScripts to create wsj0-2 speaker mixtures,\u201d MERL Research, retrieved October 23, 2023. [Online]. Available: https://www.merl.com/demos/deepclustering/create-speaker-mixtures.zip\\n\\n[28] J. Garofolo, D. Graff, D. Paul, and D. Pallett, \u201ccsr-i (wsj0) complete ldc93s6a,\u201d Web Download. Philadelphia: Linguistic Data Consortium, vol. 83, 1993.\\n\\n[29] M. Pariente, S. Cornell, J. Cosentino, S. Sivasankaran, E. Tzinis, J. Heitkaemper, M. Olvera, F.-R. St \u00a8oter, M. Hu, J. M. Mart \u00b4\u0131n-Do\u02dcnas, D. Ditter, A. Frank, A. Deleforge, and E. Vincent, \u201cAsteroid: The PyTorch-based audio source separation toolkit for researchers,\u201d in *INTERSPEECH*, 2020, pp. 2637\u20132641.\\n\\n[30] J. L. Roux, S. Wisdom, H. Erdogan, and J. R. Hershey, \u201cSDR \u2013 half-baked or well done?\u201d in *ICASSP*, 2019, pp. 626\u2013630.\\n\\n[31] D. P. Kingma and J. Ba, \u201cAdam: A method for stochastic optimization,\u201d in ICLR, 2015.\"}"}
{"id": "ewert24_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Does the Lombard Effect Matter in Speech Separation? Introducing the Lombard-GRID-2mix Dataset\\n\\nIva Ewert1, Marvin Borsdorf1, Haizhou Li3,2, Tanja Schultz4\\n\\n1 Machine Listening Lab (MLL), University of Bremen, Germany\\n2 Department of Electrical and Computer Engineering, National University of Singapore, Singapore\\n3 SDS, SRIBD, The Chinese University of Hong Kong, Shenzhen, China\\n4 Cognitive Systems Lab (CSL), University of Bremen, Germany\\n\\niewert@uni-bremen.de, marvin.borsdorf@uni-bremen.de\\n\\nAbstract\\n\\nInspired by the human ability of selective listening, speech separation aims to equip machines with the capability to disentangle cocktail party soundscapes into the individual sound sources. Recently, neural network based algorithms have been studied to work reliably under various conditions. However, to the best of our knowledge, a change in the speaking style has not yet been studied. The Lombard effect, a reflexive change in speaking style triggered by noisy environments, is a typical behavior in everyday conversational situations. In this work, we introduce a new first of its kind dataset, called Lombard-GRID-2mix, to study speech separation for two-speaker mixtures on normal speech and Lombard speech. In a comprehensive study, we show that speech separation systems can be equipped to work for both normal speech and Lombard speech. We apply a carefully designed finetuning method to enable the system to work even if noise is present in the Lombard speech for different SNR ratios.\\n\\nIndex Terms\\nSpeech separation, cocktail party problem, selective auditory attention, Lombard effect, noisy speech\\n\\n1. Introduction\\n\\nHumans have the ability to almost effortlessly focus on a particular sound source within a given mixture signal, referred to as selective auditory attention. Cherry et al. [1] formulated this in 1953 by introducing the cocktail party problem. Equipping machines with this ability, however, still represents an unsolved research problem. Solutions to the problem are motivated by two main strands: (a) the application in smart hearing aids (b) its potential as a front-end for downstream tasks such as automatic speech recognition (ASR) and speaker verification. The research that aims to develop machines that mimic this human ability is called speech separation. The goal of speech separation is to disentangle a given mixture signal into the individual speech signals. For this, two main algorithms have been introduced: Blind source separation (BSS) [2, 3, 4, 5, 6, 7] and target speaker extraction (TSE) [8, 9, 10]. BSS separates a given mixture signal of overlapping sources into all individual sources in one step. This approach usually requires the number of contributing sources to be known in advance. Furthermore, the assignment of output channels to the sound sources is ambiguous. This so called permutation problem can be solved by applying the permutation invariant training (PIT) [3, 4] method.\\n\\nIn contrast to BSS, TSE extracts solely the voice of a particular target speaker from a given mixture signal. To perform this method, a supplementary information commonly in form of a target speaker's speech sample is used.\\n\\nInitially, speech separation has been studied in the frequency-domain in which the algorithms operate on the Short-Time Fourier Transform representation of the mixture signal [2, 3, 11]. In recent time, end-to-end approaches operating in the time-domain have been introduced [5, 6, 7]. The latter elegantly circumvent the inaccuracy of using the phase information of the mixture signal for the reconstruction of the separated sources in the time-domain and, in addition, allow to directly process the raw audio signal.\\n\\nIn everyday conversational situations, speech separation systems have to handle typical changes in the conversation and soundscape, such as unknown voices, different numbers of overlapping voices, and varying background noise. Another typical behavior of human speakers is a change in the speaking style to enhance the intelligibility of their speech in adverse conditions. While speakers who communicate with hearing-impaired listeners adapt a so-called clear speaking style characterized by overly articulated speech, speakers who are faced by noisy environments tend to increase their vocal effort to overcome the communication barrier [12], which is called the Lombard effect [13]. Typically, the effect is characterized by a rise in the sound volume, an alteration of the fundamental frequency, an increase in the vowel duration, and a change in the formant frequencies of the speech signals [14, 15, 16]. Usually, as the acquisition of speech in noisy environments requires a complex recording setup, noise is, if at all, artificially added to normal speech in the datasets to develop noise-robust speech separation systems [17, 18]. In real-life scenarios, however, speech separation systems have to cope with the combination of noise and Lombard speech, as this particular speaking style adaptation is usually accompanied by noisy environments.\\n\\nIn the field of ASR, recent studies [14, 19, 20, 21] investigated the effect of Lombard speech on selected ASR systems. Ma et al. [20] investigated the impact of the Lombard effect on audio-only, video-only, and audio-visual speech recognition and demonstrated the benefits of integrating Lombard speech into the system development. The influence of the Lombard effect has also recently attracted attention in the field of speech enhancement [22, 23, 24]. Speech enhancement aims to improve the quality of speech signals that are adversely affected for example by noise. In Michelsanti et al. [23], a performance gap of approx. 5 dB between systems trained on normal speech and systems trained on Lombard speech was identified, if tested on Lombard speech. Consequently, the existence of similar phenomena in the field of speech separation can be assumed. However, to the best of our knowledge, studies on this topic have not...\"}"}
{"id": "ewert24_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"yet been carried out. In this work, we study the influence of the Lombard effect on speech separation systems. For this, we propose and construct a new first of its kind dataset, called Lombard-GRID-2mix. The dataset consists of two-speaker mixtures generated on the basis of speech material derived from the Audio-Visual Lombard GRID Corpus [25]. Lombard-GRID-2mix is designed to match the BSS paradigm and is divided into two sets containing mixtures of normal or Lombard speech, respectively. On the basis of this dataset, we develop two systems and evaluate each on both normal and Lombard speech. In a comprehensive experimental setup, we investigate the benefits of integrating Lombard speech in the system development and apply different finetuning strategies. We record a performance degradation of the system trained on normal data in the presence of Lombard speech and identify a suitable finetuning strategy to overcome this problem. As Lombard speech is triggered by the occurrence of noise in real world conversational situations, we extend our dataset with four additional versions of the Lombard subset that integrate speech-shaped noise (SSN) at different signal-to-noise-ratios (SNRs). We find that the performances of all systems drop drastically on Lombard speech in noise, but we can substantially mitigate this degradation by integrating Lombard speech into a carefully designed training process.\\n\\nThe rest of the paper is organized as follows. In Section 2, we introduce the Lombard-GRID-2mix dataset and explain its construction. In Section 3, we describe the experimental setup, followed by Section 4, which presents and discusses the results. Section 5 concludes our study and highlights some future work. We make all scripts to simulate the Lombard-GRID-2mix dataset publicly available.\\n\\n2. Construction of Lombard-GRID-2mix\\n\\nTo compare the speech separation performance on normal speech versus Lombard speech, an appropriate dataset is required. To achieve this, we propose a new first of its kind dataset, called Lombard-GRID-2mix, which provides two-speaker speech mixtures and the respective single speaker voices in both normal speech and Lombard speech. The dataset is derived from the Audio-Visual Lombard GRID Corpus [25].\\n\\n2.1. The Audio-Visual Lombard GRID Speech Corpus\\n\\nThe Audio-Visual Lombard GRID Speech Corpus [25] contains recorded utterances produced by 54 (30 female and 24 male) native speakers of British English between the age of 18 and 30. The construction of the recorded sentences followed the Grid corpus syntax [26]. From a set of 30,000 sentences, a subset of 50 unique sentences was assigned to a speaker and recorded in normal (N) and in Lombard (L) speech. To trigger the Lombard speech, SSN was presented to the speaker at a sound pressure level of 80 dB via headphones. The speaker read the sentences to a human listener to ensure the intelligibility of the speech, which represented one of the prerequisites for the Lombard effect. Every five to seven sentences, the human listener asked the speaker to repeat the sentence while pretending not to understand the last utterance, which represented the first form of feedback. In addition, the produced speech of the speaker was presented to the speaker at a carefully adjusted level, as speakers regulate their speaking style also by considering the perceived level of their own speech.\\n\\nSince the combination of all speakers and utterances to simulate the two-speaker mixtures would lead to high computational costs, we apply the following strategy: First, we introduce different groups. Each group consists of five utterances per speaker in the considered set. Second, within these groups, we combine all utterances of different speakers. Third, for each utterance combination, a SNR is randomly sampled. The SNR value is drawn from a uniform distribution in the range of \\\\([0, 5]\\\\) dB. Fourth, the fore- and background speakers are randomly selected by assigning \\\\(\\\\pm \\\\text{SNR}\\\\). This strategy ensures a zero mean and a signal-level difference between both speakers based on the sampled SNR value. Fifth, the scripts of Isik et al. [27], originally implemented for the creation of the wsj0-2mix and wsj0-3mix datasets [2], are used to simulate the actual mixture data. For the presented experiments, a sampling frequency of 8 kHz and the \\\"min\\\" mode are applied. In the \\\"min\\\" mode, the longer utterance is cut to the length of the shorter utterance when mixing two utterances, resulting in highly overlapped speech.\\n\\nThe final Lombard-GRID-2mix dataset comprises 109.5, 29, and 9.2 hours (normal) and 118.3, 31.2, and 9.9 hours (Lombard) of total audio data for training, validation, and testing, respectively. The total amount of audio data in the Lombard set is higher due to an increased utterance duration because of the adapted speaking style.\\n\\n2.3. Addition of speech-shaped noise\\n\\nAs Lombard speech is typically accompanied by noise, we repeat the simulation of the Lombard subset (Lombard-GRID-2mix-Lombard) with additional background noise at four different SNR ranges. For this, we simulate speech-shaped noise (SSN) that matches the Lombard recording condition of the Audio-Visual Lombard GRID speech corpus. SSN is a stationary noise type that follows the spectrum of human speech, obtained by applying the Discrete Fast Fourier Transform. To ensure the independence of the noise signals from the speech material given in the mixtures, we utilize a different dataset for noise generation, namely the Wall Street Journal (WSJ0) [28] corpus. For each speaker in the WSJ0 corpus, a noise signal is created by extracting the long-term spectrum of the respective speech material, followed by phase randomization. A SSN sample is assigned to each two-speaker mixture signal in the Lombard-GRID-2mix-Lombard set. To simulate the two-speaker mixture signal including SSN in the background, the three-speaker mixture simulation scripts from [27] are used in which the SSN is considered as a third speaker\u2019s signal. In each of the four\"}"}
{"id": "ewert24_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Speech separation results for different systems and training methods. All finetuned systems are pre-trained on the Lombard-GRID-2mix-Normal subset. Systems #5 and #6 are finetuned with a learning rate of $1 \\\\times 10^{-5}$ and $1 \\\\times 10^{-4}$, respectively. The results are reported in terms of SI-SDRi (dB) as mean over all samples in the normal speech and Lombard speech test sets, respectively. In addition, we report the mean performance over both test sets. The higher the SI-SDRi, the better.\\n\\n| Number | System              | Training method | Trained on Lombard-GRID-2mix-Normal | Results on Lombard-GRID-2mix-Lombard | Mean |\\n|--------|---------------------|-----------------|-------------------------------------|--------------------------------------|------|\\n| 1      | Conv-TasNet-N       | from scratch    | \u2713                                   | 14.71                                | 13.48 |\\n| 2      | Conv-TasNet-L       | from scratch    | \u2717                                   | 15.05                                | 15.03 |\\n| 3      | DPRNN-N             | from scratch    | \u2713                                   | 14.70                                | 13.84 |\\n| 4      | DPRNN-L             | from scratch    | \u2717                                   | 14.19                                | 14.32 |\\n| 5      | DPRNN-FT-I          | finetuning (from #3) | \u2717                                 | 14.49                                | 14.26 |\\n| 6      | DPRNN-FT-II         | finetuning (from #3) | \u2713                                 | 15.04                                | 14.62 |\\n\\nIn addition, we report the mean performance over both test sets. The higher the SI-SDRi, the better.\\n\\n3. Experimental setup\\n\\nIn our study, we develop and evaluate nine speech separation systems on the Lombard-GRID-2mix dataset. We train the systems from scratch and apply finetuning methods. The system performance of the systems is evaluated on different test sets. The experiments are implemented in Python using PyTorch.\\n\\n3.1. Network architectures\\n\\nThe systems in our experiments are based on the widely studied Conv-TasNet [5] and DPRNN [6] architectures. Both architectures work in the time-domain and apply the mask estimation approach as follows: The encoder transforms the input mixture signal into a latent representation. The separation part of the system estimates masks for each of the sources of the input mixture, which are subsequently element-wise multiplied with the latent representation of the input mixture to obtain the separated signals. The decoder reconstructs the waveform of the separated sources.\\n\\nThe systems are implemented using the audio source separation toolkit Asteroid [29]. The configuration of the Conv-TasNet is chosen according to the best system identified by Luo et al. [5]. Due to limited computation power, the configuration of the DPRNN with a chunk size of 100 and a kernel length of 16 is chosen. The used implementations of the Conv-TasNet and the DPRNN comprise 5.05 million and 3.65 million parameters, respectively.\\n\\n3.2. Training and evaluation procedure\\n\\nThe speech separation systems are trained from scratch or finetuned on different subsets of the Lombard-GRID-2mix dataset in a supervised learning fashion. During training and finetuning, the negative value of the scale-invariant source-to-distortion ratio (SI-SDR) [30] (Eq. 1) is used as the loss function:\\n\\n$$\\\\text{SI-SDR} \\\\approx 20 \\\\cdot \\\\log_{10} \\\\left( \\\\frac{\\\\hat{s}^T \\\\cdot s}{\\\\|s\\\\|^2_2} + \\\\epsilon \\\\cdot \\\\frac{\\\\hat{s}^T \\\\cdot s}{\\\\|s\\\\|^2_2} + \\\\epsilon \\\\cdot s - \\\\hat{s} + \\\\epsilon \\\\right)$$\\n\\nwith $s$ being the ground truth signal and $\\\\hat{s}$ denoting the reconstructed signal. We add $\\\\epsilon = 1 \\\\times 10^{-8}$ to stabilize the loss function. To circumvent the source permutation problem, utterance-level PIT [3] is applied. The training routine is implemented based on a publicly available framework [3]. The data is split into chunks of 4 s length, smaller samples between two and four seconds are padded with zeros while even smaller samples are discarded. The chunks are merged into mini-batches. The Conv-TasNet and the DPRNN based system are trained with a batch size of 32 and 64, respectively. Adam [31] is used as optimizer with an initial learning rate of $1 \\\\times 10^{-3}$ and a weight decay of $1 \\\\times 10^{-5}$. For the finetuning experiments, the initial learning rate is set to $1 \\\\times 10^{-5}$ or $1 \\\\times 10^{-4}$ depending on whether Lombard speech is used solely or altogether with normal speech data. The learning rate is halved after two subsequent epochs without any improvement on the validation data. The minimum learning rate is set to $1 \\\\times 10^{-8}$. After six epochs with no improvement on the validation loss, the training is stopped. The maximum number of epochs is set to 150 for both strategies, training from scratch and finetuning.\\n\\nAll systems are evaluated on all test sets. During evaluation, the utterances are fed into the systems with their entire length. The estimated separated signals are compared with their respective ground truth signals by calculating the SI-SDR [30]. The results are reported in terms of SI-SDR improvement (SI-SDRi) which is calculated as the difference between the SI-SDR of the estimated signals and the SI-SDR of the input mixture. SI-SDRi results are stated as the mean over all utterances in the considered test set.\\n\\n4. Results and discussion\\n\\nIn total, we trained nine speech separation systems. While two systems were trained on Lombard-GRID-2mix-Normal only, two other systems were trained solely on Lombard-GRID-2mix-Lombard. The other systems were developed by applying different finetuning methods to one of the pretrained systems. The systems are evaluated on Lombard-GRID-2mix-Normal and Lombard-GRID-2mix-Lombard test sets (see Table 1).\"}"}
{"id": "ewert24_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 2: Speech separation results for different systems and training methods on noisy Lombard speech (Lombard-noisy). All finetuned systems are pre-trained on the Lombard-GRID-2mix-Normal subset. While system #5 is finetuned with a learning rate of $1 \\\\times 10^{-5}$, systems #6-9 are finetuned with a learning rate of $1 \\\\times 10^{-4}$. The results are reported in terms of SI-SDRi in dB as mean over all samples in the respective Lombard-noisy test set. The SNR range (dB) between the speakers and the noise given in the mixtures is indicated by $N[\\\\text{Higher limit}, \\\\text{Lower limit}]$.\\n\\n| Number | System Training method | Trained on Lombard | Lombard | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy | Lombard-noisy |"}
