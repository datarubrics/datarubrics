{"id": "rameau24_interspeech", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. References\\n\\n[1] J. Robin, J. E. Harrison, L. D. Kaufman, F. Rudzicz, W. Simpson, and M. Yancheva, \u201cEvaluation of Speech-Based Digital Biomarkers: Review and Recommendations,\u201d Digit Biomark, vol. 4, no. 3, pp. 99\u2013108, Sep. 2020.\\n\\n[2] R. Fusaroli, A. Lambrechts, D. Bang, D. M. Bowler, and S. B. Gaigg, \u201cIs voice a marker for Autism spectrum disorder? A systematic review and meta-analysis,\u201d Autism Res., vol. 10, no. 3, pp. 384\u2013407, Mar. 2017.\\n\\n[3] G. Fagherazzi, A. Fischer, M. Ismael, and V. Despotovic, \u201cVoice for Health: The Use of Vocal Biomarkers from Research to Clinical Practice,\u201d Digit Biomark, vol. 5, no. 1, pp. 78\u201388, Apr. 2021.\\n\\n[4] M. Bowden, E. Beswick, J. Tam, D. Perry, A. Smith, J. Newton, S. Chandran, O. Watts, and S. Pal, \u201cA systematic review and narrative analysis of digital speech biomarkers in Motor Neuron Disease,\u201d NPJ Digit Med, vol. 6, no. 1, p. 228, Dec. 2023.\\n\\n[5] J. D. S. Sara, D. Orbelo, E. Maor, L. O. Lerman, and A. Lerman, \u201cGuess What We Can Hear\u2014Novel Voice Biomarkers for the Remote Detection of Disease,\u201d Mayo Clin. Proc., vol. 98, no. 9, pp. 1353\u20131375, Sep. 2023.\\n\\n[6] A. Idrisoglu, A. L. Dallora, P. Anderberg, and J. S. Berglund, \u201cApplied Machine Learning Techniques to Diagnose Voice-Affecting Conditions and Disorders: Systematic Literature Review,\u201d J. Med. Internet Res., vol. 25, p. e46105, Jul. 2023.\\n\\n[7] D. M. Low, K. H. Bentley, and S. S. Ghosh, \u201cAutomated assessment of psychiatric disorders using speech: A systematic review,\u201d Laryngoscope Investig Otolaryngol, vol. 5, no. 1, pp. 96\u2013116, Feb. 2020.\\n\\n[8] Y. Bensoussan, O. Elemento, and A. Rameau, \u201cVoice as an AI Biomarker of Health\u2014Introducing Audiomics,\u201d JAMA Otolaryngol. Head Neck Surg., Feb. 2024.\\n\\n[9] L. C. Kourtis, O. B. Regele, J. M. Wright, and G. B. Jones, \u201cDigital biomarkers for Alzheimer's disease: the mobile/wearable devices opportunity,\u201d NPJ Digit Med, vol. 2, Feb. 2019.\\n\\n[10] E. D. Foster and A. Deardorff, \u201cOpen Science Framework (OSF),\u201d J. Med. Libr. Assoc., vol. 105, no. 2, pp. 203\u2013206, Apr. 2017.\"}"}
{"id": "rameau24_interspeech", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Developing Multi-Disorder Voice Protocols: A team science approach involving clinical expertise, bioethics, standards, and DEI.\\n\\nAnais Rameau, Satrajit Ghosh, Alexandros Sigaras, Olivier Elemento, Jean-Christophe Belisle-Pipon, Vardit Ravitsky, Maria Powell, Alistair Johnson, David Dorr, Philip Payne, Micah Boyer, Stephanie Watts, Ruth Bahr, Frank Rudzick, Jordan-Lerner-Ellis, Shaheen Awan, Don Bolser, Bridge2AI-Voice Consortium, Yael Bensoussan.\\n\\n1. Department of Otolaryngology-Head and Neck Surgery, Weill Cornell Medicine, New York, New York, USA\\n2. McGovern Institute, Massachusetts Institute of Technology, Boston, Massachusetts, USA\\n3. Institute for Computational Biomedicine, Weill Cornell Medicine, New York, New York, USA\\n4. Englander Institute for Precision Medicine, Weill Cornell Medicine, New York, New York, USA\\n5. Faculty of Health Sciences, Simon-Fraser University, Vancouver, British Columbia, Canada\\n6. Hasting Center, Garrison, New York, USA\\n7. Department of Otolaryngology-Head & Neck Surgery, Vanderbilt University Medical Center, Nashville, Tennessee, USA\\n8. Division of Biostatistics, Hospital for Sick Children, Toronto, Ontario, Canada\\n9. Department of Medical Informatics, School of Medicine, Oregon Health & Science University, Portland, Oregon, USA\\n10. Institute for Informatics, Washington University in St Louis, St Louis, Missouri, USA\\n11. Department of Otolaryngology-Head & Neck Surgery, University of South Florida, Tampa, Florida, USA\\n12. Department of Communication Sciences & Disorders, University of South Florida, Tampa, Florida, USA\\n13. Faculty of Computer Science, Dalhousie University, Calgary, Manitoba Canada\\n14. Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, Ontario, Canada\\n15. Department of Communication Sciences & Disorders, University of Central Florida, Orlando, Florida, USA\\n16. Department of Physiological Sciences, University of Florida, Gainesville, Florida, USA\\n\\nanr2783@med.cornell.edu, satra@mit.edu, als2076@med.cornell.edu, ole2001@med.cornell.edu, jean-christophe_belisle-pipon@sfu.ca, vardit.ravitsky@umontreal.ca, maria.e.powell@vumc.org, alistair@glowyr.ca, dorrd@ohsu.edu, prpayne@wustl.edu, micahboyer@usf.edu, srandall1@usf.edu, rbahr@usf.edu, frank@spoclab.com, jordan.lerner-ellis@sinaihealth.ca, Shaheen.awan@ucf.edu, bolser@ufl.edu, yaelbensoussan@usf.edu\\n\\nInterspeech 2024\\n1-5 September 2024, Kos, Greece\\n1445 10.21437/Interspeech.2024-1926\"}"}
{"id": "rameau24_interspeech", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The world of voice biomarkers is rapidly evolving thanks to the use of artificial intelligence (AI) allowing large scale, ethically sourced and representative of a diverse population. Voice disorders are often directly linked to variations in acoustics of voice and speech recordings. However, as human acoustic tasks. Data corresponding to these datasets are often collected using laboratory settings and the generated metadata is relatively small. Most clinical voice and speech recognition research, the number of accessible and clinically relevant datasets with voice, speech, and associated clinical data for biomedical applications is hampered by several challenges.\\n\\nLack of standardized and reusable protocols for data acquisition, data are not distributed with metadata about diversity is lacking or the data are not representative of different health settings. Lack of standardized and reusable protocols for data collection approaches in varying external environments, and datasets are often inaccessible for such applications is hampered by several challenges. While there are several large datasets available for speech data, many of the existing datasets have been created without hypotheses for such applications. When available, these datasets remain inaccessible due to relevant sources of consent, and clinical protocols are lacking. Past data types: Multi-modal, diagnostic, and longitudinal data were collected as leaders in their respective fields of diseases studied. The \u201cunnamed\u201d consortium is composed of the following four adult disease cohorts were developed: 1. Voice disorders 2. Respiratory disorders 3. Mood disorders 4. Neurological Disorders.\\n\\nTeam science was tasked to develop protocols including the past literature review and clinical expertise over the course of 6 weeks. Each cohort lead searched the literature extensively to find the current standards to inform protocol development. Team science was composed of clinicians with expertise in specific disease cohorts including laryngologists and speech pathologists, Bioinformaticians: This group included software developers, data scientists, machine learning, and accessibility in the context of innovation. Stakeholders were involved in the development of protocols: Past data types: Multi-modal, diagnostic, and longitudinal data were collected as leaders in their respective fields of diseases studied. The \u201cunnamed\u201d consortium is composed of the following four adult disease cohorts were developed: 1. Voice disorders 2. Respiratory disorders 3. Mood disorders 4. Neurological Disorders.\\n\\nTeam science was tasked to develop protocols including the past literature review and clinical expertise over the course of 6 weeks. Each cohort lead searched the literature extensively to find the current standards to inform protocol development. Team science was composed of clinicians with expertise in specific disease cohorts including laryngologists and speech pathologists, Bioinformaticians: This group included software developers, data scientists, machine learning, and accessibility in the context of innovation. Stakeholders were involved in the development of protocols: Past data types: Multi-modal, diagnostic, and longitudinal data were collected as leaders in their respective fields of diseases studied. The \u201cunnamed\u201d consortium is composed of the following four adult disease cohorts were developed: 1. Voice disorders 2. Respiratory disorders 3. Mood disorders 4. Neurological Disorders.\"}"}
{"id": "rameau24_interspeech", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Confounders: The group was asked to include confounders and social habits that are known to affect voice and speech (e.g., smoking status, hydration status, etc).\\n\\nAcoustic tasks: The group was asked to include common acoustic tasks performed for screening or diagnosis of the conditions studied in the clinical setting or research setting.\\n\\nValidated questionnaires and PROs: Patient-reported outcomes (PROs) and validated patient questionnaires commonly used in clinical or research practice with evidenced-based correlation with the diseases studied (e.g., GAD-7 for anxiety or VHI-10 for dysphonia).\\n\\nClinical Validation: The group was asked to develop a section including questions that would confirm the diagnosis and treatment obtained by a clinician.\\n\\n\u201cGold Standards\u201d: The group was asked to add data modality that are used for confirmation or included in the basic work-up of the diseases studied (e.g., MRI of the brain for Alzheimer\u2019s disease, pathology report for laryngeal cancer, pulmonary function test for Asthma, etc).\\n\\n2.3. Protocol alignment for \u201cPart A\u201d and \u201cPart B\u201d\\n\\nOnce protocols were created independently for the 4 disease cohorts, they were then reviewed iteratively by the overall team to identify commonalities between protocols. Common data types were grouped and a common protocol across all disease cohorts was created for \u201cPart A\u201d. This part of the protocol was meant to include demographics, past medical history, confounders, acoustic tasks, and patient-reported outcome measures (PROMs) that are valuable across all cohorts. Moreover, tasks used to screen for certain diseases were included. For example, the GAD-7 questionnaire was included in PART A as it is a common screening tool for anxiety. Therefore, a patient with a voice disorder doing the \u201cvoice disorder protocol\u201d would still be screened for anxiety with the GAD-7 which could become a confounder in the analysis. A \u201cPart B\u201d was then developed with more specific questions or tasks that are particular to a disease cohort. For example, the \u201cPart B\u201d of the neurological disorder includes more in-depth neurological assessments.\\n\\n2.4. Validation of the protocols for Standards, Ethics, Clinical expertise, Tools and PEDP\\n\\nOnce the draft \u201cPart A \u2013 Across all cohort\u201d and \u201cPart B \u2013 Cohort Specific\u201d protocols were developed, each section was reviewed by a group of eight experts during 3 different three-hour review sessions. Reviewers included clinical experts, bioethicists, standards experts, diversity experts, and software developers. Each question of the protocol was reviewed and amended based on the following determinations:\\n\\n\u25cf Standards experts assessed if standard version of the question was available (e.g., how to ask for gender, or socio-economic status based on Canadian and US Standards).\\n\\n\u25cf Ethics experts assessed if there were any ethical issues with the question (e.g., some questions about health history were asked before consent which was deemed unethical and had to be moved to after the consent section).\\n\\n\u25cf DEI experts assessed if diversity and inclusion was well represented in each question (e.g., some questions about disabilities were altered to focus on accessibility instead of disability status which was deemed to be discriminatory).\\n\\n\u25cf Tools experts assessed how software development and technology could automate or facilitate data collection.\\n\\n\u25cf Clinical experts assessed the clinical significance and validity of each task and rated them in order of clinical importance.\\n\\n3. Results\\n\\nProtocols for data acquisition were harmonized across the 4 adult cohorts and a final protocol containing \u201cPART A \u2013 across all cohorts\u201d and \u201cPART B \u2013 Cohort Specific\u201d was created. Feasibility studies were conducted to assess feasibility metrics such as time of completion, understandability of tasks, task complexity, and need for assistance, and will be described in a separate manuscript. Overall, the mean protocol completion rate ranged between 45 and 75 minutes depending on the disease cohort, age of participant, and cognitive function. The complete protocols include 51 demographic questions, 92 confounder questions, 22 acoustic tasks, and 12 PROs and validated questionnaires. Full protocols will be available in the REDCap Instrument Shared Library and are also available for download on our GitHub repository https://github.com/eipm/bridge2ai-redcap.\\n\\n3.1 Development of protocols for the \u201cControl Cohort\u201d\\n\\nAfter an extensive literature review on what represents a control cohort in voice and speech science, our group decided to avoid the term \u201cnormal voice and speech\u201d when describing the control cohort but rather describe it as individuals that did not have any of the diseases studied in the \u201cdisease cohorts\u201d. This decision was made to avoid overfitting and optimize the generalizability and scalability of potential machine learning models trained on the datasets produced by these protocols. The control cohort protocol consisted of 1 of the protocols of the disease cohorts paired with a \u201ccontrol cohort\u201d clinical validation section (see Annex 6).\"}"}
{"id": "rameau24_interspeech", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Here, we have described the Bridge2AI-Voice protocols, a funded multi-institutional and multidisciplinary effort towards standardizing voice, speech, and respiratory sounds data collection protocols for broad applications within clinical science. The Bridge2AI Voice Consortium is funded by the NIH's Common fund, Grant Number: OT2-OD032720-01S1 and OT2-OD032720-01.\\n\\nOur data collection protocol is the foundation of this endeavor is paramount for voice biomarkers to be validated for disease monitoring, and establish a framework for different disease categories, with miniatures that are adaptable to the protocols for data acquisition in the wild with remote consent and no researcher involvement. The inclusion of a common trunk of data acquisition transcending continues to grow. This unique feature of our data collection protocol is the overcoming of limitations from ethical, scientific, and technical perspectives.\\n\\nAdvocating for voice/speech and respiratory sounds biomarker adoption of ethical principles, and technical meticulousness makes our approach unique. We strongly believe that transparency, continuous feedback, and collaboration with data governance and computing. From an acoustics standpoint, our team has pushed forth a low-cost solution that is adaptable to the protocols for data acquisition in the wild with remote consent and no researcher involvement. The inclusion of a common trunk of data acquisition transcending continues to grow.\\n\\nFor too long, voice/speech and respiratory sounds biomarker data has been named in the authorship line. To date, the consent has undergone several rounds of revision. We are also exploiting several models of participatory approaches to recruiting populations to hardware specification, the lack of incorporation of patient perspective, consent, and midstream feedback. To date, the consent has undergone several rounds of revision. We are also exploiting several models of participatory approaches to recruiting populations to hardware specification, the lack of incorporation of patient perspective, consent, and midstream feedback.\\n\\nAny solution that is forthcoming is the recognition and is honored in the formulation and continuous improvement of data protocols. For instance, this connected data has been primordial, and our early efforts in integrating this connected data have been named in the authorship line. We believe this is a significant contribution to the field of voice AI biomarkers.\\n\\nThe Bridge2AI-Voice project in its early feasibility work through early mobile app development has provided a pathway for establishing reusable standards for voice AI biomarkers. This work has been accomplished through iterative revisions, as crystallized in our protocol standards for voice AI biomarkers can only be widely available, and we welcome feedback for continuous improvement.\\n\\nIn the spirit of the Open Science Framework, we have shared our protocols widely with the scientific community, in the spirit of the Open Science Framework, we have shared our protocols widely with the scientific community. Following the Open Science Framework, we have shared our protocols widely with the scientific community. We are also exploiting several models of participatory approaches to recruiting populations to hardware specification, the lack of incorporation of patient perspective, consent, and midstream feedback. To date, the consent has undergone several rounds of revision. We are also exploiting several models of participatory approaches to recruiting populations to hardware specification, the lack of incorporation of patient perspective, consent, and midstream feedback.\"}"}
