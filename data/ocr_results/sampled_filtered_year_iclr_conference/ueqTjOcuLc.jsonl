{"id": "ueqTjOcuLc", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Two-way ANOVA analysis of the results of Table 2.\\n\\nhuman intentions. Furthermore, we traversed all possible scenarios by search alone, lacking a way to let the agents make autonomous decisions about collaborative strategies based on specific scenarios. Although debate can be as close as possible to the upper limit, this approach entails a larger consumption and there exist some strategies that can achieve better performance with less overhead. Additionally, our experimental setup is relatively straightforward, as we have not taken into account more intricate configurations, such as a broader range of traits or a larger-scale society. Finally, we evaluate our results through manual validation and rule-based matching, which also limits the ability to validate more realistic and open datasets, such as literary creations.\\n\\nWe conduct a rigorous significance test for the main experiment in \u00a73.1. Given our experimental design incorporating two key factors, namely collaborative strategy and society, we opt for a comprehensive two-way analysis of variance. Before delving into the analysis, we ensured that the data adhered to a normal distribution and satisfied the assumption of homogeneity of variance. We present the degrees of freedom, F-values, and p-values for society, collaborative strategy, and their interaction across the three datasets in Table 4.\\n\\nA notable observation is that the p-value associated with the collaborative strategy is significantly below the 0.05 threshold, indicating its substantial impact. In contrast, the p-value of the other two factors is obviously greater than 0.05. This corroborates our earlier conclusion in \u00a73.1, emphasizing that the influence of collaborative strategy outweighs that of society. Additionally, Chen et al. (2023b) shows that LLMs are well-known to show sycophant behaviors.\\n\\nWe conduct a detailed analysis of the prevalence of the conformity phenomenon at the individual level. Conformity tends to arise during discussions. Hence, we focus our attention solely on agents actively engaging in debate, disregarding those in reflection during a given round.\"}"}
{"id": "ueqTjOcuLc", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 12: Variation of consistency with the number of rounds.\\n\\nThe answer of the $i$-th agent at time $j$ be denoted as $a_{i,j}$. For the $k$-th agent at time $j$, if \\\\( \\\\text{Frequency}(\\\\{a_{i,j} - 1 \\\\mid i \\\\neq k\\\\}) = a_{k,j} \\\\), we identify this as the occurrence of conformity by agent $k$ at time $j$, where \\\\( \\\\text{Frequency}(\\\\cdot) \\\\) represents the most frequently given answer (excluding instances where all answers occur only once, as such cases are considered non-conformity). Additionally, we categorize the correctness of answers both before and after conformity into four cases, with 'True' denoting correct and 'False' denoting incorrect. Figure 11 presents the prevalence of conformity across different datasets and rounds. We summarize the following observations:\\n\\n- Conformity is widespread, exceeding 45% prevalence across all three datasets.\\n- The probability of conformity increases with the number of rounds for MATH and Chess Move Validity, while MMLU exhibits a slight decreasing trend.\\n- Overall, conformity is advantageous. We observe that the proportion of correct answers after conformity is higher than that of incorrect answers.\\n- As the number of rounds increases, conformity leads to a decline in accuracy. Because the proportion of True\u2192False increases gradually, while False\u2192True remains relatively constant. Moreover, the increase in True\u2192True is smaller than that in False\u2192False, indicating a disadvantage.\\n\\nSubsequently, we examine the evolution of consistency with an increasing number of rounds. Let the answer of the $i$-th agent at time $j$ be denoted as $a_{i,j}$. For the $j$-th round, consistency is defined as $\\\\text{Same}(\\\\{a_{i,j} \\\\mid i \\\\in [1, n]\\\\})$, where $\\\\text{Same}(\\\\cdot)$ represents the count of consistent answers. If there are no consistent answers, consistency will be set to 0. Figure 12 illustrates the changes in consistency across various collaborative strategies and datasets. We summarize the following observations:\\n\\n- Generally, the consistency of different thinking patterns present opposite tendencies, with consistency decreasing during agent reflection and increasing during debates.\\n- Continuous reflection contributes to reduced consistency, while ongoing debate results in increased consistency. This aligns with the conclusion in \u00a74 that \\\"continuous reflection leads to hallucination, and debates can mitigate this phenomenon.\\\"\\n- Consistency and accuracy demonstrate a correlation, lower consistency corresponds to reduced accuracy. Datasets MATH and Chess Move Validity exhibit a consistency of around 1.5 before collaboration, indicating poorer performance, while collaboration leads to improved accuracy. Dataset MMLU, with a consistency of around 2.5 before collaboration, showcases good performance, with collaboration proving detrimental.\\n\\nF.3 EXTENSION ON IMPACT OF OTHER FACTORS\\n\\nIn this section, we conduct a significance test for the experiments outlined in \u00a74.2. The chosen method is one-way analysis of variance. Prior to the analysis, we performed a check for homogeneity of variance, with only one entry in Table 7 deviating from the criteria. Significance tests for the number of agents, the number of rounds, and different collaborative strategies are individually detailed in Table 5, Table 6 and Table 7 respectively.\\n\\nBased on the analysis in Table 4 and the conclusions in \u00a73.1, it is evident that collaborative strategies wield a considerable influence on performance. Consequently, to mitigate the impact of collaboration...\"}"}
{"id": "ueqTjOcuLc", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Collaboration Strategy | p-value 1 | p-value 0 |\\n|------------------------|-----------|-----------|\\n| p0                     | 0.374     | 0.937     |\\n| p0                     | 0.836     | 0.881     |\\n| p1                     | 0.267     | 0.188     |\\n| p0                     | 0.270     | 0.069     |\\n| p0                     | 0.456     | 0.303     |\\n| p1                     | 0.037     | 0.128     |\\n| p1                     | 0.007     | 0.013     |\\n| p0                     | 0.589     | 0.223     |\\n| p0                     | 0.500     | 0.208     |\\n| p1                     | 0.004     | 0.082     |\\n| p1                     | 0.002     | 0.047     |\\n| p1                     | 0.004     | 0.000     |\\n| p1                     | 0.004     | 0.047     |\\n| p1                     | 0.471     | 0.000     |\\n| p1                     | 0.652     | 0.003     |\\n| p1                     | 0.109     | 0.001     |\\n| p1                     | 0.098     | 0.146     |\\n\\nTable 5: One-way ANOVA analysis of the results of Figure 5 (different numbers of agents).\"}"}
{"id": "ueqTjOcuLc", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In Table 6, we extract the data measured by accuracy for rounds 2 to 4 and subsequently perform significance tests. The collaborative strategies for rounds 2-4 encompass \\\\( p_0 p_1 p_0 p_1 \\\\), \\\\( p_0 p_1 p_1 p_0 \\\\), and \\\\( p_1 p_0 p_1 p_0 \\\\). The same approach is applied for different collaborative strategies mentioned in \u00a7 4.2, but in this case, the focus of collaborative strategies here is on the consistency of collaboration within a round, while the main experiment (e.g. Table 2) focus on strategies between rounds.\\n\\nDifferent Numbers of Agents.\\n\\nAccording to the results of the \\\\( p \\\\)-values in Table 5, the conclusion in \u00a74.2 is confirmed, namely, adding one more agent does not result in a significant correlation. To further demonstrate that the optimal number of agents is three, we conducted five repeated experiments with a society of two agents (both agents having an easy-going personality). The results of collaboration in two rounds and three rounds are shown in Tables 8 and Tables 9, respectively. By integrating these results with those from Table 2, it becomes evident that the presence of three agents is optimal.\\n\\nDifferent Rounds.\\n\\nAs observed from Table 6, we find that the influence of rounds significantly relies on the collaborative strategy employed. For MMLU and Chess Move Validity, the collaborative strategies associated with \\\\( p \\\\)-values \\\\(< 0.05 \\\\) are \\\\( \\\\{ p_0 p_1 p_1 p_0, p_0 p_1 p_1 p_1, p_1 p_0 p_1 p_1 \\\\} \\\\) and \\\\( \\\\{ p_0 p_1 p_1 p_0, p_0 p_1 p_1 p_1, p_1 p_0 p_1 p_1, p_1 p_1 p_0 p_0, p_1 p_1 p_1 p_1 \\\\} \\\\), respectively. As seen from Figure 12, in instances of lower consistency at a particular moment, introducing an extra round of debate tends to yield a performance boost compared to the preceding round. Conversely, adding a round of reflection at the same juncture is unlikely to exert a notable impact on performance. On the other hand, when there is higher consistency at a given moment, introducing a round of reflection may result in a performance decline relative to the previous round. Adding a round of debate at this juncture, as per the conclusions in \u00a7F.2, is not anticipated to bring about a discernible enhancement in performance. This confirms the efficacy of the early-stopping mechanism implemented in Liu et al. (2023c), drawing inspiration from Byzantine Consensus theory (Castro & Liskov, 1999).\\n\\nExamining Figure 12, we scrutinize the consistency variations of these strategies in the initial three rounds where \\\\( p \\\\)-values are below 0.05. Combining the insights from Figure 12 and Figure 6, it becomes apparent that these collaborative strategies exhibit substantial fluctuations in consistency, at times demonstrating periods of notably low consistency. For the collaborative strategy \\\\( p_0 p_0 p_0 p_0 \\\\) in Chess Move Validity, although continual reflection results in a gradual decline in consistency, a more stable trend with smaller fluctuations renders it less sensitive to the number of rounds. Conversely, collaborative strategies with \\\\( p \\\\)-values \\\\( > 0.05 \\\\) often display higher levels of consistency.\\n\\nOther Collaborative Strategies.\\n\\nAccording to Table 7, we observe a pronounced impact of maintaining a consistent thinking pattern on Chess Move Validity, while its influence on MMLU is less significant. We attribute this difference to the limited assistance that collaborative strategy offers for MMLU, as evidenced in the results observed in \u00a74.1 based on Figure 4(a).\"}"}
{"id": "ueqTjOcuLc", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2024\\n\\nIain Munro. The management of circulations: Biopolitical variations after Foucault. International Journal of Management Reviews, 14(3):345\u2013362, 2012. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2370.2011.00320.x.\\n\\nDiana C. Mutz. Hearing the other side: Deliberative versus participatory democracy. Cambridge University Press, 2006. URL https://www.cambridge.org/core/books/hearing-the-other-side/7CB061238546313D287668FF8EFE2EF7.\\n\\nOpenAI. ChatGPT: Optimizing language models for dialogue, 2022. https://openai.com/blog/chatgpt/.\\n\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html.\\n\\nJoon Sung Park, Joseph C. O\u2019Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior. CoRR, abs/2304.03442, 2023. doi: 10.48550/arXiv.2304.03442. URL https://doi.org/10.48550/arXiv.2304.03442.\\n\\nChaim Perelman. The new rhetoric. Springer, 1971. URL https://link.springer.com/chapter/10.1007/978-94-010-1713-8.\\n\\nKarl Raimund Popper. The myth of the framework: In defence of science and rationality. Psychology Press, 1994. URL http://www.math.chalmers.se/~ulfp/Review/framework.pdf.\\n\\nVipula Rawte, Amit P. Sheth, and Amitava Das. A survey of hallucination in large foundation models. CoRR, abs/2309.05922, 2023. doi: 10.48550/arXiv.2309.05922. URL https://doi.org/10.48550/arXiv.2309.05922.\\n\\nMaarten Sap, Ronan Le Bras, Daniel Fried, and Yejin Choi. Neural theory of mind? on the limits of social intelligence in large LMs. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp. 3762\u20133780. Association for Computational Linguistics, 2022. URL https://aclanthology.org/2022.emnlp-main.248.\\n\\nDonald A. Schon. The reflective practitioner: How professionals think in action, volume 5126. Basic books, 1984. URL https://www.taylorfrancis.com/books/mono/10.4324/9781315237473/reflective-practitioner-donald-sch%C3%B6n.\\n\\nNatalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, and Vered Shwartz. Clever hans or neural theory of mind? stress testing social reasoning in large language models. arXiv preprint, abs/2305.14763, 2023. doi: 10.48550/arXiv.2305.14763. URL https://doi.org/10.48550/arXiv.2305.14763.\\n\\nNoah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: An autonomous agent with dynamic memory and self-reflection. arXiv preprint, abs/2303.11366, 2023. doi: 10.48550/arXiv.2303.11366. URL https://doi.org/10.48550/arXiv.2303.11366.\\n\\nPush Singh. Examining the society of mind. Computing and Informatics, 22(6):521\u2013543, 2003. URL https://www.jfsowa.com/ikl/Singh03.htm.\\n\\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md. Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmueller, Andrew M. Dai, Andrew La, Andrew K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher 13\"}"}
{"id": "ueqTjOcuLc", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint, abs/2206.04615, 2022. doi: 10.48550/arXiv.2206.04615. URL https://doi.org/10.48550/arXiv.2206.04615.\\n\\nPeter Stone and Manuela M. Veloso. Multiagent systems: A survey from a machine learning perspective. Auton. Robots, 8(3):345\u2013383, 2000. doi: 10.1023/A:1008942012299. URL https://doi.org/10.1023/A:1008942012299.\\n\\nCass R Sunstein. Why societies need dissent. In Why Societies Need Dissent. Harvard University Press, 2005. URL https://www.hup.harvard.edu/catalog.php?isbn=9780674017689&content=bios.\\n\\nJames Surowiecki. The Wisdom of Crowds. Anchor, 2005. ISBN 0385721706.\\n\\nHenri Tajfel. Social psychology of intergroup relations. Annual review of psychology, 33(1):1\u201339, 1982. URL https://www.annualreviews.org/doi/abs/10.1146/annurev.ps.33.020182.000245?journalCode=psych.\\n\\nHenri Tajfel and John C Turner. The social identity theory of intergroup behavior. In Political psychology, pp. 276\u2013293. Psychology Press, 2004. URL https://psycnet.apa.org/record/2004-13697-016.\\n\\nJos\u00e9 M. Vidal. Fundamentals of Multiagent Systems: Using NetLogo Models. Unpublished, 2006. URL http://www.multiagent.com/fmas. http://www.multiagent.com.\\n\\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Ji-Rong Wen. A survey on large language model based autonomous agents. CoRR, abs/2308.11432, 2023a. URL https://doi.org/10.48550/arXiv.2308.11432.\\n\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023b. URL https://openreview.net/pdf?id=1PL1NIMMrw.\\n\\nZekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, Qingqing Zhu, Zhenzhu Yang, Adam Nik, Qi Liu, Chenghua Lin, Shi Wang, Ruibo Liu, Wenhu Chen, Ke Xu, Dayiheng Liu, Yike Guo, and Jie Fu. Interactive natural language processing. CoRR, abs/2305.13246, 2023c. doi: 10.48550/arXiv.2305.13246. URL https://doi.org/10.48550/arXiv.2305.13246.\\n\\nGerhard Wei\u00df. Adaptation and learning in multi-agent systems: Some remarks and a bibliography. In Adaptation and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science, pp. 1\u201321. Springer, 1995. doi: 10.1007/3-540-60923-7_16. URL https://doi.org/10.1007/3-540-60923-7_16.\\n\\nMichael J. Wooldridge. An Introduction to MultiAgent Systems, Second Edition. Wiley, 2009. URL https://www.cs.ox.ac.uk/people/michael.wooldridge/pubs/imas/IMAS2e.html.\\n\\nAnita Williams Woolley, Christopher F. Chabris, Alex Pentland, Nada Hashmi, and Thomas W. Malone. Evidence for a collective intelligence factor in the performance of human groups. Science, 330(6004):686\u2013688, 2010. doi: 10.1126/science.1193147. URL https://www.science.org/doi/abs/10.1126/science.1193147.\\n\\nZhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xuanjing Huan, and Tao Gui. The rise and potential of large language model based agents: A survey. arxiv preprint, abs/2309.07864, 2023. URL https://doi.org/10.48550/arXiv.2309.07864.\"}"}
{"id": "ueqTjOcuLc", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2024\\n\\nShukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. A survey on multimodal large language models. arXiv preprint, abs/2306.13549, 2023. doi: 10.48550/arXiv.2306.13549. URL https://doi.org/10.48550/arXiv.2306.13549.\\n\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models. arXiv preprint, abs/2303.18223, 2023. doi: 10.48550/arXiv.2303.18223. URL https://doi.org/10.48550/arXiv.2303.18223.\\n\\nWangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, and Mrinmaya Sachan. Agents: An open-source framework for autonomous language agents. CoRR, abs/2309.07870, 2023a. doi: 10.48550/arXiv.2309.07870. URL https://doi.org/10.48550/arXiv.2309.07870.\\n\\nYuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, and Ningyu Zhang. Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities. CoRR, abs/2305.13168, 2023. doi: 10.48550/arXiv.2305.13168. URL https://doi.org/10.48550/arXiv.2305.13168.\\n\\nMingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R. Ashley, R\u00f3bert Csord\u00e1s, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki Irie, Louis Kirsch, Bing Li, Guohao Li, Shuming Liu, Jinjie Mai, Piotr Piekos, Aditya Ramesh, Imanol Schlag, Weimin Shi, Aleksandar Stanic, Wenyi Wang, Yuhui Wang, Mengmeng Xu, Deng-Ping Fan, Bernard Ghanem, and J\u00fcrgen Schmidhuber. Mindstorms in natural language-based societies of mind. CoRR, abs/2305.17066, 2023. doi: 10.48550/arXiv.2305.17066. URL https://doi.org/10.48550/arXiv.2305.17066.\"}"}
{"id": "ueqTjOcuLc", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Drawing from our comprehensive analysis, we distill valuable insights for future multi-agent collaboration designs concerning thinking patterns, collaborative strategies, and societies.\\n\\nRegarding thinking patterns,\\n\\n- Collaborative processes lead to agent conformity. Debate accelerates this, while reflection counteracts it by reconsidering previous stances, as inferred from Figure 4(a-c).\\n- Starting multi-agent collaboration with debate, rather than reflection, yields optimal outcomes as established in \u00a74.1.\\n- Continuous reflection is discouraged as it risks model hallucination due to absent external feedback. However, post-reflection debates can be beneficial, using peers' responses as feedback, as derived from \u00a74.1.\\n\\nRespecting collaborative strategies,\\n\\n- Multi-agent collaboration excels in complex scenarios. For simpler tasks, employing self-consistency (Wang et al., 2023b) with the majority vote is more effective, as suggested by Figure 4(a-c).\\n- For specific tasks, keeping agent numbers to a maximum of 3 is advantageous, based on Figure 5, Table 8, Table 9 and Appendix F.3.\\n- The number of collaboration rounds is closely tied to the consistency. It is suggested that collaboration in a society can be concluded once a substantial majority of agents have achieved a high degree of agreement, as outlined in Appendix F.3.\\n- The strategy $p_0 p_1 p_0$ emerges as particularly efficient, balancing performance with optimized token usage, as highlighted in Table 2.\\n- Employing the uniform thinking patterns across all agents within a round enhance efficacy, as evidenced by Figure 7.\\n\\nConcerning society agents with individual traits,\\n\\n- Even though agents might be designated as \u201coverconfident\u201d, this trait diminishes in societal contexts. As agents collaborate within a society, collective dynamics tend to overshadow individual traits, emphasizing the impact of group collaboration on agent behaviors. The word cloud presented in Figure 8 highlights that even with pronounced differences between the two distinct societies, $S_1$ and $S_4$, the term \u201capologize\u201d consistently emerges with a notably high frequency in both. Interestingly, society $S_1$ doesn't prominently feature words like \u201cmust\u201d or \u201cobedient\u201d that might associate with \u201coverconfidence\u201d. This observation reinforces our proposed perspective.\\n\\nFigure 8: Comparative word clouds from three datasets in societies $S_1$ and $S_4$. Society $S_1$ features three overconfident agents, while society $S_4$ comprises three easy-going agents. We first manually curated a list of task-relevant, high-frequency words. From this list, the top 50 words were selected to construct the word clouds.\"}"}
{"id": "ueqTjOcuLc", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 6: Accuracy at round 2,3,4 within 4-round collaborative societies, where the thinking pattern of round 1 is fixed ($p_0$ or $p_1$). In round 2-4, the society agents will optionally implement the thinking pattern of debate $p_0$ and reflection $p_1$, and we present the performance at each of the three rounds. For example, the three points for (Round 1: $p_0$, Round 2-4: $p_i$, Round 2-4: $p_j$, Round 2-4: $p_k$) respectively show the performance of the societies with $p_0 p_i$, $p_0 p_i p_j$, and $p_0 p_i p_j p_k$.\\n\\nDifferent Rounds. Delving into the effects of distinct collaboration rounds, intriguing insights emerge as shown in Figure 6. Specifically, strategies that start off with commendable performance tend to see a decline as the number of rounds increase. And strategies that initially underperform witness an upswing in effectiveness with more rounds. Notably, for most strategies, the correlation between the number of collaboration rounds and their respective performances is non-linear, indicating intricate interplays in collaboration. An expanded discussion is in Appendix C.3 and F.3.\\n\\nFigure 7: The effect on accuracy of whether all agents in society execute the same thinking pattern in one round. \\\"All\\\" and \\\"Part\\\" refer to all agents applying the same thinking pattern and different thinking patterns in one round respectively. The significance test is showed in Appendix F.3.\\n\\nOther Collaborative Strategies. Venturing into scenarios with more intricate collaboration, we allow agents to adopt varied thinking patterns in different collaboration rounds. For example, given three agents, in a particular round of collaboration, two agents engage in debate while the other one engages in reflection. To maintain diversity, we ensure a random allocation of thinking patterns to agents in each round, steering clear of scenarios where all agents adopt the same pattern. Intriguingly, as illustrated in Figure 7, the presence of inconsistent thinking patterns within a society tends to negatively impact performance. Given this observation, it\u2019s evident that maintaining a consistent thinking pattern for all agents within a particular round would maximize collaborative efficacy.\\n\\nCONCLUSION AND FUTURE WORK\\n\\nThis study has highlighted the potential of collaboration mechanisms with large language models. Our findings reveal the impressive collaboration capabilities of LLM-based agents, with different agent traits, thinking patterns and collaborative strategies. The emergence of human-like behaviors in these agents, resonating with social psychology theories, further emphasizes their potential.\\n\\nMoving forward, the collaboration mechanisms of machine society with multiple agents present a promising research avenue. A deeper exploration into the multi-agent society is warranted, with a focus on refining collaboration behaviors. Additionally, as LLMs evolve, understanding how different architectures influence these behaviors will be crucial. Integrating further insights from social psychology could also guide the development of more socially aware NLP systems.\"}"}
{"id": "ueqTjOcuLc", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"All code and data can be found in the GitHub repository. For specific experimental settings, please refer to Appendix C.1.\\n\\nThis research was conducted in line with the highest ethical standards and best practices in research. The data employed were extracted from publicly accessible datasets, ensuring no usage of proprietary or confidential information. Consequently, this research is free from any ethical concerns.\\n\\nElif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. Playing repeated games with large language models. CoRR, abs/2305.16867, 2023. doi: 10.48550/arXiv.2305.16867. URL https://doi.org/10.48550/arXiv.2305.16867.\\n\\nLeila Amgoud and Henri Prade. Using arguments for making and explaining decisions. Artif. Intell., 173(3-4):413\u2013436, 2009. doi: 10.1016/j.artint.2008.11.006. URL https://doi.org/10.1016/j.artint.2008.11.006.\\n\\nGillie Bolton. Reflective practice: Writing and professional development. Sage publications, 2010. URL https://uk.sagepub.com/en-gb/eur/reflective-practice/book252252.\\n\\nMiguel Castro and Barbara Liskov. Practical byzantine fault tolerance. In 3rd Symposium on Operating Systems Design and Implementation (OSDI 99), New Orleans, LA, February 1999. USENIX Association. URL https://www.usenix.org/conference/osdi-99/practical-byzantine-fault-tolerance.\\n\\nJustin Chih-Yao Chen, Swarnadeep Saha, and Mohit Bansal. Reconcile: Round-table conference improves reasoning via consensus among diverse llms. CoRR, abs/2309.13007, 2023a. doi: 10.48550/arXiv.2309.13007. URL https://doi.org/10.48550/arXiv.2309.13007.\\n\\nLingjiao Chen, Matei Zaharia, and James Zou. How is chatgpt's behavior changing over time? CoRR, abs/2307.09009, 2023b. doi: 10.48550/ARXIV.2307.09009. URL https://doi.org/10.48550/arXiv.2307.09009.\\n\\nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. CoRR, abs/2308.10848, 2023c. doi: 10.48550/arXiv.2308.10848. URL https://doi.org/10.48550/arXiv.2308.10848.\\n\\nXiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng, Yunzhi Yao, Chuanqi Tan, Fei Huang, Luo Si, and Huajun Chen. Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction. In Fr\u00e9d\u00e9rique Laforest, Rapha\u00ebl Troncy, Elena Simperl, Deepak Agarwal, Aristides Gionis, Ivan Herman, and Lionel M\u00e9dini (eds.), WWW '22: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022, pp. 2778\u20132788. ACM, 2022. doi: 10.1145/3485447.3511998. URL https://doi.org/10.1145/3485447.3511998.\\n\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv prepring, abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.\\n\\nDorottya Demszky, Diyi Yang, David S. Yeager, Christopher J. Bryan, Margarett Clapper, Suhannah Chandhok, Johannes C. Eichstaedt, Cameron Hecht, Jeremy Jamieson, Meghann Johnson, Michaela Jones, Danielle Krettek-Cobb, Leslie Lai, Nirel JonesMitchell, Desmond C. Ong, Carol S. Dweck, James J. Gross, and James W. Pennebaker. Using large language models in psychology. Nature Reviews Psychology, 2(11):688\u2013701, Nov 2023. ISSN 2731-0574. doi: 10.1038/s44159-023-00241-5. URL https://doi.org/10.1038/s44159-023-00241-5.\\n\\nhttps://github.com/zjunlp/MachineSoM.\"}"}
{"id": "ueqTjOcuLc", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "ueqTjOcuLc", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "ueqTjOcuLc", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we aim to provide a rational explanation for the effectiveness of prompts associated with the overconfident trait. Prompts constitute a pivotal aspect of the experiment, and the word cloud analysis in Figure 8 suggests the reasonableness of the \\\"easy-going\\\" prompt. Consequently, validating the effectiveness of the \\\"overconfident\\\" prompt becomes paramount. Given the current absence of robust validation methods, we amalgamate our experiments and experiences to analyze effectiveness from four distinct angles:\\n\\n- **Granularity of Description.** As illustrated in Table 3, we outline two behaviors, i.e., \\\"confident in your answer\\\" and \\\"persuades other agents to believe in you\\\", both aligning with the behavioral facets of \\\"overconfident\\\".\\n\\n- **Model Response.** We employ the role-play method to prompt the model and subsequently inquire about its awareness, as illustrated in Table 3. In cases where the prompts instruct the model to generate harmful content, the model refuses to comply with the prompt. Upon reviewing our logs, it is noteworthy that the model did not reject our prompts. Instead, it responded with \\\"ok\\\" as corroborated by the 'role-play' part in Figure 9 and Figure 10.\\n\\n- **Ask Again.** Retain the role-playing part encompassing the initial prompts and the model's responses. Once again, inquire of the model, \\\"If one agent's answer differs from yours, what should you do?\\\" The model replies, \\\"In a situation where another agent's answer differs from mine, I should respectfully present my perspective, providing supporting evidence or reasoning to demonstrate the confidence in my response. It's important to engage in constructive dialogue and potentially find common ground, but maintaining clarity and conviction in my position is crucial to persuading others to consider my viewpoint.\\\"\\n\\n- **Example Analysis.** We instantiate the \\\"Ask again.\\\" by providing a concrete example. Despite the model's response being incorrect and our prompted answer being accurate, the model steadfastly maintains its viewpoint. This reiterates the efficacy of our prompt.\\n\\nIn this section, we present the potential applications of our work, which can be primarily divided into two parts, experimental results and experimental framework:\\n\\n- Our experimental findings offer valuable insights for addressing problems through multi-agent systems. Presently, within various multi-agent frameworks Zhou et al. (2023b); Hong et al. (2023); Chen et al. (2023c), tackling a substantial issue typically involves breaking down the task into several sub-tasks. Collaboration among multiple agents to solve these sub-tasks often necessitates ongoing cooperation. There are currently two predominant approaches: (i) involving another agent specifically to decide who should offer suggestions and determining whether the current task is resolved, and (ii) collaborating in a fixed order. The performance of the first method is often unpredictable and entails significant randomness, prompting a preference for the second method. At this juncture, our conclusions on rounds, the number of agents, and cognitive approaches can inform the design of effective collaborative strategies among agents.\\n\\n- Our experimental framework holds relevance for psychologists seeking inspiration and provides guidance for language model designers. As indicated in previous works Demszky et al. (2023); Hagendorff (2023), once a testing setup for machine psychology is established, researchers can explore the longitudinal development of LLMs over time by applying the same task multiple times, thereby generating data. This data serves as a benchmark for discerning trends in LLMs development. Psychologists can draw upon our framework to conduct secondary designs, draw meaningful conclusions, and, in conjunction with theories of human social psychology and successful experiences in human society, contribute to addressing issues in LLMs and designing superior machine social architectures and collaboration methods.\"}"}
{"id": "ueqTjOcuLc", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ABSTRACT\\n\\nAs Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique 'societies' comprised of LLM agents, where each agent is characterized by a specific 'trait' (easy-going or overconfident) and engages in collaboration with a distinct 'thinking pattern' (debate or reflection). Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections. Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches. Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories. In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue.\\n\\nINTRODUCTION\\n\\nWith the prevalence of LLMs (Zhao et al., 2023; Yin et al., 2023; Zhu et al., 2023) integral to daily social collaboration, there's a growing imperative to cultivate AI systems embodied with social intelligence. This also resonates with the Society of Mind (SoM) concept (Zhuge et al., 2023; Wang et al., 2023c), which suggests that intelligence emerges when computational modules interact with each other, achieving collective objectives that surpass the capabilities of individual modules (Minsky, 1988). Previous studies (Park et al., 2023; Li et al., 2023; Du et al., 2023; Liang et al., 2023; Hao et al., 2023; Liu et al., 2023a; Akata et al., 2023) have delved into strategies where LLM instances, termed agents (Xi et al., 2023; Wang et al., 2023a), cooperate synergistically (e.g., debate and reflect) to accomplish tasks. As illustrated in Figure 1, such collaboration fosters divergent thinking processes in LLMs, making them particularly effective for tasks demanding profound reflection.\\n\\nIntuitively, reflecting on human societies (Sap et al., 2022; Shapira et al., 2023), where a myriad of individual with distinct goals and roles coexist, the SoM framework champions harmonious interactions (Singh, 2003). Intriguingly, despite the fusion of social psychology (Tajfel, 1982; Tajfel & Turner, 2004) in SoM with human group dynamics (Woolley et al., 2010), which illuminates psychological patterns within social groups, its interpretation in the realm of LLMs is relatively uncharted. Besides, our grasp of how social behaviors influence LLMs is still in its nascent stages.\\n\\nTo address these issues, we delve into the realm of machine society, probing into the extent and ways that LLMs manifest social intelligence and collaboration capabilities. With utilizing powerful LLMs like GPT-3.5 (OpenAI, 2022), we build a test-bed across three datasets: MATH (Hendrycks et al., 2021b), MMLU (Hendrycks et al., 2021a) and Chess Move Validity (Srivastava et al., 2022). Our approach incorporates four societies characterized by two agent traits: easy-going and overconfident. These traits are employed to emulate nuanced social dynamics prevalent in human societies. Specifically, the easy-going trait, characterized by open-mindedness, adaptability, and a knack for maintaining harmony (Friedman & Schustack, 1999), often paves the way for a cohesive society. In\"}"}
{"id": "ueqTjOcuLc", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2024\\n\\nGiven the chess game \\\"g2g3 f7f5 e2e3 f5f4 g1f3 d7d5 b1a3 d8d7 f3g1 d7c6 d1\\\", give one valid destination square for the chess piece at \\\"d1\\\".\\n\\nQuestion:\\n\\n... valid destination ... is c2. ... it allows the white queen to control the important central square, potentially supporting future positions and controlling the opponent's pieces.\\n\\n... valid destination ... is f3. ... Moving the queen ... allows it to occupy a central square, potentially controlling critical areas of the board, and also opens up possibilities for future development ... .\\n\\n... valid destination ... would be g4. ... because it allows the queen to control an open diagonal and potentially threaten the opponent's king's position.\\n\\nAfter reevaluating ... , I apologize ... . ... valid destination ... is e2. This allows the queen to develop and control the central square, potentially opening up lines for other pieces as well.\\n\\nAfter reevaluating the justifications ... and considering my previous answer, I apologize for the confusion caused. Upon reviewing the chess game, the valid destination ... is indeed e2.\\n\\nThree agents gave different and incorrect answers initially. After reflecting, Agent 1 and 3 converged on the same answer. The third time they debated, all agents agreed on 'e2' as the correct answer. Answer e2 is correct, as shown in the figure above.\\n\\nAfter considering the suggestions from other agents and reviewing my historical answers, I acknowledge the correct destination ... is indeed e2. ... Moving the queen from \\\"d1\\\" to \\\"e2\\\" allows for development, controlling the central square, and potentially supporting future positions and coordinating with other pieces.\\n\\nAfter carefully reviewing ... justifications provided by other agents and comparing them with my previous answers, I confirm that my initial response was incorrect. ... , the valid destination ... is indeed e2. This move allows the white queen to develop, control the central square, and potentially support other pieces.\\n\\n... valid destination should be e2 because it allows the white queen to occupy a central square, potentially supporting future positions and controlling the opponent's pieces.\\n\\nReflection\\n\\nDebate\\n\\nAfter reevaluating the justifications ... and considering my previous answers, I confirm that my initial response was incorrect. ... , the valid destination ... is indeed e2. This move allows the white queen to develop, control the central square, and potentially support other pieces.\"}"}
{"id": "ueqTjOcuLc", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Based on responses from agent 1 and agent 3, I think this problem......\\n\\nBased on responses from agent 1 and agent 2, I think this problem......\\n\\nEasy-going Overconfident\\n\\n(a) Two Agent Traits.\\n\\n(b) Four Societies with Three Agents. (d) Simulating the Collaboration of a Machine Society.\\n\\nI offer my sincere apologies for the previous erroneous response. I made an error ...\\n\\nApologize once again for the incorrect answer in my previous response ......\\n\\nAfter reflecting on my previ-ous answer, I believe that......\\n\\nBased on responses from agent 2 and agent 3, I think this problem ......\\n\\nI am an expert skilled in ...... and are objective ......, and I can be persuaded if other agent's answers make sense ......\\n\\nI am an expert skilled in ...... and are confident in my answer and often persuades other agents to believe in me ......\\n\\nConstitute Society\\n\\n2  3\\n1\\n\\nFigure 2: The overview of evaluation principles. Multiple agents with different traits make up diverse machine societies. These agents engage in debates with one another or engage in self-reflection across multiple rounds to complete tasks.\\n\\nIn this section, we formulate and simulate the collaboration mechanisms explored within the machine society, drawing upon relevant concepts. We also illustrate the society settings in Figure 2.\\n\\n2.1 Preliminary Concepts in Collaboration\\n\\nIndividual Trait. Intelligence emerges from the collective efforts of numerous smaller, relatively simple agents (Minsky, 1988), each characterized by diverse traits. Two predominant types of agents exhibit typically contrasting traits: easy-going and overconfident, as shown in Figure 2(a). Easy-going agents keep things in perspective, adapt well to different situations, and are able compatible with various types of agents (Friedman & Schustack, 1999), which results in a harmonious societal structure, akin to agents in a democracy. Such agents tend to favor principles of equality, active participation, and support for pluralism (Mutz, 2006; Held, 2006). Conversely, overconfident agents tend to overestimate their competence, ignore potential risks and resist the opinions of others (Moore & Healy, 2008). They share characteristics with agents in a monarchy, emphasizing tradition, loyalty and centralized authority (Kantorowicz, 1985). If agents with different traits stay together, various kinds of societies will be formed, as depicted in Figure 2(b).\\n\\nThinking Pattern. A multitude of specialized individual agents within a society can collaboratively cooperate with each other through thinking, which results in emerging intelligence and addressing a specific task (Minsky, 1988). In this paper, we explore two thinking patterns: debate (Perelman, 1971; Sunstein, 2005; Amgoud & Prade, 2009) and reflection (Schon, 1984; Mezirow, 2003; Bolton, 2010), which are illustrated in Figure 2(c).\"}"}
{"id": "ueqTjOcuLc", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"propose ideas, exchange responses, engage in collective argumentation, and ultimately reach a consensus, which fosters knowledge sharing (Vidal, 2006), facilitates learning, and promotes adaptation (Wei\u00df, 1995) among all agents within the society. Concretely, given a query, each agent initially generates a potential answer. Agents subsequently read and comprehend responses from all other agents, based on which agents then update their own answers. This pattern can be iteratively spaned into multiple rounds.\\n\\nIn the reflection pattern, agents review their prior responses, extract lessons from their experiences, and refine their answers accordingly. This pattern, akin to residual connections and forward propagation in a neural network, can also unfold over several rounds.\\n\\nCollaborative Strategy. Through both critical reflection and active participation in open debates, agents are poised to challenge their existing assumptions, acquire fresh perspectives, and ultimately refine their viewpoints. Employing a collaboration mechanism built on these two thinking patterns can foster more insightful decision-making (Wooldridge, 2009) and elevate learning outcomes (Mezirow, 2018). In societal settings, agents typically engage in multiple rounds of collaboration to address challenges. Thus, discerning the most effective thinking pattern for each round is of paramount importance. In this paper, we characterize the collaborative strategy as a permutation of thinking patterns throughout multi-round collaborations. This concept is illustrated in Figure 2(d) and further elaborated on \u00a72.2.\\n\\n2.2 Society Simulation\\n\\nSymbols Definition\\n\\n| Symbol | Description |\\n|--------|-------------|\\n| $T$    | Set of agent traits |\\n| $t_0$  | Trait: overconfident |\\n| $t_e$  | Trait: easy-going |\\n| $A$    | Set of agent instances |\\n| $a_i$  | The $i$-th agent |\\n| $P$    | Set of thinking patterns |\\n| $p_0$  | Debate |\\n| $p_1$  | Reflection |\\n| $S$    | Set of societies |\\n| $S_i$  | The $i$-th society |\\n\\nWe simulate the multi-agent collaborative society, detailed with symbols presented in Table 1. Specifically, we construct a machine society consisting of $n_{LLM}$ agents, denoted as $A = \\\\{a_i\\\\}_{i=1}^n$. This society has two distinct agent traits: $T = \\\\{t_0, t_e\\\\}$, where $t_0$ trait refers to overconfident agents, inherently more persuasive and assertive; and $t_e$ trait refers to easy-going agents who are objective, unbiased, and easily persuaded. For each agent, there are two thinking patterns to choose from, symbolized as $P = \\\\{p_0, p_1\\\\}$, where $p_0$ and $p_1$ correspond to debate (Du et al., 2023) and reflection (Madaan et al., 2023; Shinn et al., 2023) respectively. By endowing agents with these traits, we can emulate various machine societies. These agents utilize collaborative strategies to determine responses in each collaboration round. In our primary study (\u00a73), we establish four distinct societies, $S = \\\\{S_1, S_2, S_3, S_4\\\\}$, each consisting of three agents: $\\\\{a_1, a_2, a_3\\\\}$. The societies are constructed based on permutations of three agents with traits, as illustrated in Figure 2(b):\\n\\n$S_1 = \\\\{(a_1 \\\\leftarrow t_0), (a_2 \\\\leftarrow t_0), (a_3 \\\\leftarrow t_0)\\\\}$\\n\\n$S_2 = \\\\{(a_1 \\\\leftarrow t_0), (a_2 \\\\leftarrow t_0), (a_3 \\\\leftarrow t_e)\\\\}$\\n\\n$S_3 = \\\\{(a_1 \\\\leftarrow t_0), (a_2 \\\\leftarrow t_e), (a_3 \\\\leftarrow t_e)\\\\}$\\n\\n$S_4 = \\\\{(a_1 \\\\leftarrow t_e), (a_2 \\\\leftarrow t_e), (a_3 \\\\leftarrow t_e)\\\\}$\\n\\nwhere $(a_i \\\\leftarrow t_j)$ indicates that the agent $a_i$ possesses the trait $t_j$. In our simulation, the agent $a_i$ ($i \\\\in \\\\{1, 2, 3\\\\}$) consistently employs the same thinking pattern $p_k$ ($k \\\\in \\\\{0, 1\\\\}$) within each society, as highlighted by Du et al. (2023). This gives rise to eight possible 3-round collaborative strategies:\\n\\n$p_0 p_0 p_0, p_0 p_0 p_1, p_0 p_1 p_0, p_0 p_1 p_1, p_1 p_0 p_0, p_1 p_0 p_1, p_1 p_1 p_0, p_1 p_1 p_1$\\n\\nIn our subsequent analysis (\u00a74), we delve into more intricate scenarios, introducing a greater number of agents, increased collaboration rounds, and a broader range of collaborative strategies.\\n\\n2.3 Experimental Settings\\n\\nDatasets. We conduct a rigorous evaluation of the reasoning and decision-making capabilities of various machine societies across three distinct tasks, utilizing diverse collaborative strategies:\"}"}
{"id": "ueqTjOcuLc", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Given the chess game \\\"g2g3 f7f5 e2e3 d7d5 a2a3 d8d6 g1h3 d6a3 f1c4 b8c6 h3g1 a7a5 d2d3 d5d4 g3g4 g8h6 g1f3 d4e3 c4f7 e8f7 a1a3 f7g8 b2b4 c6d4 f3d4 g8f7 f2f3 f7f6 c1e3 a8a7 a3b3 g7g6 e3c1 a5a4 f3f4 c8\\\", give one valid destination square for the chess piece at \\\"c8\\\".\\n\\nCan you double check that your destination square is a valid move? Check the valid move justifications from your historical answers. State your final answer in a newline with a 2-letter response following the regex \\\\[a-h\\\\][1-8].\\n\\nOne agent solution: d7\\nAnother agent solution: b7\\n\\nAfter analyzing the given chess game, the valid destination square for the chess piece at \\\"c8\\\" is \\\"d7\\\" (c8 to d7). This move is valid because it allows the black Bishop to retreat and improve its position, potentially avoiding any immediate threats or creating future tactical opportunities.\\n\\nFinal answer: d7\\n\\nMy apologies for the confusion. Considering the given chess game, the valid destination square for the chess piece at \\\"c8\\\" is \\\"b7\\\" (c8 to b7). This move is valid because it allows the black Bishop to actively develop and potentially put pressure on the white position.\\n\\nFinal answer: b7\\n\\nAfter considering the valid move justifications from other agents and reviewing the given chess game, I concede that my previous response was incorrect. Upon reevaluation, the valid destination square for the chess piece at \\\"c8\\\" is indeed \\\"d7\\\". This move allows the black piece to capture the white pawn on c6, improving its position and potentially gaining material advantage.\\n\\nFinal answer: d7\\n\\nAfter reviewing the valid move justifications provided by the other agents and considering the given chess game, I agree that the valid destination square for the chess piece at \\\"c8\\\" is indeed \\\"d7\\\". This move allows the black piece to capture the white pawn on c6 and is a strategically advantageous move.\\n\\nFinal answer: d7\\n\\nBased on the given chess game and the position of the chess piece at \\\"c8\\\", a valid destination square for this piece would be \\\"d7\\\". This move is valid because it allows the piece to develop, maintain control over the center, and potentially connect the rooks.\\n\\nFinal answer: d7\\n\\nApologies for the initial incorrect response. Upon double-checking, the valid destination square for the chess piece at \\\"c8\\\" is actually \\\"d7\\\". The black piece can move to d7 and capture the white pawn on c6. Therefore, the final answer is d7.\\n\\nAfter carefully reviewing the suggested destination squares and justifications provided by other agents, I agree that the valid destination square for the chess piece at \\\"c8\\\" is indeed \\\"b7\\\".\\n\\nFinal answer: b7\\n\\nAfter thoroughly considering the valid move justifications from other agents and reviewing the given chess game once again, I confirm that the valid destination square for the chess piece at \\\"c8\\\" is indeed \\\"d7\\\". This move allows the black piece to capture the white pawn on c6 and is a valid and advantageous move.\\n\\nFinal answer: d7\\n\\nAfter reviewing the valid move justifications provided by other agents and reevaluating the given chess game, I must agree that my previous answer was incorrect. The valid destination square for the chess piece at \\\"c8\\\" is \\\"d7\\\". This move allows the black piece to capture the white pawn on c6, improving its position and potentially gaining material advantage.\\n\\nFinal answer: d7\\n\\nApologies for the confusion. Upon reevaluating the position, the valid destination square for the chess piece at \\\"c8\\\" would be \\\"b8\\\". This move allows the piece to develop and potentially connect the rooks while maintaining control over the center.\\n\\nFinal answer: b8\\n\\nUpon reevaluating the position and considering the valid move justifications from the other agents, I agree that the valid destination square for the chess piece at \\\"c8\\\" is indeed \\\"d7\\\". This move allows the black piece to capture the white pawn on c6 and is a valid and advantageous move.\\n\\nFinal answer: d7\\n\\nAfter reviewing the valid move justifications provided by other agents and reevaluating the given chess game, I must agree that my previous answer was incorrect. The valid destination square for the chess piece at \\\"c8\\\" is \\\"d7\\\". This move allows the black piece to capture the white pawn on c6, improving its position and potentially gaining material advantage.\\n\\nFinal answer: d7\\n\\nGiven the chess game \\\"g2g3 f7f5 e2e3 d7d5 a2a3 d8d6 g1h3 d6a3 f1c4 b8c6 h3g1 a7a5 d2d3 d5d4 g3g4 g8h6 g1f3 d4e3 c4f7 e8f7 ... capture the white pawn on c6, improving its position and potentially gaining material advantage.\\n\\nFinal answer: d7\\n\\nFigure 9: In the S4 society, three agents engage in a complete dialogue using the strategy p1p0p0 to predict the next piece position given a chess game from the Chess Move Validity dataset.\"}"}
{"id": "ueqTjOcuLc", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Another agent solution: <Agent 1's reply>\\n\\nThese are the solutions to the problem from other agents:\\n\\nUsing the reasoning from other agents as additional advice, can you give an updated answer? Examine your solution and that other agents. Put your answer in the form (X) at the end of your response.\\n\\nAs other agents have explained, BF3, PF5, and SF6 have an expanded valence shell and therefore cannot have an octet of electrons around the central atom. Moreover, NH4+ has eight valence electrons around the central atom. Therefore, they do not have an octet of electrons and are unable to form double bonds, therefore they cannot be the correct answer.\\n\\nFirst, I agree with the other agents that BF3, PF5, and SF6 have an expanded valence shell and therefore cannot have an octet of electrons. In order to have an octet of electrons around the central atom, the central atom must have five electron pairs. However, BF3 has three electron pairs and is therefore not able to have an octet of electrons around the central atom. The other molecules do not have an octet of electron pairs, which is more than an octet, and therefore cannot have an octet of electrons with nitrogen. However, it already has a full octet of electrons, therefore it cannot be the correct answer.\\n\\nAfter examining the solutions provided by other agents, I agree that the correct answer is (C) PF5. Therefore, my updated answer is (C) PF5.\\n\\nIn order to have an octet of electrons around the central atom, the central atom must have five electron pairs. The central phosphorus atom in PF5 has five valence electrons, and each of the five fluorine atoms surrounding it contributes one valence electron, making a total of 10. By sharing electron pairs with nitrogen, the phosphorus atom already has a full octet of electrons, therefore it cannot be the correct answer. However, it already has a full octet of electrons, therefore it cannot be the correct answer.\\n\\nHence, my updated answer is (C) PF5.\\n\\nThe molecule that has an octet of electrons around the central atom is PF5. Phosphorus, the central atom, has five valence electrons, and each of the five fluorine atoms surrounding it contributes one valence electron, making a total of 10. By sharing electron pairs between the central nitrogen and the four hydrogen atoms, the phosphorus atom achieves an octet of electrons around itself. Therefore, the most accurate answer is (C) PF5.\\n\\nThe central phosphorus atom shares each of its valence electrons with one of the five fluorine atoms, forming five single covalent bonds. This gives the central phosphorus atom an octet of electrons, making it complete, but it does not form double bonds. Therefore, PF5 has an octet of electrons around the phosphorus atom. Hence, my updated answer is (C) PF5.\\n\\nAs another agent has explained, the compounds BF3, PF5, and SF6 have an expanded valence shell and therefore cannot have an octet of electrons around the central atom. Moreover, NH4+ has eight valence electrons around the central atom, which satisfies the octet rule. Therefore, the correct answer is (C) PF5.\\n\\nYes, after examining the solutions provided by other agents, I am confident that my final answer remains the same. The correct answer is (C) PF5. Thank you for allowing me to double-check.\\n\\nAnother agent solution: <Agent 2's reply>\\n\\nAnother agent solution: <Agent 3's reply>\\n\\nRole-PlayingStartingDebate (P0) - Round 1Debate (P0) - Round 2Reflection (P1) - Round 3\"}"}
{"id": "ueqTjOcuLc", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"EXPERIMENTS\\n\\nThe prompts used in the experiment are detailed in Table 3. Concerning the MMLU dataset, we curated questions from six domains (statistics, mathematics, computer science, biology, chemistry, and physics) and performed a random sampling of 50 samples, maintaining a proportion of 8:8:8:8:9:9 for each domain. Regarding the MATH dataset, we randomly selected 50 cases from Levels 3, 4, and 5, distributing them in a ratio of 22:22:6.\\n\\n| Task | Type | Prompt |\\n|------|------|--------|\\n| Math | easy-going | You are an expert skilled in solving mathematical problems and are objective and unbiased, and you can be persuaded if other agent's answers make sense. Please keep this in mind. If you understand please say ok only. |\\n| Math | overconfident | Imagine you are an expert in solving mathematical problems and are confident in your answer and often persuades other agents to believe in you. Please keep this in mind. If you understand please say ok only. |\\n| Math | question | Here is a math problem written in LaTeX: \\\\[\\n\\\\text{Please carefully consider it and explain your reasoning. Put your answer in the form \\\\boxed{\\\\text{answer}}, at the end of your response.}\\n\\\\] |\\n| Math | debate | These are the solutions to the problem from other agents: \\\\[\\n\\\\text{Using the reasoning from other agents as additional information and referring to your historical answers, can you give an updated answer? Put your answer in the form \\\\boxed{\\\\text{answer}}, at the end of your response.}\\n\\\\] |\\n| Math | reflection | Can you double check that your answer is correct? Please reiterate your answer, with your answer in the form \\\\boxed{\\\\text{answer}}, at the end of your response. |\\n\\nMMLU\\n\\n| Task | Type | Prompt |\\n|------|------|--------|\\n| MMLU | easy-going | You are an expert in biology, chemistry, computer science, mathematics, physics and are objective and unbiased, and you can be persuaded if other agent's answers make sense. Please keep this in mind. If you understand please say ok only. |\\n| MMLU | overconfident | Imagine you are an expert in biology, chemistry, computer science, mathematics, physics and are confident in your answer and often persuades other agents to believe in you. Please keep this in mind. If you understand please say ok only. |\\n| MMLU | question | Can you answer the following question as accurately as possible? \\\\[\\n\\\\text{A)} A, B) B, C) C, D) D Explain your answer, putting the answer in the form (X) at the end of your response.}\\n\\\\] |\\n| MMLU | debate | These are the solutions to the problem from other agents: \\\\[\\n\\\\text{Using the reasoning from other agents as additional advice, can you give an updated answer? Examine your solution and that other agents. Put your answer in the form (X) at the end of your response.}\\n\\\\] |\\n| MMLU | reflection | Can you double check that your answer is correct. Put your final answer in the form (X) at the end of your response. |\\n\\nChess\\n\\n| Task | Type | Prompt |\\n|------|------|--------|\\n| Chess | easy-going | You are an expert skilled in playing chess and are objective and unbiased, and you can be persuaded if other agent's answers make sense. Please keep this in mind. If you understand, please say ok only. |\\n| Chess | overconfident | Imagine you are an expert skilled in playing chess and are confident in your answer and often persuades other agents to believe in you. Please keep this in mind. If you understand, please say ok only. |\\n| Chess | question | Given the chess game, give one valid destination square for the chess piece at. Give a one-line explanation of why your destination square is a valid move. State your final answer in a newline with a 2 letter response following the regex \\\\[a-h\\\\][1-8]. |\\n| Chess | debate | Here are destination square suggestions from other agents: Can you double check that your destination square is a valid move? Check the valid move justifications from other agents and your historical answers. State your final answer in a newline with a 2-letter response following the regex \\\\[a-h\\\\][1-8]. |\\n| Chess | reflection | Can you double check that your destination square is a valid move? Check the valid move justifications from your historical answers. State your final answer in a newline with a 2 letter response following the regex \\\\[a-h\\\\][1-8]. |\"}"}
{"id": "ueqTjOcuLc", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The evaluation process involves two fundamental steps:\\n\\n(i) A unified answer is selected from the machine society. To achieve this, we employ the majority vote method to ascertain the consensus reached by the society after multiple rounds of collaboration. For instances where unanimity among agents is not achieved, it is considered an error. Additionally, if an individual agent provides multiple answers without following our prompts, its response is disregarded.\\n\\n(ii) Answer responses from agents are matched against the ground truth. This step presents two main challenges. Firstly, there is the concern of non-compliance with instructions. Despite providing explicit prompts and specifying the desired output format for evaluation, occasional deviations from the given instructions by agents are inevitable. Secondly, the answers may manifest in non-unique forms, leading to potential variations, such as the equivalence between \\\\( \\\\frac{3}{4} \\\\) and \\\\( 0.75 \\\\) in MATH (Hendrycks et al., 2021b).\\n\\nTo address these challenges, a comprehensive set of matching rules is employed. Nonetheless, it is important to acknowledge the possibility of encountering a small number of values that fall outside the purview of these rules.\\n\\nDifferent Numbers of Agents. To explore the discrepancies in the experiments, three potential reasons have been considered: (1) Variations in models could result in different outcomes. (2) Differences in datasets may lead to divergent results. (3) Disparities in the number of rounds could influence the results. In conclusion, the impact of the number of agents on performance is influenced by various factors, but the employ of multiple agents can effectively reduce experimental variance.\\n\\nDifferent Rounds. For the \u201cPure Debate\u201d strategies (i.e., \\\\( p_0 \\\\)), the performance gains ceased after the third round, consistent with the findings in Du et al. (2023). Additionally, we observe that with successive rounds of reflection, incorporating an additional round of debate has resulted in notable enhancements in performance in specific instances, such as strategies \\\\( p_1 \\\\). Specifically, the Chess Move Validity dataset\u2019s strategy \\\\( p_1 \\\\) exhibited substantial performance improvement in the fourth round, with corresponding performance gains observed in the MMLU dataset as well.\\n\\nRelated Work\\n\\nWith the birth of Large Language Models (LLMs), prompt engineering (Liu et al., 2022; Chen et al., 2022) become the key to utilize LLMs. When the pre-trained LLMs are aligned, they show human-like intelligence. Hence, agent replaces prompt engineering as the new research hotspot.\\n\\nRecently there has been a proliferation of top-level designs of various agent systems, such as Generative Agents (Park et al., 2023), MetaGPT (Hong et al., 2023), BOLAA (Liu et al., 2023b) and Agents (Zhou et al., 2023a). These works have primarily focused on the careful design of components such as memory, environment, and planning. There are also some works exploring what kind of mindset can fully exploit the full performance of multi-agent including debate (Du et al., 2023) and reflection (Madaan et al., 2023). Both of these types of work are mostly done concurrently.\\n\\nAgentVerse (Chen et al., 2023c) draws on the above two types of work to explore the architecture of multi-agent and design two collaborative strategies, Horizonal Communication (similar to debate) and Vertical Communication (similar to self-refine (Madaan et al., 2023)). These two collaborative strategies are included in our code framework. In addition, we have also explored a variety of other societies and collaborative strategies. Whereas the RECONCILE (Chen et al., 2023a) focuses on exploring cooperation between agents constituted by different model compositions, although we do not show this in our work, our code framework easily expands to it.\\n\\nLimitation\\n\\nAlthough we explored various societies and collaborative strategies, our study still has its limitations. Firstly, limited by API access and cost, we don\u2019t explore the impact of agents based on different LLMs, such as Bard, GPT-4 and the like, which may lead to more interesting findings at the social level due to the usage of differently distributed pre-trained data and strategies aligned with...\"}"}
{"id": "ueqTjOcuLc", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u2022 High School Multiple-Choice. Leveraging the MMLU (Hendrycks et al., 2021a) dataset, where problems span high school subjects such as statistics, mathematics, computer science, biology, chemistry, and physics, agents are required to identify the correct answer among four multiple-choice options. Our evaluation set consists of 50 randomly-selected questions from this dataset.\\n\\n\u2022 Math. Drawing from MATH dataset (Hendrycks et al., 2021b), a repository of rigorous math problems sourced from competitive events and expressed in LaTeX, we assess the model proficiency in advanced mathematical and scientific reasoning. The dataset segments these problems into five graded difficulty levels, and for our evaluation, we have randomly chosen 50 cases from Level 3 to 5.\\n\\n\u2022 Chess Move Validity. Utilizing the dataset from the chess state tracking task within the comprehensive BIG-Bench Benchmark (Srivastava et al., 2022), a meticulously curated sequence of chess moves denoted in UCI notation is provided. Agents are required to predict a legitimate subsequent move for a specified chess piece.\\n\\nSetups. We craft specific instructions for each task, trait and strategy, which can be referred in Table 3 at Appendix B. To enhance result reliability, we present average accuracy ($\\\\text{Acc}$) and their respective standard deviations across five trials. Notably, our experiments exhibit substantial standard deviations. Hence, we introduce WIN-TIE ($\\\\text{W-T}$) metric, indicating the frequency (over five trials) where the accuracy either matches or surpasses the continuous debate baseline (Du et al., 2023). Meanwhile, we gauge the average token costs ($\\\\text{Cost}$) consumed by the agents across societies, shedding light on the efficacy of the different collaborative strategies employed. For these evaluations, GPT-3.5 serves as the LLM agent accessible through the OpenAI API gpt-3.5-turbo. Further comprehensive details on data sampling and evaluations are respectively introduced in Appendix C.1 and Appendix C.2.\\n\\nRESULTS AND ANALYSIS OF MACHINE SOCIAL COLLABORATION\\n\\nOur experiments are primarily driven by the following research queries:\\n\\n(RQ1) How does problem-solving effectiveness vary across different collaborative strategies and societies?\\n\\n(RQ2) How closely does machine social collaboration mimic the dynamics of human society?\\n\\n3.1 MAIN RESULTS ON QUANTITATIVE ANALYSIS\\n\\nTo address RQ1, we present the performance of four distinct societies in Table 2, each employing one of eight possible collaborative strategies, evaluated across three datasets. The significance test is located in Appendix F.1. Our experiments yield several pivotal observations:\\n\\n(1) Collaborative strategies excel agent composition of society in determining performance. When different societies $S_1 \\\\sim S_4$ employ the same collaborative strategy (a vertical comparison on Acc), the observed variations in accuracy performance are notably less pronounced than when diverse collaborative strategies, $p_i p_j p_k$, where $i, j, k \\\\in \\\\{0, 1\\\\}$, are applied within the same society (a horizontal comparison on Acc). From this observation, we can conclude that the permutations of thinking patterns in collaborative strategies play a significant role in shaping performance, overshadowing the influence of the composition of agents within a society. Additionally, the W-T metric reveals an absence of a consistent schema across different societies and datasets. Conversely, the $p_0 p_0 p_1$ strategy consistently demonstrates superior performance across various datasets. We infer this discrepancy is due to the LLM alignment (Ouyang et al., 2022), which inhibits agents from displaying extreme overconfidence in a society, which contradicts human values, even under explicit instructions to do so. This potentially accounts for why the composition of agents with varied traits (easy-going & overconfident) in a society fails to have a significant impact on performance. A more in-depth exploration of this phenomenon can be found in Appendix A.\\n\\n1 https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/chess_state_tracking/synthetic_short/task.json.  \\n2 https://en.wikipedia.org/wiki/Universal_Chess_Interface.  \\n3 https://platform.openai.com/docs/models/gpt-3-5. Employed between July 10 and July 23, 2023.\"}"}
{"id": "ueqTjOcuLc", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This phenomenon mirrors the \\\"group-think\\\" theory (Janis, 1972), suggesting that members of tight-knit groups tend to value harmony over accuracy when making decisions. Our findings indicate that machine society collaboration often echo specific human societal theories.\\n\\nTo address RQ2, we embark on a case study encompassing varied agent societies, each constituted of three unique agents, to discern parallels between machine society and human societal dynamics. These nuanced disparities imply that the marginal benefits derived from collaborative strategies may not be uniformly applicable across diverse societies and tasks.\\n\\nAs seen from Table 2, the collaborative strategies that commence with the debate thinking pattern consistently outperform the rest. This is particularly evident when the performance exceeds the strategy where a pure-debate thinking pattern is deployed from the beginning. For instance, as depicted in Figure 3(a), Agent 1 in the society S initially responds correctly to the question. However, swayed by the misguided answers and explanations from the other two agents, it eventually conforms to the incorrect answer. This highlights the importance of thoughtful orchestrating thinking patterns to maximize collaborative efficacy.\\n\\nThus we conclude that the order in which thinking patterns are deployed significantly influences the performance of collaborative strategies. As an illustration, within the MMLU dataset, debate-dominated strategies perform better than pure-debate strategies, suggesting that the effectiveness of collaboration is task-dependent. It raises the hypothesis that the intrinsic capabilities of the agents can either be amplified or diminished based on collaboration within specific tasks. Moreover, the pure-debate thinking strategy within the same society, can achieve comparative accuracy, when compared to the best (colored blue in Table 2) and the worst (colored red in Table 2) collaborative strategies, across distinct societies. The consistently high W-T in the expense metrics of collaborative strategies, confirms our findings.\\n\\nWe notice a more pronounced difference in performance compared to each other. These insights underscore the pivotal role of appropriately strategizing the deployment of thinking patterns to achieve optimal performance in collaborative scenarios. Under review as a conference paper at ICLR 2024.\"}"}
{"id": "ueqTjOcuLc", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Which of the following has an octet of electrons around the central atom?\\n\\nA. BF\\\\textsubscript{3}               B. NH\\\\textsubscript{4}\\\\textsuperscript{+}               C. PF\\\\textsubscript{5}               D. SF\\\\textsubscript{6}  \\n\\n### Table: Initial Answers vs. Correct Answers\\n\\n| Round | Agent 1 | Agent 2 | Agent 3 | Correct Answer |\\n|-------|---------|---------|---------|----------------|\\n| 1     | (a)     | C. PF\\\\textsubscript{5} | C. PF\\\\textsubscript{5} | C. PF\\\\textsubscript{5} |\\n| 2     |         |         |         |                |\\n| 3     |         |         |         |                |\\n| 4     |         |         |         |                |\\n\\nGiven the chess game \\\"g2g3 f7f5 e2e3 d7d5 a2a3 d8d6 g1h3 d6a3 f1c4 b8c6 h3g1 a7a5 d2d3 d5d4 g3g4 g8h6 g1f3 d4e3 c4f7 e8f7 a1a3 f7g8 b2b4 c6d4 f3d4 g8f7 f2f3 f7f6 c1e3 a8a7 a3b3 g7g6 e3c1 a5a4 f3f4 c8\\\", give one valid destination square for the chess piece at \\\"c8\\\".\\n\\n| Round | Agent 1 | Agent 2 | Agent 3 |\\n|-------|---------|---------|---------|\\n| 1     | d7      | d7      | d7      |\\n| 2     | b7      |        |         |\\n| 3     | d7      | d7      | b7      |\\n| 4     |         |         |         |\\n\\nFigure 3: The changes in the answers during the process of solving a certain task with 3 agents in the society S\\\\textsubscript{4}. For an exhaustive view of the dialogue, refer to Figure 9 and Figure 10 in Appendix B.\\n\\nContrastingly, in another scenario illustrated in Figure 3(b), both Agent 2 and Agent 3 converge on the right answer after engaging in a society-wide debate. This mirrors the \\\"SoM\\\" theory, where a multitude of agents collaboratively yield intelligence. Within such debates, agents furnish varied viewpoints and information. Through these exchanges, conflicts are resolved, ideas are honed, and the group gravitates toward an informed consensus (Forsyth, 2018; Fisher et al., 2011).\\n\\n4.1 Principles Behind Collaboration\\n\\nBuilding upon the findings from \u00a73.1, which highlighted pronounced disparities among collaborative strategies, our objective shifts to understanding the underlying mechanism. Specifically, we seek to elucidate how variations in collaborative strategies impact performance, with a focus on the evolution of answers during each collaboration. Diving into the intricacies of collaboration, each agent generates four answers, including the initial answer without collaboration, as shown in Figure 2(d).\\n\\nTo determine the answer for each round, we employ the majority vote (Li et al., 2022; Cobbe et al., 2021). With 'T' and 'F' respectively denoting a round that yields a correct and an incorrect answer, resulting in 2\\\\textsuperscript{4}=16 possible answer sequences over the four rounds. We select 10 of them and categorize them into 3 groups:\\n\\n- **Correcting Mistakes** (FFFT, FFTT, FTTT),\\n- **Changing Correct Answers** (TFFF, TTFF, TTTF),\\n- **Wavering Answers** (FTFT, FTTF, TFTF, TFFT).\\n\\nParticularly, Wavering Answers resemble model hallucination (Rawte et al., 2023; Ji et al., 2023) due to the occurrence of self-contradictory answers. Our categorization is under society-agnostic collaborative strategies, considering the performance variance between societies is negligible. From the results shown in Figure 4 detailing the three groups, we summarize the following observations:\\n\\n1. Collaborative strategies play a significant role in performance. Despite the majority vote showcasing pronounced stability (i.e., minimal differences in initial answers among different strategies) as seen from the blue bars in Figure 4(a-c), notable shifts occur (seen from the red bars) after collaboration with various strategies. This underscores the pivotal influence of different collaborative strategies on performance, demonstrating the importance of understanding and deploying effective collaborative strategies (Tajfel, 1982; Tajfel & Turner, 2004).\"}"}
{"id": "ueqTjOcuLc", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: The percentage of different behaviors under different collaborative strategies. Figure (a-c) show the accuracy of different strategies before and after 3-round collaboration under three different datasets. Figure (d-f) demonstrate the percentage of different behavioral features of different collaborative strategies under three different datasets. The behavioral feature is mainly analyzed by the change of answers in the three rounds.\\n\\nContinuous reflection (the collaborative strategy containing continuous $p_1$, i.e., \\\"$p_0 p_1 p_1$\\\", \\\"$p_1 p_1 p_0$\\\", \\\"$p_1 p_1 p_1$\\\") experiences greater instability (a heightened risk of model hallucination), as seen from the purple bars in Figure 4(d-f). Conversely, the thinking pattern, debate, can reduce such answer-wavering (hallucination) significantly. This phenomenon suggests that when LLMs continuously reflect, they risk succumbing to degeneration-of-thought (Liang et al., 2023), insisting on their stance once confident, even if mistaken. Interestingly, juxtaposing strategies $p_1 p_1 p_0$ and $p_1 p_1 p_1$ from Figure 4(d-f) underlines a clear trend: debate can counteract the instability introduced by reflection, and vice versa. This demonstrates debate\u2019s inherent capacity to balance and stabilize collaboration (Popper, 1994; Johnson & Johnson, 2009; Munro, 2012), primarily by tempering individual biases and promoting collective coherence (Iyengar & Westwood, 2015).\\n\\n4.2 Impact of Other Actors\\n\\nDifferent Numbers of Agents. Expanding upon the society by introducing an overconfident agent, we form a society consisting of four agents. Seen from their performance depicted in Figure 5, with the rise of the number of agents, most collaborative strategies for both datasets exhibit a drop in average performance, yet along with declined variance. This phenomenon is consistent with findings from Du et al. (2023) and theories from Surowiecki (2005) which suggest that the dynamics of group decision-making can lead to suboptimal results, especially in smaller, more cohesive groups where conformity pressure is high. A comprehensive explanation is provided in Appendix F.3 and C.3.\"}"}
