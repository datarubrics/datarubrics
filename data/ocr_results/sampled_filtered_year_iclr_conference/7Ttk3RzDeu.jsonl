{"id": "7Ttk3RzDeu", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2024\\n\\n...Therefore, you should organize the summary so it presents a consistent and chronological narrative. Despite this recursive merging process, you need to create a summary that seems as though it is written in one go. The summary must be within {} words and could include multiple paragraphs.\\n\\nSummary:\\n\\nM.2.1 LL\\n\\nA\\n\\nMA 2\\n\\nPROMPTS\\n\\nGenerate lowest-level summaries\\n\\nBelow is a part of a story:\\n\\n--- {} ---\\n\\nWrite a coherent and chronological summary for the excerpt provided above. Briefly introduce characters, places, and other major elements if they are being mentioned for the first time in the summary. The summary must be within {} words and could include multiple paragraphs.\\n\\nSummary:\\n\\nMerge summaries\\n\\nBelow are several summaries of consecutive parts of a story:\\n\\n--- {} ---\\n\\nMerge the given summaries into one coherent and chronological summary. Briefly introduce characters, places, and other major elements if they are being mentioned for the first time in the summary. The summary must be within {} words and could include multiple paragraphs.\\n\\nSummary:\\n\\nMerge summaries with prior context\\n\\nBelow is a summary of the context preceding some parts of a story:\\n\\n--- {} ---\\n\\nBelow are several summaries of consecutive parts of a story:\"}"}
{"id": "7Ttk3RzDeu", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "7Ttk3RzDeu", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "7Ttk3RzDeu", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "7Ttk3RzDeu", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In 1898, a young boy named Pirbhai leaves his home in India in search of work. He meets a merchant who offers him a job ... for Africa. Once aboard, he meets Jameel, a fellow countryman, and together they endure the hardships of life at sea.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We are going over segments of a story sequentially to gradually update one comprehensive summary of the entire plot. Write a summary for the excerpt provided above, make sure to include vital information related to key events, backgrounds, settings, characters, their objectives, and motivations. You must briefly introduce characters, places, and other major elements if they are being mentioned for the first time in the summary. The story may feature non-linear narratives, flashbacks, switches between alternate worlds or viewpoints, etc. Therefore, you should organize the summary so it presents a consistent and chronological narrative. Despite this step-by-step process of updating the summary, you need to create a summary that seems as though it is written in one go. The summary should roughly contain {} words and could include multiple paragraphs.\\n\\nSummary ({} words):\\n\\nGenerate intermediate summaries\\n\\nBelow is a segment from a story:\\n---\\n{}\\n---\\n\\nBelow is a summary of the story up until this point:\\n---\\n{}\\n---\\n\\nWe are going over segments of a story sequentially to gradually update one comprehensive summary of the entire plot. You are required to update the summary to incorporate any new vital information in the current excerpt. This information may relate to key events, backgrounds, settings, characters, their objectives, and motivations. You must briefly introduce characters, places, and other major elements if they are being mentioned for the first time in the summary. The story may feature non-linear narratives, flashbacks, switches between alternate worlds or viewpoints, etc. Therefore, you should organize the summary so it presents a consistent and chronological narrative. Despite this step-by-step process of updating the summary, you need to create a summary that seems as though it is written in one go. The summary should roughly contain {} words and could include multiple paragraphs.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Currently, this summary contains {} words. Your task is to condense it to less than {} words. The condensed summary should remain clear, overarching, and fluid while being brief. Whenever feasible, maintain details about key events, backgrounds, settings, characters, their objectives, and motivations - but express these elements more succinctly. Make sure to provide a brief introduction to characters, places, and other major components during their first mention in the condensed summary. Remove insignificant details that do not add much to the overall story line. The story may feature non-linear narratives, flashbacks, switches between alternate worlds or viewpoints, etc. Therefore, you should organize the summary so it presents a consistent and chronological narrative. Despite this recursive merging process, you need to create a summary that seems as though it is written in one go.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We are creating one comprehensive summary for the story by recursively merging summaries of its chunks. Now, merge the given summaries into one single summary, make sure to include vital information related to key events, backgrounds, settings, characters, their objectives, and motivations. You must briefly introduce characters, places, and other major elements if they are being mentioned for the first time in the summary. The story may feature non-linear narratives, flashbacks, switches between alternate worlds or viewpoints, etc. Therefore, you should organize the summary so it presents a consistent and chronological narrative. Despite this recursive merging process, you need to create a summary that seems as though it is written in one go.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ABSTRACT\\n\\nSummarizing book-length documents (>100K tokens) that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, \\\\textsc{BooookScore}, that measures the proportion of sentences in a summary that do not contain any of the identified error types. \\\\textsc{BooookScore} has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving $15K USD and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher \\\\textsc{BooookScore} than those generated by open-source models. While LLaMA 2 falls behind other models, Mixtral achieves performance on par with GPT-3.5-Turbo. Incremental updating yields lower \\\\textsc{BooookScore} but higher level of detail than hierarchical merging, a trade-off sometimes preferred by annotators. We release code and annotations to spur more principled research on book-length summarization.\\n\\n1 INTRODUCTION\\n\\nJust two years ago, automatically-generated summaries were riddled with artifacts such as grammar errors, repetition, and hallucination (Zhao et al., 2020; Fabbri et al., 2020; Goyal & Durrett, 2021). Nowadays, such artifacts have mostly disappeared; in fact, Pu et al. (2023b) find that summaries generated by large language models (LLMs) are preferred over those written by humans, leading them to pronounce the death of summarization research. However, as with most prior work on summarization, the input documents in their study are relatively short (<10K tokens). Widespread adoption of LLMs outside the research community has driven the development of a more ambitious task: summarizing book-length documents, which we define to be texts longer than 100K tokens.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As these documents exceed the context window limits of today\u2019s LLMs (e.g., 8K tokens for GPT-4), summarizing them via prompt-based approaches necessitates heuristics to chunk the input, process each chunk, and then combine and compress the outputs (Wu et al., 2021). Despite the promise that LLMs hold for long-context tasks, the research community still lacks a principled and systematic approach to evaluate their capabilities on book-length summarization. Our paper identifies three open challenges with evaluation:\\n\\n1. **Data contamination**, in which existing benchmarks such as BookSum (Kryscinski et al., 2022) are in the pretraining data of modern LLMs (Chang et al., 2023);\\n2. **An unexplored error distribution**, as most prior summarization research centers around short source documents and fails to capture coherence errors that are exacerbated by the \u201cchunk and combine\u201d book-length summarization setting;\\n3. **A lack of any reliable automatic metric**, which requires careful design and validation against human annotations.\\n\\n**Contribution 1:** A protocol for evaluating coherence in book-length summarization (\u00a73). To mitigate the impact of data contamination, we design our evaluation framework around the use of newly-published books. We propose a reference-free protocol that leverages human annotation of the coherence of LLM-generated summaries (i.e., their logical connectedness) under different prompting strategies. Our protocol unifies and extends best-practices across disparate works in document understanding and evaluation research, including adoption of fine-grained annotation units, use of QA pairs to denote points of confusion, and a taxonomic breakdown of different coherence errors. We validate our protocol by collecting 1193 span-level human annotations on GPT-4 generated summaries of a carefully curated set of 100 recently-published books (costing $3K USD and 100 annotator hours) using two prompting strategies (hierarchical merging and incremental updating, shown in Figure 1). In categorizing these annotations into eight frequent error types, we reveal an error distribution in GPT-4 summaries that differs from that observed in prior studies on short-document summarizers; notably, we identify new error types (causal omissions, salience errors) through our book-length summarization setting (Table 1).\\n\\n**Contribution 2:** An automatic metric\u2014BookCORE\u2014to assess summary coherence (\u00a74). Since our human evaluation is expensive, we follow recent work by developing an LLM-based evaluation metric called BookCORE that identifies and explains instances of any of our eight established coherence errors in a given summary. Human validation shows that BookCORE\u2019s annotations are almost as reliable as those of human annotators, which allows us to automatically evaluate many other book-length summarization configurations. Because BookCORE does not rely on gold summaries, it can easily be used to evaluate new LLM summarizers on any collection of newly-published books, ensuring that the metric will remain meaningful for LLMs of the future.\\n\\n**Contribution 3:** A systematic evaluation of different LLMs using BookCORE (\u00a75). We use BookCORE to evaluate the impact of several critical design decisions on the coherence of generated summaries, including the choice of prompting strategy, base LLM, and chunk size, a study that altogether cost $10K (USD) in LLM API calls. Our findings include:\\n\\n1. Hierarchical merging generally results in more coherent summaries but reduced level of detail compared to incremental updating;\\n2. GPT-4 and Claude 2 produce the most coherent summaries, while LLaMA 2 is substantially worse and fails to follow instructions;\\n3. Increasing the chunk size does not improve hierarchical merging but does substantially benefit Claude 2 when using incremental updating;\\n4. Summary-level preference judgments are highly subjective and do not correlate with BookCORE.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We do not compute ROUGE (Lin, 2004) as it has been shown to have significantly low human correlation when applied to summaries generated by GPT-3 (Goyal et al., 2022b).\\n\\n**Computing Annotation Precision**\\n\\nIn this human evaluation task, given a summary and an annotation (span-question pair) for the summary, we ask annotators whether they agree, partially agree, or disagree with the annotation. We provide the following standards for determining agreement:\\n\\n1. The span is confusing.\\n2. The questions are:\\n   \\n   a. Relevant to the span.\\n   b. Not answered anywhere in the summary, explicitly or implicitly.\\n   c. Addressing issues that if left unresolved, would make the summary incoherent or make it hard for readers to understand the main storyline.\\n\\nAgreement would mean both the span and the questions satisfy the standards. Disagreement would imply that the span is not at all confusing, regardless of the questions. Partial agreement would apply when the span is confusing, but the questions fail to meet one or more of the standards.\\n\\nWe mix human and GPT-4 annotations in the data we present to the annotators, concealing the origin of these annotations to prevent any potential bias. Each annotator was responsible for the human and GPT-4 annotations of 25 books (different from the 25 books which they annotated summaries for).\\n\\nWe paid $1.7 per summary and $0.15 per annotation. 100 summaries and 1659 annotations resulted in a total cost of $418.85 (USD). Note that annotators were informed of this evaluation task weeks after they completed the first task (where they were asked to highlight spans and ask questions given book summaries). Thus, monetary reward for the second task could not have biased annotators to produce as many annotations as possible for the first task.\\n\\nWhen computing precision, we count all cases of agreement and partial agreement.\\n\\n**API Costs**\\n\\nWe present an estimation of the API costs of our experiments in Table 8.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 8: API cost estimates in USD.\\n\\n| Model    | Chunk Size | Summarization B | TOTAL Cost |\\n|----------|------------|-----------------|------------|\\n|          | 4096       | OOO0000000S     | 580.3      |\\n|          | 2048       | CORE Eval       | 566        |\\n| GPT-4    | 4096       | Summaries generated via hierarchical merging | 580.3 |\\n| GPT-4    | 2048       |                | 394.1      |\\n| GPT-3.5-Turbo | 2048 |                | 29.5       |\\n| Claude 2 | 2048       |                | 379.8      |\\n| Claude 2 | 88000      |                | 378.9      |\\n| Mixtral-8x7B | 2048 |                | 460.5      |\\n| LLaMA2-7B-Inst | 2048 |                | 538.5      |\\n|          | 4096       | Summaries generated via incremental updating | 786.7 |\\n|          | 2048       |                | 536.8      |\\n| GPT-4    | 4096       |                | 318.4      |\\n| GPT-3.5-Turbo | 2048 |                | 356.6      |\\n| Claude 2 | 2048       |                | 518.7      |\\n| Claude 2 | 88000      |                | 395.7      |\\n| Total    |            |                | 4020.5     |\\n|          |            |                | 6021.2     |\"}"}
{"id": "7Ttk3RzDeu", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 9: GPT-4 4096 summaries of Janika Oz's *A History of Burning*.\\n\\n**Strategy**\\n\\n**Summary**\\n\\nHier\\n\\n*A History of Burning* follows the lives of an Indian family living in Uganda during the late 19th and early 20th centuries. As they struggle to survive and maintain their culture in a foreign land, they are forced to adapt and overcome numerous challenges. The story of Janika Oz's novel is filled with heartache, loss, and resilience. The theme of history and burning serves as a metaphor for their resilience and determination to create a better future.\\n\\nIn 1898, Indian boy Pirbhai is tricked into working on a railway in Mombasa, Kenya. He finds shelter with Sonal's family and begins to rebuild his life. As he navigates the challenges of a new life, he also faces the difficulty of maintaining his heritage. The novel explores the complexities of life's difficulties as they continue to navigate the balance between their heritage and their new lives in Toronto.\\n\\n21\"}"}
{"id": "7Ttk3RzDeu", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 10: GPT-4 2048 summaries of Janika Oz's *A History of Burning*.\\n\\n| Strategy | Summary |\\n|----------|---------|\\n\\nHier\\n\\n\u201cA History of Burning\u201d by Janika Oza follows an Indian family living in Uganda through multiple generations as they navigate hardships, sacrifices, and cultural identity struggles. The story begins with Pirbhai, a 13-year-old boy from Gujarat, India, who travels to Africa in search of work during a time of drought and hardship. He eventually marries Sonal, a young girl living with her family in Kenya, and they move to Kampala, Uganda, where they have a son named Vinod.\\n\\nVinod helps elevate his family's status in Uganda and marries Rajni, a 19-year-old girl from Karachi, amidst rising tensions between Hindus and Muslims. They raise two daughters, Latika and Mayuri, while facing challenges in their relationship and adapting to their new surroundings. Throughout the story, the characters face hardships, sacrifices, and the struggle to maintain connections to their homeland while navigating the challenges of colonialism, migration, and cultural identity.\\n\\nYears later, Latika grows up and becomes involved in activism against colonial rule in Africa, writing for a secret network called Jicho. She marries Arun, a fellow activist, but struggles with her new life living with his family and the expectations placed upon her. Meanwhile, her sister Mayuri navigates a newly integrated school in Uganda, facing racism and discrimination while considering her future. Eventually, Mayuri studies medicine in India and later returns to her family in the U.S., accompanied by her partner Kunal.\\n\\nThe family faces challenges as political changes in Uganda, the Mau Mau rebellion in Kenya, and the lingering effects of British colonialism impact their lives. Latika secretly writes for an anti-government newspaper, JICHO, and her husband Arun is kidnapped due to her involvement. Mayuri is surprised by the changes in her family, particularly her parents' aging and her younger siblings, Kiya and Hari. She learns that Hari, the son of her deceased sister Latika and her husband Arun, is unaware of his true parentage.\\n\\nAs the family members struggle to maintain connections to their homeland and each other, they experience loss, love, and resilience in the face of adversity. Throughout the story, the characters find strength and hope in their shared experiences and love for one another, as they try to build a better life for themselves and their families. The story also explores the challenges faced by immigrants as they adapt to new environments, such as Mayuri's struggle to practice medicine in Canada and the family's experiences with racism and violence.\\n\\nIn the end, the family must come together to face the destruction of their shop and the loss of their past, finding solace in each other and the hope for a better future. Through their shared experiences and love for one another, they find strength and hope to endure the challenges that come their way. The story highlights the resilience and determination of the characters as they navigate the complexities of life, love, and identity across generations and continents.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: BBOOKS CORE for summaries generated under different configurations; higher scores indicate better coherence. We additionally report the average summary length in tokens based on tiktoken (https://github.com/openai/tiktoken) tokenizer, the percentage of novel trigrams compared to the source, and percentage of repeated trigrams in the summary.\\n\\n| Model Chunk size  | BBOOKS CORE | Avg. length | % novel 3-grams | % rep. 3-grams |\\n|-------------------|-------------|-------------|-----------------|---------------|\\n| Summaries generated via hierarchical merging |\\n| GPT-4 2048 | 89.1 | 778.6 | 82.4 | 4.2 |\\n| GPT-3.5-Turbo 2048 | 84.2 | 667.3 | 82.8 | 9.0 |\\n| Claude 2 2048 | 91.1 | 522.6 | 88.4 | 1.3 |\\n| Claude 2 88000 | 90.3 | 551.5 | 87.1 | 2.0 |\\n| Mixtral-8x7B 2048 | 81.5 | 679.1 | 85.9 | 4.1 |\\n| LLaMA2-7B-Inst 2048 | 72.4 | 684.9 | 76.4 | 36.1 |\\n| Summaries generated via incremental updating |\\n| GPT-4 2048 | 82.5 | 805.4 | 84.1 | 3.4 |\\n| GPT-3.5-Turbo 2048 | 67.0 | 484.5 | 68.2 | 3.5 |\\n| Claude 2 2048 | 78.6 | 657.1 | 89.4 | 1.9 |\\n| Claude 2 88000 | 90.9 | 493.7 | 84.7 | 1.9 |\\n| Mixtral-8x7B 2048 | 64.5 | 558.7 | 82.3 | 3.5 |\\n\\nGPT-4 summaries generated via incremental updating and hierarchical merging, respectively, while using LLM annotations yields a BBOOKS CORE of 82.4 and 90.8. Figure 4 compares the error distributions from GPT-4 to those of human annotators and shows that GPT-4 is more sensitive to omission errors and less sensitive to duplication or language errors. Taken as a whole, these results confirm that BBOOKS CORE is a reliable annotator of coherence for book-length summarization.\\n\\nWhile we implement BBOOKS CORE with GPT-4 for the remainder of this paper, implementing BBOOKS CORE with open-source LLM annotators is an exciting future direction.\\n\\n5 SYSTEMATIC EVALUATION OF LLMs\\n\\nArmed with BBOOKS CORE, we now investigate the impact of several critical implementation decisions on summary coherence, including the choice of prompting strategy, base LLM, and chunk size. Overall, Claude 2 produces the most coherent summaries as measured by BBOOKS CORE, followed closely by GPT-4 and distantly by GPT-3.5-Turbo, Mixtral-8x7B, and LLaMA2-7B-Inst; however, GPT-4's summaries are significantly longer and more detailed than the others across both prompting strategies. The rest of this section drills down into finer-grained results.\\n\\nExperimental setup: Table 2 contains results for five instruction-tuned LLMs: GPT-4, GPT-3.5-Turbo, Claude 2, Mixtral-8x7B, and LLaMA2-7B-Instruct. Unless otherwise specified, we set the chunk size to 2048, maximum summary length $G_n$ to 900, decoding temperature to 0.5, and $p=1$ for ancestral sampling. To avoid confounds, we use identical prompts for all models except LLaMA2-7B-Inst, which only functions with a simpler prompt. LLM API costs for our experiments were $10K USD (Table 8); more experimental details are in Appendix D.\\n\\nIncremental summaries are almost always less coherent than their hierarchical counterparts. Hierarchical summaries generally have higher BBOOKS CORE than incremental summaries, likely because the incremental updating task requires the base LLMs to follow more complex instructions.\\n\\n13 GPT-4 configurations in this table are not comparable to the ones we analyzed in Section 3 since we had to reduce chunk size and summary length due to LLaMA2-7B-Inst and GPT-3.5-Turbo's smaller context size.\\n\\n14 Claude 2 is the only exception, as we use its default temperature of 1.\\n\\n15 We use a temperature of 1 for compression, which improves adherence to the max summary length.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Incremental summarization benefits from increased chunk size. The one exception to the above result is Claude 2 with a chunk size of 88K, whose incremental configuration produces slightly more coherent summaries than the hierarchical version (90.9 vs. 90.3). In contrast, using Claude 2 for incremental summarization with a chunk size of 2048 results in a BBOOKS CORE of 78.6, so clearly the model benefits from fewer updating and compression steps. We do not observe similar behavior with hierarchical summaries, which suggests that hierarchical book-length summarization is preferred for smaller context models.\\n\\nLLaMA 2 struggles on book-length summarization while Mixtral shows promising performance. Table 2 shows that LLaMA-2-7B-Instruct achieves by far the worst hierarchical BBOOKS CORE of any model. Its summaries also contain significant repetition (% of repeated tri-grams), which is a critical coherence error. Furthermore, we could not get the LLaMA-2-7B-Instruct checkpoint to perform incremental updating at all, as it just copied text from the chunks until it reached the summary length limit, at which point it failed to follow the compression instruction.\\n\\nOn the positive side, Mixtral-8x7B, another open-source LLM, outperforms LLaMA-2-7B-Instruct by a substantial margin, though it still trails behind most of the closed-source models. Nonetheless, it is encouraging to note that with performances closely matching that of GPT-3.5-Turbo on both summarization approaches, Mixtral-8x7B signals the narrowing gap between open-source and closed-source models.\\n\\nHigh coherence does not necessarily correlate with human preferences. How well do coherence measurements from BBOOKS CORE correlate with coarse-grained human preferences? We conduct another human evaluation study with the same four annotators in which we solicit preference judgments on pairs of GPT-4 generated incremental and hierarchical summaries. As shown in Table 4, incremental summaries are almost always preferred over hierarchical summaries in terms of level of detail (83% vs. 11%). However, hierarchical summaries are preferred for better structure (59% vs. 35%), logical consistency (53% vs 38%), and overall (54% vs. 44%). When forming their overall preference, some annotators preferred the higher level of detail of incremental summaries at the expense of coherence; thus, both strategies can be viable depending on the needs of the user.\\n\\nQualitative analysis: Appendix L contains summaries generated from Janika Oz\u2019s A History of Burning, which tells a multi-generational story about an Indian family living in Uganda. We observe that both GPT-4 and GPT-3.5-Turbo tend to generate oft-repetitive and vague sentences within their summaries (e.g., The story highlights the resilience and determination of the characters as they navigate the complexities of life, love, and identity across generations and continents.). Such artifacts are rarely produced by the 88K chunk size version of Claude 2, which instead omits key information present in the beginning or middle of the input (e.g., the entire story of the first generation in the book) in favor of focusing on the end of the book, following the findings of Liu et al. (2023a).\\n\\nAll configurations make faithfulness errors: for example, in A History of Burning, the mother of the character Hari is incorrectly identified as Rajni by Claude 2, while GPT-4 does describe Hari\u2019s parentage correctly at one point in the summary but incorrectly at another. We show in Appendix I that automatic quality metrics such as BLANC (Vasilyev et al., 2020) and SUPERT (Gao et al., 2020) are inadequate for book-length summarization.\\n\\nLIMITATIONS\\n\\nOur error taxonomy is derived just from errors made by GPT-4. We decided to conduct our human evaluations in Section 3 on summaries produced by GPT-4 for two reasons: (1) we wanted our error taxonomy to focus on errors that are actually made by state-of-the-art LLMs (unlike e.g., fluency errors present in SNaC); and (2) human evaluation is very costly, so we could not evaluate many different LLMs on our annotation budget. Similarly, we implement BBOOKS CORE using GPT-4 as a base LLM, which may have some systematic biases that could be alleviated by using a pool of LLM annotators as in AlpacaEval (Dubois et al., 2023).\"}"}
{"id": "7Ttk3RzDeu", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Since computing BOOKS can be expensive, it requires iterating through a summary sentence by sentence using GPT-4, making it expensive and slow, especially given the length of the annotation prompt (see Appendix M.4). We experimented with an approach that asked GPT-4 to annotate errors in the entire summary at once, but the generated annotations often included too many trivial questions, and alignment with human judgments was low. Despite these costs and evaluation times, BOOKS is still significantly cheaper and faster than performing human evaluations.\\n\\nBOOKS does not account for the relative importance of different error types. Unlike similar evaluation frameworks such as MQM (Freitag et al., 2021), we choose not to assign severity weights to different error types. Nowadays, powerful LLMs rarely make errors related to grammar, which can be objectively defined. For other error types in our taxonomy, the notion of assigning relative importance is ill-defined. Furthermore, prior work (Goyal et al., 2022a; Dou et al., 2022) shows low recall between human annotations for NLG evaluation, indicating that error type severity is subjective as annotators often do not highlight issues that others may find critical.\\n\\nNo validation of recall. Due to the expense, we do not collect overlapping annotations for each summary during human evaluation. Since the annotation task involves subjectivity, overlapping annotations can help ensure that all errors within a summary can be captured. However, recent work (Krishna et al., 2023) shows that a comprehensive annotation of all information units is not required to produce a useful aggregate score that can be used to rank different models.\\n\\n**Related Work**\\n\\n**Book-length narrative summarization:** Most prior long-form summarization work still focuses on documents shorter than 10K tokens (Cohan et al., 2018; Kornilova & Eidelman, 2019; Wang et al., 2022). BookSum (Kryscinski et al., 2022) is the first published summarization dataset that includes book-level source text as part of their data, which encouraged modeling efforts in this direction (Wu et al., 2021; Xiong et al., 2022; Pang et al., 2023; Cao & Wang, 2023; Pu et al., 2023a).\\n\\n**Fine-grained evaluation of generated text:** Our work relates to evaluation protocols within machine translation that annotate spans, error types, and error severities (Freitag et al., 2021; Fernandes et al., 2023), which are more meaningful than output ranking and Likert ratings. Also related is ACU (Liu et al., 2023c), an annotation protocol for summary salience evaluation that breaks summaries down into fine-grained content units, FactScore (Min et al., 2023), which dissects machine-generated text into atomic facts before evaluating their factual consistency, LongEval (Krishna et al., 2023), which includes an in-depth analysis of best practices for faithfulness evaluation in long-form summarization, and coherence evaluation, and SNaC (Goyal et al., 2022a), a coherence error taxonomy built for fine-tuned summarization models.\\n\\n**Automatic evaluation with LLMs:** LLM evaluators have recently emerged as a cost-effective alternative to human evaluations for both general conversational and instruction following capabilities (Dubois et al., 2023; Zheng et al., 2023) and traditional NLG tasks like summarization (Fu et al., 2023; Liu et al., 2023b; Wang et al., 2023). These latter studies substantiate LLMs\u2019 potential as an NLG metric, but only for evaluating short input-output pairs. In our work, we use GPT-4 to evaluate book-length summaries, uniquely employing a fine-grained automatic evaluation schema to set our work apart from existing research.\\n\\n**Conclusion**\\n\\nOur work presents the first systematic study of book-length summarization using LLMs. We establish a novel human evaluation protocol to assess summary coherence on newly-published books. Then, we develop an LLM-based automatic metric called BOOKS that relies on a coherence error taxonomy derived from our human annotations. Using BOOKS allows us to evaluate various prompting strategies and model choices, revealing insights such as: hierarchical merging produces more coherent summaries but may lack detail compared to incremental updating; and increasing chunk size can significantly improve incremental updating. Interesting future directions include automatically evaluating faithfulness in the book-length summarization setting, benchmarking newer long-context LLMs using BOOKS, and expanding BOOKS to multilingual texts. We release our BOOKS metric and annotated summaries to enable meaningful progress in book-length summarization.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACKNOWLEDGMENTS\\n\\nWe extend special gratitude to members from the UMass NLP lab for participating in the pilot study and offering valuable feedback, and to the Upwork annotators for their hard work. This project was partially supported by awards IIS-2202506 and IIS-2046248 from the National Science Foundation (NSF) as well as an award from Open Philanthropy. We also thank the NSF's CloudBank program for supporting the majority of our LLM API-based experiments.\\n\\nREFERENCES\\n\\nGriffin Adams, Alexander Fabbri, Faisal Ladhak, Eric Lehman, and No\u00e9mie Elhadad. From sparse to dense: GPT-4 summarization with chain of density prompting, 2023.\\n\\nShuyang Cao and Lu Wang. Awesome: GPU memory-constrained long document summarization using memory mechanism and global salient content, 2023.\\n\\nKent K. Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. Speak, memory: An archeology of books known to chatGPT/GPT-4, 2023.\\n\\nArman Cohan, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli Goharian. A discourse-aware attention model for abstractive summarization of long documents. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pp. 615\u2013621, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-2097. URL https://aclanthology.org/N18-2097.\\n\\nYao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, and Yejin Choi. Is GPT-3 text indistinguishable from human text? Scarecrow: A framework for scrutinizing machine text, 2022.\\n\\nYann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. AlpacaFarm: A simulation framework for methods that learn from human feedback, 2023.\\n\\nAlexander R. Fabbri, Wojciech Kr\u00f3wczy\u0144ski, Bryan McCann, Caiming Xiong, Richard Socher, and Dragomir Radev. Summeval: Re-evaluating summarization evaluation. arXiv preprint arXiv:2007.12626, 2020.\\n\\nPatrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, Jonathan H. Clark, Markus Freitag, and Orhan Firat. The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation, 2023.\\n\\nMarkus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. Experts, errors, and context: A large-scale study of human evaluation for machine translation. Transactions of the Association for Computational Linguistics, 9:1460\u20131474, 2021. doi: 10.1162/tacl_a_00437. URL https://aclanthology.org/2021.tacl-1.87.\\n\\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. GPTScore: Evaluate as you desire. arXiv preprint arXiv:2302.04166, 2023.\\n\\nYang Gao, Wei Zhao, and Steffen Eger. SUPERT: Towards new frontiers in unsupervised evaluation metrics for multi-document summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 1347\u20131354, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.124. URL https://aclanthology.org/2020.acl-main.124.\\n\\nTanya Goyal and Greg Durrett. Annotating and modeling fine-grained factuality in summarization. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1449\u20131462, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.114. URL https://aclanthology.org/2021.naacl-main.114.\\n\\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. SNAC: Coherence error detection for narrative summarization, 2022a.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "7Ttk3RzDeu", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "7Ttk3RzDeu", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A DETAILS ON THE TWO PROMPTING STRATEGIES\\n\\nAssume an LLM with context window size $W$ is used to summarize an input document $D$ whose length $L \\\\gg W$. We thus split $D$ into non-overlapping chunks $c_1, c_2, \\\\ldots, c_{\\\\lceil L/C \\\\rceil}$ where $C < W$ is the length of each chunk.\\n\\nA.1 HIERARCHICAL MERGING\\nHierarchical merging works as follows:\\n\\n1. Obtain summaries at the base level $l = 0$ by summarizing each chunk.\\n2. Obtain summaries for the first level $l = 1$ by prompting the LLM to merge as many consecutive level-0 summaries $s_i, s_{i+1}, \\\\ldots$ as possible such that the total length of the merging prompt, the selected summaries, and the prior context (if there exists a preceding summary at the same level) is less than $W - G_l$, where $G_l$ is a hyperparameter controlling summary length that varies depending on the level $l$.\\n3. Repeat the previous step recursively until we are left with a single summary for the book.\\n\\nA.2 INCREMENTAL UPDATING\\nIncremental updating works as follows:\\n\\n1. Feed the summarization prompt into the LLM along with the first chunk $c_1$ to obtain a summary of the first chunk, which initializes the global summary $g_1$.\\n2. Now, provide the LLM with the updating prompt, the next chunk $c_2$, and the current global summary $g_1$. The model is prompted to updating the global summary to $g_2$ with information from the current chunk.\\n3. Iterate through the remaining chunks. If $g_i$ exceeds the maximum summary length $G_n$, call the compression prompt to compress $g_i$ to fit within the length limit.\\n\\nSee Appendix A.2.1 for more details on compression.\\n\\nA.2.1 COMPRESSION\\nThe compression step is required for incremental updating. Through our experimentation, we have observed that as the model processes a book through incremental updating, it consistently adds more information to the running summary instead of removing things. Even with an updating prompt, the summary often surpasses the target length as removing content from it is not in the model's natural inclination. Thus, a separate prompt is needed for the model to condense the summary. However, in hierarchical summarization, condensing is not required. The merging step is less likely to run over the summary limit since it does not have to work with a pre-existing running summary. If the summaries generated during hierarchical merging go over the summary limit, simply asking the model to regenerate up to a fixed number of times would suffice.\\n\\nB DATASET DETAILS\\n\\nB.1 TABLE OF ALL BOOKS IN THE DATASET\\nSee Table 3.\\n\\n17 Wu et al. (2021) suggest that since independent chunk-level summarization might miss vital context from earlier sections of the story, we can mitigate this effect by joining as many preceding summaries from the same level as possible. We thus implement this approach in our method.\\n\\n18 As the final summary often contains artifacts like \u201cin the current segment\u201d or \u201cin this section\u201d, especially with weaker models, we included an additional post-processing prompt to clean up these artifacts. See Appendix M.3.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Title, author, genres, and publication date of all books in our dataset, sorted alphabetically.\\n\\n| Name                       | Author     | Genres                | Published     |\\n|----------------------------|------------|-----------------------|---------------|\\n| A Day of Fallen Night      | Samantha Shannon | fantasy, fiction, lgbt | 2023/02/28    |\\n| A Fever in the Heartland:  |            | fiction, mystery, thriller | 2022/05/12    |\\n| The Ku Klux Klan's Plot    | R. F. Kuang | contemporary, fiction, mystery, thriller | 2023/05/16 |\\n\\nTable 4 shows detailed results of the coarse-grained human evaluation as discussed in Section 5.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Results from coarse-grained human evaluation. Annotators compare 100 pairs of GPT-4 generated incremental and hierarchical summaries and judge (1) overall preference; (2) level of detail; (3) structure and pacing; (4) logic and understandability of each summary.\\n\\n| Preference | Incremental | Hierarchical | Tie |\\n|------------|-------------|--------------|-----|\\n| Overall    | 44          | 54           | 2   |\\n| Detail     | 83          | 11           | 6   |\\n| Structure  | 35          | 59           | 6   |\\n| Logic      | 38          | 53           | 9   |\\n\\nD.1 EXPERIMENT DETAILS\\n\\nWe use the LLaMA-2-7B-Instruct checkpoint fine-tuned on long-context summarization (BookSum). For Mixtral, we used the mistralai/Mixtral-8x7B-Instruct-v0.1 checkpoint hosted by the Together API. For closed-source models, we use the gpt-4 2023-03-15 and gpt-3.5-turbo-0301 checkpoints on Microsoft Azure. Anthropic unfortunately does not disclose checkpoint information, but our summaries were all obtained via their Claude 2 API in September 2023.\\n\\nIn our experiments, LLaMA 2 uses a context window size of 4096 tokens, while other models leverage their full context window. While generating LLaMA 2 hierarchical summaries, we have to truncate the results at the final punctuation mark. If not, the model would be stuck at the regeneration phase, as it does not follow the given word limit at all. In addition, for LLaMA 2 summaries, we do not apply post-processing as described in Appendix D.1, because it would significantly alter the structure of the LLaMA 2 summaries, thereby enhancing their coherence. Instead, we post-process the summaries using a standard string matching approach to get rid of sentences copied from the prompt. Without this step, we cannot evaluate them with GPT-4, since GPT-4 would treat these prompt artifacts as instructions rather than sentences to annotate.\\n\\nD.1 DATA PROCESSING DETAILS\\n\\nIn order to preserve all visual separators within the text, we extract all text elements from the epub files without further automatic processing. As a result, sometimes content from non-narrative sections would appear in the generated summaries. We apply simple post-processing by prompting GPT-4 to remove information coming from non-narrative sections of the book. The prompt can be found in Appendix M.3.\\n\\nE EXPERIMENTS WITH SQUALITY\\n\\nTo investigate the effect of incremental updating and hierarchical merging on summary coherence, we evaluated GPT-4 on the validation set of the SQuALITY dataset, which contains sci-fi stories that are 4000-6000 words long. Table 5 shows the ROUGE-L scores. The baseline setting is where the model summarizes the stories in one go, truncating the stories whenever they exceed the model's context window. Using incremental updating lowers ROUGE-L by a small amount, indicating that baseline summaries have slightly more overlap with the provided reference summaries. We will update the BOOKS of these summaries in the next version of the paper.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: ROUGE-L of summaries generated by GPT-4 on the SQuALITY validation set under two settings: baseline and incremental updating.\\n\\n| Chunk size | ROUGE-L |\\n|------------|---------|\\n| Baseline   | -14.9   |\\n| Incremental updating | 256 13.2 |\\n| Incremental updating | 512 13.7 |\\n\\nE.1 QUALITATIVE ANALYSIS\\n\\nWe show the baseline, incremental, and human summaries for Venus Is a Man's World from SQuALITY in Table 6. The incremental summary was generated by GPT-4 with a chunk size of 512.\\n\\nThe baseline summary provides the most coherent and comprehensive overview of the story's key events and themes. It clearly introduces the main characters - Ford, Evelyn, and Butt - and their backgrounds, while succinctly summarizing the plot including Ford's friendship with Butt, Evelyn's discovery and confrontation, and Butt's unconventional marriage proposal. The summary highlights central conflicts related to gender roles and norms. In contrast, the incremental summary, while touching on similar plot points and themes, does so in a more disjointed, less cohesive manner. Details about the setting, dunging drug harvesting, and weaponry feel redundant. Finally, the human summary lacks clarity in many parts, with confusing references to the Male Desuffrage Act and inconsistent character details. It focuses heavily on the early parts of the plot at the expense of later key events.\\n\\nOverall, our finding that GPT-4 summaries can be better than human summaries aligns with results from recent work on LLM-based short-document summarization (Pu et al., 2023b). The qualitative analysis shows that methods like incremental updating could introduce coherence errors into LLM-generated summaries.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Summaries of William Tenn\u2019s *Venus Is a Man\u2019s World*.\\n\\n**Baseline**\\n\\n**Incremental updating**\\n\\n**Human**\\n\\n*Venus Is a Man\u2019s World* is a story about a young boy named Ferdinand, or \u201cFord,\u201d and his sister Evelyn, who are traveling on a spaceship called the Eleanor Roosevelt to the planet Venus. Evelyn is seeking a husband on Venus, as there is a shortage of men on Earth due to wars and other factors. Ford, curious and adventurous, explores the ship and stumbles upon a stowaway named Butt Lee Brown, a Venusian farmer who had gotten into trouble on Earth and is now hiding in a lifeboat.\\n\\nFord and Butt form a bond, with Butt teaching Ford about Venusian culture, songs, and even politics. Ford starts to admire Butt\u2019s strong, independent nature and begins to question the Earth\u2019s female-dominated society. However, when Evelyn discovers Ford\u2019s friendship with Butt, she confronts the stowaway, accusing him of corrupting her brother\u2019s morals and breaking the law by stowing away on the ship.\\n\\nButt, unfazed by Evelyn\u2019s accusations, proposes marriage to her, stating that they are both on the same journey to find a partner and that she has the qualities he is looking for in a wife. Ford excitedly urges his sister to accept Butt\u2019s proposal, but the story leaves the outcome of this unconventional proposal unresolved. The story highlights the clash of gender roles, societal norms, and the challenges faced by individuals seeking love and companionship in a rapidly changing world.\\n\\nIn the story, siblings Ford and Evelyn from an underwater city accompany women seeking husbands on a journey to Venus. Ford befriends stowaway, Butt Lee Brown, who has a troubled past. They bond over their life stories as Butt educates Ford about Venusian culture and weaponry. Despite being outsiders, they travel together.\\n\\nEvelyn convinces Ford to attend a geography lecture, where she becomes deeply engaged in the discussion of illegal dunging drug harvesting on the Macro Continent. Ford\u2019s knowledge of dunging and the Venusian term \u201cPaddlefoot\u201d piques Evelyn\u2019s interest. Ford argues that Venusians are pioneers who need strong, independent men for building a civilization on the new planet, thus intriguing Evelyn.\\n\\nFord takes Evelyn to meet Butt Lee Brown, making her promise not to turn him in. Upon meeting, Evelyn confronts Butt about his illegal activities and moral delinquency. Butt dismisses her concerns, sparking a debate between them about Earth and Venusian societies. During their conversation, Butt proposes to Evelyn, stating that they both have similar goals in finding a spouse and that she possesses qualities he finds desirable. Evelyn is taken aback by the proposal, and her brother Ford excitedly encourages her to accept.\\n\\nThe story continues to explore the characters\u2019 relationships and their differing perspectives on the new planet, as well as the potential consequences of their actions and decisions.\\n\\nTo explore the impact of summary length on BBOOOKSCORE, we plot BBOOOKSCORE vs. length in Figure 3 for the 100 summaries generated by GPT-4 with incremental updating using a chunk size of 2048. The plot indicates that there is no discernible correlation between length and BBOOOKSCORE.\\n\\n**G BOOTSTRAPPING ANALYSIS OF BBOOOKSCORE**\\n\\nTo check the stability of the BBOOOKSCORE metric, we ran a bootstrapping experiment. Given the BBOOOKSCORE of 100 summaries generated by GPT-4 using incremental updating with a chunk size of 2048, we randomly sample 1000 times with replacement using a sample size of 100, then compute the mean of these 1000 samples. The standard deviation of these samples is 0.015, which suggests that BBOOOKSCORE is consistent and reliable across multiple random samples.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Distribution of all error types for incremental and hierarchical summaries generated by GPT-4, normalized by the total number of sentences in the summaries.\\n\\nIn our approach to GPT-4 automatic evaluation, we incorporate error type prediction into the prompt to assist the model in making reasoned judgments. We analyze the label-wise correlation between GPT-4 and human annotations, presenting the results in Figure 4. Despite the high agreement between precision as discussed in Section 4.1, GPT-4's error distributions vary significantly from those of human annotations. GPT-4 demonstrates a strong propensity for labeling omission errors, occasionally applying these labels to sentences that could be more appropriately categorized under different error types. In this study, we have not delved deeper into the error types predicted by GPT-4 given the observed inaccuracy. Further analysis of GPT-4's capability to precisely predict error types remains a potential area for future research.\\n\\n### Effectiveness of Existing Reference-Free Evaluation Metrics\\n\\n| Model                  | BLANC | SUPERT |\\n|------------------------|-------|--------|\\n| GPT-4 (4096)           | 0.0248| 0.3627 |\\n| GPT-4 (2048)           | 0.0221| 0.3615 |\\n| GPT-3.5-Turbo (2048)   | 0.0203| 0.3658 |\\n| Claude 2 (88000)       | 0.0171| 0.3490 |\\n| Claude 2 (2048)        | 0.0167| 0.3559 |\\n| Mixtral-8x7B (2048)    | 0.0169| 0.3836 |\\n| LLaMA2-7B-Inst (2048)  | 0.0130| 0.3446 |\\n\\nWe investigate how well existing reference-free evaluation metrics work for our setting where the source text is at book level. BLANC (Vasilyev et al., 2020) measures how helpful a summary is to understanding the source document by testing if a pre-trained model can better fill in masked words given access to the summary. SUPERT (Gao et al., 2020) measures the semantic similarity between the summary and some pseudo reference summaries generated from the source document. We compute both metrics for hierarchical summaries generated under all configurations, and show results in Table 7. Both BLANC and SUPERT differ by nearly negligible margins across models, which makes them less meaningful. Furthermore, both metrics rate Claude 2 (88000) summaries as inferior to GPT-3.5-Turbo (2048) summaries, a finding that clearly contradicts results from our qualitative analysis.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: To perform book-length summarization, we first divide a book into smaller chunks that fit within the context window of an LLM. Then, we explore two strategies for summarization: (1) hierarchical merging, in which chunks are first summarized and then the corresponding summaries merged via separate prompts; and (2) incremental updating, in which a global summary is updated and compressed as we step through the book chunk-by-chunk.\\n\\nMore specifically, both strategies assume an LLM with context window size $W$ is used to summarize an input document $D$ whose length $L \\\\gg W$. We thus split $D$ into non-overlapping chunks $c_1, c_2, \\\\ldots, c_{\\\\lceil L/C \\\\rceil}$ where $C < W$ is the length of each chunk.\\n\\nHierarchical merging: Wu et al. (2021) propose a method in which an LLM (in their case, GPT-3) is fine-tuned via reinforcement learning to summarize each chunk and then hierarchically merge the chunk-level summaries until one summary is left of the entire input document. This method has since been simplified into a zero-shot prompting strategy without further training, as shown in Figure 1 (left). Hierarchical merging requires three unique prompts for (1) summarizing an input chunk, (2) merging chunk-level summaries, and (3) merging summaries with added context from previously-generated merged summaries. We ensure that the total length of each prompt and its associated inputs is less than $W - G_l$, where $G_l$ is a hyperparameter controlling summary length that varies depending on the level $l$. Summaries are recursively merged until only one summary (of the full book) remains; see Appendix A.1 for further details.\\n\\nIncremental updating: It is possible that since hierarchical merging necessitates summarizing portions of the input document without complete context, it may introduce more coherence errors. For example, in the first level, chunks towards the end of the book will be summarized without knowledge of what came before, which can lead to incoherent summaries especially for non-linear or multi-perspective narratives. We thus explore an alternate prompting strategy\u2014incremental updating (Figure 1, right)\u2014that iterates through each chunk in order while continuously updating a global summary with salient information. While this method may be better able to handle inter-chunk dependencies than hierarchical merging, it requires more complicated prompts for (1) summarizing an input chunk, (2) updating the global summary $s_1, s_2, \\\\ldots, s_{i-1}$ with information from the current chunk $c_i$, and (3) compressing the global summary when it exceeds the maximum summary length $G_n$. See Appendix A.2 for a full specification of incremental updating.\\n\\n3 EVALUATING COHERENCE OF BOOK SUMMARIES\\n\\nIn this section, we define our framework for human evaluation of coherence errors in book-length summarization. Our framework involves: (1) corpus collection focusing on newly-published books, (2) unification and extension of best-practices from prior document understanding and evaluation literature to guide data annotation, and (3) analysis of human annotations centered around emergent coherence error categories of summaries generated by modern LLMs.\\n\\n2 We ensure each chunk ends at a sentence boundary.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Collecting a corpus of newly-published books.\\n\\nThe only existing public dataset for book-length summarization is BookSum (Kryscinski et al., 2022), which contains famous books from the Project Gutenberg public-domain repository along with reference summaries scraped from popular websites such as CliffNotes and GradeSaver. Both the source books and reference summaries are in the pretraining data of existing LLMs: Chang et al. (2023) confirm that many books in the BookSum held-out split (e.g., *The Adventures of Huckleberry Finn*, *The Picture of Dorian Gray*) are among the most-memorized books by GPT-4 and GPT-3.5-Turbo, and we were able to auto-complete several reference BookSum summaries by prompting GPT-4 with a short prefix of the summary.\\n\\nTo reduce the confounding impact of summary memorization, we manually collect 100 books published within the past year to form our dataset (see Table 3 for a full list). Some of these books could still have appeared in the pretraining dataset of recent LLMs such as Claude 2 and LLaMa2, although it is much less likely than in BookSum. However, summaries of these books do not publicly exist: we did not find summaries online for any books in our dataset, which significantly lowers the possibility of LLM memorization. The average length of the books in our dataset is 190K tokens, compared to 112K tokens in BookSum. Due to copyright laws, we cannot publicly release this dataset; even if we could, we would still recommend that researchers collect their own datasets of newly-published books to minimize contamination with LLMs of the future.\\n\\nAn evaluation framework for book-length summarization.\\n\\nSince we lack gold summaries, we design our evaluation framework to be reference-free, which aids in scalability. To do this, our evaluation framework synthesizes best-practices of prior document understanding and summarization evaluation research. Our evaluation employs: (1) fine-grained evaluation units as recommended by LongEval (Krishna et al., 2023); (2) information-seeking questions to represent naturally-occurring points of confusion (Ko et al., 2020; Wu et al., 2023; Meng et al., 2023; Newman et al., 2023); and (3) focus on summary coherence, which evaluates the logical structure and readability of the summary itself (Goyal et al., 2022a). We do not directly evaluate the faithfulness of the summaries (i.e., how factually accurate they are at conveying information from the source text), as the length of the source texts poses considerable issues for any existing faithfulness evaluation. We qualitatively discuss faithfulness in Section 5 and leave further investigation for future work.\\n\\nAnnotation protocol.\\n\\nWe implement our framework through a source- and reference-free annotation protocol where (1) annotators read through an LLM-generated summary, (2) highlight all confusing spans, and (3) ask question(s) for each marked span that highlight their confusion. See Table 1 (third column) for examples of spans and questions produced by our annotators. We hired four annotators with extensive English proofreading experience on Upwork, each of whom annotated 25 disjoint summaries. Each summary takes roughly 30 minutes to fully annotate with spans and questions, and we paid $15 USD per summary for a total of $3K to evaluate both prompting strategies. To generate the summaries, we set the base LLM to GPT-4 with a chunk size of 4096 and a maximum summary length $G_n = 1200$; other hyperparameters are detailed in Section 5. In total, the annotators mark 840 (incremental updating) and 353 (hierarchical merging) coherence errors for GPT-4-generated summaries; see Table 1 (right) for the split across error types.\\n\\nValidating the annotations:\\n\\nTypical measures of agreement are difficult to obtain in our setup, as measuring recall would require ground truth annotations with all possible coherence errors in the summaries; additionally, Goyal et al. (2022a) and Dou et al. (2022) observed low recall among annotators when evaluating machine-generated text at a fine-grained level. This motivates us to instead measure the precision of a given error annotation (i.e., after reading the corresponding question, do you agree that the span is confusing?), as it is simpler and cheaper while still being an informative metric. Given a span from a summary marked as containing an error, along with questions highlighting the confusion, we ask annotators (1) whether they think the span is confusing; and (2) whether the corresponding questions highlight the central confusion. We use the same four annotators hired before for this task, but make them validate human and (and later GPT-4) annotations for 25 books that they did not annotate in the first task. Overall, we validated 1,659 annotations for a total cost of 3K.\\n\\nWe roughly balance our dataset across the following genres: fiction, non-fiction, sci-fi, fantasy, historical, contemporary, and memoir. We also include both linear and non-linear (multi-perspective and time-shifting) narratives in the dataset, and we purchase electronic copies of each of the 100 books in the dataset. However, we did find book reviews, which intentionally do not reveal major plot points or other spoilers. We also enabled forming relations between two spans in case multiple spans contributed to the same issue.\\n\\nhttp://upwork.com\"}"}
{"id": "7Ttk3RzDeu", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Definition of all coherence error types, an example annotation for each, and their prevalence (%) in generated summaries, which is calculated as the number of error occurrences in all summaries normalized by the total number of sentences in all summaries.\\n\\n| Error Type Definition | Example spans & questions | % errors per sentence |\\n|-----------------------|---------------------------|-----------------------|\\n| Entity omission       | Span: A mysterious man introduces Proctor to \\\"Arrivalism.\\\" | 7.3 / 3.71 |\\n| Event omission        | Span: During a mission to find Caeli, Proctor is captured by watchmen while Thea escapes. | 4.25 / 2.27 |\\n| Causal omission       | Span: Proctor seeks answers from... Callista about the investigation. | 2.75 / 1.21 |\\n| Discontinuity         | Span: In the new settlement, Thea adjusts to her life, working hard and finding solace in nature. | 2.23 / 1.56 |\\n| Salience inclusion    | Span: His father... flees, resulting in a chaotic chase on the pier. | 1.42 / 1.03 |\\n| Language errors       | Span 1: Despite her love for him, Deborah is heartbroken by his decision. | 0.82 / 0.71 |\\n| Inconsistency         | Span: In a farewell, Proctor marries his brother Malcolm to Cynthia and says goodbye to his loved ones. | 0.97 / 1.03 |\\n| Duplication           | Span 1: Proctor... deals with students and school issues, seeking help from Callista to fund a roof replacement. Span 2: Proctor's life continues as he... deals with school issues, such as funding for a roof replacement. | 2.12 / 1.18 |\\n\\n$418.90 (USD), and we discover that 79.7% of annotated spans are validated as legitimate through this task. More details on our validation can be found in Appendix J.\\n\\nCategorizing coherence errors: After collecting spans and questions from the annotators, we develop an error taxonomy consisting of the eight types detailed in Table 1, which covers the vast majority of annotations, and we manually code each annotation using this taxonomy. We intentionally went through this process without relying on the SNaC taxonomy (Goyal et al., 2022a) so as to not be overly influenced by their error annotation schema which was tailor-made for fine-tuned summarization models. While we find considerable overlap in the two error schemas, we also discover two new instances of prominent errors not present in SNaC: causal omissions and salience issues.\\n\\nOur taxonomy also places less emphasis on language errors (e.g. coreference issues from SNaC) since modern LLMs rarely make such mistakes (Goyal et al., 2022b). Table 1 shows that omission errors are the most common across both incremental and hierarchical prompting strategies, and also that hierarchical merging makes fewer errors of every type but inconsistencies.\\n\\nSince human evaluation of summary coherence is not scalable due to the high financial and time cost, we develop an automatic metric \u2014 BOOOKS \u2014 that prompts an LLM to identify instances of the eight error types we identified in Section 3. We validate BOOOKS via a human evaluation of its precision (following the annotation task discussed in the previous section) and show that its precision matches that of human annotators (78.2% vs. 79.7%). We then use BOOOKS to evaluate many other book-length summarization configurations, saving $15K USD in evaluation costs and 500 hours in annotator time. We emphasize that incorporating definitions and examples from our error taxonomy into the prompt is critical to achieve high precision with BOOOKS.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Girl Called Samson is a historical fiction novel set in the early 1800s, following the life of Deborah Samson, a young girl orphaned and sent to live with Widow Thatcher. She is later indentured to a man named Robert Shurtleff, who becomes her mentor and helps her escape. Deborah eventually enlists in the Fourth Massachusetts Regiment as a private.\\n\\nDeborah navigates her complex relationships and the challenges of war. As one of the few women in the army, she faces discrimination and ridicule but also finds a sense of community and strength among her fellow soldiers. She forms close bonds with fellow soldiers, such as Phineas, and deals with mutinies from soldiers who are frustrated with the conditions and the war.\\n\\nDeborah also grapples with her feelings for General Paterson, as they journey together. Despite the difficulties and dangers of war, Deborah remains determined to prove her worth and keep her secret identity. She impresses General Paterson with her skills and is eventually granted a soldier's pension, acknowledging her courageous service. Throughout the story, Deborah grapples with her personal identity, and the struggle for freedom during the American Revolution.\\n\\nAfter the war, Deborah faces various challenges and the contradictions of fighting for freedom while slavery still exists in the colonies. She determines to pursue her dream, which is to have a family and a life of independence. Deborah disguises herself as a man named Robert Shurtleff and enlists in the Fourth Massachusetts Regiment to fight for freedom.\\n\\nDeborah's secret is eventually discovered by a few trusted individuals, including General Paterson and his aide, Agrippa Hull. Agrippa Hull continues to prove her worth and keep her secret. While working closely with General Paterson, Deborah becomes intrigued by the idea of Jeremiah, and is encouraged by Reverend Conant to engage in correspondence with his niece, Elizabeth. As the American Revolution unfolds, Deborah becomes interested in the idea of marriage and finding a man who values her for who she is, rather than her gender.\\n\\nThroughout her journey, Deborah forms close bonds with fellow soldiers, such as Phineas, and deals with mutinies from soldiers who are frustrated with the conditions and the war. She shares intimate moments and discusses her pasts, including her correspondence when she was still a girl. Deborah's secret is eventually discovered by a few trusted individuals, including General Paterson, who proposes marriage to her. They marry in Philadelphia, but Deborah struggles to maintain her secret identity while facing the hardships of independence and self-governance. Determined to pursue her dream, Deborah disguises herself as a man named Robert Shurtleff and enlists in the Fourth Massachusetts Regiment to fight for freedom.\\n\\nIn the end, Deborah's determination and courage lead her to a life of independence and self-governance. Despite facing challenges, Deborah and General Paterson build a new life together in Lenox, Massachusetts. Deborah also grapples with her feelings for General Paterson, as they make a plan for her to wait for John in Lenox once the war is over. Deborah eventually marries General Paterson, and they settle in Lenox, where Deborah works to improve living conditions and opportunities for women. She eventually becomes a soldier's pension receiver, acknowledging her courageous service.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of the given summary, and those which, if left unresolved, would make the summary highly incoherent or significantly hinder readers from understanding the main storyline. If you don't identify any confusion like that, simply say \\\"no confusion\\\" for both questions and types in your response.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 11: GPT-3.5-Turbo 2048 summaries of Janika Oza\u2019s \u201cA History of Burning\u201d.\\n\\n| Strategy | Summary |\\n|----------|---------|\\n| Hier     | \u201cA History of Burning\u201d by Janika Oza is a multi-generational story that follows the lives of Pirbhai, Sonal, and their children Vinod, Rajni, Mayuri, Kiya, Meetu, and Hari through displacement, cultural struggles, and personal tragedies. The novel is set during political unrest in Kenya and Uganda in the mid-twentieth century, where the family faces poverty and exploitation as migrant workers. Pirbhai leaves his family in India to work in Kenya, where he faces poverty and exploitation as a migrant worker. He is haunted by the guilt of leaving his family behind and is forced to make difficult choices, including burning down a cluster of abandoned huts. Pirbhai marries Sonal, and they start a family, facing financial struggles and the impact of colonialism. The story explores themes of poverty, desperation, and the harsh realities of migrant workers. The family faces political unrest and racial tensions in Uganda during the time of the country\u2019s independence from British rule. They are forced to leave Uganda due to the political instability caused by Idi Amin\u2019s regime. The story also delves into Mayuri\u2019s struggles as a medical professional facing discrimination in Toronto. The characters are motivated by their desire to protect their families and survive in a dangerous environment, with themes of family, resilience, and the challenges faced by immigrants in adapting to new cultures. The story follows their children, Vinod and Rajni, and their struggles with identity, cultural expectations, and displacement. The family\u2019s relationships and dynamics are explored, and their motivations and fears are hinted at. The family lives in Uganda during the time of the country\u2019s independence from British rule, and the story explores themes of grief, family, and tradition. Pirbhai and Sonal celebrate the birth of their third granddaughter, Kiya, and plan a picnic at the Botanical Gardens in Entebbe. The family faces political unrest and racial tensions, with Pirbhai\u2019s granddaughter Latika becoming involved in a resistance movement against tyranny. The story features non-linear narratives and flashbacks, with Pirbhai reflecting on his past and the consequences of his actions. The novel shifts between different characters\u2019 experiences, flashbacks, and tragedies, providing a rich and layered narrative. Specifically, the characters\u2019 past traumas, including the disappearance of Latika, add complexity to their struggles and sense of loss, while moments of triumph and fear reveal the human capacity for resilience and transformation. Beyond the family\u2019s personal struggles, the novel delves into themes such as community inclusivity, belonging, and solidarity. Despite the family\u2019s struggles, the story presents moments of hope and triumph, such as Vinod\u2019s dream of buying a house, and moments of uncertainty and fear, such as Hari\u2019s fall from a ladder. Ultimately, the story presents a nuanced and emotionally resonant portrait of immigrant life and the human capacity for resilience and transformation. The setting is in Uganda, Kenya, and Canada, and the story highlights the importance of family, resilience, and the challenges faced by immigrants in adapting to new cultures. The characters are motivated by their desire to protect their families and survive in a dangerous environment. The story presents a consistent and chronological narrative, despite featuring non-linear narratives, flashbacks, and switches between alternate worlds or viewpoints. In conclusion, \u201cA History of Burning\u201d is a complex and emotionally resonant story that explores themes of family, resilience, displacement, and the challenges faced by immigrants in adapting to new cultures. The story follows the lives of Pirbhai, Sonal, and their children through political unrest, racial tensions, and personal tragedies. Despite the family\u2019s struggles, the story presents moments of hope and triumph, ultimately presenting a nuanced and layered portrait of immigrant life and the human capacity for resilience and transformation. |\\n\\nInc\\n\\n\u201cA History of Burning\u201d follows the lives of nine family members over a century, exploring the importance of knowing one\u2019s history and family lineage to achieve a greater understanding of personal identity. The novel emphasizes the significance of community and belonging, while also considering who is included and excluded in these spaces. Food plays a pivotal role in placemaking and finding one\u2019s way into new understandings of home and belonging. The protagonist of the novel is the family itself, and the choice of whose voice to enter for specific moments was often intuitive. Vinod\u2019s health is declining, and he suffers a stroke. His family worries about him, and Rajni struggles with memories of the past, including the secret of her lost daughter, Latika. Mayuri and Kiya tell Hari and Meetu about their lost sister, and they all eat cake together. Hari confides in Sol about his boss accusing him of stealing tips, and they start playing basketball together. While Hari marches in a protest with Solomon, Marcus, and Sami, the protest becomes violent, and Hari is blinded by a searing fog. He stumbles on, trying to feel his way unseeing over whose streets. Hari yells out the names of his family, who have come and gone, and sees visions of a body huddled in a dank chamber, a tree blooming red as flame, and a boat dimly bobbing across black waters. The chemical fog hangs like a white sheet in the night sky, and Hari opens his eyes to see the destruction around him. He runs home, and his family is relieved to see him. Later, Vinod and Rajni meet with a woman on a rocky outcropping off the shore. They recognize each other and speak of people remote and unknowable as the land before the water. The woman has traveled far, and yet in all the movement, a part of her feels restored. Encircled by her family, she knows that she has come not just forward, but also back. When their conversation falters, they take in the stillness around them, how the waves make silence with sound. They let the tide crest over their feet and remember what the water has carried and what it has swallowed. The man slips a little on a rock slick with algae, and the woman rights him in a gesture unpracticed and natural. They recall losses that they cannot know. Beyond them, the tide continues. The water shifts the sand, reassembles the shells, sucks the stones to pebbles. The waves break and mend, break and mend.\u201d\"}"}
{"id": "7Ttk3RzDeu", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 12: Claude 2048 summaries of Janika Oz's *A History of Burning*.\\n\\n**Strategy**\\n\\n**Summary**\\n\\nThe novel follows an Indian family across multiple generations, beginning in late 19th century India when the patriarch Pirbhai boards a ship to Africa seeking work. Tricked into indentured labor in Africa, Pirbhai endures difficult conditions building the Uganda Railway. Years later in 1902, his granddaughter Sonal notices the strong arms of an Indian laborer, Pirbhai, who comes asking for work at her father's shop in Nairobi. Sonal develops an interest in Pirbhai, who remains quiet about his traumatic past.\\n\\nThe story shifts to 1917, where Sonal is now a married woman with two daughters, living in Kampala, Uganda. Her husband Pirbhai insists on sending money to his aging mother in India, while Sonal resents having another child amidst financial struggles. In the 1940s, their daughter-in-law Rajni secretly poisons her husband Vinod to make him too ill for military conscription during World War II, afraid he will die in combat.\\n\\nYears later, another descendant, Latika marries a local activist named Arun, against her parents' wishes. During political turmoil in the 1960s, Arun is imprisoned for sedition. Latika flees Uganda for London, abandoning their infant son. Decades later, Latika's sister Mayuri arranges her son Hari's marriage to a woman named Rajni, keeping secret that Rajni is actually Latika's daughter-in-law. In the 1970s, President Idi Amin expels Asians from Uganda, forcing the family to scatter across continents. They lose their home, bonds, and history in the upheaval.\\n\\nIn 1980s Canada, Rajni and Vinod struggle to assimilate while hiding the truth about Hari's parentage. Hari feels disconnected from his family's silenced history. He grapples with fighting racism alongside friends versus fulfilling his duties to their shop and ill grandfather. When Hari finally learns about his mother Latika, he is furious over the lies. The family ruptures further when Latika mysteriously returns after 30 years, devastating Rajni.\\n\\nThey continue navigating the legacy of Latika's unexplained absence and the cultural erasure caused by their exile from Uganda. But glimmers of reconciliation emerge, as when Rajni and Vinod open a new shop providing community. Later, while caring for their bedridden grandfather, Hari realizes his family's perseverance outweighs the hidden past. Ultimately, Latika's return signifies the possibility of mending fissures left by displacement and secrecy. Spanning a tumultuous century, the epic novel conveys a family's resilience and quest for home and belonging amidst upheaval.\\n\\nRajni cared for her ailing husband Vinod after his stroke. Their adopted son Hari moved back in to help, though Rajni still felt distant from him after revealing his birth mother Latika was alive. Rajni heard warnings about potential violence at an upcoming protest rally, but let Hari decide to attend and support his marginalized community.\\n\\nRajni reflected on her family's complex history and relationships. She considered her daughters Kiya and Mayuri, who had tried in their own ways to heal family rifts. Rajni realized she had once been close with Hari and longed for that again. She thought of the connections between her family's struggles and those of other marginalized groups like Hari's friends. Rajni gained perspective on the importance of open communication to bring people together across divides.\\n\\nMeanwhile, Vinod slowly recovered, regaining mobility and strength. He woke up determined to become more independent. Vinod and Rajni both acknowledged their growing frailty, but continued supporting each other.\\n\\nVinod's daughters Kiya and Mayuri tended a community garden, bringing together neighbors and friends. Though facing opposition, Kiya was inspired by her ancestor's vision of a shared place welcoming to all. She hoped the garden could be part of creating an inclusive home.\\n\\nLatika had told them the story of how their grandfather Vinay ripped up homes and displaced communities when building the Ugandan railway. Vinod now reflected on his father's complex legacy and motivations. Despite their troubled relationship, he empathized with Vinay's desire for security and belonging. Vinod realized he himself had fought hard to establish a home in Canada, sometimes neglecting to appreciate what he had. Now physically weakened but gaining perspective, Vinod hoped to find contentment.\\n\\nHari went to the protest rally downtown with his friend Solomon and others. As the peaceful protest ended, tensions rose between protesters and police. Chaos broke out, with violence erupting on both sides. Police barricaded the protesters, using tear gas and force to disperse them. In the confusion, Hari lost sight of Solomon and the others. Blinded by the tear gas, Hari desperately tried to find his way and reconnect with his friends during the fray.\\n\\nRajni and Vinod went searching for Hari during the chaotic protest. In their confusion amidst the clashes, they struggled to find their way home. Fortunately their daughter Meetu arrived and helped guide them back, reuniting with the rest of the family. They returned home to find their shop had been destroyed in a fire during the fray. Though devastated, the family drew strength from one another, committed to rebuilding together.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Strategy\\n\\nIn 1972 in Uganda, Latika and Arun, an Indian couple with a baby son named Harilal, receive a mysterious letter delivered by a young Ugandan soldier. The country is under the dictatorship of Idi Amin, who has ordered all Asians to leave Uganda within 90 days. Latika hides the letter from Arun and reads it alone, discovering it is an order from Amin to immediately stop publishing their underground newspaper Jicho, which has been printing anti-government articles. Latika has secretly kept the paper going against Arun's wishes, as he argues it endangers their family while she believes justice is more important than their personal safety.\\n\\nLatika hides the letter out of fear of Arun's reaction and thrill at the power it places in her hands, as the soldier assumed Arun was in charge, not realizing she runs Jicho. Her secrecy over the paper and letter signals a rupture in trust between them, as Arun wants to protect his family but Latika is singleminded in her activism, sparking conflict in their marriage.\\n\\nWith the expulsion order, this clash between family and justice becomes increasingly fraught.\\n\\nThe story then jumps ahead to 1992 in Canada, where Rajni and Vinod are searching at night for their missing son Hari after a protest rally turned violent. They find their daughters Mayuri, Kiya and granddaughter Meetu waiting, but Hari is still missing. Earlier that day, Hari went to the rally despite his family's concerns. His friend Solomon was also there. When police arrived, tear gas was released and protesters fled as confrontations broke out. Hari lost Solomon in the chaos.\\n\\nUnable to find Hari, Rajni realizes they should go home, as home is where her family is, not any physical place. Just then, Mayuri spots them and brings them to their shop, which has been set on fire during the unrest. As the family watches the burning shop, Hari appears, having made his way back alone. Angry they are just standing there, he wants to try saving the shop, but Rajni says calmly it's done; they know how to rebuild. Vinod agrees, saying now is the time to rest.\\n\\nThe fire destroys the shop but leaves the ground ready for something new. Hari realizes his family has persevered, almost whole. Though they will have to start over with the shop gone, they will insist on something better next time rather than accept injustice. Rajni reflects on how they have migrated from India to Africa to Canada, realizing anywhere can feel like home if her family is together. After so much loss, they made it here united. While the shop is destroyed, their family remains strong.\\n\\nIn summary, the story spans 20 years and two families, exploring how broader political conflicts intertwine with and impact family relationships. In 1970s Uganda, rising political tensions strain the marriage of activists Latika and Arun as they clash over family versus justice. Two decades later in 1990s Canada, the family of Rajni and Vinod draw closer amidst violent unrest, losing their shop but keeping their bond intact. Despite different places and contexts, both families experience the complex dynamics between individual ideals, family ties, and turbulent political realities. Ultimately they share the resilient hope that as long as their family is together, they have arrived home.\\n\\nIn 1972, Latika and her husband Arun live in Kampala, Uganda with their baby son Harilal. Latika runs an underground newspaper called Jicho with her friend Daniel, who has recently disappeared likely due to being critical of dictator Idi Amin's regime. On the morning of August 4th, Amin declares over the radio that Asians must leave Uganda within 90 days. Latika's family is in shock, trying to understand if they will be impacted as Ugandan citizens. Her sister Mayuri is away studying medicine in India. Latika's father Vinod goes to pray at the temple and sees a dead body in the river, then finds a copy of Jicho which he destroys out of fear.\\n\\nThe family spends days waiting in endless lines to try to get paperwork to leave, selling possessions, and being humiliated by soldiers. Latika's parents are unable to secure clearance to leave yet. One day, soldiers line up and shoot Asians on the street, but Vinod is spared because he has a red mark on his forehead from praying. He sees his childhood friend Moses, now a soldier, who lets him go.\\n\\nMeanwhile, a soldier delivers a letter to Latika ordering her to cease publication of Jicho, but she hides it from Arun. As the deadline to leave looms, Latika reflects on her tense relationship with Arun over her activism and thinks about why she chose him. She resolves to continue publishing the banned paper in secret, seeing it as the purpose of her life.\\n\\nOn the night of September 9th, the eve of the expulsion deadline, soldiers break into Latika and Arun's apartment. They beat and arrest Arun while Latika screams and clings to their baby Harilal. The next day, Latika's parents and sister Kiya come to collect Harilal so they can flee the country together. But despite their pleas, Latika refuses to leave Kampala without Arun, entrusting them with caring for her son. Heartbroken, the family leaves Latika behind as they make their way to the airport and eventually resettle as refugees in Canada.\\n\\nNow alone in Kampala, Latika descends into despair searching for Arun. She publishes one final defiant issue of Jicho before her supplies run out. An old friend named Adroa visits and is shocked to find Latika still there. Seeing the toll it has taken on her, he encourages Latika to leave Uganda and make a new life elsewhere. Latika finally resolves to do so, boarding a plane to London with the other remaining Asian refugees.\"}"}
{"id": "7Ttk3RzDeu", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 14: Mixtral 2048 summaries of Janika Oz's *A History of Burning*.\\n\\n| Strategy | Summary |\\n|----------|---------|\\n| Hier     | \\\"A History of Burning\\\" by Janika Oza is an intricate, multigenerational saga that explores themes of intergenerational trauma, resilience, identity, and colonial exploitation across time, spaces, and continents. The narrative spans from Jamnagar, Gujarat, to Kenya, Uganda, and Canada, weaving together the lives of several characters whose experiences intersect and diverge amidst political upheaval, personal sacrifices, and cultural expectations. The story begins in Jamnagar during a severe drought, where thirteen-year-old Pirbhai struggles to find work. Driven by his mother's encouragement, he embarks on a journey to Jamnagar and meets a mysterious merchant who leads him to work on a dhow sailing towards an unknown destination. Meanwhile, in Kenya, Sonal is a young Indian woman living with her family. When Pirbhai, now a refugee in Kenya, is employed by Sonal's father, the two form a deep bond as they navigate their lives together amidst political turmoil and personal sacrifices. Pirbhai's past unveils his harrowing experiences as an indentured laborer in East African colonies and the guilt he feels over the circumstances that led him to Kenya. Simultaneously, the narrative explores Sonal's losses, including her brothers who perished during migration, and her struggle to forge connections with her family and her new home. The narrative intertwines with Rajni's story during her migration from Uganda to Canada, following Idi Amin's expulsion of Asians from the country. Rajni, a resilient woman, grapples with her new life in a cold and foreign country while mourning the loss of her daughter, Latika. The lives of these characters continue to intersect and diverge in Toronto, revealing a rich tapestry of experiences, hopes, and triumphs despite the adversities they encounter. Other characters play significant roles in shaping the narrative. Vinod, an Indian immigrant, navigates cultural assimilation, identity, and family expectations in Canada. Kiya, Rajni's daughter, deals with her resentment towards her sister Mayuri, who left the family during their time of need. Hari, the Patels' son, and his friend Solomon grapple with the consequences of their actions during a protest against racism. Through the characters' experiences, the narrative explores the intricate connections between historical events and their impact on the characters' lives. From the struggles of poverty in Jamnagar, the brutal labor conditions in East African colonies, to the racial tensions and political turmoil in Uganda, the story emphasizes the power of resilience, human connections, and the complex nature of identity forged amidst shifting political alliances and dislocations. In Toronto, Kiya joins the army, and the family grieves after Latika's disappearance. Hari and Solomon confront the consequences of their actions during a protest against racism. The non-linear storytelling features past and present flashbacks, providing a rich context for the characters' experiences. Despite the non-linear narrative, the story ultimately presents a consistent and chronological account of the characters' lives and their struggles to forge a sense of belonging amidst adversity. In conclusion, \\\"A History of Burning\\\" is a compelling exploration of characters' lives woven together throughout history, emphasizing the profound power of resilience, human connections, and the complex nature of identity. By engaging with themes such as colonial exploitation, community, survival, and identity, the story forges a rich and imaginative world that touches on the lives of Pirbhai, Sonal, Rajni, Vinod, Kiya, Mayuri, and others, as they navigate across continents and navigate an intricate web of cultural expectations, personal sacrifices, and political upheaval. The story follows the Pirbhai family, whose roots lie in India but have ties to Kenya, Uganda, and now Canada. The family includes Rajni and Vinod, their sons Hari and the late Arun, daughter Mayuri, Rajni's uncle Nanu, reemerged sister Kiya, and her son Harilal. In 1991, Hari bonds with friends Marcus, Solomon, and Sami over shared experiences and basketball. He grapples with Arun's death and the revelation of a long-lost sister, Latika. The family unites to discuss Latika and commemorate Arun. Hari investigates the Ugandan Asian expulsion but discovers limited information. In 1992, Hari turns 19 and forms a close friendship with Marcus, Solomon, and Sami. Ignited by the Rodney King beating and the deaths of Raymond Lawrence and Michael Wade Lawson, he joins community protests, driven by his pursuit of justice and skepticism of official narratives. Together, they restore a vandalized local basketball court. Hari's reflections on family dynamics lead him to play basketball with Solomon instead of completing a report. Parallelly, Rajni navigates Vinod's deteriorating health while embracing his desire for privacy. Together, they face his physical decline. Rajni's past reemerges while she raises her concerns for Hari's safety during protests. She understands the importance of supporting their causes despite her fears and apprehensions. At the demonstration, Hari advocates for justice and unity. When tensions escalate, he gets separated from his friends. Rajni turns to prayer for Hari's safety, prompted by reminiscences of her past. Upon discovering Hari's disappearance, the family unites in searching for him. After the protest, disoriented and lost, Hari reconnects with his friends, who assist him in returning home. Aware of Hari's safety, the family reconvenes to make sense of the day's events, solidifying their unity and commitment to fighting for justice. The narrative intertwines Rajni, Hari, and their friendships as they confront their histories, find comfort in unity, and sustain their roots amid political strife. Acclaimed writers like Sharon Bala, Ngig) wa Thiong'o, and Gaiutra Bahadur enrich the storyline with dedicated support, historical context, and scholarship. Mentors and writing programs bolstered Hari's belief in his writing abilities. The Pirbhai family's story spans generations and continents, with each member experiencing their own trials and triumphs. They carry the weight of their family legacy and the history of their ancestors. Through it all, the family remains united, finding strength in their shared experiences and their commitment to fighting for justice and equality. The story emphasizes the importance of community, collectivism, and solidarity, inviting readers to reflect on who is included and excluded in their own spheres.\"}"}
