{"id": "DB3BH3arU2Y", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nGalileo Namata, Ben London, Lise Getoor, Bert Huang, and U Edu. Query-driven active surveying for collective classification. In 10th International Workshop on Mining and Learning with Graphs, volume 8, pp. 1, 2012.\\n\\nLawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford InfoLab, 1999.\\n\\nPrithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93\u201393, 2008.\\n\\nMurat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. Advances in neural information processing systems, 31, 2018.\\n\\nOleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G\\\"unnemann. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868, 2018.\\n\\nMaximilian Stadler, Bertrand Charpentier, Simon Geisler, Daniel Z\\\"ugner, and Stephan G\\\"unnemann. Graph posterior network: Bayesian predictive uncertainty for node classification. Advances in Neural Information Processing Systems, 34:18033\u201318048, 2021.\\n\\nXujiang Zhao, Feng Chen, Shu Hu, and Jin-Hee Cho. Uncertainty aware semi-supervised learning on graph data. Advances in Neural Information Processing Systems, 33:12827\u201312836, 2020.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"In Figures 2\u20138, we provide the visualization of different split strategies for all the datasets. Some graphs have multiple connected components \u2014 in that case, we keep only the largest one.\\n\\nFigure 2: Visualization of data splits for CoraML dataset: ID is blue, OOD is red.\\n\\nFigure 3: Visualization of data splits for CiteSeer dataset: ID is blue, OOD is red.\\n\\nFigure 4: Visualization of data splits for PubMed dataset: ID is blue, OOD is red.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nFigure 5: Visualization of data splits for AmazonComputers dataset: ID is blue, OOD is red.\\n\\nFigure 6: Visualization of data splits for AmazonPhoto dataset: ID is blue, OOD is red.\\n\\nFigure 7: Visualization of data splits for CoauthorCS dataset: ID is blue, OOD is red.\\n\\nFigure 8: Visualization of data splits for CoauthorPhysics dataset: ID is blue, OOD is red.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This section provides a detailed analysis and comparison of the proposed distribution shifts. For this purpose, we consider three representative real-world datasets: AmazonComputers, CoauthorCS, and CoraML, and discuss how different distribution shifts affect the basic properties of data: class balance, degree distribution, and graph distances between nodes within ID and OOD subsets.\\n\\nClass balance\\n\\nClass balance directly affects the amount of evidence acquired by the graph processing model and used for estimating uncertainty and making predictions. It is especially important for evaluating Dirichlet-based models which exploit Normalising Flows, as their density estimates can become irrelevant due to a significant change in class balance.\\n\\nIn Figures 9\u201311, one can see that neither feature-based nor PageRank-based split makes a notable difference in the class balance between the ID and OOD subsets. At the same time, the PPR-based split leads to significant changes for some classes. This shows that the split strategies based on the structural locality in a graph can be very challenging as they also affect such crucial statistics as class balance. Interestingly, the PageRank-based split does not lead to significant shifts of class balance (for the datasets under consideration), i.e., the more important and less important nodes have, on average, the same probability of belonging to a particular class.\\n\\nDegree distribution\\n\\nThe node degree distribution is one of the basic structural characteristics of a graph that describes the local importance of nodes. Degrees are especially important for such graph\"}"}
{"id": "DB3BH3arU2Y", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"processing methods as GNNs, since they describe how many channels around the considered node are used for message passing and aggregation.\\n\\nIn Figures 12\u201314, one can see that the most significant change in the degree distribution appears when the ID and OOD subsets are separated based on PageRank: the ID part contains more high-degree nodes. This is expected since PageRank is a graph characteristic measuring node importance (a.k.a. centrality), and node degree is the simplest centrality measure known to be correlated with PageRank. For PPR-based splits, the difference in degree distribution is smaller but still significant since PPR selects nodes by their relative importance for a particular node, so some high-degree nodes can be less important in terms of PPR. Finally, for features-based splits, the degree distribution also changes, but the shift level is much less significant.\\n\\nDistribution of pairwise distances\\n\\nThe distance between two nodes in a graph is defined as the length of the shortest path between them. Here, we compute such distances between the nodes in the ID or OOD subset within the original graph, i.e., we consider the whole graph when searching for the shortest path. The distribution of distances shows how easily messages can be passed between the nodes. Therefore, we expect that larger pairwise distances create more complicated tasks.\\n\\nIn Figures 15\u201317, one can observe that the PPR-based split leads to the most significant changes in distances, making the OOD nodes nearly twice as far from each other as the ID ones. At the same time, the PageRank-based split does not lead to such a difference, revealing almost the same distributions on ID and OOD subsets. This means that the popularity bias in a graph does not prevent one...\"}"}
{"id": "DB3BH3arU2Y", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"from covering the less popular periphery nodes since the most popular nodes may be widespread.\\n\\nFinally, the feature-based split preserves the distances within the subsets.\\n\\n**Comparison with Good Benchmark from Gui et al. (2022).** Our work complements and extends the GOOD benchmark recently proposed by Gui et al. (2022). However, there are several important differences that we discuss in this section.\\n\\nOne of the main properties of the GOOD benchmark is its theoretical distinction between two types of distribution shifts, which are represented through a graphical model. In particular, the authors consider covariate shifts, in which the distribution of features changes while the conditional distribution of targets given features remains the same, and concept shifts, where the opposite situation occurs, i.e., the conditional target distribution changes, while the feature distribution is the same.\\n\\nAlthough this distinction might be very helpful for understanding the properties of particular GNN models, such exclusively covariate or concept shifts rarely happen in practice where both types of shifts are present at the same time.\\n\\nTo create pure covariate or concept shifts, Gui et al. (2022) introduce different subsets of variables that either fully determine the target, create confounding associations with the target, or are completely independent of the target. This has to be properly handled and makes it non-trivial to create distribution shifts on new datasets with this approach. Indeed, the distribution shifts in the GOOD benchmark can be properly implemented only for synthetic graph datasets or via appending synthetic features that either describe various domains as completely independent variables or create confounding associations with the target.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the necessary concepts by inducing some spurious correlation with the target. Moreover, the authors claim that, in the case of real-world datasets, one has to perform screening over the available node features to create the required setup of domain or concept shift. This fact implies numerous restrictions on how the data splits can be prepared.\\n\\nIn contrast, our method does not make a distinction between covariate and concept shifts and thus can be universally applied to any dataset and does not require any dataset modifications. Importantly, the type of distribution shift and the sizes of all split parts are easily controllable. This flexibility is the main advantage of our approach.\\n\\nFinally, Gui et al. (2022) confirm the importance of using both node features and graph structure. Still, their node-level distribution shifts are usually based on node features such as the number of words or the year of publication in a citation network, the language of users in a social network, or the name of organizations in a webpage network. As for the graph properties, only node degrees are used in some citation networks. In contrast, we propose to use the graph structure directly and create significant distribution shifts using a very simple technique that requires computing some node property in the graph that should be chosen depending on a specific problem. For instance, one may use PageRank to create distribution shifts by the structural popularity of instances or Personalized PageRank to take into account the locality and distinguish between the core and periphery nodes.\\n\\nFurther in this section, we compare our benchmark with GOOD in terms of distribution shift statistics discussed in Appendix B.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Class balance\\n\\nIn our benchmark, the PPR-based shift significantly changes the class balance between ID and OOD subsets, while, for feature-based and PageRank-based shifts, the class balance does not change significantly. In GOOD, the level of distribution shift depends on the dataset and the type of shift. For instance, Figures 19 and 20 show a significant change for both types of shifts.\\n\\nDegree distribution\\n\\nComparing to our distribution shifts, the GOOD data splits have much less impact on the degree distribution: this graph property changes dramatically only when the covariate shift is constructed using the degree domain, as in the case of GOOD-Cora dataset (see Figure 22).\\n\\nGraph distance distribution\\n\\nIn contrast to our benchmark, the GOOD approach does not lead to a significant change in pairwise distance distribution between ID and OOD parts: the distance distribution hardly changes for concept shifts, and only covariate shifts make the difference between ID and OOD subsets somehow notable. This proves the necessity of considering the graph structure for inducing challenging distribution shifts.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 20: Experiment results on various datasets.\\n\\n| Feature | Random | EnsNatPN | EnsGNN | NatGPN | GPN | NatPN | EN | GNN | EnsGPN | EnsNatPN | EnsGNN | NatGPN | GPN | NatPN | EN | GNN |\\n|---------|--------|----------|--------|--------|-----|-------|----|-----|--------|----------|--------|--------|-----|-------|----|-----|\\n| Accuracy | PRR@TU | AUPRC@TU | AUROC@KU |\\n| 62 \u00b1 23 | 16 \u00b1 77 | 70 \u00b1 30 | 14 \u00b1 66 |\\n| 54 \u00b1 13 | 39 \u00b1 64 | 31 \u00b1 33 | 28 \u00b1 41 |\\n| 49 \u00b1 29 | 34 \u00b1 34 | 77 \u00b1 29 | 95 \u00b1 56 |\\n| 27 \u00b1 32 | 94 \u00b1 70 | 24 \u00b1 16 | 90 \u00b1 41 |\\n| 95 \u00b1 97 | 97 \u00b1 71 | 57 \u00b1 56 | 64 \u00b1 65 |\\n| 92 \u00b1 09 | 59 \u00b1 42 | 96 \u00b1 73 | 73 \u00b1 94 |\\n| 83 \u00b1 10 | 57 \u00b1 15 | 97 \u00b1 78 | 57 \u00b1 78 |\\n| 84 \u00b1 07 | 94 \u00b1 97 | 97 \u00b1 78 | 54 \u00b1 59 |\\n| 74 \u00b1 34 | 59 \u00b1 25 | 97 \u00b1 78 | 97 \u00b1 97 |\\n| 59 \u00b1 34 | 57 \u00b1 42 | 97 \u00b1 78 | 94 \u00b1 94 |\\n| 77 \u00b1 09 | 59 \u00b1 42 | 97 \u00b1 78 | 94 \u00b1 94 |\\n| 85 \u00b1 10 | 57 \u00b1 15 | 97 \u00b1 78 | 94 \u00b1 94 |\\n| 37 \u00b1 24 | 94 \u00b1 00 | 97 \u00b1 97 | 97 \u00b1 97 |\\n\\nn/a indicates data not available.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Dataset | Accuracy | PRR | TU | AUPRC | TU | AUROC | KU | AUROC | KU |\\n|---------|----------|-----|----|--------|----|--------|----|--------|----|\\n| CiteSeer | 88 \u00b1 38 | 54 \u00b1 48 | 40 \u00b1 23 | 75 \u00b1 59 | 32 \u00b1 32 | 36 \u00b1 29 | 34 \u00b1 38 | 37 \u00b1 31 | 46 \u00b1 31 |\\n\\nUnder review as a conference paper at ICLR 2023\"}"}
{"id": "DB3BH3arU2Y", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Dataset | Accuracy | PRR@TU | AUPRC@TU | AUROC@KU |\\n|---------|----------|--------|----------|----------|\\n| PubMed  | 81\u00b135    | 60\u00b113  | 65\u00b103    | 74\u00b143    |\\n| EnNatPN | 85\u00b142    | 42\u00b106  | 47\u00b114    | 77\u00b140    |\\n| NatPN   | 77\u00b165    | 65\u00b124  | 77\u00b102    | 92\u00b118    |\\n| PN      | 64\u00b197    | 86\u00b132  | 86\u00b111    | 90\u00b112    |\\n| EN      | 39\u00b150    | 50\u00b100  | 50\u00b144    | 70\u00b102    |\\n| GNN     | 44\u00b183    | 83\u00b102  | 83\u00b124    | 93\u00b171    |\\n| GPN     | 37\u00b199    | 99\u00b103  | 99\u00b173    | 73\u00b185    |\\n| NatGPN  | 80\u00b120    | 20\u00b110  | 20\u00b141    | 43\u00b116    |\\n| EnsGPN  | 34\u00b158    | 58\u00b106  | 58\u00b129    | 29\u00b112    |\\n| EnsGNN  | 99\u00b147    | 47\u00b132  | 47\u00b163    | 32\u00b103    |\\n| EnsNatPN| 60\u00b167    | 67\u00b108  | 67\u00b131    | 31\u00b104    |\\n\\nUnder review as a conference paper at ICLR 2023.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"One property that we vary in these methods is the number of Normalizing Flows and how we use their density estimates. In particular, we consider a Standard approach (Charpentier et al., 2020), where distinct Normalizing Flows $p_\\\\psi(z_i | k)$ are used per each class $k$ to predict the corresponding Dirichlet parameter $\\\\beta^{\\\\text{feat}}_{ik}$ based on the representation $z_i = f_\\\\phi(x_i)$:\\n\\n$$\\\\beta^{\\\\text{feat}}_{ik} = n \\\\cdot p_\\\\psi(z_i, k) = n \\\\cdot p_\\\\psi(z_i | k) \\\\cdot P(k) = n_k \\\\cdot p_\\\\psi(z_i | k),$$\\n\\nwhere the probability $P(k)$ of class $k$ is approximated by the ratio of train observations from class $k$, $n$ is usually equal to the dataset size (but can, in general, be a hyper-parameter), and $n_k = n \\\\cdot P(k)$.\\n\\nAnother approach is the Natural version of Posterior Network that is proposed by Charpentier et al. (2021). It exploits a single Normalizing Flow $p_\\\\psi(z_i)$ to predict the evidence $S_i$, while the normalized Dirichlet parameters $\\\\mu_i$ are obtained using one-layer linear transformation $g_{\\\\omega}(z_i)$. The final predictions are obtained as follows:\\n\\n$$S_i = n \\\\cdot p_\\\\psi(z_i), \\\\quad \\\\mu_i = g_{\\\\omega}(z_i) \\\\Rightarrow \\\\beta^{\\\\text{feat}}_{ik} = S_i \\\\cdot \\\\mu_{ik}.$$\"}"}
{"id": "DB3BH3arU2Y", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Uncertainty estimation is an important task that can be essential for high-risk applications of machine learning. This problem is especially challenging for node-level prediction in graph-structured data, as the samples (nodes) are interdependent. However, there is no established benchmark that allows for the evaluation of node-level uncertainty estimation methods in a unified setup, covering diverse and meaningful distribution shifts. In this paper, we address this problem and propose such a benchmark, together with a technique for the controllable generation of data splits with various types of distribution shifts. Importantly, we describe the shifts that are specific to the graph-structured data. Our benchmark consists of several graph datasets equipped with various distribution shifts on which we evaluate the robustness of models and their uncertainty estimation performance. To illustrate the benchmark, we decompose the current state-of-the-art Dirichlet-based framework and perform an ablation study on its components. In our experiments on the proposed benchmark, we show that when faced with complex yet realistic distribution shifts, most models fail to maintain high classification performance and consistency of uncertainty estimates with prediction errors. However, ensembling techniques help to partially overcome significant drops in performance and achieve better results than distinct models.\\n\\nIntroduction\\n\\nUncertainty estimation is an important and challenging task with many applications in financial systems, medical diagnostics, autonomous driving, etc. It aims at quantifying the confidence of machine learning models and can be used to design more reliable decision-making systems. In particular, it enables one to solve such problems as misclassification detection, where the model has to assign higher uncertainty to the potential prediction errors, or out-of-distribution (OOD) detection, when the model is required to yield higher uncertainty for the samples from an unknown distribution.\\n\\nDepending on the source of uncertainty, it can be divided into data uncertainty, which describes the inherent noise in data due to the labeling mistakes or class overlap, and knowledge uncertainty, which accounts for insufficient amount of information for accurate predictions when the distribution of test data is different from the training one (Gal, 2016; Malinin, 2019).\\n\\nThe problem of uncertainty estimation for graph-structured data has recently started to gain attention. It is especially complex at the node level as one has to deal with interdependent samples that may come from different distributions, so their predictions can change significantly depending on the neighborhood. This problem has already been addressed in several studies, and the proposed methods are commonly based on the Dirichlet distribution and introduce various extensions to the Dirichlet framework (Sensoy et al., 2018; Malinin & Gales, 2018; Malinin, 2019; Charpentier et al., 2020), such as graph-based kernel Dirichlet estimation (Zhao et al., 2020) or graph propagation of Dirichlet parameters (Stadler et al., 2021).\\n\\nHowever, the field of robustness and uncertainty estimation for node-level graph problems suffers from the absence of benchmarks with diverse and meaningful distribution shifts. Usually, the evaluation is limited to somewhat unrealistic distribution shifts, such as noisy node features (Stadler et al., 2021) or left-out classes (Zhao et al., 2020; Stadler et al., 2021). Importantly, Gui et al. (2022) try to overcome this issue and systematically construct a graph OOD benchmark, in which they explicitly make distinctions between covariate and concept shifts. However, the authors either consider...\"}"}
{"id": "DB3BH3arU2Y", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"synthetic datasets or ignore the graph structure when creating distribution shifts. The problem with the mentioned approaches is that, in real applications, distribution shifts can be much more complex and diverse, and may depend on the global graph structure (for a more detailed discussion, refer to Appendix C). Thus, the existing benchmarks can be insufficient to reliably and comprehensively evaluate uncertainty estimation methods for graph-structured data. Therefore, the current status quo about the best uncertainty estimation methods for node classification remains unclear and requires further investigation.\\n\\nIn this work, we propose a new benchmark for evaluating robustness and uncertainty estimation in transductive node classification tasks. The main feature of our benchmark is a general approach to constructing the data splits with distribution shifts: it can be applied to any graph dataset, allows for generating shifts of different nature, and one can easily vary the sizes of splits. For demonstration purpose, we apply our method to 7 common node classification datasets and describe 3 particular strategies to induce distribution shifts. Using the proposed benchmark, we evaluate the robustness of various models and their ability to detect errors and OOD inputs. Thus, we show that the recently proposed Graph Posterior Network (Stadler et al., 2021) is consistently the best method for detecting the OOD inputs. However, the best results for the other tasks are achieved using Natural Posterior Networks (Charpentier et al., 2021). We also confirm that ensembling often allows one to improve the model performance \u2014 ensembles of GPNs achieve the best performance for OOD detection, while ensembles of NatPNs have the best predictive performance and error detection.\\n\\n2 PROBLEM STATEMENT\\n\\nWe consider the problem of transductive node classification in an attributed graph $G = (A, X, Y)$ with an adjacency matrix $A \\\\in \\\\{0, 1\\\\}^{n \\\\times n}$, a node feature matrix $X \\\\in \\\\mathbb{R}^{n \\\\times d}$ and categorical targets vector $Y \\\\in \\\\{1, \\\\ldots, C\\\\}^n$. We split the set of nodes $V$ into several non-intersecting subsets depending on whether they are used for training, validation, or testing and if they belong to in-distribution (ID) or out-of-distribution (OOD) subset. Let $Y_{\\\\text{train}}$ denote the labels of train nodes $V_{\\\\text{train}}$. Given a graph $G_{\\\\text{train}} = (A, X, Y_{\\\\text{train}})$, we aim at predicting the labels $Y_{\\\\text{test}}$ of test nodes $V_{\\\\text{test}}$ and estimating the uncertainty measure $u_i \\\\in \\\\mathbb{R}$ associated with these predictions. The obtained uncertainty estimates are used to solve the misclassification detection and OOD detection problems.\\n\\n3 PROPOSED BENCHMARK\\n\\nThis section describes our benchmark for evaluating uncertainty estimates and robustness to distribution shifts for node-level graph problems. The most important ingredient of our benchmark is a unified approach for the controllable generation of diverse distribution shifts that can be applied to any graph dataset. Our benchmark includes a collection of common node classification datasets, several data split strategies, a set of problems for evaluating robustness and uncertainty estimation performance, and the associated metrics. We describe these components below.\\n\\n3.1 GRAPH DATASETS\\n\\nWhile our approach can potentially be applied to any node classification or node regression dataset, for our experiments, we pick the following 7 datasets commonly used in the literature: 3 citation networks, including CoraML, CiteSeer (McCallum et al., 2000; Giles et al., 1998; Getoor, 2005; Sen et al., 2008) and PubMed (Namata et al., 2012), 2 co-authorship graphs \u2014 CoauthorPhysics and CoauthorCS (Shchur et al., 2018), and 2 co-purchase datasets \u2014 AmazonPhoto and Amazon-Computers (McAuley et al., 2015; Shchur et al., 2018).\"}"}
{"id": "DB3BH3arU2Y", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"In this section, we provide additional experimental results.\\n\\n- Tables 6\u20138 are similar to Table 1 in the main text. They show how difficult our splits are for different models. These results are consistent: the feature-based split is the easiest for all the methods, while the PPR-based one is the hardest. Interestingly, it holds for the graph-agnostic MLP, which means that this graph-based shift also implies a noticeable shift in the feature space;\\n- Table 9 is a detalization of Table 4, where we consider different distribution shifts separately and add a random partition. Similarly, Table 10 detalizes Table 5;\\n- Tables 11\u201314 aggregates win/tie/loss counts for all pairs of methods;\\n- Table 15 compares all the methods in terms of their ranks averaged over the datasets;\\n- Tables 16\u201322 provide the results for all the methods on all the datasets. Note that all other aggregated results can be deduced from these tables.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Table 8: Accuracy of GPN vs NatGPN on ID vs OOD test subsets for every split strategy. |\\n|----------------------------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|\\n| Accuracy | GPN | NatGPN | GPN | NatGPN | GPN | NatGPN | GPN | NatGPN | GPN | NatGPN | GPN | NatGPN |\\n|----------|-----|--------|-----|--------|-----|--------|-----|--------|-----|--------|-----|--------|\\n| PRR@TU  | 78  | 50     | 48  | 07     | 00  | 68     | 91  | 35     | 18  | 36     | 02  | 44     |\\n| AUPRC@TU| 66  | 91     | 05  | 79     | 86  | 03     | 97  | 04     | 37  | 50     | 23  | 98     |\\n| AUROC@KU| 61  | 91     | 05  | 79     | 86  | 03     | 97  | 04     | 37  | 50     | 23  | 98     |\\n\\nTable 9: Win/tie/loss under review as a conference paper at ICLR 2023.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 10: Pairwise strategies (except Random).\\n\\n| EnsGNN | NatPN | EN | GNN | MLP |\\n|--------|-------|----|-----|-----|\\n| EnsNatPN | NatGPN | GPN | NatPN | PN |\\n\\nTable 11: Pairwise win/tie/loss\\n\\nTable 12: Pairwise win/tie/loss\\n\\nTable 13: Pairwise win/tie/loss\\n\\nUnder review as a conference paper at ICLR 2023.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":false,\"rotation_correction\":90,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Dataset | EnsGNN | EnsNatPN | EnsGPN | NatGPN | GPN | NatPN | PN | EN | GNN | MLP |\\n|---------|--------|----------|--------|--------|-----|-------|----|----|-----|-----|\\n| CLEVR  | n/a    | 0        | 1      | 2      | 3   | 4     | 5  | 6  | 7   | 8   |\\n| QM9     | 5      | 1        | 10     | 12     | 14  | 17    | 15 | 16 | 18  | 19  |\\n\\nTable 14: Pairwise win/tie/loss for EN methods.\\n\\nTable 15: Average ranks of the considered methods across all datasets.\\n\\n| Method | CLEVR | QM9 |\\n|--------|-------|-----|\\n| Random | 1     | 2   |\\n| MLP    | 3     | 4   |\\n| GNN    | 5     | 6   |\\n| EN     | 7     | 8   |\\n| PN     | 9     | 10  |\\n| NatPN  | 11    | 12  |\\n| GPN    | 13    | 14  |\\n\\nPageRank (PRR) and TED@TU for EN methods.\\n\\n| Method | Accuracy | PRR@TU | AUPRC@TU | AUROC@TU |\\n|--------|----------|--------|----------|----------|\\n| Random | 0.5      | 0.5    | 0.5      | 0.5      |\\n| MLP    | 0.6      | 0.6    | 0.6      | 0.6      |\\n| GNN    | 0.7      | 0.7    | 0.7      | 0.7      |\\n| EN     | 0.8      | 0.8    | 0.8      | 0.8      |\\n| PN     | 0.9      | 0.9    | 0.9      | 0.9      |\\n| NatPN  | 1.0      | 1.0    | 1.0      | 1.0      |\\n| GPN    | 1.1      | 1.1    | 1.1      | 1.1      |\\n\\nAccuracy, PRR@TU, AUPRC@TU, and AUROC@TU for EN methods.\\n\\n| Method | Accuracy | PRR@TU | AUPRC@TU | AUROC@TU |\\n|--------|----------|--------|----------|----------|\\n| Random | 0.5      | 0.5    | 0.5      | 0.5      |\\n| MLP    | 0.6      | 0.6    | 0.6      | 0.6      |\\n| GNN    | 0.7      | 0.7    | 0.7      | 0.7      |\\n| EN     | 0.8      | 0.8    | 0.8      | 0.8      |\\n| PN     | 0.9      | 0.9    | 0.9      | 0.9      |\\n| NatPN  | 1.0      | 1.0    | 1.0      | 1.0      |\\n| GPN    | 1.1      | 1.1    | 1.1      | 1.1      |\\n\\nAccuracy, PRR@TU, AUPRC@TU, and AUROC@TU for EN methods.\\n\\nUnder review as a conference paper at ICLR 2023.\\n\\n*strategies (except Random).\"}"}
{"id": "DB3BH3arU2Y", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Train contains the nodes $V_{\\\\text{train}}$ that are used for the regular training of models and represent the only observations that take part in gradient computation;\\n\\nValid-In enables us to monitor the best model during the training stage by computing the validation loss for the nodes $V_{\\\\text{valid-in}}$ and choose the best checkpoint;\\n\\nTest-In is used for testing on the remaining in-distribution nodes $V_{\\\\text{test-in}}$ and represents the most simple setup that requires the model to reproduce in-distribution dependencies. Both Valid-In and Test-In parts are assumed to come from the exact same distribution as Train.\\n\\nAt the same time, we introduce the following OOD parts:\\n\\nValid-Out contains the validation nodes $V_{\\\\text{valid-out}}$ that also can be used for monitoring but tends to be a more difficult part of graph with potentially different dependencies;\\n\\nTest-Out represents the most shifted part $V_{\\\\text{test-out}}$ and can be used for evaluating robustness of models to distribution shifts.\\n\\nTo construct a particular data split, we choose some characteristic $\\\\sigma_i$ and compute it for every node $i \\\\in V$, as described in Section 3.3. This characteristic reflects some node property that may depend on features or graph structure. After that, we sort all nodes in ascending order of $\\\\sigma_i$. Some fraction of nodes with the smallest values of $\\\\sigma_i$ is considered to be ID, while the remaining ones become OOD and are split into Valid-Out and Test-Out based on their values of $\\\\sigma_i$. Importantly, this general split strategy is very flexible \u2014 it allows one to vary the size of the training part and to analyze the effect of this size on the robustness and the quality of uncertainty estimates. The type of distribution shift depends on the choice of $\\\\sigma_i$ and can also be easily varied.\\n\\nIn our experiments, we split the dataset in the following proportions. The half of the nodes with the smallest values of $\\\\sigma_i$ are assumed to be ID and are split into Train, Valid-In, and Test-In uniformly at random in proportion 30%/10%/10%. The second half contains the remaining OOD nodes split into Valid-Out and Test-Out in the ascending order of $\\\\sigma_i$ in proportion 10%/40%. As a result, the Test-Out part has the most significant distribution shift.\\n\\n3.3 DISTRIBUTION SHIFTS\\n\\nTo define our data splits, it is necessary to choose some node characteristic $\\\\sigma_i$ as a split factor. We aim to consider diverse characteristics which cover a variety of distribution shifts that may occur in practice. In a standard non-graph ML setup, shifts typically happen only in feature space (or, more generally, the joint distribution of features and targets may become shifted). In graph learning tasks, there can be shifts specifically related to the graph structure: the training part can be biased towards more popular nodes or may consist of nodes from a particular region in the graph. Thus, we consider the following representative data split strategies.\\n\\nRandom This is a standard approach to constructing the data splits, where the nodes are selected uniformly at random, i.e., we can take $\\\\sigma_i$ to be a random position in a sorted list. This type of shift is not realistic for practical applications but can be helpful for the analysis: it shows how well the model generalizes given that the distribution does not change. The random splitting strategy also allows for evaluating the robustness of models when the size of the training dataset varies.\\n\\nFeature This approach represents a family of possible feature-based shifts that do not take into account the graph structure explicitly. There are multiple ways to construct such shifts, e.g., a split can be based on values of one particular feature (Gui et al., 2022). However, to follow our general setup described above, we base a split on a continuous characteristic that can be computed for any dataset. Namely, we project the original features $x_i \\\\in \\\\mathbb{R}^d$ into $\\\\mathbb{R}^2$ via a random linear transform $W$, where all entries $w_{ij}$ are independent and come from $\\\\mathcal{N}(0, 1)$. After that, $\\\\sigma_i$ is set to the distance between the node $i \\\\in V$ and the centroid of the projected data, so the most central nodes in terms of features are said to be ID, while OOD parts are close to periphery. This setup naturally corresponds to the situation when the training dataset consists of the most typical elements, while some outliers may be encountered at the inference stage. Thus, this type of shift tests the robustness of models to non-standard feature combinations.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"We visualize all the split strategies applied to the AmazonPhoto dataset in Figure 1. The figures for the remaining datasets can be found in Appendix A. Here, one can see that the feature-based split does not introduce a notable structural shift, i.e., the nodes are distributed across all regions of the graph. This fact is additionally confirmed by our analysis in Appendix B: it is clear that there is no significant difference in the degree distribution and pairwise node distances between the ID and OOD parts. Our empirical observations confirm that the feature-based shifts are the easiest to handle by the considered methods.\\n\\nFigure 1: Visualization of data splits for AmazonPhoto dataset: ID is blue, OOD is red.\\n\\nPageRank\\nThis strategy represents a possible bias towards popularity. It is natural to expect the training set to consist of more popular items. For instance, in the web search, the importance of pages in the internet graph can be measured via PageRank (Page et al., 1999). For this application, the labeling of pages should start with important ones, since they are visited more often. Similar situations may happen for social networks, where it is natural to start labeling with the most influential users, or citation networks, where the most cited pages should be labeled first. However, when applying the model, it is essential to make accurate predictions on less popular elements. Motivated by that, we introduce a PageRank-based split. In particular, we compute the PageRank (PR) values for every node $i \\\\in V$ and define the measure $\\\\sigma_i$ as the negative PR score, which means that the nodes with smaller values of PR (i.e., less important ones) come to the OOD subsets.\\n\\nAs can be seen in Figure 1, the PageRank-based split separates the most important nodes that belong to the cores of large clusters and the structural periphery, which consists of less important nodes in terms of PageRank. Our analysis in Appendix B confirms this observation: the degree distribution changes significantly across the ID and OOD subsets, tending to higher values for the ID nodes. The distance between such nodes also appears to be smaller on average. Our experiments prove that such a structural distribution shift creates a more severe challenge for the considered methods.\\n\\nPersonalized PageRank\\nThis strategy is focused on a potential bias towards locality, which may happen when labeling is performed by exploring the graph starting from some node. For instance, this may occur in a web search where a crawler has to explore the web graph following the links. Similarly, information about the users of a social network can usually be obtained via an API, and new users are discovered following the friends of known users. To model such a situation, we use the concept of Personalized PageRank (PPR) (Page et al., 1999). It represents the stationary distribution of a random walk that always restarts from some fixed node (see, e.g., (Klicpera et al., 2018) for more details). The associated distribution shift naturally combines popularity and locality: PPR is related to node importance since the stationary distribution concentrates more on higher-degree nodes. On the other hand, the locality is also preserved since restarts always happen in a fixed node.\\n\\nFor our splits, we select the node $j \\\\in V$ with the highest PR score as a restarting node and compute the PPR score for every node $i \\\\in V$. After that, we define the measure $\\\\sigma_i$ as negative PPR. The nodes with high PPR, which belong to the ID part, are expected to be close to the restarting node, while far away nodes go to the OOD subset.\\n\\nFigure 1 shows that locality is indeed preserved, as the ID part consists of one compact region around the most important node chosen as the restarting one. Thus, the ID subset includes periphery nodes as well as some nodes that were previously marked as the most important in the PR-based split but...\"}"}
{"id": "DB3BH3arU2Y", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"are now less important for the restarting node. The remaining nodes come to the OOD part. Our analysis in Appendix B also provides strong evidence for the mentioned behavior: the PPR-based split strongly affects the distribution of pairwise distances within the ID/OOD parts as the locality bias of the ID part makes the OOD nodes even more distant from each other. The shift of the degree distribution is also notable but not as severe as for the PR-based split since here we consider only the popularity conditioned on some fixed node. Finally, our empirical results in Section 5 confirm that the PPR-based split is the most challenging one for graph neural networks.\\n\\n3.4 METRICS\\n\\nTo evaluate the classification performance, we exploit standard Accuracy and compute these metrics on Test-In and Test-Out parts. To analyze the aggregated performance, we also report Accuracy and AUROC on the mixture of Test-In and Test-Out.\\n\\nTo evaluate the quality of uncertainty estimates, we consider two problems: error (misclassification) detection and OOD detection. To assess how well a model can detect misclassified samples, we use the concept of Prediction Rejection Curve (PRC) (Malinin et al., 2021; 2022). PRC traces the error rate as we replace model predictions with ground-truth labels in the order of decreasing uncertainty. If uncertainty is high for incorrectly classified samples, then the error rate is expected to drop quickly as we replace such predictions with ground true labels.\\n\\nThus, the Area Under Prediction Rejection Curve (AUPRC) evaluates the joint classification and uncertainty estimation performance, requiring the model not only to provide high prediction accuracy but also to signalize about possible errors through higher uncertainty scores. In our experiments, we compute AUPRC model on the merged test subset of nodes $V_{test}$ using total uncertainty (TU), as the errors may occur due to the inherent noise in data or because of predicting on OOD samples.\\n\\nA measure called Prediction Rejection Ratio (PRR) is also based on the Prediction Rejection Curve but evaluates only the ability of a model to detect misclassified samples. For this purpose, AUPRC is normalized as follows. Let $PRC_{model}$ be the predicted uncertainty estimates, $PRC_{random}$ be random uncertainty estimates, and $PRC_{oracle}$ be estimates that perfectly sort samples according to the prediction errors (i.e., all misclassified samples have higher oracle uncertainty). Then, the PRR metric is defined as follows:\\n\\n$$PRR = \\\\frac{AUPRC_{random} - AUPRC_{model}}{AUPRC_{random} - AUPRC_{oracle}}$$\\n\\nThe best value of this measure is 1 (for the perfect uncertainty estimates), while random uncertainty estimates give $PRR = 0$. Note that each model has its own oracle with the associated estimates that perfectly match its prediction errors. So the AUPRC values of different models are independent and computed only based on the corresponding model predictions.\\n\\nWe also evaluate the ability of models to detect OOD samples. For this, we consider the mixture of Test-In and Test-Out. A good model is expected to have higher knowledge uncertainty (KU) (Gal, 2016; Malinin, 2019) values for the observations from Test-Out compared to Test-In.\\n\\nHere, we use the standard AUROC for the binary classification with positive events corresponding to the observations coming from the OOD subset.\\n\\n4 METHODS\\n\\nWe consider several methods for estimating uncertainty in graph-related problems. Specifically, we cover message-passing neural networks, ensemble approaches Lakshminarayanan et al. (2017), and Dirichlet-based methods that are currently considered to be state-of-the-art for OOD detection that is called GPN (Stadler et al., 2021). For Dirichlet-based approaches, we conduct an ablation study to evaluate which design choices contribute most to performance.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.1 STANDARD METHODS\\n\\nIn this class of methods, the constructed model $f_{\\\\theta}(x_i)$ predicts the parameters $\\\\mu_i = f_{\\\\theta}(x_i)$ of the categorical distribution $P_{\\\\theta}(y_i | x_i) = P(y_i | \\\\mu_i)$ in the standard classification task, while the uncertainty estimates are obtained based on the entropy of this distribution.\\n\\nA simple baseline that serves us as a lower bound for our further experiments with more advanced methods is MLP, which represents a graph-agnostic MLP model and takes into account only the features of the current observation. Further, GNN is a simple GNN model based on a two-layer SAGE convolution (Hamilton et al., 2017), which combines the information from both the central node and its neighborhood. As a training objective, these methods use the standard Cross-Entropy loss between the one-hot-encoded target $y_i$ and the predicted categorical vector $\\\\mu_i$. For these methods, we can only define uncertainty as the entropy $u_i = H_{P_{\\\\theta}(y_i | \\\\mu_i)}$ of the predictive categorical distribution.\\n\\n4.2 DIRICHLET-BASED METHODS\\n\\nThe core idea behind the Dirichlet-based uncertainty estimation methods is to model the pointwise Dirichlet distribution $p_{\\\\theta}(\\\\mu_i | x_i) = p(\\\\mu_i | \\\\beta_{\\\\text{post}})$ by predicting its parameters $\\\\beta_{\\\\text{feat}} = f_{\\\\theta}(x_i)$ and updating the uniform prior distribution with parameters $\\\\beta_{\\\\text{prior}}$ through their sum $\\\\beta_{\\\\text{post}} = \\\\beta_{\\\\text{feat}} + \\\\beta_{\\\\text{prior}}$.\\n\\nUsing this Dirichlet distribution, one can obtain the target categorical one as follows:\\n\\n$$P_{\\\\theta}(y_i | x_i) = E_{p_{\\\\theta}(\\\\mu_i | \\\\beta_{\\\\text{post}})} P(y_i | \\\\mu_i).$$\\n\\nIt implies that $P_{\\\\theta}(y_i | x_i)$ has parameters $\\\\beta_{\\\\text{post}} / S_i$, where $S_i = \\\\sum_k \\\\beta_{\\\\text{post}}^{ik}$ is called evidence or precision. In other words, the parameters of the categorical distribution can be obtained from the Dirichlet ones by normalization. Importantly, the Dirichlet-based methods allow us to distinguish between total and knowledge uncertainty as follows:\\n\\n$$u_{\\\\text{total}} = H_{P_{\\\\theta}(y_i | x_i)} = H_{E_{p_{\\\\theta}(\\\\mu_i | \\\\beta_{\\\\text{post}})} P(y_i | \\\\mu_i)} - S_i.$$\\n\\nFor this class of methods, the training objective is Expected Cross-Entropy with an optional regularisation term that is equal to the entropy of the predicted Dirichlet distribution $p(\\\\mu_i | \\\\beta_{\\\\text{post}})$:\\n\\n$$L_i = E_{p_{\\\\theta}(\\\\mu_i | \\\\beta_{\\\\text{post}})} - \\\\log P(y_i | \\\\mu_i) - \\\\lambda H_{p(\\\\mu_i | \\\\beta_{\\\\text{post}})}.$$  \\\\(1\\\\)\\n\\nThis loss function can be computed in closed form (Malinin & Gales, 2018; Charpentier et al., 2020).\\n\\nAs the most straightforward method in this class, we consider a modification of GNN that is referred to as EN (Evidential Network) (Sensoy et al., 2018) \u2014 while exploiting the same architecture, it is trained to predict the Dirichlet parameters via Loss (1).\\n\\nThere are also more advanced methods based on the Dirichlet distribution which induce the behavior of the underlying model by estimating the density function in the latent space using Normalizing Flows (Kingma et al., 2016; Huang et al., 2018). These methods can be united within the recently proposed framework Posterior Networks (Charpentier et al., 2020; 2021). It was applied to the node-level problems in (Stadler et al., 2021). In this paper, we provide a detailed study of this framework and consider different variations depending on how the density estimation is performed and how the graph information is used. The description of these components can be found in Appendix E.\\n\\n4.3 ENSMBLES\\n\\nIn our study, we also consider ensembling techniques that proved to increase the predictive performance of models and provide instruments for estimating uncertainty. Among the methods that predict the parameters $\\\\mu_i$ of categorical distributions $P(y_i | \\\\mu_i)$, there is a widely used approach for uncertainty estimation introduced by Lakshminarayanan et al. (2017). It can be formulated as an\\n\\n1 For GNNs, we formally have $\\\\mu_i = f_{\\\\theta}(A, X, i)$ but we write $f_{\\\\theta}(x_i)$ for simplicity of notation and consistency with non-graph methods.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"empirical distribution of model parameters $q(\\\\theta|G_{\\\\text{train}})$ that can be obtained after training several instances of the model with different random seeds for initialization:\\n\\n$$P_{\\\\theta}(y_i|x_i) = E_{q(\\\\theta|G_{\\\\text{train}})} P(y_i|\\\\mu_i).$$\\n\\nGiven this, we can split the total uncertainty into data and knowledge uncertainty through the following expression (Malinin & Gales, 2018):\\n\\n$$u_{\\\\text{total}} = H(P_{\\\\theta}(y_i|x_i)) = H(E_{q(\\\\theta|G_{\\\\text{train}})} P(y_i|\\\\mu_i)),$$\\n\\n$$u_{\\\\text{data}} = E_{q(\\\\theta|G_{\\\\text{train}})} H(P(y_i|\\\\mu_i)),$$\\n\\n$$u_{\\\\text{know}} = u_{\\\\text{total}} - u_{\\\\text{data}}.$$\\n\\nWe apply this approach to GNN models and denote the obtained ensemble as $\\\\text{EnsGNN}$. As for the Dirichlet-based approaches, we follow Charpentier et al. (2021) and define an ensemble of models that predict the parameters of posterior Dirichlet distribution as the mean over the parameters in ensemble. Here, uncertainty is estimated in the same way as for a single Dirichlet-based model.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Accuracy of GNN on ID vs OOD test subsets. Diff.% is the difference between the accuracy scores on the OOD and ID parts divided by the accuracy score on the ID part.\\n\\n| Feature   | GNN | ID   | OOD  | Diff, % |\\n|-----------|-----|------|------|---------|\\n| AmazonComputers |    | 84.88 | 84.84 | 0.02   |\\n| AmazonPhoto   |    | 94.90 | 92.23 | -2.67  |\\n| CoauthorCS    |    | 92.44 | 93.74 | 1.41   |\\n| CoauthorPhysics| | 96.57 | 96.06 | -0.54  |\\n| CoraML        |    | 85.68 | 86.96 | 3.92   |\\n| CiteSeer      |    | 70.87 | 71.50 | 0.88   |\\n| PubMed        |    | 87.58 | 86.01 | -1.79  |\\n\\nTable 2: Average ranks of standard uncertainty estimation methods over graph datasets.\\n\\n| Method   | Accuracy | PRR@TU | AUPRC@TU | AUROC@KU |\\n|----------|----------|--------|----------|----------|\\n| Random GNN | 2.33     | 1.7    | 2.33     | n/a      |\\n| GPN       | 2.66     | 3.0    | 2.66     | n/a      |\\n| EnsGNN    | 1.11     | 1.3    | 1.11     | n/a      |\\n\\nFeature GNN | 2.33 | 1.6 | 2.13 | 2.33 |\\nFeature GPN | 2.44 | 2.3 | 2.67 | 1.00 |\\nFeature EnsGNN | 1.33 | 1.4 | 1.44 | 2.33 |\\n\\nPageRank GNN | 2.44 | 1.9 | 2.67 | 2.44 |\\nPageRank GPN | 2.11 | 1.7 | 2.11 | 1.33 |\\nPageRank EnsGNN | 1.33 | 1.4 | 1.44 | 2.33 |\\n\\nPPR GNN | 2.44 | 2.3 | 2.67 | 2.99 |\\nPPR GPN | 2.11 | 1.7 | 2.11 | 1.00 |\\nPPR EnsGNN | 1.33 | 1.4 | 1.44 | 2.33 |\\n\\nand GPN which is known to be state-of-the-art for the OOD detection (Stadler et al., 2021). Table 2 compares these methods over all datasets. One can see that, according to AUROC@KU, the best OOD detection performance is achieved by GPN for all types of shifts, which is consistent with previously reported results (Stadler et al., 2021). Unsurprisingly, EnsGNN shows the best predictive performance, as measured by Accuracy. Moreover, it has the most consistent uncertainty estimates in context of PRR@TU and provides the best joint performance via AUPRC@TU. In summary, ensembles are the best for all tasks but OOD detection, where the superior method is GPN.\\n\\nQ3: Which Dirichlet-based methods are the best for each prediction task?\\n\\nHere, we provide a detailed analysis of the Dirichlet-based framework. The simplest method is EN, which represents a standard GNN trained with the Loss (1). Further, we consider the methods using Normalizing Flows, and compare Standard vs Natural density estimation and Graph Encoding vs Graph Propagation. Based on Table 3, one can make the following conclusions. First, GPN is still the best method for OOD detection. Second, NatPN is the best according to all other tasks. Third, EN is a strong baseline that shows competitive results in Accuracy, PRR@TU, and AUCPRC@TU, often staying close to NatPN. To show whether the difference is statistically significant, we report the win/tie/loss counts for some pairs of models. See Table 4 for the aggregated results and Tables 9, 11\u201314 in Appendix for more details.\\n\\nQ4: Do ensembles consistently improve the performance of complex models?\\n\\nEnsemble are known to consistently improve the model performance in various tasks, so we aim to confirm that this result holds in the transductive node classification. For this purpose, we compare the ensembles of the two most promising methods GPN and NatPN. The aggregated results are shown in Table 5 (also, see Tables 10\u201314 in Appendix for more details). One can see that ensembling via EnsGPN consistently improves GPN for OOD detection, but the difference is mostly insignificant. In contrast, EnsNatPN is noticeably better than NatPN, and this gain is especially significant for Accuracy and the joint performance measured by AUPRC.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 3: Average ranks of Dirichlet-based methods over datasets, including EN, PN, NatPN, GPN and NatGPN, which are obtained for every considered split strategy and prediction task.\\n\\n| Feature | EN | PN | NatPN | GPN | NatGPN |\\n|---------|----|----|-------|-----|--------|\\n| Accuracy | 2.0 | 3.7 | 2.2 | 3.0 | 3.4 |\\n| PRR@TU | 1.07 | 3.77 | 2.4 | 3.3 | 3.1 |\\n| AUPRC@TU | 2.49 | 3.41 | 2.2 | 2.4 | 2.6 |\\n| AUROC@KU | n/a | n/a | n/a | n/a | n/a |\\n\\n### Table 4: Win/tie/loss counts for some pairs of Dirichlet-based methods across all the considered graph datasets and split strategies (except Random).\\n\\n| Pair               | Win | Tie | Loss |\\n|--------------------|-----|-----|------|\\n| NatPN vs EN        | 3/18 | 6/14 | 8/12 |\\n| GPN vs NatGPN      | 14/5 | 2/11 | 2/12 |\\n| NatPN vs GPN       | 12/2 | 7/5 | 13/5 |\\n\\n### Table 5: Win/tie/loss counts for ensembles vs the corresponding single models across all the considered graph datasets and split strategies (except Random).\\n\\n| Pair                | Win | Tie | Loss |\\n|---------------------|-----|-----|------|\\n| EnsGPN vs GPN       | 9/11 | 1/1 | 6/14 |\\n| EnsNatPN vs NatPN   | 14/7 | 0/0 | 6/15 |\\n\\nTo summarize our findings, we refer to Table 15 for the comparison of all the methods in terms of ranks and to Tables 11\u201314 for the detailed comparison of their win/tie/loss counts. One can conclude that GPN is the best single-pass method for OOD detection, while NatPN is the best one for all other tasks. Moreover, the performance of the latter can be further improved by ensembling, so EnsNatPN achieves the best results in terms of Accuracy, PRR, and AUPRC.\\n\\n### Conclusion\\nIn this work, we propose a new benchmark for evaluating robustness and uncertainty estimation in transductive node classification tasks. For this, we design a universal approach to creating data splits with distribution shifts: it can be applied to any graph dataset and allows for generating shifts of various nature. Using our benchmark, we show that the recently proposed Graph Posterior Network (Stadler et al., 2021) is consistently the best method for detecting the OOD inputs, while the best results for the other tasks are achieved using Natural Posterior Networks (Charpentier et al., 2021). Our experiments also confirm that ensembling allows one to improve the model performance. Thus, we believe that our benchmark will be useful for future studies of node-level uncertainty estimation.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Bertrand Charpentier, Daniel Z\u00fcgner, and Stephan G\u00fcnnemann. Posterior network: Uncertainty estimation without ood samples via density-based pseudo-counts. Advances in Neural Information Processing Systems, 33:1356\u20131367, 2020.\\n\\nBertrand Charpentier, Oliver Borchert, Daniel Z\u00fcgner, Simon Geisler, and Stephan G\u00fcnnemann. Natural posterior network: Deep bayesian predictive uncertainty for exponential family distributions. In International Conference on Learning Representations, 2021.\\n\\nYarin Gal. Uncertainty in deep learning. University of Cambridge, Cambridge, 2016.\\n\\nLise Getoor. Link-based classification. In Advanced methods for knowledge discovery from complex data, pp. 189\u2013207. Springer, 2005.\\n\\nC Lee Giles, Kurt D Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing system. In Proceedings of the third ACM conference on Digital libraries, pp. 89\u201398, 1998.\\n\\nShurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022.\\n\\nWill Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. Advances in Neural Information Processing Systems, 30, 2017.\\n\\nChin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron Courville. Neural autoregressive flows. In International Conference on Machine Learning, pp. 2078\u20132087. PMLR, 2018.\\n\\nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\\n\\nDurk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improved variational inference with inverse autoregressive flow. Advances in neural information processing systems, 29, 2016.\\n\\nJohannes Klicpera, Aleksandar Bojchevski, and Stephan G\u00fcnnemann. Predict then propagate: Graph neural networks meet personalized pagerank. arXiv preprint arXiv:1810.05997, 2018.\\n\\nBalaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.\\n\\nAndrey Malinin. Uncertainty estimation in deep learning with application to spoken language assessment. PhD thesis, University of Cambridge, 2019.\\n\\nAndrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. Advances in neural information processing systems, 31, 2018.\\n\\nAndrey Malinin, Neil Band, German Chesnokov, Yarin Gal, Mark JF Gales, Alexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, Vatsal Raina, et al. Shifts: A dataset of real distributional shift across multiple large-scale tasks. arXiv preprint arXiv:2107.07455, 2021.\\n\\nAndrey Malinin, Andreas Athanasopoulos, Muhamed Barakovic, Meritxell Bach Cuadra, Mark JF Gales, Cristina Granziera, Mara Graziani, Nikolay Kartashev, Konstantinos Kyriakopoulos, Po-Jui Lu, et al. Shifts 2.0: Extending the dataset of real distributional shifts. arXiv preprint arXiv:2206.15407, 2022.\\n\\nJulian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval, pp. 43\u201352, 2015.\\n\\nAndrew Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. Automating the construction of internet portals with machine learning. Information Retrieval, 3(2):127\u2013163, 2000.\"}"}
{"id": "DB3BH3arU2Y", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We evaluate all the methods discussed in Section 4 using the benchmark proposed in Section 3. Some of the considered methods require a specific training procedure consisting of several stages. Methods without Normalizing Flows, including MLP, GNN, EnsGNN, and EN, have only one training stage when the corresponding models train in the standard end-to-end mode. Methods with Normalizing Flows have at least three phases of training \u2014 warm-up of exclusively Flow neural layers, end-to-end training of the entire model, and finetuning the same Flow layers. In this regard, we follow the setup of Stadler et al. (2021). Further details can be found in Appendix G.\\n\\nIn our experiments, one training stage (i.e., warm-up, main training stage, or finetuning) takes 200 epochs, while the best loss value on the Valid-In part serves as a criterion for saving the model checkpoint. We exploit the standard Adam optimizer (Kingma & Ba, 2014) with a learning rate of 0.001 for Normalizing Flows and 0.0003 for other neural modules. For all the considered models, we utilize weight decay of 0.00001 and set $\\\\lambda = 0.001$ in Expected Cross-Entropy.\\n\\nAs for model configurations, we set the hidden size of linear layers to 64, the number of layers in Normalizing Flows to 8 and the latent space dimension to 16. Also, Graph Propagation is performed in 5 steps with $\\\\alpha = 0.23$.1\"}"}
{"id": "DB3BH3arU2Y", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 16: Experiment results on dataset.\\n\\n| Method      | Accuracy | PRR | TU   | AUPRC   | AUROC   |\\n|-------------|----------|-----|------|---------|---------|\\n| EnsGPN      | 77\u00b130    | 44\u00b144| 05\u00b148| 67\u00b167   | 98\u00b198   |\\n| EnsNatPN    | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| EnsGNN      | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n| NatGPN      | 40\u00b160    | 72\u00b134| 98\u00b179| 64\u00b164   | 23\u00b123   |\\n| GPN          | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| NatPN       | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n| PN          | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| GNN         | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n| EnsNatPN    | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| EnsGNN      | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n| NatGPN      | 40\u00b160    | 72\u00b134| 98\u00b179| 64\u00b164   | 23\u00b123   |\\n| GPN          | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| NatPN       | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n| PN          | 30\u00b105    | 44\u00b144| n/a  | n/a     | n/a     |\\n| GNN         | 25\u00b160    | 78\u00b103| n/a  | n/a     | n/a     |\\n\\n*Under review as a conference paper at ICLR 2023*\"}"}
{"id": "DB3BH3arU2Y", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Table 1: Experiment results on AmazonPhoto dataset. | Accuracy PRR@TU AUPRC@TU AUROC@KU |\\n|-----------------------------------------------|----------------|----------------|----------------|\\n| EnsGPN                                        | 0.30 \u00b1 0.24    | 0.76 \u00b1 0.71    | 0.68 \u00b1 0.65    |\\n| EnsNatPN                                      | 0.24 \u00b1 0.36    | 0.47 \u00b1 0.47    | 0.55 \u00b1 0.55    |\\n| EnsGNN                                        | 0.18 \u00b1 0.15    | 0.22 \u00b1 0.23    | 0.31 \u00b1 0.31    |\\n| NatGPN                                        | 0.65 \u00b1 0.68    | 0.89 \u00b1 0.89    | 0.76 \u00b1 0.76    |\\n| GPN                                           | 0.45 \u00b1 0.49    | 0.57 \u00b1 0.57    | 0.63 \u00b1 0.63    |\\n| EN                                            | 0.90 \u00b1 0.90    | 0.94 \u00b1 0.94    | 0.96 \u00b1 0.96    |\"}"}
{"id": "DB3BH3arU2Y", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\n|                  | Accuracy  | PRR@TU AUPRC@TU AUROC@KU |\\n|------------------|-----------|--------------------------|\\n| CoauthorCS       | \u00b174       | \u00b141                      |\\n| EnNatPN          | \u00b122       | \u00b105                      |\\n| EnsGNN           | \u00b112       | \u00b122                      |\\n| NatGPN           | \u00b100       | \u00b164                      |\\n| GPN              | \u00b161       | \u00b172                      |\\n| PN               | \u00b131       | \u00b129                      |\\n| EN               | \u00b121       | \u00b177                      |\\n| GNN              | \u00b184       | \u00b146                      |\\n| EnsGPN           | \u00b156       | \u00b138                      |\\n| EnsNatPN         | \u00b157       | \u00b157                      |\\n| EnsGNN           | \u00b187       | \u00b188                      |\\n| NatGPN           | \u00b181       | \u00b102                      |\\n| GPN              | \u00b193       | \u00b119                      |\\n| PN               | \u00b199       | \u00b193                      |\\n| EN               | \u00b195       | \u00b186                      |\\n| GNN              | \u00b193       | \u00b193                      |\\n| EnsGPN           | \u00b181       | \u00b181                      |\\n| EnsNatPN         | \u00b110       | \u00b110                      |\\n| EnsGNN           | \u00b186       | \u00b186                      |\\n| NatGPN           | \u00b184       | \u00b109                      |\\n| GPN              | \u00b190       | \u00b133                      |\\n| PN               | \u00b180       | \u00b128                      |\\n| EN               | \u00b191       | \u00b186                      |\\n| GNN              | \u00b159       | \u00b183                      |\\n| EnsGPN           | \u00b175       | \u00b172                      |\\n| EnsNatPN         | \u00b180       | \u00b100                      |\\n| EnsGNN           | \u00b125       | \u00b118                      |\\n| NatGPN           | \u00b142       | \u00b125                      |\\n| GPN              | \u00b182       | \u00b144                      |\\n| PN               | \u00b139       | \u00b107                      |\\n| EN               | \u00b139       | \u00b120                      |\\n| GNN              | \u00b163       | \u00b113                      |\\n| EnsGPN           | \u00b167       | \u00b130                      |\\n| EnsNatPN         | \u00b168       | \u00b113                      |\\n| EnsGNN           | \u00b176       | \u00b163                      |\\n| NatGPN           | \u00b144       | \u00b195                      |\\n| GPN              | \u00b170       | \u00b173                      |\\n| PN               | \u00b198       | \u00b127                      |\\n| EN               | \u00b140       | \u00b105                      |\\n| GNN              | \u00b181       | \u00b198                      |\\n| EnsGPN           | \u00b125       | \u00b118                      |\\n| EnsNatPN         | \u00b118       | \u00b118                      |\\n| EnsGNN           | \u00b193       | \u00b118                      |\\n| NatGPN           | \u00b193       | \u00b193                      |\\n| GPN              | \u00b197       | \u00b197                      |\\n| PN               | \u00b188       | \u00b188                      |\\n| EN               | \u00b172       | \u00b172                      |\\n| GNN              | \u00b142       | \u00b142                      |\\n| EnsGPN           | \u00b151       | \u00b151                      |\\n| EnsNatPN         | \u00b151       | \u00b151                      |\\n| EnsGNN           | \u00b164       | \u00b142                      |\\n| NatGPN           | \u00b160       | \u00b129                      |\\n| GPN              | \u00b174       | \u00b133                      |\\n| PN               | \u00b198       | \u00b128                      |\\n| EN               | \u00b144       | \u00b144                      |\\n| GNN              | \u00b193       | \u00b193                      |\\n| EnsGPN           | \u00b188       | \u00b188                      |\\n| EnsNatPN         | \u00b173       | \u00b173                      |\\n| EnsGNN           | \u00b182       | \u00b182                      |\\n| NatGPN           | \u00b171       | \u00b171                      |\\n| GPN              | \u00b190       | \u00b168                      |\\n| PN               | \u00b142       | \u00b171                      |\\n| EN               | \u00b152       | \u00b152                      |\\n| GNN              | \u00b173       | \u00b173                      |\\n| EnsGPN           | \u00b195       | \u00b195                      |\\n| EnsNatPN         | \u00b197       | \u00b197                      |\\n| EnsGNN           | \u00b192       | \u00b192                      |\"}"}
{"id": "DB3BH3arU2Y", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: Experiment results on EnsGPN, EnsGNN, GPN, NatPN, EN, GNN, EnsNatPN, EnsGNN, NatGPN, PN, EN, GNN.\\n\\n|         | Accuracy | PRR@TU | AUPRC@TU | AUROC@KU |\\n|---------|----------|--------|----------|----------|\\n| EnsGPN  | \u00b163      | \u00b167    | \u00b111      | \u00b111      |\\n| EnsGNN  | \u00b156      | \u00b175    | \u00b129      | \u00b125      |\\n| GPN     | \u00b156      | \u00b175    | \u00b129      | \u00b125      |\\n| NatPN   | \u00b115      | \u00b110    | \u00b116      | \u00b130      |\\n| EN      | \u00b131      | \u00b158    | \u00b149      | \u00b149      |\\n| GNN     | \u00b133      | \u00b158    | \u00b149      | \u00b149      |\\n| EnsNatPN| \u00b168      | \u00b167    | \u00b158      | \u00b158      |\\n| EnsGNN  | \u00b168      | \u00b167    | \u00b158      | \u00b158      |\\n| NatGPN  | \u00b192      | \u00b112    | \u00b109      | \u00b113      |\\n| PN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| GNN     | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EnsNatPN| \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EnsGNN  | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| NatGPN  | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| PN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| GNN     | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EnsNatPN| \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EnsGNN  | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| NatGPN  | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| PN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| EN      | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\\n| GNN     | \u00b190      | \u00b109    | \u00b107      | \u00b131      |\"}"}
