{"id": "eGm22rqG93", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This page discusses the optimization of models in test-time adaptation tasks. The text mentions the use of normalization statistics in the test-time adaptation methods (TTA) and introduces DOT as a method to alleviate the problem of optimization being highly skewed towards dominant classes, making the model more biased. DOT introduces TBR to improve it using approximate global statistics. The text also mentions the use of pseudo categories in the test samples' prediction and a moving cosine similarity between the arrived samples.\\n\\nThe text introduces Logit adjustment (LA) as a method to augment loss function to encourage the predictions of test samples to be uniform. It notes that this approach can be detrimental, and TBR and DOT can effectively alleviate them. The text compares DOT against other techniques for class imbalance, such as KL-div, and finds that DOT consistently promotes TENT in all scenarios, especially in class-imbalanced scenarios.\\n\\nThe text concludes with an expectation that these strategies can improve test-time adaptation methods, particularly in scenarios where class imbalance is a concern. The table shows the comparison of different techniques for class imbalance, with DOT performing reasonably well under various thresholds.\\n\\nThe text also introduces more strategies for solving class imbalance, such as Div-W and Div-W+, and demonstrates that both DOT and TENT+DELTA can consistently promote TENT against other techniques and the biased optimization.\"}"}
{"id": "eGm22rqG93", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACKNOWLEDGMENTS\\n\\nThis work is supported in part by the National Natural Science Foundation of China under Grant 62171248, the R&D Program of Shenzhen under Grant JCYJ20220818101012025, the PCNL KEY project (PCL2021A07), and Shenzhen Science and Technology Innovation Commission (Research Center for Computer Network (Shenzhen) Ministry of Education).\\n\\nREFERENCES\\n\\nShaden Alshammari, Yu-Xiong Wang, Deva Ramanan, and Shu Kong. Long-tailed recognition via weight balancing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6897\u20136907, 2022.\\n\\nArsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, and Dmitry Vetrov. Pitfalls of in-domain uncertainty estimation and ensembling in deep learning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=BJxI5gHKDr.\\n\\nMalik Boudiaf, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8344\u20138353, 2022.\\n\\nDian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In CVPR, 2022.\\n\\nYin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 9268\u20139277, 2019.\\n\\nCharles Elkan. The foundations of cost-sensitive learning. In International joint conference on artificial intelligence, volume 17, pp. 973\u2013978. Lawrence Erlbaum Associates Ltd, 2001.\\n\\nYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc \u00b8ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096\u20132030, 2016.\\n\\nArthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Sch \u00a8olkopf, and Alex Smola. A kernel method for the two-sample-problem. In B. Sch \u00a8olkopf, J. Platt, and T. Hoffman (eds.), Advances in Neural Information Processing Systems, volume 19. MIT Press, 2006. URL https://proceedings.neurips.cc/paper/2006/file/e9fb2eda3d9c55a0d89c98d6c54b5b3e-Paper.pdf.\\n\\nYin-Yin He, Jianxin Wu, and Xiu-Shen Wei. Distilling virtual examples for long-tailed recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 235\u2013244, 2021.\\n\\nDan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=HJz6tiCqYm.\\n\\nDan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. AugMix: A simple data processing method to improve robustness and uncertainty. Proceedings of the International Conference on Learning Representations (ICLR), 2020.\\n\\nDan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 8340\u20138349, 2021.\\n\\nJudy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In International conference on machine learning, pp. 1989\u20131998. Pmlr, 2018.\"}"}
{"id": "eGm22rqG93", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "eGm22rqG93", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2023\\n\\nEsteban Real, Jonathon Shlens, Stefano Mazzocchi, Xin Pan, and Vincent Vanhoucke. Youtube-boundingboxes: A large high-precision human-annotated data set for object detection in video. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7464\u20137473, 2017.\\n\\nMengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning. In International conference on machine learning, pp. 4334\u20134343. PMLR, 2018.\\n\\nKuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised domain adaptation. In International Conference on Machine Learning, pp. 2988\u20132997. PMLR, 2017.\\n\\nSteffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539\u201311551, 2020.\\n\\nDequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=uXl3bZLkr3c.\\n\\nQin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7201\u20137211, 2022a.\\n\\nTao Wang, Yu Li, Bingyi Kang, Junnan Li, Junhao Liew, Sheng Tang, Steven Hoi, and Jiashi Feng. The devil is in classification: A simple framework for long-tail instance segmentation. In European conference on computer vision, pp. 728\u2013744. Springer, 2020.\\n\\nXudong Wang, Zhirong Wu, Long Lian, and Stella X Yu. Debiased learning from naturally imbalanced pseudo-labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 14647\u201314657, 2022b.\\n\\nSaining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1492\u20131500, 2017.\\n\\nShiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adaptation. In 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 8958\u20138967, 2021a. doi: 10.1109/ICCV48922.2021.00885.\\n\\nMikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and Yasaman Khazaeni. Bayesian nonparametric federated learning of neural networks. In International Conference on Machine Learning, pp. 7252\u20137261. PMLR, 2019.\\n\\nWerner Zellinger, Thomas Grubinger, Edwin Lughofer, Thomas Natschl\u00e4ger, and Susanne Saminger-Platz. Central moment discrepancy (CMD) for domain-invariant representation learning. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id=SkB-_mcel.\\n\\nM. Zhang, S. Levine, and C. Finn. MEMO: Test time robustness via adaptation and augmentation. 2021.\\n\\nBowen Zhao, Xi Xiao, Guojun Gan, Bin Zhang, and Shu-Tao Xia. Maintaining discrimination and fairness in class incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13208\u201313217, 2020.\"}"}
{"id": "eGm22rqG93", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ficient. TEMA can consistently improve BN adapt: the normalization statistics in Figure 2 become more stable and accurate, and the test accuracy in Table 2 is improved as well. However, for TENT which involves parameters update, TEMA can destroy the trained model as shown in Table 2. As discussed in Ioffe & Szegedy (2015), simply employing the moving averages would neutralize the effects of gradient optimization and normalization, as the gradient descent optimization does not consider the normalization, leading to unlimited growth of model parameters. Thus, we introduce batch renormalization (Ioffe, 2017) into test-time adaptation, leading to TBR, which is formulated by:\\n\\n\\\\[\\n\\\\hat{v} = v - \\\\hat{\\\\mu}_{\\\\text{batch}} \\\\cdot \\\\hat{\\\\sigma}_{\\\\text{ema}} \\\\cdot r + d,\\n\\\\]\\n\\nwhere\\n\\n\\\\[\\nr = \\\\sigma(\\\\hat{\\\\sigma}_{\\\\text{batch}}) / \\\\sigma(\\\\hat{\\\\sigma}_{\\\\text{ema}}),\\n\\\\]\\n\\n\\\\[\\nd = \\\\mu(\\\\hat{\\\\mu}_{\\\\text{batch}}) - \\\\hat{\\\\mu}_{\\\\text{ema}} \\\\cdot \\\\hat{\\\\sigma}_{\\\\text{ema}},\\n\\\\]\\n\\nWe present a detailed algorithm description in Appendix A.2. Different from BN adapt, we use the test-time moving averages to rectify the normalization (through \\\\(r\\\\) and \\\\(d\\\\)). Different from the TEMA, TBR is well compatible with gradient-based adaptation methods (e.g., TENT) and can improve them as summarised in Table 2. For BN adapt, TEMA is equal to TBR. Different from the original batch renormalization used in the training phase, TBR is employed in the inference phase which uses the statistics and moving averages derived from test batches. Besides, as the adaptation starts with a trained model \\\\(f(\\\\{\\\\theta_0, a_0\\\\})\\\\), TBR discards the warm-up and truncation operation to \\\\(r\\\\) and \\\\(d\\\\), thus does not introduce additional hyper-parameters. TBR can be applied directly to a common pre-trained model with BN without requiring the model to be trained with such calibrated normalization.\\n\\n### 3.3 A CLOSER LOOK AT TEST-TIME PARAMETER OPTIMIZATION\\n\\nWe evaluate the model on IS+CB and DS+CB gaussian-noise-corrupted test data (Gauss) of CIFAR100-C. We also test the model on the original clean test set of CIFAR100 for comparison. Figure 3 depicts the per-class number of predictions, while Table 3 shows the corresponding standard deviation, range (maximum subtract minimum), and accuracy. We draw the following five conclusions.\\n\\n- Predictions are imbalanced, even for a model trained on class-balanced training data and tested on a class-balanced test set with \\\\(P_{\\\\text{test}}(x, y) = P_{\\\\text{train}}(x, y)\\\\): the \u201cclean\u201d curve in Figure 3 (left) with standard deviation 8.3 and range 46. This phenomenon is also studied in Wang et al. (2022b).\\n- Predictions become more imbalanced when \\\\(P_{\\\\text{test}}(x, y) \\\\neq P_{\\\\text{train}}(x, y)\\\\) as shown in Figure 3 (left): the ranges are 46 and 956 on the clean and corrupted test set respectively.\\n- BN adapt+TEMA improves accuracy (from 27.0% to 58.0%) and alleviates the prediction imbalance at the same time (the range dropped from 956 to 121.6).\\n- Though accuracy is further improved with TENT+TBR (from 58.0% to 62.2%), the predictions become more imbalanced inversely (the range changed from 121.6 to 269.8). The entropy minimization loss focuses on data with low entropy, while samples of some classes may have relatively lower entropy owing to the trained model, thus TENT would aggravate the prediction imbalance.\\n- On dependent test streams, not only the model accuracy drops, but also the predictions become more imbalanced (range 269.8 / range 469.2 on independent/dependent samples for TENT+TBR), as the model may be absolutely dominated by some classes over a period of time in DS+CB scenario.\\n\\n![Figure 3: Per-class number of predictions under combinations of data, scenario, method.](image)\\n\\n![Table 3: Standard Deviation (STD), Range (R) of per-class number of predictions and accuracy (Acc, %) on Gauss data.](image)\"}"}
{"id": "eGm22rqG93", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 1: Dynamic Online reweighting (DOT)\\n\\nInput: inference step $t := 0$; test stream samples $\\\\{x_j\\\\}$; pre-trained model $\\\\{\\\\theta_0, a_0\\\\}$; class-frequency vector $z_0$; loss function $L$; smooth coefficient $\\\\lambda$.\\n\\n1. while the test mini-batch $\\\\{x_{mt+b}\\\\}_{b=1}^B$ arrives do\\n2. \\\\hspace{1em} $t = t + 1$\\n3. \\\\hspace{1em} $\\\\{p_{mt+b}\\\\}_{b=1}^B, f\\\\{\\\\theta_{t-1}, a_{t-1}\\\\} \\\\leftarrow \\\\text{Forward}\\\\(\\\\{x_{mt+b}\\\\}_{b=1}^B, f\\\\{\\\\theta_{t-1}, a_{t-1}\\\\}\\\\) \\\\quad \\\\text{// output predictions}$\\n4. \\\\hspace{1em} for $b = 1$ to $B$ do\\n5. \\\\hspace{2em} $k^*_{mt+b} = \\\\arg \\\\max_{k \\\\in [1,K]} p_{mt+b}[k] \\\\quad \\\\text{// predicted label}$\\n6. \\\\hspace{2em} $w_{mt+b} = \\\\frac{1}{z_{t-1}[k^*_{mt+b}]+\\\\epsilon}$ \\\\quad \\\\text{// assign sample weight}$\\n7. \\\\hspace{2em} $\\\\bar{w}_{mt+b} = \\\\frac{B \\\\cdot w_{mt+b}}{P_{B \\\\cdot b=1} w_{mt+b}}$ \\\\quad \\\\text{// normalize sample weight}$\\n8. \\\\hspace{1em} l = \\\\frac{1}{BP_{B \\\\cdot b=1} \\\\bar{w}_{mt+b}} \\\\cdot L(p_{mt+b}) \\\\quad \\\\text{// combine sample weight with loss}$\\n9. \\\\hspace{1em} f\\\\{\\\\theta_t, a_t\\\\} \\\\leftarrow \\\\text{Backward & Update}\\\\(l, f\\\\{\\\\theta_{t-1}, a_{t-1}\\\\}\\\\) \\\\quad \\\\text{// update $\\\\theta$}$\\n10. $z_t = \\\\lambda z_{t-1} + (1-\\\\lambda) \\\\cdot P_{B \\\\cdot b=1} p_{mt+b}$ \\\\quad \\\\text{// update $z$}$\\n\\nThe imbalanced data is harmful during the normal training phase, resulting in biased models and poor overall accuracy (Liu et al., 2019; Menon et al., 2021). Our main motivation is that the test-time adaptation methods also involve gradient-based optimization which is built on the model predictions; however, the predictions are actually imbalanced, particularly for dependent or class-imbalanced streams and the low-entropy-emphasized adaptation methods. Therefore, we argue that the test-time optimization is biased towards some dominant classes actually, resulting in inferior performance. A vicious circle is formed by skewed optimization and imbalanced predictions.\\n\\nTreatment II: Dynamic online re-weighting (DOT) can alleviate the biased optimization. Many methods have been developed to deal with class imbalance during the training phase, but they face several challenges when it comes to fully test-time adaptation: (i) Network architectures are immutable. (ii) Because test sample class frequencies are dynamic and agnostic, the common constraint of making the output distribution uniform (Liang et al., 2020) is no longer reasonable. (iii) Inference and adaptation must occur in real-time when test mini-batch arrived (only a single pass through test data, no iterative learning).\\n\\nGiven these constraints, we propose DOT as presented in Algorithm 1. DOT is mainly derived from class-wise re-weighting (Cui et al., 2019). To tackle the dynamically changing and unknown class frequencies, we use a momentum-updated class-frequency vector $z \\\\in \\\\mathbb{R}^K$ instead (Line 10 of Algorithm 1), which is initiated with $z[k] = \\\\frac{1}{K}, k = 1, 2, \\\\ldots, K$. For each inference step, we assign weights to each test sample based on its pseudo label and the current $z$ (Line 5, 6 of Algorithm 1). Specifically, when $z[k]$ is relatively large, during the subsequent adaptation, DOT will reduce the contributions of the $k$th class samples (pseudo label) and emphasize others. It is worth noting that DOT can alleviate the biased optimization caused by the pre-trained model (e.g., inter-class similarity), test stream (e.g., class-imbalanced scenario) simultaneously.\\n\\nDOT is a general idea to tackle the biased optimization, some parts in Algorithm 1 have multiple options, so it can be combined with different existing test-time adaptation techniques. For the \u201cForward (\u00b7)\u201d function (Line 3 of Algorithm 1), the discussed BN adapt and TBR can be incorporated. For the loss function $L(\u00b7)$ (Line 8 of Algorithm 1), studies usually employ the entropy minimization loss: $L(p_b) = -\\\\sum_{k=1}^K p_b[k] \\\\log p_b[k]$ or the cross-entropy loss with pseudo labels: $L(p_b) = -I_{p_b[k^*b] \\\\geq \\\\tau} \\\\cdot \\\\log p_b[k^*b]$ (commonly, only samples with high prediction confidence are utilized, $\\\\tau$ is a pre-defined threshold). Similarly, for entropy minimization, EntW (Niu et al., 2022) also discards the high-entropy samples and emphasizes the low-entropy ones: $L(p_b) = -I_{H_b<\\\\tau} \\\\cdot e^{\\\\tau - H_b} \\\\cdot P_{K \\\\cdot k=1} p_b[k] \\\\log p_b[k]$, where $H_b$ is the entropy of sample $x_b$.\\n\\n4 EXPERIMENTS\\n\\nDatasets and models. We conduct experiments on common datasets CIFAR100-C, ImageNet-C (Hendrycks & Dietterich, 2019), ImageNet-R (Hendrycks et al., 2021), and a newly introduced video (segments) dataset: the subset of YouTube-BoundingBoxes (YTBB-sub) (Real et al., 2017). CIFAR100-C / ImageNet-C contains 15 corruption types, each with 5 severity levels; we use the\"}"}
{"id": "eGm22rqG93", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Following Cui et al. (2019), we resample the test images of COCO. Details of the tasks, datasets and examples are provided in Appendix A.1.\\n\\nEvaluation in IS+CI and DS+CI scenarios. We test on the corresponding original training data. For YTBB-sub, we use a ResNet-18 trained on the COCO train2017 images. For the remaining datasets, we use the trained ResNet-50 model from Torchvision. The models are trained on the related images of COCO. Details of the tasks, datasets and examples are provided in Appendix A.1.\\n\\nResults are averaged over 15 different corruption types for CIFAR100-C and ImageNet-C in the IS+CI and DS+CI scenarios. For CIFAR100-C and ImageNet-C, we report the mean accuracy over classes (Acc, %) (Liu et al., 2019).\\n\\nMetrics.\\n\\nImplementation.\\n\\nThe configurations are mainly followed previous work Wang et al. (2021; 2022a); the main text, please see detailed performance on each corruption type in Appendix A.5, A.6. Unless otherwise specified, we report the mean accuracy over classes (Acc, %) (Liu et al., 2019). The results are reported in Table 4. As can be seen, the proposed DELTA consistently improves the previous adaptation approaches PL, TENT, and Ent-W in this work.\\n\\nCoTTA* achieves 14.3% gain over PL, 13.1% gain over TENT, and 5.6% gain over Ent-W.\\n\\nEvaluation in IS+CB scenario.\\n\\nThe results on CIFAR100-C are reported in Table 4. As can be seen, the proposed DELTA significantly outperforms the baselines, achieving 14.3% gain over PL, 13.1% gain over TENT, and 5.6% gain over Ent-W.\\n\\nEvaluation in DS+CB scenario.\\n\\nTable 5: Acc in DS+CB scenario with varying \u03c1.\\n\\n| Method    | CIFAR100-C | ImageNet-C |\\n|-----------|------------|------------|\\n| PL        | 54.9\u00b10.5   | 50.5\u00b10.2   |\\n| TENT+DELTA| 68.7\u00b11.0   | 67.3\u00b10.5   |\\n| Ent-W+DELTA| 69.3\u00b10.8  | 69.5\u00b10.9   |\\n| CoTTA     | 53.8\u00b10.4   | 54.1\u00b10.0   |\\n| TTA       | 70.1\u00b10.7   | 68.5\u00b10.1   |\\n| LAME      | 49.0\u00b10.5   | 50.8\u00b10.3   |\\n| BN adapt  | 64.6\u00b10.2   | 63.5\u00b10.1   |\\n| DELTA     | 68.8\u00b10.0   | 68.9\u00b10.0   |\\n\\nThe highest level unless otherwise specified. ImageNet-R contains various styles (Niu et al., 2022), for evaluations on CIFAR100-C, ImageNet-C / -R, we use the trained ResNet-50 model from Torchvision. The models are trained on the ImageNet training dataset and the corresponding ImageNet-R test set.\\n\\nBaselines.\\n\\nWe adopt the following SOTA methods as baselines: labeled data augmentation (LDA) (Schneider et al., 2020); continual test-time adaptation (CoTTA/CoTTA*: Schneider et al., 2020; Nado et al., 2020); test-time entropy minimization (TENT) (Wang et al., 2021); marginal entropy minimization (Ent-W) (Wang et al., 2021); cian adjusted maximum-likelihood estimation (LAME) (Boudiaf et al., 2021); efficient test-time adaptation (ETA) (Niu et al., 2022); entropy minimization with one test point (MEMO) (Zhang et al., 2022); test-time entropy minimization (TENT) (Wang et al., 2021); marginal entropy minimization (Ent-W) (Wang et al., 2021).\\n\\ne.g., TTA \u2013 17.7, Source 53.5 \u00b1 0.0.\\n\\nDELTA successfully helps models adapt to environments across different concentration factors. It is worth noting that DELTA\u2019s performance degradation in the dependent streams, following Yurochkin et al. (2021) and Efrat et al. (2022a, b), is alleviated when the settings \u03c1 = 0.5.\\n\\nWe evaluate the proposed DELTA method on CIFAR100-C and ImageNet-C datasets with varying \u03c1 values (\u03c1 \u2208 {0, 0.1, 0.5, 1}). The results are provided in Table 5.\\n\\nThe repre...\"}"}
{"id": "eGm22rqG93", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Method            | Accuracy (%) |\\n|-------------------|--------------|\\n| ResNet18          | 35.0         |\\n| ResNet18 +1.0     | 36.5         |\\n| Ent-W             | 40.0         |\\n| Ent-W +1.3        | 41.3         |\\n| TENT              | 45.0         |\\n| TENT +1.5         | 46.5         |\\n| Ent-W +1.4        | 41.4         |\\n| TENT +1.7         | 46.7         |\\n| Ent-W +1.5        | 41.5         |\\n| TENT +1.9         | 46.9         |\\n\\n**Table 6:** Mean acc in IS+CI, DS+CI scenarios with different architectures. More analyses (e.g., Evaluation with different architectures.)\\n\\n**Table 7:** Results on in-distribution test data. ImageNet-R is inherently class-imbalanced and still difficult to recognize for DELTA, the gain is not as great as on ImageNet-C. For YTBB-sub, dependent and class-imbalanced samples are encountered naturally. We see that classical methods suffer from severe degradation, whereas DELTA assists them in achieving good performance.\\n\\n**Table 8:** Mean acc on realistic out-of-distribution datasets ImageNet-R and YTBB-sub. ImageNet-C. For YTBB-sub, dependent and class-imbalanced samples are encountered naturally. We see that classical methods suffer from severe degradation, whereas DELTA assists them in achieving good performance.\\n\\n**Table 9:** We analyze their contributions on the basis of TENT with four scenarios and two datasets. More analyses (e.g., Evaluation with different architectures.)\\n\\n**Figure 4:** Across architecture.\\n\\nFigure 4 indicates that DELTA can help improve previous methods. TBR is extremely effective and necessary for dependent samples.\\n\\n**Table 10:** Mean acc in IS+CI, DS+CI scenarios with different architectures. More analyses (e.g., Evaluation with different architectures.)\\n\\n**Figure 4:** Across architecture.\"}"}
{"id": "eGm22rqG93", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"APPENDIX A.1 DATASETS\\n\\nExamples of ImageNet-R and ImageNet-C are shown in Figure 6 and Figure 7 respectively. ImageNet-R Hendrycks et al. (2021) holds a variety of renditions (sketches, graphics, paintings, plastic objects, cartoons, graffiti, origami, patterns, deviantart, plush objects, sculptures, art, tattoos, toys, embroidery, video game) of 200 ImageNet classes, resulting in 30,000 images.\\n\\nCIFAR100-C and ImageNet-C are established in Hendrycks & Dietterich (2019). CIFAR100-C contains 10,000 images with 15 corruption types: Gaussian Noise (abbr. Gauss), Shot Noise (Shot), Impulse Noise (Impul), Defocus Blur (Defoc), Frosted Glass Blur (Glass), Motion Blur (Motion), Zoom Blur (Zoom), Snow, Frost, Fog, Brightness (Brit), Contrast (Contr), Elastic, Pixelate (Pixel), JPEG. There are 50,000 images for each corruption type in ImageNet-C, others are the same as CIFAR100-C.\\n\\nFor the real-world applications with dependent and class-imbalanced test samples, we consider an automatic video content moderation task (e.g., for the short-video platform), which needs to recognize the categories of interest from the extracted frames. It is exactly a natural DS+CI scenario. We collect 1686 test videos from YouTube, which are annotated in YouTube-BoundingBoxes dataset. 49006 video segments are extracted from these videos and form the test stream in this experiment, named YTBB-sub here. We consider 21 categories. For the trained model, we adopt a model (ResNet18) trained on the related images from COCO dataset. Thus, there is a natural difference between the training domain and test domain. The consecutive video segments form the natural dependent samples (an object usually persists over several frames) as shown in Figure 8. Moreover, the test class distribution is also skewed naturally as shown in Figure 8.\\n\\nTo simulate dependent test samples, for each class, we sample $q_k \\\\sim \\\\text{Dir}_J(\\\\rho)$, $q_k \\\\in \\\\mathbb{R}^J$ and allocate a $q_{k,j}$ proportion of the $k$th class samples to piece $j$, then the $J$ pieces are concatenated to form a test stream in our experiments ($J$ is set to 10 for all experiments); $\\\\rho > 0$ is a concentration factor, when $\\\\rho$ is small, samples belong to the same category will concentrate in test stream.\\n\\nTo simulate class-imbalanced test samples, we re-sample data points with an exponential decay in frequencies across different classes. We control the degree of imbalance through an imbalance factor $\\\\pi$, which is defined as the ratio between sample sizes of the least frequent class and the most frequent class.\\n\\nFor DS+CI scenario, we mimic a class-imbalanced test set first, then the final test samples are dependently sampled from it.\"}"}
{"id": "eGm22rqG93", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: Different corruption types of class n01694178 (African chameleon) from ImageNet-C.\\n\\nFigure 8: Characters of YTBB-sub dataset.\\n\\nA.2 THE ALGORITHM DESCRIPTION OF TBR\\n\\nWe present the detailed algorithm description of TBR in Algorithm 2.\"}"}
{"id": "eGm22rqG93", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 2: Test-time Batch Renormalization (TBR) module\\n\\nInput:\\nmini-batch test features $v \\\\in \\\\mathbb{R}^{B \\\\times C \\\\times S \\\\times S'}$ with batch size $B$, $C$ channels, height $S$ and width $S'$; learnable affine parameters $\\\\gamma \\\\in \\\\mathbb{R}^C$, $\\\\beta \\\\in \\\\mathbb{R}^C$; current test-time moving mean $\\\\hat{\\\\mu}_{ema} \\\\in \\\\mathbb{R}^C$ and standard deviation $\\\\hat{\\\\sigma}_{ema} \\\\in \\\\mathbb{R}^C$; smoothing coefficient $\\\\alpha$.\\n\\n1. $\\\\hat{\\\\mu}_{batch}[c] = \\\\frac{1}{BSS'} \\\\sum_{b,s,s'} v[b,c,s,s']$, $c=1,2,\\\\ldots,C$ // get mean (for each channel)\\n2. $\\\\hat{\\\\sigma}_{batch}[c] = \\\\sqrt{\\\\frac{1}{BSS'} \\\\sum_{b,s,s'} (v[b,c,s,s']^2 - \\\\hat{\\\\mu}_{batch}[c]^2) + \\\\epsilon}$, $c=1,2,\\\\ldots,C$ // get standard deviation (for each channel)\\n3. $r = \\\\text{sg}(\\\\hat{\\\\sigma}_{batch}) \\\\hat{\\\\sigma}_{ema}$ // get $r$\\n4. $d = \\\\text{sg}(\\\\hat{\\\\mu}_{batch}) \\\\hat{\\\\mu}_{ema} \\\\hat{\\\\sigma}_{ema}$ // get $d$\\n5. $v^* = v - \\\\hat{\\\\mu}_{batch} \\\\hat{\\\\sigma}_{batch} \\\\cdot r + d // normalize$\\n6. $v^\\\\star = \\\\gamma \\\\cdot v^* + \\\\beta // scale and shift$\\n7. $\\\\hat{\\\\mu}_{ema} \\\\leftarrow \\\\alpha \\\\cdot \\\\hat{\\\\mu}_{ema} + (1-\\\\alpha) \\\\cdot \\\\text{sg}(\\\\hat{\\\\mu}_{batch})$ // update $\\\\hat{\\\\mu}_{ema}$\\n8. $\\\\hat{\\\\sigma}_{ema} \\\\leftarrow \\\\alpha \\\\cdot \\\\hat{\\\\sigma}_{ema} + (1-\\\\alpha) \\\\cdot \\\\text{sg}(\\\\hat{\\\\sigma}_{batch})$ // update $\\\\hat{\\\\sigma}_{ema}$\\n\\nOutput:\\n$v^\\\\star$, $\\\\hat{\\\\mu}_{ema}$, $\\\\hat{\\\\sigma}_{ema}$\\n\\nA.3 IMPLEMENTATIONS\\n\\nWe use Adam optimizer with learning rate of $1 \\\\times 10^{-3}$, batch size of 200 for CIFAR100-C; SGD optimizer with learning rate of $2.5 \\\\times 10^{-4}$, batch size of 64 for ImageNet-C/-R; SGD optimizer with learning rate of $2.5 \\\\times 10^{-4}$, batch size of 200 for YTBB-sub. For DELTA, the hyper-parameters $\\\\alpha$ and $\\\\lambda$ are roughly selected from $\\\\{0.9, 0.95, 0.99, 0.999\\\\}$ on validation sets, e.g., the extra sets with corruption types outside the 15 types used in the benchmark. The smoothing coefficient $\\\\alpha$ in TBR is set to 0.95 for CIFAR100-C and ImageNet-C/-R, 0.999 for YTBB-sub, $\\\\lambda$ in DOT is set to 0.95 for ImageNet-C/-R and 0.9 for CIFAR100-C / YTBB-sub.\\n\\nThen, we summarize the implementation details of the compared methods here, including BN adapt, PL, TENT, LAME, ETA, Ent-W, and CoTTA (CoTTA*). Unless otherwise specified, the optimizer, learning rate, and batch size are the same as those described in the main paper. For BN adapt, we follow the operation in Nado et al. (2020) and the official code of TENT (https://github.com/DequanWang/tent), i.e., using the test-time normalization statistics completely. Though one can introduce a hyper-parameter to adjust the trade-off between current statistics and those inherited from the trained model ($a_0$) (Schneider et al., 2020), we find this strategy does not lead to significant improvement and its effect varies from dataset to dataset. For PL and TENT, besides the normalization statistics, we update the affine parameters in BN modules. The confidence threshold in PL is set to 0.4, which can produce acceptable results in most cases. We adopt/modify the official implementation https://github.com/DequanWang/tent to produce the results of TENT/PL. For LAME, we use the k-NN affinity matrix with 5 nearest neighbors following Boudiaf et al. (2022) and the official implementation https://github.com/fiveai/LAME. For ETA, the entropy constant threshold is set to $0.4 \\\\times \\\\ln K$ ($K$ is the number of task classes), and the similarity threshold is set to $0.4/0.05$ for CIFAR/ImageNet experiments following the authors' suggestion and official implementation https://github.com/mr-eggplant/EATA. For Ent-W, the entropy constant threshold is set to $0.4$ or $0.5$ times $\\\\ln K$. For CoTTA, the used random augmentations include color jitter, random affine, gaussian blur, random horizontal flip, and gaussian noise. 32 augmentations are employed in this method. The learning rate is set to 0.01 for ImageNet experiments following official implementation https://github.com/qinenergy/cotta. The restoration probability is set to 0.01 for CIFAR experiments and 0.001 for ImageNet experiments. The augmentation threshold is set to 0.72 for CIFAR experiments and 0.1 for ImageNet experiments. The exponential-moving-average factor is set to 0.999 for all experiments. CoTTA optimizes all learnable parameters during adaptation.\\n\\nA.4 ADDITIONAL ANALYSIS\\n\\nFully test-time adaptation with small (test) batch size.\\n\\nIn the main paper, we report results with the default batch size following previous studies. Here, we study test-time adaptation with a much smaller batch size. The small batch size brings two serious challenges: the normalization statistics can be inaccurate and fluctuate dramatically; the gradient-based optimization can be noisy. Previous studies often use a small corruption type set (with $a_0=1$) and a small $\\\\lambda$.\"}"}
{"id": "eGm22rqG93", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ous study (Niu et al., 2022) employs a sliding window with $L$ samples in total (including $L-B$ previous samples, assuming $L > B$, $L\\\\%B=0$ here) to perform adaptation. However, this strategy significantly increases the computational cost: $L \\\\times B \\\\times$ forward and backward, e.g., $64 \\\\times 64$ when $B=1$, $L=64$. We employ another strategy, called \\\"fast-inference and slow-update\\\". When the samples arrive, infer them instantly with the current model but do not perform adaptation; the model is updated with the recent $L$ samples every $L \\\\times B$ mini-batches. Thus, this strategy only needs $2 \\\\times$ forward and $1 \\\\times$ backward. Note that the two strategies both need to cache some recent test samples, which may be a bit against the \\\"online adaptation\\\". We evaluate TENT and DELTA on the IS+CB test stream of CIFAR100-C with batch sizes 128, 16, 8, and 1. The results are listed in Table 11. We find that TENT suffers from severe performance degeneration when the batch size is small, which is due to TENT always using the normalization statistics derived from the test mini-batches, thus it is still affected by the small batch size during \\\"fast-inference\\\". With the assistance of DELTA, the performance degradation can be significantly alleviated: it only drops by 0.7% (from 69.8% to 69.1%) when $B=1$.\\n\\nTable 11: Results (classification accuracy, %) with different batch sizes on IS+CB test stream of CIFAR100-C.\\n\\n| Method    | 128  | 16   | 8    | 1    |\\n|-----------|------|------|------|------|\\n| Source    | 53.5 | 53.5 | 53.5 | 53.5 |\\n| TENT      | 68.7 | 64.9 | 59.9 | 1.6  |\\n| TENT+DELTA| 69.8 | 69.4 | 69.0 | 69.1 |\\n\\nThe initialization of TBR's normalization statistics. As described in Section 3.2, TBR keeps the moving normalization statistics $\\\\hat{\\\\mu}_{ema}$, $\\\\hat{\\\\sigma}_{ema}$, we usually have two ways to initialize them: using the statistics $\\\\hat{\\\\mu}_{batch1}$, $\\\\hat{\\\\sigma}_{batch1}$ derived from the first test mini-batch (First); using the statistics $\\\\mu_{ema}$, $\\\\sigma_{ema}$ inherited from the trained model (Inherit). In the main paper, we use the \\\"First\\\" initialization strategy. However, it is worth noting that \\\"First\\\" is not reasonable for too small batch size. We perform TENT+DELTA with the above two initialization strategies and different batch sizes on the IS+CB test stream of CIFAR100-C. Figure 9 summaries the results, we can see that when the batch size is too small, using the inherited normalization statistics as initialization is better; when the batch size is acceptable (just $\\\\geq 8$ for CIFAR100-C), using the \\\"First\\\" initialization strategy is superior.\\n\\nInfluence of random seeds. As fully test-time adaptation is established based on a pre-trained model, i.e., does not need random initialization; methods like PL, TENT, Ent-W, and our DELTA...\"}"}
{"id": "eGm22rqG93", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ablation on DOT.\\n\\nWe examine the performance of DOT with another way to get the sample weights (Line 5, 6 in Algorithm 1). One can discard line 5 and modify line 6 to adopt the original soft probabilities:\\n\\n\\\\[ \\\\omega_m(t) + b = \\\\frac{1}{\\\\log(z_t - 1) + \\\\epsilon} \\\\cdot p_m(t) + b[k] \\\\]\\n\\nWe compare the hard label strategy (Algorithm 1) with the soft one in Table 14 (on the basis of Enw-W+TBR, on ImageNet-C). We find that both strategies work well in all scenarios, demonstrating the effectiveness of the idea of DOT. The performance of the soft strategy is slightly worse than the hard strategy in some scenarios. However, we think it is difficult to say \u201chard labels are necessarily better than soft labels\u201d or \u201csoft labels are necessarily better than hard labels\u201d, for example, the two strategies both exist in recent semi-supervised methods: hard label in FixMatch, soft label in UDA.\"}"}
{"id": "eGm22rqG93", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 14: Ablation on DOT.\\n\\n| Method       | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|--------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source       |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n| IS+CB scenario |     |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n| BN adapt     | 57.6  | 59.0 | 56.9  | 72.3  | 58.0  | 70.3   | 71.8 | 64.8 | 64.8  | 58.1 | 73.3 | 69.7  | 64.0    | 66.7  | 58.4 | 64.4 |\\n| BN adapt+TEMA | 58.0 | 59.7 | 57.1  | 72.5  | 58.6  | 70.3   | 72.5 | 65.3 | 65.5  | 58.3 | 74.1 | 70.2  | 64.4    | 67.0  | 59.2 | 64.9 |\\n| TENT         | 62.4  | 64.7 | 67.3  | 74.3  | 62.5  | 72.4   | 74.2 | 69.4 | 67.6  | 66.8 | 75.6 | 71.8  | 66.9    | 71.3 | 62.6 | 68.7 |\\n| TENT+TEMA    | 19.4  | 14.9 | 16.4  | 31.9  | 14.8  | 25.0   | 28.9 | 24.3 | 25.0  | 19.3 | 31.1 | 24.3  | 25.5    | 26.0  | 18.2 | 23.0 |\\n| TENT+TBR     | 62.1  | 64.7 | 67.7  | 74.6  | 62.0  | 72.6   | 74.0 | 69.7 | 67.9  | 67.8 | 76.2 | 71.6  | 67.1    | 71.8 | 63.3 | 68.9 |\\n| DS+CB scenario |     |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n| BN adapt     | 24.1  | 24.7 | 23.4  | 30.2  | 23.2  | 29.9   | 29.8 | 26.6 | 27.2  | 24.2 | 30.0 | 28.6  | 25.7    | 27.8 | 23.8 | 26.6 |\\n| BN adapt+TEMA | 56.0 | 57.8 | 55.2  | 70.7  | 56.7  | 68.6   | 70.2 | 63.2 | 63.6  | 56.6 | 71.7 | 67.8  | 62.2    | 64.8 | 57.2 | 62.8 |\\n| TENT         | 21.2  | 22.7 | 21.9  | 26.6  | 20.0  | 25.5   | 26.6 | 23.0 | 22.2  | 21.7 | 26.3 | 21.6  | 21.7    | 24.7 | 20.3 | 23.1 |\\n| TENT+TEMA    | 18.0  | 17.3 | 15.2  | 34.2  | 18.6  | 26.3   | 36.6 | 18.9 | 27.2  | 24.6 | 36.2 | 25.8  | 26.5    | 28.6 | 20.4 | 25.0 |\\n\\nA.5 RESULTS OF EACH CORRUPTION TYPE ON CIFAR100-C.\\n\\nTable 2 has compared the usages of different normalization statistics, we further provide the detailed results of all corruption types in Table 15.\\n\\nTable 15 presents the results of all corruption types under different batch sizes and the two initialization strategies for normalization statistics in TBR, the averaged results have been illustrated in Table 11 and Figure 9 respectively.\\n\\nTable 17 summarises the detailed performance on IS+CB test stream with different severity levels.\\n\\nTable 18 compares the test-time adaptation methods in IS+CB scenario; Table 19 for DS+CB test stream ($\\\\rho = 1.0$), Table 20 for DS+CB test stream ($\\\\rho = 0.5$), Table 21 for DS+CB test stream ($\\\\rho = 0.1$); Table 22, 23 for IS+CI data with $\\\\pi = 0.1$, $\\\\pi = 0.05$; Table 24 / Table 25 for DS+CI test data with $\\\\rho = 0.5$ and $\\\\pi = 0.1 / \\\\pi = 0.05$.\\n\\nA.6 RESULTS OF EACH CORRUPTION TYPE ON ImageNet-C.\\n\\nTable 26 compares the test-time adaptation methods in IS+CB scenario and Table 27 further compares them with different model architectures; Table 28, Table 29, and Table 30 for DS+CB test streams with $\\\\rho = 1.0$, $\\\\rho = 0.5$ and $\\\\rho = 0.1$, respectively; Table 31, 32 for IS+CI data with $\\\\pi = 0.1$, $\\\\pi = 0.05$; Table 33 / Table 34 for DS+CI test data with $\\\\rho = 0.5$ and $\\\\pi = 0.1 / \\\\pi = 0.05$. The results in Table 15-Table 34 are obtained with seed 2020.\\n\\nTable 15: Comparison of the normalization statistics on IS+CB and DS+CB test streams of CIFAR100-C with $B = 128$ in terms of classification accuracy (%).\\n\\n| Source       |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\\n|--------------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|\\n| IS+CB scenario |     |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\\n| BN adapt     | 57.6 | 59.0 | 56.9 | 72.3 | 58.0 | 70.3 | 71.8 | 64.8 | 64.8 | 58.1 | 73.3 | 69.7 | 64.0 | 66.7 | 58.4 | 64.4 |\\n| BN adapt+TEMA | 58.0 | 59.7 | 57.1 | 72.5 | 58.6 | 70.3 | 72.5 | 65.3 | 65.5 | 58.3 | 74.1 | 70.2 | 64.4 | 67.0 | 59.2 | 64.9 |\\n| TENT         | 62.4 | 64.7 | 67.3 | 74.3 | 62.5 | 72.4 | 74.2 | 69.4 | 67.6 | 66.8 | 75.6 | 71.8 | 66.9 | 71.3 | 62.6 | 68.7 |\\n| TENT+TEMA    | 19.4 | 14.9 | 16.4 | 31.9 | 14.8 | 25.0 | 28.9 | 24.3 | 25.0 | 19.3 | 31.1 | 24.3 | 25.5 | 26.0 | 18.2 | 23.0 |\\n| TENT+TBR     | 62.1 | 64.7 | 67.7 | 74.6 | 62.0 | 72.6 | 74.0 | 69.7 | 67.9 | 67.8 | 76.2 | 71.6 | 67.1 | 71.8 | 63.3 | 68.9 |\\n| DS+CB scenario |     |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |\\n| BN adapt     | 24.1 | 24.7 | 23.4 | 30.2 | 23.2 | 29.9 | 29.8 | 26.6 | 27.2 | 24.2 | 30.0 | 28.6 | 25.7 | 27.8 | 23.8 | 26.6 |\\n| BN adapt+TEMA | 56.0 | 57.8 | 55.2 | 70.7 | 56.7 | 68.6 | 70.2 | 63.2 | 63.6 | 56.6 | 71.7 | 67.8 | 62.2 | 64.8 | 57.2 | 62.8 |\\n| TENT         | 21.2 | 22.7 | 21.9 | 26.6 | 20.0 | 25.5 | 26.6 | 23.0 | 22.2 | 21.7 | 26.3 | 21.6 | 21.7 | 24.7 | 20.3 | 23.1 |\\n| TENT+TEMA    | 18.0 | 17.3 | 15.2 | 34.2 | 18.6 | 26.3 | 36.6 | 18.9 | 27.2 | 24.6 | 36.2 | 25.8 | 26.5 | 28.6 | 20.4 | 25.0 |\\n| TENT+TBR     | 55.8 | 60.0 | 58.8 | 70.7 | 57.2 | 67.4 | 69.7 | 64.4 | 62.8 | 60.2 | 71.5 | 64.0 | 60.9 | 67.1 | 56.4 | 63.1 |\"}"}
{"id": "eGm22rqG93", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 16: Comparison of different batch sizes and the initialization strategies for TBR\u2019s normaliza-\\n\\ntion statistics on IS+CB test stream of CIFAR100-C in terms of classification accuracy (%).\\n\\n| Method        | Init | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|---------------|------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source        | -    | 27.0  | 32.0 | 60.6  | 70.7  | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7| 70.5 | 44.9  | 62.8    | 25.3  | 58.8 | 53.5|\\n| TENT, $B=128$ |       | 62.4  | 64.7 | 67.3  | 74.3  | 62.5  | 72.4   | 74.2 | 69.4 | 67.6  | 66.8| 75.6 | 71.8  | 66.9    | 71.3  | 62.6 | 68.7|\\n| TENT, $B=16$  |       | 58.7  | 61.0 | 63.8  | 70.8  | 58.7  | 68.8   | 70.3 | 65.8 | 64.1  | 63.3| 72.2 | 66.9  | 62.7    | 67.6  | 59.4 | 64.9|\\n| TENT, $B=8$   |       | 54.0  | 56.1 | 58.6  | 65.9  | 53.0  | 64.1   | 65.4 | 61.0 | 58.6  | 57.8| 67.1 | 62.9  | 58.1    | 62.8  | 53.8 | 59.9|\\n| TENT, $B=1$   |       | 1.5   | 1.5  | 1.6   | 1.6   | 1.6   | 1.8    | 1.7  | 1.8  | 1.6   | 1.5| 1.6  | 1.6   | 1.5    | 1.8  | 1.6  | 1.6|\\n| TENT+DELTA, $B=128$ Inherit | 62.4 | 63.9 | 69.0 | 75.3 | 63.2 | 73.2 | 74.8 | 69.8 | 69.2 | 66.6 | 76.0 | 71.3 | 67.4 | 69.7 | 64.3 | 69.1|\\n| TENT+DELTA, $B=128$ First | 64.0 | 66.0 | 69.1 | 75.3 | 63.3 | 73.0 | 74.6 | 70.3 | 69.4 | 68.1 | 76.7 | 72.9 | 67.6 | 72.3 | 64.6 | 69.8|\\n| TENT+DELTA, $B=16$ Inherit | 62.3 | 64.0 | 69.1 | 75.2 | 63.1 | 73.3 | 74.8 | 69.6 | 69.3 | 66.7 | 75.9 | 71.2 | 67.3 | 69.6 | 64.2 | 69.0|\\n| TENT+DELTA, $B=16$ First | 63.5 | 65.5 | 68.2 | 74.8 | 63.2 | 72.7 | 74.6 | 70.2 | 69.3 | 67.7 | 75.7 | 72.4 | 67.5 | 71.9 | 63.9 | 69.4|\\n| TENT+DELTA, $B=8$ Inherit | 62.4 | 64.0 | 69.0 | 75.2 | 63.1 | 73.3 | 74.8 | 69.7 | 69.4 | 66.6 | 75.9 | 71.2 | 67.3 | 69.6 | 64.2 | 69.0|\\n| TENT+DELTA, $B=8$ First | 60.0 | 62.0 | 64.4 | 71.4 | 59.5 | 69.0 | 71.4 | 65.6 | 65.7 | 62.9 | 72.6 | 64.0 | 63.6 | 68.6 | 59.8 | 65.4|\\n\\nTable 17: Classification accuracy (%) on IS+CB test stream of CIFAR100-C with different severity\\n\\n| Method        | Level | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|---------------|-------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source 1      |       | 64.2  | 70.9 | 77.6 | 78.9 | 54.4  | 77.0   | 76.8 | 76.5 | 74.2  | 78.4| 78.7 | 78.2 | 74.4    | 76.5 | 70.5 | 73.8|\\n| Source 2      |       | 49.3  | 63.6 | 75.3 | 78.1 | 56.6  | 75.1   | 76.6 | 69.9 | 69.7  | 76.1| 77.7 | 75.2 | 75.0    | 72.3 | 65.8 | 70.4|\\n| Source 3      |       | 36.5  | 47.2 | 73.1 | 76.8 | 60.6  | 72.3   | 75.4 | 69.6 | 62.1  | 72.3| 76.6 | 71.9 | 73.7    | 69.1 | 64.1 | 66.8|\\n| Source 4      |       | 31.2  | 40.6 | 68.0 | 75.2 | 39.5  | 72.4   | 74.0 | 65.2 | 61.1  | 65.8| 74.9 | 65.7 | 68.9    | 52.3 | 62.5 | 61.2|\\n| Source 5      |       | 27.0  | 32.0 | 60.6 | 70.7 | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7| 70.5 | 44.9  | 62.8    | 25.3 | 58.8 | 53.5|\\n\\nTable 18: Classification accuracy (%) on IS+CB test stream of CIFAR100-C.\\n\\n| Method        | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|---------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source        | 27.0  | 32.0 | 60.6  | 70.7  | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7| 70.5 | 44.9  | 62.8    | 25.3  | 58.8 | 53.5|\\n| BN adapt      | 57.9  | 59.3 | 57.3  | 72.4  | 58.2  | 70.3   | 72.1 | 65.1 | 65.0  | 58.5| 73.5 | 69.7  | 64.3    | 67.1  | 58.8 | 64.6|\\n| ETA           | 63.2  | 65.3 | 66.9  | 75.1  | 63.2  | 73.1   | 74.9 | 70.0 | 69.7  | 66.9| 76.5 | 73.6  | 67.7    | 72.0  | 64.0 | 69.5|\\n| LAME          | 24.1  | 29.0 | 59.2  | 69.0  | 42.8  | 67.0   | 68.9 | 58.3 | 50.7  | 46.5| 67.6 | 39.2  | 60.3    | 21.4  | 56.7 | 50.7|\\n| CoTTA         | 60.0  | 61.8 | 60.1  | 72.6  | 60.2  | 70.5   | 72.3 | 64.8 | 65.5  | 56.7| 73.6 | 69.9  | 64.3    | 68.4  | 62.6 | 65.5|\\n| CoTTA*        | 60.0  | 62.2 | 60.8  | 73.2  | 62.3  | 71.9   | 73.7 | 67.0 | 67.9  | 59.8| 75.4 | 72.9  | 67.5    | 72.0  | 66.6 | 67.5|\\n| PL            | 61.8  | 64.5 | 65.0  | 74.6  | 62.0  | 72.1   | 74.2 | 68.9 | 68.4  | 64.8| 75.5 | 72.0  | 66.8    | 61.9  | 68.2 | 65.5|\\n| PL+DELTA      | 62.8  | 64.8 | 66.3  | 74.3  | 62.7  | 72.7   | 74.6 | 69.4 | 68.5  | 65.7| 75.5 | 72.8  | 66.8    | 62.7  | 68.7 | 65.5|\\n| TENT          | 62.8  | 65.4 | 66.3  | 74.8  | 62.3  | 72.8   | 74.6 | 69.6 | 68.6  | 66.8| 76.1 | 72.3  | 67.3    | 71.6  | 63.5 | 69.0|\\n| TENT+TBR      | 62.5  | 64.9 | 67.0  | 74.8  | 62.1  | 72.9   | 74.3 | 69.8 | 68.3  | 66.8| 76.6 | 72.0  | 67.1    | 71.9  | 63.0 | 68.9|\\n| TENT+DOT      | 63.6  | 65.7 | 66.9  | 75.1  | 63.0  | 73.1   | 74.8 | 69.8 | 69.0  | 67.1| 76.2 | 73.2  | 67.6    | 71.8  | 63.8 | 69.4|\\n| TENT+DELTA    | 63.5  | 65.7 | 67.8  | 75.1  | 63.3  | 73.1   | 74.7 | 70.3 | 69.3  | 67.4| 76.8 | 72.8  | 67.8    | 72.3  | 63.6 | 69.6|\\n| Ent-W         | 63.5  | 65.5 | 67.2  | 75.1  | 63.2  | 73.1   | 74.8 | 70.1 | 69.8  | 67.1| 76.6 | 73.5  | 67.7    | 72.0  | 64.1 | 69.6|\\n| Ent-W+TBR+Div-W(0.05) | 60.3 | 63.5 | 63.8  | 73.5  | 60.8  | 71.8   | 73.7 | 68.6 | 66.2  | 63.8| 74.9 | 71.8  | 66.7    | 69.9  | 61.7 | 67.4|\\n| Ent-W+TBR+Div-W(0.1) | 63.5 | 65.3 | 67.0  | 75.2  | 62.7  | 72.8   | 74.7 | 70.0 | 69.4  | 66.7| 76.1 | 73.2  | 67.1    | 71.7  | 63.8 | 69.3|\\n| Ent-W+TBR+Div-W(0.2) | 63.8 | 65.6 | 68.1  | 75.3  | 63.1  | 73.4   | 75.0 | 70.7 | 70.0  | 67.4| 77.0 | 73.5  | 67.3    | 72.5  | 64.1 | 69.8|\\n| Ent-W+TBR+Div-W(0.4) | 63.6 | 65.4 | 68.2  | 75.3  | 63.1  | 73.3   | 75.0 | 70.8 | 69.9  | 67.3| 76.9 | 73.6  | 67.1    | 72.6  | 64.0"}
{"id": "eGm22rqG93", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"## Table 19: Classification accuracy (%) on DS+CB ($\\\\rho = 1$) test stream of CIFAR100-C.\\n\\n| Method    | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source    | 27.0  | 32.0 | 60.6  | 70.7  | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7 | 70.5 | 44.9  | 62.8    | 25.3  | 58.8 | 53.5|\\n| BN adapt  | 47.2  | 47.8 | 46.2  | 59.5  | 47.2  | 57.4   | 58.8 | 52.2 | 53.2  | 46.7 | 59.9 | 57.4  | 51.9    | 54.4  | 46.9 | 52.4|\\n| ETA       | 50.1  | 51.2 | 52.6  | 60.3  | 49.4  | 58.7   | 60.2 | 55.2 | 54.7  | 51.2 | 61.0 | 58.0  | 53.2    | 56.8  | 50.1 | 54.9|\\n| LAME      | 28.0  | 34.2 | 68.6  | 80.1  | 52.1  | 78.6   | 80.7 | 70.5 | 61.1  | 57.4 | 79.3 | 49.2  | 73.3    | 26.1  | 68.7 | 60.5|\\n| CoTTA     | 49.1  | 51.2 | 49.7  | 57.7  | 49.3  | 56.8   | 58.6 | 52.8 | 53.6  | 46.6 | 60.0 | 53.6  | 52.6    | 57.3  | 50.9 | 53.3|\\n| CoTTA*    | 49.1  | 51.3 | 49.5  | 57.4  | 49.8  | 56.6   | 58.4 | 53.1 | 54.1  | 46.9 | 59.1 | 54.2  | 53.3    | 57.1  | 52.8 | 53.5|\\n| PL        | 49.9  | 50.5 | 51.5  | 60.0  | 48.3  | 58.2   | 60.4 | 54.2 | 54.6  | 50.4 | 60.7 | 57.4  | 53.0    | 56.5  | 49.2 | 54.3|\\n| PL+DELTA  | 61.3  | 62.9 | 64.4  | 73.9  | 61.8  | 71.7   | 74.0 | 68.1 | 68.0  | 63.9 | 74.9 | 71.2  | 66.2    | 70.1  | 62.2 | 67.6|\\n| TENT      | 49.3  | 50.7 | 52.6  | 59.9  | 48.7  | 57.8   | 59.5 | 53.8 | 53.5  | 50.7 | 60.2 | 56.8  | 52.7    | 56.1  | 49.4 | 54.1|\\n| TENT+DELTA| 62.3  | 64.4 | 66.7  | 74.5  | 62.6  | 72.0   | 74.3 | 68.9 | 68.5  | 65.8 | 75.6 | 72.0  | 66.8    | 71.4  | 63.4 | 68.6|\\n| Ent-W     | 50.0  | 51.3 | 52.9  | 60.3  | 49.3  | 58.9   | 60.3 | 54.9 | 54.9  | 51.1 | 61.0 | 57.8  | 53.1    | 56.7  | 50.0 | 54.8|\\n| Ent-W+DELTA| 62.7 | 64.9 | 67.4  | 74.6  | 62.7  | 72.6   | 74.4 | 69.6 | 69.2  | 66.1 | 75.7 | 72.4  | 66.8    | 71.7  | 64.2 | 69.0|\\n\\n## Table 20: Classification accuracy (%) on DS+CB ($\\\\rho = 0.5$) test stream of CIFAR100-C.\\n\\n| Method    | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source    | 27.0  | 32.0 | 60.6  | 70.7  | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7 | 70.5 | 44.9  | 62.8    | 25.3  | 58.8 | 53.5|\\n| BN adapt  | 43.8  | 45.2 | 43.9  | 56.2  | 44.5  | 54.7   | 55.5 | 49.1 | 50.0  | 43.9 | 57.0 | 54.2  | 48.7    | 51.2  | 45.0 | 49.5|\\n| ETA       | 45.8  | 47.5 | 48.9  | 56.4  | 45.3  | 54.5   | 55.8 | 51.2 | 51.2  | 48.1 | 57.4 | 53.8  | 49.4    | 53.1  | 45.9 | 50.9|\\n| LAME      | 28.5  | 34.8 | 69.7  | 80.8  | 53.5  | 79.6   | 81.8 | 71.9 | 62.7  | 58.6 | 81.1 | 50.6  | 74.5    | 26.9  | 69.5 | 61.6|\\n| CoTTA     | 46.9  | 48.3 | 46.5  | 55.1  | 46.6  | 54.2   | 55.2 | 49.3 | 50.6  | 43.4 | 56.9 | 50.8  | 49.3    | 54.2  | 48.3 | 50.4|\\n| CoTTA*    | 46.9  | 48.4 | 46.5  | 54.5  | 47.2  | 53.8   | 54.4 | 50.0 | 51.2  | 43.9 | 56.1 | 51.5  | 50.3    | 53.9  | 49.4 | 50.5|\\n| PL        | 45.4  | 47.0 | 47.8  | 56.0  | 45.7  | 54.3   | 55.7 | 50.8 | 51.3  | 47.2 | 57.1 | 52.6  | 49.4    | 52.7  | 45.9 | 50.6|\\n| PL+DELTA  | 61.3  | 62.5 | 63.2  | 73.1  | 61.3  | 70.8   | 73.6 | 68.0 | 67.0  | 63.3 | 74.5 | 70.0  | 65.7    | 69.7  | 61.2 | 67.0|\\n| TENT      | 44.8  | 46.7 | 48.4  | 55.9  | 45.5  | 54.0   | 55.2 | 50.0 | 50.1  | 47.3 | 56.6 | 52.2  | 48.4    | 52.6  | 45.6 | 50.2|\\n| TENT+TBR  | 59.7  | 62.4 | 64.6  | 73.3  | 60.7  | 70.7   | 72.9 | 67.3 | 66.6  | 64.2 | 74.2 | 68.9  | 65.0    | 69.5  | 61.0 | 66.7|\\n| TENT+DOT  | 45.9  | 47.5 | 49.3  | 56.8  | 46.4  | 54.8   | 55.8 | 50.8 | 51.1  | 48.2 | 57.4 | 53.6  | 49.6    | 53.0  | 46.4 | 51.1|\\n| TENT+DELTA| 61.3  | 63.5 | 65.5  | 73.9  | 62.2  | 71.5   | 73.8 | 68.3 | 67.5  | 65.6 | 74.8 | 70.8  | 66.1    | 70.4  | 62.0 | 67.8|\\n| Ent-W     | 45.8  | 47.5 | 49.0  | 56.3  | 45.5  | 54.5   | 55.6 | 51.6 | 51.1  | 48.3 | 57.2 | 53.8  | 49.3    | 53.0  | 45.9 | 51.0|\\n| Ent-W+TBR+Div-W(0.05) | 61.5  | 64.0 | 64.1  | 73.8  | 60.7  | 71.7   | 73.5 | 67.6 | 68.2  | 64.2 | 74.8 | 71.0  | 66.4    | 70.3  | 62.2 | 67.6|\\n| Ent-W+TBR+Div-W(0.1) | 62.4  | 63.9 | 65.7  | 74.3  | 61.9  | 71.8   | 73.8 | 68.3 | 68.5  | 65.0 | 75.0 | 71.1  | 66.2    | 70.5  | 62.4 | 68.1|\\n| Ent-W+TBR+Div-W(0.2) | 61.0  | 63.5 | 65.5  | 73.6  | 60.8  | 71.2   | 72.9 | 68.0 | 67.9  | 65.1 | 74.5 | 70.7  | 65.7    | 70.2  | 62.2 | 67.5|\\n| Ent-W+TBR+LA | 60.0  | 62.8 | 64.2  | 72.3  | 59.5  | 69.9   | 71.7 | 66.8 | 66.8  | 63.9 | 73.3 | 69.4  | 64.7    | 69.1  | 61.0 | 66.4|\\n| Ent-W+TBR+Sample-drop | 61.9  | 64.2 | 65.6  | 74.2  | 61.8  | 71.7   | 73.8 | 68.3 | 68.4  | 65.5 | 74.9 | 71.4  | 66.2    | 70.7  | 62.7 | 68.1|\\n| Ent-W+DELTA | 61.9  | 64.2 | 66.0  | 74.3  | 61.9  | 71.9   | 73.9 | 68.3 | 68.5  | 65.9 | 74.9 | 71.5  | 66.4    | 70.9  | 62.9 | 68.2|\\n\\n## Table 21: Classification accuracy (%) on DS+CB ($\\\\rho = 0.1$) test stream of CIFAR100-C.\\n\\n| Method    | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source    | 27.0  | 32.0 | 60.6  | 70.7  | 45.9  | 69.2   | 71.2 | 60.5 | 54.2  | 49.7 | 70.5 | 44.9  | 62.8    | 25.3  | 58.8 | 53.5|\\n| BN adapt  | 31.5  | 32.8 | 31.4  | 40.4  | 31.0  | 39.3   | 40.0 | 35.3 | 35.7  | 31.5 | 40.7 | 38.0  | 34.5    | 36.7  | 31.7 | 35.4|\\n| ETA       | 31.2  | 32.2 |"}
{"id": "eGm22rqG93", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION\\n\\nBowen Zhao\\\\(^1,2\\\\), Chen Chen\\\\(^3\\\\), Shu-Tao Xia\\\\(^1,4\\\\),\\n\\\\(^1\\\\)Tsinghua University, \\\\(^2\\\\)Tencent TEG AI, \\\\(^3\\\\)OPPO research institute, \\\\(^4\\\\)Peng Cheng Laboratory\\nzbw18@mails.tsinghua.edu.cn, chen1634chen@gmail.com, xiast@sz.tsinghua.edu.cn\\n\\nABSTRACT\\n\\nFully test-time adaptation aims at adapting a pre-trained model to the test stream during real-time inference, which is urgently required when the test distribution differs from the training distribution. Several efforts have been devoted to improving adaptation performance. However, we find that two unfavorable defects are concealed in the prevalent adaptation methodologies like test-time batch normalization (BN) and self-learning. First, we reveal that the normalization statistics in test-time BN are completely affected by the currently received test samples, resulting in inaccurate estimates. Second, we show that during test-time adaptation, the parameter update is biased towards some dominant classes. In addition to the extensively studied test stream with independent and class-balanced samples, we further observe that the defects can be exacerbated in more complex test environments, such as (time) dependent or class-imbalanced data. We observe that previous approaches work well in certain scenarios while show performance degradation in others due to their faults. In this paper, we provide a plug-in solution called DELTA for Degradation-free Fully Test-time Adaptation, which consists of two components: (i) Test-time Batch Renormalization (TBR), introduced to improve the estimated normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to address the class bias within optimization. We investigate various test-time adaptation methods on three commonly used datasets with four scenarios, and a newly introduced real-world dataset. DELTA can help them deal with all scenarios simultaneously, leading to SOTA performance.\\n\\n1 INTRODUCTION\\n\\nModels suffer from performance decrease when test and training distributions are mismatched (Quinonero-Candela et al., 2008). Numerous studies have been conducted to narrow the performance gap based on a variety of hypotheses/settings. Unsupervised domain adaptation methods (Ganin et al., 2016) necessitate simultaneous access to labeled training data and unlabeled target data, limiting their applications. Source-free domain adaptation approaches (Liang et al., 2020) only need a trained model and do not require original training data when performing adaptation. Nonetheless, in a more difficult and realistic setting, known as fully test-time adaptation (Wang et al., 2021), the model must perform online adaptation to the test stream in real-time inference. The model is adapted in a single pass on the test stream using a pre-trained model and continuously arriving test data (rather than a prepared target set). Offline iterative training or extra heavy computational burdens beyond normal inference do not meet the requirements.\\n\\nThere have been several studies aimed at fully test-time adaptation. Test-time BN (Nado et al., 2020) / BN adapt (Schneider et al., 2020) directly uses the normalization statistics derived from test samples instead of those inherited from the training data, which is found to be beneficial in reducing the performance gap. Entropy-minimization-based methods, such as TENT (Wang et al., 2021), further optimize model parameters during inference. Contrastive learning (Chen et al., 2022), data augmentation (Wang et al., 2022a) and uncertainty-aware optimization (Niu et al., 2022) have been introduced to enhance adaptation performance. Efforts have also been made to address test-time adaptation in more complex test environments, like LAME (Boudiaf et al., 2022).\\n\\n\\\\(^*\\\\)Work done by Bowen Zhao (during internship) and Chen Chen at Tencent.\"}"}
{"id": "eGm22rqG93", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: IS+CB / DS+CB: the test stream which is independently / dependently sampled from a class-balanced test distribution; IS+CI/ DS+CI: independently / dependently drawn from a class-imbalanced test distribution. Each bar represents a sample, each color represents a category.\\n\\nTable 1: Comparison of fully test-time adaptation methods against the pre-trained model on CIFAR100-C. DELTA achieves improvement in all scenarios.\\n\\n| Scenario    | TENT | LAME | DELTA (Ours) |\\n|-------------|------|------|--------------|\\n| IS+CB       |      |      |              |\\n| DS+CB       |      |      |              |\\n| IS+CI       |      |      |              |\\n| DS+CI       |      |      |              |\\n\\nDespite the achieved progress, we find that there are non-negligible defects hidden in the popular methods. First, we take a closer look at the normalization statistics within inference (Section 3.2). We observe that the statistics used in BN adapt is inaccurate in per batch compared to the actual population statistics. Second, we reveal that the prevalent test-time model updating is biased towards some dominant categories (Section 3.3). We notice that the model predictions are extremely imbalanced on out-of-distribution data, which can be exacerbated by the self-learning-based adaptation methods. Besides the most common independent and class-balanced test samples considered in existing studies, following Boudiaf et al. (2022), we investigate other three test scenarios as illustrated in Figure 1 (please see details in Section 3.1) and find when facing the more intricate test streams, like dependent samples or class-imbalanced data, the prevalent methods would suffer from severe performance degradation, which limits the usefulness of these test-time adaptation strategies.\\n\\nTo address the aforementioned issues, we propose two powerful tools. Specifically, to handle the inaccurate normalization statistics, we introduce test-time batch renormalization (TBR) (Section 3.2), which uses the test-time moving averaged statistics to rectify the normalized features and considers normalization during gradient optimization. By taking advantage of the observed test samples, the calibrated normalization is more accurate. We further propose dynamic online re-weighting (DOT) (Section 3.3) to tackle the biased optimization, which is derived from cost-sensitive learning. To balance adaptation, DOT assigns low/high weights to the frequent/infrequent categories. The weight mapping function is based on a momentum-updated class-frequency vector that takes into account multiple sources of category bias, including the pre-trained model, the test stream, and the adaptation methods (the methods usually do not have an intrinsic bias towards certain classes, but can accentuate existing bias). TBR can be applied directly to the common BN-based pre-trained models and does not interfere with the training process (corresponding to the fully test-time adaptation setting), and DOT can be easily combined with other adaptation approaches as well.\\n\\nTable 1 compares our method to others on CIFAR100-C across various scenarios. The existing test-time adaptation methods behave differently across the four scenarios and show performance degradation in some scenarios. While our tools perform well in all four scenarios simultaneously without any prior knowledge of the test data, which is important for real-world applications. Thus, the whole method is named DELTA (Degradation-freE fuLly Test-time Adaptation).\\n\\nThe major contributions of our work are as follows.\\n\\n(i) We expose the defects in commonly used test-time adaptation methods, which ultimately harm adaptation performance.\\n\\n(ii) We demonstrate that the defects will be even more severe in complex test environments, causing performance degradation.\\n\\n(iii) To achieve degradation-free fully test-time adaptation, we propose DELTA which comprises two components: TBR and DOT, to improve the normalization statistics estimates and mitigate the bias within optimization.\\n\\n(iv) We evaluate DELTA on three common datasets with four scenarios and a newly introduced real-world dataset, and find that it can consistently improve the popular test-time adaptation methods on all scenarios, yielding new state-of-the-art results.\\n\\n2 RELATED WORK\\n\\nUnsupervised domain adaptation (UDA). In reality, test distribution is frequently inconsistent with the training distribution, resulting in poor performance. UDA aims to alleviate the phenomenon with the collected unlabeled samples from the target distribution. One popular approach is to align the statistical moments across different distributions (Gretton et al., 2006; Zellinger et al., 2017; Long et al., 2017). Another line of studies adopts adversarial training to achieve adaptation (Ganin et al., 2016;...\"}"}
{"id": "eGm22rqG93", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2023.\\n\\nLong et al., 2018). UDA has been developed for many tasks including object classification (Saito et al., 2017) detection (Li et al., 2021) and semantic segmentation (Hoffman et al., 2018).\\n\\nSource-free domain adaptation (SFDA). SFDA deals with domain gap with only the trained model and the prepared unlabeled target data. To be more widely used, SFDA methods should be built on a common source model trained by a standard pipeline. SHOT (Liang et al., 2020) freezes the source model's classifier and optimizes the feature extractor via entropy minimization, diversity regularization, and pseudo-labeling. SHOT incorporates weight normalization, 1D BN, and label-smoothing into backbones and training, which do not exist in most off-the-shelf trained models, but its other ideas can be used. USFDA (Kundu et al., 2020) utilizes synthesized samples to achieve compact decision boundaries. NRC (Yang et al., 2021b) encourages label consistency among local target features with the same network architecture as SHOT. GSFDA (Yang et al., 2021a) further expects the adapted model performs well not only on target data but also on source data.\\n\\nFully test-time adaptation (FTTA).\\n\\nFTTA is a more difficult and realistic setting. In the same way that SFDA does not provide the source training data, only the trained model is provided. Unlike SFDA, FTTA cannot access the entire target dataset; however, the methods should be capable of doing online adaptation on the test stream and providing instant predictions for the arrived test samples. BN adapt (Nado et al., 2020; Schneider et al., 2020) replaces the normalization statistics estimated during training with those derived from the test mini-batch. On top of it, TENT (Wang et al., 2021) optimizes the affine parameters in BN through entropy minimization during test. EATA (Niu et al., 2022) and CoTTA (Wang et al., 2022a) study long-term test-time adaptation in continually changing environments. ETA (Niu et al., 2022) excludes unreliable and redundant samples from the optimization. AdaContrast (Chen et al., 2022) resorts to contrastive learning to promote feature learning along with a pseudo label refinement mechanism. Both AdaContrast and CoTTA utilize heavy data augmentation during test, which will increase inference latency. Besides, AdaContrast modifies the model architecture as in SHOT. Different from them, LAME (Boudiaf et al., 2022) does not rectify the model's parameters but only the model's output probabilities via the introduced unsupervised objective laplacian adjusted maximum-likelihood estimation.\\n\\nClass-imbalanced learning.\\n\\nTraining with class-imbalanced data has attracted widespread attention (Liu et al., 2019). Cost-sensitive learning (Elkan, 2001) and resampling (Wang et al., 2020) are the classical strategies to handle this problem. Ren et al. (2018) designs a meta-learning paradigm to assign weights to samples. Class-balanced loss (Cui et al., 2019) uses the effective number of samples when performing re-weighting. Decoupled training (Kang et al., 2020b) learns the feature extractor and the classifier separately. Menon et al. (2021) propose logit adjustment from a statistical perspective. Other techniques such as weight balancing (Alshammari et al., 2022; Zhao et al., 2020), contrastive learning (Kang et al., 2020a), knowledge distillation (He et al., 2021), etc. have also been applied to solve this problem.\\n\\n3 DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION\\n\\n3.1 PROBLEM DEFINITION\\n\\nAssume that we have the training data $D_{\\\\text{train}} = \\\\{(x_i, y_i)\\\\}_{i=1}^N \\\\sim P_{\\\\text{train}}(x, y)$, where $x \\\\in X$ is the input and $y \\\\in Y = \\\\{1, 2, \\\\ldots, K\\\\}$ is the target label; $f(\\\\theta_0, a_0)$ denotes the model with parameters $\\\\theta_0$ and normalization statistics $a_0$ learned or estimated on $D_{\\\\text{train}}$. Without loss of generality, we denote the test stream as $D_{\\\\text{test}} = \\\\{(x_j, y_j)\\\\}_{j=1}^N \\\\sim P_{\\\\text{test}}(x, y)$, where $\\\\{y_j\\\\}$ are not available actually, the subscript $j$ also indicates the sample position within the test stream. When $P_{\\\\text{test}}(x, y) \\\\neq P_{\\\\text{train}}(x, y)$ (the input/output space $X/Y$ is consistent between training and test data), $f(\\\\theta_0, a_0)$ may perform poorly on $D_{\\\\text{test}}$. Under fully test-time adaptation scheme (Wang et al., 2021), during inference step $t \\\\ge 1$, the model $f(\\\\theta_{t-1}, a_{t-1})$ receives a mini-batch of test data $\\\\{x_{mt+b}\\\\}_{b=1}^B$ with $B$ batch size ($mt$ is the number of test samples observed before inference step $t$), and then elevates itself to $f(\\\\theta_t, a_t)$ based on current test mini-batch and outputs the real-time predictions $\\\\{p_{mt+b}\\\\}_{b=1}^B$ ($p \\\\in \\\\mathbb{R}^K$). Finally, the evaluation metric is calculated based on the online predictions from each inference step. Fully test-time adaptation emphasizes performing adaptation during real-time inference entirely, i.e., the training process cannot be interrupted, the training data is no longer available during test, and the adaptation should be accomplished in a single pass over the test stream.\"}"}
{"id": "eGm22rqG93", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"However, when P data following the benchmark of previous studies. Furthermore, when\\n\\nDiagnosis I: Normalization statistics are inaccurate\\n\\nWe revisit BN (Ioffe & Szegedy, 2015) briefly. Let \\\\( v \\\\in \\\\mathbb{R} \\\\) be a mini-batch of features, \\\\( \\\\{ \\\\theta \\\\} \\\\in \\\\mathbb{R}^{|R| \\\\times \\\\text{channels}} \\\\), and \\\\( \\\\{ \\\\gamma, \\\\beta \\\\} \\\\in \\\\mathbb{R}^{|R| \\\\times \\\\text{channels}} \\\\) are the learnable affine parameters, \\\\( \\\\{ \\\\mu, \\\\sigma \\\\} \\\\in \\\\mathbb{R}^{|R| \\\\times \\\\text{channels}} \\\\) are the normalization statistics, and \\\\( q = \\\\text{BN adapt} + \\\\text{TEMA} \\\\). We mainly focus on the first part, which are the exponential-moving-average (EMA) estimates over training process (a simple and powerful tool to improve the normalization, referring to as TEMA, where \\\\( \\\\hat{\\\\mu}, \\\\hat{\\\\sigma} \\\\) are set to the empirical mean and standard deviation, respectively, and are inaccurate in most test mini-batches. It should be noted that for BN adapt, predictions are made based on the test-time moving average of the test mini-batch: \\n\\n\\\\[ \\\\text{Test mini-batch} \\\\]\\n\\nGlobal\\nBN adapt\\nBN adapt+TEMA\\n\\nRegarding training class distribution, in experiments, we primarily use models learned on balanced training data following the benchmark of previous studies. Furthermore, when the assumptions do not always hold, the normalizer moves away from the trained network. Two hypotheses are considered: the test samples are class-imbalanced in real-world, the test stream can be class-imbalanced in a certain period of time, leading to another hypothesis: the test samples are dependent sampled. Most studies only considered the scenario with class-balanced test samples, while the other three scenarios also frequently appear in real-world applications. We investigate fully-test time adaptation because they statistics severely impede test-time adaptation because they are derived solely from the current small mini-batch. In BN, during training, \\\\( \\\\mu, \\\\sigma \\\\) are set to zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\sigma \\\\) are set to a small value to avoid division by zero. During inference, \\\\( \\\\"}
{"id": "eGm22rqG93", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 32: Classification accuracy (%) on IS+CI ($\\\\pi = 0.05$) test stream of ImageNet-C.\\n\\n| Method  | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg  |\\n|---------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|------|\\n| Source  | 2.2   | 2.9  | 1.9   | 18.0  | 10.0  | 14.6   | 22.5 | 16.6 | 23.1  | 24.4| 58.4 | 5.5   | 16.9 | 20.6 | 31.5 | 17.9 |\\n| BN adapt | 15.1  | 15.2 | 15.6  | 14.9  | 15.8  | 25.6   | 39.0 | 34.6 | 33.2  | 47.8| 64.7 | 17.2  | 44.1 | 48.2 | 39.9 | 31.4 |\\n| ETA     | 34.2  | 36.1 | 35.0  | 32.0  | 32.0  | 46.1   | 52.0 | 50.6 | 45.0  | 59.4| 67.3 | 43.4  | 57.0 | 60.3 | 54.5 | 47.0 |\\n| LAME    | 1.6   | 2.4  | 1.4   | 17.7  | 9.1   | 13.9   | 21.9 | 15.4 | 22.3  | 22.7| 58.0 | 5.2   | 15.1 | 19.8 | 30.9 | 17.2 |\\n| CoTTA   | 17.3  | 17.4 | 17.8  | 15.4  | 17.1  | 29.8   | 43.1 | 37.5 | 35.4  | 51.9| 65.8 | 19.3  | 46.8 | 53.3 | 42.5 | 34.0 |\\n| CoTTA*  | 17.3  | 21.6 | 23.8  | 19.9  | 22.9  | 29.3   | 37.4 | 35.7 | 36.6  | 44.5| 59.0 | 24.2  | 45.5 | 51.8 | 45.9 | 34.4 |\\n| PL      | 24.2  | 24.6 | 25.8  | 24.7  | 23.5  | 36.2   | 45.8 | 42.7 | 38.9  | 54.3| 65.9 | 27.0  | 49.0 | 55.0 | 48.0 | 39.0 |\\n| PL+DELTA| 26.1  | 27.3 | 27.1  | 25.8  | 25.3  | 36.2   | 46.8 | 43.2 | 39.9  | 54.8| 66.4 | 32.6  | 51.1 | 55.4 | 48.8 | 40.5 |\\n| TENT    | 27.1  | 29.0 | 28.8  | 27.7  | 27.1  | 40.3   | 49.1 | 46.4 | 40.7  | 57.1| 66.6 | 24.8  | 53.1 | 57.8 | 51.3 | 41.8 |\\n| TENT+DELTA| 30.1 | 32.3 | 31.2  | 29.6  | 29.6  | 41.4   | 50.0 | 47.4 | 42.4  | 57.6| 67.2 | 35.3  | 55.1 | 58.5 | 52.6 | 44.0 |\\n| Ent-W   | 17.2  | 13.4 | 25.6  | 15.8  | 12.1  | 45.9   | 51.0 | 50.4 | 44.6  | 59.3| 66.9 | 10.0  | 56.5 | 60.0 | 54.1 | 38.9 |\\n| Ent-W+DELTA| 35.7 | 38.2 | 37.1  | 34.1  | 33.8  | 46.5   | 51.7 | 51.1 | 45.6  | 58.4| 66.0 | 43.5  | 57.0 | 59.3 | 54.5 | 47.5 |\\n\\n### Table 33: Classification accuracy (%) on DS+CI ($\\\\rho = 0.5$, $\\\\pi = 0.05$) test stream of ImageNet-C.\\n\\n| Method  | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg  |\\n|---------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|------|\\n| Source  | 2.4   | 3.0  | 1.9   | 17.8  | 9.7   | 14.7   | 22.4 | 16.5 | 23.1  | 24.2| 58.9 | 5.5   | 16.9 | 20.4 | 31.5 | 17.9 |\\n| BN adapt| 9.7   | 10.1 | 10.1  | 9.3   | 9.5   | 16.1   | 24.2 | 21.7 | 21.4  | 30.8| 43.5 | 11.2  | 27.0 | 30.9 | 25.7 | 20.1 |\\n| ETA     | 11.9  | 12.7 | 12.7  | 8.6   | 7.3   | 18.8   | 27.1 | 25.9 | 22.8  | 34.0| 41.9 | 7.9   | 30.7 | 34.9 | 30.3 | 21.8 |\\n| LAME    | 2.0   | 2.8  | 1.5   | 22.4  | 11.4  | 17.1   | 27.5 | 19.4 | 28.0  | 29.5| 73.1 | 6.0   | 19.8 | 24.9 | 40.0 | 21.7 |\\n| CoTTA   | 11.4  | 11.6 | 11.7  | 9.8   | 10.4  | 17.9   | 26.4 | 22.9 | 22.6  | 33.3| 44.4 | 11.6  | 28.6 | 33.8 | 27.3 | 21.6 |\\n| CoTTA*  | 11.4  | 13.9 | 14.9  | 11.7  | 13.3  | 17.9   | 22.8 | 22.7 | 23.5  | 29.2| 39.4 | 14.6  | 28.2 | 33.1 | 29.6 | 21.7 |\\n| PL      | 14.4  | 12.5 | 14.0  | 12.6  | 11.8  | 20.2   | 27.2 | 25.3 | 24.1  | 34.1| 43.9 | 10.7  | 29.8 | 34.2 | 29.8 | 23.0 |\\n| PL+DELTA| 24.8  | 25.5 | 25.4  | 23.6  | 23.0  | 34.9   | 44.8 | 41.0 | 38.8  | 53.2| 65.9 | 29.6  | 49.7 | 54.1 | 47.3 | 38.8 |\\n| TENT    | 12.9  | 13.9 | 14.3  | 12.8  | 11.7  | 18.5   | 27.0 | 25.0 | 21.7  | 34.1| 42.9 | 6.6   | 30.1 | 34.5 | 30.1 | 22.4 |\\n| TENT+DELTA| 28.3 | 30.1 | 29.1  | 27.5  | 27.2  | 39.3   | 48.3 | 45.2 | 41.2  | 56.3| 66.8 | 31.0  | 53.6 | 57.2 | 51.2 | 42.2 |\\n| Ent-W   | 1.6   | 1.6  | 2.4   | 2.3   | 1.3   | 5.6    | 12.9 | 13.5 | 11.1  | 16.7| 40.4 | 1.1   | 16.8 | 17.4 | 16.6 | 10.8 |\\n| Ent-W+DELTA| 32.2 | 35.0 | 34.1  | 30.5  | 29.4  | 44.8   | 50.7 | 49.5 | 44.5  | 58.1| 66.6 | 36.6  | 55.7 | 58.4 | 53.7 | 45.3 |\\n\\n### Table 34: Classification accuracy (%) on DS+CI ($\\\\rho = 0.5$, $\\\\pi = 0.05$) test stream of ImageNet-C.\\n\\n| Method  | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg  |\\n|---------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|------|\\n| Source  | 2.2   | 2.9  | 1.9   | 18.0  | 10.0  | 14.6   | 22.5 | 16.6 | 23.1  | 24.4| 58.4 | 5.5   | 16.9 | 20.6 | 31.5 | 17.9 |\\n| BN adapt| 9.8   | 9.9  | 10.5  | 9.6   | 9.5   | 15.8   | 23.8 | 22.1 | 21.8  | 31.4| 43.9 | 11.2  | 26.9 | 30.6 | 25.8 | 20.2 |\\n| ETA     | 9.1   | 11.2 | 12.5  | 3.9   | 7.8   | 18.2   | 26.3 | 25.6 | 22.4  | 34.4| 41.9 | 6.4   | 30.7 | 33.7 | 29.7 | 20.9 |\\n| LAME    | 1.8   | 2.7  | 1.6   | 21.9  | 11.5  | 16.9   | 27.3 | 19.3 | 28.3  | 29.3| 71.4 | 5.8   | 20.2 | 24.6 | 39.1 | 21.5 |\\n| CoTTA   | 11.3  | 11.4 | 12.1  | 8.9   | 10.0  | 17.9   | 26.3 | 23.4 | 23.0  | 33.9| 44.6 | 10.1  | 29.0 | 34.1 | 27.6 | 21.6 |\\n| CoTTA*  | 11.3  | 13.6 | 14.9  | 12.1  | 13.4  | 17.8   | 23.1 | 23.3 | 23.5  | 29.1| 40.0 | 13.9  | 28.4 | 33.1 | 29.8 | 21.8 |\\n| PL      | 13.3  | 11.2 | 14.7  | 12.4  | 12.4  | 19.6   | 27.1 | 25.7 | 24.2  | 34.7| 44.4 | 8.4   | 29.7 | 34.0 | 30.0 | 22.8 |\\n| PL+DELTA| 23.8  | 25.0 | 25.1  | 23.4  | 22.6  | 33.6   | 44.3 | 41.2 | 38.7  | 53.1| 65.4 | 27.9  | 48.9 | 53.6 | 46.6 | 38.2 |\\n| TENT    | 12.6  | 13.6 | 14.3  | 12.6  | 11.4  | 17.2   | 26.6 | 25.2 | 21.7  | 34.6| 43.0 | 6.0   | 29.6 | 34.2 | 30.3 | 22.2 |\\n| TENT+TBR| 24.7  | 26.6 | 26.9  | 24.8  | 24.7  | 37.1   | 47.0 | 44.4 | 39.0  | 55.5| 66.2 | 15.5  | 51.0 | 56.3 | 50.0 | 39.3 |\\n| TENT+DOT| 15.4  | 16.6 | 16.4  | 14.6  | 14.5  | 20.1   | 27"}
{"id": "eGm22rqG93", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 22: Classification accuracy (%) on IS+CI ($\\\\pi = 0.1$) test stream of CIFAR100-C.\\n\\n| Method          | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source          |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n|                 | 26.2  | 31.7 | 60.1  | 70.3  | 45.7  | 69.5   | 71.2 | 60.1 | 53.9  | 49.7 | 69.7  | 45.1  | 62.5    | 25.6  | 58.9 | 53.3 |\\n| BN adapt        | 58.0  | 58.8 | 56.7  | 71.6  | 58.3  | 69.6   | 71.5 | 64.9 | 65.1  | 58.6 | 72.9  | 68.7  | 64.4    | 66.3  | 58.5 | 64.3 |\\n| ETA             | 62.6  | 63.7 | 65.2  | 73.6  | 62.9  | 71.6   | 73.8 | 68.6 | 68.9  | 65.6 | 75.2  | 72.1  | 65.9    | 70.7  | 62.7 | 68.2 |\\n| LAME            | 23.5  | 28.6 | 59.4  | 68.8  | 43.3  | 67.1   | 68.8 | 58.2 | 50.9  | 46.6 | 67.1  | 39.4  | 60.4    | 21.6  | 56.7 | 50.7 |\\n| CoTTA           | 59.8  | 61.3 | 59.7  | 71.8  | 59.8  | 69.6   | 71.6 | 64.4 | 65.3  | 56.5 | 73.1  | 68.5  | 64.2    | 68.2  | 62.5 | 65.1 |\\n| CoTTA*          | 59.8  | 61.9 | 60.1  | 72.0  | 61.7  | 70.9   | 72.6 | 66.2 | 67.4  | 59.1 | 74.5  | 71.3  | 67.3    | 71.5  | 66.3 | 66.8 |\\n| PL              | 61.7  | 62.3 | 62.8  | 73.1  | 61.7  | 71.1   | 73.6 | 67.2 | 68.1  | 63.7 | 74.3  | 71.3  | 65.5    | 69.7  | 61.3 | 67.2 |\\n| PL+DELTA        | 62.4  | 63.0 | 63.2  | 73.4  | 61.3  | 71.9   | 73.5 | 67.2 | 68.3  | 64.0 | 75.0  | 71.5  | 65.6    | 70.1  | 62.2 | 67.5 |\\n| TENT            | 61.7  | 63.3 | 63.9  | 73.3  | 62.3  | 71.4   | 73.1 | 67.6 | 68.1  | 65.1 | 74.9  | 71.4  | 66.1    | 70.7  | 62.5 | 67.6 |\\n| TENT+TBR        | 61.6  | 63.8 | 64.4  | 73.3  | 62.2  | 71.5   | 73.6 | 68.0 | 68.0  | 64.9 | 74.8  | 71.4  | 65.5    | 71.0  | 63.0 | 67.8 |\\n| TENT+DOT        | 62.4  | 63.6 | 64.7  | 73.1  | 62.6  | 71.6   | 73.7 | 68.0 | 68.6  | 65.3 | 74.7  | 71.8  | 66.1    | 70.7  | 63.0 | 68.0 |\\n| TENT+DELTA      | 62.5  | 64.3 | 65.3  | 73.8  | 62.4  | 71.3   | 73.6 | 68.3 | 69.0  | 66.1 | 75.1  | 71.6  | 66.2    | 71.1  | 63.9 | 68.3 |\\n| Ent-W           | 62.5  | 63.8 | 65.2  | 73.6  | 62.9  | 71.7   | 73.7 | 68.5 | 68.9  | 65.5 | 75.3  | 72.0  | 66.3    | 70.7  | 62.9 | 68.2 |\\n| Ent-W+TBR+Div-W(0.05) | 61.1  | 62.0 | 62.6  | 73.0  | 60.8  | 71.1   | 73.1 | 66.9 | 66.9  | 63.4 | 74.1  | 70.2  | 65.6    | 68.6  | 60.5 | 66.7 |\\n| Ent-W+TBR+Div-W(0.1) | 62.5  | 63.5 | 64.8  | 73.7  | 62.8  | 72.0   | 74.2 | 68.5 | 68.7  | 65.5 | 75.2  | 71.7  | 66.7    | 70.7  | 62.4 | 68.2 |\\n| Ent-W+TBR+Div-W(0.2) | 63.3  | 64.1 | 66.2  | 73.9  | 63.2  | 72.0   | 73.8 | 68.9 | 69.5  | 65.8 | 75.7  | 72.5  | 66.8    | 71.2  | 62.9 | 68.7 |\\n| Ent-W+TBR+LA    | 63.6  | 64.6 | 66.4  | 74.2  | 63.7  | 72.1   | 74.2 | 69.0 | 70.1  | 66.0 | 76.0  | 73.3  | 67.2    | 71.8  | 63.4 | 69.0 |\\n| Ent-W+TBR+Sample-drop | 63.3  | 64.6 | 65.8  | 73.8  | 63.6  | 72.2   | 74.0 | 69.5 | 69.7  | 66.4 | 75.6  | 72.5  | 67.0    | 71.5  | 63.1 | 68.8 |\\n| Ent-W+DELTA     | 63.9  | 64.8 | 66.4  | 74.1  | 63.7  | 72.2   | 74.4 | 69.2 | 70.5  | 66.2 | 75.6  | 73.3  | 67.0    | 71.6  | 63.3 | 69.1 |\\n\\nTable 23: Classification accuracy (%) on IS+CI ($\\\\pi = 0.05$) test stream of CIFAR100-C.\\n\\n| Method          | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source          |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n|                 | 26.2  | 31.8 | 60.5  | 70.5  | 46.4  | 68.9   | 70.6 | 59.8 | 53.7  | 50.3 | 70.4  | 44.9  | 61.8    | 24.7  | 58.2 | 53.3 |\\n| BN adapt        | 56.7  | 58.0 | 55.5  | 71.4  | 57.5  | 69.5   | 71.1 | 64.7 | 64.1  | 57.5 | 72.5  | 69.0  | 63.1    | 66.2  | 58.0 | 63.6 |\\n| ETA             | 61.3  | 63.2 | 64.6  | 73.6  | 61.5  | 72.2   | 73.3 | 68.1 | 67.7  | 65.0 | 74.4  | 71.4  | 65.6    | 70.2  | 62.8 | 67.7 |\\n| LAME            | 23.2  | 28.9 | 59.0  | 67.9  | 43.8  | 66.7   | 67.8 | 58.2 | 50.5  | 47.1 | 67.7  | 39.8  | 59.7    | 20.6  | 56.9 | 50.5 |\\n| CoTTA           | 58.4  | 60.6 | 58.8  | 71.6  | 58.2  | 69.4   | 71.2  | 63.5 | 64.2  | 55.6 | 72.5  | 68.6  | 62.4    | 67.9  | 61.0 | 64.3 |\\n| CoTTA*          | 58.4  | 60.9 | 59.1  | 72.0  | 59.9  | 70.9   | 71.8  | 65.2 | 66.5  | 58.6 | 73.9  | 71.0  | 65.7    | 70.5  | 65.2 | 66.0 |\\n| PL              | 60.4  | 62.1 | 62.9  | 72.8  | 60.8  | 71.4   | 72.7  | 67.7 | 67.1  | 62.6 | 73.5  | 71.3  | 65.4    | 69.4  | 61.4 | 66.8 |\\n| PL+DELTA        | 61.0  | 63.1 | 62.8  | 73.2  | 61.8  | 71.6   | 73.2  | 67.9 | 67.6  | 63.5 | 74.2  | 71.4  | 65.3    | 69.6  | 62.0 | 67.2 |\\n| TENT            | 61.0  | 63.4 | 64.0  | 73.3  | 60.6  | 71.7   | 73.2  | 68.7 | 66.9  | 64.9 | 73.9  | 71.0  | 65.1    | 70.0  | 62.0 | 67.3 |\\n| TENT+DELTA      | 61.7  | 64.8 | 65.6  | 73.5  | 62.1  | 71.2   | 73.4  | 69.0 | 68.6  | 65.4 | 74.6  | 71.1  | 66.1    | 70.6  | 63.1 | 68.1 |\\n| Ent-W           | 61.4  | 63.2 | 64.7  | 73.7  | 61.5  | 72.1   | 73.2  | 68.4 | 67.8  | 64.9 | 74.4  | 71.3  | 65.6    | 70.1  | 62.7 | 67.7 |\\n| Ent-W+DELTA     | 62.8  | 64.4 | 65.6  | 74.4  | 62.5  | 72.3   | 74.1  | 69.1 | 68.9  | 66.2 | 75.5  | 73.0  | 66.1    | 71.7  | 63.0 | 68.6 |\\n\\nTable 24: Classification accuracy (%) on DS+CI ($\\\\rho = 0.5$, $\\\\pi = 0.1$) test stream of CIFAR100-C.\\n\\n| Method          | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|-----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source          |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n|                 | 26.2  | 31.7 | 60.1  | 70.3  | 45.7  | 69.5   | 71.2 | 60.1 | 53.9  | 49.7 | 69"}
{"id": "eGm22rqG93", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 25: Classification accuracy (%) on DS+CI ($\\\\rho = 0.5$, $\\\\pi = 0.05$) test stream of CIFAR100-C.\\n\\n| Method       | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|--------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source       |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n| BN adapt     | 43.0  | 45.0 | 42.3  | 55.4  | 44.0  | 54.2   | 54.9 | 49.1 | 49.4  | 43.8 | 56.2  | 53.1  | 48.5    | 51.3  | 44.3 | 49.0 |\\n| ETA          | 45.4  | 46.4 | 46.8  | 56.2  | 45.3  | 54.7   | 54.8 | 50.7 | 50.1  | 46.5 | 56.4  | 52.2  | 48.8    | 53.0  | 45.5 | 50.2 |\\n| LAME         | 27.1  | 33.3 | 67.6  | 78.7  | 51.7  | 77.1   | 78.9 | 68.5 | 59.7  | 56.0 | 77.5  | 49.3  | 70.1    | 25.1  | 66.6 | 59.2 |\\n| CoTTA        | 46.5  | 47.3 | 45.3  | 54.5  | 45.5  | 53.7   | 55.0 | 48.6 | 49.9  | 42.4 | 56.0  | 49.0  | 49.1    | 53.5  | 47.2 | 49.6 |\\n| CoTTA*       | 46.5  | 47.8 | 45.5  | 54.1  | 46.2  | 53.4   | 54.2 | 48.8 | 50.6  | 43.5 | 54.2  | 49.4  | 49.6    | 52.8  | 48.7 | 49.7 |\\n| PL           | 44.3  | 45.8 | 46.4  | 55.8  | 45.2  | 54.2   | 54.8 | 50.7 | 49.3  | 45.8 | 56.5  | 52.4  | 49.1    | 52.0  | 45.5 | 49.9 |\\n| PL+DELTA     | 59.3  | 61.1 | 62.2  | 71.6  | 59.4  | 70.3   | 70.8 | 66.3 | 65.5  | 61.4 | 74.0  | 69.0  | 64.5    | 67.5  | 59.8 | 65.5 |\\n| TENT         | 44.7  | 46.7 | 45.7  | 55.3  | 44.6  | 53.8   | 53.7 | 50.0 | 48.6  | 46.1 | 55.5  | 50.0  | 48.9    | 52.0  | 44.6 | 49.3 |\\n| TENT+TBR     | 58.8  | 61.6 | 62.5  | 72.2  | 58.6  | 70.3   | 70.9 | 67.0 | 64.8  | 62.5 | 73.5  | 68.1  | 63.4    | 68.5  | 59.4 | 65.5 |\\n| TENT+DOT     | 45.2  | 47.1 | 46.7  | 55.6  | 45.4  | 54.3   | 54.3 | 50.9 | 49.7  | 47.3 | 56.1  | 51.7  | 49.2    | 52.9  | 45.6 | 50.1 |\\n| TENT+DELTA   | 60.3  | 62.3 | 63.7  | 72.9  | 60.3  | 70.3   | 71.3 | 67.8 | 66.2  | 64.1 | 74.2  | 68.7  | 64.3    | 69.1  | 60.7 | 66.4 |\\n| Ent-W        | 45.6  | 46.4 | 47.0  | 56.0  | 45.4  | 54.9   | 54.9 | 50.7 | 50.1  | 46.8 | 56.3  | 52.2  | 48.6    | 53.1  | 45.1 | 50.2 |\\n| Ent-W+TBR+Div-W(0.05) | 60.9  | 62.3 | 62.9  | 73.0  | 59.5  | 70.7   | 72.0 | 67.0 | 66.2  | 62.4 | 74.5  | 69.8  | 64.9    | 69.0  | 60.7 | 66.4 |\\n| Ent-W+TBR+Div-W(0.1)  | 61.2  | 62.8 | 64.5  | 73.5  | 59.9  | 71.3   | 71.8 | 67.4 | 66.4  | 63.7 | 74.5  | 70.6  | 65.2    | 69.5  | 61.0 | 66.9 |\\n| Ent-W+TBR+Div-W(0.2)  | 60.4  | 62.4 | 63.6  | 73.5  | 59.4  | 70.7   | 72.0 | 67.1 | 65.8  | 63.4 | 74.4  | 70.1  | 64.5    | 69.5  | 60.4 | 66.5 |\\n| Ent-W+TBR+LA   | 59.2  | 61.6 | 62.3  | 71.9  | 58.9  | 69.5   | 71.3 | 65.7 | 65.1  | 62.8 | 73.2  | 69.0  | 63.3    | 68.2  | 60.0 | 65.5 |\\n| Ent-W+TBR+Sample-drop | 60.9  | 62.6 | 63.7  | 73.2  | 60.0  | 70.6   | 72.0 | 66.9 | 66.6  | 64.1 | 74.9  | 69.4  | 64.6    | 69.9  | 61.1 | 66.7 |\\n| Ent-W+DELTA   | 61.2  | 62.9 | 64.0  | 73.7  | 60.4  | 71.1   | 72.3 | 67.4 | 67.0  | 64.2 | 74.7  | 70.2  | 64.7    | 69.8  | 61.0 | 67.0 |\\n\\nTable 26: Classification accuracy (%) on IS+CB test stream of ImageNet-C.\\n\\n| Method       | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|--------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source       |       |      |       |       |       |        |      |      |       |     |      |       |         |       |      |     |\\n| TTA          | 4.1   | 4.9  | 4.5   | 12.5  | 8.2   | 12.9   | 25.8 | 14.0 | 19.1  | 21.3| 53.0  | 12.4  | 14.6    | 24.6  | 33.6 | 17.7 |\\n| BN adapt     | 15.2  | 15.8 | 15.8  | 15.0  | 15.3  | 26.4   | 38.8 | 34.3 | 33.1  | 47.8| 65.3  | 16.8  | 43.9    | 48.9  | 39.7 | 31.5 |\\n| MEMO         | 7.5   | 8.7  | 9.0   | 19.7  | 13.0  | 20.7   | 27.6 | 25.3 | 28.8  | 32.1| 61.0  | 11.0  | 23.8    | 33.0  | 37.5 | 23.9 |\\n| ETA          | 35.6  | 37.5 | 36.2  | 33.7  | 33.1  | 47.7   | 52.5 | 51.9 | 45.8  | 60.0| 67.8  | 44.7  | 57.8    | 60.9  | 55.2 | 48.0 |\\n| LAME         | 1.6   | 2.4  | 1.3   | 17.6  | 9.1   | 13.9   | 21.9 | 15.6 | 22.5  | 22.8| 58.6  | 5.2   | 15.2    | 19.9  | 31.1 | 17.2 |\\n| CoTTA        | 17.6  | 18.0 | 17.4  | 15.6  | 18.2  | 31.2   | 43.6 | 36.6 | 35.1  | 53.0| 66.5  | 19.5  | 46.3    | 54.9  | 42.6 | 34.4 |\\n| CoTTA*       | 17.6  | 22.1 | 24.3  | 19.8  | 22.7  | 29.7   | 38.1 | 36.0 | 37.2  | 45.2| 60.1  | 26.4  | 46.6    | 53.4  | 46.8 | 35.1 |\\n| PL           | 26.2  | 26.2 | 27.0  | 25.2  | 24.3  | 37.2   | 46.5 | 43.3 | 39.5  | 55.0| 66.7  | 30.2  | 51.2    | 55.7  | 49.1 | 40.2 |\\n| PL+DELTA     | 27.7  | 29.4 | 28.5  | 27.0  | 26.1  | 38.1   | 47.9 | 44.1 | 40.7  | 55.9| 67.4  | 34.1  | 52.9    | 56.6  | 50.3 | 41.8 |\\n| TENT         | 28.7  | 30.5 | 30.1  | 28.0  | 27.2  | 41.4   | 49.4 | 47.2 | 41.2  | 57.4| 67.4  | 26.5  | 54.6    | 58.5  | 52.5 | 42.7 |\\n| TENT+TBR     | 29.5  | 31.4 | 30.9  | 28.8  | 28.0  | 41.9   | 50.3 | 47.7 | 41.8  | 58.3| 68.1  | 26.9  | 55.4    | 59.3  | 53.3 | 43.5 |\\n| TENT+DOT     | 30.5  | 32.3 | 31.6  | 29.6  | 29.3  | 42.5   | 49.9 | 47.8 | 42.2  | 57.5| 67.5  | 37.5  | 55.4    | 58.8  | 52.9 | 44.4 |\\n| TENT+DELTA   | 31.2  | 33.1 | 32.1  | 30.5  | 30.2  | 42.9   | 50.9 | 48.2 | 43.0  | 58.5| 68.1  | 37.9  | 56.2    | 59.5  | 53.6 | 45.1 |\\n| Ent-W        | 34.5  | 29.0 | 33.1  | 29.6  | 26.3  | 47.4   | 52.2 | 51.9 | 45.6  | 59.9| 67.8  | 17.8  | 57.8    | 60.9  | 55.0 | 44.6 |\\n| Ent-W+TBR+Div-W(0.05) | 36.1  | 37.9 | 37.8  | 34.4  | 33.5  | 49.1   | 53.3 | 53.2 | 46.7  | 60.9| 68.5  | 45.1  | 58.9    | 61.7  | 56.0 | 48.9 |\\n| Ent-W+TBR+Div-W"}
{"id": "eGm22rqG93", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 27: Classification accuracy (%) on IS+CB test stream of ImageNet-C with different architectures.\\n\\n| Method        | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|---------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| ResNet18      | 1.2   | 1.8  | 1.0   | 11.4  | 8.7   | 11.2   | 17.6 | 10.9 | 16.5  | 14.3| 51.3 | 3.4   | 16.8    | 23.1  | 29.6 | 14.6|\\n| TENT          | 22.3  | 24.7 | 22.2  | 20.3  | 21.1  | 32.2   | 41.1 | 37.8 | 33.7  | 49.0| 59.2 | 19.5  | 46.9    | 50.6  | 45.8 | 35.1|\\n| TENT+DELTA    | 24.5  | 26.8 | 24.4  | 22.6  | 23.7  | 34.0   | 42.7 | 38.9 | 35.4  | 50.2| 60.3 | 27.5  | 48.5    | 51.9  | 47.0 | 37.2|\\n| Ent-W         | 27.1  | 30.7 | 24.3  | 22.3  | 17.5  | 37.6   | 44.2 | 42.5 | 37.8  | 51.5| 59.9 | 5.5   | 49.5    | 52.9  | 48.5 | 36.8|\\n| Ent-W+DELTA   | 31.7  | 33.8 | 32.0  | 29.0  | 30.3  | 40.2   | 46.1 | 44.2 | 39.7  | 53.1| 60.9 | 36.9  | 51.5    | 54.7  | 49.8 | 42.3|\\n\\nTable 28: Classification accuracy (%) on DS+CB ($\\\\rho = 1.0$) test stream of ImageNet-C.\\n\\n| Method        | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|---------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| ResNet18      | 2.2   | 2.9  | 1.9   | 17.9  | 9.8   | 14.8   | 22.5 | 16.9 | 23.3  | 24.4| 58.9 | 5.4   | 17.0    | 20.6  | 31.6 | 18.0|\\n| BN adapt      | 10.6  | 10.9 | 10.9  | 10.2  | 10.3  | 17.5   | 25.8 | 23.5 | 23.1  | 33.0| 46.5 | 11.3  | 30.2    | 33.3  | 27.0 | 21.6|\\n| ETA           | 17.0  | 19.2 | 18.2  | 14.1  | 12.0  | 25.9   | 31.1 | 30.9 | 26.8  | 38.6| 46.1 | 18.9  | 36.0    | 38.7  | 33.5 | 27.1|\\n| LAME          | 1.8   | 2.7  | 1.5   | 22.4  | 11.3  | 17.2   | 28.4 | 19.8 | 28.4  | 29.8| 74.4 | 5.9   | 20.0    | 25.6  | 40.4 | 22.0|\\n| CoTTA         | 12.2  | 12.5 | 12.8  | 9.5   | 11.2  | 19.7   | 28.4 | 24.7 | 23.9  | 35.9| 47.4 | 12.8  | 31.1    | 37.0  | 28.4 | 23.2|\\n| CoTTA*        | 12.2  | 14.9 | 16.2  | 12.3  | 14.2  | 18.9   | 24.2 | 24.4 | 25.2  | 30.0| 41.5 | 15.3  | 30.8    | 35.5  | 31.2 | 23.1|\\n| PL            | 15.9  | 15.6 | 16.4  | 14.4  | 13.9  | 23.1   | 29.8 | 28.1 | 26.2  | 37.3| 47.2 | 12.8  | 34.2    | 37.2  | 32.2 | 25.6|\\n| PL+DELTA      | 26.3  | 27.4 | 27.1  | 25.5  | 25.1  | 37.4   | 46.5 | 43.0 | 39.8  | 54.8| 66.6 | 32.7  | 51.4    | 55.6  | 48.6 | 40.5|\\n| TENT          | 16.1  | 16.8 | 16.8  | 15.1  | 14.1  | 23.3   | 30.2 | 28.8 | 24.9  | 37.5| 46.7 | 9.3   | 34.9    | 37.8  | 33.0 | 25.7|\\n| TENT+DELTA    | 29.6  | 31.7 | 30.4  | 29.1  | 28.6  | 41.5   | 49.8 | 47.0 | 42.1  | 57.6| 67.5 | 35.7  | 54.9    | 58.5  | 52.0 | 43.7|\\n| Ent-W         | 4.2   | 2.8  | 3.1   | 2.9   | 3.6   | 11.3   | 20.2 | 20.0 | 12.5  | 34.4| 44.7 | 1.7   | 32.0    | 37.1  | 21.5 | 16.8|\\n| Ent-W+DELTA   | 35.6  | 37.9 | 36.0  | 34.4  | 34.4  | 47.9   | 52.8 | 51.9 | 46.5  | 60.1| 67.8 | 44.2  | 57.9    | 60.8  | 55.4 | 48.3|\"}"}
{"id": "eGm22rqG93", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 29: Classification accuracy (%) on DS+CB ($\\\\rho = 0.5$) test stream of ImageNet-C.\\n\\n| Method         | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source         | 2.2   | 2.9  | 1.9   | 17.9  | 9.8   | 14.8   | 22.5 | 16.9 | 23.3  | 24.4| 58.9 | 5.4   | 17.0    | 20.6  | 31.6 | 18.0|\\n| BN adapt       | 9.6   | 9.9  | 9.8   | 8.8   | 9.1   | 15.8   | 22.8 | 21.0 | 20.8  | 29.5| 41.9 | 10.3  | 26.7    | 29.5  | 24.2 | 19.3|\\n| ETA            | 13.9  | 15.5 | 13.3  | 11.1  | 10.3  | 21.4   | 26.2 | 26.1 | 22.9  | 33.4| 40.5 | 13.4  | 30.9    | 33.2  | 29.3 | 22.8|\\n| LAME           | 1.9   | 2.8  | 1.6   | 23.6  | 11.7  | 17.8   | 29.4 | 20.4 | 29.4  | 30.5| 76.1 | 6.2   | 20.8    | 26.4  | 41.5 | 22.7|\\n| CoTTA          | 10.8  | 11.0 | 11.0  | 7.8   | 10.4  | 17.4   | 25.0 | 22.0 | 21.6  | 32.0| 42.6 | 9.9   | 27.9    | 32.5  | 25.8 | 20.5|\\n| CoTTA*         | 10.8  | 13.3 | 14.3  | 11.0  | 12.9  | 17.1   | 22.0 | 21.8 | 22.8  | 27.6| 38.0 | 14.8  | 27.8    | 32.6  | 28.0 | 21.0|\\n| PL             | 14.2  | 13.4 | 14.5  | 12.5  | 11.5  | 20.0   | 26.3 | 24.9 | 23.4  | 33.2| 42.4 | 11.1  | 30.5    | 33.1  | 28.5 | 22.6|\\n| PL+DELTA       | 25.6  | 27.3 | 26.2  | 25.2  | 24.6  | 36.0   | 45.7 | 42.9 | 39.3  | 54.4| 66.5 | 31.0  | 50.6    | 55.0  | 47.9 | 39.9|\\n| TENT           | 13.9  | 14.6 | 14.5  | 12.6  | 11.7  | 19.0   | 26.1 | 25.2 | 21.5  | 33.2| 41.6 | 6.5   | 30.5    | 33.1  | 28.9 | 22.2|\\n| TENT+TBR       | 27.3  | 28.5 | 28.2  | 26.0  | 25.4  | 38.9   | 48.5 | 46.0 | 39.6  | 57.1| 67.3 | 18.5  | 53.6    | 57.6  | 51.2 | 40.9|\\n| TENT+DOT       | 15.5  | 16.5 | 15.9  | 14.2  | 14.0  | 20.9   | 27.1 | 25.9 | 23.5  | 33.7| 41.8 | 15.2  | 31.4    | 33.5  | 29.5 | 23.9|\\n| TENT+DELTA     | 29.1  | 30.9 | 29.7  | 28.2  | 27.8  | 40.3   | 49.0 | 46.7 | 41.5  | 57.3| 67.3 | 33.9  | 54.4    | 58.1  | 51.6 | 43.1|\\n| Ent-W          | 2.9   | 2.5  | 3.5   | 1.4   | 1.0   | 7.1    | 11.9 | 15.1 | 8.5   | 27.7| 37.0 | 1.3   | 22.2    | 31.1  | 20.1 | 12.9|\\n| Ent-W+TBR+Div-W(0.05) | 32.4 | 34.6 | 33.3 | 27.2 | 28.3 | 45.2 | 51.3 | 50.5 | 44.3 | 59.3 | 67.4 | 36.0 | 57.0    | 60.1  | 54.3 | 45.4|\\n| Ent-W+TBR+Div-W(0.1) | 30.1 | 33.4 | 31.1 | 25.5 | 21.7 | 44.8 | 51.1 | 50.4 | 43.4 | 59.3 | 67.4 | 16.3 | 56.9    | 60.2  | 54.3 | 43.1|\\n| Ent-W+TBR+Div-W(0.2) | 23.7 | 30.5 | 26.5 | 19.7 | 12.2 | 44.3 | 51.1 | 50.5 | 41.1 | 59.4 | 67.4 | 7.0   | 56.8    | 60.2  | 54.2 | 40.3|\\n| Ent-W+TBR+Div-W(0.4) | 17.1 | 15.3 | 22.2 | 11.2 | 4.8  | 43.7 | 51.1 | 50.2 | 36.5 | 59.5 | 67.4 | 6.1   | 56.7    | 60.3  | 54.2 | 37.1|\\n| Ent-W+TBR+LA   | 10.9  | 7.2  | 14.3  | 5.1   | 5.0   | 35.0   | 39.9 | 39.3 | 23.2  | 46.8| 53.6 | 4.1   | 44.6    | 47.2  | 42.4 | 27.9|\\n| Ent-W+TBR+Sample-drop | 33.7 | 36.4 | 35.1 | 31.9 | 30.8 | 46.7 | 52.2 | 51.2 | 45.6 | 60.0 | 67.6 | 40.4 | 57.3    | 60.6  | 54.7 | 46.9|\\n| Ent-W+DELTA    | 34.9  | 37.5 | 35.8  | 32.7 | 32.3 | 46.7   | 52.3 | 51.5 | 46.0  | 59.7| 67.3 | 42.8  | 57.3    | 60.4  | 54.9 | 47.5|\\n\\n### Table 30: Classification accuracy (%) on DS+CB ($\\\\rho = 0.1$) test stream of ImageNet-C.\\n\\n| Method         | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source         | 6.3   | 6.4  | 6.2   | 5.6   | 5.6   | 9.8    | 13.9 | 13.6 | 13.4  | 18.4| 26.1 | 6.4   | 16.5    | 18.1  | 15.0 | 12.1|\\n| ETA            | 4.6   | 5.2  | 5.1   | 2.3   | 2.8   | 7.0    | 12.3 | 11.6 | 10.9  | 17.5| 22.5 | 2.3   | 14.5    | 17.1  | 14.4 | 10.0|\\n| LAME           | 1.9   | 2.9  | 1.6   | 26.2  | 12.8  | 19.8   | 32.7 | 22.8 | 32.5  | 33.8| 80.0 | 6.6   | 22.5    | 29.0  | 45.5 | 24.7|\\n| CoTTA          | 7.1   | 7.0  | 7.1   | 5.0   | 6.2   | 10.5   | 15.0 | 14.1 | 13.7  | 19.3| 26.5 | 6.4   | 17.1    | 19.6  | 15.8 | 12.7|\\n| CoTTA*         | 7.1   | 8.2  | 8.7   | 6.3   | 7.3   | 10.3   | 13.4 | 14.3 | 14.5  | 17.9| 23.7 | 7.9   | 16.9    | 19.4  | 17.3 | 12.9|\\n| PL             | 7.7   | 7.6  | 8.3   | 6.4   | 6.1   | 10.8   | 15.4 | 15.0 | 14.0  | 20.0| 25.9 | 5.0   | 17.5    | 19.4  | 17.0 | 13.1|\\n| PL+DELTA       | 23.4  | 24.6 | 24.0  | 22.0  | 21.5  | 33.3   | 43.4 | 40.0 | 37.3  | 52.2| 65.0 | 26.1  | 47.8    | 52.5  | 45.4 | 37.2|\\n| TENT           | 7.4   | 7.8  | 7.8   | 6.2   | 5.9   | 8.9    | 14.7 | 12.5 | 11.6  | 19.0| 24.5 | 3.0   | 16.8    | 18.5  | 16.5 | 12.1|\\n| TENT+DELTA     | 26.7  | 28.2 | 27.3  | 25.0  | 24.8  | 37.1   | 46.6 | 43.6 | 39.6  | 55.1| 65.7 | 27.2  | 51.6    | 55.6  | 49.0 | 40.2|\\n| Ent-W          | 1.5   | 0.6  | 1.4   | 1.1   | 0.8   | 2.3    | 4.6   | 4.4  | 3.1   | 8.4 | 15.5 | 0.5   | 7.0     | 9.7   | 5.7  | 4.4 |\\n| Ent-W+DELTA    | 30.4  | 33.1 | 31.4  | 26.8  | 28.1  | 42.2   | 48.9 | 48.2 | 42.6  | 56.9| 65.4 | 31.5  | 54.4    | 57.8  | 51.5 | 43.3|\\n\\n### Table 31: Classification accuracy (%) on IS+CI ($\\\\pi = 0.1$) test stream of ImageNet-C.\\n\\n| Method         | Gauss | Shot | Impul | Defoc | Glass | Motion | Zoom | Snow | Frost | Fog | Brit | Contr | Elastic | Pixel | JPEG | Avg |\\n|----------------|-------|------|-------|-------|-------|--------|------|------|-------|-----|------|-------|---------|-------|------|-----|\\n| Source         | 2.4   | 3.0  | 1.9   | 17.8  | 9.7   | 14.7   | 22.4 | 16.5 | 23.1  | 24.2| 58.9 | 5.5   | 16.9    | 20.4  | 31.5 | 17.9|\\n| BN adapt       | 15.0  | 15.8 | 15.4  | 14.7  | 15.1  | 25.6   | 39.1 | 34.4 | 33.2  | 47.8| 65.1 | 17.5  | 44.4    | 48.8  | 39.8 | 31.5|\\n| ETA            | 34.6  | 36.7 | 35.7  | 33.1  | 32.5  | 46.5   | 51.9 | 51.3 | 45.4  | 59.5| 67.6 | 44.8  | 57.3    | 60.9  | 55.1 | 47.5|\\n| LAME           | 1.8  "}
