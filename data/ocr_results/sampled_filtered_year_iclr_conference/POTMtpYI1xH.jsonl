{"id": "POTMtpYI1xH", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ABSTRACT\\n\\nA large number of studies that analyze deep neural network models and their ability to encode various linguistic and non-linguistic concepts provide an interpretation of the inner mechanics of these models. The scope of the analyses is limited to pre-defined concepts that reinforce the traditional linguistic knowledge and do not reflect on how novel concepts are learned by the model. We address this limitation by discovering and analyzing latent concepts learned in neural network models in an unsupervised fashion and provide interpretations from the model's perspective. In this work, we study: i) what latent concepts exist in the pre-trained BERT model, ii) how the discovered latent concepts align or diverge from classical linguistic hierarchy and iii) how the latent concepts evolve across layers. Our findings show: i) a model learns novel concepts (e.g. animal categories and demographic groups), which do not strictly adhere to any pre-defined categorization (e.g. POS, semantic tags), ii) several latent concepts are based on multiple properties which may include semantics, syntax, and morphology, iii) the lower layers in the model dominate in learning shallow lexical concepts while the higher layers learn semantic relations and iv) the discovered latent concepts highlight potential biases learned in the model. We also release a novel BERT ConceptNet dataset (BCN) consisting of 174 concept labels and 1M annotated instances.\\n\\nINTRODUCTION\\n\\nInterpreting deep neural networks (DNNs) is essential for understanding their inner workings and successful deployment to real-world scenarios, especially for applications where fairness, trust, accountabilty, reliability, and ethical decision-making are critical metrics. A large number of studies have been devoted towards interpreting DNNs. A major line of research work has focused on DNNs in interpreting deep Natural Language Processing (NLP) models and their ability to learn various pre-defined linguistic concepts (Tenney et al., 2019b; Liu et al., 2019a). More specifically, they rely on pre-defined linguistic concepts such as: parts-of-speech tags and semantic tags, and probe whether the specific linguistic knowledge is learned in various parts of the network. For example, Belinkov et al. (2020) found that lower layers in the Neural Machine Translation (NMT) model capture word morphology and higher layers learn long-range dependencies.\\n\\nA pitfall to this line of research is its study of pre-defined concepts and the ignoring of any latent concepts within these models, resulting in a narrow view of what the model knows. Another weakness of using user-defined concepts is the involvement of human bias in the selection of a concept which may result in a misleading interpretation. In our work, we sidestep this issue by approaching interpretability from a model's perspective, specifically focusing of the discovering of latent concepts in pre-trained models.\\n\\nMikolov et al. (2013); Reif et al. (2019) showed that words group together in the high dimensional space based on syntactic and semantic relationships. We hypothesize that these groupings represent latent concepts, the information that a model learns about the language. In our approach, we cluster...\"}"}
{"id": "POTMtpYI1xH", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Concept labels:\\n\\nSEM.\"}"}
{"id": "POTMtpYI1xH", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6 provides a list of all pre-defined concepts used in this work.\\n\\nD P\\nRE\\n- DEFINED\\nCONCEPTS\\nINFORMATION\\nD.1 P\\nRE\\n- DEFINED\\nCONCEPTS\\n\\nFigure 9: Example Concepts\\n\\n(a) POS:noun; SEM:named entity:Portuguese\\n(b) LEX:abbreviation, SEM:named entity:person:initial, LEX:case:upper case\\n(c) LEX:suffix:ly, POS:adverb\\n(d) LEX:prefix:un, SEM:negative\\n(e) SEM:medical:medical condition\\n(f) SEM:media:social media\\n\\nLand animals\\nFlying animals\\nSea animals\"}"}
{"id": "POTMtpYI1xH", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"We used standard splits for training, development and test data for the 4 linguistic tasks (POS, SEM, Chunking and CCG super tagging). The splits to preprocess the data are available through git.\\n\\n| Type         | Concepts                                                                 |\\n|--------------|--------------------------------------------------------------------------|\\n| Lexical      | Ngram, Prefix, Suffix, Casing                                            |\\n| Morphology   | Parts of speech                                                          |\\n| Semantics    | Lexical semantic tags, LIWC, WordNet, Named entity tags                  |\\n| Syntactic    | CCG, Chunking, First word, Last word                                     |\"}"}
{"id": "POTMtpYI1xH", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 11: RoBERTa (numbers inside brackets show the maximum match across all layers)\\n\\nFigure 12: XLNet (numbers inside brackets show the maximum match across all layers)\\n\\nrepository\\n8\\n\\nreleased with Liu et al. (2019a). See Table 7 for statistics. We obtained the understudied pre-trained models from the authors of the paper, through personal communication.\\n\\n| Task       | Train | Dev   | Test  | Tags |\\n|------------|-------|-------|-------|------|\\n| POS        | 36557 | 1802  | 1963  | 44   |\\n| SEM        | 36928 | 5301  | 10600 | 73   |\\n| Chunking   | 8881  | 1843  | 2011  | 22   |\\n| CCG        | 39101 | 1908  | 2404  | 1272 |\\n\\nTable 7: Data statistics (number of sentences) on training, development and test sets using in the experiments and the number of tags to be predicted\\n\\nHow do models compare with respect to the pre-defined concepts? Similar to BERT, we created layer-wise latent clusters using RoBERTa (Liu et al., 2019b) and XLNet (Yang et al., 2019). We aligned the clusters with the pre-defined concepts. Figure 11 and 12 shows the results. The overall trend of the models learning shallow concepts in lower layers and linguistic concepts in the middle-higher layers is consistent across all models. A few exceptions are: suffixes have a consistently decreasing pattern for XLNet and RoBERTa, the FirstWord information improved for every higher layer till the last few layers. Moreover, XLNet showed a significant drop in matches with the linguistic tasks for the last layers. The last layers of the models are optimized for the objective function (Kovaleva et al., 2019) and there the drop in matches for most of the concepts reflects the existence of novel task-specific concepts which may not be well aligned with the human-defined concepts.\\n\\nThe number of matches as shown in brackets in Figure 4, 11 and 12 provides a relative comparison across models and pre-defined concepts. The RoBERTa and XLNet found substantially more\"}"}
{"id": "POTMtpYI1xH", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"contextualized representations in high dimensional space and study the relations behind each group by using hierarchical clustering to identify groups of related words. We manually annotate the groups and assemble a concept dataset. This is the first concept dataset that enables model-centric interpretation and will serve as a benchmark for analyzing these types of models. While we base our study on BERT (Devlin et al., 2019), our method can be generically applied to other models.\\n\\nWe study: i) what latent concepts exist in BERT, ii) how the discovered latent concepts align with pre-defined concepts, and iii) how the concepts evolve across layers. Our analysis reveals interesting findings such as: i) the model learns novel concepts like the hierarchy in animal kingdom, demographic hierarchy etc. which do not strictly adhere to any pre-defined concepts, ii) the lower layers focus on shallow lexical concepts while the higher layers learn semantic relations, iii) the concepts learned at higher layers are more aligned with the linguistically motivated concepts compared to the lower layers, and iv) the discovered latent concepts highlight potential biases learned in the model.\\n\\nThere are two main contributions of our work: i) We interpret BERT by analyzing latent concepts learned in the network, and ii) we provide a first multi-facet hierarchical BERT ConceptNet dataset (BCN) that addresses a major limitation of a prominent class of interpretation studies. Our proposed concept pool dataset not only facilitates interpretation from the perspective of the model, but also serves as a common benchmark for future research. Moreover, our findings enrich existing linguistic and pre-defined concepts and has the potential to serve as a new classification dataset for NLP in general.\\n\\nBCN consists of 174 fine-grained concept labels with a total of 1M annotated instances.\\n\\nA concept represents a notion and can be viewed as a coherent fragment of knowledge. Stock (2010) defines concept as \\\"a class containing certain objects as elements, where the objects have certain properties\\\". Deveaud et al. (2014) considers latent concepts as words that convey the most information or that are the most relevant to the initial query. A concept in language can be anything ranging from a shallow lexical property such as character bigram, to a complex syntactic phenomenon such as an adjectival phrase or a semantic property such as an event. Here, we loosely define concept as a group of words that are meaningful i.e. can be clustered based on a linguistic relation such as lexical, semantic, syntactic, morphological etc. For example, names of ice-hockey teams form a semantic cluster, words that occur in a certain position of a sentence represent a syntactic concept, words that are first person singular verbs form a morphological cluster, words that begin with \\\"anti\\\" form a lexical cluster. We consider clusters of word contextual representations in BERT as concept candidates and the human-annotated candidates with linguistic meanings as our discovered latent concepts. However, if a human is unable to identify a relation behind a group of words, we consider it as uninterpretable. It is plausible that BERT learns a relation between words that humans are unable to comprehend.\\n\\n3. METHODOLOGY\\n\\nConsider a Neural Network (NN) model $M$ with $L$ layers $\\\\{l_1, l_2, ..., l_L\\\\}$, where each layer contains $H$ hidden nodes. An input sentence consisting of $M$ words $w_1, w_2, ..., w_i, ..., w_M$ is fed into NN. For the $i$-th word input, we compute the node output (after applying the activation functions) $y_{l_h}(i)$ of every hidden node $h \\\\in \\\\{1, ..., H\\\\}$ in each layer $l$, where $\\\\rightarrow y_{l_h}(i)$ is the vector representation of all hidden node outputs in layer $l$ for $w_i$. Our goal is to cluster $\\\\rightarrow y_{l_h}(i)$, the contextual representation, among all $i$-th input words. We call this clustering as latent concepts that map words into meaningful groups. We introduce an annotation schema and manually assign labels to each cluster following our definition of a concept. In the following, we discuss each step in detail.\\n\\n3.1 CLUSTERING\\n\\nAlgorithm 1 (Appendix A) presents the clustering procedure. For each layer, we cluster the hidden nodes into $K$ groups using agglomerative hierarchical clustering (Gowda & Krishna, 1978) trained on the contextualized representation. We apply Ward's minimum variance criterion that minimizes the total within-cluster variance. The distance between two vector representations is calculated with the squared Euclidean distance. The number of clusters $K$ is a hyperparameter. We empirically set $2$...\"}"}
{"id": "POTMtpYI1xH", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Illustration of a hierarchical concept tree. Our new concepts represent novel aspects that are not found in the pre-defined concepts.\\n\\n$K = 1000$ with an aim to avoid many large clusters of size more than 1000 tokens (under-clustering) and a large number of small clusters having less than five word types (over-clustering).\\n\\n3.2 DATA PREPARATION\\n\\nThe choice of a dataset is an important factor to be considered when generating latent concepts. Ideally, one would like to form latent clusters over a large collection with diverse domains. However, clustering a large number of points is computationally and memory intensive. In the case of agglomerative hierarchical clustering using Ward linkage, the memory complexity is $O(n^2)$, which translates to about 400GB of runtime memory for 200k input vectors. A potential workaround is to use a different linkage algorithm like single or average linkage, but each of these come with their own caveats regarding assumptions around how the space is structured and how noisy the inputs are. We address these problems by using a subset of a large dataset of News 2018 WMT (359M tokens). We randomly select 250k sentences from the dataset ($\\\\approx$ 5 million tokens). We further limit the number of tokens to $\\\\approx$ 210k by discarding singletons, closed-class words, and tokens with a frequency higher than 10. For every token, we extract its contextualized representations and embedding layer representation using the 12-layered BERT-base-cased model (Devlin et al., 2019) in the following way: First, we tokenize sentences using the Moses tokenizer and pass them through the standard pipeline of BERT as implemented in HuggingFace. We extract layer-wise representations of every token. If the BERT tokenizer splits an input token into subwords or multiple tokens, we mean pool over them to create an embedding of the input token. For every layer, we cluster tokens using their contextualized representations.\\n\\n3.3 CONCEPT LABELS\\n\\nWe define a hierarchical concept-tagset, starting with the core language properties i.e., semantics, parts-of-speech, lexical, syntax, etc. For each cluster, we assign the core properties that are represented by that cluster, and further enrich the label with finer hierarchical information. It is worth noting that the core language properties are not mutually exclusive i.e., a cluster can belong to more than one core properties at the same time. Consider a group of words mentioning first name of the football players of the German team and all of the names occur at the start of a sentence, the following series of tags will be assigned to the cluster:\\n\\n- semantic:origin:Germany\\n- semantic:entertainment:sport:football\\n- semantic:namedentity:person:firstname\\n- syntax:position:firstword\\n\\nHere, we preserve the hierarchy at various levels such as, sport, person name, origin, etc., which can be used to combine clusters to analyze a larger group.\\n\\n---\\n\\n2 We experimented with Elbow and Silhouette but they did not show reliable results.\\n\\n3 http://data.statmt.org/news-crawl/en/\\n\\n4 https://pypi.org/project/mosestokenizer/\\n\\n5 https://huggingface.co\"}"}
{"id": "POTMtpYI1xH", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Following our definition of concepts, we formulated the annotation task using the two questions below:\\n\\nQ1: Is the cluster meaningful?\\nQ2: Can the two clusters be combined to form a meaningful group?\\n\\nWe show annotators the contextual information (i.e., corresponding sentences) of the words for each of these questions. The annotator can answer them as (i) yes, (ii) no, and (iii) don't know or can't judge.\\n\\nQ1 mainly involves identifying if the cluster is meaningful, according to our definition of a concept (Section 2). Based on the yes answer of Q1, annotators' task is to either introduce a new concept label where it belongs or classify it into an appropriate existing concept label. Note that at the initial phase of the annotation, the existing concept label set was empty. As the annotators annotate and finalize the concept labels, we accumulate them into the existing concept label set and provide them in the next round of annotations, in order to facilitate and speed-up the annotations. In Q2, we ask the annotators to identify whether two sibling clusters can be also combined to form a meaningful super-cluster. Our motivation here is to keep the hierarchical information that BERT is capturing intact. For example, a cluster capturing Rock music bands in the US can be combined with its sibling that groups Rock music bands in the UK to form a Rock music bands cluster. Similarly, based on the yes answer of Q2, the annotators are required to assign a concept label for the super-cluster.\\n\\nThe annotation guidelines combined with the examples and screenshots of the annotation platform is provided in Appendix B.\\n\\nThe annotators are asked to maintain hierarchy while annotating e.g., a cluster of ice hockey will be annotated as semantic:entertainment:sport:ice_hockey since the words are semantically grouped and the group belongs to sports, which is a subcategory of entertainment. In case of more than one possible properties that form a cluster, we annotate it with both properties e.g., title case and country names where the former is a lexical property and the latter is a semantic property.\\n\\nSince annotation is an expensive process, we carried out annotation of the final layer of BERT only. The concept annotation is performed by three annotators followed by a consolidation step to resolve disagreements if there are any. For the annotation task, we randomly selected 279 clusters out of 1000 clusters obtained during the clustering step (see Section 3.1).\\n\\n4.1 INTER-ANNOTATION AGREEMENT\\n\\nWe computed Fleiss $\\\\kappa$ (Fleiss et al., 2013) and found the average value for Q1 and Q2 to be 0.61 and 0.64, respectively, which is substantial in the $\\\\kappa$ measurement (Landis & Koch, 1977). The detail on $\\\\kappa$ measures and agreement computation using other metrics are reported in Appendix (Table 2).\\n\\n4.2 STATISTICS\\n\\nFor Q1, we found 243 (87.1%) meaningful clusters and 36 (12.9%) non-meaningful clusters. For Q2, we found that 142 (75.9%) clusters out of 187 clusters can form a meaningful cluster when combined with their siblings. The annotation process resulted in 174 unique concept labels from the 279 clusters (See Appendix B.3 for the complete list of labels). The high number of concept labels is due to the fine-grained distinctions and multi-facet nature of the clusters where a cluster can get more than one labels. The label set consists of 11 lexical labels, 10 morphological labels, 152 semantic labels and one syntactic label. The semantic labels form the richest hierarchy where the next level of hierarchy consists of 42 labels such as: entertainment, sports, geo-politics, etc.\\n\\n4.3 EXAMPLES OF CONCEPT HIERARCHY\\n\\nIn this Section, we describe the concept hierarchy that we have achieved through our annotation process. Figure 1 illustrates an example of a resulting tree found by hierarchical clustering. Each node is a concept candidate. We capture different levels of fine-grained meanings of word groups, which do not exist in pre-defined concepts. For example, a SEM or an NE tagger would mark a name as person, but our discovery of latent concepts show\"}"}
{"id": "POTMtpYI1xH", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Example Concepts. 2a shows a cluster that has a lexical property (hyphenation) and a morphological property (adjective). Similarly, 2b shares a common suffix est and additionally possesses the morphological phenomenon, superlative adjectives. Finally, a large number of clusters were grouped based on the fine-grained semantic information. For example, the cluster in 2c is a named entity cluster specific to places in Germany.\\n\\nthat BERT uses a finer hierarchy by further classifying them as \u201cbaseball players\u201d, \u201csoccer players\u201d, and \u201cathletes\u201d. Our annotation process preserves this information and provides hierarchical labels such as semantic:named-entity:person:celebrity:actor and semantic:named-entity:person:athletes:soccer. Due to the multi-faceted nature of the latent clusters, many of them are annotated with more than one concept label. In the case of the clusters shown in Figure 1, they have a common lexical property (title case) and hence will also get the label LEX:case:title during annotation. Figure 2 shows word clouds of a few annotated clusters along with their descriptions.\\n\\n5.1 Qualitative Analysis\\nOur annotated dataset unveils insightful analysis of the latent concepts learned within BERT representations. Figure 3 presents a few examples of the discovered concepts. The two clusters of decimal numbers (Figure 3a, 3b) look quite similar, but are semantically different. The former represents numbers appearing as percentages e.g., 9.6% or 2.4 percent and the latter captures monetary figures e.g., 9.6 billion Euros or 2.4 million dollars. We found these two clusters to be sibling, which shows that BERT is learning a morpho-semantic hierarchy where it grouped all the decimal numbers together (morphologically) and then further made a semantic distinction by dividing them into percentages and monetary figures. Such a subtle difference in the usage of decimal numbers shows the importance of using fine-grained concepts for interpretation. For example, numbers are generally analyzed as one concept (CD tag in POS) which may be less informative or even misleading given that BERT treats them in a variety of different ways. Figure 3c shows an example of a cluster where the model captures an era of time, specifically 18 and 19 hundreds. Learning such information may help the model to learn relation between a particular era and the events occurring in that time period. Similarly, we found BERT learning semantic distinction of animal kingdom and separated animals into land, sea and flying groups (see Appendix B.3). These informative categories support the use of pre-trained models as a knowledge base (Petroni et al., 2019).\\n\\nWe further observed that BERT learns aspects specific to the training data. Figure 3d shows a cluster of words where female roles (Moms, Mothers, Granny, Aunt) are grouped together with job roles such as (housekeeper, Maid, Nanny). The contextual information in the sentences where these words appear, do not explicate whether the person is a male or a female, but based on the data used for the training of BERT, it has associated these roles to females. For example, the sentence \\\"Welfare staff\u2019s\u2019 good housekeeping praised for uncovering disability benefits error\\\" is a general sentence. However, the contextualized representation of housekeeping in this sentence associates it to a female-related concept. Similarly, in another example BERT clustered names based on demography even though the context in which the word is used, does not explicitly provide such information. An example is the sentence, \\\"Bookings: Dzagoev, Schennikov, Musa, Akinfeev\\\" where the name Musa is used in a diverse context but it is associated to a cluster of specific demography (Arab region). While it is natural to form clusters based on specific data aspects, we argue that the use of such concepts while making a general prediction raises concerns of bias and fairness. For example, a loan prediction application should not rely on the background of the name of the applicant.\"}"}
{"id": "POTMtpYI1xH", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"REFE RENCES\\n\\nLasha Abzianidze, Johannes Bjerva, Kilian Evang, Hessel Haagsma, Rik van Noord, Pierre Ludmann, Duc-Duy Nguyen, and Johan Bos. The parallel meaning bank: Towards a multilingual corpus of translations annotated with compositional meaning representations. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL '17, pp. 242\u2013247, Valencia, Spain, 2017.\\n\\nAnthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. Identifying and controlling important neurons in neural machine translation. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=H1z-PsR5KX.\\n\\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do Neural Machine Translation Models Learn about Morphology? In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), Vancouver, July 2017a. Association for Computational Linguistics. URL https://aclanthology.coli.uni-saarland.de/pdf/P/P17/P17-1080.pdf.\\n\\nYonatan Belinkov, Llu\u00eds Marquez, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks. In Proceedings of the 8th International Joint Conference on Natural Language Processing (IJCNLP), November 2017b.\\n\\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. On the linguistic representational power of neural machine translation models. Computational Linguistics, 45(1):1\u201357, March 2020.\\n\\nFahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, and Stephan Vogel. Understanding and Improving Morphological Learning in the Neural Machine Translation Decoder. In Proceedings of the 8th International Joint Conference on Natural Language Processing (IJCNLP), November 2017.\\n\\nFahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, D. Anthony Bau, and James Glass. What is one grain of sand in the desert? analyzing individual neurons in deep nlp models. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI, Oral presentation), January 2019a.\\n\\nFahim Dalvi, Avery Nortonsmith, D. Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, and James Glass. Neurox: A toolkit for analyzing individual neurons in neural networks. In AAAI Conference on Artificial Intelligence (AAAI), January 2019b.\\n\\nRomain Deveaud, Eric SanJuan, and Patrice Bellot. Accurate and effective latent concept modeling for ad hoc information retrieval. Document num\u00e9rique, 17(1):61\u201384, 2014.\\n\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, Minnesota, 2019. Association for Computational Linguistics.\\n\\nNadir Durrani, Fahim Dalvi, Hassan Sajjad, Yonatan Belinkov, and Preslav Nakov. One size does not fit all: Comparing NMT representations of different granularities. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 1504\u20131516, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1154. URL https://www.aclweb.org/anthology/N19-1154.\\n\\nNadir Durrani, Hassan Sajjad, Fahim Dalvi, and Yonatan Belinkov. Analyzing individual neurons in pre-trained language models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4865\u20134880, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.395. URL https://www.aclweb.org/anthology/2020.emnlp-main.395.\"}"}
{"id": "POTMtpYI1xH", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "POTMtpYI1xH", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "POTMtpYI1xH", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "POTMtpYI1xH", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.2 ALIGNMENT WITH PRE-DEFINED CONCEPTS\\n\\nA number of works on interpreting DNNs study to what extent various linguistic concepts such as parts-of-speech tags, semantic tags, etc are captured within the learned representations. This is in view of one school of thought which believes that an NLP model needs to learn linguistic concepts in order to perform well and to generalize (Marasovi\u0107, 2018). For example, the holy grail in machine translation is that a proficient model ought to be aware of word morphology, grammatical structure, and semantics to do well (Vauquois, 1968; Jones et al., 2012). In this section, we explored how well the latent concepts in BERT align with the pre-defined linguistic concepts.\\n\\nWe compared the resulting clusters with the following pre-defined concepts: parts of speech (POS) tags (Marcus et al., 1993), semantic tags (SEM) using the Parallel Meaning Bank data (Abzianidze et al., 2017), CCG supertagging using CCGBank (Hockenmaier, 2006), syntactic chunking (Chunking) using CoNLL 2000 shared task dataset (Tjong Kim Sang & Buchholz, 2000), WordNet (Miller, 1995) and LIWC psycholinguistic-based tags (Pennebaker et al., 2001). We also introduced lexical and syntactic concepts such as casing, ngram matches, affixes, first and last word in a sentence etc. Appendix D provides the complete list of pre-defined concepts. For POS, SEM, Chunking, and CCG tagging, we trained a BERT-based classifier using the training data of each task and tagged the words in the selected News dataset. For WordNet and LIWC, we directly used their lexicon.\\n\\nWe consider a latent concept to align with a corresponding pre-defined concept if 90% of the cluster's tokens have been annotated with that pre-defined concept. For example, Figure 3a and 3b are assigned a tag POS:CD (parts-of-speech:cardinal numbers). Table 1 shows the statistics on the number of clusters matched with the pre-defined concepts. Of the 1000 clusters, we found the linguistic concepts in POS to have maximum alignment (30%) with the latent concepts in BERT, followed by Casing (23%). The remaining pre-defined concepts including various linguistic categories aligned with fewer than 10% of the latent concepts. We further explored the parallelism between the hierarchy of latent and pre-defined linguistic concepts using POS tags. We merged the POS tags into 9 coarse tags and aligned them with the latent concepts. The number of latent concepts aligned to these coarse concepts increased to 50%, showing that the model has learned coarser POS concepts and does not strictly follow the same fine-grained hierarchy.\\n\\n5.3 LAYER-WISE COMPARISON OF CONCEPTS\\n\\nHow do the latent concepts evolve in the network? To answer this question, we need to manually annotate per-layer latent concepts and do a cross-layer comparison. However, as manual annotation is an expensive process, we used pre-defined concepts as a proxy to annotate the concepts.\"}"}
{"id": "POTMtpYI1xH", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Alignment of BERT concepts (Layer 12) with the pre-defined concepts\\n\\n| Concept          | Matches | (2.0%) | (0.5%) | (23%) | (30%) | (10%) | (1.5%) | (3.9%) | (8.7%) | (6.3%) | (3.5%) |\\n|------------------|---------|--------|--------|-------|-------|-------|--------|--------|-------|--------|-------|\\n| Lexical Morphology and Semantics | 20 | 5 | 229 | 297 | 96 | 15 | 39 | 87 | 63 | 35 |\\n\\nFigure 4 summarizes the layer-wise matching of pre-defined concepts with the latent concepts. Interestingly, the layers differ significantly in terms of the concepts they capture.\\n\\nIn Figure 4a, the embedding layer is dominated by the concepts based on common ngram affixes. The number of ngram-based shallow lexical clusters consistently decreases in the subsequent layers. The suffixes concept showed a different trend, where the information peaks at the lower-middle layers and then drops in the higher layers. The dominance of ngrams-based concepts in the lower layers is due to the subword segmentation. The noticeable presence in the middle layers might be due to the fact that suffixes often maintain grammatical information unlike other ngrams. For example, the ngram \\\"ome\\\" does not have a linguistic connotation, but suffix \\\"ful\\\" converts a noun into an adjective. Interestingly, casing information is least represented in the lower layers and is consistently improved for higher layers. Casing in English has a morphological role, marking a named entity, which is an essential knowledge to preserve at the higher layers.\\n\\nThe patterns using the classical NLP tasks: POS, SEM, CCG and Chunking all showed similar trends (See Figure 4b and 4c). The concepts were predominantly captured at the middle and higher layers, with minimal representation at the lower layers. WordNet and LIWC, which are cognitive and psychology based grouping of words respectively, showed a rather different trend. These concepts had a higher match at the embedding layer and a consistent drop after the middle layers. In other words, the higher and last layers of BERT are less aligned with the cognitive and psychology based grouping of words, and these concepts are better represented at the embedding and lower layers. We manually investigate a few clusters from the lower layers that match with WordNet and LIWC. We found that these clusters group words based on similar meaning e.g. all words related to \\\"family relations\\\" or \\\"directions in space\\\" form a cluster (See Appendix C for more examples). Lastly, Figure 4c also shows that the FirstWord position information is predominantly learned at the last layers only. This is somewhat unexpected, given that no clusters were based on this concept in the embedding layer, despite it having an explicitly position component.\\n\\nThese trends reflect the evolution of knowledge across the network: lower layers encode the lexical and meaning-related knowledge and with the inclusion of context in the higher layers, the encoded concepts evolve into representing linguistic hierarchy. These findings are in line with Mamou et al. (2020) where they found the emergence of linguistic manifolds across layer depth.\\n\\nIn this section, we discuss the concepts that were not matched with the pre-defined concepts. We have divided them into 3 categories: i) latent concepts that can be explained via composition of\\n\\n---\\n\\n7 For every cluster we pick a matching ngram with highest frequency match. Longest ngram is used when tie-breaker is required. We ignore unigrams.\"}"}
{"id": "POTMtpYI1xH", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Unaligned Concepts\\n\\ntwo pre-defined concepts, ii) concepts that cannot be explained via auto-labels but are meaningful and interpretable, iii) concepts that are uninterpretable. Figure 5a and 5b are examples of the first category mentioned above. The former describes a concept composed of different verb forms. It does not fully align with any of the fine-grained verb categories but can be deemed as a verb cluster at coarser level. Similarly the latter shows a cluster containing singular and plural nouns (described by POS:NN and POS:NNS) and WordNet concepts (WN:noun:food and WN:noun:plants) and can be aligned with a coarser noun category. Figure 5c shows a cluster that does not match with any human-defined concept but are interpretable in that the cluster is composed of compound words. Lastly in Figure 5d, we show a cluster that we found to be uninterpretable.\\n\\nIn addition to the manually labeled dataset, we also developed a large dataset, BCN, using a weakly supervised approach. The motivation of creating such a dataset is to provide a reasonable size dataset that can be effectively use for interpretation studies and other tasks. The idea is to expand the number of tokens for every concept cluster by finding new token occurrences that belong to the same cluster. There are several possible ways to develop such a dataset. Here, we explored two different approaches.\\n\\nFirst: we compute the centroid for each cluster and find the cluster that is closest to the representation of any given new token. However, this did not result in accurate cluster assignment because of the non-spherical and irregularly shaped clusters.\\n\\nSecond: we developed a logistic regression classifier (as shown in Appendix A, Algorithm 2) using our manually annotated dataset to assign new tokens to given concept clusters. We found the second approach better than the former in terms of token to cluster assignment. We trained the model using 90% of the concept clusters and evaluate its performance on the remaining 10% concept clusters (held-out set). The classifier achieved a precision score of 75% on the held-out set. In order to achieve higher precision, we introduce a threshold $t = 0.97$ on the confidence of the predicted cluster id, assigning new tokens to particular clusters only when the confidence of the classifier is higher than the threshold. This enables better precision in cluster assignment to the new tokens, at the expense of discarding some potentially good assignments, which can be offset by using more data for prediction.\\n\\nUsing the trained model we labeled all the tokens from the 2 million random sentences from the unused News 2018 dataset (see Section 3). The resulting dataset: BCN is a unique multi-faceted resource consisting of 174 concept labels with a total of 997,195 annotated instances. The average number of annotated instances per concept label are 5,731. The utility of this resource is not limited to interpretation, but can serve as a valuable fine-grained dataset for the NLP community at large. The hierarchy present in the concept labels provides flexibility to use data with various granularity levels. Appendix F provides the detailed statistics for BCN.\\n\\nCase Study\\n\\nIn order to showcase the efficacy of BCN as a useful resource in interpretation, we present a case-study based on neuron-level interpretation in this section. The goal of neuron interpretation is to discover a set of neurons responsible for any given concept (Sajjad et al., 2021). Most of the work in this direction Lakretz et al. (2019); Durrani et al. (2020); Torroba Hennigen et al. (2020) identified neurons responsible for concepts belonging to the core NLP tasks such as morphology, syntax and semantics. In this work, we found that BERT learns finer categories compared to the ones defined in the core NLP tasks. For example, BCN consists of a large number of fine-grained proper noun categories, each representing a unique facet such as proper-noun:person:specific-demography. This enables identifying neurons learning very fine-grained properties, thus provides a more informed interpretation of models.\"}"}
{"id": "POTMtpYI1xH", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In a preliminary experiment, we performed neuron analysis using the PER (person) concept of SEM and the fine-grained concept of Muslim names (Figure 3e). We then compared the amount of neurons required for each concept. For the SEM dataset, we used the standard splits (Appendix D). For the fine-grained concept, the BCN dataset consists of 2748 Muslim name instances. We randomly selected an equal amount of negative class instances and split the data into 80% train, 10% development and 10% test sets. We used Linguistic Correlation Analysis (Dalvi et al., 2019a), using the NeuroX toolkit Dalvi et al. (2019b) and identified the minimum number of neurons responsible for each concept. We found that only 19 neurons are enough to represent the fine-grained concept as opposed to 74 neurons for the PER concept of SEM, showing that the BCN dataset enables selection of specialized neurons responsible for very specific aspects of the language. The discovery of such specialized neurons also facilitate various applications such as model control (Bau et al., 2019; Gu et al., 2021; Suau et al., 2020), domain adaptation (Gu et al., 2021) and debiasing.\\n\\nThe interpretation of DNNs in NLP has been largely dominated by the post-hoc model analysis (Belinkov et al., 2017a; Liu et al., 2019a; Tenney et al., 2019a) where the primary question is to identify which linguistic concepts are encoded in the representation. Researchers have analyzed a range of concepts varying from low-level shallow concepts such as word position and sentence length to linguistically motivated concepts such as morphology (Vylomova et al., 2016; Dalvi et al., 2017; Durrani et al., 2019), syntax (Shi et al., 2016; Linzen et al., 2016) and semantics (Qian et al., 2016; Belinkov et al., 2017b) and provide insights into what concepts are learned and encoded in the representation. One of the shortcomings of these studies is their reliance on pre-defined concepts for interpretation. Consequently, novel concepts that models learn about the language are largely undiscovered.\\n\\nRecently Michael et al. (2020) analyzed latent concepts learned in pre-trained models using a binary classification task to induce latent concepts relevant to the task and showed the presence of linguistically motivated and novel concepts in the representation. Mamou et al. (2020) analyzed representations of pre-trained models using mean-field theoretic manifold analysis and showed the emergence of linguistic structure across layer depth. Similar to these two studies, we aim to analyze latent concepts learned in the representation. However different from them, we analyze raw representations independent of a supervised task. The reliance on a supervision task effects the type of latent concepts found and may not fully reflect the latent concepts encoded in the raw representation. Moreover, the post-hoc classifiers require a careful evaluation to mitigate the concerns regarding the power of the probe (Hewitt & Liang, 2019; Zhang & Bowman, 2018). In this work, we address these limitations by analyzing latent concepts learned in BERT in an unsupervised fashion.\\n\\nIn this work, we have provided a comprehensive analysis of latent concepts learned in the BERT model. Our analysis revealed various notable findings such as, i) the model learns novel concepts which do not strictly adhere to any pre-defined linguistic groups, ii) various latent concepts are composed of multiple independent properties, such as proper-nouns and first word in a sentence, iii) lower layers specialize in learning shallow lexical concepts while the middle and higher layers have a better representation of core linguistic and semantic concepts. We also released a novel BERT-centric concept dataset that not only facilitates future interpretation studies, but will also serve as an annotated dataset similar to POS, WordNet and SEM. Different from the classical NLP datasets, it provides a unique multi-facet set of concepts.\\n\\nWhile this work has led to plenty of insight into the inner workings of BERT and led to a novel resource, increasing the diversity of the observed concepts is an important direction of future work. Working around the memory and algorithm constraints will allow the creation of a more varied concept set. Phrase-level concepts is yet another direction that can be explored further. Finally, a few works on analyzing word representations (both static and contextual) like Reif et al. (2019) and Ethayarajh (2019) have alluded that taking the principal components into account may lead to a more controlled analysis. Incorporating this line of work may yield useful insights into the type of discovered latent clusters.\"}"}
{"id": "POTMtpYI1xH", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 1: Learning Latent Concept with Clustering\\n\\nInput: $y_l = \\\\text{word representation of all running words}$\\n\\nParameter: $K = \\\\text{No. of output clusters}$\\n\\n1: for each word $w_i$ do\\n2: $\\\\text{assign } w_i \\\\text{ to cluster } c_i$\\n3: end for\\n\\n4: while No. of clusters $\\\\neq K$ do\\n5: for each cluster pair $c_i, c_i'$ do\\n6: $d_{i,i'} =$ inner-cluster difference of combined cluster $c_i$ and $c_i'$\\n7: end for\\n8: $c_j, c_j'$ = cluster pair with minimum value of $d$\\n9: $\\\\text{merge clusters } c_j$ and $c_j'$\\n10: end while\\n\\nAlgorithm 2: Concept Prediction with Logistic Regression\\n\\nInput: $X_{\\\\text{train}} = \\\\text{word representations for train data}$, $Y_{\\\\text{train}} = \\\\text{cluster id from Algorithm 1}$, $X_{\\\\text{test}} = \\\\text{word representations for test data}$\\n\\nParameter: $t = \\\\text{probability threshold}$\\n\\n1: $c = \\\\text{unique cluster ids from } Y_{\\\\text{train}}$\\n2: $M = \\\\text{train Logistic Regression model on } X_{\\\\text{train}} \\\\text{ and } Y_{\\\\text{train}}$\\n3: for each $x \\\\in X_{\\\\text{test}}$ do\\n4: $p =$ predict $K$ probabilities for each cluster using $M$ and input $x$\\n5: $i = \\\\text{arg max } p$\\n6: if $p_i > t$ then\\n7: $\\\\text{assign } x \\\\text{ to cluster id } c_i$\\n8: end if\\n9: end for\\n\\n**Appendix A**\\n\\n**Algorithm and BCN Algorithm**\\n\\n**Annotation Details**\\n\\nFor the annotation, we prepared detailed instructions to guide the annotators, which they followed during the annotation tasks. Our annotation consists of two questions:\\n\\n(i) **Q1**: Is the cluster meaningful?\\n(ii) **Q2**: Can the two clusters be combined to form a meaningful group?\\n\\nThe word cluster is represented in a form of a word cloud, where the frequency of the word in the data represents a relative size of the word in the word cloud. To understand the context of each word in the cluster we also facilitated annotators with associated sentences from the dataset. For the annotation, we provided specific instructions with examples for each question. With the second question, the idea is to understand whether two sibling clusters can be combined to form a meaningful super-cluster. For the second question, two clusters are siblings, which we automatically identified from our hierarchical clustering model. We showed the second question only if a sibling of the main cluster (cluster presented in the first question) was available or identified by the clustering algorithm. Hence, annotators did not see the second question in all annotations. Below we provided instructions which we accompanied with the annotation platform in a form of a tutorial.\\n\\n**B.1 Annotation Instructions**\\n\\nThe annotation task was to look first look at a group of words (i.e., representing as a cluster) and answer the first question. Then, look at two groups of words to answer the second question.\\n\\n**Q1: Is the cluster meaningful?**\\n\\nA word group is meaningful if it contains semantically, syntactically, or lexically similar words. The example in Figure 6 has only numbers with two digits, hence, this is a meaningful group. The labels for this question include the following:\\n\\n1. **Yes** (if represents a meaningful cluster)\\n2. **No** (if it does not represent any meaningful cluster)\\n3. **Don't know or can't judge** (if it does not have enough information to make a judgment. It is recommended to categorize the word groups using this label when the word group is not understandable at all.)\"}"}
{"id": "POTMtpYI1xH", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Example of a group of tokens representing a meaningful cluster.\\n\\nIf the answer to this question is **Yes**, then the task would be to assign a name to the word cluster using one or more words. While assigning the name, it is important to maintain the hierarchy. For example, for the above word group in Figure 6, we can assign a name: semantic:number. This needs to be written in the text box right below this question. While deciding the name of the cluster, the priority has to be to focus on semantics first, syntax second, and followed by any other meaningful aspects. While annotating it is also important to consider\\n\\n(i) their relative frequency of the tokens in the cluster, which is clearly visible in the word cluster,\\n\\n(ii) context in a sentence where the word appears in.\\n\\nQ2: **Can the two clusters be combined to form a meaningful group?**\\n\\nFor this question, two clusters are shown and the task is to see if they can form a meaningful super-cluster after combining. In these two clusters, the left one is the same cluster annotated for the first question. The answer (i.e., labels) of this question is similar to Q1: **Yes**, **No**, and **Don't know or can't judge**. Depending on the answer to this question the task is to provide a meaningful name similar to Q1.\\n\\nIn Figure 7 and 8 we provide screenshots for Q1 and Q2, respectively.\"}"}
{"id": "POTMtpYI1xH", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\nFigure 8: An example of the annotation interface for Q2.\\n\\nAgree. Pair Fleiss $\\\\kappa$. K. alpha Avg. Agr.\\n\\n|   | A1 - C | A2 - C | A3 - C | Avg |\\n|---|--------|--------|--------|-----|\\n| Q1 | 0.604  | 0.622  | 0.604  | 0.610 |\\n|    | 0.604  | 0.623  | 0.604  | 0.610 |\\n| Q2 | 0.702  | 0.625  | 0.602  | 0.643 |\\n|    | 0.700  | 0.621  | 0.592  | 0.638 |\\n\\nTable 2: Inter-annotator agreement using Fleiss Kappa ($\\\\kappa$).\\n\\nA refers to annotator, and C refers to consolidation.\\n\\nB.2 Annotation Agreement\\n\\nWe computed annotation agreement using Fleiss $\\\\kappa$ Fleiss et al. (2013), Krippendorff's $\\\\alpha$ Krippendorff (1970) and average observed agreement Fleiss et al. (2013). In Table 2, we present the annotation agreement with different approaches.\\n\\nB.3 Concept Labels\\n\\nOut annotation process resultant in 183 concept labels. In Table 3, 4 and 5 we report LEX, POS and SEM concepts labels, respectively.\\n\\nC. Analysis\\n\\nFigure 9 shows example concepts. Figure 10 shows examples of LIWC and WordNet concepts found in lowe layers.\"}"}
{"id": "POTMtpYI1xH", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 3: Concept labels: LEX and POS.\\n\\n| Concept Label | Description |\\n|---------------|-------------|\\n| SEM:action    | entertainment:music:US rock-bands and musicians SEM:honour systemSEM:action:body:face SEM:entertainment:sport SEM:languageSEM:activism:demonstration SEM:entertainment:sport:american football SEM:language:foreign wordSEM:agent SEM:entertainment:sport:american football:game play SEM:measurement:heightSEM:agent:passerby SEM:entertainment:sport:baseball SEM:measurement:imperialSEM:animal:land animal SEM:entertainment:sport:basketball SEM:measurement:lengthSEM:animal:sea animal SEM:entertainment:sport:club name SEM:measurement:length and weightSEM:art:physical SEM:entertainment:sport:cricket SEM:media:social mediaSEM:attribute:human SEM:entertainment:sport:football SEM:media:tv:channelSEM:baby related SEM:entertainment:sport:game score SEM:medicine:drug relatedSEM:brand SEM:entertainment:sport:game time SEM:medicine:medical conditionSEM:crime:assault SEM:entertainment:sport:ice hockey SEM:metaphysical:death relatedSEM:crime:tool SEM:entertainment:sport:player name SEM:mining and energySEM:defense:army SEM:entertainment:sport:rugby SEM:named entitySEM:defense:army:title SEM:entertainment:sport:team name SEM:named entity:locationSEM:defense:guns SEM:entertainment:sport:team selection SEM:named entity:location:citySEM:demography SEM:entertainment:sport:winter sport SEM:named entity:location:city and countySEM:demography:age SEM:entertainment:vacation:outdoor SEM:named entity:location:city and stateSEM:demography:age:young SEM:fashion SEM:named entity:location:countySEM:demography:muslim name SEM:fashion:apparel SEM:named entity:organizationSEM:donation and recovery SEM:fashion:clothes SEM:named entity:personSEM:entertainment SEM:financial SEM:named entity:person:first nameSEM:entertainment:actors SEM:financial:money figure SEM:named entity:person:initialSEM:entertainment:fictional SEM:financial:stock SEM:named entity:person:last nameSEM:entertainment:fictional:games of thrones SEM:food:wine related SEM:negativeSEM:entertainment:film:hollywood SEM:food and plant SEM:numberSEM:entertainment:film and tv SEM:gender:feminine SEM:number:alpha numericSEM:entertainment:gaming SEM:geopolitics SEM:number:cardinal:spelledSEM:entertainment:music SEM:group:student SEM:number:floating pointSEM:entertainment:music:classical SEM:historic:medieval SEM:number:less than hundred |\\n\\nTable 4: Concept labels: SEM.\"}"}
{"id": "POTMtpYI1xH", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 8: Concept labels (LEX, POS) with token and type.\\n\\nmatches with most of the classical NLP tasks compared to BERT. The difference is much more pronounced in the case of POS with RoBERTa having the highest match. This may reflect that the latent concepts of RoBERTa follow a closer hierarchy to POS compared to other models. On the contrary, for WordNet and LIWC, BERT showed substantially better alignment than the other two models.\"}"}
{"id": "POTMtpYI1xH", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Concept Label | Token | Type |\\n|---------------|-------|------|\\n| SEM:action    | 2,908 |      |\\n| SEM:negative  | 364   |      |\\n| POS:verb      |       |      |\\n| SEM:action:body:face | 1,553 | 101  |\\n| SEM:agent     | 4,491 | 483  |\\n| POS:noun:singular |     |      |\\n| SEM:agent:passerby | 330  | 14   |\\n| SEM:animal:land |     |      |\\n| SEM:animal    | 2,121 | 419  |\\n| SEM:animal:sea |      |      |\\n| SEM:art:physical | 5,041 | 647  |\\n| SEM:baby      |       |      |\\n| related       | 2,184 | 181  |\\n| SEM:crime:assault | 2,707 | 275  |\\n| SEM:crime:tool |      | 34   |\\n| defense:army  | 6,619 | 331  |\\n| defense:army:title |     |      |\\n| LEX:case:title |       |      |\\n| defense:guns  | 9,803 | 516  |\\n| demography    | 19,150| 461  |\\n| demography:age:young | 27,929 | 274  |\\n| donation and recovery | | |\\n| and            |       |      |\\n| LEX:case:title |       |      |\\n| case          | 255   | 21   |\\n| SEM:named     |       |      |\\n| entity        | 3,774 | 499  |\\n| entertainment:fictional | | 17  |\\n| and            |       |      |\\n| entertainment:film | |      |\\n| and            |       |      |\\n| entertainment:tv | |      |\\n| entertainment:gaming | | 555 |\\n| entertainment:music | | 710 |\\n| entertainment:music:classical | | 390 |\\n| entertainment:music:US | |      |\\n| entertainment:sport | | 154 |\\n| entertainment:sport | | 704 |\\n| entertainment:sport:american | | 704 |\\n| entertainment:sport:baseball | |      |\\n| entertainment:sport:game | |      |\\n| score         | 1,835 | 383  |\\n| entertainment:sport:team | |      |\\n| selection     | 12,919| 815  |\\n| entertainment:sport:winter | |      |\\n| entertainment:vacation:outdoor | | 149 |\\n| fashion:apparel | | 108 |\\n| fashion:clothes | | 376 |\\n| financial     | 7,003 | 308  |\\n| financial:stock | | 201 |\\n| food          | 3,601 | 256  |\\n| food:wine     | 494   | 20   |\\n| gender:feminine | |      |\\n| unnamed-entity:role | | 278 |\\n| group:student | 596   | 60   |\\n| historic:medieval | | 431 |\\n| historic:medieval | |      |\\n| origin:europe:uk | | 128 |\\n| honour system | |      |\\n| system        | 1,124 | 128  |\\n| language      | 8,166 | 336  |\\n| language:foreign word | | 394 |\\n| language:foreign word | |      |\\n| language:foreign word | |      |\\n| measurement:height | | 275 |\\n| measurement:length | | 673 |\\n| measurement:length | |      |\\n| measurement:imperial | | 156 |\\n| media:social media | | 975 |\\n| media:social media | |      |\\n| technology:communication | | 116 |\\n| medicine:drug related | | 92 |\\n| medicine:medical condition | | 261 |\\n| metaphysical:death related | | 164 |\\n| mining and energy | | 279 |\\n| named entity | |      |\\n| named entity | |      |\\n| named entity:person | | 258 |\\n| named entity:person | |      |\\n| named entity:person | |      |\\n| origin:asia:east asian | | 405 |\\n| origin:asia:myanmar | |      |\\n| named entity:person | | 258 |\\n| named entity:person | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity | |      |\\n| known entity |"}
{"id": "POTMtpYI1xH", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| No. | Concept Label | SEM Type | Token | Type |\\n|-----|---------------|----------|-------|------|\\n| 1   | named entity, origin: europe: germany | related | 2,958 | LEX: case:title |\\n| 2   | named entity, origin: europe: sweden | related | 2,881 | LEX: case:title |\\n| 3   | location, origin: north america | related | 330  | SEM: case: |\\n| 4   | location, origin: latin america | related | 152  | SEM: case: |\\n| 5   | location, origin: greece and italy | historic: medieval | 2,512 | SEM: case: |\\n| 6   | location: city and county | related | 359  | SEM: case: |\\n| 7   | location: city and county | related | 19,267 | SEM: case: |\\n| 8   | location: county | related | 1,946 | SEM: case: |\\n| 9   | organization | related | 2,379 | LEX: acronym |\\n| 10  | person | related | 1,842 | LEX: case:title |\\n| 11  | person | related | 1,159 | LEX: case:title |\\n| 12  | person: last name | related | 3,107 | LEX: case:title |\\n| 13  | person: last name | related | 2,532 | LEX: case:title |\\n| 14  | person: first name | related | 1,024 | SYN: position: first: word |\\n| 15  | person: last name | related | 3,515 | LEX: case:title |\\n| 16  | person: last name | related | 4,190 | LEX: case:title |\\n| 17  | person: last name | related | 1,400 | LEX: case:title |\\n| 18  | person: last name | related | 707  | LEX: case:title |\\n| 19  | person: last name | related | 1,056 | LEX: case:title |\\n| 20  | person: last name | related | 3,884 | LEX: case:title |\\n| 21  | person: last name | related | 930  | LEX: case:title |\\n| 22  | person: last name | related | 792  | LEX: case:title |\\n| 23  | person: last name | related | 1,400 | LEX: case:title |\\n| 24  | person: last name | related | 707  | LEX: case:title |\\n| 25  | person: last name | related | 4,190 | LEX: case:title |\\n| 26  | person: last name | related | 1,400 | LEX: case:title |\\n| 27  | person: last name | related | 707  | LEX: case:title |\\n| 28  | person: last name | related | 4,190 | LEX: case:title |\\n| 29  | person: last name | related | 1,400 | LEX: case:title |\\n| 30  | person: last name | related | 707  | LEX: case:title |\\n| 31  | person: last name | related | 4,190 | LEX: case:title |\\n| 32  | person: last name | related | 1,400 | LEX: case:title |\\n| 33  | person: last name | related | 707  | LEX: case:title |\\n| 34  | person: last name | related | 4,190 | LEX: case:title |\\n| 35  | person: last name | related | 1,400 | LEX: case:title |\\n| 36  | person: last name | related | 707  | LEX: case:title |\\n| 37  | person: last name | related | 4,190 | LEX: case:title |\\n| 38  | person: last name | related | 1,400 | LEX: case:title |\\n| 39  | person: last name | related | 707  | LEX: case:title |\\n| 40  | person: last name | related | 4,190 | LEX: case:title |\\n| 41  | person: last name | related | 1,400 | LEX: case:title |\\n| 42  | person: last name | related | 707  | LEX: case:title |\\n| 43  | person: last name | related | 4,190 | LEX: case:title |\\n| 44  | person: last name | related | 1,400 | LEX: case:title |\\n| 45  | person: last name | related | 707  | LEX: case:title |\\n| 46  | person: last name | related | 4,190 | LEX: case:title |\\n| 47  | person: last name | related | 1,400 | LEX: case:title |\\n| 48  | person: last name | related | 707  | LEX: case:title |\\n| 49  | person: last name | related | 4,190 | LEX: case:title |\\n| 50  | person: last name | related | 1,400 | LEX: case:title |\\n| 51  | person: last name | related | 707  | LEX: case:title |\\n| 52  | person: last name | related | 4,190 | LEX: case:title |\\n| 53  | person: last name | related | 1,400 | LEX: case:title |\\n| 54  | person: last name | related | 707  | LEX: case:title |\\n| 55  | person: last name | related | 4,190 | LEX: case:title |\\n| 56  | person: last name | related | 1,400 | LEX: case:title |\\n| 57  | person: last name | related | 707  | LEX: case:title |\\n| 58  | person: last name | related | 4,190 | LEX: case:title |\\n| 59  | person: last name | related | 1,400 | LEX: case:title |\\n| 60  | person: last name | related | 707  | LEX: case:title |\\n| 61  | person: last name | related | 4,190 | LEX: case:title |\\n| 62  | person: last name | related | 1,400 | LEX: case:title |\\n| 63  | person: last name | related | 707  | LEX: case:title |\\n| 64  | person: last name | related | 4,190 | LEX: case:title |\\n| 65  | person: last name | related | 1,400 | LEX: case:title |\\n| 66  | person: last name | related | 707  | LEX: case:title |\\n| 67  | person: last name | related | 4,190 | LEX: case:title |\\n| 68  | person: last name | related | 1,400 | LEX: case:title |\\n| 69  | person: last name | related | 707  | LEX: case:title |\\n| 70  | person: last name | related | 4,190 | LEX: case:title |\\n| 71  | person: last name | related | 1,400 | LEX: case:title |\\n| 72  | person: last name | related | 707  | LEX: case:title |\\n| 73  | person: last name | related | 4,190 | LEX: case:title |\\n| 74  | person: last name | related | 1,400 | LEX: case:title |\\n| 75  | person: last name | related | 707  | LEX: case:title |\\n| 76  | person: last name | related | 4,190 | LEX: case:title |\\n| 77  | person: last name | related | 1,400 | LEX: case:title |\\n| 78  | person: last name | related | 707  | LEX: case:title |\\n| 79  | person: last name | related | 4,190 | LEX: case:title |\\n| 80  | person: last name | related | 1,400 | LEX: case:title |\\n| 81  | person: last name | related | 707  | LEX: case:title |\\n| 82  | person: last name | related | 4,190 | LEX: case:title |\\n| 83  | person: last name | related | 1,400 | LEX: case:title |\\n| 84  | person: last name | related | 707  | LEX: case:title |\\n| 85  | person: last name | related | 4,190 | LEX: case:title |\\n| 86  | person: last name | related | 1,400 | LEX: case:title |\\n| 87  | person: last name | related | 707  | LEX: case:title |\\n| 88  | person: last name | related | 4,190 | LEX: case:title |\\n| 89  | person: last name | related | 1,400 | LEX: case:title |\\n| 90  | person: last name | related | 707  | LEX: case:title |\\n| 91  | person: last name | related | 4,190 | LEX: case:title |\\n| 92  | person: last name | related | 1,400 | LEX: case:title |\\n| 93  | person: last name | related | 707  | LEX: case:title |\\n| 94  | person: last name | related | 4,190 | LEX: case:title |\\n| 95  | person: last name | related | 1,400 | LEX: case:title |\\n| 96  | person: last name | related | 707  | LEX: case:title |\\n| 97  | person: last name | related | 4,190 | LEX: case:title |\\n| 98  | person: last name | related | 1,400 | LEX: case:title |\\n| 99  | person: last name | related | 707  | LEX: case:title |\\n| 100 | person: last name | related | 4,190 | LEX: case:title |\\n| 101 | person: last name | related | 1,400 | LEX: case:title |\\n| 102 | person: last name | related | 707  | LEX: case:title |\\n| 103 | person: last name | related | 4,190 | LEX: case:title |\\n| 104 | person: last name | related | 1,400 | LEX: case:title |\\n| 105 | person: last name | related | 707  | LEX: case:title |\\n| 106 | person: last name | related | 4,190 | LEX: case:title |\\n| 107 | person: last name | related | 1,400 | LEX: case:title |\\n| 108 | person: last name | related | 707  | LEX: case:title |\\n| 109 | person: last name | related | 4,190 | LEX: case:title |\\n| 110 | person: last name | related | 1,400 | LEX: case:title |\\n| 111 | person: last name | related | 707  | LEX: case:title |\\n| 112 | person: last name | related | 4,190 | LEX: case:title |\\n| 113 | person: last name | related | 1,400 | LEX: case:title |\\n| 114 | person: last name | related | 707  | LEX: case:title |\\n| 115 | person: last name | related | 4,190 | LEX: case:title |\\n| 116 | person: last name | related | 1,400 | LEX: case:title |\\n| 117 | person: last name | related | 707  | LEX: case:title |\\n| 118 | person: last name | related | 4,190 | LEX: case:title |\\n| 119 | person: last name | related | 1,400 | LEX: case:title |\\n| 120 | person: last name | related | 707  | LEX: case:title |\\n| 121 | person: last name | related | 4,190 | LEX: case:title |\\n| 122 | person: last name | related | 1,400 | LEX: case:title |\\n| 123 | person: last name | related | 707  | LEX: case:title |\\n| 124 | person: last name | related | 4,190 | LEX: case:title |\\n| 125 | person: last name | related | 1,400 | LEX: case:title |\\n| 126 | person: last name | related | 707  | LEX: case:title |\\n| 127 | person: last name | related | 4,190 | LEX: case:title |\\n| 128 | person: last name | related | 1,400 | LEX: case:title |\\n| 129 | person: last name | related | 707  | LEX: case:title |\\n| 130 | person: last name | related | 4,190 | LEX: case:title |\\n| 131 | person: last name | related | 1,400 | LEX: case:title |\\n| 132 | person: last name | related | 707  | LEX: case:title |\\n| 133 | person: last name | related | 4,190 | LEX: case:title |\\n| 134 | person: last name | related | 1,400 | LEX: case:title |\\n| 135 | person: last name | related | 707  | LEX: case:title |\\n| 136 | person: last name | related | 4,190 | LEX: case:title |\\n| 137 | person: last name | related | 1,400 | LEX: case:title |\\n| 138 | person: last name | related | 707  | LEX: case:title |\\n| 139 | person: last name | related | 4,190 | LEX: case:title |\\n| 140 | person: last name | related | 1,400 | LEX: case:title |\\n| 141 | person: last name | related | 707  | LEX: case:title |\\n| 142 | person: last name | related | 4,190 | LEX: case:title |\\n| 143 | person: last name | related | 1,400 | LEX: case:title |\\n| 144 | person: last name | related | 707  | LEX: case:title |\\n| 145 | person: last name | related | 4,190 | LEX: case:title |\\n| 146 | person: last name | related | 1,400 | LEX: case:title |\\n| 147 | person: last name | related | 707  | LEX: case:title |\\n| 148 | person: last name | related | 4,190 | LEX: case:title |\\n| 149 | person: last name | related | 1,400 | LEX: case:title |\\n| 150 | person: last name | related | 707  | LEX: case:title |\\n| 151 | person: last name | related | 4,190 | LEX: case:title |\\n| 152 | person: last name |"}
{"id": "POTMtpYI1xH", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example of Sem tags Words\\n\\nSEM:action:negative\\nconfine, cripple, decimate, demonised, disappoints, dislocation, disobeyed, disqualify, distort, downsized, jeopardise, hijacked, trashed, traumatizing, undercutting, underpins, underplayed, undervalue, spoilt, spouting, spurned, stifled\\n\\nSEM:action:body:face\\nGaze, LAUGH, Tears, admiring, blushing, chuckles, clap, frown, gasp, giggle, grimace, murmur, smirk, ...\\n\\nAggression, Arguments, Armored, Attackers, Attacks, Backlash, Ceasefire, Clashes, Cops, Counterfeiting\\n\\nSEM:animal:land\\nAnimal Ants, Bees, Beetle, Cobra, Frog, Jaws, Leopard, Paw, Snakes, Spider, Sumatran, frog\\n\\nSEM:animal:sea\\nAnimal Salmon, Shellfish, Trout, catfish, crabs, eel, herring, octopus, oyster, oysters, snail, squid, trout\\n\\nTable 11: Example of Sem tags with associated words.\"}"}
