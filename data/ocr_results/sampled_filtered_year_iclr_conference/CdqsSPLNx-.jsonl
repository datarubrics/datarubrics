{"id": "CdqsSPLNx-", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Vehicle routing problems (VRPs) are a type of classical combinatorial optimization problems widely existing in logistics and transportation operations. There has been an increasing interest to use deep reinforcement learning (DRL) techniques to tackle VRPs, and previous DRL-based studies assumed time-independent travel times between customers. However, travel times in real-world road networks are time-varying, which need to be considered in practical VRPs. We thus propose a Deep Dynamic Attention Models with Gate Mechanisms (DDAM-GM) to learn heuristics for time-dependent VRPs (TDVRPs) in real-world road networks. It extracts the information of node location, node demand, and time-varying travel times between nodes to obtain enhanced node embeddings through a dimension-reducing MHA layer and a synchronous encoder. In addition, we use a gate mechanism to obtain better context embedding. On the basis of a 110-day travel time dataset with 240 time periods per day from an urban road network with 408 nodes and 1250 directed links, we conduct a series of experiments to validate the effectiveness of the proposed model on TDVRPs without and with consideration of time windows, respectively. Experimental results show that our model outperforms significantly two state-of-the-art DRL-based models.\\n\\n1 INTRODUCTION\\n\\nThe vehicle routing problem (VRP) is a classical combinatorial optimization problem and one of the most widely investigated problems in transportation science and logistics. VRPs aim to determine the set of routes for a fleet of vehicles to serve a given set of customers in a road network so that one or more objectives can be optimized without violating constraints imposed. Travel speeds in real-world road network are time-dependent. That is, the travel speeds (time) on a road link are different in different time periods. VRPs with time-dependent travel speeds (time) are called as time-dependent VRPs (TDVRPs). A practical TDVRP can be defined on a directed graph $G = (V, L)$, where $V = \\\\{0, \\\\ldots, V\\\\}$ is a set of vertices (nodes), and $L = \\\\{1, \\\\ldots, L\\\\}$ is the set of directed links connecting the nodes in $V$. Node 0 is the depot at which $K$ vehicles with capacity $Q$ are based.\\n\\nLet $N = \\\\{1, \\\\ldots, N\\\\} (N \\\\subset V)$ denote the set of customers nodes to be visited (served). Each node $i \\\\in V$ is associated with a feature vector consisting of the horizontal coordinate $x_{hi}$, the vertical coordinate $x_{vi}$ and the demand $x_{di}$ of the node, i.e., $x_i = (x_{hi}, x_{vi}, x_{di})$. Each customer node has a certain customer demand and the demands of other nodes are 0. That is, $x_{di} = 0$ for $i \\\\in V \\\\setminus N$. Let $T_{i,j,p}$ denote the travel time between nodes $i$ and $j$ ($i,j \\\\in V$) at time period $p$, and $T_p$ denote the travel time matrix composed of all $T_{i,j,p}$. That is, $T_p = \\\\{T_{i,j,p}\\\\} (V+1) \\\\times (V+1)$.\"}"}
{"id": "CdqsSPLNx-", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"recent years because they are problem-independent and have the potentials of providing better solutions than heuristics. However, they are prone to getting stuck in local optima and cannot provide effective solutions to practical VRPs within a reasonable computation time.\\n\\nIn recent years, deep learning (DL) and deep reinforcement learning (DRL) techniques have attracted more and more optimization researchers' attention because it is promising to use neural networks to directly and quickly learn heuristics from data without any hand-engineered reasoning (Bengio et al., 2021). Some researchers have developed some DRL-based methods to solve effectively several travelling salesmen problems (TSPs) (Bello et al., 2016; Ma et al., 2019) and VRPs (Kool et al., 2018; Nazari et al., 2018), which used much less computation time to find near-optimal solutions than benchmarking techniques did. Although the great potential of using DRL for such combinatorial optimization problems as VRPs, related studies are still in their early stage. In the DRL field, TDVRPs in real road networks have not been investigated so far, which is the focus of this paper.\\n\\nThis paper investigate TDVRPs, without and with consideration of time windows respectively, based on a road network with 408 network nodes and 1250 road links of Chengdu City, China. We used a 110-day link travel speed dataset with 240 2-minute time periods per day to represent the time-dependency of travel speeds of the Chengdu road network. We develop a deep dynamic attention models with gate mechanisms (DDAM-GM) based on the MARDAM (Bono et al., 2020). The novelty of this model consists of three improvements. First, instead of using 3-dimensional model inputs in previous studies (Nazari et al., 2018; Kool et al., 2018; Bono et al., 2020), we propose 4-dimensional model inputs with travel time information to handle TDVRPs effectively, and develop a dimension-reducing MHA to convert reduce 4-dimensional model inputs to 3-dimensional node embeddings and extracts the static travel time information. Second, we propose a synchronous encoder for synchronous coding, so that the model can extract time-varying traveling time information. Third, a gate mechanism used by Parisotto et al. (2020) is introduced to our model to obtain the better context embedding.\\n\\nWe test our DDAM-GM on problem instance sets with different number of customers and the results show that the proposed model achieves the better performance than two learning-based baselines. The main contributions of this paper are as follows.\\n\\n1) This paper is the first to address practical TDVRPs with time-varying travel time in real road networks.\\n2) We propose a novel DRL model, DDAM-GM, to learn problem-solving heuristics, which can provide superior solutions to the investigate TDVRPs over two learning-based models.\\n3) We propose three improvements for learning-based models, which can improve effectively the performance of DRL models for TDVRPs.\\n\\n2 RELATED WORK\\n\\nA pioneering work by Vinyals et al. (2015) developed the Pointer Networks (PtrNets) to solve multiple combinatorial optimization problems (e.g., TSP) based on an encoder-decoder framework (Sutskever et al., 2014). The model was trained off-line and supervised by example solutions. Since then, DL applications in routing problems have attracted increasing attention (Bello et al., 2016; Kool et al., 2018; Bono et al., 2020).\\n\\nBello et al. (2016) extended PtrNets by using REINFORCE algorithm (Williams, 1992) to train PtrNets without supervised solutions, which is the first to introduce DRL to handling combinatorial optimization problems. The graph PtrNets developed by Ma et al. (2019) integrated a graph embedding layer and hierarchical RL (Haarnoja et al., 2018) into PtrNets, which extended the applications of PtrNets to large-scaled TSPs with time windows but increased the computation time heavily.\\n\\nThere has been an increasing interest to using DRL in tackling VRPs since they are extensions of TSPs. Some DRL-based models work like constructive heuristics, which construct each vehicle's route by starting with an empty route and adding new customer nodes to visit in turn until a complete route is formed. In these models, the new node is chosen out based on the attention values (i.e., selection probability) of available nodes in node decoding. Nazari et al. (2018) used element-wise projections to encode nodes instead of using LSTM (Hochreiter & Schmidhuber, 1997) in PtrNets to solve a capacitated vehicle routing problem (CVRP). Kool et al. (2018) proposed the Attention Model (AM) by using a transformer model (Vaswani et al., 2017) for node encoding and a self-attention model approach...\"}"}
{"id": "CdqsSPLNx-", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"mechanism for node decoding, which exhibited superior performances over several benchmarking models (e.g., OR-Tools, PtrNets) on several routing problems. Duan et al. (2020) proposed a graph convolution network-based DRL model to effectively solve a practical CVRP in a real road network. These previous studies construct each vehicle route in turn in optimization process. Following AM (Kool et al., 2018), Bono et al. (2020) developed a MARDAM model to solve a dynamic CVRP with stochastic customers based on manually generated travel speeds and problem sets, which integrate fleet state and fleet state representation modules into the AM model and construct multiple vehicle routes simultaneously.\\n\\nSimilar to improvement heuristics, some DRL-based models, integrating DRL with heuristics, iteratively improve the solutions based on a given initial solution (Chen & Tian, 2019; Lu et al., 2019; Gao et al., 2020). Chen & Tian (2019) proposed a neural-based DRL model, NeuRewriter, by learning a policy to pick heuristics and rewrite the local components of the current solution to solve a CVRP. Following this study, Lu et al. (2019) proposed a transformer-based model by employing a rich set of improvement and perturbation operators to solve a CVRP. Similarly, Gao et al. (2020) designed a graph attention network-based DRL model to learn the local-search heuristics to handle CVRPs with and without time windows. However, these improvement-type DRL models were much more time-consuming in finding optimal solutions than constructive-type DRL models did.\\n\\nIn summary, previous studies were conducted usually based on manually generated problem sets and have not considered time-varying travel speeds in real road networks. It is thus worthy to explore novel and effective DRL models for TDVRPs in real road networks.\\n\\n3.1 Model Overview\\n\\nOur DDAM-GM is developed based on the MARDAM in Bono et al. (2020) by integrating three novel improvements with the MARDAM to handle TDVRPs effectively. Solving a VRP can be modeled as a sequential Multi-agent Markov Decision Process (sM-MDP) with \\\\( T \\\\) time steps (Bono et al., 2020). In each time step \\\\( t \\\\), the current vehicle \\\\( k \\\\) selects an unserved customer \\\\( \\\\pi_k^t \\\\) to visit. This step is repeated \\\\( T \\\\) times until a complete solution \\\\( \\\\pi = \\\\{\\\\pi_1, \\\\ldots, \\\\pi_k, \\\\ldots, \\\\pi_K\\\\} \\\\) \\\\((1 \\\\leq k \\\\leq K)\\\\) is formed, where \\\\( \\\\pi_k \\\\) denotes the \\\\( k \\\\)th vehicle's route. This procedure of constructing the solution \\\\( \\\\pi \\\\) is called as an episode. The objective of learning in DDAM-GM is to obtain a policy \\\\( p_k \\\\) for each vehicle so that the sum of all routes' objective values (rewards) are optimized. We consider homogeneous vehicles only. We can thus simplify the learning objective by making all vehicles' policies share a same group of parameters \\\\( \\\\theta \\\\). That is, we only need to learn a policy parameterized by \\\\( \\\\theta \\\\) and formulated in equation 1. The sMMDP can be solved based on the REINFORCE algorithm (Williams, 1992)\\n\\n\\\\[\\np_{\\\\theta}(\\\\pi|s) = \\\\prod_{t=1}^{T} p_{\\\\theta}(\\\\pi_t|s, \\\\pi_1: t-1)\\n\\\\] (1)\\n\\nLike the MARDAM, the DDAM-GM follows a similar encoder-decoder framework with the Multi-Head Attention (MHA) layer introduced by (Vaswani et al., 2017), which is designed for fully connected road networks in which any node pairs are connected. However, any road nodes in a real road network are only connected with several neighboring nodes. We thus convert the real road network to a fully connected directed road network consisting of only customer nodes by using the method in Huang et al. (2017) to find the travel paths with the shortest travel time between any two customer nodes. Moreover, the encoder in MARDAM only extracts the location and demand information of each road network, and cannot extract time-varying travel time information between road nodes. Intuitively, travel time information between the current node and other nodes are critical to choose next node to visit. Furthermore, the MARDAM cannot represent important relevant information (e.g., the local and global traffic information in the road network) that are critical to select next nodes to visit in TDVRPs.\\n\\nWe thus introduce three novel improvements to the MARDAM to overcome the drawbacks of the MARDAM for TDVRPs. First, we propose a dimension-reducing MHA layer, detailed in section 3.2, to extract travel time information in the encoder. Second, instead of using a one-time encoding\"}"}
{"id": "CdqsSPLNx-", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"process to obtain node embedding only once during encoding in MARDAM, we propose a synchronous encoder to perform an encoding process in each time step $t$ and obtain time-varying node embedding in each encoding so that the time-varying travel time information in real road network can be extracted. Meanwhile, we mask the customer nodes visited in each encoding to improve the optimization performance. Third, we use the travel times from a vehicle's location to other nodes to represent the local traffic information of this vehicle, and use the travel times travelling between nodes of all customer node pairs in the road network to represent the global traffic information at a certain time. These traffic information and other relevant information are aggregated by the gate mechanism in Parisotto et al. (2020) to represent the fleet state in our DDAM-GM.\\n\\nFigure 1: Architecture of one encoding-decoding procedure in the DDAM-GM. The model input $I_t$ represents TDVRPs-related feature values of the depot node and customer nodes in the road network at the $t$th encoding-decoding procedure. Let $T_{i,j,t}$ denote the travel time from node $i$ to node $j$ at time step $t$. We set $f_{i,j,t} = (x_h^i, x_v^i, x_d^i, T_{i,j,t})$ and have $I_t = \\\\{f_{i,j,t}\\\\}_{B \\\\times (N+1) \\\\times (N+1)}$, where $B$ represents the number of problem instances (i.e. batch size). Based on input $I_t$, the initial node embeddings $I_{\\\\text{proj}}t$ is obtained through a linear projection, which is then converted to $I_{\\\\text{mask}}\\\\text{proj}t$ by using a mask operation to mask all served nodes. The $I_{\\\\text{mask}}\\\\text{proj}t$ is then inputted into a \\\"Node Encoder\\\" consisting of a \\\"DR-Trans\\\" block and two same \\\"Trans\\\" block proposed in Vaswani et al. (2017), by which it is converted into node embeddings $e_{\\\\text{node}}t$. The \\\"DR-Trans\\\" block is same to the \\\"Trans\\\" block except for using a DR-MHA layer, described in section 3.2, to replace the MHA layer in \\\"Trans\\\" block. We extract the node embedding of each vehicle's current location from $e_{\\\\text{node}}t$, based on which the node embeddings $e_{\\\\text{fleet}}\\\\text{node}t$ of the fleet can be obtained as the local traffic information of all vehicle locations in the road network. Instead of averaging $e_{\\\\text{node}}t$ as the graph embedding at the time step $t$ in the AM (Kool et al., 2018), we take the average and the maximum of $e_{\\\\text{node}}t$ to obtain the average graph embedding $e_{\\\\text{avg}}\\\\text{graph}t$ and the maximum graph embedding $e_{\\\\text{max}}\\\\text{graph}t$, and then obtain the global graph embedding $e_{\\\\text{global}}\\\\text{graph}t$ of the whole road network at the time step $t$ by using a gate mechanism proposed in Parisotto et al. (2020).\"}"}
{"id": "CdqsSPLNx-", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: DDAM-GM vs baselines\\n\\n| Method       | Obj.    | Percent change | Time    |\\n|--------------|---------|----------------|---------|\\n| TDVRP        | AM (g)  | 62.98          | -0.04s  |\\n|              | AM-I (g)| 62.41          | -0.91%  |\\n|              | MGRA    | 71.42          | 13.40%  |\\n| TDVRP-TW     | AM (g)  | 86.79          | -0.05s  |\\n|              | AM-I (g)| 81.76          | -5.80%  |\\n|              | MARDAM  | 107.90         | 24.32%  |\\n\\nTable 2: Results of Ablation study for DDAM-GM Structure\\n\\n| Method                               | Obj.    | Percent change | Time    |\\n|--------------------------------------|---------|----------------|---------|\\n| DDAM-GM (g)                          | 113.06  | -0.66s         |         |\\n| DDAM-GM (no DR-MHA) (g)              | 115.05  | 1.76%          | 0.29s   |\\n| DDAM-GM (SE change 1) (g)            | 113.66  | 0.53%          | 0.38s   |\\n| DDAM-GM (SE change 2) (g)            | 114.05  | 0.88%          | 0.60s   |\\n| DDAM-GM (no GM) (g)                  | 114.78  | 1.52%          | 0.64s   |\\n\\nTo evaluate the effectiveness of three improvement, we perform an ablation study for the DDAM-GM structure based on a TDVRP with 20 customers. The corresponding experimental results are presented in Table 2. In this table, \\\"DDAM-GM (g) w/o DR-MHA\\\" and \\\"DDAM-GM (g) w/o GM\\\" represent the DDAM-GM without improvement 1 and improvement 3, respectively. \\\"DDAM-GM (g) with 1 encoding 2 decoding\\\" and \\\"DDAM-GM (g) w/o customer nodes mask\\\" are used to investigate the effectiveness of improvement 2. The former is to encode nodes every two time steps, but decode nodes every time step. The latter is to cancel out the node mask operation before the node-encoder. Table 2 shows the objective values of the 5 models, percent changes relative the DDAM-GM (g), and computation time used.\\n\\nIt can be found from Table 2 that three improvements are all helpful to improve the performance of MARDAM. The performance of our DDAM-GM decreases the most (1.76%) without improvement 1 although improvement 1 increases largely the computation time. Without the gate mechanism, the computation time is almost the same, but the model performance will decrease by 1.52%.\\n\\nCONCLUSION\\n\\nThis paper proposes a novel DDAM-GM to tackle practical TDVRPs with time-varying travel time in real road networks. In this model, three improvements are integrated into the MARDAM in Bono et al. (2020) to adapt the practical TDVRPs, which include a dimension-reducing MHA layer, a synchronous encoder, and a gate mechanism. We contain time-varying travel time in the road network as model input. Our experimental results show that our model outperforms significantly two state-of-the-art DRL-based models and a greedy algorithm. The future work can extend the proposed model to solve other real-world combinatorial optimization problems and compare the performance of the proposed model with commercial software and other traditional methods.\\n\\nACKNOWLEDGMENTS\\n\\nThis work was supported by The General Program of National Natural Science Foundation of China (Grant No.s, 72171159 and 71872118), Sichuan Provincial Science and Technology Planning Project (Grant No., 2020YJ0043), and Sichuan University (Grant No., SKSYL201819).\"}"}
{"id": "CdqsSPLNx-", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940, 2016.\\n\\nYoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: A methodological tour d'horizon. European Journal of Operational Research, 290(2):405\u2013421, apr 2021. doi: 10.1016/j.ejor.2020.07.063.\\n\\nGuillaume Bono, Jilles S. Dibangoye, Olivier Simonin, Laetitia Matignon, and Florian Pereyron. Solving multi-agent routing problems using deep attention mechanisms. IEEE Transactions on Intelligent Transportation Systems, pp. 1\u201310, 2020. doi: 10.1109/tits.2020.3009289.\\n\\nXinyun Chen and Yuandong Tian. Learning to perform local rewriting for combinatorial optimization. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 6281\u20136292, 2019.\\n\\nSaid Dabia, Stefan Ropke, Tom van Woensel, and Ton De Kok. Branch and price for the time-dependent vehicle routing problem with time windows. Transportation Science, 47(3):380\u2013396, aug 2013. doi: 10.1287/trsc.1120.0445.\\n\\nAlberto V. Donati, Roberto Montemanni, Norman Casagrande, Andrea E. Rizzoli, and Luca M. Gambardella. Time dependent vehicle routing problem with a multi ant colony system. European Journal of Operational Research, 185(3):1174\u20131191, mar 2008. doi: 10.1016/j.ejor.2006.06.047.\\n\\nLu Duan, Yang Zhan, Haoyuan Hu, Yu Gong, Jiangwen Wei, Xiaodong Zhang, and Yinghui Xu. Efficiently solving the practical vehicle routing problem. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, jul 2020. doi: 10.1145/3394486.3403356.\\n\\nLei Gao, Mingxiang Chen, Qichang Chen, Ganzhong Luo, Nuoyi Zhu, and Zhixin Liu. Learn to design the heuristics for vehicle routing problem. arXiv preprint arXiv:2002.08539, 2020.\\n\\nMaha Gmira, Michel Gendreau, Andrea Lodi, and Jean-Yves Potvin. Tabu search for the time-dependent vehicle routing problem with time windows on a road network. European Journal of Operational Research, 288(1):129\u2013140, jan 2021. doi: 10.1016/j.ejor.2020.05.041.\\n\\nFeng Guo, Dongqing Zhang, Yucheng Dong, and Zhaoxia Guo. Urban link travel speed dataset from a megacity road network. Scientific Data, 6(1), may 2019. doi: 10.1038/s41597-019-0060-3.\\n\\nTuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, and Sergey Levine. Latent space policies for hierarchical reinforcement learning. In International Conference on Machine Learning, pp. 1851\u20131860. PMLR, 2018.\\n\\nSepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735\u20131780, nov 1997. doi: 10.1162/neco.1997.9.8.1735.\\n\\nYixiao Huang, Lei Zhao, Tom Van Woensel, and Jean-Philippe Gross. Time-dependent vehicle routing problem with path flexibility. Transportation Research Part B: Methodological, 95:169\u2013195, jan 2017. doi: 10.1016/j.trb.2016.10.013.\\n\\nVincent Huart, Sylvain Perron, Gilles Caporossi, and Christophe Duhamel. A heuristic for the time-dependent vehicle routing problem with time windows. In Lecture Notes in Economics and Mathematical Systems, pp. 73\u201378. Springer International Publishing, 2016. doi: 10.1007/978-3-319-20430-7.\\n\\nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\\n\\nA. L. Kok, E. W. Hans, J. M. J. Schutten, and W. H. M. Zijm. A dynamic programming heuristic for vehicle routing with time-dependent travel times and required breaks. Flexible Services and Manufacturing Journal, 22(1-2):83\u2013108, jun 2010. doi: 10.1007/s10696-011-9077-4.\\n\\nA. L. Kok, E. W. Hans, J. M. J. Schutten, and W. H. M. Zijm. A dynamic programming heuristic for vehicle routing with time-dependent travel times and required breaks.\"}"}
{"id": "CdqsSPLNx-", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nWouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems! In International Conference on Learning Representations, 2018.\\n\\nGonzalo Lera-Romero, Juan J. Miranda Bront, and Francisco J. Soulignac. Linear edge costs and labeling algorithms: The case of the time-dependent vehicle routing problem with time windows. Networks, 76(1):24\u201353, mar 2020. doi: 10.1002/net.21937.\\n\\nHao Lu, Xingwen Zhang, and Shuang Yang. A learning-based iterative method for solving vehicle routing problems. In International Conference on Learning Representations, 2019.\\n\\nQiang Ma, Suwen Ge, Danyang He, Darshan Thaker, and Iddo Drori. Combinatorial optimization by graph pointer networks and hierarchical reinforcement learning. November 2019.\\n\\nChryssi Malandraki and Mark S. Daskin. Time dependent vehicle routing problems: Formulations, properties and heuristic algorithms. Transportation Science, 26(3):185\u2013200, aug 1992. doi: 10.1287/trsc.26.3.185.\\n\\nMohammadreza Nazari, Afshin Oroojlooy, Martin Tak\u00e1\u010d, and Lawrence V Snyder. Reinforcement learning for solving the vehicle routing problem. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 9861\u20139871, 2018.\\n\\nEmilio Parisotto, Francis Song, Jack Rae, Razvan Pascanu, Caglar Gulcehre, Siddhant Jayakumar, Max Jaderberg, Raphael Lopez Kaufman, Aidan Clark, Seb Noury, et al. Stabilizing transformers for reinforcement learning. In International Conference on Machine Learning, pp. 7487\u20137498. PMLR, 2020.\\n\\nNicolas Rincon-Garcia, Ben Waterson, Tom J. Cherrett, and Fernando Salazar-Arrieta. A metaheuristic for the time-dependent vehicle routing problem considering driving hours regulations \u2013 an application in city logistics. Transportation Research Part A: Policy and Practice, 137:429\u2013446, jul 2020. doi: 10.1016/j.tra.2018.10.033.\\n\\nRemy Spliet, Said Dabia, and Tom Van Woensel. The time window assignment vehicle routing problem with time-dependent travel times. Transportation Science, 52(2):261\u2013276, mar 2018. doi: 10.1287/trsc.2016.0705.\\n\\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pp. 3104\u20133112, 2014.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pp. 5998\u20136008, 2017.\\n\\nOriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 2, pp. 2692\u20132700, 2015.\\n\\nRonald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3):229\u2013256, 1992.\\n\\nDongqing Zhang, Stein W. Wallace, Zhaoxia Guo, Yucheng Dong, and Michal Kaut. On scenario construction for stochastic shortest path problems in real road networks. Transportation Research Part E: Logistics and Transportation Review, 152:102410, aug 2021. doi: 10.1016/j.tre.2021.102410.\"}"}
{"id": "CdqsSPLNx-", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nWe then obtain the context embedding $e_{\\\\text{context}}^t$ of a fleet by combining $e_{\\\\text{global}}^t$, $e_{\\\\text{fleet node}}^t$ and fleet state projection $e_{\\\\text{fleet proj}}^t$ together based on the same gate mechanism. $e_{\\\\text{fleet proj}}^t$ is determined by a linear projection of $I_{\\\\text{fleet}}^t$. $I_{\\\\text{fleet}}^t$ represented by the location, remaining capacity, and completion time of serving next customer of each vehicle in the fleet. Then, we use $e_{\\\\text{context}}^t$ and $e_{\\\\text{node}}^t$ as the input of a Mask MHA layer to obtain the fleet state representation $e_{\\\\text{fleet}}^t$ and the current vehicle embedding $e_{\\\\text{cur veh}}^t$. During each encoding-decoding procedure, the vehicle that completes its current customer service first is chosen as the current vehicle for which its next customer to visit is determined in this decoding. \u201cMask\u201d in \u201cMask MHA\u201d refers to forcing the attention value of customers who cannot be served to 0 (i.e. the customers that have been served and the customers whose demand exceeds the vehicle capacity). Next through an MHA layer, the \u201cVehicle State Representation\u201d block gathers all vehicles\u2019 state representations in $e_{\\\\text{fleet}}^t$ on the current vehicle, so as to get a context embedding $e_{\\\\text{context}}^t$. Given $e_{\\\\text{node}}^t$ and $e_{\\\\text{context}}^t$, the attention value for each node is then computed by a Mask Attention layer in the \u201cCompatibility\u201d block, and the next node $\\\\pi_k^t$ to visit for vehicle $k$ and a binary vector $n_{\\\\text{served}}^t$ are determined finally.\\n\\n3.2 Dimension-Reducing MHA Layer\\n\\nIn previous studies (Kool et al., 2018; Nazari et al., 2018; Bono et al., 2020), DRL-based model inputs have three dimensions, including problem instance, node, and feature. Let $d_1$, $d_2$, and $d_3$ denote their dimension sizes, respectively. $d_1$ is the number of problem instances (i.e., batch size) inputted in each iteration in model inference. $d_2$ is equal to $N + 1$ since we consider the depot and $N$ customer nodes. $d_3$ is equal to 3 since each node is characterized by 3 feature values consisting of two coordinates and one demand value (i.e, a $1 \\\\times 3$ vector). To handle TDVRPs in real road networks, one of our contribution in methodology is to add time-varying travel times as new features in the model inputs, which extends the feature dimension to a $(N + 1) \\\\times 4$ vector, and thus leads to a 4-dimensional network input and much larger memory use and computational complexity.\\n\\nTo reduce memory use and improve computational efficiency, we propose a dimension-reducing MHA (DR-MHA) layer to extract the information of node location, node demand, and travel time between nodes simultaneously, and convert the 4-dimensional inputs into 3-dimensional embeddings. Specifically, using $I_{\\\\text{mask proj}}^t$ as inputs, the DR-MHA generates three $d_1 \\\\times (N + 1) \\\\times (N + 1) \\\\times d_k$ tensors, including the query $Q$, the key $K$, and the value $V$. Let $A^T(x,y)$ denote the transpose of the $x$th dimension and $y$th dimension of multidimensional array $A$, and $A^T(x,y) & T(x',y')$ denotes that the transpose $A^T(x,y)$ and $A^T(x',y')$ are performed on tensor $A$ in turn. We then compute the single-head function by the equation below,\\n\\n$$\\\\text{Attention}(Q, K, V) = \\\\frac{\\\\text{softmax} \\\\left( \\\\text{diagnoal}(QK^T(2,3) & T(3,4)) \\\\sqrt{d_k} \\\\right)}{V^T(2,3)(2)}$$\\n\\nwhere $\\\\text{diagnoal}(\\\\cdot)$ is a function of getting the value of the diagonal of the matrix. If the dimension of $QK^T(2,3) & T(3,4)$ is $d_1 \\\\times (N + 1) \\\\times d_k \\\\times d_k$, and $\\\\text{diagnoal}(QK^T(2,3) & T(3,4))$ means to get a tensor with dimension $d_1 \\\\times (N + 1) \\\\times d_k$.\\n\\nNext, to attend jointly information from different sub-networks at different nodes, we compute the multi-head function by the equation below according to the method in Vaswani et al. (2017),\\n\\n$$\\\\text{MultiHead}(Q, K, V) = \\\\text{Contact}(\\\\text{head}_1, ..., \\\\text{head}_h) W_O$$\\n\\nwhere $\\\\text{head}_i = \\\\text{Attention}(QW_Q^i, KW_K^i, VW_V^i)$ (3)\\n\\nwhere $W_Q^i \\\\in \\\\mathbb{R}^{d_h \\\\times d_k}$, $W_K^i \\\\in \\\\mathbb{R}^{d_h \\\\times d_k}$, $W_V^i \\\\in \\\\mathbb{R}^{d_h \\\\times d_v}$ and $W_O \\\\in \\\\mathbb{R}^{hd_h \\\\times d_v}$ the are parameter matrices of linear projections. This paper sets $h = 8$, $d_h = 128$, and $d_k = d_v = d_h / h = 16$.\\n\\n3.3 Synchronous Encoder\\n\\nThe node encoder with DR-MHA layer can only obtain the node embeddings with the information of node location, node demand and travel time between nodes in a given time step $t$, and cannot obtain time-varying travel time information. We develop a dynamic encoding method, called as synchronous encoder, to represent time-varying travel times in real road network, which is synchronized with its corresponding decoding process (i.e., encoding once, decoding once).\"}"}
{"id": "CdqsSPLNx-", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Previous DRL-based VRP studies masked served customers only in decoding by setting the probability of selecting served customers to 0. Intuitively, served customers should be irrelevant to further node-selection decisions, and the embedding information of served customer nodes contained in $e_{node_t}$ could have negative effects on $e_{curr_veh_t}$ since $e_{curr_veh_t}$ is highly related to $e_{node_t}$. The model performance could be improved if the served customer are not considered in further encoding and decoding. Thus, we mask the served customers further before decoding by the following equation.\\n\\n$$I_{mask_proj_t} = I_{proj_t} \\\\odot n_{served_t}(4)$$\\n\\nwhere $n_{served_t}$ is a binary vector in which each element represents a customer node. The element value is set to 0 if the corresponding node has been served, otherwise it is set to 1. $\\\\odot$ means element-by-element multiplication.\\n\\n3.4 GATE MECHANISMS\\n\\nWe use a gate mechanism proposed in Parisotto et al. (2020) to obtain effectively the global graph embedding $e_{global_graph_t}$ of the whole road network and the context embedding $e_{fleet_context_t}$ of a fleet at time step $t$. The gate mechanism is implemented by the formula below.\\n\\n$$r_t = \\\\sigma(W_r e_2^t + U_r e_1^t) (5)$$\\n$$z_t = \\\\sigma(W_z e_2^t + U_z e_1^t - b_g) (6)$$\\n$$h_t = \\\\tanh(W_g e_2^t + U_g (r_t \\\\odot e_1^t)) (7)$$\\n$$g(e_1^t, e_2^t) = (1 - z_t) \\\\odot e_1^t + z_t \\\\odot h_t (8)$$\\n\\nwhere $W_r, W_z, W_g, U_r, U_z$ and $U_g$ are parameter matrices of linear projections, $b_g = 0$. $\\\\sigma(\\\\cdot)$ is the Sigmoid function. We calculate $e_{global_graph_t}$ by setting $e_1^t$ to $e_{avg_graph_t}$ and $e_2^t$ to $e_{max_graph_t}$. To calculate $e_{fleet_context_t}$, we set $e_1^t$ to $e_{global_graph_t}$ and $e_2^t$ to $\\\\text{Concat}(e_{fleet_node_t}, e_{fleet_proj_t})$.\\n\\n3.5 MODEL EXTENSION FOR TDVRP WITH TIME WINDOWS\\n\\nThe model described above is designed for the TDVRP without customer time windows. It can be easily extended to handle the TDVRP with time windows (TDVRP-TW). Let $t_{win_i}$ denote the desired time window of serving customer node $i$. We have $t_{win_i} = [a_i, b_i]$, where $a_i$ and $b_i$ represent the lower bound and the upper bound of the expected arrival time at node $i$. Our TDVRP-TW considers soft time windows. That is, if the actual arrival time of a vehicle arriving node $i$ is less than $a_i$ or greater than $b_i$, an earliness or tardiness penalty occurs. Setting sufficiently large earliness and tardiness penalty rates is equivalent to considering hard time windows.\\n\\nCompared with the model for TDVRP without time windows, the model made two changes to adapt the TDVRP-TW. First, the input $I_t$ of DDAM-GM consists of node coordinates $x_{h_i}, x_{v_i}$, demand $x_d_i$, travel time $T_{i,j,t}$ from node $i$ to node $j$ at time step $t$, and time window $t_{win_i}$ of each node $i$ ($i \\\\in \\\\{V, 0\\\\}$). That is, we have $f_{i,j,t} = (x_{h_i}, x_{v_i}, x_d_i, T_{i,j,t}, a_i, b_i)$ and have $I_t = \\\\{f_{i,j,t}\\\\}_{B \\\\times (N+1) \\\\times (N+1)}$.\\n\\nSecond, the model does not mask the served nodes in encoding because our experiments show that masking served nodes in encoding will reduce the optimum-seeking performance for TDVRP-TW.\\n\\n3.6 MODEL TRAINING\\n\\nOur DDAM-GM is trained by policy gradient using REINFORCE algorithm (Williams, 1992). The objective $L(\\\\theta | s)$ is the expected loss, which can be estimated with respect to the parameters $\\\\theta$.\\n\\n$$\\\\nabla L(\\\\theta | s) = E_{p_{\\\\theta}(\\\\pi | s)}[ (L(\\\\pi | s) - b(s)) \\\\nabla \\\\log p_{\\\\theta}(\\\\pi | s)] (9)$$\\n\\nwhere $L(\\\\pi | s)$ is the objective value to be minimized of solution $\\\\pi$, $b(s)$ is a baseline to reduce variance. We adopt either critic network or rollout randomly as baseline $b(s)$. The critic network $\\\\phi$, shares the parameters of DDAM-GM and connects two fully connected layers behind the decoder of DDAM-GM to output the estimated expected objective value. Rollout is similar to the baseline with the best performance in Kool et al. (2018).\"}"}
{"id": "CdqsSPLNx-", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In training, we use the Monte Carlo sampling to approximate the gradients of parameters $\\\\theta$ as:\\n\\n$$\\\\nabla L(\\\\theta) \\\\approx \\\\frac{1}{B} \\\\sum_{i=1}^{B} \\\\left[ (L(\\\\pi_{s_i} | s_i) - b(s_i)) \\\\nabla \\\\log p_{\\\\theta}(\\\\pi_{s_i} | s_i) \\\\right] \\\\quad (10)$$\\n\\nwhere $B$ is the batch size, $\\\\pi_{s_i}$ is the solution constructed by sample rollout to instance $s_i$. For rollout baseline, $b(s_i) = L(\\\\pi_{g_i} | s_i)$, where $\\\\pi_{g_i}$ is the solution constructed by greedy rollout to instance $s_i$.\\n\\nFor critic network $\\\\phi$, $b(s_i)$ is the output value obtained by taking instance $s_i$ as the input of $\\\\phi$. We use the Adam optimizer (Kingma & Ba, 2014) to update the model\u2019s parameters.\\n\\n4 EXPERIMENTS\\n\\nOur models are programed with Pytorch, and executed on a server with Intel Xeon Platinum 8260 CPU and NVIDIA RTX3090 GPU. Our code of the DDAM-GM will be made available on github.\\n\\n4.1 EXPERIMENTAL SETTING\\n\\n4.1.1 GENERATION OF INSTANCE SETS\\n\\nThe experiments are conducted on the basis of a real urban road network and a time-varying travel speed dataset from a megacity in China, Chengdu. For TDVRPs either with or without time windows, we train and test our DDAM-GM model based on 3 different problem instance sets with 10, 20, and 50 customers respectively. The objective of our TDVRP without time windows is to minimize the total travel time (minutes) while the objective of our TDVRP with time windows is to minimize the sum of the total travel time, the total earliness and tardiness penalty, and the penalty of unserved customers. The unit earliness and tardiness penalties are set to 1 and 30 per minute respectively, and the unit penalty of unserved customers is set to 30.\\n\\nThe road network contains 408 nodes and 1250 directed edges within the first ring road in the network presented in Zhang et al. (2021). Using the method in Guo et al. (2019), we obtain a 110-day travel speed dataset based on the raw GPS trajectory data of floating taxis within the first-ring road from June 1 to September 17, 2017. In each day, we consider 240 consecutive 2-minute time periods from 8am to 16pm. For an instance set with a certain $N$, we select randomly a depot and $N$ customer nodes from the 408 road nodes, the coordinates of which are represented in the Universal Transverse Mercator Grid System. Customer demands are sampled randomly between 1 and 9. In all TDVRP instances, we calculate the objective function values by using the travel speed dataset of the 110th day. For a road link directly connected in the road network in a time period, we use the median of its all historical travel speeds during the first 100 days to represent its historical travel speed. Then we obtain the shortest travel time $T_{i,j,p}$ between any two nodes from the depot and the $N$ customer nodes in each time period $p$ based on the method in Huang et al. (2017). Hence, we have a total of $240(N + 1)(N + 1)$ matrices consisting of shortest travel times. Together with node coordinates and demands, these matrices are contained in the input $I_t$ of the DDAM-GM in time step $t$. The current time period $p$ is determined by the time of the current vehicle completing its current customer service at time step $t$.\\n\\nBased on the Chengdu road network, we generate the time windows of customers in each instance according to the rules in Bono et al. (2020). The full time horizon is [0, 480] since we consider 8 hours from 8am to 16pm. The lower and upper bounds of time windows are sampled uniformly from [10, 30] and [60, 90] respectively. We set the vehicle capacity to 30 in all problem instances.\\n\\n4.1.2 HYPERPARAMETERS\\n\\nOur DDAM-GM has the same hyperparameter settings as MARDAM. The node embedding dimension is 128. The encoder consists of a \u201cDR-Trans\u201d block and two \u201cTrans\u201d block. The decoder consists of two MHAs with eight attention heads followed by a single-head attention layer. The tanh clip is applied with $C = 10$.\\n\\nWe train the models for 100 epochs. For each epoch, we generate 1,280,000 instances on the fly and train with batch size of 512 (except for TDVRP and TDVRP-TW with 50 customers, where we...\"}"}
{"id": "CdqsSPLNx-", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"generate 160,000 instances and train with batch size of 64). We use the Adam optimizer and set the learning rate as $10^{-4}$ without decay. We generated 10,240 validation instances to judge whether the current model has improved compared with the previous model after training 100 batches. If there is any improvement, save the model. We sample 10,000 instances from the same distributions used for training and validation to evaluate model.\\n\\n4.1.3 Algorithms and Models for Comparison\\n\\nThe investigated TDVRPs consider time-varying travel time in a real urban road network, which leads to 240 time periods. Existing methods in the vehicle routing area have not considered so many time periods and cannot tackle our TDVRPs well. We compare the performances of the following models, in which the last two are our DDAM-GM with different decoding strategies.\\n\\n1) Greedy algorithm (GRA): The nearest and unvisited node is selected as the next node to visit.\\n2) AM (g): AM (Kool et al., 2018) with greedy decoding strategy.\\n3) AM-I (g): A DRL model integrating AM (g) with the three improvements described in sections 3.2-3.4.\\n4) MARDAM (g): MARDAM (Bono et al., 2020) with greedy decoding strategy.\\n5) MARDAM (s): MARDAM (Bono et al., 2020) with sampling decoding strategy.\\n6) DDAM-GM (g): Our DDAM-GM with greedy decoding strategy.\\n7) DDAM-GM (s): Our DDAM-GM with sampling decoding strategy.\\n\\nThe greedy decoding strategy indicates that the model selects the node with the largest probability calculated in \u201cCompatibility\u201d block each time step in decoding. The sampling decoding strategy indicates that the model uses a largest probability to select the node with the largest probability calculated in \u201cCompatibility\u201d block each time step in decoding. Moreover, in our sampling decoding, we randomly generate 1280 solutions for each instance, and select the solution with the smallest objective value as the final solution to this instance.\\n\\n4.1.4 Evaluation\\n\\nWe measure the performance $\\\\zeta$ of each model by the percentage change of its objective value relative to the objective value generated by the AM(g)), which is formulated as follows,\\n\\n$$\\\\zeta = \\\\frac{V - V_{AM(g)}}{V_{AM(g)}} \\\\times 100\\\\%$$\\n\\n4.2 Results and Discussion\\n\\nTable 1 shows the performance comparison of our DDAM-GM model and 5 baselines. We report the mean of objective function values of all test instances. Each model is trained and tested on problem instances with the same number of customer nodes. We have not presented the results of AM-I for the TDVRP-TW instance with $N=50$ because (1) the performances of AM-I are worse than the DDAM-GM\u2019s at $N=10$ and $N=20$, and (2) the training of AM-I is very time-consuming (approximately more than 10 days in the server we used) at $N=50$.\\n\\nIt can be found from Table 1 that,\\n\\n1) For both TDVRPs with and without time windows, two models (i.e., AM-I and DDAM-GM) with our three improvements are clearly superior over the corresponding original models (i.e., AM and MARDAM) by reducing the objective value by 0.41% to 6.28%. That is, our three improvements on DRL models are helpful to improve DRL models\u2019 performances on TDVRPs.\\n\\n2) For TDVRPs without time windows, both DDAM-GM and the MARDAM are inferior to the AM and AM-I, which is similar to the results in Bono et al. (2020) where the AM outperformed the MARDAM in a CVRP. It indicates that it is not important for TDVRPs without time windows to construct multiple vehicle routes simultaneously.\\n\\n3) For TDVRP-TWs, our DDAM-GM outperforms AM, AM-I and MARDAM largely. Its performance superiority increases with the number of customer nodes, which ranges from 0.41% to 20.57%. It indicates that constructing multiple vehicle routes simultaneously is helpful for TDVRP-TWs to improve the solution performance.\\n\\n4) The greedy algorithm performs the worst, for the 6 test instance sets, the performances of the GRA are 10.96%-23.17% worse than those of the AM (g).\"}"}
