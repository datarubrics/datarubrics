{"id": "czmQDWhGwd9", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u2022 Bytecode ops. We execute the programs and count the number of bytecode operations performed. This metric should mimic the number of mental operations performed needed to compute the output of a program.\\n\\n\u2022 Cyclomatic complexity. This metric (McCabe, 1976) is used to measure the general complexity of software systems. It is defined as a function of the number of nodes, edges, and the connected components in a program\u2019s control flow graph. While its efficacy as a metric to measure software complexity has been contested (Shepperd, 1988), we include it to see if brain activity is correlated to any explicit syntactic constructs of a program.\\n\\n\u2022 Halstead difficulty. This metric (Halstead, 1977) was defined to measure how difficult any piece of software would be for a programmer to comprehend or write. It is defined as a function of the number of tokens, operations, vocabulary that appears in a program.\\n\\nThe inter-correlations between these metrics have been tabulated in Table 18, Appendix G.\\n\\nCode models - Model details. We evaluate the following models in this work\u2013\\n\\n\u2022 bag-of-words, TF-IDF. These are count-based language models. They predict the likelihood of a token appearing in a program based on vocabulary statistics and frequencies.\\n\\n\u2022 seq2seq (Sutskever et al., 2014), CodeTransformer (Z\u00fcgner et al., 2021), CodeBERTa (HuggingFace, 2020). We evaluate these three autoencoder (AE) models with increasing model complexity. AE based pretraining reconstructs the original program from corrupted input.\\n\\n\u2022 XLNet (Yang et al., 2019). We evaluate an auto-regressive (AR) model with a model complexity similar to that of transformers and CodeBERTa. AR language modeling estimates the probability distribution of a text corpus in one direction\u2013either forward or backward, while AE models capture dependencies in both directions. We use an AR model to mimic a top-down, single pass comprehension style by humans.\\n\\n\u2022 Random embedding. We compare the results of the above models against an aggressive baseline provided by using unique Gaussian-distributed random vectors for the token embeddings in a vocabulary, and returning the sum of these token embeddings across a program. The resultant embedding is not transformed by any model or any weights\u2014it instead serves as a proxy for the tokens that appear in the program. This sets a higher bar than the null-distribution labeling baseline (Section 5.2).\\n\\nCode models - Configuration details. In setting up our code model bench, we aimed to select a collection of models ranging in their complexity, namely bag-of-words, TF-IDF, seq2seq, XLNet, CodeTransformer, and CodeBERTa, as well as a Random embedding embedding model.\\n\\n\u2022 The bag-of-words, TF-IDF, seq2seq, and Random embedding models all use the same custom tokenizer defined by the current authors, whereas XLNet, CodeTransformer, and CodeBERTa use tokenizers defined by the original training authors (Z\u00fcgner et al., 2021; HuggingFace, 2020).\\n\\n\u2022 The tokenizer set up for the models trained by the current authors establishes a unique token in the vocabulary for each Python keyword, each Python builtin function, one token for all numeric types, one token for all string types, and N tokens for each of the N variables in a given program.\\n\\n\u2022 In the case of the Random embedding baseline, this tokenizer was used to map each token in a piece of source code to an index in the vocabulary, which in turn was used to index a Gaussian distributed random matrix (D = 128). The sum of these random token projections was calculated to return a unique embedding for each program.\\n\\n\u2022 For bag-of-words and TF-IDF, the validation split of the code-search-net Python dataset (Husain et al., 2019) was used to enumerate vocabulary and token occurrence statistics. These data were then used to transform each program to a vector where each dimension represented the raw (bag-of-words) or document-weighted (TF-IDF) count of the unique items in the vocabulary.\\n\\n\u2022 If a given set of programs viewed by a subject never included a specific token, leading that column to equal the zero vector, then those dimensions would be filtered out.\"}"}
{"id": "czmQDWhGwd9", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\n\u2022 We used the dataset released by Project Codenet (Puri et al., 2021) to pretrain a seq2seq model (Sutskever et al., 2014). The dataset contains Python programs that are solutions to olympiad-style programming problems in data structures and algorithms. We trained a seq2seq model with a GRU unit for 15 epochs, with a dropout probability of 0.2, dot product attention, and a maximum sentence length of 500.\\n\\n\u2022 For XLNet, CodeTransformer, and CodeBERTa, each program was passed through that model's tokenizer and model pipeline as defined by the original authors. The representations of each program were extracted from the pretrained encoders. XLNet and CodeTransformer were originally trained on the Python subset of the code-search-net dataset, whereas CodeBERTa was originally trained on the full code-search-net dataset, which also incorporates go, java, javascript, php, and ruby.\"}"}
{"id": "czmQDWhGwd9", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Using representations from localized brain regions, we attempt to decode static and dynamic properties of comprehended code, and learn maps to code model representations of that same code. We report decoding performance of each brain region to the original Ivanova et al. (2020) code properties in Table 1, the complexity-related code properties in Table 2, and the code model mappings in Table 3. We find that the MD system and the Language system decode all code properties and code models except variable language significantly above baseline, as established through a null permutation test. The Visual system decodes 4 of the 6 code properties and 6 of the 7 code models, whereas the Auditory system only decodes the code vs sentences property.\\n\\n| Brain Representation | MD | Language | Visual | Auditory |\\n|---------------------|----|----------|--------|----------|\\n| **Code Properties** |    |          |        |          |\\n| Empirical Baseline  |    |          |        |          |\\n| Code vs. Sentence   | 0.55 | 0.88 (+0.33) | 0.87 (+0.32) | 0.88 (+0.33) |\\n| Control Flow        | 0.33 | 0.49 (+0.16) | 0.45 (+0.12) | 0.39 (+0.06) |\\n| Data Type           | 0.49 | 0.63 (+0.14) | 0.58 (+0.09) | 0.61 (+0.12) |\\n| Variable Language   | 0.50 | 0.53 (+0.03) | 0.51 (+0.01) | 0.53 (+0.03) |\\n\\nTable 1: Brain region decoding performance on original Ivanova et al. (2020) code properties. Scores represent classification accuracy and are contrasted with an empirical baseline from the null permutation analysis. Values in parentheses are units above baseline.\\n\\n| Brain Representation | MD | Language | Visual | Auditory |\\n|---------------------|----|----------|--------|----------|\\n| **Code Properties** |    |          |        |          |\\n| Static Analysis     | 0.17 | 0.24 | 0.09 | 0.00 |\\n| Dynamic Analysis    | 0.33 | 0.20 | 0.17 | 0.12 |\\n\\nTable 2: Brain region decoding performance on static analysis and dynamic analysis code properties. Scores represent Pearson correlation between predicted and true code properties.\"}"}
{"id": "czmQDWhGwd9", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We additionally evaluate whether code models contain linearly decodable information about the code properties we explore in this work (Section 4.2). The models decode with near perfect accuracy on most classification tasks (avg. accuracy $= 0.96 \\\\pm 0.01$), and with high correlations on the regression tasks (avg. $r = 0.89 \\\\pm 0.02$). This is expected for the classification tasks, since the dataset contains tokens which help with perfectly separable decision boundaries. For example, for the control flow code property, the dataset contains programs with if, for, or neither, but never both. These results suggest that the code models we evaluate faithfully encode the set of properties we evaluate them on.\\n\\n### Table 3: Brain region decoding performance on code model mappings. Scores represent rank accuracy and are contrasted with an empirical baseline from the null permutation analysis. Values in parentheses are units above baseline.\\n\\n| Code Models          | Control Flow | Dynamic Analysis | Static Analysis |\\n|----------------------|--------------|------------------|-----------------|\\n| Empirical Baseline   | 0.31         | 0.48             | 0.00            |\\n| Random Embedding     | 1.00         | 0.94             | 0.88            |\\n| Bag Of Words         | 1.00         | 0.92             | 0.93            |\\n| TF-IDF               | 1.00         | 0.94             | 0.94            |\\n| Seq2Seq              | 0.95         | 0.97             | 0.87            |\\n| XLNet                | 0.92         | 0.92             | 0.76            |\\n| CodeTransformer      | 1.00         | 0.95             | 0.90            |\\n| CodeBERTa            | 0.96         | 0.98             | 0.81            |\\n\\n### Table 4: Decoding performance of all models on all tasks. Scores represent classification accuracy for control flow and data type, and Pearson correlation for the remaining benchmarks. These can be contrasted with an empirical baseline from the null permutation analysis.\\n\\n| Code Models          | Control Flow | Data Type         | Dynamic Analysis | Static Analysis |\\n|----------------------|--------------|-------------------|------------------|-----------------|\\n| Empirical Baseline   | 0.31         | 0.48              | 0.00             | 0.00            |\\n| Random Embedding     | 1.00         | 0.94              | 0.88             | 1.00            |\\n| Bag Of Words         | 1.00         | 0.92              | 0.93             | 0.98            |\\n| TF-IDF               | 1.00         | 0.94              | 0.94             | 0.89            |\\n| Seq2Seq              | 0.95         | 0.97              | 0.87             | 0.91            |\\n| XLNet                | 0.92         | 0.92              | 0.76             | 0.88            |\\n| CodeTransformer      | 1.00         | 0.95              | 0.90             | 0.91            |\\n| CodeBERTa            | 0.96         | 0.98              | 0.81             | 0.79            |\"}"}
{"id": "czmQDWhGwd9", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nwould experience when comprehending code respectively. We defer predicting other advanced static analysis metrics such as tracking abstract interpretation joins, data flow analysis-related metrics, etc.\\n\\n\u2022 Dynamic analysis.\\n\\nWe decode information about a code's execution behavior. We evaluate two properties\u2013runtime steps (number of instructions executed in the program) and bytecode ops (number of bytecode operations executed in running the program). We expect these properties to be correlated with the number of mental instructions needed to arrive at the output.\\n\\nProgram length as a potential confound.\\n\\nProgram length is a potential confound in our experiments because the properties we examine can also potentially be differentiated using program length and other low-level code features. We measured the inter-correlations of these properties, and their correlation to the number of tokens in the program (program length) (see Appendix G). We expectedly found the four static analysis properties to be highly correlated to each other and to bytecode ops. We hence use one representative metric each from the two categories of properties for the rest of our analysis\u2013token count for static analysis, and runtime steps for dynamic analysis. Importantly, the other properties we examine cannot be explained by program length alone, and therefore program length is not a confound in our experiments.\\n\\nThe brain representations (Section 4.1) are mapped to each of the code properties by training a ridge regression or classification model each for every participant-property pair. To evaluate model performance, we use classification accuracy when the predicted values are categorical (e.g. string vs. numeric data types), and the Pearson correlation coefficient when the predicted values are continuous (e.g. number of runtime steps). We choose Pearson correlation over RMSE, the canonical distance metric for continuous values, for its simplicity and interpretability. See Appendix I for the RMSE results, which are similar to the correlation results. When testing for the significance of these predictions, we perform false discovery rate (FDR) correction for the number of brain systems tested and the number of properties tested. See Appendix B for a detailed description of model hyper-parameters and cross-validation settings employed.\\n\\n4.3 Model representations and decoding.\\n\\nWe evaluate a bench of unsupervised language models, spanning from count-based language models to transformer neural networks (Vaswani et al., 2017). These models were all trained on large (\u223c1M programs) Python datasets (Husain et al., 2019; Puri et al., 2021). We use the output of the trained encoders (raw logits) in each of the neural network models as representations of the code input to the model. We vary the general complexity of these models to test whether that variation is meaningful in establishing the quality of brain to model fits. Model complexity here is the number of a model's learnable parameters. We evaluate the following models, ordered by their increasing model complexity: simple frequency-based language models\u2014bag-of-words, TF-IDF; auto-encoder based unsupervised models\u2014seq2seq (Sutskever et al., 2014), CodeTransformer (Z\u00fcgner et al., 2021), CodeBERTa (HuggingFace, 2020); auto-regressive model with a model complexity similar to that of transformers and CodeBERTa\u2014XLNet (Yang et al., 2019).\\n\\nWe compare the results of the above models against an aggressive baseline (relative to the null-distribution labeling baseline), a token projection model provided by using unique Gaussian-distributed random vectors for the token embeddings in a vocabulary, and returning the sum of these token embeddings across a program. The resultant embedding is not transformed by any model or any weights\u2014it instead serves as a proxy for the tokens that appear in the program. The results of this baseline model should be interpreted as the level of performance achievable from the presence of tokens alone with no structural information.\\n\\nThe brain representations (Section 4.1) are mapped to code representations by training another set of ridge regression models to learn an affine map, and a ranked accuracy metric is used to compare outputs. Ranked accuracy scores are commonly used in information retrieval where several elements in a range are similar to the correct one. In our case, the top-ranked prediction by the linear model indicates the closest fit (Euclidean distance) to the code model's representation. When reporting result significance, we perform false discovery rate (FDR) correction for the number of brain systems and the number of models. See Appendix B for a detailed discussion of the implemented code models and the corresponding metrics.\\n\\n5 Experiments & Results\\n\\nOur experiments address two research questions:\\n\\n\u2022 Experiment 1. How well do the different brain systems encode specific code properties?\\n\\n\u2022 Experiment 2. How do the brain representations of code correspond to the representations learned by computational language models of code?\"}"}
{"id": "czmQDWhGwd9", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 3: In Experiment 1, a linear model is trained on brain representations to predict each of the code properties described in Section 4.2. Error bars represent 95% confidence interval of individual subject scores. Dotted lines signify the empirical baseline for a null permutation distribution on shuffled labels. All results were compared to this permuted null distribution, and p-values for the number of comparisons in this experiment were corrected for false discovery rates (FDR). Statistically significant results are denoted with a $^*$.\\n\\n### 5.1 Experiment 1 - How well do the different brain systems encode specific code properties?\\n\\nHere, we analyze the classification models and regressions trained on brain representations to predict each of the code properties described in Section 4.2. The results of our analyses are summarized in Figure 3. The classification and regression tests are marked on the x-axis of the left and right subplots respectively; the classification accuracy or Pearson correlation for each of the tasks is marked on the y-axes. We plot dynamic and static properties separately from the others because their baselines are different due to a difference in the similarity metric (classification accuracy vs. Pearson correlation). The baselines for the categorical code properties differ from each other due to variation in the number of target classes.\\n\\n**Auditory and Visual systems.**\\n\\nThe Auditory system serves as a negative control for the other systems. Given that the code comprehension task we use is visual, we do not expect to decode any meaningful information from it. We find that, out of 6 tested properties, only code vs sentences can be decoded from the Auditory system, and even then the decoding performance is much lower than in other systems. The Visual system also serves as a control for low-level visual properties of the code (as opposed to abstract semantic or syntactic features). Given the visual attributes of a program such as the layout and indentation of the code, the length of the program, and the presence of letters and alphabets in the programs (Park et al., 2012; Roux et al., 2008; Polk et al., 2002), this system might reflect at least some of the properties we evaluate. This is indeed what we observe: 4 out of 6 tested properties can be decoded from the visual system above-chance. The MD and the Language systems yield the following specific observations. In a follow-up analysis (Analysis 3), we investigate the extent to which the MD and the Language systems represent decodable information beyond that which is represented in the Visual system.\\n\\n**Analysis 1 - How accurately are different properties predicted by MD and LS?**\\n\\nWe analyze how accurately each of MD and LS predict all the properties we evaluate.\\n\\n- **Code vs. sentences**\\n  - Code and sentence properties are decoded most accurately among all the properties we test. The MD, LS, and VS decode with $\\\\sim 90\\\\%$ accuracy. The high accuracy from MD validates claims from previous works suggesting the involvement of these regions in code comprehension.\\n\\n- **Variable language**\\n  - This requires distinguishing between sets of nearly identical programs, with the only variation being in the language of the variable names (English vs. Japanese). We hence expect the Language system will most accurately encode this information, since it is sensitive to the presence of new words. However, no such effect is observed\u2013no brain system shows any significant decoding. This unexpected finding is however consistent with Ivanova et al. (2020), who show a lack of any significant difference in the aggregate neural activity between the two variations. Both suggest that these brain systems do not seem to rely on variable names as a meaningful feature.\\n\\n- **Control flow and data type**\\n  - Both control flow and data type tasks are most accurately predicted by the MD, followed by the LS. In the case of control flow, the more accurate predictions by the MD and\"}"}
{"id": "czmQDWhGwd9", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Experiment 2 - How do the brain representations of code correspond to the representations learned by computational language models of code?\\n\\nHere, we train ridge regression models with brain representations of programs from a specific brain system to predict code model representations of the same programs. The full set of results from this experiment are summarized in Figure 4.\\n\\nAuditory and Visual systems. Similar to Experiment 1, the Auditory system performs as expected, exhibiting the lowest decoding performance across all code models. The VS exhibits the second\"}"}
{"id": "czmQDWhGwd9", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Analysis 1 - How well do brain representations in MD and LS map to code model representations?\\n\\nTo ease our analysis of the MD and LS systems, we re-plot in Figure 5 the decoding accuracies of just these two brain systems from Figure 4. We find that the MD system and Language system map to all the models in our suite significantly more accurately than the null permutation baseline (baseline accuracy of 50% in Figures 4 and 5). Further, from Figure 5, we see the MD maps more accurately than the LS across all code models. We test the significance of the differences between the two systems and find that the MD ranked accuracy is higher than LS for CodeBERTa, seq2seq, and TF-IDF, while the differences are not significant for the other models (Table 10, Appendix E). We discuss the implication of these results in Section 6.\\n\\nAnalysis 2 - The effect of model complexity on decoding to code models.\\n\\nWe investigate the impact model complexity has on the performance of the mapping between brain and code representations. Model complexity here is the number of a model's learnable parameters. In analysis 1 above, we saw that the MD system mapped to the representations of CodeBERTa, seq2seq, and TF-IDF significantly more accurately than the Language system. These three models vary substantially in their complexity, thus suggesting the lack of any relationship between model complexity and brain systems.\\n\\nWe also compare each of these code models against the Random embedding model. This baseline model assigns a random vector of numbers to every unique token that appears in the vocabulary, and sums the vectors of all the tokens that appear in a program. By its design, this model encodes only the presence of specific tokens in programs. The mapping accuracies of random embeddings in the MD and the Language systems are marked in blue and green horizontal lines in Figure 5. We find that the Multiple Demand system maps to all the models more accurately than the Random embedding. This is not seen in the LS, which confirms the lack of variability of ranked accuracies observed in the LS.\\n\\nIn a set of pairwise significance tests, we find that the MD maps to CodeBERTa significantly more accurately than Random embedding while other systems are more accurate numerically, but not significantly (Table 11, Appendix E). We discuss its implications in the following section.\\n\\n6 DISCUSSION\\n\\nThrough this study, we learn what computer program-related information can be decoded from the brain, and which brain systems primarily encode that information. In Experiment 1, we investigate whether a set of manually-selected code properties are encoded in different brain systems. In Experiment 2, by comparing brain representations to code model representations, we investigate if the brain encodes more than just the properties investigated in Experiment 1. Because the code models are trained on a much more expressive set of programs than the ones used in our Experiment 1, we also can learn what additional information these models learn about code.\\n\\nKey among our contributions is demonstrating that it is possible to predict a range of code properties from brain system activity (representations). Experiment 1 shows that control flow and data type information, two fundamental program properties, as well as dynamic analysis and static analysis properties of code, can be decoded with high performance from the MD and the Language systems. In several cases, this decoding performance reflects decoding from information beyond what can be predicted from low-level features of the programs encoded in the Visual system alone. This is a new finding which indicates that the MD and the Language systems encode higher-level program-related information. Future work should additionally experiment with a larger set of programs that have more complex properties across multiple programming languages.\\n\\nAnother key contribution of our work, from Experiment 2, is demonstrating that it is possible to map brain representations to representations learned by code models. Unlike many prior decoding works in cognitive neuroscience, which record multiple responses to each of their experimental stimuli (done generally to control for the noise present in fMRI data), our decoders are trained on individual trials. This demonstrates the feasibility of probing aspects of code comprehension in the brain without the need to present the same program multiple times to a participant.\"}"}
{"id": "czmQDWhGwd9", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We present the first study relating representations of computer programs generated by unsupervised machine learning (ML) models and representations of computer programs in the human brain. We analyze recordings\u2014brain representations\u2014from functional magnetic resonance imaging (fMRI) studies of people comprehending Python code. We discover brain representations, in different and specific regions of the brain, that encode static and dynamic properties of code such as abstract syntax tree (AST)-related information and runtime information. We also map brain representations to representations of a suite of ML models that vary in their complexity. We find that the Multiple Demand system, a system of brain regions previously shown to respond to code, contains information about multiple specific code properties, as well as machine learned representations of code. We make all the corresponding code, data, and analysis publicly available.\\n\\nINTRODUCTION\\n\\nA question of interest, as yet uninvestigated, is what aspects of computer programs, i.e. code, are encoded by the human brain when comprehending them. Is it possible that common code properties and the semantics of programs are encoded in brain activity patterns when code is comprehended? A few prior works have investigated the neural bases of programming (Siegmund et al., 2017; Floyd et al., 2017; Peitek et al., 2018; Castelhano et al., 2019; Huang et al., 2019; Krueger et al., 2020; Prat et al., 2020; Ivanova et al., 2020; Liu et al., 2020; Ikutani et al., 2021; Peitek et al., 2021). These works use analysis techniques like functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) to investigate brain regions involved in coding tasks like code comprehension, code writing, and data structure manipulation. The primary quest of these works though has been to locate physical regions in the brain involved in these activities, with the goal of determining whether code-related activity joins other activities supported by those brain regions. It remains unclear what specific code-related information these regions encode. Do these regions encode specific syntactic or semantic code properties? Further, are different regions involved in encoding different such properties? To date, no systematic method exists to generate the evidence from which to draw answers. These questions form the focus of this work.\\n\\nOne way to learn what information is encoded in the brain is by recording brain signals when reading code (through fMRI or EEG), and then decoding from the recorded signals a code property of interest. Being able to decode the property accurately from a specific region of the brain establishes that information related to that code property is faithfully represented in that brain region. A question central to such a decoding analysis would be the choice of the target code property\u2013what code properties should be investigated? We can hand-select a set of fundamental properties of code and test if they can be decoded. While helpful, such a set will not preclude other, more complex aspects of code being encoded.\\n\\nTo address the limitation of hand-selected properties, we look to recent advances in unsupervised machine learning (ML) models trained on code. Dubbed code models, they process large corpora of code to learn ML model representations of computer programs. These models are increasingly being used in software engineering workflows (Allamanis et al., 2018a), and have been shown to perform well on tasks like code summarization (Alon et al., 2019), detecting variable misuse (Bichsel et al., 2016), and more recently, code auto-completion (Chen et al., 2021). These continuous representations likely encode syntax and semantics of programs (Bichsel et al., 2016; Allamanis et al., 2018b; Srikant et al., 2021). Beyond the fundamental, hand-selected properties, they may encode and describe more complex code properties. Decoding these continuous representations from brain activity data then promises to inform us whether such additional properties are also encoded.\"}"}
{"id": "czmQDWhGwd9", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Comparison between representations from code models and the code-related information encoded in the brain also informs us whether code models resemble humans in the knowledge they learn and encode. Yamins et al. (2013) first showed how information encoded in our visual system resembles what convolutional neural networks learn when trained to recognize images. A similar correspondence can possibly be established between code models and the human brain.\\n\\nIn this work, we study code comprehension and utilize the fMRI recordings dataset from Ivanova et al. (2020) to investigate human brain representations of code. We present two means of proceeding\u2014probing of brain region representations for specific code properties, and analyzing the mapping of these representations onto various code models with differing model complexity. We learn affine maps from brain representations to predict hand-selected code properties which summarize the syntactic and semantic behavior of programs, and similarly predict code representations of different code models. We investigate the effects that brain regions, the nature of code properties, and the complexity of the code models have on the accuracies with which we decode brain representations. We find that we can decode code-related information from brain representations, and can map representations of code models from brain representations. We find the Multiple Demand system, followed by the Language system, to consistently encode specific code properties and map with machine learned representations of code. We provide an open-source framework to replicate our experiments, and we release our data and analysis publicly. Link - https://github.com/anonmyous-author/anonymous-code. The framework allows both brain data and program metrics to be easily added to extend the current set of experiments. This should enable authors from other neuroimaging studies or code model developers to collaborate and analyze data across these works, which will also help amortize the high costs of carrying out such experiments.\\n\\nOf the prior works that have investigated the neural bases of programming through fMRI and EEG techniques (Siegmund et al., 2017; Floyd et al., 2017; Peitek et al., 2018; Castelhano et al., 2019; Huang et al., 2019; Krueger et al., 2020; Ivanova et al., 2020; Liu et al., 2020; Ikutani et al., 2021; Peitek et al., 2021) and through behavioral studies (Prat et al., 2020; Casalnuovo et al., 2020; Critchton et al., 2021), the following probe brain recordings for program properties encoded in them. Floyd et al. (2017) learn a linear model to successfully classify whether an observed brain activity corresponds to reading code or reading text. Ikutani et al. (2021) study expert programmers and show that it is possible to classify code into the four problem categories\u2013math, search, sort, and string from the brain activations corresponding to the code. Similarly, Liu et al. (2020) classify whether a brain signal corresponds to code implementing an if condition or not. Peitek et al. (2021) analyze correlations between brain recordings of participants reading code and a set of code complexity metrics.\\n\\nIn testing for code properties, our work uses a similar methodology (a linear model trained on fMRI data), but we evaluate a larger set of static and dynamic code properties. We also systematically test whether key programming constructs like control flow and data operations are encoded by these brain representations. A systematic analysis of multiple such properties has not been performed in any of these works. Further, we perform these tests in those brain regions identified by Liu et al. (2020) and Ivanova et al. (2020) as being responsive specifically to code comprehension. This gives us a finer insight into how different regions encode these properties. In addition to these tests, we study representations generated by a suite of ML models with varying model complexity and compare those representations to brain representations.\\n\\nBrain representations have also been studied in domains like natural language, vision, and motor control. Among related works in natural language, a domain that resembles programming languages, Mitchell et al. (2008); Pallier et al. (2011); Brennan & Pylkk\u00e4nen (2017); Jain & Huth (2018); Gauthier & Levy (2019); Schwartz et al. (2019); Wang et al. (2020); Schrimpf et al. (2020); Cao et al. (2021) have studied brain representations of words and sentences by relating them to representations produced by language models. While the broader tools we use to investigate these representations, like multi-voxel pattern analysis (MVPA), are similar to some of these prior works, our focus is on properties specific to code and not natural language.\"}"}
{"id": "czmQDWhGwd9", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nMeasuring brain activity with fMRI.\\n\\nFunctional magnetic resonance imaging (fMRI) is a brain imaging technique used to measure brain activity in specific brain regions. When a brain region is active, blood flows into the region to aid its processing. An MRI machine measures this change in blood flow, and reports BOLD (blood oxygen level dependent) values sampled at the machine's frequency (Glover, 2011, usually 2 seconds). The smallest unit of brain tissue for which BOLD signal is recorded is called a voxel (an equivalent of a 3D pixel); it comprises several cubic millimeters of brain tissue. For our analyses, we select subsets of voxels belonging to specific brain systems. Following common practice, the parameters of a general linear model, fit to time-varying BOLD values, are used as a measure of the overall activation in each voxel in response to a given input. It is the values of these parameters that, according to the neuroscience community, are brain representations.\\n\\nFigure 1: The approximate locations of MD and the Language systems in the human brain. The regions depicted are used as a starting point to functionally localize these systems in individual participants.\\n\\nBrain systems.\\n\\nA system of brain regions can span different areas of the brain but behaves as a holistic unit, showing similar patterns of engagement across a given cognitive task. We probe the following systems of regions in our work. See Appendix A for a detailed description of these systems along with relevant references.\\n\\n- **Multiple Demand (MD) system.** This system of regions is known to engage in cognitively demanding, domain agnostic tasks like general problem solving, logic, and spatial memory tasks. Liu et al. (2020) and Ivanova et al. (2020) reported that this system is active during code comprehension.\\n\\n- **Language system (LS).** This system responds during language production and comprehension across modalities (speech, text) and languages (across 10 language families, including American sign language). Siegmund et al. (2014; 2017) reported activity in regions resembling the LS during code comprehension, whereas Floyd et al. (2017); Liu et al. (2020); Krueger et al. (2020) concluded that brain regions processing language and code are distinct. Ivanova et al. (2020) reported moderate levels of activity within the LS in response to Python, but not to code in a visual programming language, ScratchJr.\\n\\nWe also probe brain representations in two brain systems responsible for perception.\\n\\n- **Visual system (VS).** These regions respond primarily to visual inputs. We expect activity in this system to reflect low-level visual properties of the code (e.g., code length and indentation).\\n\\n- **Auditory system.** These regions respond primarily to auditory inputs. We do not expect activity in this system to reflect code-related properties.\\n\\n4.1 Brain Representations and Decoding\\n\\nWe describe in this section the method we follow to gather representations of code in the brain (Section 4.1), evaluate the different code properties they encode (Section 4.2), and how we compare brain representations to those generated by ML models (Section 4.3).\\n\\n**Dataset.** We use the publicly available brain recordings released as part of the study by Ivanova et al. (2020). It contains brain recordings of 24 participants reading 72 programs from a set of 108 unique Python programs. The 72 programs were presented in 12 blocks of 6 programs each. These programs were 3-10 lines in length and contained simple Python constructs, such as lists, for loops and if statements. A whole program was presented at once, and the task required participants to read the code and mentally compute the expected output, press a button when done, and select one of four choices presented to them which matched their calculated output.\\n\\n**From dataset to brain representations.** The original dataset contains 3D images of the brain of each participant. Each voxel value in these images is an estimate of the response strength in this voxel when a particular code (or sentence) problem is presented. To determine which brain systems contain information about particular code properties, we focus our analyses to four systems \u2013 MD, Language, Visual, and Auditory (Section 3). A vector of voxels' activation values in each brain system is then taken to constitute that system's representation of a computer program and serves as an input to all our analyses. See Appendix B for details on data processing and voxel selection.\"}"}
{"id": "czmQDWhGwd9", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The goal of this work is to relate brain representations of code to (1) specific code properties and (2) representations of code produced by language models trained on code. In Experiment 1, we predict the different static and dynamic analysis metrics from the brain MRI recordings (each of dimension $D_B$) of 24 human subjects reading 72 unique Python programs ($N$) by training separate linear models for each subject and metric. In Experiment 2, we learn affine maps from brain representations to the corresponding representations generated by code language models (each of dimension $D_M$) on these 72 programs.\\n\\nAnalyzing brain representations of code. We probe brain representations from each participant separately. We do not average data across participants since the regions which respond to any task (comprehending code in our case) need not align anatomically. For each of two experiments\u2014decoding different code properties, and mapping to code model representations\u2014we train ridge regression/classification models which take as input normalized brain representations per participant. We hence learn 24 different regression models, for each code property or code model (one per participant), and then report the mean performance of these models across participants. This procedure is also referred to as multi-voxel pattern analysis (MVPA) (Norman et al., 2006). Linear models are conventionally preferred for probes into brain representations since there has been evidence supporting the idea that other brain areas linearly map information from such brain representations (Kamitani & Tong, 2005; Kriegeskorte, 2011). We choose a linear model primarily to control for over-fitting in light of the relatively small dataset.\\n\\nA remark on data scarcity. We train a linear regression/classification model with L2-regularization for every participant on unique cross-validated leave-one-run-out folds of the 72 programs they attempted (or 48 programs when sentences are removed). On the order of 1000 voxels were selected from each brain region responding to any given program per participant. As a baseline for the model predictions, we use the accuracy of a null permutation distribution generated from sampling 1000 random assignments of the labels.\\n\\n4.2 CODE PROPERTIES\\nWe attempt to decode the following code properties from brain representations.\\n\\n- **Code vs. sentences.** The dataset provides a control condition where code problems are described in English sentences (referred to as sentences). See Figure B, Appendix B for an example. We classify these two stimuli categories from brain data.\\n- **Variable language.** We classify programs containing meaningful variable names from brain representations. The dataset has half its programs with variables in English, and the other half in Japanese (written in English characters), which do not convey any contextual meaning.\\n- **Control flow.** We predict whether a program contains a loop (for loop), a branch (if condition), or has sequential instructions without any control branching. The dataset contains an equal number of programs with each of the three conditions.\\n- **Data type.** We predict whether a program contains string operations or numeric operations in them. Half the programs in the dataset exclusively have string operations within them, while the other half are exclusively numeric.\\n- **Static analysis.** We decode static properties of a program. Specifically, we predict token count (number of tokens in the program) and node count (number of AST nodes). We also consider cyclomatic complexity, and Halstead difficulty (details in Appendix B), which have been used by software engineering practitioners to quantify the complexity of code, and to quantify the difficulty a human\"}"}
{"id": "czmQDWhGwd9", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: Sensitivity of brain representation mapping to model output dimensions. Each subplot contains the decoding results from a given brain network, and each line reflects a unique code model across a range of controlled embedding dimensions.\\n\\nSENSITIVITY OF BRAIN MAPPING TO MODEL OUTPUT DIMENSIONS\\n\\nOf potential interest to the decoding framework is not just the complexity of code models, but their intrinsic dimensionality as well. In order to investigate to what extent brain model mappings are robust to changes in code model dimensionality, and to assess which model representations are most sensitive to compression and expansion, we rerun our current decoding framework while controlling for embedding size.\\n\\nFor each brain network to code model mapping task, prior to the MVPA analysis, we control for the dimensionality of the code model embedding via projection through a Gaussian random matrix \\\\( R_{d_1 \\\\times d_2} \\\\) drawn from \\\\( N(0, \\\\frac{1}{d_2}) \\\\) where \\\\( d_1 \\\\) is the original code model embedding dimensionality and \\\\( d_2 \\\\) is the desired dimensionality. We observe that models of lower complexity (e.g., bag-of-words, TF-IDF, seq2seq, XLNet) appear relatively robust to compression, whereas the most complex models (e.g., CodeTransformer, CodeBERTa) gain considerable performance from higher dimensional expression, and suffer considerably when constrained. This indicates that higher dimensions of the encoder in complex models encode relevant neural information. Additionally, these effects appear to be most pronounced when decoding from the brain region whose representations yield the strongest mappings, the MD system.\\n\\nWe note here however that we could be observing an interaction effect between model complexity and dimensionality output in these results. Since we cannot fully control for the complexity of these models (by making them all 'equally complex'), this experiment alone cannot drive definitive conclusions. These results instead constitute a preliminary exploration into the effects of code model dimensionality on brain to model representation mappings, and suggest an avenue for future investigation.\"}"}
{"id": "czmQDWhGwd9", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For the decoding analysis of the continuous valued dynamic analysis and static analysis properties, it is reasonable to ask why the Pearson correlation metric was chosen as opposed to RMSE, as is typically customary for regression tasks. While we present the results using the Pearson correlation metric in the core results for interpretability via the zero baseline, here we confirm that the use of an RMSE metric leads to the same conclusions. As we see here, the MD, LS, and Visual system decode the dynamic analysis property, and MD and LS decode the static analysis property with significantly lower RMSE than the null permutation baseline. These results precisely confirm and mirror the patterns observed in Figure 3.\\n\\n| Brain Network Code Property       | RMSE | Null \u00b1 RMSE | Is Significant? |\\n|-----------------------------------|------|-------------|-----------------|\\n| MD Dynamic Analysis               | 3.49 | 4.03 \u00b1 0.08 | 1               |\\n| MD Static Analysis                | 7.68 | 8.27 \u00b1 0.15 | 1               |\\n| Language Dynamic Analysis         | 3.68 | 3.95 \u00b1 0.08 | 1               |\\n| Language Static Analysis          | 7.34 | 8.00 \u00b1 0.15 | 1               |\\n| Visual Dynamic Analysis           | 3.79 | 4.05 \u00b1 0.08 | 1               |\\n| Visual Static Analysis            | 7.99 | 8.28 \u00b1 0.16 | 0               |\\n| Auditory Dynamic Analysis         | 3.79 | 3.98 \u00b1 0.07 | 0               |\\n| Auditory Static Analysis          | 8.04 | 8.10 \u00b1 0.15 | 0               |\\n\\nTable 19: RMSE between observed and predicted continuous-valued code properties from the MVPA regression task in Experiment 1, confirming the pattern of results observed in 5.1.\"}"}
{"id": "czmQDWhGwd9", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We run a series of one-way ANOVA statistical tests to assess whether decoding performance varies across brain regions for each code property and code model, and whether decoding performance varies across code models for each brain region. We report these results in Tables 5, 6, and 7. We find that decoding performance varies across brain region for all code properties and code models, except the variable language property and the Random embedding model, and decoding performance varies across code models for the MD system and the Visual system.\\n\\n| Code Property       | F    | p (corrected) | p (uncorrected) | Is Significant? |\\n|---------------------|------|--------------|-----------------|----------------|\\n| Code vs. Sentence   | 53.57| 4.03e-20     | 2.42e-19        |                |\\n| Control Flow        | 12.52| 6.13e-07     | 1.84e-06        |                |\\n| Static Analysis     | 6.71 | 3.82e-04     | 7.65e-04        |                |\\n| Data Type           | 4.46 | 5.66e-03     | 8.50e-03        |                |\\n| Dynamic Analysis    | 4.15 | 8.38e-03     | 1.01e-02        |                |\\n| Variable Language   | 0.82 | 4.84e-01     | 4.84e-01        |                |\\n\\nTable 5: Results from statistical testing of variance across brain regions for each code property.\\n\\n| Code Model          | F    | p (corrected) | p (uncorrected) | Is Significant? |\\n|---------------------|------|--------------|-----------------|----------------|\\n| CodeTransformer     | 11.85| 1.25e-06     | 7.95e-06        |                |\\n| CodeBERTa           | 11.28| 2.27e-06     | 7.95e-06        |                |\\n| TF-IDF              | 8.46 | 5.08e-05     | 9.48e-05        |                |\\n| Seq2Seq             | 8.40 | 5.42e-05     | 9.48e-05        |                |\\n| Bag Of Words        | 5.66 | 1.33e-03     | 1.86e-03        |                |\\n| XLNet               | 3.48 | 1.90e-02     | 2.22e-02        |                |\\n| Random Embedding    | 2.32 | 8.04e-02     | 8.04e-02        |                |\\n\\nTable 6: Results from statistical testing of variance across brain regions for each code model.\\n\\n| Brain Region        | F    | p (corrected) | p (uncorrected) | Is Significant? |\\n|---------------------|------|--------------|-----------------|----------------|\\n| Visual              | 4.00 | 9.17e-04     | 3.67e-03        |                |\\n| MD                  | 2.72 | 1.54e-02     | 3.08e-02        |                |\\n| Language            | 2.18 | 4.70e-02     | 6.27e-02        |                |\\n| Auditory            | 0.43 | 8.57e-01     | 8.57e-01        |                |\\n\\nTable 7: Results from statistical testing of variance across code models for each brain region.\"}"}
{"id": "czmQDWhGwd9", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"To extend the findings from the ANOVA analyses towards specific pairwise comparisons between brain regions and code models, we compare scores between brain regions for each code property or code model, and compare scores between code models and a subset of code properties for each brain region, using two-sample two-tail t-tests with unequal variance. We report all pairwise brain region comparisons in Tables 8 and 10, and report all pairwise code property and model comparisons in Tables 9 and 11. To highlight a few key results from code properties, we find that the MD system decodes runtime steps and control flow significantly better than the Visual system (Table 8). Additionally, the Language system decodes static analysis and control flow significantly better than the Visual system. Moving onto code models, we find that the MD system decodes CodeBERTa, seq2seq, and TF-IDF significantly more accurately than the Language system, and additionally decodes CodeTransformer, seq2seq, TF-IDF, and bag-of-words significantly more accurately than the Visual system (Table 10). Finally, an investigation into model complexity reveals that CodeBERTa is significantly more accurately decoded from the MD system than the Random embedding model.\\n\\n| Brain Region A | Brain Region B | t    | p (corrected) | Is Significant? |\\n|----------------|----------------|------|---------------|-----------------|\\n| Code vs. Sentence | Language Auditory | 8.82 | 5.33e-11 | 6.40e-10 | 1 |\\n| Code vs. Sentence | MD Auditory | 9.79 | 1.28e-11 | 4.62e-10 | 1 |\\n| Code vs. Sentence | Visual Auditory | 9.06 | 2.65e-11 | 4.78e-10 | 1 |\\n| Control Flow | Language Auditory | 4.28 | 1.02e-04 | 6.10e-04 | 1 |\\n| Control Flow | Language Visual | 2.60 | 1.26e-02 | 3.30e-02 | 1 |\\n| Control Flow | MD Auditory | 5.59 | 1.65e-06 | 1.49e-05 | 1 |\\n| Control Flow | MD Visual | 3.92 | 2.95e-04 | 1.52e-03 | 1 |\\n| Data Type | MD Auditory | 3.16 | 2.98e-03 | 1.21e-02 | 1 |\\n| Data Type | Visual Auditory | 2.93 | 5.33e-03 | 1.88e-02 | 1 |\\n| Dynamic Analysis | MD Auditory | 3.13 | 3.03e-03 | 1.21e-02 | 1 |\\n| Dynamic Analysis | MD Visual | 2.59 | 1.28e-02 | 3.30e-02 | 1 |\\n| Static Analysis | Language Auditory | 4.70 | 2.97e-05 | 2.14e-04 | 1 |\\n| Static Analysis | Language Visual | 2.92 | 5.75e-03 | 1.88e-02 | 1 |\\n| Static Analysis | MD Auditory | 2.79 | 7.68e-03 | 2.30e-02 | 1 |\\n| Code vs. Sentence | Language Visual | -0.28 | 7.83e-01 | 8.30e-01 | 0 |\\n| Code vs. Sentence | MD Language | 0.49 | 6.27e-01 | 6.84e-01 | 0 |\\n| Code vs. Sentence | MD Visual | 0.18 | 8.55e-01 | 8.55e-01 | 0 |\\n| Control Flow | MD Language | 1.44 | 1.58e-01 | 2.84e-01 | 0 |\\n| Control Flow | Visual Auditory | 1.50 | 1.40e-01 | 2.81e-01 | 0 |\\n| Data Type | Language Auditory | 2.30 | 2.62e-02 | 6.30e-02 | 0 |\\n| Data Type | Language Visual | -0.94 | 3.55e-01 | 4.91e-01 | 0 |\\n| Data Type | MD Language | 1.48 | 1.47e-01 | 2.81e-01 | 0 |\\n| Data Type | MD Visual | 0.64 | 5.24e-01 | 6.18e-01 | 0 |\\n| Dynamic Analysis | Language Auditory | 1.29 | 2.03e-01 | 3.04e-01 | 0 |\\n| Dynamic Analysis | Language Visual | 0.57 | 5.73e-01 | 6.45e-01 | 0 |\\n| Dynamic Analysis | MD Language | 2.11 | 4.01e-02 | 9.03e-02 | 0 |\\n| Dynamic Analysis | Visual Auditory | 0.75 | 4.55e-01 | 5.85e-01 | 0 |\\n| Static Analysis | MD Language | -1.34 | 1.89e-01 | 3.04e-01 | 0 |\\n| Static Analysis | MD Visual | 1.32 | 1.94e-01 | 3.04e-01 | 0 |\\n| Static Analysis | Visual Auditory | 1.47 | 1.48e-01 | 2.81e-01 | 0 |\\n| Variable Language | Language Auditory | 0.66 | 5.15e-01 | 6.18e-01 | 0 |\\n| Variable Language | Language Visual | -0.63 | 5.32e-01 | 6.18e-01 | 0 |\\n| Variable Language | MD Auditory | 1.40 | 1.68e-01 | 2.88e-01 | 0 |\\n| Variable Language | MD Language | 0.84 | 4.06e-01 | 5.41e-01 | 0 |\\n| Variable Language | MD Visual | 0.23 | 8.20e-01 | 8.44e-01 | 0 |\\n| Variable Language | Visual Auditory | 1.23 | 2.26e-01 | 3.25e-01 | 0 |\"}"}
{"id": "czmQDWhGwd9", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 9: Results from pairwise t-tests of continuous code metrics across brain regions. Only this subset of properties was selected so as to evaluate scores with a consistent metric and baseline.\\n\\n| Brain Region | Code Property | Static Analysis | Dynamic Analysis | t | p | p (corrected) | Is Significant? |\\n|--------------|---------------|----------------|-----------------|---|---|---------------|----------------|\\n|              |               |                 |                 |   |   |               |                |\\n|              |               |                 |                 |   |   |               |                |\\n\\n- \\\\( t \\\\) reflects \\\\( A > B \\\\), whereas \\\\(- t \\\\) reflects \\\\( A < B \\\\).\"}"}
{"id": "czmQDWhGwd9", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Brain Region | Code Model A | Code Model B |\\n|--------------|--------------|--------------|\\n| MD           | t            | -t           |\\n| Visual       | t            | -t           |\\n| Language     | t            | -t           |\\n| Auditory     | t            | -t           |\\n\\n**Table 11: Results from pairwise t-tests of code models for each brain region.**\\n\\n+ reflect A > B, whereas -t reflects A < B.\"}"}
{"id": "czmQDWhGwd9", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nThomas J McCabe. A complexity measure. IEEE Transactions on software engineering, pp. 308\u2013320, 1976.\\n\\nTom M Mitchell, Svetlana V Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L Malave, Robert A Mason, and Marcel Adam Just. Predicting human brain activity associated with the meanings of nouns. Science, 320(5880):1191\u20131195, 2008.\\n\\nKenneth A Norman, Sean M Polyn, Greg J Detre, and James V Haxby. Beyond mind-reading: multi-voxel pattern analysis of fmri data. Trends in cognitive sciences, 10(9):424\u2013430, 2006.\\n\\nSam Norman-Haignere, Nancy G Kanwisher, and Josh H McDermott. Distinct cortical pathways for music and speech revealed by hypothesis-free voxel decomposition. Neuron, 88(6):1281\u20131296, 2015.\\n\\nSam V Norman-Haignere, Nancy Kanwisher, Josh H McDermott, and Bevil R Conway. Divergence in the functional organization of human and macaque auditory cortex revealed by fmri responses to harmonic tones. Nature neuroscience, 22(7):1057\u20131060, 2019.\\n\\nPaul Nuyujukian, Jose Albites Sanabria, Jad Saab, Chethan Pandarinath, Beata Jarosiewicz, Christine H Blabe, Brian Franco, Stephen T Mernoff, Emad N Eskandar, John D Simeral, et al. Cortical control of a tablet computer by people with paralysis. PloS one, 13(11):e0204566, 2018.\\n\\nChristophe Pallier, Anne-Dominique Devauchelle, and Stanislas Dehaene. Cortical representation of the constituent structure of sentences. Proceedings of the National Academy of Sciences, 108(6):2522\u20132527, 2011.\\n\\nJoonkoo Park, Andrew Hebrank, Thad A. Polk, and Denise C. Park. Neural Dissociation of Number from Letter Recognition and Its Relationship to Parietal Numerical Processing. Journal of Cognitive Neuroscience, 24(1):39\u201350, 2012.\\n\\nNorman Peitek, Janet Siegmund, Chris Parnin, Sven Apel, Johannes C Hofmeister, and Andr\u00e9 Brechmann. Simultaneous measurement of program comprehension with fmri and eye tracking: A case study. In Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, pp. 1\u201310, 2018.\\n\\nNorman Peitek, Sven Apel, Chris Parnin, Andr\u00e9 Brechmann, and Janet Siegmund. Program comprehension and code complexity metrics: An fmri study. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 524\u2013536. IEEE, 2021.\\n\\nThad A. Polk, Matthew Stallcup, Geoffrey K. Aguirre, David C. Alsop, Mark D'Esposito, John A. Detre, and Martha J. Farah. Neural Specialization for Letter Recognition. Journal of Cognitive Neuroscience, 14(2):145\u2013159, 2002.\\n\\nChantel S Prat, Tara M Madhyastha, Malayka J Mottarella, and Chu-Hsuan Kuo. Relating natural language aptitude to individual differences in learning programming languages. Scientific reports, 10(1):1\u201310, 2020.\\n\\nRuchir Puri, David Kung, Geert Janssen, Wei Zhang, Giacomo Domeniconi, Vladmir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey Decker, Veronika Thost, Luca Buratti, Saurabh Pujar, Shyam Ramji, Ulrich Finkler, Susan Malaika, and Frederick Reiss. Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks, 2021.\\n\\nEdmund T. Rolls, Chu-Chung Huang, Ching-Po Lin, Jianfeng Feng, and Marc Joliot. Automated anatomical labelling atlas 3. NeuroImage, 206:116189, 2020.\\n\\nFranck-Emmanuel Roux, Vincent Lubrano, Valerie Lauwers-Cances, Carlo Giussani, and Jean-Fran\u00e7ois D\u00e9monet. Cortical areas involved in arabic number reading. Neurology, 70:210\u2013217, 2008.\\n\\nMartin Schrimpf, Idan Blank, Greta Tuckute, Carina Kauf, Eghbal A. Hosseini, Nancy Kanwisher, Joshua Tenenbaum, and Evelina Fedorenko. Artificial neural networks accurately predict language processing in the brain. bioRxiv, 2020.\\n\\nDan Schwartz, Mariya Toneva, and Leila Wehbe. Inducing brain-relevant bias in natural language processing models. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.\"}"}
{"id": "czmQDWhGwd9", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nMartin Shepperd. A critique of cyclomatic complexity as a software metric. Software Engineering Journal, 3(2):30\u201336, 1988.\\n\\nJanet Siegmund, Christian Kastner, Sven Apel, Chris Parnin, Anja Bethmann, Thomas Leich, Gunter Saake, and Andre Brechmann. Understanding understanding source code with functional magnetic resonance imaging. In Proceedings of the 36th International Conference on Software Engineering, pp. 378\u2013389, 2014.\\n\\nJanet Siegmund, Norman Peitek, Chris Parnin, Sven Apel, Johannes Hofmeister, Christian Kastner, Andrew Begel, Anja Bethmann, and Andre Brechmann. Measuring neural efficiency of program comprehension. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 140\u2013150, 2017.\\n\\nShashank Srikant, Sijia Liu, Tamara Mitrovska, Shiyu Chang, Quanfu Fan, Gaoyuan Zhang, and Una-May O'Reilly. Generating adversarial computer programs using optimized obfuscations. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=PH5PH9ZO_4.\\n\\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems, volume 27. Curran Associates, Inc., 2014. URL https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf.\\n\\nFabian David Tschopp, Michael B. Reiser, and Srinivas C. Turaga. A connectome based hexagonal lattice convolutional network model of the drosophila visual system, 2018.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\\n\\nShaonan Wang, Jiajun Zhang, Nan Lin, and Chengqing Zong. Probing brain activation patterns by dissociating semantics and syntax in sentences. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):9201\u20139208, Apr. 2020. doi: 10.1609/aaai.v34i05.6457.\\n\\nDaniel L Yamins, Ha Hong, Charles Cadieu, and James J DiCarlo. Hierarchical modular optimization of convolutional networks achieves representations similar to macaque it and human ventral stream. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013. URL https://proceedings.neurips.cc/paper/2013/file/9a1756fd0c741126d7bbd4b692ccbd91-Paper.pdf.\\n\\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for language understanding. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9e-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf.\\n\\nDaniel Zubner, Tobias Kirschstein, Michele Catasta, Jure Leskovec, and Stephan Gunemann. Language-agnostic representation learning of source code from structure and context. In International Conference on Learning Representations (ICLR), 2021.\"}"}
{"id": "czmQDWhGwd9", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A BRAIN REGIONS\\nRegions of Interest (ROIs).\\n\\nWe investigate the representations of code in well-studied systems of brain regions\u2014the MD system, Language system, Visual system, and the Auditory system (details below). A region (also referred to as a parcel) here denotes a contiguous chunk of brain mass involved in a cognitive task. A system of regions (also referred to as a network) can comprise multiple disjoint regions that exhibit shared activity patterns across a range of tasks. For many cognitive tasks, a region marks only the approximate location of voxel populations involved in a cognitive task.\\n\\nFunctional ROIs (fROIs) are voxels within these broad regions that respond most strongly to a given task (language, working memory, etc.). The use of fROIs enables accounting for the exact anatomical locations of these task-sensitive voxels, which vary across individuals.\\n\\nMultiple Demand (MD) system. Located in the prefrontal and parietal areas of the brain, this system of regions is active in a host of tasks requiring working memory and general problem solving skills, including math and logic (Duncan, 2010; Fedorenko et al., 2013; Amalric & Dehaene, 2019).\\n\\nLanguage system. These regions have been identified to respond to both comprehension and production of language across modalities (written, speech, sign language), respond to typologically diverse languages (>50 languages, from across 10 language families), form a functionally integrated system, reliably and robustly track linguistic stimuli, and have been shown to be causally important for language (Clark & Cummings, 2003; Fedorenko et al., 2010; Blank & Fedorenko, 2017; Ayyash et al., 2021).\\n\\nVisual system. These regions in the occipital lobe of the brain respond to visual input, ranging from low-level features like lines and edges, through intermediate categories like shapes, letters, and numbers, through higher order structures like faces and scenes. (Hubel & Wiesel, 1959; Polk et al., 2002; Epstein & Kanwisher, 1998; Kanwisher et al., 1997).\\n\\nAuditory system. The auditory system is located in the superior temporal region of the brain. This region uniquely encodes pitch, speech, and music, but is not involved in high-level language comprehension and production (Norman-Haignere et al., 2015; 2019). In our experiments pertaining to programming language comprehension, we use the activity seen in the auditory system as a negative control.\"}"}
{"id": "czmQDWhGwd9", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Selecting brain representations. For each trial in the fMRI experiment, stimulus responses in each voxel were extracted from the parameters of a General Linear Model (GLM) fit to the time-varying BOLD signal in which each experimental condition was modeled with a boxcar function convolved with the canonical hemodynamic response function (HRF). For the localizer experiments, conditions were modeled as the entire block. For the Python program comprehension experiment, individual programs were modeled using the period from the onset of the code/sentence problem until the button press. The predictors for the GLM included trial ID (equivalent to problem ID), run number, and motion regressors. The voxels were then filtered using gray-matter masking and network localization. Although fMRI measurements return whole brain responses, only a thin layer of cortex dubbed gray matter contains BOLD signal of interest to these analyses. Gray matter voxels were selected using a Bayesian segmentation of the anatomical brain image into standard tissue types, and then returning the set of indices where the posterior gray matter probability exceeds 0.70 (Ashburner et al., 1999). Next, these sets of voxels were filtered separately for each of the brain regions outlined in Appendix A. For the visual and auditory networks, primary sensory areas were identified using an anatomical atlas (Rolls et al., 2020). For the MD and the Language systems, voxels were functionally localized as those containing the top 10% of responses to their respective functional localizer tasks, as described in Ivanova et al. (2020). See Fedorenko et al. (2010) for a discussion of the functional localization approach as it pertains to the language network. GLM modeling and gray matter segmentation was performed using SPM12; functional localization was performed using the toolbox released by Ivanova et al. (2020). Once voxel responses within each brain region were extracted for each trial of each run, some additional preprocessing was required before finalizing the brain representations, and passing them to downstream models. Due to differences in MRI sensitivity across runs, each of the 12 runs of 6 programs for a given subject appeared with nonuniform mean and variance. In order to normalize these signals, so as to leverage data across a participant's entire scanning session, brain representations were z-transformed within each run to achieve a common scale. In order to avoid data-leakage from this preprocessing step, all downstream analyses were cross-validated via a leave-one-run-out approach, such that no intra-run rescaling could be used for prediction.\\n\\nMVPA cross-validation and hyperparameters. For each brain system and each code property or code model, we run a separate MVPA analysis. For each subject, we train a separate ridge regression model on each cross-validated leave-one-run-out fold, and then predict the remaining targets using the brain representations from the left-out run. We use $L^2$ regularization to control for model complexity, and employ a leave-one-out cross validation scheme to select $\\\\lambda$. We score resulting predictions using a series of different metrics to maximize interpretability. For the categorical code properties, we report classification accuracy of model estimates. For the continuously scaled code properties, we report Pearson correlation between the model estimates and true targets. For the model representations, we report rank accuracy between model representation predictions and the true model representations of left-out samples. We calculate rank accuracy as the percentile of a predicted and true target pairing within the full set of possible pairings sorted by a Euclidean distance metric. Rank accuracy was chosen for this experiment as it returns a more interpretable $50\\\\%$ baseline through which to evaluate the brain to model mappings. Following metric calculation on each cross-validation fold, we take the mean of those estimates to report an out-of-sample score over the entire dataset for each subject. We then take the mean of those scores across subjects to derive an overall performance measure. As a baseline, we repeat the above process in its entirety 1000 times for each MVPA analysis, to provide a null permutation distribution against which to compare scores. These null distributions are fit with a univariate Gaussian and used to calculate z-statistics and p-values for MVPA scores. All statistical tests were corrected for false discovery rate. The code to run our MVPA analysis is available in https://github.com/anonmyous-author/anonymous-code.\"}"}
{"id": "czmQDWhGwd9", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"In order to investigate whether each of the brain systems included contribute unique information towards the decoding tasks, we combine brain representations from different systems in paired combinations and evaluate effects on downstream decoding performance across all experiments. We find that the addition of MD or LS to VS, relative to VS alone, improves downstream decoding of code vs sentences. The same effect is observed for the combination of MD and LS compared to either alone. These data suggest that the MD system and the Language system encode unique variance relevant to the decoding of code vs sentences, and this is above and beyond the information encoded in the Visual system or each other individually. Additionally, we observe that the addition of MD to VS, relative to VS alone, improves downstream decoding of control flow and data type. This same effect is observed for the addition of LS to Visual system for control flow. These data suggest that the MD system and the Language system encode unique information above and beyond information encoded in the Visual system for the control flow decoding task, and the MD system encodes unique information above and beyond information encoded in the Visual system for the data type decoding task (Table 15). We repeat this process for Experiment 2, where we find that the addition of MD to VS improves decoding for 5 models, the addition of MD to LS improves decoding for 4 models, and the addition of LS to Visual system improves decoding for 2 models (Table 16).\\n\\n### Table 12: Multi-system regression analysis on original Ivanova et al. (2020) code properties\\n\\n| Brain Representation | Code Properties | L+V | MD+L | MD+V |\\n|---------------------|-----------------|-----|------|------|\\n| Code vs. Sentence   | Empirical Baseline | 0.56 | 0.94 (+0.38) | 0.94 (+0.38) | 0.93 (+0.37) |\\n| Control Flow        | 0.33 | 0.45 (+0.12) | 0.49 (+0.16) | 0.49 (+0.16) |\\n| Data Type           | 0.50 | 0.62 (+0.12) | 0.63 (+0.13) | 0.68 (+0.18) |\\n\\nTable 12: Multi-system regression analysis on original Ivanova et al. (2020) code properties. Scores represent classification accuracy and are contrasted with an empirical baseline from the null permutation analysis. Values in parentheses are units above baseline.\\n\\n### Table 13: Multi-system regression analysis on static and dynamic code properties\\n\\n| Brain Representation | Code Properties | L+V | MD+L | MD+V |\\n|---------------------|-----------------|-----|------|------|\\n| Dynamic Analysis    | 0.22 | 0.32 | 0.31 |\\n| Static Analysis     | 0.19 | 0.21 | 0.20 |\\n\\nTable 13: Multi-system regression analysis on static and dynamic code properties. Scores represent Pearson correlation between predicted and true code properties.\\n\\n### Table 14: Multi-system regression analysis on code model mappings\\n\\n| Brain Representation | Code Models | L+V | MD+L | MD+V |\\n|---------------------|-------------|-----|------|------|\\n| Random Embedding    | Empirical Baseline | 0.50 | 0.57 (+0.07) | 0.56 (+0.06) | 0.57 (+0.07) |\\n| Bag Of Words        | 0.50 | 0.57 (+0.07) | 0.59 (+0.09) | 0.59 (+0.09) |\\n| TF-IDF              | 0.50 | 0.56 (+0.06) | 0.58 (+0.08) | 0.57 (+0.07) |\\n| Seq2Seq             | 0.50 | 0.55 (+0.05) | 0.57 (+0.07) | 0.56 (+0.06) |\\n| XLNet               | 0.50 | 0.57 (+0.07) | 0.58 (+0.08) | 0.57 (+0.07) |\\n| CodeTransformer     | 0.50 | 0.58 (+0.08) | 0.60 (+0.10) | 0.60 (+0.10) |\\n| CodeBERTa           | 0.50 | 0.60 (+0.10) | 0.62 (+0.12) | 0.62 (+0.12) |\\n\\nTable 14: Multi-system regression analysis on code model mappings. Scores represent rank accuracy and are contrasted with an empirical baseline from the null permutation analysis. Values in parentheses are units above baseline.\"}"}
{"id": "czmQDWhGwd9", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Code Property       | Variable         | t | p      | Corrected p      | Significant |\\n|---------------------|------------------|---|--------|------------------|-------------|\\n| L+V Language        |                  |   |        |                  |             |\\n|                     |                  | 3.88 | 3.94e-04 | 5.20e-03 | 1            |\\n|                     |                  | 3.56 | 9.82e-04 | 7.07e-03 | 1            |\\n|                     |                  | 3.77 | 5.96e-04 | 5.36e-03 | 1            |\\n|                     |                  | 3.83 | 4.33e-04 | 5.20e-03 | 1            |\\n|                     |                  | 3.25 | 2.29e-03 | 1.37e-02 | 1            |\\n|                     |                  | 2.96 | 5.36e-03 | 2.54e-02 | 1            |\\n|                     | Control Flow     | 2.91 | 5.63e-03 | 2.54e-02 |             |\\n|                     | Data Type        | 2.86 | 6.41e-03 | 2.56e-02 | 1            |\\n|                     | Dynamic Analysis | 0.15 | 8.80e-01 | 1.00e+00 | 0            |\\n|                     |                  | 1.46 | 1.50e-01 | 3.18e-01 |             |\\n|                     |                  | -0.11 | 9.16e-01 | 1.00e+00 | 0            |\\n|                     |                  | 0.03 | 9.73e-01 | 1.00e+00 | 0            |\\n|                     | Data Type        | 1.50 | 1.39e-01 | 3.13e-01 | 0            |\\n|                     |                  | 0.44 | 6.59e-01 | 9.49e-01 | 0            |\\n|                     |                  | 1.93 | 6.00e-02 | 1.80e-01 |             |\\n|                     |                  | 0.24 | 8.11e-01 | 9.94e-01 | 0            |\\n|                     |                  | 1.76 | 8.67e-02 | 2.23e-01 | 0            |\\n|                     | Variable Language| 0.62 | 5.36e-01 | 9.18e-01 | 0            |\\n|                     |                  | -0.00 | 1.00e+00 | 1.00e+00 | 0            |\\n|                     |                  | 0.53 | 5.98e-01 | 9.25e-01 | 0            |\\n|                     |                  | -0.27 | 7.86e-01 | 9.94e-01 | 0            |\\n|                     |                  | 0.50 | 6.17e-01 | 9.25e-01 | 0            |\\n\\nTable 15: Results from pairwise t-tests of paired brain systems with their individual components for each code property.\\n\\n* t reflects A>B, whereas \u2212t reflects A<B.\"}"}
{"id": "czmQDWhGwd9", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 16: Results from pairwise t-tests of paired brain systems with their individual components for each code model.\\n\\n| Code Model | Brain Region A | Brain Region B | t | p | corrected p | R |\\n|------------|----------------|----------------|---|---|-------------|---|\\n| Bag Of Words | L+V Language | 0.64 | 5.24e-01 | 6.47e-01 | 0 |\\n| | L+V Visual | 1.77 | 8.35e-02 | 1.59e-01 | 0 |\\n| | MD+L Language | 2.25 | 2.92e-02 | 7.65e-02 | 0 |\\n| | MD+L MD | 0.82 | 4.15e-01 | 5.44e-01 | 0 |\\n| | MD+V MD | 0.60 | 5.49e-01 | 6.59e-01 | 0 |\\n| CodeBERTa | L+V Visual | 1.46 | 1.52e-01 | 2.45e-01 | 0 |\\n| | MD+L MD | 0.88 | 3.84e-01 | 5.20e-01 | 0 |\\n| | MD+V MD | 1.11 | 2.74e-01 | 4.05e-01 | 0 |\\n| CodeTransformer | L+V Language | 1.61 | 1.15e-01 | 1.94e-01 | 0 |\\n| | L+V Visual | 2.18 | 3.48e-02 | 8.47e-02 | 0 |\\n| | MD+L MD | 0.36 | 7.21e-01 | 7.97e-01 | 0 |\\n| | MD+V MD | 0.48 | 6.31e-01 | 7.16e-01 | 0 |\\n| Random Embedding | L+V Language | 1.72 | 9.15e-02 | 1.66e-01 | 0 |\\n| | L+V Visual | 1.80 | 7.91e-02 | 1.58e-01 | 0 |\\n| | MD+L Language | 1.71 | 9.46e-02 | 1.66e-01 | 0 |\\n| | MD+L MD | 0.51 | 6.11e-01 | 7.13e-01 | 0 |\\n| | MD+V MD | 1.09 | 2.80e-01 | 4.05e-01 | 0 |\\n| | MD+V Visual | 2.30 | 2.65e-02 | 7.56e-02 | 0 |\\n| Seq2Seq | L+V Language | 1.10 | 2.78e-01 | 4.05e-01 | 0 |\\n| | MD+L Language | 2.43 | 1.99e-02 | 6.41e-02 | 0 |\\n| | MD+L MD | 0.20 | 8.39e-01 | 8.39e-01 | 0 |\\n| | MD+V MD | -0.28 | 7.78e-01 | 8.17e-01 | 0 |\\n| TF-IDF | L+V Language | 2.16 | 3.63e-02 | 8.47e-02 | 0 |\\n| | MD+L MD | 1.00 | 3.22e-01 | 4.50e-01 | 0 |\\n| | MD+V MD | 0.31 | 7.60e-01 | 8.17e-01 | 0 |\\n| XLNet | L+V Language | 1.91 | 6.23e-02 | 1.31e-01 | 0 |\\n| | L+V Visual | 2.11 | 4.07e-02 | 8.99e-02 | 0 |\\n| | MD+L MD | 0.79 | 4.35e-01 | 5.53e-01 | 0 |\\n| | MD+V MD | 0.24 | 8.10e-01 | 8.30e-01 | 0 |\\n| | MD+V Visual | 2.29 | 2.70e-02 | 7.56e-02 | 0 |\\n\\nt reflects A>B, whereas -t reflects A<B.\"}"}
{"id": "czmQDWhGwd9", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We analyzed a series of code properties as part of the static and dynamic code analysis. As several of these properties (token count, node count, Halstead difficulty, cyclomatic complexity, and bytecode ops) were revealed to be highly correlated in a post-hoc analysis, we report only one measure for this subset in Experiment 1, token count, but include all scores here for completeness (Table 17).\\n\\nWe also report the correlation matrix between all code properties that led us to select token count as the representative property for this subset (Table 18).\\n\\n### Table 17: Brain region decoding performance on all static analysis and dynamic analysis code properties.\\n\\n|                  | MD | Language | Visual | Auditory |\\n|------------------|----|----------|--------|----------|\\n| Token Count      | 0.17 | 0.24 | 0.09 | 0.00 |\\n| Node Count       | 0.12 | 0.20 | 0.03 | 0.01 |\\n| Halstead Difficulty | 0.11  | 0.17 | 0.10 | -0.01 |\\n| Cyclomatic Complexity | 0.18  | 0.24 | 0.10 | 0.01 |\\n| Bytecode Operations | 0.15  | 0.18 | 0.03 | 0.02 |\\n| Runtime Steps    | 0.33 | 0.20 | 0.17 | 0.12 |\\n\\n### Table 18: Correlation matrix across all code properties. The control flow property was split into two binary properties here, conditional and iteration. Of relevance is that token count presents with \\\\( r > 0.8 \\\\) for all static analysis properties in the set and as such is used as the representative static analysis code property in Experiment 1.\\n\\n|                  | Datatype | Conditional | Iteration | Tokens | Nodes | Halstead | Cyclomatic | Runtime | Bytecode |\\n|------------------|----------|-------------|-----------|--------|-------|----------|------------|---------|----------|\\n| Datatype         | 1.00     | 0.00        | 0.00      | 0.41   | 0.33  | 0.39     | 0.18       | 0.13    | 0.28     |\\n| Conditional      | -        | 1.00        | -0.50     | 0.44   | 0.46  | 0.50     | 0.61       | -0.41   | 0.49     |\\n| Iteration        | -        | -           | 1.00      | -0.10  | -0.14 | -0.35    | -0.09      | 0.90    | 0.01     |\\n| Tokens           | -        | -           | -         | 1.00   | 0.97  | 0.89     | 0.80       | 0.08    | 0.95     |\\n| Nodes            | -        | -           | -         | -      | 1.00  | 0.86     | 0.79       | 0.00    | 0.96     |\\n| Halstead         | -        | -           | -         | -      | -     | 1.00     | -0.17      | 0.80    |          |\\n| Cyclomatic       | -        | -           | -         | -      | -     | -        | 1.00       | 0.02    |          |\\n| Runtime          | -        | -           | -         | -      | -     | -        | -          | 1.00    |          |\\n| Bytecode         | -        | -           | -         | -      | -     | -        | -          | -       | 1.00     |\\n\\n28\"}"}
{"id": "czmQDWhGwd9", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The performance of mappings between brain and code model representations does not appear to be correlated to the complexity of the models. However, we do observe a preferential encoding of the properties represented by code models in the MD over LS for the models CodeBERTa, seq2seq, and TF-IDF. Such a preferential encoding of properties in MD over LS was not seen for the properties we evaluated in Experiment 1, which provides evidence that the brain activation data encodes more than just the code properties we evaluated.\\n\\nThe MD and LS map to complex models like seq2seq and CodeTransformer almost as well as to a combination of random token embeddings. One plausible explanation for this surprising result is that the MD and LS signals we have access to mostly encode token-level information, and not richer structural information from the programs. The program stimuli are simple enough to allow the different properties evaluated in our work (control flow, data type, etc.) to be discerned from token level information alone (as validated in Experiment 1), which is likely why the random embeddings model is also able to predict these properties very well (see Table 4, Appendix C.2).\\n\\nTaken together, this suggests that the information being decoded from brain activations in these two regions is driven at least by the information conveyed by tokens in the programs. We cannot come to this conclusion from the code properties investigated in Experiment 1 alone. CodeBERTa alone, for which the response is significantly greater than random embeddings, and which maps more accurately to the MD system than any other brain system, provides initial evidence for the MD system encoding more than just token information. This will need more investigation.\\n\\nGiven the current data and the number of observations we have, we can only conclude that tokens do get encoded well in both\u2014brain activations and code models. This is a new finding on what aspects of code comprehension get encoded by our brains which can be successfully read out using a linear model.\\n\\nLimitations. The average program in any software project exhibits non-trivial control and data dependencies, object manipulation, function calls, types, and state changes, which our dataset does not possess. However, the programming tasks in Ivanova et al. (2020) are short snippets of procedural code with limited program properties. Responses to longer, more realistic programs should be studied on a larger number of participants in the future, building on the understanding of simpler snippets provided by our work. Further, while there are equally important aspects to programming like designing solutions, selecting appropriate data structures, and writing programs, we have chosen to study a very specific activity related to programming\u2014comprehending programs.\\n\\nOne aspect that cannot be inferred from these results, is whether the MD and LS are driven by the same underlying features of code that are used to discriminate between code properties, and to map to different code models. Future work should consider an encoding analysis, where we predict the activity of voxels in different brain systems from code properties, in order to establish the relative contributions of those properties to the activations of individual voxels in these systems.\\n\\nBroader impact. Our findings have the potential to improve our understanding of the organization of the human brain, which can in turn lead to the design of better code models. In computer vision, recent results by Tschopp et al. (2018) show how deep network architectures that mimic the visual system in fruit flies exhibit superior image classification rates on image recognition tasks. One immediate outcome is reconsidering the current design of ML models of code. Extant code model architectures do not explicitly model the Multiple Demand system in any way\u2014they only model syntactic information and infer dependency information from program ASTs. Taking inspiration from the role of the Multiple Demand system we identified in this work, modeling both static and dynamic information should be explored.\\n\\nThis work could perhaps also enhance code prosthetics\u2014artificial interfaces in the body that can help the physically challenged engage with programming environments. Such systems generally rely on brain decoders\u2014models that convert brain activity data to electrical impulses modulating external devices. An open challenge is to improve them. See the discussion in Nuyujukian et al. (2018) and Andersen et al. (2019) for details.\\n\\nFinally, our aspiration is that the framework we release in this work will bring together the neuroscience and machine learning communities to better understand the cognitive and neural bases of programming.\"}"}
{"id": "czmQDWhGwd9", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"REPRODUCIBILITY STATEMENT\\n\\nAll the results, and corresponding tables, plots, and intermediate results we introduce in this paper are fully reproducible. We have made the source code to our work publicly available through this anonymized code repository - https://github.com/anonmyous-author/anonymous-code/\\n\\nThe repository contains detailed instructions for setting up the source code and running the two main experiments we introduce in this work. Further, a copy of the dataset released by Ivanova et al. Ivanova et al. (2020) is also available in the repository, along with the source code.\\n\\nAll the intermediate results which we use to arrive at our conclusions are available in Appendix A through Appendix I.\"}"}
{"id": "czmQDWhGwd9", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. A survey of machine learning for big code and naturalness. *ACM Computing Surveys (CSUR)*, 51(4):1\u201337, 2018a.\\n\\nMiltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs with graphs. In *International Conference on Learning Representations*, 2018b. URL https://openreview.net/forum?id=BJOFETxR-.\\n\\nUri Alon, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured representations of code. In *International Conference on Learning Representations*, 2019. URL https://openreview.net/forum?id=H1gKYo09tX.\\n\\nMarie Amalric and Stanislas Dehaene. A distinct cortical network for mathematical knowledge in the human brain. *NeuroImage*, 189:19\u201331, 2019.\\n\\nRichard A Andersen, Tyson Aflalo, and Spencer Kellis. From thought to action: The brain\u2013machine interface in posterior parietal cortex. *Proceedings of the National Academy of Sciences*, 116(52):26274\u201326279, 2019.\\n\\nJohn Ashburner, Jesper L.R. Andersson, and Karl J. Friston. High-dimensional image registration using symmetric priors. *NeuroImage*, 9(6):619\u2013628, 1999.\\n\\nDima Ayyash, Saima Malik-Moraleda, Jeanne Gall\u00e9e, Josef Affourtit, Malte Hoffman, Zachary Mineroff, Olessia Jouravlev, and Evelina Fedorenko. The universal language network: A cross-linguistic investigation spanning 45 languages and 11 language families. *bioRxiv*, 2021.\\n\\nBenjamin Bichsel, Veselin Raychev, Petar Tsankov, and Martin Vechev. Statistical deobfuscation of android applications. In *Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security*, pp. 343\u2013355, 2016.\\n\\nIdan A Blank and Evelina Fedorenko. Domain-general brain regions do not track linguistic input as closely as language-selective regions. *Journal of Neuroscience*, 37(41):9999\u201310011, 2017.\\n\\nJonathan R Brennan and Liina Pylkk\u00e4nen. Meg evidence for incremental sentence composition in the anterior temporal lobe. *Cognitive science*, 41:1515\u20131531, 2017.\\n\\nLu Cao, Dandan Huang, Yue Zhang, Xiaowei Jiang, and Yanan Chen. Brain decoding using fnirs. *Proceedings of the AAAI Conference on Artificial Intelligence*, 35(14):12602\u201312611, May 2021.\\n\\nCasey Casalnuovo, Kevin Lee, Hulin Wang, Prem Devanbu, and Emily Morgan. Do programmers prefer predictable expressions in code? *Cognitive Science*, 44(12):e12921, 2020.\\n\\nJo\u00e3o Castelhano, Isabel C Duarte, Carlos Ferreira, Jo\u00e3o Duraes, Henrique Madeira, and Miguel Castelo-Branco. The role of the insula in intuitive expert bug detection in computer code: an fmri study. *Brain imaging and behavior*, 13(3):623\u2013637, 2019.\\n\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code, 2021.\\n\\nDavid Glenn Clark and Jeffrey L Cummings. Aphasia. In *Neurological Disorders*, pp. 265\u2013275. Elsevier, 2003.\\n\\nWill Crichton, Maneesh Agrawala, and Pat Hanrahan. The role of working memory in program tracing. In *Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems*, pp. 1\u201313, 2021.\\n\\nJohn Duncan. The multiple-demand (md) system of the primate brain: mental programs for intelligent behaviour. *Trends in cognitive sciences*, 14(4):172\u2013179, 2010.\"}"}
{"id": "czmQDWhGwd9", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Russell A. Epstein and Nancy Kanwisher. A cortical representation of the local visual environment. *Nature*, 392:598\u2013601, 1998.\\n\\nEvelina Fedorenko, Po-Jiang Hsieh, Alfonso Nieto-Castanon, Susan Whitfield-Gabrieli, and Nancy Kanwisher. New method for fmri investigations of language: defining rois functionally in individual subjects. *Journal of neurophysiology*, 104(2):1177\u20131194, 2010.\\n\\nEvelina Fedorenko, John Duncan, and Nancy Kanwisher. Broad domain generality in focal regions of frontal and parietal cortex. *Proceedings of the National Academy of Sciences*, 110(41):16616\u201316621, 2013.\\n\\nBenjamin Floyd, Tyler Santander, and Westley Weimer. Decoding the representation of code in the brain: An fmri study of code review and expertise. In *2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)*, pp. 175\u2013186. IEEE, 2017.\\n\\nJon Gauthier and Roger Levy. Linking artificial and human neural representations of language. *arXiv preprint arXiv:1910.01244*, 2019.\\n\\nGary H Glover. *Overview of functional magnetic resonance imaging.* *Neurosurgery Clinics*, 22(2):133\u2013139, 2011.\\n\\nMaurice H Halstead. *Elements of Software Science (Operating and programming systems series).* Elsevier Science Inc., 1977.\\n\\nYu Huang, Xinyu Liu, Ryan Krueger, Tyler Santander, Xiaosu Hu, Kevin Leach, and Westley Weimer. Distilling neural representations of data structure manipulation using fmri and fnirs. In *2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)*, pp. 396\u2013407. IEEE, 2019.\\n\\nDavid H. Hubel and Torsten N. Wiesel. Receptive fields of single neurones in the cat's striate cortex. *The Journal of Physiology*, 148, 1959.\\n\\nHuggingFace. *Codeberta - a roberta-like model trained on the codesearchnet dataset from github.* HuggingFace, 2020. URL https://huggingface.co/huggingface/CodeBERTa-small-v1.\\n\\nHamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc Brockschmidt. *Code-searchnet challenge: Evaluating the state of semantic code search.* CoRR, abs/1909.09436, 2019. URL http://arxiv.org/abs/1909.09436.\\n\\nYoshiharu Ikutani, Takatomi Kubo, Satoshi Nishida, Hideaki Hata, Kenichi Matsumoto, Kazushi Ikeda, and Shinji Nishimoto. Expert programmers have fine-tuned cortical representations of source code. *Eneuro*, 8(1), 2021.\\n\\nAnna A Ivanova, Shashank Srikant, Yotaro Sueoka, Hope H Kean, Riva Dhamala, Una-May O'Reilly, Marina U Bers, and Evelina Fedorenko. Comprehension of computer code relies primarily on domain-general executive brain regions. *Elife*, 9:e58906, 2020.\\n\\nShailee Jain and Alexander Huth. Incorporating context into language encoding models for fmri. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), *Advances in Neural Information Processing Systems*, volume 31. Curran Associates, Inc., 2018.\\n\\nYukiyasu Kamitani and Frank Tong. Decoding the visual and subjective contents of the human brain. *Nature neuroscience*, 8(5):679\u2013685, 2005.\\n\\nNancy Kanwisher, Josh McDermott, and Marvin M. Chun. The fusiform face area: A module in human extrastriate cortex specialized for face perception. *The Journal of Neuroscience*, 17:4302\u20134311, 1997.\\n\\nNikolaus Kriegeskorte. *Pattern-information analysis: from stimulus decoding to computational-model testing.* *Neuroimage*, 56(2):411\u2013421, 2011.\\n\\nRyan Krueger, Yu Huang, Xinyu Liu, Tyler Santander, Westley Weimer, and Kevin Leach. Neurological divide: an fmri study of prose and code writing. In *2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)*, pp. 678\u2013690. IEEE, 2020.\\n\\nYun-Fei Liu, Judy Kim, Colin Wilson, and Marina Bedny. Computer code comprehension shares neural resources with formal logical inference in the fronto-parietal network. *Elife*, 9:e59340, 2020.\"}"}
