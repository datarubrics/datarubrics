{"id": "gjfOL9z5Xr", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2024\\n\\naag = (aac AND aaf) = (True AND False) = False.\\n\\nThus, the answer is <<<False>>>.\\n\\n\u2022 Deductive Logic:\\n\\nInput:\\n\\nHere is a description of a deductive logic problem:\\n\\naaa is False.\\n\\naab is False.\\n\\n(aaa or aab) -> aac.\\n\\n(NOT aac) -> aad.\\n\\nThe symbol '->' represents a deductive relationship, e.g., A -> B implies that if A is true, then B is true. If A is false, B's truth value remains undetermined (N/A). Deduce the result of aad. If the solution cannot be deduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nInference steps:\\n\\naaa is False.\\n\\naab is False.\\n\\n(aaa OR aab) = (False OR False) -> aac.\\n\\nThe premise (False OR False) is False, thus, the value of aac cannot be deduced and is set to N/A.\\n\\n(NOT aac) = (NOT N/A) -> aad.\\n\\nThe value of aad cannot be deduced, and is set to N/A.\\n\\nThus, the answer is <<<N/A>>>.\\n\\n\u2022 Abductive Logic:\\n\\nInput:\\n\\nHere is a description of an abductive logic problem:\\n\\n(aad or aae) -> aaf.\\n\\n(aaa or aab) -> aac.\\n\\n(aac or aaf) -> aag.\\n\\nGiven aag is False, what is the value of aab?\\n\\nThe symbol '->' represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A's truth value remains undetermined (N/A). If the solution cannot be abduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nInference steps:\\n\\n(aac OR aaf) -> aag = False.\\n\\nGiven aag is False, the value of premise (aac OR aaf) is False, thus, the value of aac is abduced as False.\\n\\n(aaa OR aab) -> aac = False.\\n\\nGiven aac is False, the value of premise (aaa OR aab) is False, thus, the value of aab is abduced as False.\\n\\nThus, the answer is <<<False>>>.\\n\\n\u2022 Reachability:\"}"}
{"id": "gjfOL9z5Xr", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Input:\\nGiven a directed graph:\\n\\n- aag points to: (None).\\n- aaf points to: (None).\\n- aaa points to: (aag, aaf).\\n- aac points to: (aaa).\\n- aab points to: (aaa).\\n- aad points to: (aaa).\\n- aae points to: (aad).\\n\\nCan aag be reached starting from aaf?\\n\\nRespond with either '<<<True>>>' if reachable, or '<<<False>>>'\\notherwise.\\n\\nInference steps:\\nStarting the search process from node aaf with the goal to reach node aag.\\nChecking node aaf.\\nNode aaf has no unvisited children. Moving back.\\nExhausted all possible paths without reaching node aag.\\nThus, the answer is <<<False>>>.\\n\\nMax Sum Path:\\nInput:\\nGiven a directed graph with values assigned to each node:\\n\\n- aag points to: (None).\\n- aaf points to: (aag).\\n- aae points to: (aaf, aag).\\n- aab points to: (aaf).\\n- aad points to: (aab, aae).\\n- aac points to: (aag, aad).\\n- aaa points to: (aac, aag, aae).\\n\\nThe value of aaa is 3\\nThe value of aab is 2\\nThe value of aaf is 5\\nThe value of aag is 5\\nThe value of aae is 1\\nThe value of aad is 7\\nThe value of aac is 2\\n\\nWhat's the maximum sum path from aab to aae?\\n\\nFor example, the value of the path A->B->C is obtained by summing the values of nodes A, B, and C. Please format your response as <<<Answer>>>. For example, if the answer is 1, it should be presented as <<<1>>>.\\n\\nInference steps:\\nStarting the search for the maximum sum path from node aab to node aae.\\nReaching node aab with current sum of 2.\\nNow, we explore the children of node aab: aaf.\\nReaching node aaf with current sum of 7.\\nNow, we explore the children of node aaf: aag.\\nReaching node aag with current sum of 12.\\nNode aag has no children. Moving back.\\nThere is no path from node aab to node aae.\\nThus, the answer is <<<N/A>>>.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"E.2 Training Data and Testing Data\\n\\nE.2.1 Training Data\\nFor mathematical tasks and logical reasoning tasks that utilize T-DAGs, we construct four types of training datasets. Each dataset consists of 500 training samples. All of these types have a depth of 3. The settings are as follows:\\n\\n1. width=2, add random links=0, embed random descs=0,\\n2. width=2, add random links=1, embed random descs=0,\\n3. width=2, add random links=1, embed random descs=1,\\n4. width=3, add random links=0, embed random descs=0.\\n\\nFor algorithm tasks, two types of training datasets are generated:\\n\\n1. num nodes=7, max links per node=3,\\n2. num nodes=10, max links per node=4.\\n\\nE.2.2 Testing Data\\nWe create three types of testing data:\\n\\n1. In-Distribution (ID) Test Set: The difficulty level matches that of the training set.\\n   - For T-DAGs: depth=4, width=2, with no extra links and random descriptions.\\n   - For G-DAGs: num nodes=15 with max links=6.\\n2. Out-of-Distribution (OOD) Test Set:\\n   - For T-DAGs: depth=4, width=2, without extra links and random descriptions.\\n   - For G-DAGs: num nodes=15 with max links=6.\\n3. Out-of-Distribution-Hard (OOD-hard) Test Set:\\n   - For T-DAGs: depth=4, width=2, with one extra link per node and one random description.\\n   - For G-DAGs: num nodes=20 with max links=8.\\n\\nNote that the definition of OOD in our tasks is mainly on the different complexities of the samples that may come with more advanced structures or descriptions. For model evaluation, when using the DYGIVAL generated testing data, a zero-shot setting was adopted. For existing benchmarks, few-shot COT examples were provided in the context: 4 examples for GSM8K and SV AMP, 3 for FOLIO and RACO, and 2 for DP and LCS. The results of evaluation in our tasks are presented in Figure 10.\\n\\nE.3 Results of Fine-tuning\\nWe fine-tuned Llama2-13b-chat with LORA (Hu et al., 2022) for 3 epochs where the rank was 8, the scaling factor was 16 and the drop out rate was 0.05. We used a 0.0003 learning rate with batch size 128. Results on existing benchmarks of the fine-tuned model is in Figure 6 of the main paper.\\n\\nFigure 10 displays the results after fine-tuning on our test datasets as described in Sec.E.2.2. The performance of Llama2-13B-chat on tasks like boolean logic, deductive logic, and reachability significantly improves after fine-tuning on our dataset. However, noticeable gaps remain, particularly in areas such as mathematic tasks, abductive logic and the max sum path.\\n\\nEmbarrassed Generated Dataset\\nOur algorithm can easily satisfy the balance requirement by meticulously controlling the flexible dynamic generation process. For example, in reachability task, we can drop the generated evaluation samples with \u2018False\u2019 labels until we generate a sample with \u2018True\u2019 label. We presented the results of GPT-3.5-Turbo and GPT-4 in balanced datasets in Table 8. The results in balanced datasets are similar to our initial findings: (1) GPT-3.5-Turbo consistently predicted all questions as \u201cTrue,\u201d resulted in a uniform accuracy rate of 50%. (2) GPT-4 demonstrated excellent performance. It maintained significantly higher accuracy rates across all complexity levels.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 10: Fine-tuned results on ID and OOD sets of our tasks. For arithmetic, linear equation, reachability and max sum path tasks, the vanilla accuracy is zero.\\n\\nTable 8: Results of fine-tuned ChatGPT model on general natural language understanding tasks\\n\\n| Model         | Vanilla-ID | Gain FT-ID | Vanilla-OOD | Gain FT-OOD | Vanilla-OOD hard | Gain FT-OOD hard |\\n|---------------|------------|------------|-------------|------------|------------------|------------------|\\n| ChatGPT       |            |            |             |            |                  |                  |\\n| GPT4          |            |            |             |            |                  |                  |\\n\\nWe fine-tuned GPT-3.5-turbo-0613 using our generated data on abductive logic and reachability datasets, as GPT-3.5 performs worst on these two datasets. Specifically, we generated 100 samples across complexity levels D1, D2, and D3 for each task. We compared the performance of original and fine-tuned models on several benchmark tasks in GLUE dataset. The performance of abductive logic and reachability task are tested on D4 task (different from fine-tuning dataset). As shown in Table 9, performance on WNLI and QNLI datasets dropped for the fine-tuned model. However, fine-tuned model achieves better results on CoLA, QQP, and MRPC datasets. Despite the mixed results, the overall improvement in several datasets suggests that fine-tuning on our generated datasets does not necessarily hurt the general language understanding ability.\\n\\nTable 9: Results of fine-tuned ChatGPT model on general natural language understanding tasks\\n\\n| Model          | SST-2 | CoLA | WNLI | QNLI | QQP | MRPC |\\n|----------------|-------|------|------|------|-----|------|\\n| GPT3.5         | 55.27 | 50.00| 93.29| 77.00| 59.15| 80.00| 76.50| 73.00|\\n| GPT3.5-FT      | 85.10 | 96.53| 93.23| 78.00| 45.07| 72.50| 78.00| 77.50|\\n\\nFinally, we discuss the flexibility of DYVAL while the main focus of this paper is on reasoning tasks. We show that DYVAL can be easily extended to natural language processing tasks using an initial experiment on sentiment analysis.\\n\\nGenerally speaking, a natural language sentence can be expressed as a syntax tree, similar to DAGs. However, generating sentences through direct syntax tree construction (which is similar to the construction of arithmetic task) presents notable challenges, primarily due to the need for grammatical correctness and the inherent naturalness of these sentences. Nevertheless, DYVAL can still be applied to generate tasks in natural language by utilizing syntax tree templates extracted by existing sentences. For each sentence in the SST-2 dataset, we initially employ GPT-3.5-Turbo to extract its syntactic structure. Within each syntax tree (i.e., DAGs), we identify the elements that can be modified: namely, nouns (such as names and places) and adjectives. GPT-3.5-Turbo is then used to create five alternative candidates for each of these modifiable components, which are subsequently replaced in an iterative fashion. Throughout this process, we continuously assess whether these replacements alter the original semantic meaning of the sentence. Any changes that result in a semantic shift are discarded. Note that the graph cannot be randomly generated as the reasoning tasks...\"}"}
{"id": "gjfOL9z5Xr", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A's value is calculated by the sum of B and C.\\nB's value is...\\nG's value is...\\nAdd random links\\nEmbed random descriptions\\nAdding difficulty\\nOrigin\\nFigure 7: The complexity constraints for Tree-based DAGs.\\n\\nTasks (DV-A), which includes reachability task and max sum path task.\\n\\nFor DYVAL-M, we design mathematical problems that can be categorized into two main types:\\n\\nArithmetic:\\nGiven a T-DAG, the DAG description function has already demonstrated the premise:\\nthe leaf nodes and the intermediate steps of inference: non-leaf nodes. Next, we select the root node\\nas the variable required to solve, we append the question \\\"What is the value of [Root]?\\\"\\nto the final of the description where [Root] is filled with the name of the root variable.\\n\\nHere is a description of an arithmetic problem:\\nThe value of aaa is 9.\\nThe value of aad is 4.\\nAAE gets its value by taking the square root of the value that aad has.\\nThe value of aab is 3.\\nAAC gets its value by adding together the value of aaa and aab.\\nAaf gets its value by subtracting the value of aae from the value of aac.\\nCompute the result of aaf. If the solution cannot be calculated,\\nanswer 'N/A'. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\\n\\nLinear Equations:\\nLinear equations with multiple variables present a higher degree of complexity compared to arithmetic. We use two-variable linear equations described as\\n\\\\[a_1 x + b_1 y = c_1,\\\\]\\n\\\\[a_2 x + b_2 y = c_2.\\\\]\\nThe coefficients are assigned a random value. We ask LLMs to solve the value of x, y for this linear system. Note that constructing such linear equations does not need T-DAGs or G-DAGs.\\nTo introduce additional challenges, some coefficients can be substituted with values derived from the T-DAG's roots, forcing a two-step problem-solving approach: first calculating the coefficients from the DAG and subsequently resolving the linear equations. Note that in our experiment, the tree depth and width for linear equation task are\\n\\\\[(1,1), (2,2), (3,2), (4,2)\\\\] respectively.\\n(1,1) represent that the value of the replaced coefficient is directly given.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Given the following linear equation system with two variables:\\n\\\\[-7x + aac_0 y = 1\\\\]\\n\\\\[8x - y = 10\\\\]\\n\\nThe calculation of $aac_0$ is defined as:\\n\\nThe value of $aab_0$ is 4.\\nThe value of $aaa_0$ is 9.\\n\\n$aac_0$ gets its value by adding together the value of $aaa_0$ and $aab_0$.\\n\\nDetermine the values of $x$ and $y$. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x's value y's value>>>, e.g., if $x=1$ and $y=2$, then it should be <<<1 2>>>\\n\\nB.3.2 D Y V AL -L also shares a natural compatibility with the structured representation of T-DAGs due to the innate progression and dependencies inherent in logical constructs. The tasks are:\\n\\n**Boolean Logic:**\\nSimilar to arithmetic task, it primarily revolves around the manipulation and combination of True and False values using operators: AND, OR, NOT. The problems are presented as: What is the truth value of [Root]?\\n\\nHere is a description of a boolean logic problem:\\n$aaa$ is True.\\n$aab$ equals to (NOT $aaa$).\\n$aac$ equals to (NOT $aab$).\\nCompute the result of $aac$. If the solution cant be calculated, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\n**Deductive Logic:**\\nThe process of deductive logic is similar to boolean logic, but deduction introduces a bit complexity compared to boolean logic inference. For instance, given premises $A$ (True) and $B$ (False), and the relationship $(A \\\\land B) \\\\rightarrow C$, the value of conclusion $C$ remains undetermined because the conjunction $(A \\\\land B)$ is false. Given the description of T-DAGs, the problem is formulated as:\\n\\nBy the rule of deduction, what is the value of [Root]?\\n\\nHere is a description of a deductive logic problem:\\n$aab$ is True.\\n$aaa$ is True.\\n$(aaa \\\\text{ and } aab) \\\\rightarrow aac$.\\n$aad$ is False.\\n$(\\\\text{NOT } aad) \\\\rightarrow aae$.\\n$(aac \\\\text{ or } aae) \\\\rightarrow aaf$.\\n\\nThe symbol '->' represents a deductive relationship, e.g., $A \\\\rightarrow B$ implies that if $A$ is true, then $B$ is true. If $A$ is false, $B$'s truth value remains undetermined (N/A). Deduct the result of $aaf$. If the solution cant be calculated, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abductive Logic:\\nIt aims to hypothesize the most likely cause or explanation based on observed outcomes. When working with a T-DAG, we assign a random value to the root node. Then, we randomly select a leaf node, the problem is to determine the leaf node's value based on the given the DAG structure and root's value. The task description is Given the value of \\\\([\\\\text{Root}]\\\\) is \\\\([\\\\text{value}]\\\\), what is the value of \\\\([\\\\text{Node}]\\\\)?\\n\\nHere is a description of an abductive logic problem:\\n\\\\((\\\\text{aaa or aab}) \\\\rightarrow \\\\text{aac}\\\\).\\n\\\\((\\\\text{NOT aac}) \\\\rightarrow \\\\text{aad}\\\\).\\nGiven \\\\(\\\\text{aad}\\\\) is \\\\(\\\\text{False}\\\\), what is the value of \\\\(\\\\text{aab}\\\\)?\\nThe symbol '->' represents a deductive relationship, e.g., \\\\(\\\\text{A} \\\\rightarrow \\\\text{B}\\\\) implies that if \\\\(\\\\text{B}\\\\) is \\\\(\\\\text{False}\\\\), then \\\\(\\\\text{A}\\\\) is \\\\(\\\\text{False}\\\\). If \\\\(\\\\text{B}\\\\) is \\\\(\\\\text{True}\\\\), \\\\(\\\\text{A}\\\\)'s truth value remains undetermined (N/A). If the solution can not be deducted, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nB.3.3 DY VAL-A D Y V AL tasks is suitable for D-DAG since they aim to model the real-world applications. Among many problems that can be abstracted and modeled as a G-DAG, here we select two representative tasks.\\nReachability:\\nA classic example of where G-DAGs shine is in modeling problems like the reachability of two nodes in the DAG. Given various nodes representing cities and links indicating roads between them, the question models can help deduce the if there exists a route from one city to an-other. Thus, the description for this task is: \\\"Can the \\\\([\\\\text{Node1}]\\\\) be reached by \\\\([\\\\text{Node2}]\\\\)\\\" where \\\\(\\\\text{Node1}\\\\) and \\\\(\\\\text{Node2}\\\\) are randomly selected from the nodes in G-DAG.\\n\\nGiven a directed graph:\\n\\\\(\\\\text{aai}\\\\) points to: (None).\\n\\\\(\\\\text{aac}\\\\) points to: (\\\\text{aai}).\\n\\\\(\\\\text{aaj}\\\\) points to: (\\\\text{aai}).\\n\\\\(\\\\text{aah}\\\\) points to: (\\\\text{aai}, \\\\text{aac}, \\\\text{aaj}).\\n\\\\(\\\\text{aag}\\\\) points to: (\\\\text{aac}).\\n\\\\(\\\\text{aaf}\\\\) points to: (\\\\text{aag}, \\\\text{aah}, \\\\text{aaj}).\\n\\\\(\\\\text{aab}\\\\) points to: (\\\\text{aaf}, \\\\text{aah}).\\n\\\\(\\\\text{aaa}\\\\) points to: (\\\\text{aag}, \\\\text{aah}, \\\\text{aaf}, \\\\text{aaj}).\\n\\\\(\\\\text{aae}\\\\) points to: (\\\\text{aai}, \\\\text{aac}, \\\\text{aaa}).\\n\\\\(\\\\text{aad}\\\\) points to: (\\\\text{aab}, \\\\text{aaf}, \\\\text{aae}).\\n\\nCan \\\\(\\\\text{aaf}\\\\) be reached starting from \\\\(\\\\text{aag}\\\\)?\\nRespond with either '<<<True>>>' if reachable, or '<<<False>>>' otherwise.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Max sum path:\\n\\nCompared to reachiability problem, max sum path is more complex. This problem assigns a value for each city, and then requires to find a path from two cities that the sum of the values the path go through is maximum. It requires the LLMs to find all the paths between two nodes, and then determine the path with maximum value. The description for this task is What is the max sum path from [Node 1] to [Node 2]?\\n\\nGiven a directed graph with values assigned to each node:\\n- aaj points to: (None).\\n- aah points to: (None).\\n- aai points to: (aah).\\n- aag points to: (aai).\\n- aac points to: (aag).\\n- aab points to: (aac, aag).\\n- aaf points to: (aai).\\n- aae points to: (aac, aah).\\n- aad points to: (aag, aae, aaj).\\n- aaa points to: (aae, aai, aaj, aad).\\n\\nThe value of aaj is 9\\nThe value of aab is 8\\nThe value of aah is 3\\nThe value of aaf is 3\\nThe value of aai is 3\\nThe value of aae is 3\\nThe value of aad is 6\\nThe value of aac is 4\\nThe value of aag is 8\\nThe value of aaa is 4\\n\\nWhat's the maximum sum path from aaa to aae? For example, the value of the path A->B->C is obtained by summing the values of nodes A, B, and C. Please format your response as <<<Answer>>>.\\n\\nB.4 D\\n\\nDESCRIPTION ORDER\\n\\n\u2022 Topological Order: This approach sequences the description of nodes in a manner where every node is introduced after all its descendent nodes. Such a sequence ensures that leaf nodes are laid out prior to any operation that utilizes them (e.g., an addition or a logical AND).\\n\\n\u2022 Reversed Topological Order: Taking an almost counter-intuitive approach, this order starts by spotlighting the culminating nodes or outcomes. Once these results are laid bare, the narrative retraces its steps, navigating backwards to the root nodes or primary inputs.\\n\\n\u2022 Random Order: This unstructured method presents nodes in a random sequence, irrespective of their dependencies within the DAG. Such a disordered narrative challenges LLMs to independently connect the dots and derive patterns.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"aab gets its value by squaring the value that aaa has.\\n\\nThe value of aaf is 10.\\n\\naae gets its value by multiplying together the value of aab and aad and aai.\\n\\nCompute the result of aao. If the solution cannot be calculated, answer 'N/A'. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\\n\\nGPT-4's response:\\n\\nLet's solve this step by step:\\n\\n1. aac = 6\\n2. aai = 6\\n3. aag = 8\\n4. aaa = 6\\n5. aad = \\\\sqrt{aac} = \\\\sqrt{6}\\n6. aaj = 4\\n7. aaq = 7\\n8. aap = 1\\n9. aaf = 10\\n10. aab = aab = 6^2 = 36\\n11. aae = aab * aad * aai = 36 * \\\\sqrt{6} * 6\\n12. aak = aai - (aaj + aae) = 6 - (4 + 36 * \\\\sqrt{6} * 6)\\n13. aah = aaf * aag * aae = 10 * 8 * 36 * \\\\sqrt{6} * 6\\n14. aan = aah - (aak + aae) = 10 * 8 * 36 * \\\\sqrt{6} * 6 - (6 - (4 + 36 * \\\\sqrt{6} * 6) + 36 * \\\\sqrt{6} * 6)\\n15. aao = aae * aan * aae = (36 * \\\\sqrt{6} * 6) * (10 * 8 * 36 * \\\\sqrt{6} * 6 - (6 - (4 + 36 * \\\\sqrt{6} * 6) + 36 * \\\\sqrt{6} * 6)) * (36 * \\\\sqrt{6} * 6)\\n\\nThis is a complex calculation and it's not possible to simplify it further. However, it's clear that the result will be a very large number. Since the problem doesn't provide any constraints on the values of the variables, we can't say that the solution is 'N/A'.\\n\\n(The equation is correct however GPT-4 did not simplify it. In our experiment, we found that GPT-4 can handle large numbers, so the error does not originate from them.)\\n\\nSo, the result of aao is a very large number that can't be simplified further.\\n\\nGround truth: 11848342359.78579\\n\\nAs shown in Figure 5, we systematically vary the levels of complexity in GPT-3.5-Turbo by adjusting individual constraints while keeping others constant. Specifically, we explore how performance metrics evolve as we incrementally adjust depth, width, #nodes, #max links, the number of extra links, and the quantity of random descriptions across arithmetic, boolean logic, and deductive logic tasks. To comprehensively evaluate the impact of complexity constraints, various parameters were meticulously adjusted. The following elucidates the configurations employed:\"}"}
{"id": "gjfOL9z5Xr", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Results of GPT-3.5-Turbo with prompt engineering techniques on the toughest evaluation sets generated by D4.\\n\\n| Prompt engineering | Arithmetic | Linear Equation | Deductive Logic | Abductive Logic | Reachability | Max SumPath |\\n|--------------------|------------|----------------|----------------|----------------|--------------|-------------|\\n| Vanilla            | 42.13      | 14.93          | 56.40          | 54.33          | 49.40        | 5.07        |\\n| CoT (Wei et al., 2022) | 42.33      | 21.93          | 52.93          | 43.73          | 47.73        | 1.93        |\\n| Fewshot (Brown et al., 2020) | 47.86      | 2.40           | 35.93          | 41.60          | 81.80        | 12.20       |\\n| Least2most (Zhou et al., 2023b) | 36.73      | 12.47          | 44.07          | 38.80          | 76.53        | 8.07        |\\n| APE (Zhou et al., 2023d) | 45.20      | 23.40          | 44.67          | 53.13          | 62.80        | 8.87        |\\n| SKiC (Chen et al., 2023) | 32.07      | 13.70          | 63.00          | 78.27          | 71.40        | 11.80       |\\n\\nTable 6: Results of Llama 2 with different sizes on D4-VAI-generated evaluation samples (D1).\\n\\n| Size  | Arithmetic | Boolean logic | Reachability |\\n|-------|------------|---------------|--------------|\\n| 7b    | 13.07      | 28.93         | 29.53        |\\n| 13b   | 24.20      | 19.53         | 26.53        |\\n| 70b   | 29.71      | 28.30         | 47.38        |\\n\\n- Depth Constraint: Maintaining the width at 2, with neither the addition of random links nor the embedding of extra descriptions (both set to 0), the depth was systematically varied, with values set to 2, 3, 4, 5, and 6.\\n- Width Constraint: With a fixed depth of 3, and with the addition of random links and embedding of extra descriptions both neutralized to 0, the width was tested with the values 2, 3, 4, 5, and 6.\\n- Random Link Addition Constraint: For this, a depth of 4 and a width of 2 were maintained, with extra descriptions set to 0. The number of random links introduced varied as 0, 1, 2, 3, and 4. It should be highlighted that due to the inherent acyclic constraint, certain nodes may preclude the addition of extra links.\\n- Embedding Extra Descriptions: With a depth and width fixed at 4 and 2, respectively, and no addition of random links (set to 0), the levels of embedded extra descriptions were calibrated to 0, 1, 2, 3, and 4.\\n\\nAcross these variations, our results consistently underscore a notable trend: as the tasks become more intricate through the augmentation of these complexity parameters, LLMs progressively struggle, underscoring the inherent challenges posed by increasing task intricacy. It can be observed that depth is the most influential complexity constraint of tree-based DAGs, indicating that LLMs struggle to deal with problems that require more inference steps.\\n\\nD.7 DETAILS OF PROMPT ENGINEERING\\n\\nWe explored five prompting techniques to evaluate their potential impact on our most challenging datasets (excluding boolean logic since GPT-3.5-Turbo achieved comparable results on most challenging datasets): Zeroshot-CoT (Wei et al., 2022), Fewshot (3-shot in our experiments) (Brown et al., 2020), Least-to-most (Zhou et al., 2023b), automatic prompt engineering (APE) (Zhou et al., 2023d), and skill-in-context (SKiC) (Chen et al., 2023). The details of these techniques are as follows:\\n\\n- Zeroshot-CoT: An approach that allows models to generalize from their pre-training without explicit examples in the target task (Wei et al., 2022).\\n- Fewshot (3-shot in our experiments): Provides the model with a small number of examples from the target task to aid in understanding and generalizing to the broader task (Brown et al., 2020).\\n- Least to Most Prompting: This technique incrementally provides more specific prompts to guide the model\u2019s responses, adapting the prompt based on the difficulty level of the problem (Zhou et al., 2023b).\\n- Automatic Prompting Engineering (APE): A method where prompts are automatically engineered to elicit the desired response from the model, often maximizing its performance (Zhou et al., 2023d).\\n- Skill-in-Context (SKiC): This method seeks to understand a model\u2019s inherent skills and utilize them in a specific context to improve its outputs (Chen et al., 2023).\\n\\nD.8 HUMAN STUDY\\n\\nWe conducted our human study by obeying the local laws and regulations. The demographics of the human subjects are shown in Table 7.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 7: Demographics of the recruited human subjects.\\n\\n| Sex          | Age   | Degree  |\\n|--------------|-------|---------|\\n| Male: 63     | 63%   | Bachelor 62 |\\n| Female: 37   | 37%   | Master 38 |\\n| 20-25: 75    | 75%   |          |\\n| 26-36: 25    | 25%   |          |\\n\\nE D\\nETAILS OF\\nF\\nINE\\nTUNING\\n\\nE.1 C\\nONSTRUCTING TRAINING DATA\\n\\nThe training data includes the problems and their corresponding inference steps. Constructing inference steps is similar to the DAG description. For mathematics tasks and logical reasoning tasks, which utilize T-DAG, we follow the topological order to describe how the intermediate gets its value from its children. For algorithm tasks, the inference are indeed an algorithm, thus, we formalize each step in the algorithm into natural language, which finally form the inference steps. Following list presented a training sample of each task. Note that the inference steps for each task are also highly flexible and can be augmented with more details, and we believe that the more detailed inference steps will benefit more.\\n\\n- **Arithmetic:**\\n  - **Input:** Here is a description of an arithmetic problem:\\n    - The value of $aae$ is 2.\\n    - The value of $aad$ is 4.\\n    - $aaf$ gets its value by dividing the value of $aad$ by those of $aae$.\\n    - $aag$ gets its value by taking the square root of the value that $aaf$ has.\\n  - Compute the result of $aag$. If the solution cannot be calculated, answer 'N/A'. Ensure your result is within a relative precision of 0.0001 (or 0.01%). Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\\n  - **Inference steps:**\\n    - $aae$ is 2.0\\n    - $aad$ is 4.0\\n    - $aaf = aad / aae = 4.0 / 2.0 = 2.0$\\n    - $aag = \\\\sqrt{aaf} = \\\\sqrt{2.0} = 1.41421356$\\n    - Thus, the answer is <<<1.41421356>>>.\\n\\n- **Linear Equation:**\\n  - **Input:** Given the following linear equation system with two variables:\\n    - $aag0 \\\\times x + -6 \\\\times y = -6$\\n    - $-2 \\\\times x + 6 \\\\times y = 0$\\n  - The calculation of $aag0$ is defined as:\\n    - The value of $aab0$ is 10.\\n    - The value of $aaa0$ is 6.\\n    - $aac0$ gets its value by adding together the value of $aaa0$ and $aab0$.\\n    - The value of $aad0$ is 6.\\n    - The value of $aae0$ is 1.\\n    - $aaf0$ gets its value by multiplying together the value of $aad0$ and $32$\\n\\n...\"}"}
{"id": "gjfOL9z5Xr", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Determine the values of x and y. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x's value y's value>>>, e.g., if x=1 and y=2, then it should be <<<1 2>>>\\n\\nInference steps:\\nLet's first solve the coefficients of the linear equation.\\n\\n\\\\[ \\\\text{aab} = 10.0 \\\\]\\n\\\\[ \\\\text{aaa} = 6.0 \\\\]\\n\\\\[ \\\\text{aac} = \\\\text{aaa} + \\\\text{aab} = 6.0 + 10.0 = 16.0 \\\\]\\n\\\\[ \\\\text{aad} = 6.0 \\\\]\\n\\\\[ \\\\text{aae} = 1.0 \\\\]\\n\\\\[ \\\\text{aaf} = \\\\text{aad} \\\\times \\\\text{aae} = 6.0 \\\\times 1.0 = 6.0 \\\\]\\n\\\\[ \\\\text{aag} = \\\\text{aac} \\\\times \\\\text{aaf} = 16.0 \\\\times 6.0 = 96.0 \\\\]\\nThus, \\\\( \\\\text{aag} = 96.0 \\\\)\\n\\nNext, solve the linear equation:\\n\\\\[ 96.0 \\\\times x + -6.0 \\\\times y = -6.0 \\\\]\\n\\\\[ -2.0 \\\\times x + 6.0 \\\\times y = 0.0 \\\\]\\nTo eliminate 'y', multiply the first equation by 6 and the second equation by -6. This makes the coefficients of 'y' equal.\\nSubtracting the second equation from the first then gives: 564.0x = -36.0.\\nFrom the equation 564.0x = -36.0, we can solve for x.\\nSolving for x, we get \\\\( x = -0.06382979 \\\\).\\nSubstituting \\\\( x = -0.06382979 \\\\) into the first original equation, we get: \\\\( -6.0y = 0.12765957 \\\\), which gives \\\\( y = -0.0212766 \\\\).\\nThus, the answer is <<<-0.06382979 -0.0212766>>>\\n\\n\u2022 Boolean Logic:\\n\\nInput:\\nHere is a description of a boolean logic problem:\\n\\\\[ \\\\text{aaa} \\\\text{ is False.} \\\\]\\n\\\\[ \\\\text{aab} \\\\text{ is True.} \\\\]\\nThe value of \\\\( \\\\text{aac} \\\\) equals to \\\\( (\\\\text{aaa} \\\\text{ OR } \\\\text{aab}) \\\\).\\n\\\\[ \\\\text{aad} \\\\text{ is False.} \\\\]\\n\\\\[ \\\\text{aae} \\\\text{ is False.} \\\\]\\nThe value of \\\\( \\\\text{aaf} \\\\) equals to \\\\( (\\\\text{aad} \\\\text{ AND } \\\\text{aae}) \\\\).\\nThe value of \\\\( \\\\text{aag} \\\\) equals to \\\\( (\\\\text{aac} \\\\text{ AND } \\\\text{aaf}) \\\\).\\nCompute the result of \\\\( \\\\text{aag} \\\\). If the solution can not be calculated, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nInference steps:\\n\\\\[ \\\\text{aaa} \\\\text{ is False.} \\\\]\\n\\\\[ \\\\text{aab} \\\\text{ is True.} \\\\]\\n\\\\[ \\\\text{aac} = (\\\\text{aaa} \\\\text{ OR } \\\\text{aab}) = (\\\\text{False} \\\\text{ OR } \\\\text{True}) = \\\\text{True.} \\\\]\\n\\\\[ \\\\text{aad} \\\\text{ is False.} \\\\]\\n\\\\[ \\\\text{aae} \\\\text{ is False.} \\\\]\\n\\\\[ \\\\text{aaf} = (\\\\text{aad} \\\\text{ AND } \\\\text{aae}) = (\\\\text{False} \\\\text{ AND } \\\\text{False}) = \\\\text{False.} \\\\]\"}"}
{"id": "gjfOL9z5Xr", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2024.\\n\\nOn \\\"A is B\\\" fail to infer \\\"B is A\\\", which doubts the abilities of LLMs might come from memorization. Second, static dataset and fixed complexity. As LLMs progress at a rapid pace, existing datasets usually fail to match the models' ever-evolving capabilities, because the complexity level of existing benchmarks is usually static and fixed. As Dziri et al. (2023) demonstrated, while handling simple problems pretty well, LLMs fail to solve complex problems. The inability to automatically and dynamically increase complexity levels based on existing data prevents static benchmarks from being adapted to accurately select, compare, and advance LLMs. Although there are a few existing dynamic benchmarks like DynaBench (Kiela et al., 2021) and DynaBoard (Ma et al., 2021), they rely on crowd-sourcing efforts for data collection, which might be expensive and tedious.\\n\\nIn this paper, we introduce DYVAL\u2014a novel, general, and flexible evaluation protocol for the dynamic evaluation of LLMs (Sec. 3.1). The core of DYVAL is to dynamically generate evaluation samples on the fly instead of collecting a fixed set of data. DYVAL consists of three components: 1) the generation algorithm $G$ to generate test samples with diversities; 2) the constraint $C$ to modulate sample complexity and validity; and 3) the description function $F$ to translate the generated samples into natural languages. Based on this framework, we propose a graph-informed DYVAL (Sec. 3.2, Figure 1) to generate data using graphs. Specifically, inspired by techniques such as the compiler principle (Alfred V et al., 2007) and parsing trees which decompose complexities (Klein & Manning, 2003; Vinyals et al., 2015), we employ directed acyclic graphs (DAG) (Thulasiraman & Swamy, 2011) to compose fundamental elements into more intricate problems, with each unit symbolized as a graph node. The extendable and stochastic nature of graph generation effectively regulates the complexity levels. Additionally, the hierarchical attributes of graphs suit them for multi-step inferential tasks like logics. Problems generated by DYVAL not only require profound understanding of problem solving rather than simple memorization but also echo the human approach to incremental problem-solving and solution derivation. Being general and flexible, DYVAL co-exists and co-evolves with existing benchmarks for better LLMs evaluation and evolution.\\n\\nWe leverage DYVAL to synthesize 7 reasoning tasks, encompassing: (1) Mathematics: arithmetic and linear equations; (2) Logical reasoning: boolean, deductive, and abductive logic; (3) Algorithm: reachability and maximum sum path problems. We then re-examine the state-of-the-art LLMs ranging from Flan-T5-large (Chung et al., 2022), phi-1.5 (Li et al., 2023d), Xwin-13B (Team, 2023), Llama2-13B-chat (Touvron et al., 2023), Vicuna-13B-v1.3 (Chiang et al., 2023), WizardMath-13B (Luo et al., 2023), to GPT-3.5-Turbo (OpenAI, 2023a) and GPT-4 (OpenAI, 2023b) with DYVAL. We also test with recent prompting techniques including Few-shot (Brown et al., 2020), CoT (Wei et al., 2022), Least to Most prompting (Zhou et al., 2023b), Automatic Prompt Engineering (Zhou et al., 2023d), and Skills-in-Context prompting (Chen et al., 2023). Finally, we perform human study involving 82 human evaluators for comparison and fine-tuning experiments using DYVAL-generated evaluation samples. Furthermore, experiments on existing benchmarks also show that fine-tuning LLMs with data generated by DYVAL could directly improve models' abilities without extra careful collection of training data (Zhou et al., 2023a). We further show the flexibility of DYVAL by extending it to natural language tasks in Appendix H. Our key findings are:\\n\\n- Results on DYVAL evaluation are not always consistent with those on existing benchmarks, indicating possible low training data quality and/or data contamination of existing LLMs (Sec. 4.2). For instance, phi-1.5, WizardMath-13B, and Xwin-13B perform poorly on DYVAL while claiming huge improvements on existing benchmarks.\\n\\n- As difficulty increases, LLMs tend to perform worse and their performance gap becomes larger, emphasizing the lack of compositionality of current LLMs and the importance of evolving complexity evaluations (Sec. 4.2).\\n\\n- Our error analysis based on DYVAL evaluation exhibits various failure patterns which shed light on how to further improve LLMs. (Sec. 4.3).\\n\\n- No prompt engineering methods can perform best in all of our evaluation sets; and larger model sizes tend to achieve better performances (Sec. 4.4).\\n\\n- DYVAL can further be utilized to generate training data to improve the abilities of LLMs. (Sec. 5). For instance, fine-tuning the Llama2 models with our DYVAL generated data demonstrates enhanced results on 6 existing benchmarks.\\n\\nWe choose reasoning tasks mainly due to (1) the intrinsic connection between reasoning proficiency and intelligence; (2) the notable progress LLMs have achieved in reasoning-centric tasks (Sawada et al., 2023).\\n\\nNote that DYVAL could also be applied to existing benchmarks to create new and harder evaluation data.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To sum up, this paper makes the following contributions:\\n\\n\u2022 A dynamic evaluation protocol. DYNAMICAL \\\\textit{AL} is a dynamic evaluation protocol designed to generate test samples dynamically, mitigating the issues of data contamination and static complexity.\\n\\n\u2022 A graph-informed DYNAMICAL algorithm for evaluation of the reasoning abilities of LLMs. We use DAGs to compose reasoning problems from mathematics, logical reasoning to algorithms.\\n\\n\u2022 Extensive experiments and analysis. We conduct extensive experiments to provide insights for evaluating and improving LLMs.\\n\\n2 RELATED WORK\\n\\nEvaluating LLMs. While neural networks are recognized as the universal function approximators (Cybenko, 1989) with remarkable data fitting capabilities (Zhang et al., 2021; Arpit et al., 2017), debates (Bender et al., 2021; Zhang et al., 2021; T\u00a8anzer et al., 2022; Magar & Schwartz, 2022; Carlini et al., 2023; Wu et al., 2023; Tang et al., 2023; Ze \u02c7cevi\u00b4c et al., 2023; Koco \u00b4n et al., 2023; Schaeffer, 2023; Biderman et al., 2023; Zhu & Li, 2023) persist regarding the true nature of LLMs' generalization abilities. The growing prominence of LLMs necessitates rigorous benchmarks (Hendrycks et al., 2021; Li et al., 2023b; Zhong et al., 2023; HuggingFace, 2023). Recent trends include: (1) human-centric evaluations (Gao et al., 2022; Ribeiro & Lundberg, 2022), (2) crowd-sourced testing (Kiela et al., 2021; Ma et al., 2021), and (3) specialized task challenges (Liang et al., 2023; Tian et al., 2018; Ribeiro et al., 2020; bench authors, 2023). Complementing with these, our DYNAMICAL introduces a dynamic evaluation system, consistently relevant in the swiftly evolving landscape of AI. Although Krause et al. (2018) introduced the term \u201cdynamic evaluation\u201d, our DYNAMICAL differs considerably in its approach and goals. Specifically, reasoning is widely recognized as the core of both human and AI. Our focus on constructing reasoning tasks mirrors the intricate and multi-step nature of human reasoning (Brody, 1999; Lohman & Lakin, 2011; Sawada et al., 2023), building reasoning benchmarks is a critical step to help LLMs towards intelligence.\\n\\nData Contamination. Researchers start to realize the potential data contamination problem in LLMs (Lovin, 2023; Chowdhuri et al., 2023; Bender et al., 2021; Koco\u00b4n et al., 2023). The GPT-4 and LLama reports clearly stated the phenomenon of data contamination. Recently, Zhou et al. (2023c) discussed the risks and impacts of data contamination of evaluation benchmarks in assessing LLMs. Li (2023) examined the data contamination problem of LLama models. The Skywork LLM Wei et al. (2023) again demonstrated the data contamination issue in several. Golchin & Surdeanu (2023a;b); Oren et al. (2023); Yang et al. (2023b) designed novel methods to detect the data contamination of LLMs. DYNAMICAL is not a detection approach but a new protocol to mitigate the contamination issue.\\n\\nComplex-to-simple problem decomposition and evaluation set construction. Employing graphs to deconstruct complex tasks has been an enduring and effective strategy across domains. Compilers, as seen in computational theory (Alfred V et al., 2007), effectively break down high-level constructs, while in NLP, parsing trees bring clarity to intricate syntactic and semantic structures (Klein & Manning, 2003; Vinyals et al., 2015). Roy & Roth (2015) displayed the potency of this method in arithmetic, using trees for solving multi-step problems. Additionally, several contemporary techniques have implored LLMs to decompose complex problems (Wei et al., 2022; Zhou et al., 2023b; Khot et al., 2022; Zhang et al., 2023). Several studies have leveraged graph-based approaches for constructing compositional tasks, particularly in the domains of first-order logic (Sinha et al., 2019; Clark et al., 2020; Tian et al., 2021) and causal reasoning (Jin et al., 2023). DYNAMICAL presents notable distinctions in both objective and methodology. Additionally, GraphWorld (Palowitch et al., 2022) primarily benchmarks Graph Neural Networks (GNNs), whereas DYNAMICAL focuses on LLMs using the graph structure. They are different in nature.\\n\\n3 DYNAMICAL\\n\\nIn this section, we first elucidate our general dynamic evaluation protocol to address the challenges of data contamination with dynamic data generation and controllable complexity in Sec. 3.1. We then adapt this general protocol for reasoning tasks by leveraging the Directed Acyclic Graphs (DAGs) in Sec. 3.2. More analysis of the flexibility of DYNAMICAL is in Sec. 3.3.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"First, we introduce the general description language of the dynamic evaluation protocol. Given a task $T$, a dynamic evaluation algorithm is formulated as $A_T = F(G(C))$, where\\n\\n1. $G$ is the sample generation algorithm, incorporating randomness to guarantee uniqueness of each sample. Randomness may vary in different tasks, such as the numbers in math problems and the logic chains in a logic reasoning task.\\n2. $C = \\\\{C_T, C_G\\\\}$ denotes constraints on $G$, where $C_T$ is the task constraint for task $T$, such as the legality guarantee of the generated samples in the context of the task. $C_G$ is the complexity constraint for the generation process, such as the sampling strategy for the value at each node and the number of perturbations added to the evaluation samples.\\n3. $F = \\\\{F_T, F_G\\\\}$ is the description function to translate the raw evaluation samples generated by $G$ into natural language descriptions. $F_G$ elucidates the characteristics and properties of the samples generated by $G$. $F_T$ is the description for task $T$ such as task objective and expected outcomes.\\n\\nIn general, an evaluation sample can be represented as $d_{eval} = F_T(F_G(G(C_G, C_T)))$ using the above description language. $G$ first produces a sample that adheres to the complexity constraint $C_G$ and the task constraint $C_T$. Then it undergoes transformation by description function $F_G$ into a natural language format and finally goes through the task description function $F_T$. The description language above naturally (1) avoids data contamination by dynamic generation through $G$, and (2) promises dynamic datasets and controllable complexity through $C$. Specifically, by varying the constraints in $C$, we can generate evaluation samples of different difficulties, allowing \\\"co-evolution\\\" of both the LLMs and the evaluation process. The description language is flexible since it allows for different generation algorithms and complexity control by changing $G$ and $C$ accordingly.\\n\\n### 3.2 Graph-informed Dynamic Evaluation for Reasoning Tasks\\n\\nIn this section, following the general evaluation description language, we implement DYVAL for reasoning tasks by taking inspiration from the graph structure. Given the intrinsic multistep inferential nature of reasoning tasks, they inherently exhibit structural characteristics, making directed acyclic graphs (DAGs) a natural choice for modeling these tasks. DAGs also facilitate dynamic sample generation by modulating the internal structure and fine-grained control over problem difficulty by adjusting the structural complexity. More background of DAGs can be found in Appendix A.\\n\\n#### 3.2.1 Generation Algorithm $G$: DAG Construction\\n\\nThe generation algorithm is established on the graph construction process. We categorize DAGs as Tree-based DAGs (T-DAGs) and General DAGs (G-DAGs), illustrated in Figure 1. T-DAGs are inherently hierarchical, making them suitable for tasks that proceed from a set of initial premises to...\"}"}
{"id": "gjfOL9z5Xr", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: Three types of reasoning tasks generated by DYNAMICAL.\\n\\n| Field          | Task Generationalgorithm | Constraint | # Classes | Description                          |\\n|---------------|--------------------------|------------|-----------|--------------------------------------|\\n| Mathematics   | Arithmetic Tree-based    |            |           | Depth, Width, Extra links, Random desc |\\n|               |                          |            |           | What is the value of [Root]?          |\\n| Logical       | Bool Tree-based          |            |           | Depth, Width, Extra links, Random desc |\\n|               |                          |            |           | What is the value of [Root]?          |\\n| Deductive     | Deductive Tree-based     |            |           | Depth, Width, Extra links, Random desc |\\n|               |                          |            |           | What is the value of [Root]?          |\\n| Abductive     | Abductive Tree-based     |            |           | Depth, Width, Extra links, Random desc |\\n|               |                          |            |           | Given [Root] is [Value], what is the value of [Leaf i]? |\\n\\nDAGs can be seen as a new way to construct complex tasks in a modular way. For instance, a final inference, such as arithmetic problems and logical reasoning tasks, is made possible through concatenation of all the individual building blocks. These subproblems are chained by the links between nodes and finally form a complex problem. Conversely, G-DAGs excel in mapping intricate relationships, especially in tasks demanding understanding of non-linear interactions. They are ideal for algorithmic challenges involving complex dependencies. For instance, imagine modeling a system where a change in one entity might impact multiple others in a cascading fashion, or tasks require finding different potential pathways between entities. The generation process for these two types of DAGs are presented in Appendix B.1.\\n\\nRandomness in DAGs generation process. T-DAG randomness arises from operations assigned to the nodes and the initial values of the leaf nodes. For instance, in arithmetic, the operation can be \\\"+\", with the leaf nodes receiving random numbers. On the other hand, for G-DAGs, each node is endowed with a random value (if needed for a certain problem). For every node, the number of children is determined randomly, and the maximum number of children depends on the input. We then establish the links by selecting the target child nodes at random.\\n\\nTheorems 3.1 and 3.2 formally guarantee the dynamic generation process by exploring the probability that two samples generated by T-DAG and G-DAG are identical. We focus exclusively on the base case, setting aside additional complexities like the integration of random links or the embedding of random descriptions, which would further diminish the likelihood of two DAGs being identical.\\n\\n**Theorem 3.1.** Given a tree-based DAG with depth $d$ and width $w$, if the operation set for non-leaf nodes has $k$ distinct operations and the value set for leaf nodes contains $n$ distinct values, the probability that two independently generated DAGs are identical is:\\n\\n$$P = \\\\frac{k\\\\cdot d}{-1} \\\\cdot \\\\frac{1}{w-1} \\\\cdot \\\\frac{n\\\\cdot w}{d-1}.$$\\n\\n**Theorem 3.2.** Given a general DAG with $n$ nodes where each node has a minimum of $l \\\\geq 1$ links, the probability that two randomly selected DAGs are identical is bounded by $\\\\frac{1}{(n-1)!}$.\\n\\nProofs can be found in Appendix C. These theorems guarantee that the odds of producing identical evaluation samples are considerably low. For instance, in the arithmetic task (where $k = 6$, $n = 10$) with $d = 4$ and $w = 2$, the chances that two DAGs are identical hover around $1 \\\\times e^{-15}$.\\n\\n### Constraints\\n\\n**Task constraints $CT$.** Task constraints vary for tasks. Take the node creation for instance: 1) What distribution should the node value adhere to? 2) What set of operations is permissible? 3) How should a node's value be computed from its children's values? In arithmetic tasks, $CT$ includes ensuring that a dividend is nonzero, avoiding overflow, etc. Here, we concentrate on two general task constraints: (1) **Value distribution $V$:** Specifies the permissible range or distribution from which leaf node values can be assigned. For example, in logic reasoning tasks, the premises (leaf nodes) are assigned either as True or False. (2) **Operation set $O$:** Lists the operations allowed within the DAG. The operation set constraint is usually used for tree-based DAGs. For example, in an arithmetic task, the set of allowed operations can be defined as the basic arithmetic operations \\\\{+, \u2212, \u00d7, \u00f7\\\\}.\\n\\n### Complexity constraints $CG$\\n\\nWe investigate 4 techniques to inject complexity into DAGs (Figure 5): (1) Change width and depth for T-DAGs: The natural way to control tree complexity. (2) Change number of nodes and links for G-DAGs: We control the total number of nodes in G-DAGs. The number of children of each node can be randomly chosen, limited by the maximum number of children allowed by the input.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: Descriptions of 7 tasks.\\n\\nB.5 POTENTIALS IN USING GPT-4 TO GENERATE DESCRIPTION FUNCTIONS\\n\\nIn this section, we explore the potentials in using GPT-4 to generate more natural and contextualized problem descriptions rather than the plain ones in Section B.3.\\n\\nWe simply feed the following instruction to GPT-4: \u201cHere is a description of an arithmetic problem, please generate an application math test using the following information. Do not change the exact numbers. Note that the test should be contextualized, real applications test, instead of the plain description.\u201d followed by the DYVAL-generated problems such as the one in DYVAL-M.\\n\\nThen, GPT-4 will generate the following application problem which is more vivid:\\n\\nProblem: Imagine you are managing a small warehouse. The warehouse has a total storage capacity of 9 large crates (represented by \u2018aaa\u2019). You also have an additional area that can store 3 more crates (represented by \u2018aab\u2019). Recently, you purchased a set of 4 special crates (represented by \u2018aad\u2019) that are stackable. When stacked, these crates take up the space of 2 regular crates.\\n\\nYour task is to calculate the new total storage capacity of your warehouse after adding the stackable crates and utilizing the additional storage area.\\n\\nSteps:\\n- Identify the total initial capacity (aaa).\\n- Identify the additional capacity (aab).\\n- Calculate the effective space taken by the stackable crates (aae) - consider them as a single unit after stacking.\\n- Calculate the new total capacity by adding the initial and additional capacities (aac).\\n- Finally, adjust the total capacity by considering the space taken by the stackable crates (aaf).\\n\\nQuestion: What is the new total storage capacity of the warehouse after these adjustments?\\n\\n(Use the given values and operations to solve the problem)\"}"}
{"id": "gjfOL9z5Xr", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"While the above application problem looks more vivid than the plain one, it is in fact challenging to verify its rationale and correctness. For instance, is the problem natural? Is the context correct?\\n\\nNote that GPT-4 tends to first compute the answers to the original problem before generating a new one, which may accumulate errors including problem understanding, application generation, and computation. Therefore, while we point the feasibility of such practice, this in current stage is difficult to verify and should be left for future work.\\n\\nTheorem C.1. Given a tree-based DAG with depth $d$ and width $w$, if the operation set for non-leaf nodes has $k$ distinct operations and the value set for leaf nodes contains $n$ distinct values, the probability that two independently generated DAGs are identical is:\\n\\n$$P = \\\\frac{k}{w^{d-1}} \\\\times \\\\frac{1}{w^{d-1}} \\\\times \\\\frac{n}{w^{d-1}}.$$ \\n\\nProof. To determine the overall probability, we analyze the likelihood at each depth and then multiply these probabilities. For depth $i$, the number of nodes is $w^{i-1}$. For depth $i$, $1 \\\\leq i \\\\leq d - 1$. Since these nodes are non-leaf nodes, the probability they are identical in two independently generated DAGs is the likelihood all of them have the same operations: $p_i = \\\\frac{1}{k w^{i-1}}$.\\n\\nFor the leaf nodes at depth $d$, the probability that they are the same across two DAGs is: $p_d = \\\\frac{1}{n w^{d-1}}$.\\n\\nThus, the overall probability $P$ that two DAGs are identical is:\\n\\n$$P = \\\\prod_{i=1}^{d-1} p_i \\\\times p_d.$$ \\n\\nSubstituting the above expressions and simplifying gives the result:\\n\\n$$P = \\\\frac{k}{w^{d-1}} \\\\times \\\\frac{1}{w^{d-1}} \\\\times \\\\frac{n}{w^{d-1}}.$$ \\n\\nNote: We consider two trees to be distinct even if they only differ in the order of operations. For instance, the tree representing $3 \\\\times 5$ is considered different from the tree representing $5 \\\\times 3$. Excluding such cases may be non-trivial and is unlikely to significantly affect the odds.\\n\\nTheorem C.2. Given a general DAG with $n$ nodes where each node has a minimum of $l \\\\geq 1$ links, the lower bound of the probability that two randomly selected DAGs of this configuration are identical is $(\\\\frac{n-1}{n})!$.\\n\\nProof. Consider a DAG where each node has exactly one outgoing link. The first node can be connected to any of the remaining $n - 1$ nodes. Subsequently, the second node can connect to any of the remaining $n - 2$ nodes, excluding the one already connected to the first node. Following this logic, the third node can connect to any of the $n - 3$ unconnected nodes, and so on.\\n\\nThus, the total number of distinct DAGs that can be constructed under these constraints is given by:\\n\\n$$(n-1) \\\\times (n-2) \\\\times . . . \\\\times 2 \\\\times 1 = (n-1)!.$$ \\n\\nGiven two randomly chosen DAGs of this kind, the likelihood they are identical is the inverse of the number of unique DAGs:\\n\\n$$1 \\\\times (n-1)!$$\\n\\nThis probability serves as the lower bound when considering the general case of DAGs with nodes having a minimum of $l \\\\geq 1$ links, hence proving the theorem.\\n\\nDetails of Experiments\\n\\nAll experiments are conducted on a workstation equipped with an NVIDIA V100 GPU with 16GB memory and A100 GPU with 80GB memory. For GPT-3.5-Turbo and GPT-4, we use OpenAI's...\"}"}
{"id": "gjfOL9z5Xr", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"API for inference, the versions are gpt-3.5-turbo-0613 and gpt-4-0613. For the Llama2 models, we downloaded from the Llama2 github repository and follow the instruction to convert them into huggingface models. For Vicuna-13B-v1.3, we downloaded it from its github repository. The remaining models can be downloaded directly via huggingface.\\n\\nD.2 PROMPTS\\n\\n\u2022 Arithmetic:\\nHere is a description of an arithmetic problem: {} Compute the result of {}. If the solution cannot be calculated, answer 'N/A'. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\\n\\n\u2022 Linear Equation:\\nGiven the following linear equation system with two variables: {} Determine the values of x and y. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x's value y's value>>>, e.g., if x=1 and y=2, then it should be <<<1 2>>>\\n\\n\u2022 Boolean Logic:\\nHere is a description of a boolean logic problem: {} Compute the result of {}. If the solution can not be calculated, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\n\u2022 Deductive Logic:\\nHere is a description of a deductive logic problem: {} The symbol '->' represents a deductive relationship, e.g., A -> B implies that if A is true, then B is true. If A is false, B's truth value remains undetermined (N/A). Deduce the result of {}. If the solution can not be deduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\n\u2022 Abductive Logic:\\nHere is a description of an abductive logic problem: {} The symbol '->' represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A's truth value remains undetermined (N/A). Deduce the result of {}. If the solution can not be deduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"D.3 E VALUATION SET\\n\\nWe categorize tasks into four complexity levels, denoted as D1 to D4. For tasks reliant on general Directed Acyclic Graphs (DAGs), the node count is set to $7, 10, 15, 20$. Each of these nodes possesses a maximum link range of $3, 4, 6, 8$ and a minimum link count of $1$. Conversely, for tasks that utilize tree-based DAGs, the tree depths and widths are defined as $(2, 2), (3, 2), (3, 3), (4, 2)$, in order of increasing complexity.\\n\\nThe range of these datasets progresses from simple to intricate. To illustrate, an arithmetic problem with a tree depth of 2 represents a basic two-variable arithmetic computation. In contrast, a task with a tree depth of 4 exhibits heightened complexity, necessitating multiple inferential steps for resolution.\\n\\nD.4 DETAILS OF EXPERIMENT RESULTS\\n\\nWe do not report the results of Flan-T5-large, phi-1.5, WizardMath-13B, and Xwin-13B since their performance is almost 0 even on simplest evaluation sets generated by our DYVAL. Therefore, we extensively run the results of four remaining models: Vicuna-13B-v1.3, Llama2-13B-chat, GPT-3.5-Turbo, and GPT-4. Table 2, 3, and 4 report the detailed results (average \u00b1 standard error) of these models in different complexity (D1 \u223c D4) and different description generation orders (topological, reversed topological, and random orders).\\n\\nIn the reachability task, as task difficulty escalated, Llama2-13B-chat's performance paradoxically improved. Upon investigation, Llama2-13B-chat essentially resorted to random guessing across datasets. The proportion of 'True' answers increased (from 40% in D1 to 60% in D3), with 'False' responses being nearly absent. The remainder were non-responses, thus elevating the overall accuracy. The observation is similar to those made in Sec.4.4 where we investigated the influence of different model size.\\n\\nFurther, generation description order affects outcomes: in the reachability task, GPT-4's accuracy drops by 13.67% when given reversed order compared to topological order. See Appendix D.4 for details of experiment results.\\n\\nD.5 DETAILS OF CASE STUDY\\n\\nWe select 20 failure cases of the most challenging datasets of arithmetic, deductive logic, abductive logic, and reachability of GPT-4.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"number of links in each node is randomly selected from a predefined range, e.g., $[1, 5]$. (3)\\n\\nAdd extra random links: For each node, we may introduce an additional link to another random node. (4)\\n\\nEmbed random descriptions: Add random descriptions to the primary DAG's descriptions. More details of complexity can be found in Appendix B.2 with Figure 7 as illustrations.\\n\\n3.2.3 Description Function $F$\\n\\nAfter constructing DAGs with certain constraints, we then need to convert them into comprehensible natural language descriptions using the description function $F_D$. We describe the DAG node by node and then form the description of the nodes into sequences. The interpretation of each node in natural language depends on its position and the task. For leaf nodes that represent primary input or premises, they can be described as: \\\"The value of [Name] is [Value].\\\" For instance, a node denoting number 5 could be expressed as: \\\"The value of node A is 5.\\\" For T-DAGs, the intermediate nodes that typically denote operations performed on their child nodes, the description can be formulated as: \\\"The value of [Name] is derived by [Operation] the values of [Children's Names].\\\" For G-DAG, the intermediate nodes are usually described as the connections between nodes: \\\"The [Name] points to [Children's Names].\\\" Note that natural language descriptions can be replaced according to custom needs and can be further incorporated with textual adversarial attacks (Li et al., 2019; Gao et al., 2018; Jin et al., 2020; Li et al., 2020).\\n\\nMoreover, complexity is also influenced by the order that nodes are described. We design three orders: topological, reversed topological, and random orders, each offering a unique challenge in understanding the DAGs. The details of these orders are presented in Appendix B.4.\\n\\nTask description function $F_T$.\\n\\nThe construction of $F_T$ highly depends on the context of tasks. Noteably, this construction is also highly flexible. For instance, incorporating adversarial prompts (Zhu et al., 2023) to the task description can make problems more difficult. Here we present the task description function for arithmetic and reachability tasks that are representative of T-DAG and G-DAG, respectively. Appendix B.3 presents details and examples of the remaining 5 tasks.\\n\\nArithmetic:\\n\\nGiven a T-DAG, the DAG description function has already demonstrated the premise: the leaf nodes and the intermediate steps of inference: non-leaf nodes. Next, we select the root node as the variable required to solve, we append the question \\\"What is the value of [Root]?\\\" to the description where [Root] is filled with the name of the root variable (Figure 8).\\n\\nReachability:\\n\\nThe reachability task aims to model if two nodes are connected in a graph. For a G-DAG, the DAG description function has demonstrated the connections between nodes. The task description for reachability task is: \\\"Can the $Node_i$ be reached by $Node_j$\\\" where $Node_i$ and $Node_j$ are randomly selected from the nodes in G-DAG (Figure 9).\\n\\nFinally, while it is feasible to directly adopt GPT-4 to generate a contextualized description rather than the plain one (see Appendix B.5), it is challenging to verify the rationale of the problems generated by GPT-4. Thus, we leave it for future work.\\n\\n3.3 Diversity and Co-evolves with Existing Benchmarks\\n\\nDIV is complementary to existing benchmarks. First, tasks with an intrinsic structure benefit significantly from DIV since they can modulate complexity and randomness by adjusting the generation process. Efforts such as CheckList (Ribeiro et al., 2020), data augmentation (Andreas, 2020; Zhang et al., 2022), and reasoning dataset synthesis (Sinha et al., 2019; Zhao et al., 2019; Clark et al., 2020; Tian et al., 2021; Jin et al., 2023) can be easily integrated into DIV. On the contrary, tasks without a well-defined structure may present challenges for DIV\u2019s implementation. Second, DIV can be enhanced by existing benchmarks to formulate more challenging scenarios. For instance, the description function $F$ is all about natural language texts, so it can be easily combined with adversarial attacks (Li et al., 2019; Jin et al., 2020; Zhu et al., 2023) or out-of-distribution prompts (Yang et al., 2023a) to assess the robustness of LLMs.\\n\\nNote that while this paper focuses on evaluating reasoning tasks, DIV is flexible to evaluate natural language tasks. We show an initial study using DIV to evaluate sentiment analysis in Appendix H and more work can be done in the future. Finally, DIV guarantees an unbiased and...\"}"}
{"id": "gjfOL9z5Xr", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Results on 7 tasks with complexity from D1 to D4 (averaged on 3 description orders and 3 seeds). Xwin-13B, phi-1.5, and WizardMath-13B are not shown as their results are all 0.\\n\\n4 EXPERIMENT\\n\\n4.1 SETUP\\n\\nTasks and complexity level.\\n\\nWe mainly discuss the constraint used in each task. Test set accuracy might differ as it is generated dynamically. To balance test time and discrepancy, we produce 500 samples for each dataset. To mitigate the impact of randomness on evaluation results, we assess each dataset three times. We define 4 complexity levels (D1 \u223c D4) for each task. For tasks that use general DAGs, the number of nodes is set to \\\\{7, 10, 15, 20\\\\} with each node having \\\\{3, 4, 6, 8\\\\} maximum links and 1 minimum link. For tasks that use tree-based DAGs, tree depths and widths are \\\\((2, 2)\\\\), \\\\((3, 2)\\\\), \\\\((3, 3)\\\\), \\\\((4, 2)\\\\), respectively. More details of D1 \u223c D4 are presented in Appendix D.\\n\\nEvaluation metric.\\n\\nOur primary evaluation metric is accuracy. For tasks where answers are numerical, we employ relative precision (Burden et al., 2015) to determine the correctness of a prediction, i.e., an answer is deemed correct if its relative precision is within a specified threshold, \\\\(\\\\sigma\\\\) (e.g., 0.01%), in relation to the ground truth value. Relative precision is calculated as\\n\\n\\\\[\\n\\\\frac{|\\\\text{pred} - \\\\text{gt}|}{\\\\text{gt} + \\\\epsilon} \\\\leq \\\\sigma\\n\\\\]\\n\\nwhere \\\\(\\\\text{gt}\\\\) represents the ground truth value, \\\\(\\\\text{pred}\\\\) is the model's prediction, \\\\(| \\\\cdot |\\\\) is the absolute value function, \\\\(\\\\sigma\\\\) is the desired relative precision threshold, and \\\\(\\\\epsilon\\\\) is a small value introduced to prevent division by zero.\\n\\nLLMs.\\n\\nOur evaluated LLMs include Flan-T5-large (Chung et al., 2022), phi-1.5 (Li et al., 2023d), WizardMath-13B (Luo et al., 2023), Xwin-13B (Team, 2023), Llama2-13B-chat (Touvron et al., 2023), Vicuna-13B-v1.3 (Chiang et al., 2023), GPT-3.5-Turbo (OpenAI, 2023a), and GPT-4 (OpenAI, 2023b). Temperature is set to 0 to avoid randomness. We set the generation length to be directly proportional to the input length. Specifically, for GPT-3.5-Turbo and GPT-4, the generate length is set to be twice the input length; for the remaining models, it is set to be five times the input length.\\n\\nWe designed prompts for each task, incorporating demonstrations of rules, particularly for reasoning and algorithm tasks. To ensure formatted output, we further ask LLMs to explicitly output their predictions between \\\"\u27e8\u27e8\u27e8\\\" and \\\"\u27e9\u27e9\u27e9\\\". All implementations are based on Huggingface.\\n\\n4.2 RESULTS FOR MATH, LOGICAL REASONING, AND ALGORITHM TASKS\\n\\nBefore presenting the main results, note that the results of Flan-T5-large, phi-1.5, WizardMath-13B, and Xwin-13B in all tasks are 0, so we no longer report them. We carried out experiments using three random seeds. Figure 2 shows the results of all tasks averaged in three generation orders and three random seeds (full results in Appendix D.4). GPT-4 performs best, followed closely by GPT-3.5-Turbo. Llama2-13B-chat's performance is subpar, with Vicuna-13B-v1.3 occasionally outperforming Llama2-13b-chat. More findings are as follows.\\n\\nInconsistent performance between existing static benchmarks and DYNAMICAL VAL:\\\\n\\nDespite the excellent results of phi-1.5, Xwin-13B and WizardMath-13B on existing benchmarks, their poor performance in our evaluations highlights the potential problems when evaluating LLMs solely on static benchmarks and possible low training data quality or data contamination issue.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Difficulty with complex datasets:\\n\\nPerformance mostly decreases sharply from D1 to D4, highlighting LLMs' struggles with increasing complexity. For example, GPT-3.5-Turbo's performance drops by 23% for arithmetic task as complexity increases. Notably, performance in abductive logic (inferring premises from conclusions) is much lower than in deductive logic (deriving conclusions from premises), as supported by Berglund et al. (2023), which shows LLMs excel more in \\\"A is B\\\" than \\\"B is A\\\". In addition, the performance difference between GPT-4 and GPT-3.5-Turbo, while subtle in simpler tasks like D1, becomes prominent in complex tasks. These observations indicate the value of intricate and evolving tasks to effectively differentiate and evaluate models. We also present more interesting observations in Appendix D.4.\\n\\nHuman study:\\n\\nWe recruited 82 human evaluators, to gauge their skills against LLMs on the most complex dataset (D4) for mathematical and logical reasoning tasks. Each participant tackled 5 problems from each dataset. As depicted in Figure 3, both GPT-4 and GPT-3.5-Turbo consistently showed high competence in most tasks, surpassing average human results. The reason could be that the generated problems are generally harder for humans but easier for LLMs. Nevertheless, GPT-4 struggled in areas like linear equations and abductive logic. This indicates that future development could involve more data from specific domains.\\n\\n4.3 CASE STUDY\\n\\nPartial calculation error:\\n\\nGPT-4 occasionally errs in intermediate steps, while keeping the remaining steps correct. We emphasize that the errors may be as simple as $20/7 = 2.857$. This aligns with (Dziri et al., 2023) noting LLMs sometimes give partially correct multi-digit multiplication results.\\n\\nIncorrect reasoning and self contradiction:\\n\\nIn reasoning tasks, GPT-4 may misinterpret rules. Given an abductive logic $A \\\\lor B \\\\rightarrow C$ with $C$ is False, the premise $A, B$ must be False. However, GPT-4 inaccurately abduced that either $A$ or $B$ might be False. Further, GPT-4 occasionally contradicts itself in its assumptions for the same inference in abductive logic task.\\n\\nUnsubstantiated response:\\n\\nIn reasoning tasks and algorithm tasks, GPT-4 often answers without any inferences or justifications. Its answer-only responses suggest possible memorization or shallow understanding.\\n\\nInstructional oversight:\\n\\nOccasionally, GPT-4 adeptly arrives at the correct computation but stumbles when it comes to adhering to the output instructions laid out in prompts, for example, the required relative precision of mathematic calculation.\\n\\n4.4 ABALATION STUDY\\n\\nImpact of complexity constraints $C_G$:\\n\\nIn Figure 5, we vary complexity in GPT-3.5-Turbo by adjusting constraints as described in Sec. 3.2.2 and observe how LLMs performance shifts across arithmetic, boolean logic, and deductive logic tasks. Notably, as task intricacy rises due to augmented complexity parameters, LLMs' performance diminishes. Depth emerges as the predominant challenge in tree-based DAGs, emphasizing the LLMs' difficulty with extended inference steps.\\n\\nPrompt engineering:\\n\\nWe evaluate five prompting techniques (PE) on our most challenging datasets, as outlined in Table 5 and Appendix D.7. No PE methods can perform best in all tasks. While APE notably boosts the Linear Equation task by 10%, it negatively impacts deductive and abductive logic. These varied outcomes highlight the importance of task-specific PE selection and development.\\n\\nThe results may not represent the highest level of human performance. Demographics are in Appendix D.8.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A conference paper discusses the influence of model size on the performance of Llama2 in arithmetic, boolean logic, and reachability tasks. Table 6 shows that larger model sizes produce better results but still do not surpass GPT-4 and human performance. The paper further evaluates the performance of Llama2 with different model sizes and demonstrates that DYV generated data can be utilized to fine-tune LLMs to improve their capabilities of solving complex tasks. The fine-tuned model shows increased performance in all tasks, suggesting that DYV is effective not only as a benchmark but also in enhancing the performance of LLMs on existing benchmarks via fine-tuning on its generated samples.\\n\\nThe paper concludes with several limitations, including the focus on reasoning tasks, the use of a limited set of test samples due to resource constraints, and the need for fine-tuning on more diverse models and datasets to gain deeper insights.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"since we need to constrain the naturalness and grammar correctness of the generated sentences. As a remedy, the structure of the graph can be abstracted using the template sentences generated by GPT-3.5-Turbo. We generate three alternative versions for each sentence in the above process, forming our newly generated dataset. We then evaluate the performance of both Flan-T5-large and Llama2-7b models, using the original SST-2 dataset as well as our generated dataset for comparison. The results of these evaluations are detailed in Table 10. It shows that using our generated samples, the performance drops, indicating that we are creating challenging test sets. Note that this is an initial study and extending DyVal to NLP tasks is nontrivial that cannot be covered in this paper, but should be left for future work.\\n\\n|               | Flan-T5-large | Llama2-7b |\\n|---------------|---------------|-----------|\\n| Origin        | 93.12         | 90.37     |\\n| DyVal         | 86.46         | 72.03     |\"}"}
{"id": "gjfOL9z5Xr", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACKNOWLEDGEMENT AND DISCLAIMER\\n\\nThe purpose of this research is to present a dynamic and evolving evaluation protocol in response to the rapid development of LLMs. We have the following claims. First, the generation mechanism of DYVAL does not contain any potentially harmful words or expressions but only mathematical, logical, and algorithmic descriptions. In the future, the usage of DYVAL on other natural language tasks should be dealt with cautions to not include any harmful or irresponsible languages. Second, human subjects are involved in this study to act as LLMs' competitors for performance comparison and analysis. All human studies are conducted obeying laws and regulations in certain countries. Third, the experiments on GPT-3.5-Turbo and GPT-4 conducted in this paper are based on their latest version in June, 2023. Authors recommend using the same version of these services for reproducibility. As we tried our best to tune the best prompts for our experiments, it is, however, well-known that LLMs are highly sensitive to prompts. Therefore, the experiments in this paper are only based on our prompt design and codebase. Finally, we may have concluded that some LLMs in this paper achieved poor performance in our benchmark, but this does not mean these models are not good or cannot be used in practice. Authors remain positive and optimistic to all evaluated LLMs that they will further be stronger.\\n\\nREFERENCES\\n\\nAho Alfred V, Lam Monica S, Sethi Ravi, Ullman Jeffrey D, et al. Compilers-principles, techniques, and tools. Pearson Education, 2007.\\n\\nJacob Andreas. Good-enough compositional data augmentation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7556\u20137566, Online, July 2020.\\n\\nAssociation for Computational Linguistics.\\n\\nDevansh Arpit, Stanislaw Jastrzkebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maximder S. Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, and Simon Lacoste-Julien. A closer look at memorization in deep networks. In Proceedings of the 34th International Conference on Machine Learning, volume 70, pp. 233\u2013242, 06\u201311 Aug 2017.\\n\\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023, 2023.\\n\\nBIG bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research, 2023. ISSN 2835-8856.\\n\\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? FAccT 2021, pp. 610\u2013623, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450383097.\\n\\nLukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. The reversal curse: Llms trained on \\\"a is b\\\" fail to learn \\\"b is a\\\". arXiv preprint arXiv:2309.12288, 2023.\\n\\nStella Biderman, USVSN Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin Anthony, Shivanshu Purohit, and Edward Raf. Emergent and predictable memorization in large language models. arXiv preprint arXiv:2304.11158, 2023.\\n\\nNathan Brody. What is intelligence? International Review of Psychiatry, 11(1):19\u201325, 1999.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.\\n\\nS\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "gjfOL9z5Xr", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022.\\n\\nYuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, et al. C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models. arXiv preprint arXiv:2305.08322, 2023.\\n\\nHuggingFace. Open-source large language models leaderboard. https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard, 2023.\\n\\nDi Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. Is bert really robust? a strong baseline for natural language attack on text classification and entailment. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pp. 8018\u20138025, 2020.\\n\\nZhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona Diab, and Bernhard Sch\u00f6lkopf. Can large language models infer causation from correlation? arXiv preprint arXiv:2306.05836, 2023.\\n\\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks. In The Eleventh International Conference on Learning Representations, 2022.\\n\\nDouwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and Adina Williams. Dynabench: Rethinking benchmarking in NLP. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4110\u20134124, June 2021.\\n\\nDan Klein and Christopher D Manning. Accurate unlexicalized parsing. In Proceedings of the 41st annual meeting of the association for computational linguistics, pp. 423\u2013430, 2003.\\n\\nJan Koc\u00f3\u0144, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek, Dominika Szyd\u0142o, Joanna Baran, Julita Bielaniewicz, Marcin Gruza, Arkadiusz Janz, Kamil Kanclerz, et al. Chatgpt: Jack of all trades, master of none. Information Fusion, pp. 101861, 2023.\\n\\nBen Krause, Emmanuel Kahembwe, Iain Murray, and Steve Renals. Dynamic evaluation of neural sequence models. In International Conference on Machine Learning, pp. 2766\u20132775. PMLR, 2018.\\n\\nJinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang. TextBugger: Generating adversarial text against real-world applications. In Proceedings 2019 Network and Distributed System Security Symposium. Internet Society, 2019. doi: 10.14722/ndss.2019.23138.\\n\\nLinyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. BERT-ATTACK: Adversarial attack against BERT using BERT. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6193\u20136202, November 2020.\\n\\nMinghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank: A benchmark for tool-augmented llms. arXiv preprint arXiv:2304.08244, 2023a.\\n\\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following models. https://github.com/tatsu-lab/alpaca_eval, 2023b.\\n\\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Alpacaeval: An automatic evaluator of instruction-following models, 2023c.\\n\\nYuanzhi Li, S\u00e9bastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. Textbooks are all you need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463, 2023d.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "gjfOL9z5Xr", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Rylan Schaeffer. Pretraining on the test set is all you need. arXiv preprint arXiv:2309.08632, 2023.\\n\\nKoustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. CLUTRR: A diagnostic benchmark for inductive reasoning from text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4506\u20134515, Hong Kong, China, November 2019. Association for Computational Linguistics.\\n\\nXiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. Large language models are in-context semantic reasoners rather than symbolic reasoners. arXiv preprint arXiv:2305.14825, 2023.\\n\\nMichael T\u00e4nzer, Sebastian Ruder, and Marek Rei. Memorisation versus generalisation in pre-trained language models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 7564\u20137578, May 2022.\\n\\nXwin-LM Team. Xwin-lm, 2023. URL https://github.com/Xwin-LM/Xwin-LM.\\n\\nKrishnaiyan Thulasiraman and Madisetti NS Swamy. Graphs: theory and algorithms. John Wiley & Sons, 2011.\\n\\nJidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, and Yaohui Jin. Diagnosing the first-order logical reasoning ability through LogicNLI. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 3738\u20133747, November 2021.\\n\\nYuchi Tian, Kexin Pei, Suman Jana, and Baishakhi Ray. Deeptest: Automated testing of deep-neural-network-driven autonomous cars. In Proceedings of the 40th international conference on software engineering, pp. 303\u2013314, 2018.\\n\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko\u0142ay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\\n\\nOriol Vinyals, \u0141ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. Grammar as a foreign language. Advances in neural information processing systems, 28, 2015.\\n\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022.\\n\\nTianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang, Haihua Yang, Biye Li, Cheng Cheng, Weiwei L \u00fc, Rui Hu, et al. Skywork: A more open bilingual foundation model. arXiv preprint arXiv:2310.19341, 2023.\\n\\nZhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Aky \u00a8urek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim. Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. arXiv preprint arXiv:2307.02477, 2023.\\n\\nLinyi Yang, Shuibai Zhang, Libo Qin, Yafu Li, Yidong Wang, Hanmeng Liu, Jindong Wang, Xing Xie, and Yue Zhang. Glue-x: Evaluating natural language understanding models from an out-of-distribution generalization perspective. In Findings of ACL, 2023a.\\n\\nShuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph E Gonzalez, and Ion Stoica. Rethinking benchmark and contamination for language models with rephrased samples. arXiv preprint arXiv:2311.04850, 2023b.\\n\\nMatej Ze\u02c7cevi\u00b4c, Moritz Willig, Devendra Singh Dhami, and Kristian Kersting. Causal parrots: Large language models may talk causality but are not causal. Transactions on Machine Learning Research, 2023.\\n\\nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107\u2013115, 2021.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Le Zhang, Zichao Yang, and Diyi Yang. TreeMix: Compositional constituency-based data augmentation for natural language understanding. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 5243\u20135258, July 2022.\\n\\nYifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. Cumulative reasoning with large language models. arXiv preprint arXiv:2308.04371, 2023.\\n\\nJie Zhao, Xiang Deng, and Huan Sun. Easy-to-hard: Leveraging simple questions for complex question generation, 2019.\\n\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685, 2023.\\n\\nWanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. Agieval: A human-centric benchmark for evaluating foundation models. arXiv preprint arXiv:2304.06364, 2023.\\n\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. Lima: Less is more for alignment, 2023a.\\n\\nDenny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models. In ICLR, 2023b.\\n\\nKun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han. Don't make your llm an evaluation benchmark cheater. arXiv preprint arXiv:2311.01964, 2023c.\\n\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. In ICLR, 2023d.\\n\\nKaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. arXiv preprint arXiv:2306.04528, 2023.\\n\\nZeyuan Allen Zhu and Yuanzhi Li. Physics of language models: Part 3.1, knowledge storage and extraction, 2023.\\n\\nCaleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang. Can large language models transform computational social science? arXiv preprint arXiv:2305.03514, 2023.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Directed Acyclic Graphs, commonly referred to as DAGs, are a category of graphs that encapsulate a unique structure: they are directed and contain no cycles. In a DAG, vertices are connected by directed links, and there exists no sequence of links that loops back to an original node. Every link in a DAG has an initial node and a terminal node, giving it a direction. This is often symbolized as $a \\\\rightarrow b$, where $a$ is the starting node and $b$ is the ending node. A key property that differentiates DAGs from other directed graphs is their lack of cycles. In other words, starting from any node in the graph, one cannot traverse a series of links and return to the same node.\\n\\nIn our implementation, each node comprises three attributes: 1) Children (Links): These are the direct dependents or subsequent nodes that a given node connects to. They highlight the immediate\"}"}
{"id": "gjfOL9z5Xr", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"relations or following a particular node. 2) Value: Every node possesses a value, which can either be explicitly assigned or derived based on its operation and its children. This value captures the essence or result of the represented subproblem. 3) Operation: Especially relevant in tree-based DAGs, the operation dictates how a node interprets or processes the values of its children to compute its own value. Operations might include mathematical functions, logical evaluations.\\n\\n### B.1 Generation Algorithm\\n\\nWe distinguish DAGs into two primary categories: Tree-based DAGs (T-DAGs) and General DAGs (G-DAGs), as shown in Figure 1.\\n\\n#### B.1.1 T-DAG\\n\\nTree-based DAGs possess an innate hierarchical structure that frequently encapsulate tasks that entail a sequence of conditions culminating in a definitive conclusion or result. This hierarchy naturally aligns with the structure of many mathematical and logical problems. For instance, in solving a multi-step algebraic problem, one often starts with the provided equations (leaf nodes) and proceeds step-by-step, combining and reducing these equations until arriving at the final solution (root node). Such a natural progression of deduction makes tree-based DAGs particularly feasible for these problems.\\n\\nWe employ a top-down approach to construct a Tree-based DAG. This algorithm is tailored to produce a tree with a designated depth and width. The inherent randomness stems from two main factors: the operations assigned to intermediate nodes and the initialization values of the leaf nodes. For the intermediate nodes, we commence by randomly selecting an operation that defines the relationship between the node and its children. Take an arithmetic task as an example: selecting 'addition (+)' implies that the node's value is the sum of its children's values. Once all child nodes are established, we compute the parent node's value accordingly. In the case of leaf nodes, values are assigned randomly, such as picking an integer from the range $[1, 10]$ for arithmetic tasks.\\n\\n#### B.1.2 G-DAG\\n\\nGeneral DAGs, diverging from tree-based ones, lack a strict hierarchy. Instead, they present a more intricate web of node relationships. Their strength lies in simulating complex, intertwined relations in real-world situations. A classic use-case is the representation of transportation systems where nodes symbolize cities and edges represent connecting roads. Challenges such as determining if one city is accessible from another encapsulate the real-world problems general DAGs adeptly model.\\n\\nTheir flexibility extends to representing a plethora of situations, from mapping supply-chain logistics to analyzing social networks.\\n\\nTo create a general DAG, we initiate by generating isolated nodes without any connecting links. Subsequently, each node is endowed with a random value. For every node, the number of children is determined randomly, the maximum number of children is depended on the input. We then establish the links by selecting target child nodes at random.\\n\\n### B.2 Complexity Control\\n\\nFigure 7 demonstrated 4 types of complexity constraints for T-DAGs. Compared to original case, adding width and additional links augments the computational intricacy of each subproblem. Increasing the depth escalates the complexity by necessitating more inference steps. Embedding random descriptions aims to distract LLMs.\\n\\n### B.3 Description Function\\n\\nFigure 9 presented an illustration of our generated 7 tasks in 3 subjects: (1) Mathematics (D-YAL-M), which includes arithmetic task and linear equation task; (2) Logical Reasoning (D-YAL-L),\"}"}
{"id": "gjfOL9z5Xr", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Here we present one failure case for each error type. The realm of multi-digit multiplication.\\n\\nLearning models (LLMs) occasionally produce results that are only partially accurate, particularly in seemingly straightforward calculations such as can be incorrectly computed. This observed behavior\\n\\n| Task        | Dataset | GPT4 | ChatGPT | Llama2-13b-chat | Vicuna-13b-v1.3 |\\n|-------------|---------|------|---------|----------------|-----------------|\\n| D1          |         |      |         |                |                 |\\n| D2          |         |      |         |                |                 |\\n| D3          |         |      |         |                |                 |\\n| D4          |         |      |         |                |                 |\\n\\n| Topo Reversed | Rand | Topo Reversed | Rand | Topo Reversed | Rand | Topo Reversed | Rand |\\n|---------------|------|---------------|------|---------------|------|---------------|------|\\n|               | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1    |\\n\\n| \u00b1            | \u00b1    | \u00b1             | \u00b1    | \u00b1             | \u00b1"}
{"id": "gjfOL9z5Xr", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"aae gets its value by dividing the value of aac by those of aad.\\n\\naaf gets its value by dividing the value of aab by those of aae.\\n\\naao gets its value by adding together the value of aaf and aan.\\n\\nCompute the result of aao. If the solution cannot be calculated, answer 'N/A'. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\\n\\nGPT-4's response:\\n\\nFirst, let's calculate the values step by step:\\n\\n\\\\[ aaj = 7 \\\\]\\n\\\\[ aak = aaj^2 = 49 \\\\]\\n\\\\[ aah = 6 \\\\]\\n\\\\[ aag = 2 \\\\]\\n\\\\[ aai = \\\\frac{aag}{aah} = \\\\frac{2}{6} = 0.3333 \\\\]\\n\\\\[ aan = aai \\\\times aak = 0.3333 \\\\times 49 = 16.3167 \\\\] (should be 16.3317)\\n\\\\[ aaa = 6 \\\\]\\n\\\\[ aab = aaa^2 = 36 \\\\]\\n\\\\[ aac = 8 \\\\]\\n\\\\[ aad = 1 \\\\]\\n\\\\[ aae = \\\\frac{aac}{aad} = \\\\frac{8}{1} = 8 \\\\]\\n\\\\[ aaf = \\\\frac{aab}{aae} = \\\\frac{36}{8} = 4.5 \\\\]\\n\\\\[ aao = aaf + aan = 4.5 + 16.3167 = 20.8167 \\\\]\\n\\nSo, the result of aao is 20.8167.\\n\\nTherefore, the final result is <<<20.8167>>>.\\n\\nGround truth:\\n\\n20.8333\\n\\nIncorrect reasoning\\n\\nWhen tasked with reasoning, GPT-4 can occasionally falter in rule interpretation, especially in abductive logic tasks.\\n\\nInput:\\n\\nHere is a description of an abductive logic problem:\\n\\n\\\\( (aaa \\\\text{ and } aab) \\\\rightarrow aac. \\\\)\\n\\\\( (aae \\\\text{ or } aaf) \\\\rightarrow aag. \\\\)\\n\\\\( (aah \\\\text{ or } aai) \\\\rightarrow aaj. \\\\)\\n\\\\( (aag \\\\text{ or } aaj) \\\\rightarrow aak. \\\\)\\n\\\\( (\\\\text{NOT } aac) \\\\rightarrow aad. \\\\)\\n\\\\( (aad \\\\text{ or } aak) \\\\rightarrow aan. \\\\)\\n\\nGiven \\\\( aan \\\\) is False, what is the value of \\\\( aab? \\\\)\\n\\nThe symbol '->' represents a deductive relationship, e.g., \\\\( A \\\\rightarrow B \\\\) implies that if \\\\( B \\\\) is false, then \\\\( A \\\\) is false. If \\\\( B \\\\) is true, \\\\( A \\\\)'s truth value remains undetermined (N/A). If the solution cannot be abducted, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is 1, your final result should be <<<1>>>.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Given $aan$ is False, it means either $aad$ or $aak$ must be False (both $aad$ and $aak$ should be False) (since $aad$ or $aak \\\\rightarrow aan$).\\n\\nIf $aak$ is False, then either $aag$ or $aaj$ must be False (since $aag$ or $aaj \\\\rightarrow aak$).\\n\\nIf $aag$ is False, then either $aae$ or $aaf$ must be False (since $aae$ or $aaf \\\\rightarrow aag$).\\n\\nIf $aaj$ is False, then either $aah$ or $aai$ must be False (since $aah$ or $aai \\\\rightarrow aaj$).\\n\\nHowever, none of these conditions provide any information about $aab$. Therefore, the value of $aab$ cannot be abduced from the given information.\\n\\nSo, the answer is <<<N/A>>>.\\n\\nGround truth:\\nN/A\\n\\nSelf Contradiction\\nGPT-4, on occasion, presents self-contradictory assumptions during the same inference in an abductive logic task.\\n\\nInput:\\nHere is a description of an abductive logic problem:\\n\\n$(aah \\\\text{ or } aai) \\\\rightarrow aaj$.\\n\\n$(\\\\text{NOT } aaj) \\\\rightarrow aak$.\\n\\n$(aad \\\\text{ or } aae) \\\\rightarrow aaf$.\\n\\n$(aaa \\\\text{ or } aab) \\\\rightarrow aac$.\\n\\n$(aac \\\\text{ or } aaf) \\\\rightarrow aag$.\\n\\n$(aag \\\\text{ or } aak) \\\\rightarrow aan$.\\n\\nGiven $aan$ is False, what is the value of $aah$?\\n\\nThe symbol '$\\\\rightarrow$' represents a deductive relationship, e.g., $A \\\\rightarrow B$ implies that if $B$ is false, then $A$ is false. If $B$ is true, $A$'s truth value remains undetermined (N/A). If the solution can not be abduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nGPT-4's response:\\nSince $aan$ is False, at least one of $aag$ or $aak$ must be False. However, we don't know which one is False, so we can't determine the value of $aah$. (This inference step contradicts to the former example, where GPT-4 assumes $aah$ is False.) Therefore, the answer is 'N/A'.\\n\\n<<<N/A>>>\\n\\nGround truth:\\nN/A\\n\\nUnsubstaintiated response\\nA recurring observation in both reasoning and algorithmic tasks is GPT-4's propensity to provide answers without accompanying justifications. These succinct, answer-only responses raise concerns about the depth of GPT-4's understanding and whether its approach is grounded in actual comprehension or simply a result of memorization. This error mostly happens in algorithm tasks and occasionally happens in logical reasoning tasks.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Here is a description of an abductive logic problem:\\n(aaa or aab) -> aac.\\n(aad or aae) -> aaf.\\n(aac or aaf) -> aag.\\n(NOT aah) -> aai.\\n(NOT aaj) -> aak.\\n(aai or aak) -> aan.\\n(aag or aan) -> aao.\\n\\nGiven aao is False, what is the value of aaa?\\nThe symbol '->' represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A's truth value remains undetermined (N/A). If the solution can not be abduced, answer 'N/A'. Ensure your final result begins with '<<<' and ends with '>>>', for example, if the answer is True, your final result should be <<<True>>>.\\n\\nGPT-4's response:\\n<<<N/A>>>\\n\\nGround truth:\\nN/A\\n\\nInterestingly, while GPT-4 often computes accurately, it sometimes falls when it comes to precisely following the output instructions as described in given prompts. This discrepancy points to a potential gap in the model's ability to parse and adhere to intricate instructional details, even when the underlying computational capability is sound.\\n\\nHere is a description of an arithmetic problem:\\nThe value of aac is 6.\\nThe value of aai is 6.\\nThe value of aag is 8.\\naan gets its value by subtracting the sum of the values of aak and aae from the value of aah.\\naao gets its value by multiplying together the value of aae and aan and aae.\\naah gets its value by multiplying together the value of aaf and aag and aae.\\nThe value of aap is 1.\\nThe value of aaa is 6.\\naad gets its value by taking the square root of the value that aac has.\\nThe value of aaj is 4.\\naak gets its value by subtracting the sum of the values of aaj and aae from the value of aai.\\nThe value of aaq is 7.\\naar gets its value by dividing the value of aap by those of aaq.\"}"}
{"id": "gjfOL9z5Xr", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nLarge language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns are raised about potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. In this paper, we introduce DYVAL, a general and flexible protocol for dynamic evaluation of LLMs. Based on our framework, we build graph-informed DYVAL by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DYVAL generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to GPT-3.5-Turbo and GPT-4. Experiments show that LLMs perform worse in DYVAL-generated evaluation samples with different complexities, highlighting the significance of dynamic evaluation. We also analyze the failure cases and results of different prompting methods. Moreover, DYVAL-generated samples are not only evaluation sets, but also helpful data for fine-tuning to improve the performance of LLMs on existing benchmarks. We hope that DYVAL can shed light on future evaluation research of LLMs. Code is available at: https://github.com/microsoft/promptbench.\\n\\nIntroduction\\n\\nLarge Language Models (LLMs) have recently achieved unprecedented performance across diverse tasks (OpenAI, 2023b; Bubeck et al., 2023). The great endeavor have led to positive speculation on the possibility of LLMs being precursors of artificial general intelligence, necessitating the creation of nuanced evaluations. By pinpointing gaps for improvements, evaluation becomes the bedrock that enhances the understanding of current models and ensures AI's continued progression.\\n\\nEfforts to evaluate LLMs have become intensified significantly. Liang et al. (2023) introduced HELM, which offers a holistic assessment of LLM in various scenarios. Similarly, Chatbot Arena (Zheng et al., 2023) evaluates LLMs by contrasting their generated output. Other benchmarks that have set the standard in the realm of LLM evaluations include AlpacaEval (Li et al., 2023c), C-Eval (Huang et al., 2023), ARB (Sawada et al., 2023), API-Bank (Li et al., 2023a), Socket (Choi et al., 2023), and Big-Bench (bench authors, 2023). Moreover, manual experiments have emerged as a complementary approach to these benchmarks, with works such as Bubeck et al. (2023) and Bang et al. (2023). Complementing these, human evaluators have also been instrumental in gauging the prowess of LLMs, as discussed by Ziems et al. (2023) and Zecevic et al. (2023).\\n\\nCurrent evaluation benchmarks face two fundamental challenges. First, data contamination. Many benchmarks source their data from the Internet, causing potential overlap with the vast corpus on which LLMs are trained, leading to the debate of \u201cGeneralization vs. Memorization\u201d (Bender et al., 2021; Magar & Schwartz, 2022; Carlini et al., 2023; Biderman et al., 2023): Are the model's results stemming from genuine ability or just memorization of the training data? A recent example is provided by Zecevic et al. (2023): LLMs can ambiguously deduce the conclusion that altitude influences temperature based on seen data. Similarly, Berglund et al. (2023) found that LLMs trained...\"}"}
