{"id": "MTex8qKavoS", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Summary of MetaShift.\\n\\nMetaShift covers a wide range of 410 classes and 12,868 sets of natural images in total. For each class, we have 31.4 subsets on average together with an annotation graph (i.e., meta-graph) that explains the similarity/distance between two subsets (edge weight) as well as what is unique about each subset (node metadata). More concretely, the subsets are characterized by a diverse collection of 1,853 distinct contexts, which covers 1,702 object presence, 37 general contexts and 114 object attributes.\\n\\nThe minimum is reached for $X$ equal to the matrix of eigenvectors of the Laplacian matrix associated with the eigenvalues $\\\\lambda_2, ..., \\\\lambda_{K+1}$. After calculating the spectral embeddings, we use the euclidean distance between the embeddings of two nodes as their distance. Other off-the-shelf node embedding methods like Node2Vec (Grover & Leskovec, 2016) can be readily plugged into MetaShift. We delay exploring them as future work.\\n\\nAlthough the subset overlap (i.e., edge weight) can also be used as a similarity metric, it does not incorporate the structural information from neighboring nodes. Our node embedding-based distance captures not only such overlap, but also broader similarities.\\n\\nStep 4: Simulating Distribution Shifts\\n\\nMetaShift allows users to benchmark both (1) domain generalization and (2) subpopulation shifts in a well-annotated (explicit annotation of what drives the shift) and well-controlled (easy control of the amount of distribution shift) fashion.\\n\\n\u2022 In domain generalization, the train and test distributions comprise data from related but distinct domains. This arises in many real-world scenarios since it is often infeasible to construct a comprehensive training set that spans all domains. To simulate this setting, we can sample two\"}"}
{"id": "MTex8qKavoS", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"distinct collections of subsets as the train domains and the test domains respectively (e.g. bathroom vs. outdoor contexts). To adjust the magnitude of the shift, we can fix the test domains and change the train domains with different distances. For example, if we use cats-in-living-room as the test set, then this is a smaller distribution shift.\\n\\nIn subpopulation shifts, the train and test distributions are mixtures of the same domains, but the mixture weights change between train and test. It is also an important setting since ML models are often reported to perform poorly on under-represented groups. To simulate this setting, we can sample the training set and test set from the same subsets but with different mixture weights. To adjust the magnitude of the shift, we can use different mixture weights for the training set while keeping the test set unchanged.\\n\\nWe demonstrate both settings in the experiment section. It is also worth noting that different subsets may share common images\u2014e.g. a dog image can have both grass and frisbee would occur in both dog with grass and dog with frisbee. Therefore, a post-processing step is needed to remove the training images that also occur in the test set to ensure no data leakage.\\n\\nMetaShift Statistics\\n\\nFigure 3 shows the statistics of MetaShift across all tasks. We start from the pre-processed and cleaned version of Visual Genome (Hudson & Manning, 2019), which contains 113,018 distinct images across 1,702 object classes. After the dataset construction, we have 12,868 sets of natural images from 410 classes. Concretely, each class has 31.4 subsets, and each subset has 200.4 images on average.\\n\\nThe subsets are characterized by a diverse vocabulary of 1,853 distinct contexts. Beyond 1,702 contexts defined by object presence, MetaShift also leverages the 37 distinct general contexts and 114 object attributes from Visual Genome. The general contexts typically describe locations (i.e., indoor, outdoor), weather (e.g., rainy, cloudless), and places (e.g., bathroom, ocean). The object attributes include color (e.g., white, red), material (e.g., wood, plastic), shape (e.g., round, square), and other object-specific properties (e.g., empty/full for plates). See Appendix A for examples and more information.\\n\\nGeneralizability: Case Study on COCO\\n\\nThe MetaShift construction methodology is quite simple, and can be extended to any dataset with metadata tags (i.e., multilabel). To demonstrate this, we apply the construction methodology on MS-COCO dataset (Lin et al., 2014), which provides object detection labels for each image. Applying our construction methodology, we are able to construct 1321 subsets, with an average size of 389 and a median size of 124, along with 80 meta-graphs that help to quantify the amount of distribution shift among MS-COCO subsets. Experiments on MetaShift from COCO can be found in Appendix D.\\n\\nEven though the data that we used here (e.g. Visual Genome, COCO) is not new, the idea of turning one dataset into a structured collection of datasets for assessing distribution shift is less explored. COCO (Lin et al., 2014) and many other datasets provide meta-data that could be naturally used for generating candidate subsets. The main contribution of our methodology is that after generating the candidate subsets, our method provides a meta-graph that could be used to determine the train and test domains, and also specifies the similarity between the two subsets via graph distance. MetaShift opens up a new window for systematically evaluating domain shifts.\\n\\n4 EXPERIMENT\\n\\nWe demonstrate the utility of MetaShift in two applications:\\n\\n\u2022 Evaluating distribution shifts: MetaShift supports evaluating both domain generalization (Section 4.1) and subpopulation shifts (Section 4.2). We perform controlled studies on ML models' behavior under different amounts of distribution shift. We also evaluate several recent proposals for training models to be robust to data shifts.\\n\\n\u2022 Assessing training conflicts: The subset information in MetaShift also sheds light on the training dynamics of ML models (Section 4.3). Since we have the subset membership information for each training datum, we could attribute the contribution of each gradient step back to the training subsets, and then analyze the heterogeneity of the contributions made by different training subsets.\"}"}
{"id": "MTex8qKavoS", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\nAlgorithm Task 1: Cat vs. Dog Task 2: Bus vs. Truck Task 3: Elephant vs. Horse Task 4: Bowl vs. Cup\\n\\nd_1 = 0.44 d_2 = 0.71 d_3 = 1.12 d_4 = 1.43 d_5 = 0.81 d_6 = 1.20 d_7 = 1.42 d_8 = 1.52 d_9 = 0.44 d_{10} = 0.63 d_{11} = 0.89 d_{12} = 1.44 d_{13} = 0.16 d_{14} = 0.47 d_{15} = 1.03 d_{16} = 1.31\\n\\n**Table 1:** Evaluating domain generalization: out-of-domain test accuracy with different amounts of distribution shift. Higher d indicates more challenging problem. Test data are fixed and only training data are changed.\\n\\n**4.1 Evaluating Domain Generalization**\\n\\nIn domain generalization, the train and test distributions comprise data from related but distinct domains. To benchmark domain generalization using MetaShift, we can sample two distinct collections of subsets as the train domains and the test domains respectively. We also showcase adjusting the magnitude of the shift by sampling different training subsets while keeping the test set unchanged.\\n\\n**Setup**\\n\\nAs shown in figure 2, subsets like \u201ccat with sink\u201d and \u201ccat with faucet\u201d are quite similar to each other. To make our evaluation settings more challenging, we merge similar subsets by running Louvain community detection algorithm (Blondel et al., 2008) on each meta-graph. Node color in Figure 2 indicates the community detection result. The embeddings of the merged subset are calculated as the average embeddings of subsets being merged, weighted by the subset size. After merging similar subsets, we construct four binary classification tasks:\\n\\n1. **Cat vs. Dog:** Test on dog(shelf) with 129 images. The cat training data is cat(sofa + bed) (i.e., cat(sofa) unions cat(bed)). We keep the test set and the cat training data unchanged. We keep the total size of training data as 400 images unchanged. We explore the effect of using 4 different sets of dog training data:\\n   - (a) dog(cabinet + bed) as dog training data. Its distance to dog(shelf) is d = 0.44\\n   - (b) dog(bag + box) as dog training data. Its distance to dog(shelf) is d = 0.71\\n   - (c) dog(bench + bike) as dog training data. Its distance to dog(shelf) is d = 1.12\\n   - (d) dog(boat + surfboard) as dog training data. Its distance to dog(shelf) is d = 1.43\\n\\n2. **Bus vs. Truck:** Test on truck(airplane) with 161 images. The bus training data is bus(clock + traffic light). The 4 different sets of truck training data are truck(cone + fence), truck(bike + mirror), truck(flag + tower), truck(traffic light + dog). Their distances to truck(airplane) are\\n   - d = 0.81, d = 1.20, d = 1.42, d = 1.52, respectively, as shown in Table 1.\\n\\n3. **Elephant vs. Horse:** Test on horse(barn) with 140 images. The elephant training data is elephant(fence + rock). The 4 different sets of horse training data are horse(dirt + trees), horse(fence + helmet), horse(car + wagon), horse(statue + cart), with distances d = 0.44/0.63/0.89/1.44.\\n\\n4. **Bowl vs. Cup:** Test on cup(coffee) with 375 images. The bowl training data is bowl(fruits + tray). The 4 different sets of horse training data are cup(knife + tray), cup(water + cabinet), cup(computer + lamp), cup(toilet + box), with distances d = 0.16/0.47/1.03/1.31 respectively.\\n\\n**Domain generalization algorithms**\\n\\nFollowing recent benchmarking efforts (Koh et al., 2020; Gulrajani & Lopez-Paz, 2020), we evaluated several recent methods for training models to be robust to data shifts: IRM (Arjovsky et al., 2019), GroupDRO (Sagawa et al., 2020), CORAL (Sun & Saenko, 2016), CDANN (Long et al., 2018). To ensure a fair comparison, we use the implementation and the default hyperparameters from DomainBed (Gulrajani & Lopez-Paz, 2020). We discuss more experiment setup details in Appendix B.1. We also extend the binary classification experiment here to a 10-class classification experiment in Appendix B.2.1.\\n\\n**Results**\\n\\nOur experiments show that the standard empirical risk minimization performs the best when shifts are moderate (i.e., when d is small). For example, ERM consistently achieves the best test accuracy on the smallest d of all tasks. This finding is aligned with previous research, as the domain generalization methods typically impose strong algorithmic regularization in various forms (Koh et al., 2020; Santurkar et al., 2020). However, when the amount of distribution shift increases, the domain generalization algorithms typically outperform the ERM baseline, though no algorithm\"}"}
{"id": "MTex8qKavoS", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm Average Acc. Worst Group Acc.\\n\\n| p  | ERM | IRM | GroupDRO | CORAL | CDANN |\\n|----|-----|-----|----------|-------|-------|\\n| 12% | 0.840 | 0.825 | 0.837 | 0.835 | 0.836 |\\n| 6%  | 0.823 | 0.830 | 0.818 | 0.816 | 0.810 |\\n| 1%  | 0.759 | 0.773 | 0.762 | 0.755 | 0.774 |\\n| 12% | 0.715 | 0.729 | 0.701 | 0.667 | 0.701 |\\n| 6%  | 0.701 | 0.715 | 0.715 | 0.694 | 0.625 |\\n| 1%  | 0.562 | 0.528 | 0.576 | 0.597 | 0.625 |\\n\\nTable 2: Evaluating subpopulation shift: $p$ is the percentage of minority groups in the training data. Lower $p$ indicates a more challenging setting. Evaluated on a balanced test set ($p=50\\\\%$). The classification task is \u201cCat vs. Dog\u201d with \u201cindoor/outdoor\u201d as the spurious correlation.\\n\\n4.2 EVALUATING SUBPOPULATION SHIFTS\\n\\nIn subpopulation shifts, the train and test distributions are mixtures of the same domains with different mixture weights. This is a more frequently-encountered problem since real-world datasets often have minority groups, while standard models are often reported to perform poorly on under-represented demographics (Buolamwini & Gebru, 2018; Koenecke et al., 2020).\\n\\nSetup\\n\\nTo benchmark subpopulation shifts using MetaShift, we can sample two distinct collections of subsets as the minority groups and majority groups respectively. We then use different mixture weights to construct the training set and test set. For \u201cCat vs. Dog\u201d, we leverage the general contexts \u201cindoor/outdoor\u201d which have a natural spurious correlation with the class labels. Concretely, in the training data, cat( outdoor) and dog( indoor) subsets are the minority groups, while cat( indoor) and dog( outdoor) are majority groups. We keep the total size of training data as 1700 images unchanged and only vary the portion of minority groups. We use a balanced test set with 576 images to report both average accuracy and worst group accuracy. We extend the binary classification experiment here to a 10-class classification experiment in Appendix B.2.2.\\n\\nResults\\n\\nTable 2 shows the evaluation results on subpopulation shifts. In terms of the average accuracy, ERM performs the best when $p$ is large (i.e., the minority group is less underrepresented) as expected. However, in terms of the worst group accuracy, the algorithms typically outperform ERM, showcasing their effectiveness in subpopulation shifts. Furthermore, it is worth noting that no algorithm is a consistent winner compared to other algorithms for large shifts. This finding is aligned with our finding in the previous section, suggesting that subpopulation shift is an important and challenging problem and there\u2019s still a lot of room for new methods.\\n\\n4.3 ASSESSING TRAINING CONFLICTS\\n\\nNext, we demonstrate how MetaShift can shed light on the training dynamics of ML models. An important feature of MetaShift is that each training datum is not only associated with a class label, but also the annotations of subset membership. Such annotations open a window for a systematic evaluation of how training on each subset would affect the evaluation performance on other subsets.\\n\\nSetup\\n\\nConcretely, we evaluate the ML model after each gradient step. We record the change of the validation loss of each validation subset. This gives us a multi-axes description of the effect of the current gradient step. Meanwhile, we also record the subset membership information for each of the training data in the current batch. We then run a linear regression to analyze the contributions of each training subset to the change of the validation loss of each validation subset.\\n\\nWe sampled 48 subsets from cat & dog classes. We use 22 of them as out-of-domain evaluation sets and the other 26 as training and in-domain evaluation. We sample 50 images from each subset to form the training set. Figure 4 shows the abridged results for brevity and better visualization.\"}"}
{"id": "MTex8qKavoS", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Out-of-Domain Evaluation\\n\\nEvaluation Data\\nTraining Data\\nIn-Domain Evaluation\\n\\nFigure 9: The full visualization of the training conflicts experiment. Each row represents a training subset, and each column represents an evaluation subset. A positive value (green) indicates that training on the training subset would improve the performance on the evaluation subset. A negative value (red) indicates that the training would hurt the performance on the evaluation subset. See text for discussions. Coefficients are normalized to $[-1, 1]$.\\n\\nAs shown in the \\\"in-domain evaluation\\\" region of Figure 9, we randomly sample 26 cat & dog subsets for training and in-domain evaluation: we split the data in each subset into a training set and an in-domain evaluation set. As shown in the \\\"out-of-domain evaluation\\\" region of Figure 9, we additionally sample 22 subsets as out-of-domain evaluation sets. We downsample the training data to make sure that every training subset has an equal number of data points (i.e., 50).\"}"}
{"id": "MTex8qKavoS", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To provide a more intuitive understanding of the meta-graph embeddings, we visualize the spectral embeddings of all nodes in the \u201cCat\u201d meta-graph in Figure 10. Overall, the spectral embeddings work well as similar nodes are close in the t-SNE visualization. Nodes with similar color (i.e., assigned to the same cluster by the Louvain community detection algorithm) are also clustered in the t-SNE visualization. Finally, we also note that the geometry of the t-SNE visualization (Figure 10) also closely mirrors the geometry of the meta-graph visualization layout in Figure 2.\\n\\nFigure 10: t-SNE Visualization of Meta-graph Spectral Embeddings for \u201cCat\u201d. Each node represents one subset of the cat images. Node colors indicate the communities automatically detected by graph-based algorithms. Overall, the spectral embeddings work well as similar nodes are close in the t-SNE visualization. Nodes with similar color (i.e., assigned to the same cluster by the Louvain community detection algorithm) are also clustered in the t-SNE visualization. Finally, we also note that the geometry of the t-SNE visualization (Figure 10) also closely mirrors the geometry of the meta-graph visualization layout in Figure 2.\\n\\nC.2 Louvain Community Detection Algorithm\\n\\nCommunity detection algorithms detect groups of nodes in a graph that are more densely connected internally than with the rest of the graph. We apply the Louvain community detection algorithm to recover the community structure of meta-graphs. One measure of how well a network is partitioned into communities is Modularity, which is the difference between the actual number of edges in a community and the expected number of such edges. We apply the Louvain community detection algorithm (Blondel et al., 2008), which greedily maximizes modularity since optimizing modularity is NP-hard (Brandes et al., 2007). This is a bottom-up algorithm: initially, every vertex belongs to a separate community, and vertices are moved between communities iteratively in a way that maximizes the vertices' local contribution to the overall modularity score. When a consensus is reached (i.e. no single move would increase the modularity score), every community in the original graph is shrunk to a single vertex (while keeping the total weight of the adjacent edges) and the process continues on...\"}"}
{"id": "MTex8qKavoS", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the next level. The algorithm stops when it is not possible to increase the modularity anymore after shrinking the communities to vertices.\\n\\nC.3 DISCUSSIONS ON IMPERFECT OR INCOMPLETE META-DATA\\n\\nEven if there is some noise introduced by the imperfect or incomplete metadata, the noise can make the classification tasks more challenging and more realistic, as in subpopulation shifts. For example, it is rare that someone would collect a dog dataset of 100% indoor images, but it is quite possible that the dataset contains 80% indoor images and 20% outdoor images. Therefore, noise from metadata would not invalidate our approach, but make the curated dataset more realistic and challenging.\\n\\nD CONSTRUCTING META-SHIFT FROM COCO DATASET\\n\\nMetaShift from COCO\\n\\nTo demonstrate the generalizability of the MetaShift construction methodology, we apply our methodology on MS-COCO dataset (Lin et al., 2014). We construct 1321 subsets, with an average size of 389 and a median size of 124, along with 80 meta-graphs that help to quantify the amount of distribution shift among MS-COCO subsets.\\n\\nSubpopulation Shift Setup\\n\\nBased on the MetaShift from COCO, we constructed a subpopulation shift experiment similar to Section 4.2. We construct a \u201cCat vs. Dog\u201d task, where the \u201cindoor/outdoor\u201d contexts are spuriously correlated with the class labels. The \u201cindoor\u201d context is constructed by merging the following super-categories: \u2018indoor\u2019, \u2018kitchen\u2019, \u2018electronic\u2019, \u2018appliance\u2019, \u2018furniture\u2019. Similarly, the \u201coutdoor\u201d context is constructed by merging the following super-categories: \u2018outdoor\u2019, \u2018vehicle\u2019, \u2018sports\u2019. In addition, in the training data, cat(outdoor) and dog(indoor) subsets are the minority groups, while cat(indoor) and dog(outdoor) are majority groups. We keep the total size of training data as 3000 images unchanged and only vary the portion of minority groups. We use a balanced test set with 524 images to report both average accuracy and worst group accuracy.\\n\\n| Algorithm     | Average Acc. | Worst Group Acc. |\\n|---------------|--------------|------------------|\\n| ERM           | 0.826        | 0.821            |\\n| IRM           | 0.805        | 0.794            |\\n| GroupDRO      | 0.821        | 0.811            |\\n| CORAL         | 0.824        | 0.801            |\\n| CDANN         | 0.834        | 0.805            |\\n\\nTable 5: Evaluating subpopulation shift on MetaShift from COCO. $p$ is the percentage of minority groups in the training data. Lower $p$ indicates a more challenging setting. Evaluated on a balanced test set ($p=50\\\\%$).\\n\\nSubpopulation Shift Result\\n\\nAs shown in Table 5, overall, we found that the new results are consistent with our previous findings. When $p$ is large (i.e., the minority group is less underrepresented), ERM outperforms most of the other algorithms in terms of average accuracy. It is also worth noting that no algorithm is a consistent winner compared to other algorithms for large shifts. These new experiments also show that MetaShift can flexibly accommodate other source datasets including COCO.\"}"}
{"id": "MTex8qKavoS", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\nOut-of-Domain Evaluation Data Training Data In-Domain Evaluation\\n\\nFigure 4: A Visualization of Training Conflicts. Each row represents a training subset, and each column represents an evaluation subset. A positive value (green) indicates that training on the training subset would improve the performance on the evaluation subset. A negative value (red) indicates that the training would hurt the performance on the evaluation subset. See text for discussions.\\n\\nResults Region (1) and (2) in Figure 4 highlighted the \u201cconflict zones\u201d: indoor cat subsets and indoor dog subsets are having severe training conflicts with each other. This makes sense since they share the same spurious feature \u201cindoor\u201d, making the model confused. However, such training conflicts are important for out-of-domain generalization. As highlighted in Region (6), the dog (animal subset (last column, which comprises primarily outdoor images) benefits most from indoor subsets like dog (sheet), rather than outdoor dog subsets like dog (truck). These results might indicate that training conflicts force the ML model to learn generalizable features.\\n\\nFurthermore, Figure 4 also reveals the subsets that have low training contributions. As highlighted in Region (3) and (4), training on cat (faucet) and dog (frisbee) has little effect on other subsets. We hypothesize that this is because these subsets are too easy and thus provide little insight for the model. To verify this hypothesis, we remove cat (faucet), and dog (frisbee) from training and use them for out-of-domain validation. We found that the model achieves a near perfect accuracy on both subsets: cat (faucet): 98.1%, dog (frisbee): 96.6%. This shows that subsets with low training contributions tend to be the subsets that are too easy.\\n\\nOther observations include: Columns of cat (television) and dog (television) in Region (6) look opposite to each other. In addition, dog (truck) as highlighted in (5) exhibits a very different behaviour compared to other dog subsets: training on dog (truck) conflicts with all other dog subsets.\\n\\nCONCLUSION\\nWe present MetaShift\u2014a collection of 12,868 sets of natural images from 410 classes\u2014as an important resource for studying the behavior of ML algorithms and training dynamics across data with heterogeneous contexts. MetaShift contains orders of magnitude more natural data shifts than previously available. It also provides explicit explanations of what is unique about each of its data sets and a distance score that measures the amount of distribution shift between any two of its data sets. We demonstrate the utility of MetaShift in both evaluating distribution shifts, and visualizing conflicts between data subsets during model training. Even though the data that we used here (e.g. Visual Genome) is not new, the idea of turning one dataset into a structured collection of datasets for assessing distribution shift is less explored. Our methodology for constructing MetaShift is simple and powerful, and can be readily extended to create many new resources for evaluating distribution shifts, which is very much needed.\"}"}
{"id": "MTex8qKavoS", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our project website https://MetaShift.readthedocs.io/ provides detailed documentation and installation guidelines. The dataset and code are also available at https://github.com/Weixin-Liang/MetaShift. The implementations will enable researchers to download MetaShift and reproduce the results described here as well as run their own evaluations on additional datasets. In the experiments of evaluating domain generalization and subpopulation shifts, we use the implementation and the default hyperparameters from Domainbed (Gulrajani & Lopez-Paz, 2020) to ensure a fair comparison. Our MetaShift dataset and code are available in the supplementary material, and would use the Creative Commons Attribution 4.0 International License.\\n\\nOne limitation is that our MetaShift might inherit existing biases in Visual Genome, which is the base dataset of our MetaShift. Potential concerns include minority groups being under-represented in certain classes (e.g., women with snowboard), or annotation bias where people in images are by default labeled as male when gender is unlikely to be identifiable. Existing work in analyzing, quantifying, and mitigating biases in general computer vision datasets can help with addressing this potential negative societal impact. We can also use MetaShift to understand how certain subsets of training data can lead to model biases in other contexts, as done in our experiments in Figure 4.\\n\\nREFERENCES\\n\\nMart\u00edn Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. CoRR, abs/1907.02893, 2019.\\n\\nMikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural computation, 15(6):1373\u20131396, 2003.\\n\\nVincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment, 2008(10):P10008, 2008.\\n\\nUlrik Brandes, Daniel Delling, Marco Gaertler, Robert Gorke, Martin Hoefer, Zoran Nikoloski, and Dorothea Wagner. On modularity clustering. IEEE transactions on knowledge and data engineering, 20(2):172\u2013188, 2007.\\n\\nJoy Buolamwini and Timnit Gebru. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on fairness, accountability and transparency, pp. 77\u201391. PMLR, 2018.\\n\\nFan RK Chung and Fan Chung Graham. Spectral graph theory. American Mathematical Soc., 1997.\\n\\nRoxana Daneshjou, Kailas Vodrahalli, Weixin Liang, Roberto A. Novoa, Melissa Jenkins, Ver\u00f3nica M Rotemberg, Justin M. Ko, Susan M. Swetter, Elizabeth E Bailey, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, James Zou, and Albert Sean Chiou. Disparities in dermatology ai: Assessments using diverse clinical images. ArXiv, abs/2111.08006, 2021.\\n\\nSabri Eyuboglu, Maya Varma, Khaled Kamal Saab, Jean-Benoit Delbrouck, Christopher Lee-Messer, Jared Dunnmon, James Zou, and Christopher Re. Domino: Discovering systematic errors with cross-modal embeddings. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=FPCMqjI0jXN.\\n\\nAmirata Ghorbani and James Y. Zou. Data shapley: Equitable valuation of data for machine learning. In ICML, volume 97 of Proceedings of Machine Learning Research, pp. 2242\u20132251. PMLR, 2019.\\n\\nAditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 855\u2013864, 2016.\"}"}
{"id": "MTex8qKavoS", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "MTex8qKavoS", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "MTex8qKavoS", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For each image class (e.g. Dogs), the MetaShift dataset contains different sets of dogs under different contexts to represent diverse data distributions. The contexts include presence/absence of other objects (e.g. dog with frisbee). Contexts can also reflect attributes (e.g. black dogs) and general settings (e.g. dogs in sunny weather). These concepts thus capture diverse and real-world distribution shifts. We list the attribute and general location contexts below.\\n\\nA.1.1 General Location Contexts\\n\\n- Dog (Bedroom)\\n- Dog (Ocean)\\n- Dog (Street)\\n- Dog (Grass)\\n- Dog (Cloudy)\\n- Dog (Snow)\\n\\nA.1.2 Attribute Contexts\\n\\n- Black\\n- White\\n- Brown\\n- Grey\\n- Red\\n\\nFigure 5: Example subsets based on general contexts (the global context is stated in parenthesis). MetaShift covers global contexts including location (e.g., indoor, outdoor) and weather (e.g., sunny, rainy).\\n\\n**GENERAL_CONTEXT_ONTOLOGY** = {\\n    'indoor/outdoor': ['indoors', 'outdoors'],\\n    'weather': ['clear', 'overcast', 'cloudless', 'cloudy', 'sunny', 'foggy', 'rainy'],\\n    'room': ['bedroom', 'kitchen', 'bathroom', 'living room'],\\n    'place': ['road', 'sidewalk', 'field', 'beach', 'park', 'grass', 'farm', 'ocean', 'pavement', 'lake', 'street', 'train station', 'hotel room', 'church', 'restaurant', 'forest', 'path', 'display', 'store', 'river', 'yard', 'snow', 'airport', 'parking lot']\\n}\\n\\nFigure 6: The general contexts and their ontology in MetaShift. MetaShift covers 37 general contexts including location (e.g., indoor, outdoor, ocean, snow) and weather (e.g., cloudy, sunny, rainy).\"}"}
{"id": "MTex8qKavoS", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.1.2 Attribute Contexts\\n\\nCat (White)  \\nDog (Sitting)  \\nCat (Orange)  \\nDog (Jumping)  \\nBench (Wooden)  \\nBench (Metallic)  \\nPlate (Round)  \\nPlate (Square)  \\n\\nFigure 7: Example Subsets based on object attribute contexts (the attribute is stated in parenthesis). MetaShift covers attributes including activity (e.g., sitting, jumping), color (e.g., orange, white), material (e.g., wooden, metallic), shape (e.g., round, square), and so on.\\n\\nATTRIBUTE_CONTEXT_ONTOLOGY = {\\n    'darkness': ['dark', 'bright'],\\n    'dryness': ['wet', 'dry'],\\n    'colorful': ['colorful', 'shiny'],\\n    'leaf': ['leafy', 'bare'],\\n    'emotion': ['happy', 'calm'],\\n    'sports': ['baseball', 'tennis'],\\n    'flatness': ['flat', 'curved'],\\n    'lightness': ['light', 'heavy'],\\n    'gender': ['male', 'female'],\\n    'width': ['wide', 'narrow'],\\n    'depth': ['deep', 'shallow'],\\n    'hardness': ['hard', 'soft'],\\n    'cleanliness': ['clean', 'dirty'],\\n    'switch': ['on', 'off'],\\n    'thickness': ['thin', 'thick'],\\n    'openness': ['open', 'closed'],\\n    'height': ['tall', 'short'],\\n    'length': ['long', 'short'],\\n    'fullness': ['full', 'empty'],\\n    'age': ['young', 'old'],\\n    'size': ['large', 'small'],\\n    'pattern': ['checkered', 'striped', 'dress', 'dotted'],\\n    'shape': ['round', 'rectangular', 'triangular', 'square'],\\n    'activity': ['waiting', 'staring', 'drinking', 'playing', 'eating', 'cooking', 'resting', 'sleeping', 'posing', 'talking', 'looking down', 'looking up', 'driving', 'reading', 'brushing teeth', 'flying', 'surfing', 'skiing', 'hanging'],\\n    'pose': ['walking', 'standing', 'lying', 'sitting', 'running', 'jumping', 'crouching', 'bending', 'smiling', 'grazing'],\\n    'material': ['wood', 'plastic', 'metal', 'glass', 'leather', 'leather', 'porcelain', 'concrete', 'paper', 'stone', 'brick'],\\n    'color': ['white', 'red', 'black', 'green', 'silver', 'gold', 'khaki', 'gray', 'dark', 'pink', 'dark blue', 'dark brown', 'blue', 'yellow', 'tan', 'brown', 'orange', 'purple', 'beige', 'blond', 'brunette', 'maroon', 'light blue', 'light brown']\\n}\\n\\nFigure 8: The attributes and their ontology in MetaShift. MetaShift covers over 100 attributes including activity (e.g., sitting, jumping), color (e.g., orange, white), material (e.g., wooden, metallic), shape (e.g., round, square) and so on.\\n\\nA.2 Compute Requirements\\n\\nAll experiments were performed on an Amazon EC2 P3.8 instance with 4 NVIDIA V100 Tensor Core GPUs. Each training trial in evaluating distribution shifts takes less than an hour to finish.\\n\\nA.3 Dataset Licenses\\n\\nOur MetaShift and the code would use the Creative Commons Attribution 4.0 International License. Visual Genome (Krishna et al., 2017) is licensed under a Creative Commons Attribution 4.0 International License. MS-COCO (Lin et al., 2014) is licensed under CC-BY 4.0. The Visual Genome dataset uses 108,077 images from the intersection of the YFCC100M (Thomee et al., 2016) and MS-COCO. We use the pre-processed and cleaned version of Visual Genome by GQA (Hudson & Manning, 2019).\"}"}
{"id": "MTex8qKavoS", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We use the implementation and hyper-parameters from Domainbed (Gulrajani & Lopez-Paz, 2020) for empirical risk minimization (ERM) and all domain generalization baselines. Domainbed is licensed under an MIT License. It is worth noting that the implementation of empirical risk minimization (ERM) in Domainbed implicitly up-samples minority domains during training. Nevertheless, we stick with their implementation for consistency.\\n\\nEXPERIMENT DETAILS\\n\\nB.1 EXPERIMENT SETUP\\n\\nIn the experiments of evaluating domain generalization and subpopulation shifts, we use the implementation and the default hyperparameters from DomainBed (Gulrajani & Lopez-Paz, 2020) to ensure a fair comparison. More specifically, we evaluated the following methods for training models to be robust to data shifts:\\n\\n- ERM: the standard Empirical risk minimization baseline.\\n- IRM: Invariant risk minimization (Arjovsky et al., 2019), which penalizes feature distributions that have different optimal linear classifiers for each domain.\\n- GroupDRO: Group Distributionally robust optimization (Sagawa et al., 2020), which uses distributionally robust optimization to explicitly minimize the loss on the worst-case domain during training.\\n- CORAL: Correlation Alignment (Sun & Saenko, 2016), which penalizes differences in the means and covariances of the feature distributions for each domain.\\n- CDANN: Conditional Adversarial Domain Adaptation (Long et al., 2018), which uses adversarial learning to penalize differences in feature representations from different domains.\\n\\nFollowing DomainBed (Gulrajani & Lopez-Paz, 2020), we use ResNet-18 with the Adam optimizer, cross-entropy loss, learning rate $0.00005$, batch size $32$. The data augmentation steps include the following: crops of random size and aspect ratio, resizing to $224 \\\\times 224$ pixels, random horizontal flips, random color jitter, grayscaling the image with $10\\\\%$ probability, and normalization using the ImageNet channel means and standard deviations. We start from ImageNet pre-trained weights, which is consistent with the standard practice of prior work (Gulrajani & Lopez-Paz, 2020; Koh et al., 2020; Sagawa et al., 2020). For additional implementation details, we refer readers to DomainBed (Gulrajani & Lopez-Paz, 2020).\\n\\nB.2 MULTI-CLASS CLASSIFICATION EXPERIMENTS\\n\\nTo demonstrate the generalizability of our findings, we extend our binary classification experiments into a multi-class classification setting. More specifically, we augment the \u201cCat vs. Dog\u201d classification task into a 10-class animal classification task by incorporating the following classes: \u201cbear\u201d, \u201cbird\u201d, \u201ccow\u201d, \u201celephant\u201d, \u201chorse\u201d, \u201csheep\u201d, \u201cgiraffe\u201d, \u201czebra\u201d.\\n\\n| Algorithm | d = 0.44 | d = 0.71 | d = 1.12 | d = 1.43 |\\n|-----------|----------|----------|----------|----------|\\n| ERM       | 0.762    | 0.637    | 0.448    | 0.265    |\\n| IRM       | 0.699    | 0.660    | 0.422    | 0.284    |\\n| GroupDRO  | 0.690    | 0.683    | 0.451    | 0.252    |\\n| CORAL     | 0.641    | 0.624    | 0.373    | 0.261    |\\n| CDANN     | 0.676    | 0.647    | 0.392    | 0.304    |\\n\\nTable 3: Evaluating domain generalization on a 10-class animal classification task. Out-of-domain (OOD) test accuracy with different amounts of distribution shift $d$. Higher $d$ indicates more challenging problem.\\n\\nWe extend Task 1 in the domain generalization experiment (Section 4.1) into a multi-class classification setting. Overall, these new results are very consistent with our findings. The multi-class 15\"}"}
{"id": "MTex8qKavoS", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"classification setting is constructed as follows: we extend the \\\"Cat vs. Dog\\\" task to a 10-class animal classification task. Similar to Section 4.1, we only change the training data of dog, while keeping the training data of all other classes unchanged, in order to avoid introducing additional confounding effects.\\n\\nWe explore the effect of using 4 different sets of dog training data. The test is performed on dog(\\\\textit{shelf}), and thus we also report the distance between the dog training data and the test data dog(\\\\textit{shelf}).\\n\\n1. dog(\\\\textit{cabinet + bed}) as dog training data. Its distance to dog(\\\\textit{shelf}) is $d = 0.44$\\n2. dog(\\\\textit{bag + box}) as dog training data. Its distance to dog(\\\\textit{shelf}) is $d = 0.71$\\n3. dog(\\\\textit{bench + bike}) as dog training data. Its distance to dog(\\\\textit{shelf}) is $d = 1.12$\\n4. dog(\\\\textit{boat + surfboard}) as dog training data. Its distance to dog(\\\\textit{shelf}) is $d = 1.43$\\n\\nResults\\n\\nAs shown in Table 3, in the multi-class classification setting, the standard empirical risk minimization still performs the best when shifts are moderate (i.e., when $d$ is small), which is aligned with previous research, as the domain generalization methods typically impose strong algorithmic regularization in various forms (Koh et al., 2020; Santurkar et al., 2020). However, when the amount of distribution shift increases, the domain generalization algorithms typically outperform the ERM baseline, though no algorithm is a consistent winner compared to other algorithms for large shifts.\\n\\nThis finding suggests that domain generalization is an important and challenging task and that there's still a lot of room for new methods.\\n\\n\\\\textbf{B.2.2 MULTI-CLASS CLASSIFICATION: SUBPOPULATION SHIFT}\\n\\nWe extend the \\\"Cat vs. Dog\\\" subpopulation Shift to a 10-class animal classification task. Similarly, to avoid introducing additional confounding effects, we only vary the training data of cat and dog in different experiments, but keep the training data of other classes unchanged across experiments. We evaluate only on the cat and dog classes. The rationale of evaluating these two classes (instead of the other classes) is that we vary the training data of these classes, and thus these classes would be the most directly impacted.\\n\\n| Algorithm | Average Acc. | Worst Group Acc. |\\n|-----------|--------------|------------------|\\n| ERM       | 0.789        | 0.769            |\\n| IRM       | 0.780        | 0.728            |\\n| GroupDRO  | 0.785        | 0.726            |\\n| CORAL     | 0.787        | 0.713            |\\n| CDANN     | 0.783        | 0.709            |\\n\\nTable 4: Evaluating subpopulation shift in a 10-class animal classification task: $p$ is the percentage of minority groups in the training data. Lower $p$ indicates a more challenging setting. Evaluated on a balanced test set ($p = 50\\\\%$).\\n\\nResults\\n\\nTable 4 shows the evaluation results on subpopulation shifts in the multi-class classification setting. In terms of the average accuracy, ERM performs the best when $p$ is large (i.e., the minority group is less underrepresented) as expected. However, in terms of the worst group accuracy, the algorithms typically outperform ERM, showcasing their effectiveness in subpopulation shifts. Furthermore, it is worth noting that no algorithm is a consistent winner compared to other algorithms for large shifts. This finding is aligned with our finding in the previous section, suggesting that subpopulation shift is an important and challenging problem and there's still a lot of room for new methods.\\n\\n\\\\textbf{B.3 APPLICATION: ASSESSING TRAINING CONFLICTS}\\n\\nAs data is the fuel powering artificial intelligence, it is important to understand the training conflicts on heterogeneous training data. We next demonstrate the utility of MetaDataset on visualizing how different subsets of data provide conflicting training signals. The key idea is to analyze the change of...\"}"}
{"id": "MTex8qKavoS", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"METH: A DATASET OF DATASETS FOR EVALUATING CONTEXTUAL DISTRIBUTION SHIFTS AND TRAINING CONFLICTS\\n\\nWeixin Liang\\nStanford University\\nwxliang@stanford.edu\\n\\nJames Zou\\nStanford University\\njamesz@stanford.edu\\n\\nABSTRACT\\nUnderstanding the performance of machine learning models across diverse data distributions is critically important for reliable applications. Motivated by this, there is a growing focus on curating benchmark datasets that capture distribution shifts. While valuable, the existing benchmarks are limited in that many of them only contain a small number of shifts and they lack systematic annotation about what is different across different shifts. We present MetaShift\u2014a collection of 12,868 sets of natural images across 410 classes\u2014to address this challenge. We leverage the natural heterogeneity of Visual Genome and its annotations to construct MetaShift. The key construction idea is to cluster images using its metadata, which provides context for each image (e.g. cats with cars or cats in bathroom) that represent distinct data distributions. MetaShift has two important benefits: first, it contains orders of magnitude more natural data shifts than previously available. Second, it provides explicit explanations of what is unique about each of its data sets and a distance score that measures the amount of distribution shift between any two of its data sets. We demonstrate the utility of MetaShift in benchmarking several recent proposals for training models to be robust to data shifts. We find that the simple empirical risk minimization performs the best when shifts are moderate and no method had a systematic advantage for large shifts. We also show how MetaShift can help to visualize conflicts between data subsets during model training.\\n\\nINTRODUCTION\\nA major challenge in machine learning (ML) is that a model can have very different performances and behaviors when it's applied to different types of natural data (Koh et al., 2020; Izzo et al., 2021; 2022). For example, if the user data have different contexts compared to the model's training data (e.g. users have outdoor dog photos and the model's training was mostly on indoor images), then the model's accuracy can greatly suffer (Yao et al., 2022). A model can have disparate performances even within different subsets within its training and evaluation data (Daneshjou et al., 2021; Eyuboglu et al., 2022). In order to assess the reliability and fairness of a model, we therefore need to evaluate its performance and training behavior across heterogeneous types of data. However, the lack of well-structured datasets representing diverse data distributions makes systematic evaluation difficult.\\n\\nIn this paper, we present MetaShift to tackle this challenge. MetaShift is a collection of 12,868 sets of natural images from 410 classes. Each set corresponds to images in a similar context and represents a coherent real-world data distribution, as shown in Figure 1. The construction of MetaShift is different from and complementary to other efforts to curate benchmarks for data shifts by pulling together data across different experiments or sources. MetaShift leverages heterogeneity within the large sets of images from the Visual Genome project (Krishna et al., 2017) by clustering the images using metadata that describes the context of each image. The advantage of this approach is that MetaShift contains many more coherent sets of data compared to other benchmarks. Importantly, we have explicit annotations of what makes each subset unique (e.g. cats with cars or dogs next to a bench).\\n\\n1 Dataset and code available at: https://metashift.readthedocs.io/\"}"}
{"id": "MTex8qKavoS", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"MetaShift leverages the natural heterogeneity within each class (e.g., \\\"cat\\\", \\\"dog\\\") to provide many subsets of images. Each subset corresponds to images in a similar context (the context is stated in parenthesis) and represents a coherent real-world data distribution. Here, we only show 2 out of 410 classes and 8 out of 12,868 subsets of images from MetaShift.\\n\\nWe demonstrate the utility of MetaShift in two applications. First, MetaShift supports evaluation on both domain generalization and subpopulation shifts settings. Using the score between subsets provided by MetaShift, we study ML models' behavior under different carefully modulated amounts of distribution shift. Second, MetaShift can also shed light on the training dynamics of ML models. Since we have the subset membership information for each training datum, we could attribute the contribution of each gradient step back to the training subsets, and then analyze how different data subsets provide conflicting training signals.\\n\\nOur contributions:\\nWe present MetaShift as an important resource for studying the behavior of ML algorithms and training dynamics across data with heterogeneous contexts. Our methodology for constructing MetaShift can also be applied to other domains where metadata is available. We empirically evaluate the performance of different robust learning algorithms, showing that ERM performs well for modest shifts while no method is the clear winner for larger shifts. This finding suggests that domain generalization is an important and challenging task and that there's still a lot of room for new methods.\\n\\nRelated Work\\nExisting Benchmarks for Distribution Shift\\nDistribution shifts have been a longstanding challenge in machine learning. Early benchmarks focus on distribution shifts induced by synthetic pixel transformations. Examples include rotated and translated versions of MNIST and CIFAR (Worrall et al., 2017); surface variations such as texture, color, and corruptions like blur in Colored MNIST (Gulrajani & Lopez-Paz, 2020), ImageNet-C (Hendrycks & Dietterich, 2019). Although the synthetic pixel transformations are well-defined, they generally do not represent realistic shifts in real-world images that we capture in MetaShift.\\n\\nOther benchmarks do not rely on transformations but instead pull together data across different experiments or sources. Office-31 (Saenko et al., 2010) and Office-home (Venkateswara et al., 2017) contain images collected from different domains like Amazon, clipart. These benchmarks typically have only a handful of data distributions. The benchmarks collected in WILDS (Koh et al., 2020) combine data from different sources (e.g., medical images from different hospitals, animal images...\"}"}
{"id": "MTex8qKavoS", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\nfrom different camera traps). Similarly, some meta-learning benchmarks (Triantafillou et al., 2019; Guo et al., 2020) focuses on dataset-level shift by combining different existing datasets like ImageNet, Omniglot. While valuable, they lack systematic annotation about what is different across different shifts. Santurkar et al. (2020); Ren et al. (2018) utilize the hierarchical structure of ImageNet to construct training and test sets with disjoint subclasses. For example, the \u201ctableware\u201d class uses \u201cbeer glass\u201d and \u201cplate\u201d for training and testing respectively. Different from their work, we study the shifts where the core object remains the same while the context changes. NICO (He et al., 2020) query different manually-curated phrases on search engines to collect images of objects in different contexts. A key difference is the scale of MetaShift: NICO contains 190 sets of images across 19 classes while MetaShift has 12,868 sets of natural images across 410 classes.\\n\\nTo sum up, the advantages of our MetaShift are:\\n\\n\u2022 Existing benchmark datasets for distribution shifts typically have only a handful of data distributions. In contrast, our MetaShift has over 12,868 data distributions, thus enabling a much more comprehensive assessment of distribution shifts.\\n\u2022 Distribution shifts in existing benchmarks are not annotated (i.e. we don\u2019t know what drives the shift) and are not well-controlled (i.e. we can\u2019t easily adjust the magnitude of the shift). The MetaShift provides explicit annotations of the differences between any two sub-datasets, and it quantifies the distance of the shift.\\n\\nEvaluating conflicts on training data\\n\\nRecent work has shown that different training data points play a heterogeneous role in training. To quantify this, Data Shapley (Ghorbani & Zou, 2019; Kwon & Zou, 2022) provides a mathematical framework for quantifying the contribution of each training datum. Data Cartography (Swayamdipta et al., 2020) leverages a model\u2019s training confidence to discover hard-to-learn training data points. Such understanding has provided actionable insights that benefit the ML workflow. For example, removing noisy low-contribution training data points improves the model\u2019s final performance (Liang et al., 2020a; 2021). Furthermore, active learning identifies the most informative data points for humans to annotate (Liang et al., 2020b). Complementary to their work, our analysis sheds light on not only which but also why a certain portion of the training data are hard-to-learn\u2014because different subsets are providing conflicting training signals.\\n\\n3 THE METASHIFT CONSTRUCTION\\n\\nWhat is MetaShift? The MetaShift is a collection of subsets of data together with an annotation graph that explains the similarity/distance between two subsets (edge weight) as well as what is unique about each subset (node metadata). For each class, say \u201ccat\u201d, we have many subsets of cats, and we can think of each subset as a node in the graph, as shown in Figure 2. Each subset corresponds to \u201ccat\u201d in a different context: e.g. \u201ccat with sink\u201d or \u201ccat with fence\u201d. The context of each subset is the node metadata. The \u201ccat with sink\u201d subset is more similar to \u201ccat with faucet\u201d subset because there are many images that contain both sink and faucet. This similarity is the weight of the edge; a higher weight means the contexts of the two nodes tend to co-occur in the same data.\\n\\nHow can we use MetaShift? It is a flexible framework to generate a large number of real-world distribution shifts that are well-annotated and controlled. For each class of interest, say \u201ccats\u201d, we can use the meta-graph of cats to identify a collection of cats nodes for training (e.g. cats with bathroom-related contexts) and a collection of cats nodes for out-of-domain evaluation (e.g. cats in outdoor contexts). Our meta-graph tells us exactly what is different between the train and test domains (e.g. bathroom vs. outdoor contexts), and it also specifies the similarity between the two contexts via graph distance. That makes it easy to carefully modulate the amount of distribution shift. For example, if we use cats-in-living-room as the test set, then this is a smaller distribution shift.\\n\\nBase Dataset: Visual Genome\\n\\nWe leverage the natural heterogeneity of Visual Genome and its annotations to construct MetaShift. Visual Genome contains over 100k images across 1,702 object classes. For each image, Visual Genome annotates the class labels of all objects that occur in the image. Formally, for each image $x_i$, we have a list of meta-data tags $m_i = \\\\{t_{i1}, t_{i2}, \\\\ldots, t_{in}\\\\}$, each indicating the presence of an object in the context. We denote the vocabulary of the meta-data tags as $M = \\\\{m_0, \\\\ldots, m_M\\\\}$. MetaShift is constructed on a class-by-class basis: For each class, say \u201ccat\u201d, we pull out all cat images and proceed with the following steps.\"}"}
{"id": "MTex8qKavoS", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Step 1: Generate Candidate Subsets\\nWe first generate candidate subsets by enumerating all possible meta-data tags. We construct $|M|$ candidate subsets where the $i^{th}$ subset contains all images of the class of interest (i.e., \\\"cat\\\") that has a meta-tag $m_i$. We then remove subsets whose sizes are less than a threshold (e.g., 25).\\n\\nStep 2: Construct Meta-graphs\\nSince the meta-data are not necessarily disentangled, the candidate subsets might contain significant overlaps (e.g., \\\"cat with sink\\\" and \\\"cat with faucet\\\"). To capture this phenomenon, we construct a meta-graph to model the relationships among all subsets of each class. Specifically, for each class $j \\\\in Y$, we construct meta-graph, a weighted undirected graph $G = (V, E)$ where each node $v \\\\in V$ denotes a candidate subset, and the weight of each edge is the overlap coefficient between two subsets:\\n\\n$$\\\\text{overlap}(X, Y) = \\\\frac{|X \\\\cap Y|}{\\\\min(|X|, |Y|)}, \\\\quad (1)$$\\n\\nWe remove the edges whose weights are less than a threshold (e.g., 0.1) to sparsify the graph. As shown in Figure 2, the meta-graph $G$ captures meaningful semantics of the multi-modal data distribution of the class of interest.\\n\\nStep 3: Quantify Distances of Distribution Shifts\\nThe geometry of meta-graphs provides a natural and systematic way to quantify the distances of shifts across different data distributions: Intuitively, if two subsets are far away from each other in the MetaGraph, then the shift between them tend to be large. Following this intuition, we leverage spectral embeddings (Belkin & Niyogi, 2003; Chung & Graham, 1997) to assign an embedding for each node based on the graph geometry.\"}"}
