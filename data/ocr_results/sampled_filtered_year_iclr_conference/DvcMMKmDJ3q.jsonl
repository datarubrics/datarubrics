{"id": "DvcMMKmDJ3q", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"is that they must be \u201cactivated\u201d to have some effect: If some constraint must only hold between \\\\( Q \\\\) and \\\\( R \\\\) but these events never happen, the whole pattern is effectively useless. A grounding is a term that is likely to activate scopes, such as \\\\( a \\\\land \\\\neg b \\\\) or \\\\( c \\\\). The variables used here are also biased to coincide with the ones already used in previous patterns to further increase the chance for dependencies. Groundings are added with 45% probability instead of a specification pattern.\\n\\nWe observe that these changes indeed lead to a much higher chance of unsatisfiability. Consider the code in `data generation/spec patterns.py` for exact reference of the individual steps in the generation process.\\n\\n**B.2 Temporal Relaxation for Formula Inspection**\\n\\nWe inspect the unsatisfiable formulas obtained by our generation process more closely. Concretely, we want to make sure that unsatisfiabilities do not stem from simple boolean contradictions, but actually require temporal reasoning to some extent. For example, the formula \\\\((a \\\\lor b) \\\\land \\\\neg b \\\\land \\\\neg a\\\\) can be found to be unsatisfiable without considering multiple time steps. In contrast, this would be required for a formula like \\\\(\\\\neg a \\\\mathcal{U} b \\\\land \\\\neg b \\\\land a\\\\).\\n\\nWe therefore introduce a temporal relaxation that transforms a LTL formula into a purely boolean formula. This allows us to check whether the relaxed version is already unsatisfiable (so, no temporal reasoning is required) or if it is only temporally unsatisfiable, which is the desired outcome. The relaxation is defined as follows:\\n\\n\\\\[\\n\\\\text{Rel}(\\\\phi \\\\ast \\\\psi) = \\\\text{Rel}(\\\\phi) \\\\ast \\\\text{Rel}(\\\\psi)\\n\\\\]\\n\\nfor \\\\(\\\\ast \\\\in \\\\{\\\\land, \\\\lor, \\\\rightarrow, \\\\leftrightarrow, \\\\oplus\\\\}\\\\)\\n\\n\\\\[\\n\\\\text{Rel}(\\\\phi \\\\mathcal{U} \\\\psi) = \\\\text{Rel}(\\\\phi) \\\\lor \\\\text{Rel}(\\\\psi)\\n\\\\]\\n\\n\\\\[\\n\\\\text{Rel}(\\\\phi \\\\mathcal{R} \\\\psi) = \\\\text{Rel}(\\\\psi)\\n\\\\]\\n\\n\\\\[\\n\\\\text{Rel}(\\\\phi) = \\\\top\\n\\\\]\\n\\n\\\\[\\n\\\\text{Rel}(\\\\neg \\\\alpha) = \\\\neg \\\\alpha\\n\\\\]\\n\\nNotably, negation is only allowed at the level of atoms. Each LTL formula can be rewritten in a negation normal form (NNF), where only operators \\\\(\\\\land, \\\\lor, \\\\mathcal{U}, \\\\mathcal{R}\\\\) occur anywhere and negations only before atoms. Consequently, the relaxation can be applied to each LTL formula by first bringing it to NNF.\\n\\n**B.3 Dataset**\\n\\nWe generated a raw dataset of 1.6M instances (see reproducibility section for details) up to size 50. To determine satisfiability, we use the tool `aalta` (Li et al., 2014). Its length distribution and satisfiability distribution is shown in Figures 5 and 6.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We filter out duplicates and balance satisfiable and unsatisfiable instances per size (Figure 7). Additionally, we apply the temporal relaxation and determine the satisfiability of relaxed unsatisfiable instances. This distinction is included in Figure 8. Finally, the dataset is split into a training set (80%) and validation set (10%). The resulting training set contains around 380K instances.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: Generated dataset size distribution (average size 33.6)\\n\\nFigure 10: Uncertainty dataset size distribution (average size 38.0)\\n\\nC.1 Shared layers for classifier included in critic\\n\\n| shared layers | sec | val acc       |\\n|---------------|-----|---------------|\\n| 0 / 4         | 2.2 | 2.2% (0.0)    |\\n| 2 / 4         | 2.2 | 26.6% (1.7)   |\\n| 3 / 4         | 2.2 | 24.9% (0.3)   |\\n| 4 / 4         | 2.2 | 24.0% (1.2)   |\\n\\nTable 4 shows classification benefits for sharing only some layers between classifier and critic. Also note that not sharing any layers, while yielding the highest fraction of fully correct formulas in the joint GAN and classification objective, degrades performance in the uncertainty setting, where a loss is backpropagated through the classifier part.\\n\\nC.2 Hyper-parameter comparison\\n\\nA hyper-parameter comparison with a 2-run average at 15K training steps.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 11: Validation accuracy during training of Transformer classifiers on different datasets. 5-run average, smoothed ($\\\\alpha = 0.9$). Complements Table 2.\\n\\nWe provide the training curves for the data substitution experiment (see Figure 11).\\n\\nC.4 STANDARD DEVIATIONS FOR TABLE 1\\n\\nTable 5: Standard deviations for Table 1, 3-run average, smoothed ($\\\\alpha = 0.95$)\\n\\n| Architecture | $\\\\sigma_{\\\\text{real}}$ | $\\\\sigma_{\\\\text{fc}}$ | $\\\\sigma_{\\\\text{sd}}$ | $\\\\sigma_{\\\\text{se}}$ | $\\\\sigma_{\\\\text{sd}}$ |\\n|--------------|------------------------|----------------------|----------------------|----------------------|----------------------|\\n| GAN          | 0.00                   | 0.00                 | -0.05                | 0.14                 | 0.02                 |\\n|              | 0.00                   | 0.05                 | 4.10                 | 0.04                 |\\n| WGAN         | 0.00                   | 1.51                 | 0.00                 | 2.52                 |\\n|              | 0.00                   | 0.1                  | 1.08                 |\\n|              | 0.00                   | 0.2                  | 0.47                 |\\n|              | 0.00                   | 0.4                  | 0.14                 |\\n\\nWe provide the standard deviations for Table 1 across 3 runs (see Table 5).\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DvcMMKmDJ3q", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DvcMMKmDJ3q", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Kuo-Hao Zeng, Mohammad Shoeybi, and Ming-Yu Liu. Style example-guided text generation using generative adversarial transformers. \\n\\narXiv preprint arXiv:2003.00674, 2020.\\n\\nYizhe Zhang, Zhe Gan, Kai Fan, Zhi Chen, Ricardo Henao, Dinghan Shen, and Lawrence Carin. Adversarial feature matching for text generation.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we provide the formal syntax and semantics of Linear-time Temporal Logic (LTL).\\n\\nThe formal syntax of LTL is given by the following grammar:\\n\\n$$\\\\phi ::= p | \\\\neg \\\\phi | \\\\phi \\\\land \\\\phi | \\\\phi \\\\lor \\\\phi | \\\\phi U \\\\phi,$$\\n\\nwhere $p \\\\in AP$ is an atomic proposition. Let $AP$ be a set of atomic propositions. A (explicit) trace $t$ is an infinite sequence over subsets of the atomic propositions. We define the set of traces $TR := (2^AP)^\\\\omega$. We use the following notation to manipulate traces: Let $t \\\\in TR$ be a trace and $i \\\\in \\\\mathbb{N}$ be a natural number. With $t[i]$ we denote the set of propositions at the $i$-th position of $t$. Therefore, $t[0]$ represents the starting element of the trace. Let $j \\\\in \\\\mathbb{N}$ and $j \\\\geq i$. Then $t[i,j]$ denotes the sequence $t[i] t[i+1] \\\\ldots t[j-1] t[j]$ and $t[i,\\\\infty]$ denotes the infinite suffix of $t$ starting at position $i$.\\n\\nLet $p \\\\in AP$ and $t \\\\in TR$. The semantics of an LTL formula is defined as the smallest relation $|$ that satisfies the following conditions:\\n\\n$$t | = p \\\\iff p \\\\in t[0]$$\\n$$t | = \\\\neg \\\\phi \\\\iff t \\\\not| = \\\\phi$$\\n$$t | = \\\\phi_1 \\\\land \\\\phi_2 \\\\iff t | = \\\\phi_1 \\\\text{ and } t | = \\\\phi_2$$\\n$$t | = \\\\phi_1 U \\\\phi_2 \\\\iff \\\\text{there exists } i \\\\geq 0 : t[i,\\\\infty] | = \\\\phi_2 \\\\text{ and for all } 0 \\\\leq j < i \\\\text{ we have } t[j,\\\\infty] | = \\\\phi_1$$\\n\\nThere are several derived operators, such as $\\\\phi \\\\equiv \\\\text{true} U \\\\phi$ and $\\\\phi \\\\equiv \\\\neg \\\\neg \\\\phi$. $\\\\phi$ states that $\\\\phi$ will eventually hold in the future and $\\\\phi$ states that $\\\\phi$ holds globally. Operators can be nested: $\\\\phi$, for example, states that $\\\\phi$ has to occur infinitely often.\\n\\nIn contrast to propositional logic (SAT), where a solution is a variable assignment, the solution to the satisfiability problem of an LTL formula is a computation trace. Traces are finitely represented in the form of a \\\"lasso\\\" $uv^\\\\omega$, where $u$, called prefix, and $v$, called period, are finite sequences of propositional formulas. For example the mutual exclusion formula above is satisfied by a trace $(\\\\{\\\\text{access } p_0\\\\} \\\\{\\\\text{access } p_1\\\\})^\\\\omega$ that alternates indefinitely between granting process $0 (p_0)$ and process $1 (p_1)$ access. There are, however, infinite solutions to an LTL formula. The empty trace $\\\\{\\\\}^\\\\omega$, where no access is granted at all, is also a solution. In our data representation, both, the LTL formula and the solution trace are represented as a finite sequence.\\n\\n**B.1 RICH LTL PATTERN CONCATENATION**\\n\\nPreviously, LTL formula generation based on patterns worked by concatenating random instantiations of a fixed set of typical specification patterns (Hahn et al., 2021). The instantiations were single variables, i.e. the response pattern $S \\\\rightarrow T$ could be used like $d \\\\rightarrow a$. We keep the concept of concatenating such patterns, but extend the process by mainly two concepts: rich pattern instantiations and groundings.\\n\\nDwyer et al. (1999) analyzed typical specifications constructed a system of frequently occurring patterns. They are grouped into different types such as absence ($\\\\neg S$, something does not occur) or response ($S \\\\rightarrow T$, if $S$ occurred, $T$ must eventually respond). These patterns can again appear in different scopes such as globally, before or between some events. The global absence pattern is then $\\\\neg S$; the absence before $Q$ pattern reads $Q R \\\\neg S$. When generating a new pattern for concatenation, we sample both a type and a scope and assign different probabilities to account for more common and exotic combinations. Additionally, we instantiate patterns not with single variables, but full subformulas, which results in much more reasonable and interesting patterns such as $\\\\neg (a \\\\land b)$ or $(\\\\neg d \\\\lor b) \\\\rightarrow (c \\\\land f) U e$. These subformulas may still contain temporal operators, but are strongly biased towards pure boolean operators.\\n\\nDuring concatenating the different parts of a formula, we also distinguish between adding instantiated patterns and groundings. The problem with complex patterns and especially complex scopes...\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The Transformer GAN architecture for generating symbolic reasoning problems (TGAN-SR) is depicted in Figure 1. It consists of two Transformer encoders as discriminator/critic and generator, respectively. The inner layers of the encoders are largely identical to standard transformers (Vaswani et al., 2017), but their input and output processing is adjusted to the GAN setting. We use an embedding dimension of \\\\(d_{emb} = 128\\\\), \\\\(n_h = 8\\\\) attention heads, and a feed-forward network dimension of \\\\(d_{FF} = 1024\\\\) for both encoders as default.\\n\\nThe generator's input is a real scalar random value with uniform distribution \\\\([0, 1]\\\\) for each position in the sequence. It is mapped to \\\\(d_{emb}\\\\) by an affine transformation before being processed by the first layer. The position-wise padding mask is copied from the real data during training, so the lengths of real and generated formulas at the same position in a batch are always identical. During inference, the lengths can either be sampled randomly or copied from an existing dataset similar to training. Either way, the generator encoder's padding mask is predetermined so it has to adequately populate the unmasked positions. With \\\\(V\\\\) being the vocabulary, and \\\\(|V|\\\\) being the size of the vocabulary, an affine transformation to dimensionality \\\\(|V|\\\\) and a softmax is applied after the last layer. The generator's output lies, thus, in the same space as one-hot encoded tokens. We use \\\\(n_lG = 6\\\\) layers for our default model's generator.\\n\\nA GAN discriminator and WGAN critic are virtually identical in terms of their architecture. The only difference is that a critic outputs a real scalar value where a discriminator is limited to the range \\\\([0, 1]\\\\), which we achieve by applying an additional logistic sigmoid in the end. To honor their differences regarding the training scheme, we use both terms when referring to exchangeable properties and make no further distinctions between them. For input processing, their \\\\(|V|-\\\\text{dimensional (per position)}\\\\) input is mapped to \\\\(d_{emb}\\\\) by an affine transformation. After the last layer, the final embeddings are aggregated over the sequence by averaging and a linear projection to a scalar value (the prediction logit) is applied. Our default model uses \\\\(n_lD = 4\\\\) layers. We achieved best results with slightly more generator than discriminator/critic layers. A full hyperparameter study can be found in Appendix C.2.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Quality measures for the GAN and WGAN variant when generating temporal specifications.\\n\\ntell real and generated instances apart, this would pose a serious difficulty for training. We therefore sample a $|V|$-sized vector of Gaussian noise $\\\\mathcal{N}(0, \\\\sigma^2)$ for each position (see Figure 1). We add it to the real samples' one-hot encoding and re-normalize it to sum 1 before handing them to the discriminator/critic. By default, we use a value of $\\\\sigma = 0.1$ for all models to get comparable results. We study the effect of different amounts of noise more closely in Section 4.1.2.\\n\\n4 EXPERIMENTS\\n\\nIn this section, we report our experimental findings. We structure our results in three sections. We first report on the performance of the TGAN-SR architecture in constructing syntactically correct instances of temporal specifications and mathematical expressions. Secondly, we show, exemplary for LTL formulas, that the newly generated dataset can be used as a substitute for the origin dataset. Lastly, we show, by altering the target distribution, that the network can generate a dataset that is harder to solve for a classifier. We trained the models on an NVIDIA DGX A100 system for around 8 hours. We begin each subsection with a short preamble on the training setting.\\n\\n4.1 PRODUCING SYNTACTICALLY CORRECT SYMBOLIC REASONING PROBLEMS\\n\\nThe goal of the experiments in this section is to assess the generator\u2019s capability in creating valid symbolic reasoning problems as objectively as possible. If not stated otherwise, in plots and tables, we report results from our default model averaged across three runs and with an exponential smoothing ($\\\\alpha = 0.95$) applied. For temporal specifications, we use $\\\\mathcal{LTL}_{base}$ as training set and for symbolic math the dataset described in section 2.2.\\n\\n4.1.1 TRAINING SETTING\\n\\nFor the GAN variant, we employ the standard GAN training algorithm (Goodfellow et al., 2014). For our default model, we use $n_{c} = 2$ discriminator training steps per generator training step and a batch size of $bs = 1024$. Notably, we use the alternative generator loss $-\\\\mathbb{E}_{z \\\\sim p(z)} \\\\log D(G(z))$ instead of the theoretically more sound $\\\\mathbb{E}_{z \\\\sim p(z)} \\\\log (1 - D(G(z)))$. The WGAN variant uses the WGAN-GP training with gradient penalty as proposed by Gulrajani et al. (2017) with $\\\\lambda_{GP} = 10$. Standard WGAN losses are used and the training loop parameters $n_{c}$ and $bs$ are identical to the GAN variant. To calculate the gradient penalty of intermediate data points according to Gulrajani et al. (2017), we make use of the fact that for each batch element, real and generated samples share the padding mask. After the gradient with respect to an intermediate point is calculated, the gradient\u2019s squared components are masked out at padded positions before being summed up over the sequence length. For both variants, both discriminator and generator are trained with the Adam (Kingma & Ba, 2015) optimizer ($\\\\beta_1 = 0$, $\\\\beta_2 = 0.9$) and constant learning rate $lr = 10^{-4}$, similar to Gulrajani et al. (2017).\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Generating valid symbolic reasoning problems. During training we periodically sample several generated instances and convert them to their text representation, which involves taking the argmax at every position. We then try to parse a prefix-encoded tree from the resulting tokens. If the parsing of a problem is successful and no tokens remain in the sequence, we note this problem as fully correct. The fraction over the course of training to generate temporal specifications is depicted in Figure 2a. Both GAN and WGAN variants increase the measure relatively continuously, but eventually reach their limit around $30\\\\,\\\\text{K}$ training steps. Still, both generators are able to produce a large fraction of fully correct temporal specifications, despite the length of the instances (up to $50$ tokens) and the non-autoregressive, fixed-step architecture. We list some examples below:\\n\\n$$\\\\neg (h \\\\rightarrow h) \\\\land \\\\land (g \\\\lor h) \\\\land (g \\\\land g) \\\\land \\\\neg j \\\\land \\\\neg j \\\\land \\\\neg b \\\\land (h \\\\land j \\\\rightarrow j) \\\\land j,$$\\n\\n$$\\\\lnot \\\\bigl((c \\\\lor i) \\\\land \\\\lnot d \\\\land \\\\lnot c\\\\bigr) \\\\land \\\\lnot c \\\\land \\\\lnot \\\\bigl((b \\\\leftrightarrow c) \\\\leftarrow \\\\lnot (b \\\\leftrightarrow c)\\bigr) \\\\land \\\\lnot \\\\bigl((b \\\\land d \\\\rightarrow d) \\\\land c\\\\bigr).$$\\n\\nThe network also produces correct symbolic mathematical expressions when training on the forward generated mathematical dataset of Lample & Charton (2020). After $30\\\\,\\\\text{K}$ steps, on average $30\\\\%$ are fully correct. We list some examples below:\\n\\n$$x^3 \\\\cdot (\\\\ln x^3 + 2 \\\\cdot x \\\\cdot (\\\\text{acosh}(5) + 1 + (-1) \\\\cdot x \\\\cdot (2 + x)^4)),\\\\quad 1 \\\\div 2 \\\\cdot 81264 \\\\div x \\\\cdot 1 \\\\div 5 \\\\cdot x \\\\cdot \\\\ln 4 + 2,$$\\n\\n$$x \\\\cdot (3 \\\\cdot (x^3) + x \\\\cdot 2) + (2 + x) \\\\cdot 4 \\\\cdot x \\\\cdot (1 \\\\div 201 + \\\\text{acos}(44)).$$\\n\\nDifferences in homogeneity. Comparing the valid generated formulas from the WGAN and GAN variants, we find that often, the latter would produce formulas in the likes of $i \\\\land i \\\\land \\\\neg \\\\neg \\\\neg \\\\neg i \\\\land \\\\neg \\\\neg (g \\\\land g \\\\land i)$ or $\\\\tanh 1222555667667799655766669 \\\\cdot x$, which contains repetitions (of the -operator) or easily stringed together sequences (for example of numbers). In fact, some GAN runs achieved fully correct fractions above $30\\\\%$ (higher than WGAN), but these exclusively produced formulas with such low internal variety. To quantify this, we calculated a sequence entropy which treats the number of occurrences of the same token in the sequence relative to the sequences length as probability. Figure 2b shows that indeed this metric decreases for the GAN variant during training but remains stable for WGANs. We therefore speculate that the discriminator/critic indeed learns to check syntactic validity to some extend and some generators \u201cexploit\u201d this fact by producing correct, but repetitive formulas. For further experiments that use generated instances, we therefore exclusively stick to the WGAN variant.\\n\\nDiscriminator / critic predictions. We observe a quick identification of real and generated instances by the GAN discriminator as depicted in Figure 3. Predictions reach values above $0.99$ and $5$. \"}"}
{"id": "DvcMMKmDJ3q", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022.\\n\\nFigure 4: GAN discriminator predictions for generated samples with different noise level $\\\\sigma_{\\\\text{real}}$ on real samples when generating temporal specifications.\\n\\nBelow 0.01, respectively, and never change directions. Similarly, the WGAN critic\u2019s Wasserstein distance estimate soon reaches a value of around 0.4 at which it remains for the rest of training. For this behavior, one would expect the generator to not improve significantly, which is contrary to the observed improvements in quality.\\n\\nEffects of additive noise on one-hot representation. We also studied the effect of adding different amounts of noise to the one-hot representation of real temporal specification instances (see Table 1). It strongly affects the performance of the GAN scheme, which is unable to work without added noise. Stronger noise however improves this variants performance. WGAN models on the other hand were not significantly influenced by added noise and are able to be trained without it.\\n\\nAdditionally, we compare how the GAN discriminator rates unmodified generated instances and argmaxed versions thereof (see Figure 4). For this, we also evaluate argmaxed instances during each step of training without changing the training regime. While the score for unmodified instances immediately decreases at the start of the training, it initially rises for the argmaxed ones. After a while of training, though, the scores of the argmaxed samples quickly deteriorate and, at least for lower values of $\\\\sigma_{\\\\text{real}}$, approach their soft-valued counterparts. A possible interpretation is that the discriminator first identifies generated samples by their different distributions in the one-hot domain, which, naturally, is eased with low noise on the real samples, before shifting its focus from this low-level criterion to more global features.\\n\\n4.2 Substituting training data with generated instances\\n\\nIn this subsection, we show that the origin training data can be substituted with generated training data when training a classifier on the LTL satisfiability problem.\\n\\nTable 1: Comparison on fully correct formulas ($fc$) and sequence entropy ($se$) of GAN and WGAN with different $\\\\sigma_{\\\\text{real}}$ when generating temporal specifications. 3-run average, smoothed ($\\\\alpha = 0.95$), standard deviations in Table 5.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Constructing training data for symbolic reasoning domains is challenging: Existing instances are typically hand-crafted and too few to be trained on directly and synthetically generated instances are often hard to evaluate in terms of their meaningfulness. We study the capabilities of GANs and Wasserstein GANs equipped with Transformer encoders to generate sensible and challenging training data for symbolic reasoning domains. We conduct experiments on two problem domains where Transformers have been successfully applied recently: symbolic mathematics and temporal specifications in verification. Even without autoregression, our GAN models produce syntactically correct instances. We show that the generated data can be used as a substitute for real training data when training a classifier, and, especially, that training data can be generated from a real dataset that is too small to be trained on directly. Using a GAN setting also allows us to alter the target distribution: We show that by adding a classifier uncertainty part to the generator objective, we obtain a dataset that is even harder to solve for a classifier than our original dataset.\\n\\n1 INTRODUCTION\\n\\nDeep learning is increasingly applied to more untraditional domains that involve complex symbolic reasoning. Examples include the application of deep neural network architectures to SAT (Selsam et al., 2019; Selsam & Bj\u00f8rner, 2019; Ozolins et al., 2021), SMT (Balunovic et al., 2018), temporal specifications in verification (Hahn et al., 2021; Schmitt et al., 2021), symbolic mathematics (Lample & Charton, 2020), or theorem proving (Loos et al., 2017; Bansal et al., 2019; Huang et al., 2019; Urban & Jakubuv, 2020).\\n\\nThe acquisition of training data for symbolic reasoning domains, however, is a challenge. Existing instances, such as benchmarks in competitions (Biere & Claessen, 2010; Froleyks et al., 2021; Jacobs et al., 2017) are typically hand-crafted, for example, in a \u201cbring your own benchmarks\u201d setting (Balyo et al., 2017). Since the instances are too few to be trained on, training data is, thus, typically generated synthetically. For example by random sampling (Selsam et al., 2019; Lample & Charton, 2020), or by randomly re-combining parts of existing instances (Schmitt et al., 2021). Although these data generation methods already lead to good results, training on randomly generated data carries the risk of training on meaningless data or the risk of introducing unwanted biases.\\n\\nIn this paper, we study the generation of symbolic reasoning problems with Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) and show that they can be used to construct large amounts of meaningful training data from a significantly smaller data source. GANs, however, can not immediately be applied: Symbolic reasoning problems reside typically in a discontinuous domain and, additionally, training data is typically sequential and of variable length. We show that training directly in the one-hot encoding space is possible when adding Gaussian noise to each position. We, furthermore, use a Transformer (Vaswani et al., 2017) encoder to cope with the sequential form of the data and the variable length of the problem instances.\\n\\nWe provide experiments to show the usefulness of a GAN approach for the generation of reasoning problems. The experiments are based around two symbolic reasoning domains where recent studies on the applicability of deep learning relied on large amounts of artificially generated data: symbolic mathematics and linear-time temporal logic (LTL) specifications in verification. We report our experimental results in three sections. We first provide details on how to achieve a stable training of\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"a standard GAN and a Wasserstein GAN (Arjovsky et al., 2017) both equipped with Transformer encoders. We analyze the particularities of their training behavior, such as the effects of adding different amounts of noise to the one hot embeddings. Secondly, we show for an LTL satisfiability classifier that the generated data can be used as a substitute for real training data, and, especially, that training data can be generated from a real dataset that is too small to be trained on directly. In particular, we show that out of $10^k$ real training instances, a dataset consisting of $400^k$ instances can be generated, on which a classifier can successfully be trained on. Lastly, we show that generating symbolic reasoning problems in a GAN setting has a specialty: We can alter the target distribution by adding a classifier uncertainty part to the generator objective. By doing this, we show that we can obtain a dataset that is even harder to solve than the original dataset which has been used to generate the data from.\\n\\nThe remainder of this paper is structured as follows. In Section 2, we give a short introduction to the problem domains considered in this paper and describe how the origin training data has been constructed. In Section 3, we present our Transformer GAN architecture(s), before providing experimental results in Section 4. We give an overview over related work in Section 5 before concluding in Section 6.\\n\\n2 PROBLEM DOMAIN AND BASE DATASETS\\n\\nIn this section, we introduce the two problem domains on which we base our experiments on: satisfiability of temporal specifications for formal verification and function integration and ordinary differential equations (ODEs) for symbolic mathematics. We furthermore give an overview over the data generation processes of these base datasets.\\n\\n2.1 HARDWARE SPECIFICATIONS IN LINEAR-TIME TEMPORAL LOGIC (LTL)\\n\\nLinear-time Temporal Logic (LTL) (Pnueli, 1977) is the basis for industrial hardware specification languages like the IEEE standard PSL (IEEE-Commission et al., 2005). It is an extension of propositional logic with temporal modalities, such as the Next-operator ($\\\\operatorname{Next}$) and the Until-operator ($\\\\operatorname{Until}$). There also exist derived operators, such as \u201ceventually\u201d $\\\\phi$ ($\\\\equiv \\\\operatorname{true} \\\\land \\\\operatorname{Until} \\\\phi$) and \u201cglobally\u201d $\\\\phi$ ($\\\\equiv \\\\neg \\\\neg \\\\phi$). For example, mutual exclusion can be expressed as the following specification:\\n\\n$$\\\\neg (\\\\text{access} p_0 \\\\land \\\\text{access} p_1),$$\\n\\nstating that processes $p_0$ and $p_1$ should have no access to a shared resource at the same time. The base problem of any logic is its satisfiability problem. It is the problem to decide whether there exists a solution to a given formula. The satisfiability problem of LTL is a hard problem, in fact, it is PSPACE-hard (Sistla & Clarke, 1982). The full syntax, semantics and additional information on the satisfiability problem can be found in Appendix A.\\n\\nSo far, the construction of datasets for LTL formulas has been done in two ways (Hahn et al., 2021): Either by obtaining LTL formulas from a fully random generation process, which likely results in unrealistic formulas, or by sampling conjunctions of LTL specification patterns (Dwyer et al., 1999). To obtain a healthy amount of unsatisfiable and satisfiable instances in this artificial generation process, we slightly refined the pattern-based generation method with two operations. Details can be found in Appendix B. Since the formula length correlates to unsatisfiability, we filter for equal proportions of classes per formula length. We restrict the tree size of the formulas to 50. We call this dataset $\\\\text{LTLbase}$.\\n\\n2.2 SYMBOLIC MATHEMATICS\\n\\nLample & Charton (2020) showed that Transformer models perform surprisingly well on symbolic mathematics. More precisely, they applied the models to function integration and ordinary differential equations (ODEs).\\n\\nWe consider the function integration problem and use the forward generated dataset (https://github.com/facebookresearch/SymbolicMathematics). Random functions with up to $n$ operators are generated and their integrals are calculated with computer algebra systems. Functions that the system cannot integrate are discarded. Mathematical expressions are generated randomly. The dataset is cleaned, with equation simplification, coefficients simplification, and filtering out invalid expressions (Lample & Charton, 2020). We restrict the tree size to 50.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.2.1 TRAINING SETTING\\n\\nBinary classifier. We use a classifier that is similar to the GAN discriminator, consisting of a Transformer encoder followed by an averaging aggregation and linear transformation to a scalar output value. Finally, a logistic sigmoid is applied to obtain a prediction for the formula's satisfiability. The classification loss is a standard cross-entropy between real labels and predictions. Similar to the GAN discriminator, we use $\\\\text{nl}=4$ layers and a batch size of $\\\\text{bs}=1024$. Contrary to the GAN training scheme, we use the default Transformer scheme Vaswani et al. (2017) with varying learning rate and 4000 warmup steps as well as the Adam optimizer Kingma & Ba (2015) with parameters $\\\\beta_1=0.9$, $\\\\beta_2=0.98$. This training scheme resulted in a faster improvement and higher final accuracy than adopting the settings from GAN training. We trained the classifier for $30K$ steps.\\n\\nGenerated dataset.\\n\\nTo obtain a dataset of generated instances, we first train a WGAN with default parameters but smaller batch size of 512 on a set of $10K$ instances from the LTLbase dataset. After training for $15K$ steps, we collect $800K$ generated formulas from it and call this dataset Generated-raw. This set is processed similar to the original base dataset: Duplicates are removed and satisfiable and unsatisfiable instances are balanced to equal amounts per formula size. We randomly keep $400K$ instances and call the resulting dataset Generated.\\n\\n4.2.2 RESULTS\\n\\nWe compare the performance of similar classifiers on different training sets in Table 2. The training curves can be found in Appendix C.3. The validation accuracy is computed on the LTLbase dataset. Training on differently-sized subsets of LTLbase shows that a reduced number of training samples strongly decreases performance. $10K$ instances lead to immense overfitting and poor accuracy. We were not able to train a classifier on this few formulas with significantly higher accuracy. A classifier trained on the Generated set however achieves almost the identical validation accuracy on the base set as the classifier that was actually trained on it. Note that the GAN that created this set was trained on only $10K$ instances. We therefore find that the data produced by the TGAN-SR is highly valuable as it can serve as full substitute for the complete original training data even when provided with much fewer examples.\\n\\nTwo instances of LTLbase, $(\\\\neg a) \\\\land (a)$ and $(e) \\\\land (\\\\neg e)$, i.e. only 0.02%, reappear in the $800K$ large data set Generated-raw. Additionally, in Generated-raw, only $2.3K$ of the $800K$ (0.28%) generated formulas were duplicates, which displays an enormous degree of variety.\\n\\n4.3 UNCERTAINTY OBJECTIVE FOR GENERATING HARDER-TO-CLASSIFY INSTANCES\\n\\nIn this experiment, we show that, by adding an uncertainty measure to a simultaneously trained classifier, the model generates instances of temporal specifications in LTL that are harder to classify. We train a model on the LTLbase dataset to jointly learn to imitate its formulas and classify them as satisfiable or unsatisfiable.\\n\\n### Table 2: Accuracies of Transformer classifiers trained on different datasets (5-run average with standard deviations in parentheses); all are validated on the LTLbase dataset.\\n\\n| Dataset   | $\\\\text{bs}$ | train acc @ $30K$ | val acc @ $30K$ | train acc @ $50K$ | val acc @ $50K$ | train acc @ $100K$ | val acc @ $100K$ | train acc @ $500K$ | val acc @ $500K$ |\\n|-----------|-------------|------------------|----------------|------------------|----------------|-------------------|------------------|------------------|------------------|\\n| LTLbase   | 1024        | 96.6% (0.5)      | 95.5% (0.4)    | 98.1% (0.3)      | 96.1% (0.3)    |                   |                  |                  |                  |\\n| LTLbase   | 512         | 92.4% (0.7)      | 93.0% (0.8)    | 95.4% (0.5)      | 95.0% (0.8)    |                   |                  |                  |                  |\\n| LTLbase   | 1000        | 95.3% (0.7)      | 88.3% (0.9)    | 98.1% (0.3)      | 87.8% (1.0)    |                   |                  |                  |                  |\\n| LTLbase   | 512         | 100% (0.1)       | 76.4% (1.7)    | 100% (0.0)       | 75.5% (1.5)    |                   |                  |                  |                  |\\n| Generated | 1024        | 95.4% (0.2)      | 93.6% (1.0)    | 97.1% (0.1)      | 93.9% (0.3)    |                   |                  |                  |                  |\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We share the three lower layers of the encoder but have separate fourth layers. We found this to improve both classification accuracy and GAN performance slightly compared to sharing all layers (the linear projection layer is never shared). A comparison can be found in Section C.1 in the appendix. We stick to the WGAN training scheme from Section 4.1.1 including the optimizer settings, but add an additional classification loss term similar to Section 4.2.1. The classification loss is added to the GAN critic loss and scaled by coefficient $\\\\alpha_{\\\\text{class}}$, which we set to $10$ when training a WGAN.\\n\\nThe resulting model achieves similar generative performance to the pure WGAN but is limited to a classification accuracy of around $92\\\\%$.\\n\\nClassifier uncertainty. We calculate the entropy of a class prediction $s$ of the classifier as\\n\\n$$H(s) = -s \\\\cdot \\\\log(s) - (1-s) \\\\cdot \\\\log(1-s),$$\\n\\nas a measure of uncertainty on a particular instance. We add a term $-\\\\alpha_{\\\\text{unct}}H(s)$ to the generator's loss function, which leads to the uncertainty measure being propagated back through the critic just like the standard GAN objective. $H(s)$ is maximized at $s = 0$ (with value $\\\\log 2$), so the generator is encouraged to produce instances which \\\"confuse\\\" the classifier included in the critic. Naturally, this conflicts with the original GAN objective, so they must be carefully balanced. As default, we chose $\\\\alpha_{\\\\text{conf}} = 2$. Since GAN training is hindered by adding the uncertainty objective, we only apply it after pre-training for $30K$ steps with default WGAN and classification objectives. We then train for additional $15K$ steps with the uncertainty objective included. This decreases the fraction of fully correct formulas to around $10\\\\%$; sequence entropy as classification accuracy remain unaffected. From the fully trained model, we obtain a dataset similar to Section 4.2.1 and call it Uncert-e. Additionally, we construct a dataset of $200K$ formulas from this set and $200K$ from LTLbase and call it Mixed-e.\\n\\nAlternative uncertainty objective. The entropy becomes unhandy to compute for values close to 0 and 1. We therefore explore a pragmatic alternative measure for (un)certainty: the absolute value of the classification logit. Values close to zero lead to predictions around $0.5$. We therefore add a generator loss of the form $\\\\alpha_{\\\\text{unct}}|l|$ for this variant (with $l$ the classification logit; $s = \\\\sigma(l)$) and use a value of $\\\\alpha_{\\\\text{conf}} = 0.5$ in this case. The model is trained similar to the entropy variant and behaves very similarly. We call the dataset obtained from this model Uncert-a and also construct a mixed set Mixed-a.\\n\\n### 4.3.2 RESULTS\\n\\nWe compare the accuracy of classifiers trained similar to Section 4.2 (pure classifiers with optimized training schedule, not included GAN classifiers) on different (generated) datasets in Table 3. The classifier trained on LTLbase serves as reference again with $94.8\\\\%$ accuracy. Training on the Uncert sets however allows the classifier to achieve only $91.0\\\\%$ and $90.2\\\\%$ accuracy (for entropy and absolute variants, respectively). Also when trained longer than $30K$ steps, there is no significant improvement.\\n\\nThe datasets produced by WGANs with added uncertainty objective are indeed harder to classify than the original dataset LTLbase. To validate this, we also trained classifiers on Mixed sets and find that they also achieve $4.5$ percent points higher accuracy when tested on the base set compared to the generated sets. Additionally, the performance on the original dataset is never deteriorated and even slightly higher when training on the mixed set. This approach is especially useful in the domain of symbolic reasoning, because data can, in contrast to archetypal deep learning domains, often be labeled automatically (e.g. with classical tools and algorithms). This underpins the usefulness of a GAN setting when generating new training instances for symbolic reasoning problems.\\n\\n| trained on | tested on | accuracy |\\n|------------|-----------|----------|\\n| LTLbase    | Uncert-e  | 91.0% (0.5) |\\n| Uncert-e   | Uncert-e  | 90.2% (0.9) |\\n| Mixed-e    | Uncert-e  | 90.5% (0.5) |\\n| Mixed-a    | Uncert-a  | 89.6% (0.4) |\\n| Mixed-a    | LTLbase   | 94.1% (0.4) |\\n\\nTable 3: Performance of classifiers trained and tested on datasets generated with uncertainty objectives; $30K$ steps, $5$-run average with standard deviations, not smoothed.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5 RELATED WORK\\nGANs. Generative Adversarial Networks have been applied to discrete domains especially for text generation in a reinforcement learning setting (Chen et al., 2018; Yu et al., 2017; Che et al., 2017; Lin et al., 2017; Fedus et al., 2018; Guo et al., 2018) or by using a Gumbel softmax (Kusner & Hernandez-Lobato, 2016; Zhang et al.). Kumar & Tsvetkov (2020) use a continuous, pre-trained embedding. Gulrajani et al. (2017) showed that it is possible to directly use a soft one-hot representation without any sampling. Close related work is Huang et al. (2020) and Zeng et al. (2020) for adversarial text generation. They also combine Transformers and in an adversarial learning setting, where the former rely on Gumbel softmax tricks and the latter extract a style code from reference examples. Transformers and GANs have also been combined in the domain of computer vision (Vondrick & Torralba, 2017; Jiang et al., 2021; Hudson & Zitnick, 2021). GANs have been used for data augmentation, especially for images, e.g., (Antoniou et al., 2018; Bowles et al., 2018).\\n\\nTemporal logics. Temporal logics have been studied in computer science since their introduction by Pnueli (1977). Since then, many extensions have been developed: e.g., computation tree logic CTL and CTL* (Clarke & Emerson, 1981; Emerson & Halpern, 1986), signal temporal logic STL (Maler & Nickovic, 2004), or temporal logics for hyperproperties, e.g., HyperLTL, (Clarkson et al., 2014). Verification methods for temporal logics have been studied extensively over the years, e.g., LTL satisfiability (Li et al., 2013; Rozier & Vardi, 2007; Schuppan & Darmawan, 2011; Li et al., 2013; 2014; Schwendimann, 1998), LTL synthesis (Finkbeiner & Schewe, 2005; 2013; Bohy et al., 2012; Faymonville et al., 2017; Meyer et al., 2018), model checking (Clarke et al., 1986), or monitoring (Clarke et al., 2001; Bauer et al., 2011; Finkbeiner & Sipma, 2004; Donz\u00e9 et al., 2013).\\n\\nMathematical reasoning in machine learning. Other works have studied datasets derived from automated theorem provers (Blanchette et al., 2016; Loos et al., 2017; Gauthier et al., 2021), interactive theorem provers (Irving et al., 2016; Kaliszyk et al., 2017; Bansal et al., 2019; Huang et al., 2019; Yang & Deng, 2019; Polu & Sutskever, 2020; Wu et al., 2021b; Li et al., 2020; Lee et al., 2020; Urban & Jakubuv, 2020; Rabe et al., 2021; Paliwal et al., 2020; Rabe & Szegedy, 2021), symbolic mathematics (Lample & Charton, 2020; Zaremba et al., 2014; Allamanis et al., 2017; Arabshahi et al., 2018), and mathematical problems in natural language (Saxton et al., 2019; Schlag et al., 2019). Learning has been applied to mathematics long before the rise of deep learning. Earlier works focused on ranking premises or clauses (Cairns, 2004; Urban, 2004; 2007; Urban et al., 2008; Meng & Paulson, 2009; Schulz, 2013; Kaliszyk & Urban, 2014).\\n\\nNeural architectures for logical reasoning. Wu et al. (2021a) present a reinforcement learning approach for interactive theorem proving. NeuroSAT (Selsam et al., 2019) is a graph neural network (Scarselli et al., 2009; Li et al., 2018; Gilmer et al., 2017; Wu et al., 2021c) for solving the propositional satisfiability problem. A simplified NeuroSAT architecture was trained for unsat-core predictions (Selsam & Bj\u00f8rner, 2019). Neural networks have been applied to 2QBF (Lederman et al., 2020), logical entailment (Evans et al., 2018), SMT (Balunovic et al., 2018), and temporal logics (Hahn et al., 2021; Schmitt et al., 2021).\\n\\n6 CONCLUSION\\nWe studied the capabilities of (Wasserstein) GANs equipped with two Transformer encoders to generate sensible training data for symbolic reasoning problems. We showed that both can be trained directly on the one-hot encoding space when adding Gaussian noise. We exemplary conducted experiments in the domain of symbolic mathematics and hardware specifications in temporal logics. We showed that training data can indeed be generated and that the data can be used as a meaningful substitute when training a classifier. Furthermore, we showed that a GAN setting has a speciality: by adding an uncertainty measure to the generator's output, the models generated instances on which a classifier was harder to train on. In general, logical and mathematical reasoning with neural networks requires large amounts of sensible training data. Better datasets will lead to powerful neural heuristics and end-to-end approaches for many symbolic application domains, such as mathematics, search, verification, synthesis and computer-aided design. This novel, neural perspective on the generation of symbolic reasoning instances is also of interest to generate data for tool competitions, such as SAT, SMT, or model checking competitions.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Miltiadis Allamanis, Pankajan Chanthirasegaran, Pushmeet Kohli, and Charles Sutton. Learning continuous semantic representations of symbolic expressions. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pp. 80\u201388. PMLR, 2017. URL http://proceedings.mlr.press/v70/allamanis17a.html.\\n\\nAntreas Antoniou, Amos J. Storkey, and Harrison Edwards. Augmenting image classifiers using data augmentation generative adversarial networks. In Vera Kurkova, Yannis Manolopoulos, Barbara Hammer, Lazaros S. Iliadis, and Ilias Maglogiannis (eds.), Artificial Neural Networks and Machine Learning - ICANN 2018 - 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part III, volume 11141 of Lecture Notes in Computer Science, pp. 594\u2013603. Springer, 2018. doi: 10.1007/978-3-030-01424-7_58. URL https://doi.org/10.1007/978-3-030-01424-7_58.\\n\\nForough Arabshahi, Sameer Singh, and Animashree Anandkumar. Towards solving differential equations through neural programming. In ICML Workshop on Neural Abstract Machines and Program Induction (NAMPI), 2018.\\n\\nMart\u00edn Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein GAN. CoRR, abs/1701.07875, 2017. URL http://arxiv.org/abs/1701.07875.\\n\\nMislav Balunovic, Pavol Bielik, and Martin T. Vechev. Learning to solve SMT formulas. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pp. 10338\u201310349, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/68331ff0427b551b68e911eebe35233b-Abstract.html.\\n\\nTom\u00e1\u0161 Balyo, Marijn J.H. Heule, and Matti J\u00e4rvisalo. Proceedings of SAT Competition 2017: Solver and Benchmark Descriptions, volume B-2017-1 of Series of Publications B. Department of Computer Science, University of Helsinki, Finland, 2017.\\n\\nKshitij Bansal, Sarah M. Loos, Markus N. Rabe, Christian Szegedy, and Stewart Wilcox. Holist: An environment for machine learning of higher order logic theorem proving. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 454\u2013463. PMLR, 2019. URL http://proceedings.mlr.press/v97/bansal19a.html.\\n\\nAndreas Bauer, Martin Leucker, and Christian Schallhart. Runtime verification for LTL and TLTL. ACM Trans. Softw. Eng. Methodol., 20(4):14:1\u201314:64, 2011. doi: 10.1145/2000799.2000800. URL https://doi.org/10.1145/2000799.2000800.\\n\\nArmin Biere and K Claessen. Hardware model checking competition. In Hardware Verification Workshop, 2010.\\n\\nJasmin Christian Blanchette, Cezary Kaliszyk, Lawrence C. Paulson, and Josef Urban. Hammering towards QED. J. Formaliz. Reason., 9(1):101\u2013148, 2016. doi: 10.6092/issn.1972-5787/4593. URL https://doi.org/10.6092/issn.1972-5787/4593.\\n\\nAaron Bohy, V\u00e9ronique Bruy\u00e8re, Emmanuel Filiot, Naiyong Jin, and Jean-Fran\u00e7ois Raskin. Aca+cia+, a tool for LTL synthesis. In Computer Aided Verification - 24th International Conference, CAV 2012, Berkeley, CA, USA, July 7-13, 2012 Proceedings, volume 7358 of Lecture Notes in Computer Science, pp. 652\u2013657. Springer, 2012. doi: 10.1007/978-3-642-31424-7_45. URL https://doi.org/10.1007/978-3-642-31424-7_45.\\n\\nChristopher Bowles, Liang Chen, Ricardo Guerrero, Paul Bentley, Roger N. Gunn, Alexander Hammers, David Alexander Dickie, Maria del C. Vald\u00e9s Hern\u00e1ndez, Joanna M. Wardlaw, and Daniel Rueckert. GAN augmentation: Augmenting training data using generative adversarial networks. CoRR, abs/1810.10863, 2018. URL http://arxiv.org/abs/1810.10863.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: GAN variant with uniform instead of Gaussian noise. 2-run average with standard deviations, smoothed ($\\\\alpha = 0.99$).\\n\\n| $\\\\alpha$ | min | max | $f_c$ | $se$ |\\n|---------|-----|-----|-------|------|\\n| 0       | 0   | 0.1 | 19.2% | (2.94) |\\n| 0.2     | 0   | 0.2 | 33.3% | (1.04) |\\n| 0.4     | 0   | 0.4 | 11.2% | (3.32) |\\n\\nAs evident from Table 6 in comparison with Table 1, a uniform noise has no benefit over Gaussian noise.\\n\\nC.6 OUT-OF-DISTRIBUTION CLASSIFICATION EXPERIMENTS\\n\\nTable 7: Classifiers trained on different datasets tested out-of-distribution. 5-run average, not smoothed.\\n\\n|        | trained on | tested on | accuracy | $se$  |\\n|--------|------------|-----------|----------|-------|\\n| LTLbase| 30K        | Benchmarks| 85.2%    | (2.2) |\\n| Uncert-e| 30K        | Benchmarks| 85.9%    | (2.9) |\\n| Uncert-e| 30K        | LTLbase   | 87.5%    | (0.9) |\\n| Mixed-e| 30K        | Mixed-e   | 92.7%    | (0.6) |\\n| LTLbase| 50K        | Benchmarks| 86.0%    | (5.0) |\\n| Generated| 50K        | Benchmarks| 94.1%    | (1.2) |\\n\\nA synthetic dataset that is designed to bring classical solvers to their limits is a portfolio dataset (Schuppan & Darmawan, 2011), of which around 750 formulas fit into our encoder token and size restrictions. We conducted an out-of-distribution test on these scalable benchmarks (Table 7). Note that almost all of the instances are satisfiable.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nPaul A. Cairns. Informalising formal mathematics: Searching the mizar library with latent semantics. In Mathematical Knowledge Management, Third International Conference, MKM 2004, Bialowieza, Poland, September 19-21, 2004, Proceedings, volume 3119 of Lecture Notes in Computer Science, pp. 58\u201372. Springer, 2004. doi: 10.1007/978-3-540-27818-4.\\n\\nTong Che, Yanran Li, Ruixiang Zhang, R. Devon Hjelm, Wenjie Li, Yangqiu Song, and Yoshua Bengio. Maximum-likelihood augmented discrete generative adversarial networks. CoRR, abs/1702.07983, 2017. URL http://arxiv.org/abs/1702.07983.\\n\\nLiqun Chen, Shuyang Dai, Chenyang Tao, Haichao Zhang, Zhe Gan, Dinghan Shen, Yizhe Zhang, Guoyin Wang, Ruiyi Zhang, and Lawrence Carin. Adversarial text generation via feature-mover\u2019s distance. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/074177d3eb6371e32c16c55a3b8f706b-Paper.pdf.\\n\\nEdmund M. Clarke and E. Allen Emerson. Design and synthesis of synchronization skeletons using branching-time temporal logic. In Logics of Programs, Workshop, Yorktown Heights, New York, USA, May 1981, volume 131 of Lecture Notes in Computer Science, pp. 52\u201371. Springer, 1981. doi: 10.1007/BFb0025774.\\n\\nEdmund M. Clarke, E. Allen Emerson, and A. Prasad Sistla. Automatic verification of finite-state concurrent systems using temporal logic specifications. ACM Trans. Program. Lang. Syst., 8(2):244\u2013263, 1986. doi: 10.1145/5397.5399.\\n\\nEdmund M. Clarke, Orna Grumberg, and Doron A. Peled. Model checking. MIT Press, 2001. ISBN 978-0-262-03270-4. URL http://books.google.de/books?id=Nmc4wEaLXFEC.\\n\\nMichael R. Clarkson, Bernd Finkbeiner, Masoud Koleini, Kristopher K. Micinski, Markus N. Rabe, and C\u00e9sar S\u00e1nchez. Temporal logics for hyperproperties. In Mart\u00edn Abadi and Steve Kremer (eds.), Principles of Security and Trust - Third International Conference, POST 2014, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014, Grenoble, France, April 5-13, 2014, Proceedings, volume 8414 of Lecture Notes in Computer Science, pp. 265\u2013284. Springer, 2014. doi: 10.1007/978-3-642-54792-8.\\n\\nAlexandre Donz\u00e9, Thomas Ferr\u00e8re, and Oded Maler. Efficient robust monitoring for STL. In Natasha Sharygina and Helmut Veith (eds.), Computer Aided Verification - 25th International Conference, CAV 2013, Saint Petersburg, Russia, July 13-19, 2013. Proceedings, volume 8044 of Lecture Notes in Computer Science, pp. 264\u2013279. Springer, 2013. doi: 10.1007/978-3-642-39799-8.\\n\\nMatthew B. Dwyer, George S. Avrunin, and James C. Corbett. Patterns in property specifications for finite-state verification. In Proceedings of the 21st International Conference on Software Engineering, ICSE '99, pp. 411420, New York, NY, USA, 1999. Association for Computing Machinery. ISBN 1581130740. doi: 10.1145/302405.302672.\\n\\nE. Allen Emerson and Joseph Y. Halpern. \u201csometimes\u201d and \u201cnot never\u201d revisited: on branching versus linear time temporal logic. J. ACM, 33(1):151\u2013178, 1986. doi: 10.1145/4904.4999.\\n\\nRichard Evans, David Saxton, David Amos, Pushmeet Kohli, and Edward Grefenstette. Can neural networks understand logical entailment? In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018. URL https://openreview.net/forum?id=SkZxCk-0Z.\\n\\nPeter Faymonville, Bernd Finkbeiner, and Leander Tentrup. BoSy: An experimentation framework for bounded synthesis. In Computer Aided Verification - 29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part II, volume 10427 of Lecture Notes in Computer Science, pp. 325\u2013332. Springer, 2017. doi: 10.1007/978-3-319-63390-9.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"William Fedus, Ian J. Goodfellow, and Andrew M. Dai. Maskgan: Better text generation via filling in the...\\n\\nBernd Finkbeiner and Sven Schewe. Uniform distributed synthesis. In 20th IEEE Symposium on Logic in Computer Science (LICS 2005), 26-29 June 2005, Chicago, IL, USA, Proceedings, pp. 321\u2013330. IEEE Computer Society, 2005. doi: 10.1109/LICS.2005.53.\\n\\nBernd Finkbeiner and Sven Schewe. Bounded synthesis. Int. J. Softw. Tools Technol. Transf., 15(5-6):519\u2013539, 2013. doi: 10.1007/s10009-012-0228-z.\\n\\nBernd Finkbeiner and Henny Sipma. Checking finite traces using alternating automata. Formal Methods Syst. Des., 24(2):101\u2013127, 2004. doi: 10.1023/B:FORM.0000017718.28096.48.\\n\\nNils Froleyks, Marijn Heule, Markus Iser, Matti J\u00e4rvisalo, and Martin Suda. Sat competition 2020. Artificial Intelligence, 301:103572, 2021.\\n\\nThibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana Kumar, and Michael Norrish. Tactic-toe: Learning to prove with tactics. J. Autom. Reason., 65(2):257\u2013286, 2021. doi: 10.1007/s10817-020-09580-x.\\n\\nJustin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pp. 1263\u20131272. PMLR, 2017.\\n\\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems, volume 27. Curran Associates, Inc., 2014.\\n\\nIshaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.\\n\\nJiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. Long text generation via adversarial training with leaked information. In Sheila A. McIlraith and Kilian Q. Weinberger (eds.), Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pp. 5141\u20135148. AAAI Press, 2018.\\n\\nChristopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus Norman Rabe, and Bernd Finkbeiner. Teaching temporal logics to neural networks. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.\\n\\nDaniel Huang, Prafulla Dhariwal, Dawn Song, and Ilya Sutskever. Gamepad: A learning environment for theorem proving. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nFei Huang, Jian Guan, Pei Ke, Qihan Guo, Xiaoyan Zhu, and Minlie Huang. A text gan for language generation with non-autoregressive generator. 2020.\\n\\nDrew A Hudson and C Lawrence Zitnick. Generative adversarial transformers. arXiv preprint arXiv:2103.01209, 2021.\\n\\nIEEE-Commission et al. Ieee standard for property specification language (psl). IEEE Std 1850-2005, 2005.\\n\\nGeoffrey Irving, Christian Szegedy, Alexander A. Alemi, Niklas \u00c9\u00e9n, Fran\u00e7ois Chollet, and Josef Urban. Deepmath - deep sequence models for premise selection. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pp. 2235\u20132243, 2016. URL https://proceedings.neurips.cc/paper/2016/hash/f197002b9a0853eca5e046d9ca4663d5-Abstract.html.\\n\\nSwen Jacobs, Roderick Bloem, Romain Brenguier, R\u00fcdiger Ehlers, Timotheus Hell, Robert K\u00f6nighofer, Guillermo A. P\u00e9rez, Jean-Fran\u00e7ois Raskin, Leonid Ryzhyk, Ocan Sankur, Martina Seidl, Leander Tentrup, and Adam Walker. The first reactive synthesis competition (SYNTCOMP 2014). Int. J. Softw. Tools Technol. Transf., 19(3):367\u2013390, 2017. doi: 10.1007/s10009-016-0416-3. URL https://doi.org/10.1007/s10009-016-0416-3.\\n\\nYifan Jiang, Shiyu Chang, and Zhangyang Wang. Transgan: Two transformers can make one strong gan. arXiv preprint arXiv:2102.07074, 2021.\\n\\nCezary Kaliszyk and Josef Urban. Learning-assisted automated reasoning with flyspeck. J. Autom. Reason., 53(2):173\u2013213, 2014. doi: 10.1007/s10817-014-9303-3. URL https://doi.org/10.1007/s10817-014-9303-3.\\n\\nCezary Kaliszyk, Fran\u00e7ois Chollet, and Christian Szegedy. Holstep: A machine learning dataset for higher-order logic theorem proving. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https://openreview.net/forum?id=ryuxYmvel.\\n\\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2015.\\n\\nSachin Kumar and Yulia Tsvetkov. End-to-end differentiable GANs for text generation. In Proceedings on \u201cI Can\u2019t Believe It\u2019s Not Better!\u201d at NeurIPS Workshops, volume 137 of Proceedings of Machine Learning Research, pp. 118\u2013128. PMLR, 12 Dec 2020. URL http://proceedings.mlr.press/v137/kumar20a.html.\\n\\nMatt J. Kusner and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato. Gans for sequences of discrete elements with the gumbel-softmax distribution. ArXiv, abs/1611.04051, 2016.\\n\\nGuillaume Lample and Fran\u00e7ois Charton. Deep learning for symbolic mathematics. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=S1eZYeHFDS.\\n\\nGil Lederman, Markus N. Rabe, Sanjit Seshia, and Edward A. Lee. Learning heuristics for quantified boolean formulas through reinforcement learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=BJluxREKDB.\\n\\nDennis Lee, Christian Szegedy, Markus N. Rabe, Sarah M. Loos, and Kshitij Bansal. Mathematical reasoning in latent space. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=Ske31kBtPr.\\n\\nJianwen Li, Lijun Zhang, Geguang Pu, Moshe Y. Vardi, and Jifeng He. LTL satisfiability checking revisited. In 2013 20th International Symposium on Temporal Representation and Reasoning, Pensacola, FL, USA, September 26-28, 2013, pp. 91\u201398. IEEE Computer Society, 2013. doi: 10.1109/TIME.2013.19. URL https://doi.org/10.1109/TIME.2013.19.\"}"}
{"id": "DvcMMKmDJ3q", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
