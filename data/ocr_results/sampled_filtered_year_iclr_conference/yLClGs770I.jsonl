{"id": "yLClGs770I", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yLClGs770I", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.1 Mathematical Reasoning Datasets\\n\\nOur work builds upon the existing mathematical reasoning literature. Early on, mathematical reasoning is mostly focused on solving synthetic basic math problems like AddSub (Hosseini et al., 2014) and other arithmetic reasoning datasets (Koncel-Kedziorski et al., 2015; Roy & Roth, 2015; Patel et al., 2021). Later on, more difficult math word problem datasets (Cobbe et al., 2021; Amini et al., 2019; Ling et al., 2017; Hendrycks et al., 2021b) have been proposed to focus on addressing realistic math word problems. NumGLUE (Mishra et al., 2022b) and LiLA (Mishra et al., 2022a) compile the existing literature to build a more diversified dataset collection. However, these datasets are mostly focused on grade school math problems. To further test LLMs\u2019 limits in addressing more complex math problems, MMLU (Hendrycks et al., 2021a) includes college math problems in its evaluation suite. More recently, (Chen et al., 2023; Wang et al., 2023e) have proposed to tackle more challenging college-level science and math problems. Our instruction tuning dataset is built upon existing work to include a diversified collection of math problems from different subfields.\\n\\nA.2 Reasoning with Large Language Models\\n\\nLLMs have demonstrated great capabilities to reason with the help of Chain-of-Thought prompting (Wei et al., 2022b; Kojima et al., 2022; Wang et al., 2023f). Suzgun et al. (2022) have shown that CoT can already surpass human performance on challenging BIG-Bench tasks. Later on, several other works (Drozdov et al., 2023; Zhou et al., 2023c; Nye et al., 2022; Wang et al., 2022a; 2023a; Li et al., 2023b; Wang et al., 2023d; Yu et al., 2023) also propose different approaches to utilize LLMs to solve reasoning tasks by allowing intermediate steps. ReAct Yao et al. (2023) proposes to leverage external tools like search engines to enhance LLM reasoning skills. Another trend is to enable LLMs\u2019 capabilities to use programs as thought processes like PoT (Chen et al., 2022). Some follow-up works include self-critic (Gou et al., 2023), self-eval (Xie et al., 2023), plan-and-solve (Wang et al., 2023c). These methods propose to enhance LLMs\u2019 capabilities to solve math problems with PoT. Self-critic (Gou et al., 2023) and self-eval (Xie et al., 2022) both adopt self-evaluation to enhance the robustness of the generated program. Plan-and-solve (Wang et al., 2023c) instead adopts more detailed planning instructions to help LLMs create a high-level reasoning plan. These methods all prove to bring decent improvements over PoT.\\n\\nA.3 Instruction Tuning in Language Models\\n\\nInstruction tuning is part of a line of work designed to \u201calign\u201d language models with more useful objectives and human preferences. The instruction tuning step is seen as a major step to activate LLMs\u2019 certain capabilities to respond to human instructions. Previously, instruction tuning is mainly focused on enhancing LLMs\u2019 general-purpose instruction following abilities. Since 2021, CrossFit (Ye et al., 2021) and NaturalInstruction (Wang et al., 2022b), FLAN (Wei et al., 2022a) and T0 (Sanh et al., 2022) are amongst the first wave of instruction tuning effort to understand LLMs\u2019 generalization capabilities. Later on, FLAN-v2 (Chung et al., 2022; Longpre et al., 2023) have been proposed to understand the effect of scaling up the instruction datasets to understand its impact on model performance. These approaches mainly adopt human-annotated datasets to build the instruction following dataset. More recently, multiple works (Wang et al., 2023h; Xu et al., 2023; Peng et al., 2023; Zhou et al., 2023b; Wang et al., 2023g) propose to utilize synthetic instruction following data distilled from GPT-3/4 to align open-source LLMs. The most similar effort to ours is Platypus (Lee et al., 2023) which aims to utilize a domain-specialized dataset to construct a small-scale instruction following dataset to enhance LLMs\u2019 reasoning capabilities.\"}"}
{"id": "yLClGs770I", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We conduct a comparison between our PoT results vs. CoT results in Figure 3, Figure 4 and Figure 5. In the first example, even though PoT and CoT can both solve the problem, CoT gives a very tedious solution to derive the answer. Such solution is not only slow but also unstable. In the second and third case, we can further see the advantages of PoT over CoT by utilizing external tools and Python packages to greatly simplify the solution. Figure 6 shows some types of questions (especially the formal logic question) that are not easily handled by programs. In order to address these types of questions, CoT is a better choice.\\n\\n```python\\nfrom sympy import factorial\\n\\nvalue = factorial(factorial(3)) / factorial(3)\\nprint(value)\\n```\\n\\n```plaintext\\n120\\n```\\n\\nFirst, we need to understand the given expression:\\n\\nStep 1: Simplify the expression inside the parentheses.\\n\\n```plaintext\\n3! = 3 \\\\times 2 \\\\times 1 = 6\\n```\\n\\nSo, the expression becomes:\\n\\nStep 2: Recall the property of factorials that states \\\\( n! = n! \\\\) for any positive integer \\\\( k \\\\) and any positive integer \\\\( n \\\\geq k \\\\). In our case, we have \\\\( n = 6 \\\\) and \\\\( k = 6 \\\\).\\n\\nUsing this property, we can rewrite the expression as:\\n\\nStep 3: Simplify the expression further by applying the property mentioned in Step 2.\\n\\n```plaintext\\n6! = 6 \\\\times 5 \\\\times 4 \\\\times 3 \\\\times 2 \\\\times 1 = 720\\n```\\n\\nSo, the expression becomes:\\n\\nStep 4: Divide 720 by 6.\\n\\n```plaintext\\n720 \\\\div 6 = 120\\n```\\n\\nSo, the final simplified expression is: 120\\n\\nTherefore, the value of !!!!! is 120.\\nThe answer is: 120\\n\\nCoT\\n\\nWhat is the value of !!!!!?\\n\\n```python\\nfrom sympy import factorial\\n\\nword = \\\"TEEPE\\\"\\n\\nn = len(word)\\nd = word.count('E')\\n\\nways = factorial(n) / factorial(d)\\nprint(ways)\\n```\\n\\n```plaintext\\n20\\n```\\n\\nFirst we count the arrangements if all the letters are unique, which is \\\\( 4! \\\\).\\n\\nThen since the E's are not unique, we divide by \\\\( 2! \\\\) for the arrangements of the two E's, for an answer of \\\\( 4! / 2! = 60 \\\\).\\n\\nThe answer is: 60\\n\\nCoT\\n\\nDetermine the number of ways to arrange the letters of the word TEPEE.\\n\\n```python\\nfrom sympy import factorial\\n\\nword = \\\"TEEPE\\\"\\n\\nn = len(word)\\nd = word.count('E')\\n\\nways = factorial(n) / factorial(d)\\nprint(ways)\\n```\\n\\n```plaintext\\n20\\n```\\n\\nFirst we count the arrangements if all the letters are unique, which is \\\\( 4! \\\\).\\n\\nThen since the E's are not unique, we divide by \\\\( 2! \\\\) for the arrangements of the two E's, for an answer of \\\\( 4! / 2! = 60 \\\\).\\n\\nThe answer is: 60\\n\\nCoT\\n\\nDetermine the number of ways to arrange the letters of the word TEPEE.\"}"}
{"id": "yLClGs770I", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Question:\\n\\n\ud835\udc4e is chosen from the set {1, 2, 3, 4}, and \ud835\udc4f is chosen from the set {5, 6, 7, 8, 9}. What is the probability that the product \ud835\udc4e\ud835\udc4f is a prime number?\\n\\n```python\\nfrom sympy import isprime\\n\\n# define the sets\\na_set = {1, 2, 3, 4}\\nb_set = {5, 6, 7, 8, 9}\\n\\nn_a = len(a_set)\\nn_b = len(b_set)\\nprime_count = 0\\nprime_ab_count = 0\\nprime_a_count = 0\\nprime_b_count = 0\\n\\n# iterate over all possible pairs\\nfor a in a_set:\\n    for b in b_set:\\n        if isprime(a) or isprime(b):\\n            if isprime(a*b):\\n                prime_count += 1\\n                prime_ab_count += 1\\n        # check if a is prime\\n        if isprime(a):\\n            prime_a_count += 1\\n        if isprime(b):\\n            prime_b_count += 1\\n\\nprobability = prime_ab_count / (n_a * n_b)\\nprint(probability)\\n```\\n\\nThe answer is: 13/20\\n\\nFirst, we need to find the total number of possible combinations of choosing a number from each set. There are 4 numbers in the first set and 5 numbers in the second set. So, there are 4 \\\\cdot 5 = 20 possible combinations.\\n\\nNow, let's consider the prime numbers. A prime number is a number greater than 1 that has no divisors other than 1 and itself. We need to find the pairs of (a, b) where either a or b is a prime number, or both.\\n\\n1. If a is a prime number, there are 4 prime numbers in the first set: 2, 3, 5, and 7. So, there are 4 possible combinations where a is a prime number.\\n2. If b is a prime number, there are 5 prime numbers in the second set: 3, 5, 7, 11, and 13. So, there are 5 possible combinations where b is a prime number.\\n3. If both a and b are prime numbers, we need to find the pairs where the prime numbers are 2, 3, 5, or 7. There are 4 pairs in this case: (2, 3), (2, 5), (2, 7), and (3, 5).\\n\\nNow, let's add up the number of combinations where either a or b is a prime number: 4 (a is prime) + 5 (b is prime) + 4 (both are prime) = 13.\\n\\nSince there are 20 possible combinations in total, the probability that the product ab is a prime number is 13/20.\"}"}
{"id": "yLClGs770I", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Overview of our MathInstruct.\\n\\n| Dataset     | Type   | Model  | Size  | Characteristics | Fields |\\n|-------------|--------|--------|-------|-----------------|--------|\\n| GSM8K       | CoT    | GPT-4  | 14K   | + Validated     | \u220e      |\\n| GSM8K-RFT   | CoT    | Llama 2 | 28K   | Llama + Validated | \u220e      |\\n| AQuA-RAT   | CoT    | Human  | 90K   | GRE/GMAT Exam   | \u220e      |\\n| MATH        | CoT    | Human  | 7K    | Math Competition | \u220e \u220e \u220e \u220e \u220e \u220e \u220e |\\n| TheoremQA   | CoT    | GPT-4  | 600   | + Validated     | \u220e \u220e \u220e \u220e \u220e |\\n| Camel-Math  | CoT    | GPT-4  | 50K   | Unvalidated     | \u220e \u220e \u220e \u220e |\\n| College-Math| CoT    | GPT-4  | 1.8K  | Unvalidated     | \u220e      |\\n| MathQA      | PoT    | Human  | 25K   | AQuA-RAT Subset | \u220e      |\\n| NumGLUE     | PoT    | Human  | 13K   | Lila Annotated  | \u220e      |\\n| MathInstruct|        |        | 260K  | 72% CoT, 28% PoT| \u220e \u220e \u220e \u220e \u220e \u220e \u220e |\\n\\n2.0 APPROACH\\n\\nMathematical reasoning serves as a vital gauge for assessing the ability of LLMs to execute complex multi-hop and quantitative reasoning. Previously, this has been a challenging task for neural networks, which struggle to solve even basic addition and subtraction problems (Yang et al., 2023). However, recent LLMs have considerable advancements in mathematical reasoning. Key breakthroughs have been made through CoT prompting (Wei et al., 2022b; Nye et al., 2022) and PoT prompting (Chen et al., 2022; Gao et al., 2023). CoT prompting encourages LLMs to solve problems incrementally on a scratchpad, enhancing both accuracy and explainability in mathematical reasoning. This approach contrasts with traditional methods that generate answers directly. PoT prompting, on the other hand, formulates the intermediate reasoning process as a program, executed with an external tool like Python, to compute the answer. This method improves robustness in solving complex mathematical problems by offloading the calculations to external tools. However, most existing work (Zhou et al., 2023a) in PoT is limited to proprietary models like GPT-4 (OpenAI, 2023) and Codex (Chen et al., 2021). The PoT potential of open-source models is yet to be seen.\\n\\nOur work aims at optimizing LLMs\u2019 CoT and PoT reasoning capabilities through instruction tuning.\\n\\n2.1 CURATING A DIVERSE AND HYBRID INSTRUCTION DATASET\\n\\nOur study aims to compile a list of high-quality and diverse math instruction-tuning datasets, standing out with two main characteristics: (1) broad coverage of different mathematical fields and complexity levels, and (2) hybrid CoT & PoT rationales.\\n\\nBroad Coverage of Different Math Fields and Complexity Levels:\\nWe aim for a broad representation of math fields and complexity levels in our dataset. This ensures exposure to a diverse set of mathematical knowledge, fostering versatility in our models. Based on these criteria, we narrow down our choices to a few high-quality datasets that are widely adopted and encompass different math fields and complexity levels, such as GSM8K, MATH, AQuA, Camel, and TheoremQA. Furthermore, we notice a lack of coverage for college-level math knowledge, such as abstract algebra and formal logic, in existing datasets. To rectify this, we use GPT-4 to synthesize CoT rationales for questions in TheoremQA and create question-CoT pairs through Self-Instruct (Wang et al., 2023h), utilizing a few seed exemplars found online.\\n\\nHybrid CoT and PoT Rationales:\\nContrary to previous work (Yuan et al., 2023; Luo et al., 2023; Lee et al., 2023; Wang et al., 2023g) that focus on CoT, our dataset strategically combines both. This integration enhances the dataset\u2019s versatility, catering to varying mathematical problem-solving needs.\"}"}
{"id": "yLClGs770I", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"approaches. However, most existing datasets provide limited program rationales, leading to an imbalance between CoT and PoT rationales. To fill the gap, we utilize GPT-4 to supplement the PoT rationales for selected datasets, including MATH, AQuA, GSM8K, and TheoremQA. We further enhance the dataset quality by meticulously removing near-duplicated solutions. These GPT-4 synthesized programs are then validated by comparing their executed results with ground truth, ensuring the high quality and reliability of the rationales. The validation subset ratio is shown in Table 6.\\n\\nFollowing these guidelines, our instruction dataset, detailed in Table 1, encompasses 260K (instruction, response) pairs, covering a wide range of core mathematical fields (arithmetic, algebra, probability, calculus, and geometry, etc.), including hybrid CoT and PoT rationales, and offering diversity in both language and difficulty levels. This attests to its high quality and unique characteristics.\\n\\n2.2 TRAINING SETUP\\n\\nWe unify all the subsets in our MathInstruct to conform to the structure of an Alpaca-like instruction dataset (Taori et al., 2023). This standardization ensures that the fine-tuned models can process data consistently, regardless of the original dataset formats. We choose the open-source models Llama-2 (Touvron et al., 2023b) and Code Llama (Rozi\u00e8re et al., 2023) as our base models. We fine-tune these models including 7B, 13B, 34B, and 70B on MathInstruct, which allows us to validate our MathInstruct at multiple scales. We fine-tune all the models with Huggingface transformers library (Wolf et al., 2019). We use a learning rate of 2e-5 for the 7B and 13B models, and 1e-5 for the 34B and 70B models. We set the batch size at 128 and used a cosine scheduler with a 3% warm-up period for three epochs. To efficiently train the computationally intensive 34B and 70B models, we employ DeepSpeed training with ZeRO-3 stage (Rajbhandari et al., 2020).\\n\\n2.3 EVALUATION SETUP\\n\\nOur hybrid training enables models to solve problems using either the CoT or PoT approach. By default, the model provides the CoT solution. To switch to the PoT approach, one can add the trigger phrase \u201cLet\u2019s write a program to solve the problem\u201d following the question.\\n\\nOur preliminary evaluation reveals that PoT generally outperforms CoT, notably in open-form questions like GSM8K and MATH, as programmable solutions are better at solving complex mathematical and algorithmic reasoning procedures. However, PoT struggles with abstract reasoning scenarios such as commonsense reasoning, formal logic, and abstract algebra, particularly in the absence of built-in APIs. To further combine the power of both approaches, we introduce a simple hybrid decoding strategy: The model first attempts PoT prompting. If the program is not executable, we fall back to CoT prompting. This heuristic can further enhance our model\u2019s overall performance (see more discussions in Table 3.4). We also report the performance of self-consistency decoding method (Wang et al., 2023f) in Table 8.\\n\\n3 EXPERIMENTS\\n\\n3.1 EVALUATION DATASETS\\n\\nWe have selected diverse evaluation datasets (Table 2), encompassing a variety of in-domain and out-of-domain samples across diverse fields of mathematics, to assess the models\u2019 capabilities in general mathematical reasoning.\\n\\nFor the in-domain datasets, we consider GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021b), AQuA-RAT (Ling et al., 2017), and NumGLUE (Mishra et al., 2022b). For the out-of-domain datasets, we choose SV AMP (Patel et al., 2021), Mathematics (Davies et al., 2021), SimulEq (Koncel-Kedziorski et al., 2016), SAT-Math (Zhong et al., 2023), and MMLU-Math (Hendrycks et al., 2021a). The wide selection of evaluation datasets includes math problems from elementary, high school, and college levels. Some of the datasets even include formal logic and commonsense reasoning. The choice of these datasets is to ensure a comprehensive evaluation of the models\u2019 capabilities to generalize to unfamiliar situations and different math fields. The chosen evaluation datasets consist of both open-formed questions and multi-choice questions.\"}"}
{"id": "yLClGs770I", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Eval Dataset | # Samples | In-Domain? | Answer Form Fields\\n---|---|---|---\\nGSM8K (Cobbe et al., 2021) | 1319 | YES | Open-formed\\nMATH (Hendrycks et al., 2021b) | 5000 | YES | Open-formed\\nAQuA-RAT (Ling et al., 2017) | 254 | YES | Multi-choice\\nNumGLUE (Mishra et al., 2022b) | 1042 | YES | Open-formed\\nSV AMP (Patel et al., 2021) | 1000 | NO | Open-formed\\nMathematics (Davies et al., 2021) | 1000 | NO | Open-formed\\nSimulEq (Koncel-Kedziorski et al., 2016) | 514 | NO | Open-formed\\nSAT-Math (Zhong et al., 2023) | 220 | NO | Multi-choice\\nMMLU-Math (Hendrycks et al., 2021a) | 974 | NO | Multi-choice\\n\\nTable 2: Comprehensive overview of our evaluation datasets, featuring a variety of in-domain and out-of-domain problems across diverse fields of mathematics. Different colored squares represent different fields in mathematics: Pre-Algebra; Inter-Algebra; Algebra; Probability; NumTheory; Calculus; Geometry.\\n\\n3.2 Baselines\\n\\nWe partition our baselines into the following four categories:\\n\\n\u2022 Closed-source LLMs: We consider 4 closed-source LLMs including GPT-4 (OpenAI, 2023), GPT-4 (Code Interpreter), PaLM-2 Unicorn (Anil et al., 2023), Claude-2 (Bai et al., 2022) and Codex (Chen et al., 2021). GPT-4, PaLM-2, and Claude-2 use CoT prompting while GPT-4 (Code Interpreter) and Codex use PoT prompting.\\n\\n\u2022 Llama Base: For the base models, we consider Llama-1/2 (Touvron et al., 2023a;b), Llama-2-Chat (Touvron et al., 2023b).\\n\\n\u2022 Coder Model: To compare with different coder models, we choose Code-Llama (Rozi\u00e8re et al., 2023), CodeT5+ (Wang et al., 2023i) and CodeGen (Nijkamp et al., 2023).\\n\\n\u2022 STEM Pre-training: We cover Galactica (Taylor et al., 2022) mainly to understand the performance of models specialized in STEM knowledge.\\n\\n\u2022 Instruction Tuning: We include Orca-Platypus (Mukherjee et al., 2023), Vicuna-1.5 (Zheng et al., 2023b), Tulu (Wang et al., 2023g), Platypus-2 (Lee et al., 2023) and Guanaco (Dettmers et al., 2023). We cover a wide spectrum of models trained with different types of datasets.\\n\\n\u2022 Dataset-Specific Tuning: We include both RFT (Yuan et al., 2023) and WizardMath (Luo et al., 2023), which specifically tune the models to adapt to GSM8K and MATH datasets. We include them to understand their generalization.\\n\\nFor most baselines, we choose CoT prompting to maximize their performance due to their incompetence in program generation. All the 'Code Model' use PoT prompting. For GSM8K, MATH, AQuA, and NumGLUE, we will evaluate both 8-shot in-context-learning and zero-shot setups to report the highest score. For SV AMP, Mathematics, SimulEq, SAT, and MMLU, we use 5-shot in-context-learning to maintain consistency with prior work (Wei et al., 2022b; Chen et al., 2023).\\n\\nOur few-shot exemplars are mostly taken from PHP1 (Zheng et al., 2023a). For MAmmoTH and MAmmoTH-Coder, we always evaluate under 0-shot setting. For all models, we allow a maximum sequence length of 2048 tokens for decoding. For multiple-choice questions, if the generated answer lacks an option, we map it by re-prompting the model: \u201cPlease find the closest option to [generated answer]. The options are [options]\u201d.\\n\\n3.3 Results\\n\\nWe report our in-domain and out-of-domain results in Table 3 and Table 4 respectively. Overall, we can see that MAmmoTH and MAmmoTH-Coder are able to outperform the SoTA model at different scales. In general, the performance gain for OOD datasets is more significant than IND datasets. These results show us the potential of our models as a mathematical generalist. On several datasets, MAmmoTH-Coder-34B and MAmmoTH-70B are even surpassing closed-source LLMs.\\n\\n1 https://github.com/chuanyang-Zheng/Progressive-Hint\"}"}
{"id": "yLClGs770I", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model Base Math-SFT? | GSM8K MATH AQuA NumGLUE |\\n|----------------------|--------------------------|\\n| Avg                  |                          |\\n| 70.5                 |                          |\\n| GPT-4 - Unknown      | 92.0\u2020                    |\\n| 42.5                 | 72.6\u2020                    |\\n| 74.7                 |                          |\\n| PaLM-2 - Unknown     | 80.7\u2020                    |\\n| 34.3                 | 64.1                     |\\n| Claude-2 - Unknown   | 85.2\u2020                    |\\n| 32.5                 | 60.9                     |\\n| Codex (PoT) - No     | 71.6\u2020                    |\\n| 36.8                 | 54.1                     |\\n| ART (InstructGPT) - Unknown | 71.0 -                 |\\n| 13-15B Parameter Model |\\n| Llama-1 - No         | 10.7\u2020                    |\\n| 2.9                  | 22.6 24.7                |\\n| 15.5                 |                          |\\n| Llama-2 - No         | 14.6\u2020                    |\\n| 2.5                  | 30.3 29.9                |\\n| 19.3                 |                          |\\n| Galactica-6.7B       | 10.2 2.2 25.6 25.8       |\\n| Code-Llama (PoT) - No | 25.2 13.0 24.0 26.8      |\\n| 13-15B Parameter Model |\\n| Llama-1 RFT          | 46.5\u2020                    |\\n| 5.2                  | 18.8 21.1                |\\n| 22.9                 |                          |\\n| WizardMath           | 54.9\u2020                    |\\n| 10.7                 | 26.3 36.1                |\\n| 32.0                 |                          |\\n| MAmmoTH              | 53.6 31.5 44.5 61.2      |\\n| 47.7                 |                          |\\n| MAmmoTH-Coder        | 59.4 33.4 47.2 66.4      |\\n| 51.6                 |                          |\\n| 30-34B Parameter Model |\\n| Llama-1 - No         | 35.6\u2020                    |\\n| 7.1                  | 33.4 28.4                |\\n| 26.1                 |                          |\\n| Code-Llama (PoT) - No | 44.0 23.1 25.2 29.3      |\\n| 30.4                 |                          |\\n| Llama-1 RFT          | 56.5\u2020                    |\\n| 7.4                  | 18.5 24.3                |\\n| 26.6                 |                          |\\n| Galactica-30B        | 41.7 12.7 28.7 34.7      |\\n| 29.4                 |                          |\\n| Platypus Llama-1 Platypus | 37.8 9.3 27.9 40.5      |\\n| 28.8                 |                          |\\n| Tulu Llama-2 Tulu    | 51.0 10.8 25.5 43.4      |\\n| 32.6                 |                          |\\n| 65-70B Parameter Model |\\n| Llama-1 - No         | 50.9\u2020                    |\\n| 10.6                 | 35.0 50.2                |\\n| 36.6                 |                          |\\n| Llama-2              | 56.8\u2020                    |\\n| 13.5                 | 40.9 50.4                |\\n| 40.4                 |                          |\\n| Llama-2-Chat         | 54.9 18.6 37.0 51.6      |\\n| 40.5                 |                          |\\n| Guanaco Llama-2      | 59.2 4.1 45.2 53.5       |\\n| 40.5                 |                          |\\n| WizardMath           | 81.6\u2020                    |\\n| 22.7                 | 20.0 48.9                |\\n| 43.3                 |                          |\\n| Platypus Llama-2 Platypus | 70.6 15.6 51.2 55.4      |\\n| 48.1                 |                          |\\n| MAmmoTH              | 76.9 41.8 65.0 74.4      |\\n| 64.5                 |                          |\\n\\nTable 3: The table compiles all the in-domain evaluation results. Results marked as \u2020 are copied from other papers, which can be found on paperswithcode leaderboards. Math-SFT? means whether the model has been instruction-tuned on any math reasoning datasets. Pink numbers highlight the highest number within the corresponding scale and dataset. Note that there does not exist a 30B+ version for Llama-2 or a 70B version for Code-Llama.\\n\\nFrom Table 3, we can observe that our main competitors for IND datasets are WizardMath (Luo et al., 2023) and Platypus (Lee et al., 2023). WizardMath\u2019s training is heavily rooted in GSM8K.\"}"}
{"id": "yLClGs770I", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We introduce **MAmmoTH**, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The **MAmmoTH** models are trained on **MathInstruct**, our meticulously curated instruction tuning dataset. **MathInstruct** is compiled from 13 math datasets with intermediate rationales, six of which have rationales newly curated by us. It presents a unique hybrid of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also ensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT not only unleashes the potential of tool use but also allows different thought processes for different math problems. As a result, the **MAmmoTH** series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales with an average accuracy gain between 16% and 32%. Remarkably, our **MAmmoTH-7B** model reaches 33% on MATH (a competition-level dataset), which exceeds the best open-source 7B model (WizardMath) by 23%, and the **MAmmoTH-34B** model achieves 44% accuracy on MATH, even surpassing GPT-4\u2019s CoT result. Our work underscores the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.\\n\\n---\\n\\n**Figure 1:** The superior performance of **MAmmoTH**, a series of models instruction-tuned to solve a diverse set of mathematical problems using hybrid CoT and PoT rationales.\\n\\n**MAmmoTH** significantly outperforms base and SoTA models on both in-domain and out-of-domain test sets, across all scales.\\n\\n---\\n\\n\u2217 Xiang Yue and Wenhu Chen are the leading authors of the paper. They contributed equally to this project.\"}"}
{"id": "yLClGs770I", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"INTRODUCTION\\n\\nThis work focuses on mathematical reasoning, a critical capability of modern large language models (LLMs) (OpenAI, 2023; Anil et al., 2023). Despite the recent advances in this field, a noticeable gap exists between closed-source and open-source LLMs\u2014closed-source models like GPT-4 (OpenAI, 2023), PaLM-2 (Anil et al., 2023), and Claude 2 (Bai et al., 2022) dominate popular mathematical reasoning benchmarks such as GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021b), while open-source models like Llama (Touvron et al., 2023a;b), Falcon (Penedo et al., 2023), OPT (Zhang et al., 2022) lag behind on all benchmarks by a wide margin.\\n\\nCurrent efforts to bridge this gap are twofold: (1) Continued pre-training like Galactica (Taylor et al., 2022) and MINERVA (Lewkowycz et al., 2022), which continues to train an LLM on math-related web data of more than 100B tokens. This approach improves a model\u2019s general scientific reasoning capability but incurs a high computation cost. (2) Dataset-specific fine-tuning like rejection sampling fine-tuning (RFT) (Yuan et al., 2023) and WizardMath (Luo et al., 2023), which fine-tunes LLMs using supervised data specific to certain datasets. Although such approaches improve in-domain performance, they cannot generalize to a wider range of math reasoning tasks beyond their fine-tuning data. For instance, both RFT and WizardMath can increase the accuracy on GSM8K (Cobbe et al., 2021) by 30%+, one of their fine-tuning datasets, but hurt the accuracy on out-of-domain datasets like MMLU-Math (Hendrycks et al., 2021a) or AQuA (Ling et al., 2017) by up to 10%.\\n\\nIn this paper, we aim to propose a lightweight yet generalizable math instruction-tuning approach to enhance the general (i.e., not limited to the fine-tuning tasks) mathematical reasoning capabilities of LLMs. Existing methods (Luo et al., 2023; Yuan et al., 2023; Taylor et al., 2022) primarily focus on Chain-of-Thought (CoT) approaches (Wei et al., 2022b; Nye et al., 2022) to solve math problems through step-by-step natural language descriptions. This approach excels in its generality to cover most math subjects but struggles with computation precision, and complex mathematical or algorithmic reasoning procedures (e.g., solving quadratic equation roots and calculating matrix eigenvalues).\\n\\nIn contrast, prompts in the format of code like Program-of-Thought (PoT) approaches (Chen et al., 2022) and PAL (Madaan et al., 2022; Gao et al., 2023) utilize external tools (i.e., Python interpreter) to greatly simplify the math solving process. This approach advocates offloading the computation process to the external Python interpreter to solve complex mathematical and algorithmic reasoning procedures (e.g., solving quadratic equations with sympy or calculating matrix eigenvalues with numpy). However, PoT falls short in dealing with more abstract reasoning scenarios, like commonsense reasoning, formal logic, and abstract algebra, especially when there exist no built-in APIs.\\n\\nTo leverage the strengths of both CoT and PoT approaches, we introduce a new math hybrid instruction-tuning dataset MathInstruct, which has two main characteristics: (1) broad coverage of different math fields and complexity levels, and (2) hybrid CoT & PoT rationales.\\n\\nMathInstruct is based on seven existing math rationale datasets and six newly-curated datasets (see details in Table 1). We use MathInstruct to fine-tune Llama (Touvron et al., 2023a;b; Rozi`ere et al., 2023) models of different scales ranging from 7B to 70B. The resulting MAmmoTH models (Figure 1) demonstrate unprecedented potential in serving as math generalists.\\n\\nWe evaluate MAmmoTH on a spectrum of datasets, including in-domain (IND) test sets\u2014GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021b), AQuA-RAT (Ling et al., 2017), NumGLUE (Mishra et al., 2022b)\u2014and out-of-domain (OOD) test sets\u2014SV AMP (Patel et al., 2021), SAT (Zhong et al., 2023), MMLU-Math (Hendrycks et al., 2021a), Mathematics (Davies et al., 2021), and SimulEq (Koncel-Kedziorski et al., 2016). Compared with existing methods, our models generalize better to OOD datasets and substantially improve the performance of open-source LLMs in mathematical reasoning. Notably, on the popular competition-level MATH dataset (Hendrycks et al., 2021b), our 7B model can beat WizardMath (open-source MATH SoTA) (Luo et al., 2023) by 3.5x (35.2% vs 10.7%), and our 34B MAmmoTH-Coder (fine-tuned on Code Llama (Rozi`ere et al., 2023)) can even beat the result of GPT-4 (using CoT).\\n\\nWe highlight our contributions from two perspectives: (1) From the data engineering perspective, we present MathInstruct, a high-quality math instruction tuning dataset, combining a variety of math problems and hybrid rationales. (2) From the modeling perspective, we investigate the impact of various data sources and input-output formats through training and evaluating over 50 different models and baselines ranging from 7B to 70B. Our models, including MAmmoTH and MAmmoTH-Coder, achieve substantial accuracy gains over existing open-source models.\"}"}
{"id": "yLClGs770I", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yLClGs770I", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham Neubig. Language models of code are few-shot commonsense learners. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 1384\u20131403, 2022. URL https://aclanthology.org/2022.emnlp-main.90.pdf.\\n\\nSwaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. LILA: A unified benchmark for mathematical reasoning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 5807\u20135832, 2022a. URL https://aclanthology.org/2022.emnlp-main.392.\\n\\nSwaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep Sachdeva, Peter Clark, Chitta Baral, and Ashwin Kalyan. NumGLUE: A suite of fundamental yet challenging mathematical reasoning tasks. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3505\u20133523, 2022b. doi: 10.18653/v1/2022.acl-long.246. URL https://aclanthology.org/2022.acl-long.246.\\n\\nSubhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. Orca: Progressive learning from complex explanation traces of gpt-4. ArXiv preprint, abs/2306.02707, 2023. URL https://arxiv.org/abs/2306.02707.\\n\\nErik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. In International Conference on Learning Representations (ICLR), 2023. URL https://openreview.net/pdf?id=iaYcJKpY2B_.\\n\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for intermediate computation with language models. In Deep Learning for Code Workshop, 2022. URL https://arxiv.org/abs/2112.00114.\\n\\nOpenAI. Gpt-4 technical report. ArXiv preprint, abs/2303.08774, 2023. URL https://arxiv.org/abs/2303.08774.\\n\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple math word problems? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2080\u20132094, 2021. doi: 10.18653/v1/2021.naacl-main.168. URL https://aclanthology.org/2021.naacl-main.168.\\n\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb dataset for falcon llm: outperforming curated corpora with web data, and web data only. ArXiv preprint, abs/2306.01116, 2023. URL https://arxiv.org/abs/2306.01116.\\n\\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. Instruction tuning with gpt-4. ArXiv preprint, abs/2304.03277, 2023. URL https://arxiv.org/abs/2304.03277.\\n\\nSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations toward training trillion parameter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, pp. 1\u201316. IEEE, 2020. URL https://dl.acm.org/doi/10.5555/3433701.3433727.\\n\\nSubhro Roy and Dan Roth. Solving general arithmetic word problems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1743\u20131752, 2015. doi: 10.18653/v1/D15-1202. URL https://aclanthology.org/D15-1202.\\n\\nBaptiste Rozi\u00e8re, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, J\u00e9remy Rapin, et al. Code llama: Open foundation models for code. ArXiv preprint, abs/2308.12950, 2023. URL https://arxiv.org/abs/2308.12950.\"}"}
{"id": "yLClGs770I", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yLClGs770I", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "yLClGs770I", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model          | Avg | Closed-source Model | GPT-4 97.0 | Codex (PoT) | 7B Parameter Model | Llama-2 | Code-Llama (PoT) | Vicuna-1.5 | Llama-1 RFT | Galactica-6.7B | WizardMath | Toolformer | MAmmoTH | MAmmoTH-Coder |\\n|---------------|-----|---------------------|------------|-------------|-------------------|---------|------------------|------------|-------------|----------------|------------|------------|---------|---------------|\\n|               |     |                     |            |             |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 60.8|                     | 97.0       | 85.2        | 24.5              | 34.5    | 49.4             | 55.7       | 21.1        | 25.6           | 36.1       | 29.4       | 67.7    | 71.4          |\\n|               | 83.1|                     | 60.8       | 74.9        | 6.2               | 5.8     | 21.7             | 10 6.6     | 5.1         | 4.2            | 9.3        | 7         | +14     | +22           |\\n|               | 95  |                     | 83.1       | 82.1        | 4.6               | 5.0     | 3.5              | 6.6        | 11.0        | 4.2            | 12.8       | -         | +34     | +33           |\\n|               | 74.9|                     | 95         | 73.7        | 22.7              | 32.7    | 26.8             | 34.0       | 12.5        | 17.5           | 25.4       | -         | +17     | +14           |\\n|               | 82.1|                     | 74.9       | 71.4        | 30.6              | 34.4    | 29.8             | 34.1       | 21.7        | 28.0           | 31.1       | -         | +24     | +26           |\\n|               |     |                     | 82.1       | 52.3        |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 68  |                     | 74.9       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               |     |                     | 68         | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 74.9|                     | 68         | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 72.1|                     | 74.9       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 73.7|                     | 72.1       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 72.4|                     | 73.7       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 73.7|                     | 72.4       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 74.9|                     | 73.7       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 74.9       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 75.8|                     | 76.6       | -           |                   |         |                  |            |             |                |            |            |         |               |\\n|               | 76.6|                     | 75.8       | -           |                   |         |                  |            |             |                |            |            |         |               |\"}"}
{"id": "yLClGs770I", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Investigation of the influence of CoT & PoT hybrid training on the 7B Llama-2 model.\\n\\n\u201cOut-of-domain\u201d refers to the five datasets detailed in Table 2. Key insights include: 1) The SoTA model, utilizing dataset-specific CoT fine-tuning on GSM and MATH, displays strong performance within its domains but struggles in OOD scenarios; 2) Diverse data sources in MathInstruct enable better math generalist model; 3) Fine-tuning on the PoT subsets generally outperforms fine-tuning on the CoT subsets; 4) Hybrid training yields the best-performing model. The breakdown results on each dataset can be found in Appendix Table 9.\\n\\nFrom Table 4, we can observe that our main competitor for OOD datasets is Platypus (Lee et al., 2023). Similar to in-domain results, Platypus is able to yield gains over the baseline models universally across the board, especially on the MMLU-Math dataset, which is tied with MAmmoTH-70B. It is worth noting that the performance gains of our model on OOD datasets are even more significant than on in-domain datasets. This demonstrates our models' remarkable generalizability to unseen math problems. Notably, MAmmoTH-7B also boosts the CoT performance of WizardMath-7B greatly on MMLU-Math by 9%, which contains a substantial number of questions beyond the subjects we covered in our training dataset.\\n\\nComparison between Different Base Models. In our experiments, we experimented with both Llama-2 and Code-Llama as the base models. From the two tables, we can observe that Code-Llama is consistently better than Llama-2, especially on OOD datasets. The gap between MAmmoTH and MAmmoTH-Coder can even reach up to 5%. Surprisingly, the average performance on OOD datasets of MAmmoTH-Coder (34B) is actually higher than MAmmoTH (70B). We believe MAmmoTH-Coder benefits greatly from the continuous code training of Code-Llama, which not only enhances the PoT capabilities but also improves Llama's general reasoning skills.\\n\\n3.4 ABLATION STUDY ON DATA SOURCE\\n\\nAblation of the Data Source. In order to better understand what factors contribute to the great gain of MAmmoTH over existing baselines, we set up a group of control experiments in Figure 2. We study the following setups:\\n\\n(1) MAmmoTH (MathInstruct - CoT): This experiment aims to understand how much our curated CoT data could improve the generalization over the SoTA model WizardMath (Luo et al., 2023) trained specifically on GSM + MATH. As can be seen, while sacrificing accuracy on GSM + MATH by 3%, our CoT subset fine-tuning improves the overall nine-dataset accuracy from 27% to 32%.\\n\\n(2) MAmmoTH (MathInstruct - PoT): This experiment aims to understand the advantage of our PoT subset. As can be observed, our PoT subset fine-tuning can significantly improve the overall accuracy from 27% to 41%. This ablation reflects the importance of unlocking the program generation capabilities of our model.\\n\\n(3) MAmmoTH (MathInstruct - Hybrid): We further combine CoT and PoT as the hybrid training data to achieve the best overall performance of 47.9%. This combined gain comes from two aspects:\\n\\n- The CoT subset helps maintain generic language-based reasoning skills to handle scenarios where PoT cannot handle well, e.g., abstract reasoning multi-choice questions in AQuA and MMLU.\\n- The PoT subset can teach the model how to utilize Python APIs to solve complex math problems with high precision, e.g., the MATH problems requiring complex computation.\"}"}
{"id": "yLClGs770I", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Influence of Major Subsets.\\n\\nGiven the diverse sources of MathInstruct used in training MAmmoTH, it is important to understand how each dataset contributes to the overall performance of the model. We focus on five significant subsets: GSM8K, MATH, Camel, AQuA, and NumGLUE. We conduct an experiment gradually adding each dataset into training and compare the performance with the one fine-tuned on the whole MathInstruct. These results underscore the significant impact of diverse data sources on MAmmoTH performance, a core aspect of making MAmmoTH a math generalist. The results also provide valuable insights for future data curation and collection efforts (e.g., we should always collect diverse data and avoid collecting only specific types of data).\\n\\nTo help understand the contribution of the 6 newly curated datasets as shown in Table 1, we remove them from MathInstruct, and train a model on the existing data. As shown in the last two rows of Table 5, our new curated data substantially improves the performance on many datasets and leads to a 9% overall increase, which reflects the importance of the NEWLY curated dataset.\\n\\nInfluence of Hybrid Decoding.\\n\\nTo demonstrate the effectiveness of the hybrid decoding method, we conduct an experiment as outlined in subsection 2.3. By default, we initially attempt the PoT decoding method for a given question. If it fails to generate an executable query, we then transition to the CoT decoding method. The performance of different decoding methods (CoT, PoT, and Hybrid) is shown in Table 10. This hybrid decoding improves performance on every test set, showcasing that our model can effectively leverage the strengths of both CoT and PoT decoding strategies.\\n\\nConclusion\\n\\nIn this paper, we propose a novel math instruction tuning approach to activate open-source LLMs' mathematical reasoning capabilities. Through a comprehensive study, we show that our models can outperform the SoTA performance at different scales by a huge margin. Our models benefit massively from: 1) the broad coverage of different math fields and complexity levels, and 2) a hybrid of CoT and PoT training. Our instruction tuning dataset contains 260K samples, which makes fine-tuning highly affordable even for academic labs. Our work paves the road for future studies to activate LLMs' core capabilities in specialized domains.\"}"}
{"id": "yLClGs770I", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. MathQA: Towards interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 2357\u20132367, 2019. doi: 10.18653/v1/N19-1245. URL https://aclanthology.org/N19-1245.\\n\\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report. ArXiv preprint, abs/2305.10403, 2023. URL https://arxiv.org/abs/2305.10403.\\n\\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. ArXiv preprint, abs/2212.08073, 2022. URL https://arxiv.org/abs/2212.08073.\\n\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. ArXiv preprint, abs/2107.03374, 2021. URL https://arxiv.org/abs/2107.03374.\\n\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. ArXiv preprint, abs/2211.12588, 2022. URL https://arxiv.org/abs/2211.12588.\\n\\nWenhu Chen, Ming Yin, Max Ku, Elaine Wan, Xueguang Ma, Jianyu Xu, Tony Xia, Xinyi Wang, and Pan Lu. Theoremqa: A theorem-driven question answering dataset. ArXiv preprint, abs/2305.12524, 2023. URL https://arxiv.org/abs/2305.12524.\\n\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. ArXiv preprint, abs/2210.11416, 2022. URL https://arxiv.org/abs/2210.11416.\\n\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. ArXiv preprint, abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.\\n\\nAlex Davies, Petar Veli\\\\'covii, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Toma\\\\'sev, Richard Tanburn, Peter Battaglia, Charles Blundell, Andr\\\\'as Juh\\\\'asz, et al. Advancing mathematics by guiding human intuition with ai. Nature, 600(7887):70\u201374, 2021. URL https://www.nature.com/articles/s41586-021-04086-x.\\n\\nTim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms. ArXiv preprint, abs/2305.14314, 2023. URL https://arxiv.org/abs/2305.14314.\\n\\nAndrew Drozdov, Nathanael Sch\\\\\\\"arli, Ekin Aky\\\\\\\"urek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou. Compositional semantic parsing with large language models. International Conference on Learning Representations (ICLR), 2023. URL https://openreview.net/forum?id=gJW8hSGBys8.\\n\\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. In International Conference on Machine Learning, pp. 10764\u201310799. PMLR, 2023. URL https://proceedings.mlr.press/v202/gao23f/gao23f.pdf.\\n\\nZhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. Critic: Large language models can self-correct with tool-interactive critiquing. ArXiv preprint, abs/2305.11738, 2023. URL https://arxiv.org/abs/2305.11738.\"}"}
{"id": "yLClGs770I", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We show the results in Table 5. And our key findings are summarized as follows:\\n\\n\u2022 When the model is trained on individual datasets (GSM8K, MATH, or AQuA), it demonstrates strong performance in tasks closely related to the respective training dataset. However, it generally struggles to generalize this performance to other tasks.\\n\\n\u2022 The datasets GSM8K, MATH, and AQuA emerge as crucial components in the training process. Training the model on a combination of these datasets leads to a marked improvement in its overall performance, indicative of the complementary nature of these datasets. Omitting any one of these datasets results in a noticeable decline in overall performance.\\n\\n\u2022 TheoremQA, despite its smaller scale, exerts some influence on the model's performance. It tends to enhance the model's capabilities on datasets like Mathematics and SimulEq, yet it may slightly impede performance on GSM8K and MATH. Nevertheless, its inclusion in the training regimen is favored, as it introduces a broader variety of questions and could potentially aid the model in generalizing to other complex problems that require advanced computational skills.\\n\\n\u2022 Incorporating a wider range of datasets into the training consistently improves the model's performance across most tasks. This suggests that a broad and diverse knowledge base is instrumental in enhancing the model's ability to generalize.\"}"}
{"id": "yLClGs770I", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"We added some additional results here. The results provide how much of GPT-4 generated data are being filtered (see Table 6). The results also include the generalization benefits of MathInstruct vs. only training on GSM (see Table 7). We also include different self-consistency setups to show how far our method can reach with ensemble decoding methods.\\n\\n| GPT-4 Rationales Validated Ratio          |\\n|------------------------------------------|\\n| AQuA-PoT 75% (9772 /13000)              |\\n| MATH-PoT 51% (7088 / 14000)             |\\n| TheoremQA-PoT 44% (703 / 1600)          |\\n| TheoremQA-CoT 37% (592 / 1600)          |\\n| GSM8K - PoT 81% (14591 / 18000)         |\\n\\nTable 6: The validated ratio of GPT-4 distilled rationales of newly curated subsets in Table 1.\\n\\n| CodeLlama - 7B - GSM8K | 63.2 | 18.4 | 25.4 | 32.9 | 67.6 | 40.1 | 16.3 | 26.4 | 26.1 | 35.2 |\\n|------------------------|------|------|------|------|------|------|------|------|------|------|\\n| CodeLlama - 7B - MathInstruct | 59.4 | 33.4 | 47.2 | 66.4 | 71.4 | 55.4 | 45.9 | 40.5 | 48.3 | 52.0 |\\n\\nTable 7: CodeLlama 7B trained on GSM8K and MathInstruct. Training exclusively on a single dataset like GSM8K leads to challenges in generalizing to other datasets.\\n\\n| Decoding Method GSM MATH | 1 PoT | 1 PoT + 1 CoT backup | 5 PoT + 5 CoT self-consistency | 10 PoT self-consistency | 10 PoT + 10 CoT self-consistency | 20 PoT self-consistency |\\n|--------------------------|------|----------------------|--------------------------------|-------------------------|----------------------------------|-------------------------|\\n|                          | 58.8 | 32.1                 | 59.4                          | 33.4                    | 66.4                             | 37.0                    |\\n|                          |      |                      |                               |                         | 67.0                             | 37.8                    |\\n|                          |      |                      |                               |                         | 69.6                             | 38.2                    |\\n|                          |      |                      |                               |                         | 70.1                             | 38.6                    |\\n\\nTable 8: Exploration of different decoding methods. Though the self-consistency Wang et al. (2023f) decoding can further improve the performance, it introduces significantly larger inference. Our chosen strategy, while straightforward, strikes an optimal balance between complexity, performance, and practical applicability.\"}"}
{"id": "yLClGs770I", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model                | GSM | Math | AQuA | NumG | SV | Mat | Sim | SAT | MMLU | VG |\\n|----------------------|-----|------|------|------|----|-----|-----|-----|------|----|\\n| **Base**             | 14.6| 2.5  | 30.3 | 29.9 | 34.5| 6.0 | 5.0 | 26.8 | 29.8 | 19.9|\\n| WizzardMath          | 54.9| 10.7 | 26.3 | 36.1 | 36.1| 9.3 | 12.8| 25.4 | 31.1 | 27.0|\\n| **MAmmoTH (MathInstruct-CoT)** | 49.2| 9.9  | 42.2 | 37.1 | 48.5| 9.5 | 17.3| 34.1 | 39.8 | 32.0|\\n| **MAmmoTH (MathInstruct-PoT)** | 50.8| 28.9 | 28.6 | 52.7 | 65.0| 46.7| 42.0| 25.9 | 28.3 | 41.0|\\n| **MAmmoTH (MathInstruct)** | 53.6| 31.5 | 44.5 | 61.2 | 67.7| 46.3| 41.2| 42.7 | 42.6 | 47.9|\\n\\nTable 9: Breakdown results of Figure 2. Investigation of the influence of CoT & PoT hybrid training on the 7B Llama-2 model.\\n\\n| Model                | GSM | Math | AQuA | NumG | SV | Mat | Sim | SAT | MMLU | VG |\\n|----------------------|-----|------|------|------|----|-----|-----|-----|------|----|\\n| **MAmmoTH-7B CoT**   | 50.5| 10.4 | 43.7 | 44.0 | 47.3| 9.2 | 18.9| 32.7 | 39.9 | 33.0|\\n| **MAmmoTH-7B PoT**   | 51.6| 28.7 | 43.3 | 52.3 | 65.1| 41.9| 48.2| 39.1 | 44.6 | 46.1|\\n| **MAmmoTH-7B Hybrid**| 53.6| 31.5 | 44.5 | 61.2 | 67.7| 46.3| 41.2| 42.7 | 42.6 | 47.9|\\n| **MAmmoTH-Coder-7B CoT** | 22.4| 7.9  | 36.2 | 36.0 | 37.0| 8.2 | 7.2 | 32.7 | 34.6 | 24.7|\\n| **MAmmoTH-Coder-7B PoT** | 58.8| 32.1 | 47.2 | 57.1 | 71.1| 53.9| 44.6| 40.0 | 47.8 | 50.3|\\n| **MAmmoTH-Coder-7B Hybrid** | 59.4| 33.4 | 47.2 | 66.4 | 71.4| 55.4| 45.9| 40.5 | 48.3 | 52.0|\\n\\n| Model                | GSM | Math | AQuA | NumG | SV | Mat | Sim | SAT | MMLU | VG |\\n|----------------------|-----|------|------|------|----|-----|-----|-----|------|----|\\n| **MAmmoTH-13B CoT**  | 56.3| 12.9 | 45.3 | 45.6 | 53.8| 11.7| 22.4| 43.6 | 42.3 | 37.1|\\n| **MAmmoTH-13B PoT**  | 61.3| 32.6 | 48.8 | 59.6 | 72.2| 48.5| 40.3| 46.8 | 45.4 | 50.6|\\n| **MAmmoTH-13B Hybrid** | 62.0| 34.2 | 51.6 | 68.7 | 72.4| 49.2| 43.2| 46.8 | 47.6 | 52.9|\\n| **MAmmoTH-Coder-13B CoT** | 32.1| 10.2 | 40.6 | 36.2 | 43.0| 9.6 | 10.1| 40.9 | 36.6 | 28.8|\\n| **MAmmoTH-Coder-13B PoT** | 64.3| 35.2 | 46.8 | 54.2 | 73.2| 60.0| 44.2| 48.2 | 48.2 | 52.7|\\n| **MAmmoTH-Coder-13B Hybrid** | 64.7| 36.3 | 46.9 | 66.8 | 73.7| 61.5| 47.1| 48.6 | 48.3 | 54.9|\\n\\n| Model                | GSM | Math | AQuA | NumG | SV | Mat | Sim | SAT | MMLU | VG |\\n|----------------------|-----|------|------|------|----|-----|-----|-----|------|----|\\n| **MAmmoTH-34B CoT**  | 34.3| 11.6 | 39.0 | 36.2 | 44.6| 10.8| 10.9| 46.4 | 42.9 | 30.7|\\n| **MAmmoTH-34B PoT**  | 72.3| 42.8 | 53.8 | 59.6 | 84.0| 64.7| 50.6| 58.6 | 52.7 | 59.9|\\n| **MAmmoTH-34B Hybrid** | 72.7| 43.6 | 54.7 | 71.6 | 84.3| 65.4| 51.8| 60.9 | 53.8 | 62.1|\\n| **MAmmoTH-70B CoT**  | 72.4| 21.1 | 57.9 | 58.9 | 71.6| 20.0| 31.9| 57.3 | 52.1 | 49.2|\\n| **MAmmoTH-70B PoT**  | 76.7| 40.1 | 60.2 | 64.3 | 81.7| 64.7| 50.6| 64.1 | 53.5 | 60.1|\\n| **MAmmoTH-70B Hybrid** | 76.9| 41.8 | 65.0 | 74.4 | 82.4| 65.4| 51.4| 66.4 | 56.7 | 63.4|\\n\\nTable 10: Influence of different decoding methods on each dataset.\"}"}
{"id": "yLClGs770I", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Despite their training on a diverse set of mathematical rationale datasets, the MAmmoTH models might exhibit limitations when faced with problems outside their primary domain of expertise like mathematical analysis, complex analysis, graph theory, numerical analysis, etc. Thus, our models are not suitable for solving more complex problems in these fields. Also, they have not been trained with proof-type problems, thus their theorem-proving capability is also limited. In the future, we would like to expand the models' skill set to cover more fields and theorem-proving problems.\\n\\nThere is also a risk of the MAmmoTH models generating potentially harmful, offensive, or biased content, especially if they are asked to answer questions beyond math. The MAmmoTH series could be misused for malicious purposes, such as spreading misinformation or probing sensitive topics. Developers should conduct safety testing and tuning tailored to their specific applications before deploying any MAmmoTH model. While we have made every effort to ensure the cleanliness and purity of our training data, we cannot guarantee absolute perfection. It is unlikely but not impossible that some inappropriate questions slipped through the curation process.\\n\\nFuture work may continue to explore how to further improve the robustness and generalizability of MAmmoTH in mathematical reasoning. For example, recent work identifies \\\"sycophancy\\\" and \\\"Clever Hans effect\\\" in reasoning: LLMs cannot maintain truthful solutions to reasoning tasks when challenged by the user's absurdly invalid arguments and critiques (Wang et al., 2023b). Potential methods to improve the models' reasoning robustness could involve the exploration of synthetic data intervention methods as explored in (Wei et al., 2023).\"}"}
