{"id": "mk0HzdqY7i1", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ABSTRACT\\n\\nCombinatorial optimization lies at the core of many real-world problems. Especially since the rise of graph neural networks (GNNs), the deep learning community has been developing solvers that derive solutions to NP-hard problems by learning the problem-specific solution structure. However, reproducing the results of these publications proves to be difficult. We make three contributions. First, we present an open-source benchmark suite for the NP-hard Maximum Independent Set problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. Second, using our benchmark suite, we conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. By re-implementing their algorithm with a focus on code quality and extensibility, we show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. Instead, the tree search relies on algorithmic techniques like graph kernelization to find good solutions. Thus, the results from the original publication are not reproducible. Third, we extend the analysis to compare the tree search implementations to other solvers, showing that the classical algorithmic solvers often are faster, while providing solutions of similar quality. Additionally, we analyze a recent solver based on reinforcement learning and observe that for this solver, the GNN is responsible for the competitive solution quality.\\n\\nINTRODUCTION\\n\\nVarious communities have been dealing with the question of how to efficiently solve combinatorial problems, which frequently are NP-hard. These problems often have real-world applications in industry, for instance in staff assignment (Peters et al., 2019), supply chain optimization (Eskandarpour et al., 2015), and traffic optimization (B\u00f6ther et al., 2021).\\n\\nIn recent years, also the machine learning community has been engaged in solving combinatorial problems. One reason that learning-based approaches are interesting, even though commercial general purpose solvers like Gurobi (Gurobi Optimization LLC, 2021) exist, is that we might be able to learn the solution structure of a specific family of instances, e.g., similar vehicle routing problems instances are solved everyday (Khalil et al., 2017; Dong et al., 2021). Such a trained model can be used together with an algorithmic component to find feasible solutions quickly; we outline in Section 2.1 the designs that past works have used.\\n\\nHowever, these statistics-based techniques have the well-known problem of reproducibility (Ioannidis, 2005; Baker, 2016), which is a particular problem in machine learning research with untested or even unpublished code and data sets (Kapoor & Narayanan, 2020; Ding et al., 2020), and is the\"}"}
{"id": "mk0HzdqY7i1", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We adhere to the ICLR Code of Ethics and declare that we have no conflicts of interest. We tried to contact the authors of the related work, as stated in the respective sections.\\n\\nAs our results contradict previous work, we try to be as transparent as possible about our process. The solvers we use are documented in Section 2. The changes we apply to LWD and INTEL-TreeSearch are supplied as a git patch with our benchmark suite that can be accessed via the repository or in the supplementary material published alongside with this paper. The datasets we use are listed in Appendix E; we supply the code required to preprocess the datasets.\\n\\nWe thank the anonymous reviewers for their invaluable feedback and the HPI FutureSOC Lab for computing infrastructure.\\n\\nSungsoo Ahn, Younggyo Seo, and Jinwoo Shin. Learning what to defer for maximum independent sets. In Proceedings of the 37th International Conference on Machine Learning (ICML), volume 119 of Proceedings of Machine Learning Research, 2020.\\n\\nR\u00b4eka Albert and Albert-L\u00b4aszl\u00b4o Barab\u00b4asi. Statistical mechanics of complex networks. Reviews of Modern Physics, 74(1), 2002. doi: 10.1103/revmodphys.74.47.\\n\\nAnaconda Inc. Anaconda software distribution, 2020. URL https://docs.anaconda.com/.\\n\\nMonya Baker. 1, 500 scientists lift the lid on reproducibility. Nature, 533(7604), 2016. doi: 10.1038/533452a.\\n\\nMaria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch. In Proceedings of the 35th International Conference on Machine Learning (ICML), volume 80, 2018.\\n\\nJean Berger and Mohamed Barkaoui. A hybrid genetic algorithm for the capacitated vehicle routing problem. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO) 2003, 2003. doi: 10.1007/3-540-45105-6.\\n\\nThomas Bl\u00a8asius, Tobias Friedrich, Maximilian Katzmann, Anton Krohmer, and Jonathan Striebel. Towards a systematic evaluation of generative network models. In Proceedings of the International Workshop on Algorithms and Models for the Web Graph (WAW), 2018. doi: 10.1007/978-3-319-92871-5.\\n\\nThomas Bl\u00a8asius, Tobias Friedrich, Maximilian Katzmann, Ulrich Meyer, Manuel Penschuck, and Christopher Weyand. Efficiently generating geometric inhomogeneous and hyperbolic random graphs. In Proceedings of the 27th Annual European Symposium on Algorithms (ESA), 2019. doi: 10.4230/LIPICS.ESA.2019.21.\\n\\nGeoff Boeing. OSMnx: New methods for acquiring, constructing, analyzing, and visualizing complex street networks. Computers, Environment and Urban Systems, 65, 2017. doi: 10.1016/j.compenvurbsys.2017.05.004.\\n\\nMaximilian B\u00a8other, Leon Schiller, Philipp Fischbeck, Louise Molitor, Martin S. Krejca, and Tobias Friedrich. Evolutionary minimization of traffic congestion. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO), 2021. doi: 10.1145/3449639.3459307.\\n\\nSergiy Butenko. Maximum Independent Set and Related Problems, with Applications. PhD thesis, University of Florida, 2003.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mk0HzdqY7i1", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mk0HzdqY7i1", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mk0HzdqY7i1", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Violin plots of time to solution and MIS sizes of the tree searches in various configurations on a selection of data sets.\\n\\nThe default variants, where neither reduction nor local search is enabled, both Intel-TreeSearch and DGL-TreeSearch do not often find a solution. This shows that for medium-sized graphs, vanilla tree searches cannot discover solutions within a feasible time limit. The reductions often single-handedly solve the problem instance, as seen for example on the simple BA graphs, where a solution is found instantaneously.\\n\\nQueue Pruning and Weighted Queue Pop.\\n\\nTo approach the issue of requiring hand-tailored reduction techniques to obtain any solution, with DGL-TreeSearch, we analyze queue pruning and the weighted queue pop. While queue pruning itself performs similar to the default configuration for all graphs, the weighted pop vastly increases the number of solutions found. For example, for large hyperbolic random graphs, in the default configuration, the DGL-TreeSearch was only able to find solutions for 5 graphs (and the Intel-TreeSearch was not able to find any solution), whereas using queue pruning together with the weighted queue pop, we find solutions for 98% of all large HRGs. A similar observation can be made for WS graphs. Interestingly, it seems like the MIS problem is harder to address with the default approach on graphs that try to model real-world networks, such as the just mentioned HRGs and WS graphs (Bl\u00e4sius et al., 2018). Overall, queue pruning might be desirable to reduce memory consumption, but its impact on solving quality and time is limited; on the other hand, weighted queue popping is a general idea that brings some more depth-search-like behavior into the breadth-search-like approach at hand, and thus enables the solver to find a lot more solutions.\\n\\nImportance of Reduction.\\n\\nFor small and large BA, HK, WS graphs as well as HRGs, the reduction itself already leads to an achieved average approximation of 1. Only for the large ER graphs, for which GUROBI was not able to find provably optimal assignments, the local search further improves the average independent set size. Multithreading cannot improve the results of the random graphs.\\n\\nHard Real-World Graph Results.\\n\\nNow, we discuss the results for the hard benchmark datasets. Unlike previously, where we just aimed at finding an MIS on random graphs, solving the MIS problem on SATLIB is equivalent to finding a satisfiable assignment to synthesized hard 3-SAT instances. Thus, one can expect this data set to be particularly hard. Our experiments confirm this, as both implementations rarely find solutions within the time limit without reduction enabled. We can see that, similar to the random graphs, the weighted queue pop enables the search to at least find some solution, as this configuration is at least able to find 211 instead of no results at all. However, the\"}"}
{"id": "mk0HzdqY7i1", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"average independent set size is 357, which is not very good, considering each MIS in this dataset contains at least 403 vertices. Considering VC-BM, due to the higher time limit, the default configurations are already able to find some solution. Interestingly, for VC-BM, the reductions do not improve the performance of the solvers. Hence, the weighted queue pop is very important for finding results quickly, shrinking the time needed from the default 140 seconds to under 70 seconds. For DIMACS, we see similar behavior to SATLIB, i.e., the reduction and local search techniques improve the average MIS, and the weighted queue pop enables faster discovery of solutions.\\n\\nImpact of the Findings.\\n\\nThese results are interesting for various reasons. First, the models are trained on SATLIB instances, but the default configuration does not find any independent set for other instances of the this family, which was one motivation for using machine learning for optimization (c.f. Section 1). The results contradict the original paper by Li et al. (2018), which claims an average MIS of 426 and related work by Ahn et al. (2020), claiming an average MIS of 418. Additionally to our own trained weights, we test the model weights provided in the official Intel-Search repository, but do not find any differences in the results. Ahn et al. (2020) mention that they modified the official Intel-Search code. Unfortunately, neither the paper documents how exactly their queue pruning has been implemented, nor were the authors themselves able to provide us their modifications to the original Intel-Search repository when we contacted them. Hence, it remains unclear whether the difference in the SATLIB results between Ahn et al. (2020) and our experiments stems from how they implemented queue pruning, or from some unwanted side effects in their experiments (e.g., the reduction may have been still enabled). Furthermore, we unsuccessfully contacted Li et al. (2018) about our findings. As both the Intel-Search and our re-implementation DGL-Search, which was written from scratch, exhibit this behavior, we suspect that there must be an undocumented modification or problem in the experiments that leads to Ahn et al. (2020) obtaining rather good results with the default configuration. Overall, neither the original code with the original weights, nor the original code with newly trained weights, nor our reimplementation are performing as originally claimed. In order to be as transparent as possible about our findings, we provide all of our code changes applied to the Intel repository as a patch and provide the entire source code of the re-implemented DGL-Search as well.\\n\\nReplacing the GCN with Random Values.\\n\\nNext, we analyze the replacement of the outputs of the GCN with random values. We start with the randomized default configuration, i.e., no techniques like reduction are enabled. In this case, we find that for all small random graphs, the tree search is still able to find solutions; however, the quality of these MIS seems to be slightly worse than the default results. For 80% of the larger random graphs \u2013 except for ER graphs \u2013 the randomized tree search is not able to find solutions. As the default configuration is not able to find any solution for SATLIB, it is to be expected that the random configuration does not find any solution either.\\n\\nRandomness for Other Real-World Graphs.\\n\\nFor the other real-world graphs, the reddit datasets are the only datasets where the default configuration performed reasonably well. We find that the randomness here in fact increases the performance of the algorithm.\\n\\nRobustness.\\n\\nMost of our datasets consist of multiple instances. In order to shed light onto the distribution of both the solution size as well as the time until the solution was found, in Figure 1, we show violin plots for some data sets and tree search configurations. Note in most real world scenarios, we do not know when we can terminate, hence the run time will always be the maximum time limit configured. In these plots, we can for example again confirm that the combination of queue pruning and weighted popping enables us to find solutions quicker. We also see that as soon as reduction and local search are enabled, the solution distributions of the tree searches are very similar, no matter whether whether we query the GCN or use random values; for SATLIB, we see that using random values the distribution of the time to solution is even narrower towards 0, because no GPU computation is required.\\n\\nFinal Considerations.\\n\\nWe conclude that the guidance by the GCN does not help our tree search algorithm; for some datasets, it is not able to generalize well (randomness beats the GCN), for others, there is no performance difference between random values and the GCN. If we focus on the configuration of the tree search that could be considered the production version, i.e., with at least 10\\n\\nRecall that the default version is not able to solve the SATLIB dataset without the help of reduction and local search techniques.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"reduction and local search enabled, we find that random outputs lead to identical performance, with very minor differences in the time until the final solution discovery. Overall, major contributing factors to solution quality are the reduction and local search by KA\\\\textsuperscript{MIS}, and in fact, the tree search algorithm is a \\\"smarter brute-force\\\" approach that does not gain any performance by being guided by a machine learning model. Instead, the search space is only narrowed by techniques such as data reduction and weighted queue popping, instead of good guidance by the ML model.\\n\\n3.2 COMPARING TREE SEARCHES TO OTHER SOLVERS\\n\\nHaving understood the implications of the various possible configurations of tree searches, next, we compare INTEL-TREESEARCH and DGL-TREESEARCH to KA\\\\textsuperscript{MIS}, a heuristic solver optimized for the MAXIMUM INDEPENDENT SET problem, the mathematical optimization tool GUROBI, and the reinforcement learning tool LEARNINGWHTO. For LEARNINGWHTO, we train for 20,000 iterations of proximal policy optimization on the SATLIB dataset, using the hyperparameters given for SATLIB in Table 5 (Appendix A.1) of Ahn et al. (2020). Due to space constraints, the detailed results are given in Appendix A in Table 3.\\n\\nKA\\\\textsuperscript{MIS} and GUROBI. As we can see, the sophisticated state-of-the-art solver KA\\\\textsuperscript{MIS} can solve almost all instances perfectly; for example, for the large ER graphs, the multithreaded INTEL-TREESEARCH has a slightly higher average MIS, and a faster time until a solution is found. For other graphs, especially the SATLIB dataset, KA\\\\textsuperscript{MIS} is very fast, while obtaining very high-quality results.\\n\\nThese results are in line with Ahn et al. (2020), who also observed KA\\\\textsuperscript{MIS} outperforming the tree search. Regarding the general-purpose solver GUROBI, we find that it performs similar to KA\\\\textsuperscript{MIS} on simple instances, however, on harder datasets such as SATLIB or VC-BM, we see that Gurobi takes significantly more time to find good solutions, and the average MIS is a little smaller (e.g., for large ER graphs, KA\\\\textsuperscript{MIS} achieves 44.57, compared to 37.79 for GUROBI). Note that GUROBI and KA\\\\textsuperscript{MIS} have to rely on the CPU, while the tree search employs one or more GPUs, unless it uses random values. Even when assigning eight V100 GPUs to the multithreaded tree search, the computational advantage of the tree search does not help to outperform the other solvers, showing that the workload is not GPU-bound.\\n\\nLEARNINGWHTO. We analyze LEARNINGWHTO first in its default configuration and then, similar to the tree search, replace the output of the graph neural network with a random tensor. First, LEARNINGWHTO is very fast, even though it requires neural network inference. For example, on the DIMACS data set, LEARNINGWHTO finds solutions on average in just 4 seconds, while KA\\\\textsuperscript{MIS} takes 121 seconds. Quality-wise, except for the VC-BM dataset, it always finds near-optimal solutions. Note that we did not use the local search or reduction techniques for LEARNINGWHTO, which could further improve solution quality. When using random output instead of the neural network, unlike the tree search algorithms, the solution quality degrades noticeably. These promising results show that LEARNINGWHTO did not only learn the solution structure of the SATLIB instance family, but additionally is able to generalize over different datasets.\\n\\nRobustness. Due to space constraints, we show violin plots of the results in Appendix A in Figure 2. We clearly see the impact of randomness on LEARNINGWHTO, and can visually compare the time difference between GUROBI and KA\\\\textsuperscript{MIS}, for example on VC-BM.\\n\\nFinal Considerations. For tree search approaches, we see that state-of-the-art algorithmic techniques are required to find good solutions. As the fully-configured versions of the tree searches employ these KA\\\\textsuperscript{MIS}-internal routines, one can argue that the purely algorithmic solvers are the better choice, because the quality difference is negligible, while KA\\\\textsuperscript{MIS} is faster than the tree searches. Purely algorithmic solvers do not come with the overhead of a machine learning environment (training as well as execution are more complicated), and the important algorithmic techniques need to be developed in any case. Our results are in line with observations by Joshi et al. (2021) who have compared algorithmic and classical solvers to deep learning solutions for TSP, and observe that DL-based solutions are often outperformed, especially on larger instances.\\n\\n3.3 LARGE-SCALE GRAPHS\\n\\nHowever, the question is whether these observations also hold true for large-scale graphs. To this end, we evaluate the solvers on random graph instances from 500,000 to 5,000,000 vertices, and on huge real-world graphs. Detailed results can be found in Appendix A in Table 4.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Overall, we observe similar performance characteristics on large-scale graphs. Only \\\\textsc{KAMIS} and \\\\textsc{GUROBI} are able to find solutions for all scenarios. \\\\textsc{KAMIS} performs best, both with respect to solution quality and time required to find these solutions; in many cases, it is more than one order of magnitude faster than other solvers. Compared to the \\\\textsc{Intel-TreeSearch}, the \\\\textsc{DGL-TreeSearch} times outs more often due to VRAM limits; the \\\\textsc{Intel-TreeSearch} benefits from lower-level implementation using \\\\texttt{numpy} arrays and sparse adjacency matrices, while the \\\\textsc{DGL-TreeSearch} employs the higher level \\\\texttt{Deep Graph Library} graph abstraction, consuming more memory. For \\\\textsc{LW}, we see good results for graphs up to 500,000 vertices, but cannot verify the scalability up to 2,000,000 vertices of the original paper.\\n\\n\\\\subsection*{3.4 Weighted Graphs}\\n\\nHaving analyzed the solvers on unweighted graphs, we briefly want to see how the solvers perform on weighted graphs. Intuitively, the weighted problem is harder, because each vertex can have a different value; hence specialized reduction techniques have to be developed. Lamm et al. (2019) were the first to present such rules also for the weighted case that are implemented in \\\\textsc{KAMIS}, however, only integer weights are currently supported. We test weighted random graphs and three Amazon MWIS data sets. The results and details on the weighted graph generation are given in Appendix A in Table 5; note that \\\\textsc{Intel-TreeSearch} does not support the weighted case, and while Ahn et al. (2020) evaluate \\\\textsc{LW} for MWIS, they do not provide the code to do so.\\n\\nWe observe that on HK, WS, and HRG graphs, where \\\\textsc{KAMIS} is able to utilize its reduction techniques, it is able to instantaneously solve the weighted problem as well. However, on ER graphs, the reduction times out, showing that the suitability of the algorithmic techniques is graph-dependent. In the weighted case on ER graphs, the \\\\textsc{DGL-TreeSearch} with queue pruning enabled finds the best result. \\\\textsc{GUROBI} finds solutions of similar quality to \\\\textsc{KAMIS} very quickly. For the Amazon data sets, all solvers except \\\\textsc{GUROBI} reach their limits. \\\\textsc{KAMIS} does not support the large node weights that are used in the Amazon instances and hence is not able to solve them. The \\\\textsc{DGL-TreeSearch} goes out of memory and crashes while solving these instances. Overall, we see that both \\\\textsc{GUROBI} as well as the vanilla tree search have the advantage of being problem-agnostic, i.e., an extension to the weighted case was easily possible, while for the algorithmic solver, new reductions are needed, that currently cannot deal with some graphs. On smaller random graphs where the reductions are successful, \\\\textsc{KAMIS} finds solutions of the highest quality, showing the trade-off between general and specialized solvers. \\\\textsc{GUROBI} is the only solver that is able to solve large, weighted, real-world MWIS instances, and shows that industry-standard optimizers are very robust towards different inputs of different sizes, while smaller algorithmic solvers need more time to reach that level of robustness.\\n\\n\\\\section*{Conclusion and Future Work}\\n\\nWe present our comprehensive, open-source benchmark environment for the Maximum (Weighted) Independent Set problem. Using this environment, we run several experiments on both real-world and synthetic graphs of different sizes. Our analysis shows that guided tree searches, such as the \\\\textsc{Intel-TreeSearch} by Li et al. (2018), owe their good results not to the trained neural network, but instead to the various techniques used to make a \u201cbetter\u201d brute-force algorithm. To verify this, we show that the GCN that guides the search can be replaced by random values without a noticeable performance impact. Furthermore, we are not able to reproduce the results of previous work in the default configuration of the algorithm and claim that without algorithmic techniques, the tree search algorithms are not able to solve hard MIS instances. We believe our results to be an important insight for the community researching at the intersection of combinatorial optimization and machine learning. The benchmark suite lays the ground for future reproducible evaluations for new MIS solvers, and the promising results for Learning What To Do indicate that reinforcement learning is superior to supervised approaches. This might be kept in mind when developing solving techniques using machine learning in the future. For future work, further variants of the Maximum Independent Set problem, such as the Generalized Independent Set problem (Colombi et al., 2017; Hosseinian & Butenko, 2019), and other problems, such as TSP, should be considered, to further understand for what kind of problem what solver architecture should be used.\\n\\n\\\\footnote{As Ahn et al. (2020) do not explicitly state the hyperparameter configuration for their large-scale experiments and random graph generation, these experiments might not be directly comparable.}\"}"}
{"id": "mk0HzdqY7i1", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"reason for the interest in initiatives such as Papers With Code and the ReScience Journal. Keeping the importance of reproducibility in mind, we evaluate various machine learning approaches for combinatorial optimization, and compare them to traditional solvers. We focus on the MAXIMUM INDEPENDENT SET problem (Miller & Muller, 1960; Karp, 1972), as the previous works we analyze have centered around variants of this problem. Overall, we contribute the following.\\n\\n\u2022 We provide an open-source, extensible benchmark suite for MAXIMUM WEIGHTED INDEPENDENT SET solvers. The software currently supports five state-of-the-art solvers, INTEL-TREESEARCH (Li, Chen, and Koltun, 2018), GUROBI (Gurobi Optimization LLC, 2021), KAMIS (Lamm et al., 2017; Hespe et al., 2019; Lamm et al., 2019), LEARNING WHAT TO DEFER (Ahn, Seo, and Shin, 2020), and DGL-TREESEARCH. Our DGL-TREESEARCH is a modern re-implementation of the INTEL-TREESEARCH, implemented in PyTorch (Paszke et al., 2019) and the Deep Graph Library (Wang et al., 2019), with a focus on clean, readable code, as well as performance, and it fixes various issues of the original code. Our evaluation suite lays the ground for further research on hard combinatorial (graph) problems and aims at providing a fair and comparable environment for further evaluations.\\n\\n\u2022 Using our re-implementation of the tree search, we propose and analyze additional techniques aiming at improving the guided search. Employing the benchmark suite, we conduct an exhaustive analysis of various configurations of the tree search algorithms, showing that the results of the highly-cited INTEL-TREESEARCH approach are not reproducible, neither with the original code nor with our re-implementation. When exploring the design space further, we show that the various techniques used by the tree search algorithm to improve the results, like graph kernelization, are the reason for good performance, especially on hard data sets. In fact, replacing the GNN output with random values performs similar to using the trained network.\\n\\n\u2022 Having analyzed the configuration space, we compare the tree search approaches to the classical solvers like GUROBI and KAMIS, showing that problem-tailored solvers are often the superior approach. Without using techniques like graph reduction in the tree search, classical solvers are superior. The classical solvers show to be more efficient even when accessing these routines \u2013 that have been implemented for the algorithmic solvers in the first place \u2013 in the tree search. Last, we show that LEARNING WHAT TO DEFER seems to be able to find good results very quickly, indicating that unsupervised reinforcement learning for combinatorial problems is a promising direction for future research.\\n\\nIn this section, we formally introduce the MAXIMUM INDEPENDENT SET (MIS) problem as well as the solvers included in our analysis, and discuss related work in the broader space of deep learning for combinatorial optimization. Given an undirected graph \\\\( G = (V, E) \\\\), an independent set is a set of vertices \\\\( S \\\\subseteq V \\\\) for which for all vertices \\\\( u, v \\\\in S \\\\), \\\\((u, v) \\\\not\\\\in E\\\\). For \\\\( u \\\\in V \\\\), let \\\\( w_u \\\\) be its weight, and let \\\\( IS(G) \\\\) be all independent sets of \\\\( G \\\\), then the MAXIMUM WEIGHTED INDEPENDENT SET (MWIS) problem aims at determining \\\\( \\\\arg \\\\max_{S \\\\in IS(G)} \\\\sum_{u \\\\in S} w_u \\\\). The unweighted MIS problem is equivalent to the MWIS problem, where \\\\( f.a. \\\\ u \\\\in V, w_u = 1 \\\\). Both problems are strongly NP-complete (Garey & Johnson, 1978). Next, we briefly explain the solvers that we use to find such MIS.\\n\\nGUROBI. GUROBI is a commercial mathematical optimization solver. There are various ways of formulating the M(W)IS problem mathematically (Butenko, 2003). In the main paper, we formulate the MWIS problem as the linear program above, and discuss other variants in Appendix D.\\n\\nKAMIS. KAMIS is an open-source solver tailored towards the MIS and MWIS problems. It offers support both for the unweighted case (Lamm et al., 2017; Hespe et al., 2019) as well as the weighted case (Lamm et al., 2019). It employs graph kernelization and an optimized branch-and-bound algorithm to efficiently find independent sets. Note that the algorithms and techniques differ between the weighted and unweighted cases. We use the code unmodified from the official repository.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In their influential paper, Li et al. (2018) propose a guided tree search algorithm to find maximum independent sets of a graph. The idea is to train a graph convolutional network (GCN) (Kipf & Welling, 2017), which assigns each vertex a probability of belonging to the independent set, and then greedily and iteratively assign vertices to the set. They furthermore employ the reduction and local search algorithms by K\\\\textsc{A}\\\\textsc{M}IS to speed up the computation. We use their published code, which unfortunately is not runnable in its default state. We apply a git patch to make the code runnable, enable further evaluation by collecting statistics, and add command-line flags for more fine-grained control of the solver configuration. In Appendix C, we give some details on possible complications with the original code.\\n\\nBecause a good knowledge of the algorithm is important to follow the remainder of this paper, we briefly describe the algorithm. A pseudocode description of the algorithm is found in Algorithm 1. The core element of the tree search is a queue of partial solutions $S \\\\in \\\\{0, 1, \\\\perp\\\\}$ to the MIS problem, i.e., labelings of the graph at hand marking each vertex as either included in the MIS (1), excluded (0), or unlabeled (a decision is still to be made, $\\\\perp$). To be a valid (partial) solution to the MIS problem, each element in the queue fulfills the constraint that no two adjacent vertices can both be included. Furthermore, all vertices adjacent to an included one must be excluded.\\n\\nGiven a graph $G = (V, E)$, we start with an empty solution, i.e., $f.a. v \\\\in V, S_v = \\\\perp$. In each step of the tree search, a partial labeling is popped from the queue, and the residual graph $G_{\\\\text{residual}}$ consisting only of the unlabeled vertices is constructed. Next, we obtain a predefined number $m$ of probability maps, each of which contains a value for all vertices of the residual graph, posing the \u201cprobability of being in the MIS\u201d, by calling the trained GCN, which outputs its assignments from vertices to probabilities, i.e., $\\\\text{GCN}(G) \\\\in [0, 1]^{V \\\\times m}$.\\n\\nFrom each of these probability maps, a new partial solution is derived as follows: The probabilities of the maps are sorted in descending order. The vertex with the highest probability gets labeled as included, and all adjacent vertices as excluded. This step is repeated until we would have to label an already excluded vertex as included, in which case we break, and add the partial solution to the queue. In case all vertices are labeled we obtained a full solution. This procedure is repeated for all probability maps. For further modifications of this algorithm (e.g., reduction), we refer to Appendix B.\\n\\nBecause the code provided by Li et al. (2018) might be difficult to read and maintain, and hence is prone to errors in the evaluation, we re-implement the tree search using PyTorch (Paszke et al., 2019) and the established Deep Graph Library (Wang et al., 2019). Our implementation aims at offering a more readable and modern implementation, which benefits from improvements in the two deep learning libraries during recent years. Furthermore, it fixes various issues of the original implementation that sometimes deviates from the paper. Additionally, we implement further techniques to improve the search, like queue pruning, and weighted selection of the next element, as well as multi-GPU functionality.\\n\\n**Learning What To Defer.**\\n\\nWe test \\\\textsc{Learning What To Defer} (\\\\textsc{LWTD}), an unsupervised deep reinforcement learning-based solution introduced by Ahn et al. (2020). Their idea is similar to the tree search, as the algorithm iteratively assigns vertices to the independent set. However, this is not done using a supervised GCN, but instead by an unsupervised agent built upon the GraphSAGE architecture (Hamilton et al., 2017) and trained by Proximal Policy Optimization (Schulman et al., 2017). There is no queue of partial solutions. We refer to the original paper for details on the algorithm. As their code does not work with generic input, we patch their code.\\n\\nOur open-source benchmarking suite integrates all these solvers in one easily accessible command-line interface using Anaconda (Anaconda Inc., 2020), with a unified input and output format. We provide our code for \\\\textsc{DGL-TreeSearch} and our \\\\textsc{Gurobi} interface directly, and download, compile, and patch the other solvers on-demand. It handles the correct invocation of the solvers and allows to quickly run experiments on various solvers in different configurations.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"AI for Combinatorial Optimization.\\n\\nResearch at the intersection of artificial intelligence and combinatorial optimization is not limited to MIS. These methods differ in the problem they tackle, and how algorithmic components and learned components interact. The evolutionary computation community, for example, has researched various NP-hard routing problems, like the Vehicle Routing Problem (Berger & Barkaoui, 2003; Potvin, 2009) and the Multiple Routes problem (B\u00f6ther et al., 2021). In a nutshell, evolutionary optimization is an iterative improvement that is not guided by a learned component, but instead tries to mutate and combine existing solutions randomly, in order to find better solutions. ML-based solvers often are variants of branch-and-bound solvers. In general, such solvers partition the search space by some rule set; for ML-based solvers, the partition rules are not pre-defined, but given by a model that learned how to branch (Balcan et al., 2018). The concrete algorithms differ in the model used, how they utilize the model to branch within the search space, and how the model is trained. For example, the INTEL-SEARCH trains a GCN on pre-labeled data, and expects from its guidance model a probability for each vertex that describes how likely it is that the vertex belongs to the MIS, and then greedily operates on these probabilities. In comparison to that, LWD instead models the branching process as an unsupervised agent that can choose vertices in a Markov Decision Process, that similarly to the tree search iteratively picks vertices, but for example allows to roll-back invalid solutions, instead of greedily pushing forward. This methodology applies to other combinatorial problems as well. For example, Kool et al. (2019) propose an attention-based encoder-decoder-architecture as a model for solving Travelling Salesman Problem (TSP) instances, where the decoder iteratively outputs probabilities for each vertex to be visited next. They analyze different algorithmic components that utilize that model, for example, greedily following the most probable vertex, or sampling multiple tours and picking the best. Other research has shown that the question of scaling such architectures to real-world instances poses a challenge by itself, and that currently, algorithmic solvers often outperform ML-based solvers for larger instances (Joshi et al., 2021). A theoretical understanding of how such models extrapolate to different instance families is also topic of current research (Xu et al., 2021).\\n\\nWith this discussion, we want to show that the design space for ML-based solvers is broad, as on the one hand, one has to design a model that learns how to solve a problem, and on the other hand build an efficient algorithmic component that utilizes that model to actually find a solution. These components can become very complex, as seen in recent work by Nair et al. (2021) which aims at solving Mixed Integer Programs and uses two neural network components instead of one; the neural diving component finds variable assignments, while the neural branching component guides the branch-and-bound algorithm in its next step.\\n\\nOther Solvers for Maximum Independent Set.\\n\\nNext to the solvers included in this paper, there are some other solvers available. Khalil et al. (2017) propose S2V-DQN, in which they use Q-learning to solve the minimum vertex cover problem. Compared to LWD, which marks multiple vertices as part of the MIS in a single step, S2V-DQN only labels a single vertex in each step. We mention the recent publication by Hespe et al. (2021) introducing some new reduction rules for MIS, which have not yet been included in KMIS. Another heuristic for MIS that we do not consider in this paper in favor of KMIS is GRASP (Feo et al., 1994). Note that all of these solvers are heuristics and hence only solve MIS approximately; exact solvers have been proposed by Jain & Seshadhri (2020); Xiao & Nagamochi (2017); Tomita et al. (2010), for example, and theory has been working on understanding why and in what models MIS poses to be difficult (Censor-Hillel et al., 2017).\\n\\n3 EVALUATION\\n\\nIn this section, we first introduce our experimental setup and then focus on the analysis of the supervised tree search approach for combinatorial optimization in Section 3.1. After having derived a good configuration for the tree search algorithm, we continue to compare the tree search algorithms to the other classical and reinforcement learning solvers in Section 3.2. We investigate the scalability of the approaches in Section 3.3, and analyze the behavior on the weighted MIS problem in Section 3.4.\\n\\nExperimental Setup.\\n\\nWe run all our experiments on an NVIDIA DGX-1 with two 20-Core Intel Xeon E5-2698 CPUs at 2.2 GHz, leading to overall 40 physical and 80 logical cores, 512 GB of\\n\\n9 MVC is very related to the maximum independent set, as one can just flip the assignment.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: Results of the tree searches in various configurations; the full table with more datasets and more configuration options can be found in Table 2. For all configurations, in the first row, we state the average MIS size as well as the average approximation factor. In the second row, the average time in seconds until the best solution was found, and, in brackets, the number of graphs where any solution was found are given. The average values refer only to the graphs within a dataset for which a solution was found. For Intel, here we show the default setting (\\\\(d\\\\)) and the setup with both reduction and local search enabled (\\\\(r+ls\\\\)). For DGL, we explore the configuration space further, as we analyze the default (\\\\(d\\\\)), reduction and local search (\\\\(r+ls\\\\)), queue pruning and weighted queue pop (\\\\(qp+wp\\\\)), and the full configuration where we replace the GCN by randomly generated outputs (\\\\(+rand\\\\)). For the random graphs of size 50-100, all solvers have a time limit of 15 seconds; for the SATLIB and PPI datasets the time limit is 30 seconds; for VC-BM and DIMACS graphs, the time limit is 5 minutes.\\n\\n| Graph Type | Configuration | MIS Size | Approximation Factor | Time (Seconds) |\\n|------------|---------------|----------|----------------------|----------------|\\n| ER         |               |          |                      |                |\\n| 50-100     | d             | 20.58    | 0.98                 | 1.70 (500)     |\\n|            | r+ls          | 20.83    | 1.00                 | 0.02 (500)     |\\n|            | qp+wp         | 19.88    | 0.95                 | 3.53 (500)     |\\n|            | qp+wp+r+ls+rand | 20.83 | 1.00                 | 0.31 (500)     |\\n| 700-800    |               |          |                      |                |\\n|           | d             | 39.90    | -                    | 12.00 (100)    |\\n|           | r+ls          | 44.08    | -                    | 16.81 (100)    |\\n|           | qp+wp         | 37.13    | -                    | 13.63 (100)    |\\n|           | qp+wp+r+ls+rand | 43.90 | -                    | 12.82 (100)    |\\n|            | +rand         | 30.93    | 0.92                 | 9.11 (100)     |\\n| HRG        |               |          |                      |                |\\n| 50-100     | d             | 33.62    | 0.99                 | 3.24 (495)     |\\n|            | r+ls          | 33.72    | 1.00                 | 0.00 (500)     |\\n|            | qp+wp         | 32.80    | 0.97                 | 5.50 (500)     |\\n|            | qp+wp+r+ls+rand | 33.72 | 1.00                 | 0.06 (500)     |\\n| 700-800    |               |          |                      |                |\\n|           | d             | -        | -                    | -              |\\n|           | r+ls          | 304.21   | 1.00                 | -              |\\n|           | qp+wp         | -        | -                    | -              |\\n|           | qp+wp+r+ls+rand | 304.21 | 1.00                 | -              |\\n|           | +rand         | -        | -                    | -              |\\n| SATLIB     |               |          |                      |                |\\n| 1209-1347  |               | 426.39   | 0.99                 | -              |\\n|            | d             | -        | -                    | -              |\\n|            | r+ls          | -        | -                    | -              |\\n|            | qp+wp         | -        | -                    | -              |\\n|            | qp+wp+r+ls+rand | -       | -                    | -              |\\n|            | +rand         | -        | -                    | -              |\\n| VC-BM      |               |          |                      |                |\\n| 450-1534   |               | 39.85    | -                    | 149.80 (40)    |\\n|            | d             | 44.26    | -                    | 166.04 (39)    |\\n|            | r+ls          | 37.20    | -                    | 139.55 (40)    |\\n|            | qp+wp         | 44.35    | -                    | 84.08 (40)     |\\n|            | qp+wp+r+ls+rand | 44.58 | -                    | 68.33 (40)     |\\n| DIMACS     |               |          |                      |                |\\n| 125-4000   |               | 37.14    | -                    | 79.30 (37)     |\\n|            | d             | 76.41    | -                    | 43.12 (37)     |\\n|            | r+ls          | 57.68    | -                    | 87.53 (37)     |\\n|            | qp+wp         | 76.49    | -                    | 36.36 (37)     |\\n|            | qp+wp+r+ls+rand | 76.51 | -                    | 42.56 (37)     |\\n| PPI        |               |          |                      |                |\\n| 591-3480   |               | 1002.83  | 1.00                 | -              |\\n|            | d             | 269.00   | 0.97                 | 24.70 (24)     |\\n|            | r+ls          | 1002.67  | 0.99                 | 23.56 (1)      |\\n|            | qp+wp         | 1002.79  | 0.99                 | 3.70 (24)      |\\n|            | qp+wp+r+ls+rand | 1002.79 | 0.99                 | 20.11 (13)     |\"}"}
{"id": "mk0HzdqY7i1", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Results of the MIS solver KA\\\\textsuperscript{MIS}, the optimization tool GUROBI, and the DGL-\\\\textsc{TreeSearch} in various configurations on weighted random graphs, and Amazon MWIS instances.\\n\\nThe weights on the random graph have been sampled per vertex from a normal distribution $N$ with $\\\\mu = 100$, $\\\\sigma = 30$, capped to be larger than 0, and rounded to integer values. For the explanation of the various configuration flags, we refer to the caption of Table 2. All multithreaded experiments in this table use 8 threads, and all threads share a single GPU. The time limit for all graphs was set to 30 seconds. We mark the configuration that has the best average MIS in bold, and grey out configurations for which solutions were found for less than 20% of all graphs. Similar to the unweighted experiments, we run the solvers on 500 graphs per type. Configurations where there was a timeout due to KA\\\\textsuperscript{MIS}' reduction techniques are marked as TO. Configurations where the solver went out of memory are marked as OOM. Note that KA\\\\textsuperscript{MIS} did not support the Amazon instances, as the node weights are too large.\\n\\n| Graph Type | Nodes | KA\\\\textsuperscript{MIS} | GUROBI | DGL-\\\\textsc{TreeSearch} |\\n|------------|-------|--------------------------|--------|-------------------------|\\n| ER         | 700-800 | 3765.08 (-) TO TO | 3792.71 (-) | 3571.05 (-) TO TO TO TO |\\n| HK         | 700-800 | 39469.48 (0.87) 42026.61 (0.93) 45034.05 (0.99) | 39128.12 (0.87) 40441.76 (0.89) 42026.61 (0.93) 45033.46 (0.99) 45036.91 (0.99) | 20.11 (364) 1.02 (500) 0.68 (500) 20.18 (329) 11.89 (500) 0.97 (500) 0.75 (500) 0.92 (500) 0.00 (500) 0.01 (500) |\\n| WS         | 700-800 | - (-) 36010.38 (0.87) 41160.71 (0.99) 37958.50 (0.92) 36904.74 (0.89) 36010.51 (0.87) 41159.49 (0.99) 41147.84 (0.99) 41196.43 (1.00) 41196.43 (1.00) - 3.13 (500) 5.38 (500) 14.77 (2) 15.17 (439) 3.41 (500) 6.13 (500) 10.19 (500) 0.00 (500) 0.01 (500) |\\n| HRG        | 700-800 | 23641.88 (0.70) 33366.88 (0.99) 33696.93 (0.99) 22583.27 (0.68) 24497.41 (0.72) 33366.88 (0.99) 33696.93 (0.99) 33696.93 (0.99) 33696.96 (1.00) 33696.96 (1.00) 23.25 (24) 0.62 (500) 0.57 (500) 24.89 (22) 17.64 (482) 0.60 (500) 0.54 (500) 0.57 (500) 0.00 (500) 0.01 (500) |\\n| AMAZON-MR  | 14058-30467 | TO TO TO TO TO TO | inf (-) TO TO TO TO |\\n| AMAZON-MT  | 979-12320 | TO TO TO TO TO TO TO TO | 283567086.67 (-) |\\n| AMAZON-MW  | 3079-47504 | TO TO TO TO TO TO TO TO | 706635840.75 (-) |\\n\\nIn the following, we describe some additional details on the guided tree search approach introduced by Li et al. (2018). A textual description can be found in Section 2, and a pseudocode description in Algorithm 1; for a visualization, we refer to Figure 1 of Li et al. (2018). The pseudocode makes use of a function $\\\\text{genprobmaps}: G \\\\rightarrow [0, 1]|V|\\\\times m$, that can take arbitrary unweighted graphs $G \\\\in \\\\mathcal{G}$ as input. In the default case, this function calls the trained GCN, which outputs its assignments from vertices to probabilities, i.e., $\\\\text{GCN}(G) \\\\in [0, 1]|V|\\\\times m$. We obtain the final solution in a non-pseudocode implementation \u2013 like DGL-\\\\textsc{TreeSearch} \u2013 for example by choosing the largest independent set that is yielded.\\n\\nFurthermore, there are several modifications (flags) discussed in Section 3.1. In the following, we briefly discuss how these flags impact the tree search algorithm.\\n\\n- **Reduction.** Reduction or graph kernelization is an addition that uses algorithmic techniques to find vertices which (provably) have to be in the independent set. After determining the residual graph, before generating the probability maps, we optionally can determine whether some vertices can be labeled due to the reduction rules, and then continue to determine the probability maps with an even smaller residual graph. Lamm et al. (2017) and Hespe et al. (2019) provide reduction rules for the unweighted case, which both INTEL-\\\\textsc{TreeSearch} and DGL-\\\\textsc{TreeSearch} access using a Python-C++ interface. Furthermore, for the MAXIMUM WEIGHTED INDEPENDENT SET problem, DGL-\\\\textsc{TreeSearch} uses the recently proposed reduction rules by Lamm et al. (2019).\\n\\n- **Local Search.** A local search is an addition based on small mutations which try to further improve a full solution before it is yielded. It can be understood as fine-tuning a solution. The INTEL-\\\\textsc{TreeSearch} and DGL-\\\\textsc{TreeSearch} use the local search implementation by Lamm et al. (2017) and Hespe et al. (2019), and for the weighted case, DGL-\\\\textsc{TreeSearch} uses the local search by Lamm et al. (2019).\\n\\n- **Multithreading.** To find the MIS faster, one can use multiple threads that search for independent sets. The parallelization idea is very simple, each thread just follows the same procedure as stated in Algorithm 1. In the INTEL-\\\\textsc{TreeSearch}, the threads share the queue $P$, making push and pop operations a critical section. Because we want to avoid this critical section, and due to issues with shared state in Python multiprocessing,\"}"}
{"id": "mk0HzdqY7i1", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 1: Guided Treesearch Algorithm to find MIS (adjusted from Li et al. (2018)). For a solution \\\\( S \\\\) and vertex \\\\( u \\\\in V \\\\), we denote by \\\\( S_u \\\\) the current status of \\\\( u \\\\) (included, excluded, unlabeled). For a more detailed description, we refer to Appendix B.\\n\\nInput: Graph \\\\( G = (V, E) \\\\), Function \\\\( \\\\text{gen probmaps} : G \\\\rightarrow [0, 1]^{V \\\\times m} \\\\).\\n\\nOutput: Independent sets \\\\( S_i \\\\subseteq V \\\\).\\n\\n1. \\\\( P \\\\leftarrow \\\\{(\\\\perp, \\\\perp, \\\\ldots, \\\\perp) \\\\in \\\\{0, 1, \\\\perp\\\\}^V \\\\} \\\\);\\n2. While \\\\( P \\\\) is not empty do\\n3. \\\\( S \\\\leftarrow \\\\text{random pop}(P) \\\\);\\n4. \\\\( V_{\\\\text{residual}} \\\\leftarrow \\\\{u \\\\in V | S_u = \\\\perp\\\\} \\\\);\\n5. \\\\( G_{\\\\text{residual}} \\\\leftarrow (V_{\\\\text{residual}}, \\\\{(u, v) \\\\in E | u, v \\\\in V_{\\\\text{residual}}\\\\}) \\\\);\\n6. For \\\\( M \\\\in \\\\text{gen probmaps}(G_{\\\\text{residual}}) \\\\) do\\n7. \\\\( S' \\\\leftarrow S \\\\);\\n8. For \\\\( u \\\\in V_{\\\\text{residual}} \\\\) sorted by descending probability in \\\\( M \\\\) do\\n9. If \\\\( S'_u = 0 \\\\) then break;\\n10. \\\\( S'_u \\\\leftarrow 1 \\\\);\\n11. For \\\\( v \\\\in V_{\\\\text{residual}} \\\\) adjacent to \\\\( u \\\\) do\\n12. \\\\( S'_v \\\\leftarrow 0 \\\\);\\n13. If \\\\( \\\\forall u \\\\in V : S'_u \\\\neq \\\\perp \\\\) then yield \\\\( S' \\\\);\\n14. Else append \\\\( S' \\\\) to \\\\( P \\\\);\\n\\nDGL-TREESEARCH, we give each thread its own queue, and first initialize enough partial solutions, such that each thread has one partial solution to start on.\\n\\n\u2022 Queue Pruning. As we see in Section 3.1, on difficult datasets like SATLIB, the tree search almost cannot find any solution. Furthermore, in their experiments, Ahn et al. (2020) state that the INTEL-TREESEARCH runs out of memory, something that we did not observe for medium-sized graphs. Queue pruning is a technique used to tackle these two issues. Unfortunately, we could not obtain the information on how the queue pruning approach by Ahn et al. (2020) is implemented via private communication, hence we propose our own solution. We set a maximum number of elements on our queue \\\\( P \\\\), and after appending a new partial solution to the queue, we remove the oldest elements (at position 0) from the queue, until the queue is small enough again. The intuition is that we find more solutions faster, because there is a higher chance to pop an almost labeled (more recent) solution from the queue, and we also limit the memory used. Queue pruning was not proposed in the original paper by Li et al. (2018).\\n\\n\u2022 Weighted Queue Pop. By default, the random pop used in Algorithm 1 chooses an element from the queue uniformly at random. Weighted Queue Pop, on the other hand, shifts the probability of each element to be chosen according to how many unlabeled vertices are left in it, favoring fewer unlabeled vertices. Similar to queue pruning, the intuition is to find fully labeled solutions faster while keeping some randomness in the popping behavior. It can be freely combined with queue pruning or used on its own. To the best of our knowledge, no other paper has proposed this addition to the tree search algorithm yet.\\n\\n\u2022 Random Values as Probability Maps. This flag changes \\\\( \\\\text{gen probmaps} \\\\) to a random generator, effectively replacing the GCN output with probability values chosen uniformly at random.\\n\\nWe note that the original implementation by Li et al. (2018) does not exactly follow our description and Algorithm 1. We note differences between their paper and the published code in the next section.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we note some important facts to keep in mind when dealing with the original tree search implementation, next to the rather difficult understandability and maintainability of the code.\\n\\nFirst, for difficult instances, with reduction and local search both disabled, the search queue appears to grow indefinitely without ever finding a single solution. To circumvent this effect and to be able to find solutions, it might be necessary to limit the search queue to a fixed maximum size, as observed by Ahn et al. (2020). They furthermore stress the importance of pruning to limit memory usage. We discuss our approach to queue pruning in Appendix B.\\n\\nSecond, in the paper, it is stated that the GCN is trained for 200 epochs. However, in the implementation, one epoch iterates over just 2000 randomly chosen samples of the 38000 samples in the training set. This is not what you would expect given the term \u201cepoch\u201d. Furthermore, the original code has some hardcoded values (e.g., sometimes it expects the number of input graphs to be flexible, and sometimes it is hardcoded within the same file). Our patch provided in the benchmark suite fixes these issues.\\n\\nThird, the multi-threaded variant of the algorithm uses just one randomly chosen probability map of the GCN outputs instead of all. This makes this variant\u2019s performance in terms of search steps per second, appear to scale superlinearly, and furthermore is not documented in the paper, and needs to be kept in mind for evaluation.\\n\\nD. DETAILS ON USING GUROBI AS A SOLVER\\n\\nGurobi is a general purpose, off-the-shelf, mathematical optimization tool. Hence, many parameters can be tuned, and the performance can very on how the problem to be solved is inputted into the solver. In the following two subsections, we investigate the impact of these two dimensions.\\n\\nD.1 Gurobi Tuning\\n\\nSimilar to training machine learning models, we can try to optimize Gurobi\u2019s performance for the problem at hand. This is called hyperparameter tuning or algorithm configuration, and often done using heuristic searches, e.g., by evolutionary algorithms. One well known optimizer for this is SMAC (Lindauer & Hutter, 2018); however, in this subsection, we use grbtune, as it is the native tool supported by Gurobi for parameter tuning.\\n\\nOur methodology is as follows. We generate a Gurobi configuration based on 10 instances of the VC-BM dataset. We choose this data set because for most other datasets like SATLIB, grbtune states that it is not able to improve over the default parameters. We note that grbtune decides when it is done, and we do not impose a time limit on the tuning process. The resulting found parameters are Heuristics = 0.001, PumpPasses = 0, and ZeroObjNodes = 20000000. We then run Gurobi both with the default configuration and the tuned configuration on various data sets, and split the VC-BM data set into the training and test sets.\\n\\nThe results can be seen in Table 6. We find that tuning does not improve the results, and even on the training set leads to worse performance, although the optimization was performed on exactly those instances. Only for the DIMACS data set, the tuned Gurobi finds the solution faster than the default Gurobi configuration. As Gurobi states, \u201cThe bottom line is that automated performance tuning is meant to give suggestions for parameters that could produce consistent, reliable improvements on your models. It is not meant to be a replacement for efficient modeling or careful performance testing.\u201d\\n\\nOne possible explanation might be that grbtune might be more effective on more complex linear programs. Additionally, on most data sets, it even states it cannot improve the default parameters. Our\"}"}
{"id": "mk0HzdqY7i1", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Run times results of the optimization tool Gurobi with default and tuned parameters (c.f. Appendix D.1) For the explanation of the various configuration flags, we refer to the caption of Table 2. Time limits are set equally to Table 2. Gurobi employs up to 8 threads, as needed. We mark the configuration/solver that has the best average MIS in bold.\\n\\n|                | Graph Nodes | ER | 700-800 | 37.79 (-) | 36.61 (-) | 30.01 (100) | 30.02 (100) |\\n|----------------|-------------|----|---------|-----------|-----------|-------------|-------------|\\n|                | ER          |    |         |           |           |             |             |\\n|                | HRG         |    |         |           |           |             |             |\\n|                | SATLIB      |    |         |           |           |             |             |\\n|                | VC-BM (Train)|   |         |           |           |             |             |\\n|                | VC-BM (Test)|   |         |           |           |             |             |\\n|                | DIMACS      |    |         |           |           |             |             |\\n|                | PPI         |    |         |           |           |             |             |\\n\\nExperiments show that at least for the linear MIS program, the default configuration of a commercial solver like Gurobi are sufficient. This may differ for other problems and hyperparameter tuning should always be considered, but we do not find any benefit on our data sets.\\n\\nD.2 Alternative MIS formulation\\n\\nThe configuration of the solver is one way we can impact performance. Another way is reformulating the mathematical optimization task into something that the solver can solve more efficiently. Until now, we have used a linear formulation of the MWIS problem, i.e.,\\n\\n\\\\[\\n\\\\arg \\\\max_{S \\\\in \\\\text{IS}(G)} P_u \\\\in S w_u.\\n\\\\]\\n\\nLiterature has discussed different formulations of the MIS problem (Butenko, 2003). We want to see whether using a different program makes a difference on our benchmark datasets. To this end, we use a quadratic formulation of the MIS problem (Pardalos & Rodgers, 1992). Following the notation of Butenko (2003), let \\\\( G \\\\) be a graph with \\\\( n \\\\) vertices, \\\\( A_G \\\\) be its adjacency matrix, and \\\\( J \\\\) the \\\\( n \\\\times n \\\\) identity matrix. Let \\\\( A = J - A_G \\\\).\\n\\nThen, we can calculate the MIS as\\n\\n\\\\[\\n\\\\arg \\\\max_{x \\\\in \\\\{0, 1\\\\}^n} x^T A x,\\n\\\\]\\n\\nwhich is a quadratic program instead of a linear one, that however might be easier to solve in practice. To understand the impact of this formulation, we run Gurobi with this quadratic program instead of the linear one again on our data sets. The results can be seen in Table 7. We find that, with the exception of the DIMACS data set, the linear formulation always performs equally or better, with both respect to solution size and run time. On DIMACS, the quadratic formulation performs marginally better (74.35 average MIS vs 74.62 average MIS), but also requires more time (202 seconds vs 242 seconds). On all other graphs, especially the hard benchmark instances, the linear formulation is faster, for example for VC-BM, where the linear program requires 269 seconds, and the quadratic program 300 seconds.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 7: Results of the modern MIS solver KA\\\\textsc{MIS}, the reinforcement-learning based LE\\\\textsc{ARNING} \\\\textsc{W}\\\\textsc{Hat}, the tree search algorithms in their default and full configuration, in comparison to GUROBI with the MIS as a linear program (default) and quadratic program (quadratic).\\n\\nFor the explanation of the various configuration flags, we refer to the caption of Table 2. All multithreaded experiments in this table use 8 threads, and all threads share a single GPU. Time limits are set equally to Table 2. We note that KA\\\\textsc{MIS} and LE\\\\textsc{ARNING} \\\\textsc{W}\\\\textsc{Hat} always run single-threadedly, while GUROBI employs up to 8 threads, as needed. For LE\\\\textsc{ARNING} \\\\textsc{W}\\\\textsc{Hat}, the random graphs are executed with 32 iterations per episode, and all other graphs with 128 iterations per episode (c.f. Ahn et al. (2020)).\\n\\nWe mark the configuration/solver that has the best average MIS in bold, and grey out configurations for which solutions were found for less than 20% of all graphs.\\n\\n| Intel DGL | LwD | KA\\\\textsc{MIS} | GUROBI |\\n|-----------|-----|----------------|---------|\\n| Graph Nodes | d r+ls+mt | d default | default |\\n| ER 50-100 | 20.58 (0.98) | 20.88 (1.00) | 19.88 (0.95) |\\n| 700-800 | 20.83 (0.99) | 20.36 (0.97) | 20.83 (1.00) |\\n| 122 | 5.39 (500) | 3.53 (500) | 0.41 (500) |\\n| BA 50-100 | 42.42 (0.99) | 42.43 (1.00) | 42.43 (1.00) |\\n| 700-800 | 420.89 (0.97) | 432.58 (1.00) | 389.65 (0.90) |\\n| 3.09 (18) | 5.31 (100) | 16.50 (80) | 0.69 (100) |\\n| HK 50-100 | 42.32 (0.99) | 42.33 (1.00) | 42.33 (1.00) |\\n| 700-800 | 417.89 (0.98) | 429.81 (1.00) | 390.64 (0.90) |\\n| 4.23 (19) | 5.26 (100) | 19.66 (83) | 0.42 (100) |\\n| WS 50-100 | 38.69 (0.99) | 38.70 (1.00) | 37.91 (0.97) |\\n| 700-800 | - (-) | 386.90 (1.00) | - (-) |\\n| 5.49 (100) | - | 0.39 (100) | 0.28 (100) |\\n| HRG 50-100 | 33.62 (0.99) | 33.72 (1.00) | 32.80 (0.97) |\\n| 700-800 | - (-) | 304.21 (1.00) | - (-) |\\n| 5.51 (100) | - | 17.81 (5) | 0.44 (100) |\\n| SATLIB | 1209-1347 | - (-) | 426.51 (0.99) |\\n| 7.99 (500) | - | 18.48 (2) | 13.12 (500) |\\n| VC-BM | 450-1534 | 39.85 (-) | 45.10 (-) |\\n| 149.80 (40) | 51.64 (40) | 139.55 (40) | 145.24 (40) |\\n| 9.15 (122) | 2.14 (122) | 2.61 (122) | 0.17 (122) |\\n| DIMACS | 125-4000 | 37.14 (-) | 76.86 (-) |\\n| 79.30 (37) | 21.26 (37) | 87.53 (37) | 45.64 (26) |\\n| 4.13 (37) | 120.88 (37) | 202.18 (37) | 242.02 (37) |\\n| as-Caida | 8020-26475 | - (-) | 19387.47 (0.99) |\\n| 14.49 (122) | - | 15.63 (122) | 3.65 (122) |\\n| PPI | 591-3480 | - (-) | 1002.71 (0.99) |\\n| 8.73 (24) | 23.56 (1) | 3.70 (24) | 1.67 (24) |\\n| 5.86 (24) | 8.16 (24) | 29.02 (24) | 290.02 (24) |\\n| REDDIT-B | 46-2283 | 146.06 (0.99) | 287.54 (1.00) |\\n| 5.94 (200) | 5.37 (500) | 11.81 (406) | 0.26 (500) |\\n| REDDIT-5K | 55-3648 | 194.27 (0.99) | 586.31 (0.99) |\\n| 7.97 (37) | 5.35 (500) | 15.36 (152) | 0.48 (500) |\\n| REDDIT-12K | 41-897 | 28.61 (0.99) | 170.20 (1.00) |\\n| 3.99 (349) | 5.20 (500) | 9.53 (467) | 0.17 (500) |\\n| wiki-RfA | 11380 | - (-) | 8111.00 (1.00) |\\n| - 13.08 | - | 19.95 | 3.65 |\\n| wiki-Vote | 7115 | - (-) | 4866.00 (1.00) |\\n| - 8.56 | - | 11.20 | 3.94 |\\n| PubMed | 19717 | - (-) | 15912.00 (1.00) |\\n| - 12.91 | - | 23.34 | 3.34 |\\n| Cora | 2708 | - (-) | 1451.00 (1.00) |\\n| - 5.63 | - | 13.63 | 2.74 |\\n| Citeseer | 3264 | - (-) | 1808.00 (1.00) |\\n| - 5.51 | - | 14.62 | 3.38 |\\n| bitcoin-alpha | 3783 | - (-) | 2718.00 (1.00) |\\n| - 6.10 | - | 11.41 | 2.37 |\\n| bitcoin-otc | 5881 | - (-) | 4346.00 (0.99) |\\n| - 8.56 | - | 11.20 | 3.94 |\\n| ego-facebook | 4039 | - (-) | 1046.00 (1.00) |\\n| - 5.63 | - | 13.63 | 2.74 |\\n| roadnet-berlin | 6120 | - (-) | 29843.00 (0.99) |\\n| - 5.51 | - | 14.62 | 3.38 |\"}"}
{"id": "mk0HzdqY7i1", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we give some details on the datasets, groups of datasets, and random graphs models used in this paper. For all datasets, we treat all graphs as undirected. The data generation module of our benchmarking suite integrates the download/generation and conversion of these graphs. We delete all self-loops, if there are any, because the solvers deal with self-loops differently (for example, with silent failures, errors, or just ignoring the vertex).\\n\\nErd\u0151s-R\u00e9nyi. This well-known random graph model by Erd\u0151s & R\u00e9nyi (1960) connects each pair of vertices with probability $p$. We use $p = 0.15$ and for testing, generate 500 graphs with 50 to 100 vertices and 100 graphs with 700 to 800 vertices.\\n\\nBarab\u00e1si-Albert. This random graph model by Albert & Barab\u00e1si (2002) iteratively adds nodes, connecting them to $m$ already existing nodes. We use $m = 2$ and for testing, generate 500 graphs with 50 to 100 vertices and 100 graphs with 700 to 800 vertices.\\n\\nHolme-Kim. A random graph model by Holme & Kim (2002) similar to the BA-model, with an extra step for each randomly created edge that creates a triangle with probability $p$. We use $m = 2$ and $p = 0.05$ and for testing, generate 500 graphs with 50 to 100 vertices and 100 graphs with 700 to 800 vertices. For the large-scale experiments, we test on one graph per fixed amount of vertices, c.f. Table 4.\\n\\nWatts-Strogatz. A random graph model by Watts & Strogatz (1998) that starts with a well-structured ring-lattice with mean degree $k$ and in the following step replaces each edge with probability $p$ with another edge sampled uniformly at random. This way it tries to keep \u201csmall-world properties\u201d while maintaining a random structure similar to Erd\u0151s-R\u00e9nyi graphs. We use $k = 2$ and $p = 0.15$.\\n\\nFor the large-scale experiments, we test on one graph per fixed amount of vertices, c.f. Table 4.\\n\\nHyperbolic Random Graph. A random graph model by Krioukov et al. (2010), which generates graphs by randomly putting nodes in a disk in the hyperbolic plane, and connecting them if their (hyperbolic) distance is below a certain threshold. Recent works have it described to be the best model for modeling real-world networks, due to their heterogeneity and interdependency (Friedrich, 2019). As generation parameters, we use $\\\\alpha = 0.75$, $T = 0.1$, $\\\\text{deg} = 10$ and for testing, generate 500 graphs with 50 to 100 vertices and 100 graphs with 700 to 800 vertices. For the large-scale experiments, we test on one graph per fixed amount of vertices, c.f. Table 4.\\n\\nSATLIB. This is a well-known set of SAT instances in CNF commonly used as a benchmark for SAT solvers (Hoos & Stutzle, 2000). A SAT instance can easily be reduced to a graph, which has a MIS as large as the number of clauses, should the SAT instance be satisfiable. In short, for each clause a clique is created, each node of which stands for a variable or its negation, e.g., $x$ or $\\\\neg x$. Afterwards, for each variable $x$, all its nodes are connected to nodes referring to its negation $\\\\neg x$.\\n\\nWe use the \u201cRandom-3-SAT Instances with Controlled Backbone Size\u201d dataset, which consists of 40,000 instances, of which we train on 39,500 and test on 500. Each instance has between 403 to 449 clauses.\\n\\nPPI. The PPI dataset, introduced by Hamilton et al. (2017), contains of 24 graphs whose nodes describe proteins and edges describe interactions between them. They contain 591 to 3,480 nodes. We use the data set provided by DGL, as it provides a more easily understandable separation between the graphs than the original source by GraphSAGE.\\n\\nREDDIT. The REDDIT datasets, introduced by Yanardag & Vishwanathan (2015), contain graphs constructed from online discussion threads on Reddit. Vertices represent users and edges represent at least one response by one of the users to the other. The difference between REDDIT-BINARY ,\"}"}
{"id": "mk0HzdqY7i1", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"REDDIT-MULTI-5K, and REDDIT-MULTI-12K is how many subreddits have been crawled, and whether the classification task that is usually associated with these datasets is binary or multi-class classification. We obtain the data from TU Dortmund's data set collection.\\n\\nAs-Caida. The As-Caida dataset of autonomous systems, introduced by Leskovec et al. (2005), consists of 122 graphs derived from a set of RouteViews BGP table snapshots. They contain 8,020 to 26,475 nodes. We obtain the data from Stanford's SNAP repository.\\n\\nCitation. The Citation dataset consists of the three citation network graphs Cora (McCallum et al., 2000), Citeseer (Giles et al., 1998) and PubMed (Sen et al., 2008). We obtain all data from NetworkRepository (Rossi & Ahmed, 2015).\\n\\nDBLP-Coauthorship. This dataset contains the com-DBLP (Yang & Leskovec, 2013) graph. Vertices represent authors and an edge exists if two authors have published at least one paper together.\\n\\nRoad Networks. The Road Networks dataset contains two road networks of different sizes. The network roadNet-PA obtained from SNAP represents the state of Pennsylvania (Leskovec et al., 2009). The other network maps the city of Berlin, Germany, and is extracted from OpenStreetMap (OpenStreetMap Contributors, 2017) using OSMnx (Boeing, 2017).\\n\\nSocial Networks. The Social Networks dataset contains 6 social network graphs we gathered. Vertices represent users and edges represent some kind of relationship between them. The exact kind of relationship depends on the graph. The ego-Facebook and ego-Gplus graphs represent \\\"friendships\\\" between users (Leskovec & Mcauley, 2012). The bitcoin-otc and bitcoin-alpha graphs represent Bitcoin's web-of-trust network (Kumar et al., 2016; 2018). The wiki-Vote and wiki-RfA graphs are derived from interactions in the governing process of Wikipedia (Leskovec et al., 2010; West et al., 2014).\\n\\nVC-Benchmark (VC-BM). A dataset consisting of 40 graphs of different sizes from 450 to 1,534 nodes, on which finding the maximum independent set is synthetically made hard (Xu et al., 2007). Li et al. (2018) call this dataset BUAA-MC, and sometimes it us also called BHOSLIB. As the original download is not available anymore, we use a GitHub mirror.\\n\\nDIMACS. Graphs used for the evaluation of the second DIMACS implementation challenge in 1992, on which it is particular hard to solve the MIS problem. The dataset consists of 37 graphs from 125 to 4,000 nodes. We use the complementary benchmark, as the original graphs were build for the CLIQUE problem.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The Amazon data sets are several vehicle routing data sets provided for MWIS research (Dong et al., 2021). We test the smaller \\\\( MT \\\\) (6 graphs, 979-12 320 nodes), \\\\( MR \\\\) (5 graphs, 14 058-30 467 nodes), and \\\\( MW \\\\) (8 graphs, 3 079-47 504 nodes) data sets.\\n\\nhttps://registry.opendata.aws/mwis-vr-instances/\"}"}
{"id": "mk0HzdqY7i1", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mk0HzdqY7i1", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"weighted queue pop (\\\\(+r\\\\)) where any solution was found are given. The average values refer only to the graphs within a dataset where we were able to pre-calculate the provably optimal MIS using G\\\\(_\\\\text{HRG}\\\\) (limit of 15 seconds; for the SATLIB, as-caida, PPI, REDDIT, Citeseer, Cora, and ego-facebook and all threads share a single GPU. For the random graphs of size 50-100, all solvers have a time output in a multithreaded setup (\\\\(+mt\\\\)) configuration space further. After analyzing the default (\\\\(+mt\\\\) and last test reduction and local search in a multithreaded setup (the default setting (previous column; columns that do not start with a plus use +r +ls +rand +qp +wp for which a solution was found. Columns that start with a plus (\\\\(+\\\\)) for which a solution was found. Average time in seconds until the best solution was found, and, in brackets, the number of graphs output in a multithreaded setup (\\\\(+mt\\\\)). We also test a combination of reduction, queue pruning, and just the stated flags. For Intel, we start with Ukraine (\\\\(UROBI\\\\)). In the second row, the 50-10033.62 (0.99) 19387.47 (0.99) 19387.47 (0.99) 19387.47 (0.99) - (-) 19388.03 (1.00) 4352.00 (1.00) 4352.00 (1.00) 4352.00 (1.00) 4352.00 (1.00) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-) - (-"}
{"id": "mk0HzdqY7i1", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 3: Results of the modern MIS solver\\n\\n| Solver | Graph Nodes | ER 50-100 | BA 50-100 | HK 50-100 | WS 50-100 | DIMACS 125-4000 | PPI 591-3480 | REddit-B 46-2283 | REddit-5K 55-3648 | REddit-12K 41-8971 | wiki-RfA 11380 | wiki-Vote 7115 | Pubmed 19717 | Cora 2708 | Citeseer 3264 | bitcoin-alpha 3783 | bitcoin-otc 5881 | ego-facebook | roadnet-berlin 61204 |\\n|--------|-------------|-----------|-----------|-----------|-----------|-----------------|--------------|-----------------|-------------------|-------------------|---------------|--------------|----------------|-------|----------|----------------|----------------|-------------|-----------------|----------------------|\\n| KaMIS  | 20.58 (0.98) | 20.83 (1.00) | 20.36 (0.97) | 8.64 (0.41) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| Intel DGL | 20.83 (1.00) | 20.83 (1.00) | 20.83 (1.00) | 8.64 (0.41) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| LwD     | 20.83 (0.99) | 20.83 (1.00) | 20.83 (1.00) | 8.64 (0.41) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n| Gurobi  | 20.36 (0.97) | 8.64 (0.41) |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\n\\nAll multithreaded experiments in this table use 8 threads, and all threads share a single GPU. Time limits are set equally to Table 2. We note that KaMIS and LwD always run single-threadedly, while Gurobi employs up to 8 threads, as needed. For LwD, we test the default configuration (d) and replace the output of the GNN with a random tensor (rand); the random graphs are executed with 32 iterations per episode, and all other graphs with 128 iterations per episode (c.f. Ahn et al. (2020)).\\n\\nWe mark the configuration/solver that has the best average MIS in bold, and grey out configurations for which solutions were found for less than 20% of all graphs.\"}"}
{"id": "mk0HzdqY7i1", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"Table 4: Results of the modern MIS solver KA\\\\textsc{MIS}, the optimization tool G\\\\textsc{urobi}, the reinforcement-learning based L\\\\textsc{earningWhac\\\\textsc{k}er}, and the tree search algorithms in their default and full configuration, on huge random graphs and huge real world networks. We do not test huge ER graphs due to the time complexity of generating them, and do not test BA graphs as they are similar to HK graphs. For the explanation of the various configuration flags, we refer to the caption of Table 2. All multithreaded experiments in this table use 8 threads, and all threads share a single GPU. The time limit for all graphs was set to 3 hours. For L\\\\textsc{wd}, the algorithm is executed with with 128 iterations per episode (c.f. Ahn et al. (2020)). We mark the configuration that has the best average MIS in bold. Configurations that consumed too much VRAM or DRAM are noted as out of memory (OOM).\\n\\n|                | Intel | DGL  | LwD | KaMIS | Gurobi |\\n|----------------|-------|------|-----|-------|--------|\\n| **HK**         |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 500 000        |       |      |     |       |        |\\n| MIS size       |       |      |     |       |        |\\n|                | 289486.00 (-) | 289486.00 (-) | 289486.00 (-) | 289486.00 (-) | 289486.00 (-) |\\n|                | 242.91 | 177.12 | 145.40 | 0.27 | 26.86  |\\n| 2 000 000      |       |      |     |       |        |\\n| MIS size       | 1157643.00 (-) | OOM | 1157643.00 (-) | 1157643.00 (-) | 1157643.00 (-) |\\n|                | 1064.53 | 1.15 | 154.14 | 0.22 | 5.41   |\\n| 5 000 000      |       |      |     |       |        |\\n| MIS size       | OOM | OOM | 2892242.00 (-) | 2892242.00 (-) | 2892242.00 (-) |\\n|                | 1207.98 | 3.80 | 446.81 | 0.95 | 28.48  |\\n| **WS**         |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 500 000        |       |      |     |       |        |\\n| MIS size       | 258887.00 (-) | 258887.00 (-) | 258887.00 (-) | 258887.00 (-) | 258887.00 (-) |\\n|                | 219.57 | 171.97 | 61.28 | 0.22 | 5.41   |\\n| 2 000 000      |       |      |     |       |        |\\n| MIS size       | 1035715.00 (-) | 1035715.00 (-) | OOM | 1035715.00 (-) | 1035715.00 (-) |\\n|                | 923.82 | 740.14 | 0.95 | 28.48 |        |\\n| 5 000 000      |       |      |     |       |        |\\n| MIS size       | OOM | OOM | 2589519.00 (-) | 2589519.00 (-) | 2589519.00 (-) |\\n|                | 1128.76 | 2.82 | 76.26 | 28.48 |        |\\n| **HRG**        |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 500 000        |       |      |     |       |        |\\n| MIS size       | 210950.00 (-) | 210950.00 (-) | 210930.00 (-) | 210950.00 (-) | 210949.00 (-) |\\n|                | 374.53 | 216.09 | 834.99 | 0.78 | 47.20  |\\n| 2 000 000      |       |      |     |       |        |\\n| MIS size       | 843618.00 (-) | OOM | 843618.00 (-) | 843618.00 (-) | 843618.00 (-) |\\n|                | 1114.92 | 3.51 | 374.15 |        |        |\\n| 5 000 000      |       |      |     |       |        |\\n| MIS size       | OOM | OOM | 2110401.00 (-) | 2110401.00 (-) | 2110400.00 (-) |\\n|                | 1866.42 | 8.62 | 897.20 |        |        |\\n| **DBLP**       |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 317 080        |       |      |     |       |        |\\n| MIS size       | 152131.00 (1.00) | 152131.00 (1.00) | 152131.00 (1.00) | 152131.00 (1.00) | 152131.00 (1.00) |\\n|                | 142.15 | 112.32 | 236.98 | 0.30 | 7.15   |\\n| **roadnet-pennsylvania** |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 1 088 092      |       |      |     |       |        |\\n| MIS size       | OOM | OOM | OOM | 533625.00 (-) | 533628.00 (-) |\\n|                | 17.49 | 3662.87 |        |        |        |\\n| **ego-gplus**  |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 107 614        |       |      |     |       |        |\\n| MIS size       | OOM | 56794.00 (-) | 57394.00 (-) | 57321.00 (-) | 57394.00 (-) |\\n|                | 399.20 | 275.58 | 115.76 | 10802.52 |        |\\n| **web-google** |       |      |     |       |        |\\n| Graph Nodes    |       |      |     |       |        |\\n| 875 713        |       |      |     |       |        |\\n| MIS size       | OOM | OOM | 529138.00 (1.00) | 528725.00 (0.99) | 529138.00 (1.00) |\\n|                | 663.18 | 822.14 | 10.67 | 83.30 |        |\"}"}
