{"id": "TBWA6PLJZQm", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"We can find that different rows of each matrix in Figure 5b are very similar, showing the synthetic class-dependent label noise with the same expected noise transition matrix. For a controlled comparison, we synthesize the class-dependent label noise with the same expected noise transition matrix as our human-level label noise and illustrate it in Figure 5b.\\n\\nIn this section, we quantitatively compare human noise and synthetic class-dependent noise through noisy class entailment and the Nearest-Neighbor (NN) noise clusterability if the noise is feature-independent and our verification method is valid.\\n\\nFollowing the clustering results in Section 4.2.1, we further statistically test whether human annotated label noise in CIFAR-10N is feature-dependent or not. For CIFAR-10N, the null hypothesis $H_0$ states that the noise transitions are feature-independent and the alternate hypothesis $H_1$ that the noise transitions are feature-dependent.\\n\\nDefinition 1 (Nearest-Neighbor) noise clusterability) We call the Nearest-Neighbor (NN) noise clusterability if the nearest-neighbor assumption holds. For a given label noise vector $x$, let $M(x, i, \u03bd)$ denote the set of instance indices from the feature $i$ in class $\u03bd$.\\n\\nWe first visualize the noise transitions for different features from a qualitative aspect. Taking CIFAR-10 as an example, each image in CIFAR-10 only appears once. Without additional assumptions, we will show the feature-dependency from both a qualitative aspect and a quantitative aspect.\\n\\nIn our visualization, we divide the representations of images from the same true class into clusters and adaptively find a suitable $k$ for each cluster. Denote by $I_{class i}$ the set of instance indices from the class $i$.\\n\\nThe transition probability $P(i, \u03bd | x)$ can be estimated by counting the frequency of each noisy class given noisy labels in each subset $I_{class i}$, where each element $x_n \\\\in I_{class i}$ is the instance index from the class $i$.\\n\\n$P(i, \u03bd | x_n) = \\\\frac{|\\\\{ j | x_j = \u03bd \\\\} \\\\cap I_{class i} |}{|I_{class i}|}$\\n\\nFor a more formal testing, we clearly observe that different transition vectors across different features belonging to the same true class to put up a more formal testing, we will show the feature-dependency from both a qualitative aspect and a quantitative aspect.\\n\\nThe equality for different features, we will show the feature-dependency from both a qualitative aspect and a quantitative aspect.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We reproduce several popular and state-of-the-art robust methods on synthetic noisy labels (using $d$-dimensional Gaussian noise) to work well in low noise regime. Besides, ELR (Liu et al., 2020) performs even slightly better when testing with real-world human noise than that on the synthetic class-dependent noise settings.\\n\\nTable 2: Comparison of test accuracies (%)\\n\\n| Method                   | CIFAR-10N | CIFAR-100N |\\n|--------------------------|-----------|------------|\\n| CE (Standard)            | 92.92     | 94.50      |\\n| Positive-LS (Lukasik et al., 2020) | 94.76     | 94.92      |\\n| Negative-LS (Wei et al., 2021) | 94.77     | 95.39      |\\n| VolMinNet (Li et al., 2021) | 93.99     | 93.35      |\\n| CORES                    | 95.06     | 95.25      |\\n| T-Revision (Xia et al., 2019) | 93.35     | 92.41      |\\n| Co-teaching+ (Yu et al., 2019) | 94.43     | 93.02      |\\n| Peer Loss (Liu & Guo, 2020) | 94.14      | 94.76      |\\n| ELR (Liu et al., 2020)   | 94.50     | 94.92      |\\n| ELR+ (Liu et al., 2020)  | 94.77     | 95.39      |\\n| Divide-Mix (Li et al., 2020) | 94.88     | 95.06      |\\n| PES (Semi) (Bai et al., 2021) | 94.77     | 95.39      |\\n\\nMore methods are included in the Appendix E as well as http://noisylabels.com. The class-dependent noise settings which follow exactly the same learning with real-world human noise than that on the synthetic noise is much easier to learn on CIFAR-10, especially when the noise level is high. The observations in Section 4.1, in Table 3 we highlight that for most selected methods, class-dependent related methods, etc.\\n\\n5.1 Performance comparisons on CIFAR-10N\\n\\nFor a fair comparison, we adopt ResNet-34 (He et al., 2016), the same training procedure and batch-size for all implemented methods. More experiment details are deferred to the Appendix E. In Table 2, note that both ELR+ (Liu et al., 2020) and Divide-Mix (Li et al., 2020) adopt two networks with different size for all implemented methods. The gap is less obvious for CIFAR-100. However, we also observe that Divide-Mix (Li et al., 2020) fails to work well in low noise regime. As contrast, we need to compare the whole data. Thus, the null hypothesis is rejected with the significance value $w.r.t$.\\n\\nHypothesis testing results show that $H_0$ is much greater than $H_1$. The above hypotheses are converted to:\\n\\n$H_0: d_{i,\\\\nu}^{(1)} \\\\neq d_{i,\\\\nu}^{(2)}$\\n\\nNote that the synthetic label noise illustrated in Figure 5b is supposed to be feature-independent, the transition vector from the same synthetic noise but different clustering result (caused by random augmentations each time. We choose the significance level, hypothesis $H_0$ is accepted. Similar conclusion can be made for the corresponding synthetic one.\\n\\nFrom Figure 5, one measure of the difference between human noise and synthetic noise is the distance between transition vectors $p(d_i^{(1)}, d_{i,\\\\nu}^{(1)})$.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"Table 3: Performance gap between human noise and class-dependent noise: test accuracy (trained on synthetic noise) - test accuracy (trained on human noise). Negative gaps are highlighted in red.\\n\\n| Method                        | CIFAR-10 Gap | CIFAR-100 Gap |\\n|-------------------------------|--------------|---------------|\\n| Aggregate Random              | 1.20         | 0.47          |\\n| rand1                         | -0.14        | -0.61         |\\n| rand2                         | 0.89         | 0.92          |\\n| rand3                         | 0.92         | 0.86          |\\n| Worst Noisy                   | 1.05         | 1.31          |\\n| CE (Standard)                 | 4.35         | 4.50          |\\n| Forward T (Patrini et al., 2017) | 4.30       | 4.82          |\\n| Co-teaching+ (Yu et al., 2019) | 1.90         | 1.05          |\\n| Peer Loss (Liu & Guo, 2020)   | 1.95         | 2.63          |\\n| ELR (Liu et al., 2020)        | 0.78         | 1.05          |\\n| F-Div (Wei & Liu, 2020)       | 0.72         | 1.64          |\\n| Divide-Mix (Li et al., 2020)  | 0.01         | 0.44          |\\n| Negative-LS (Wei et al., 2021)| 0.77         | 1.31          |\\n| JoCoR (Wei et al., 2020)      | 0.35         | 0.78          |\\n| CORES2 (Cheng et al., 2021)   | 1.49         | 1.69          |\\n| CAL (Zhu et al., 2021a)       | 0.25         | 0.44          |\\n\\nEMORIZATION EFFECTS\\n\\nWhen learning with noisy labels on CIFAR-10 and CIFAR-100 datasets, empirical observations (Arpit et al., 2017; Liu et al., 2020; Xia et al., 2020a; Zhang et al., 2021a) on synthetic noise settings suggest that deep neural networks firstly fit on samples with clean labels, then gradually over-fit and memorize samples with wrong/noisy labels (Xie et al., 2021). We next explore the memorization of clean and noisy labels on CIFAR-10N and CIFAR-100N.\\n\\nDefinition 2 (Memorized feature)\\n\\nIn a K-class classification task, given a trained classifier $f$, a feature $x$ and confidence threshold $\\\\eta$, $x$ is memorized by $f$ if $\\\\exists i \\\\in [K]$ s.t. $P(f(x) = i) > \\\\eta$.\\n\\nIn Figure 6, we train CE loss with a ResNet-34 (He et al., 2016) neural network on three noisy label sets of CIFAR-10N: aggre-label (left column), random-label1 (middle column) and worst-label (right column). While visualizing the memorization ($\\\\eta = 0.95$) on training samples, we split the train data into two parts: images with clean labels (the annotation matches the clean label) and wrong labels (the rest). We observe that:\\n\\n- Deep neural nets memorize features more easily when learning with real-world human annotations than synthetic ones.\\n- This is attributed to the fact that, compared with synthetic label noise, human annotators are prone to providing wrong labels on more misleading/ambiguous images or complex patterns.\\n- Given the same noise level, learning with human noise labels is more challenging and deep neural nets over-fit on features of wrong annotations inevitably.\\n\\nCONCLUSIONS\\n\\nBuilding upon CIFAR datasets, we provide the weakly supervised learning community with two accessible and easy-to-use benchmarks: CIFAR-10N and CIFAR-100N. We introduce new observations from human annotations such as imbalanced annotations, the flipping of noisy labels among similar features, co-existing labels in CIFAR-100N, etc. From the perspective of noise transitions, we qualitatively show that human noise is indeed feature-dependent and differs substantially from synthetic class-dependent label noise using hypothesis testing. We empirically compare the robustness of a large quantity of popular methods when learning with CIFAR-10N, CIFAR-100N and synthetic noisy CIFAR datasets. We also consistently observe the large performance gap between human noise and synthetic noise, as well as the different memorization behavior on training samples.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACKNOWLEDGEMENT\\n\\nThis work is supported by a University of California, Santa Cruz startup fund, the National Science Foundation (NSF) under grant IIS-2007951 and IIS-2143895. TL was partially supported by Australian Research Council Projects DE-190101473 and DP-220102121.\\n\\nLICENSE\\n\\nThe released datasets CIFAR-N are publicly available at http://noisylabels.com, under the Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license. You are free to share and adapt, while under the terms of attribution and non-commercial use.\\n\\nOPEN COMPETITION\\n\\nMoving forward, we would like to invite researchers to openly compete using our CIFAR-N datasets to advance the field. Correspondingly, we will actively update our leaderboards. Featured competitions will include building better and more accurate models, estimating noise transition matrix, and detecting corrupted labels. This year (2022), we will host the inaugural public CIFAR-N competition with IJCAI-ECAI 2022. We will be actively maintaining http://noisylabels.com to disseminate future information.\\n\\nETHICS STATEMENT\\n\\nThis paper does not raise any ethics concerns. Our work contains the human subject study which involves only simple image annotation tasks in Amazon Mechanical Turk. The study has been carefully reviewed and received Institutional Review Board (IRB) exempt approval. We have followed the outlined protocol to perform the data collection. Our implemented human subject studies:\\n\\n\u2022 Do not have negative consequences, i.e., leaking the private information that would identify human annotators on Amazon Mechanical Turk.\\n\u2022 Do not misrepresent work that might be competing or related.\\n\u2022 Do not present misleading insights. Our work does not present applications that can lead to misuse.\\n\u2022 Do not introduce bias or fairness concerns, and research integrity issues.\\n\\nWe make the collected datasets (CIFAR-N) and the leaderboard publicly available at http://noisylabels.com. A starter code is provided in https://github.com/UCSC-REAL/cifar-10-100n.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ehsan Amid, Manfred KK Warmuth, Rohan Anil, and Tomer Koren. Robust bi-tempered logistic loss based on bregman divergences. In Advances in Neural Information Processing Systems, pp. 14987\u201314996, 2019.\\n\\nDevansh Arpit, Stanis\u0142aw Jastrz\u0119bski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look at memorization in deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 233\u2013242. JMLR. org, 2017.\\n\\nYingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang Niu, and Tongliang Liu. Understanding and improving early stopping for learning with noisy labels. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nDavid Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. Mixmatch: A holistic approach to semi-supervised learning. Advances in Neural Information Processing Systems, 32:5049\u20135059, 2019.\\n\\nLukas Bossard, Matthieu Guillaumin, and Luc Van Gool. Food-101\u2013mining discriminative components with random forests. In European conference on computer vision, pp. 446\u2013461. Springer, 2014.\\n\\nHao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. Learning with instance-dependent label noise: A sample sieve approach. In International Conference on Learning Representations, 2021.\\n\\nAritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss functions under label noise for deep neural networks. In Thirty-First AAAI Conference on Artificial Intelligence, 2017.\\n\\nBo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In Advances in neural information processing systems, pp. 8527\u20138537, 2018.\\n\\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016.\\n\\nDan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train deep networks on labels corrupted by severe noise. Advances in Neural Information Processing Systems, 31:10456\u201310465, 2018.\\n\\nGang Hua, Chengjiang Long, Ming Yang, and Yan Gao. Collaborative active learning of a kernel machine ensemble for recognition. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1209\u20131216, 2013.\\n\\nLu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In International Conference on Machine Learning, pp. 2304\u20132313. PMLR, 2018.\\n\\nLu Jiang, Di Huang, Mason Liu, and Weilong Yang. Beyond synthetic noise: Deep learning on controlled noisy labels. In International Conference on Machine Learning, pp. 4804\u20134815. PMLR, 2020.\\n\\nZhimeng Jiang, Kaixiong Zhou, Zirui Liu, Li Li, Rui Chen, Soo-Hyun Choi, and Xia Hu. An information fusion approach to learning with instance-dependent label noise. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=ecH2FKaARUp.\\n\\nJonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained categorization. In Proceedings of the IEEE international conference on computer vision workshops, pp. 554\u2013561, 2013.\\n\\nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun Yang. Cleannet: Transfer learning for scalable image classifier training with label noise. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5447\u20135456, 2018.\\n\\nJunnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HJgExaVtwr.\\n\\nWen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862, 2017.\\n\\nXuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end label-noise learning without anchor points. arXiv preprint arXiv:2102.02400, 2021.\\n\\nYuan-Hong Liao, Amlan Kar, and Sanja Fidler. Towards good practices for efficiently annotating large-scale image classification datasets. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4350\u20134359, 2021.\\n\\nSheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nSheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by over-parameterization. arXiv preprint arXiv:2202.14026, 2022.\\n\\nTongliang Liu and Dacheng Tao. Classification with noisy labels by importance reweighting. IEEE Transactions on pattern analysis and machine intelligence, 38(3):447\u2013461, 2015.\\n\\nYang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing noise rates. In International Conference on Machine Learning, pp. 6226\u20136236. PMLR, 2020.\\n\\nChengjiang Long and Gang Hua. Multi-class multi-annotator active learning with robust gaussian process for visual recognition. In Proceedings of the IEEE international conference on computer vision, pp. 2839\u20132847, 2015.\\n\\nMichal Lukasik, Srinadh Bhojanapalli, Aditya Menon, and Sanjiv Kumar. Does label smoothing mitigate label noise? In International Conference on Machine Learning, pp. 6448\u20136458. PMLR, 2020.\\n\\nNagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. In Advances in neural information processing systems, pp. 1196\u20131204, 2013.\\n\\nGiorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1944\u20131952, 2017.\\n\\nJoshua C Peterson, Ruairidh M Battleday, Thomas L Griffiths, and Olga Russakovsky. Human uncertainty makes classification more robust. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 9617\u20139626, 2019.\\n\\nHwanjun Song, Minseok Kim, and Jae-Gil Lee. Selfie: Refurbishing unclean samples for robust deep learning. In International Conference on Machine Learning, pp. 5907\u20135915, 2019.\\n\\nOriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.\\n\\nJialu Wang, Yang Liu, and Caleb Levy. Fair classification with group-dependent label noise. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 526\u2013536, 2021a.\\n\\nJingkang Wang, Hongyi Guo, Zhaowei Zhu, and Yang Liu. Policy learning using weak supervision. Advances in Neural Information Processing Systems, 34, 2021b.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "TBWA6PLJZQm", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The Appendix is organized as follows:\\n\\n\u2022 Section A: the details of dataset collection, processing and information of CIFAR-10N.\\n\u2022 Section B: the details of dataset collection, processing and information of CIFAR-100N.\\n\u2022 Section C: the comparison of label collection procedure among CIFAR, CIFAR-10H, and CIFAR-N.\\n\u2022 Section D: more detailed hypothesis testing results of CIFAR-N.\\n\u2022 Section E: additional experiment results and details.\\n\\nBefore proceeding to the appendix, we want to highlight our boarder impacts as follows.\\n\\nBroader Impacts\\nOur observations and contributions may have following potential broader impacts:\\n\\n\u2022 Crowd-sourcing of data annotations in computer vision: CIFAR-N may be further used for studying/proposing simulations of human annotations in crowd-sourcing, where the expenses of obtaining human annotations are often tremendous.\\n\u2022 A template for hypothesizing label noise patterns: Our hypothesis testing method of instance-dependent label noise may provide a quantitative tool for testing the simulated human labels.\\n\u2022 Benchmarking effort is important: Although learning from noisy labels has witnessed thriving developments, we often observed conflicting comparisons due to the randomness in the synthetic noisy labels. While there exist several datasets with real human noise, we view our contribution as complementary to existing ones, due to the elaborated reasons above. We believe benchmarking existing and population solutions is an important technical contribution to the community.\\n\u2022 Understanding real-world label noise: Our observations and the provided human-annotated labels help with understanding real-world label noise. Besides, our observations of the multi-label issues in CIFAR-100 impose a new label noise pattern that is largely neglected.\\n\u2022 Motivations for real-world label noise solutions: our observations, especially the memorizing effects of real-world label noise may provide the literature with motivations for addressing real-world label noise.\\n\\nREAL-WORLD NOISY LABEL BENCHMARK\\nIn this section, we introduce the preparation for data collection, collection procedure of CIFAR-10N, the workers' behaviors, and more detailed statistics of the obtained labels.\\n\\nA.1 CASE STUDIES BEFORE THE FORMAL COLLECTION\\nTo make the collection procedure reasonable and efficient, we firstly upload a few batches (500 images / batch) to test the behaviors of workers. Our observations show that the workers on image classification tasks may possibly incur following phenomenons:\\n\\n\u2022 Bots: with the appearance of bots, the accepted HIT may result in low-quality or meaningless responses if the bot is able to pick answers and maliciously/randomly submit them. Otherwise, the bot accepts the HIT but could not submit annotations. The accepted HIT may have to be re-assigned to another work after this HIT becomes expired which results in inefficient data collection.\\n\u2022 A large variance of the workers' contribution: empirical observations show that a large amount of workers contribute too few HITs, while some professional workers upload with much less time. Thus, there exists a large variance in the number of the worker's submitted HITs and the noise label pattern is substantially controlled by only a few workers.\\n\u2022 Incomplete submission: when there are more than one image per HIT, a worker would possibly neglect to click the label of one or more images, for example, the worker may only choose easy tasks to annotate and skip tough ones. The incomplete submission complexes the reassignment...\"}"}
{"id": "TBWA6PLJZQm", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"LEARNING WITH NOISY LABELS: A STUDY USING REAL-WORLD HUMAN ANNOTATIONS\\n\\nJiaheng Wei \u2217\u2020, Zhaowei Zhu \u2217\u2020, Hao Cheng \u2020, Tongliang Liu \u2021, Gang Niu \u00a7, and Yang Liu \u2020\\n\\nUniversity of California, Santa Cruz, \u2021TML Lab, University of Sydney, \u00a7RIKEN\\n\\n\u2020{jiahengwei,zwzhu,haocheng,yangliu}@ucsc.edu, \u2021tongliang.liu@sydney.edu.au, \u00a7gang.niu.ml@gmail.com\\n\\nABSTRACT\\n\\nExisting research on learning with noisy labels mainly focuses on synthetic label noise. The synthetic noise, though has clean structures which greatly enabled statistical analyses, often fails to model the real-world noise patterns. The recent literature has observed several efforts to offer real-world noisy datasets, e.g., Food-101N, WebVision, and Clothing1M. Yet the existing efforts suffer from two caveats: firstly, the lack of ground-truth verification makes it hard to theoretically study the property and treatment of real-world label noise. Secondly, these efforts are often of large scales, which may result in unfair comparisons of robust methods within reasonable and accessible computation power. To better understand real-world label noise, it is important to establish controllable, easy-to-use and moderate-sized real-world noisy datasets with both ground-truth and noisy labels. This work presents two new benchmark datasets, which we name as CIFAR-10N, CIFAR-100N (jointly we call them CIFAR-N), equipping the training datasets of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels we collected from Amazon Mechanical Turk. We quantitatively and qualitatively show that real-world noisy labels follow an instance-dependent pattern rather than the classically assumed and adopted ones (e.g., class-dependent label noise). We then initiate an effort to benchmarking a subset of the existing solutions using CIFAR-10N and CIFAR-100N. We further proceed to study the memorization of correct and wrong predictions, which further illustrates the difference between human noise and class-dependent synthetic noise. We show indeed the real-world noise patterns impose new and outstanding challenges as compared to synthetic label noise. These observations require us to rethink the treatment of noisy labels, and we hope the availability of these two datasets would facilitate the development and evaluation of future learning with noisy label solutions. The corresponding datasets and the leaderboard are available at http://noisylabels.com.\\n\\n1 INTRODUCTION\\n\\nImage classification task in deep learning requires assigning labels to specific images. Annotating labels for training use often requires tremendous expenses on the payment for hiring human annotators. The pervasive noisy labels from data annotation present significant challenges to training a quality machine learning model. The problem of dealing with label noise has been receiving increasing attentions. Typical approaches include unbiased estimators and weighted loss functions (Natarajan et al., 2013; Liu & Tao, 2015), loss correction (Patrini et al., 2017; Liu & Guo, 2020), sample selection aided (Jiang et al., 2018; Han et al., 2018; Yu et al., 2019), etc. The majority of existing solutions are often developed under stylish synthetic noise model, where the noise rates are either class-dependent or homogeneous across data instances. However, real-world supervision biases may come from humans (Peterson et al., 2019), sensors (Wang et al., 2021b), or models (Zhu et al., 2022), which are likely to be instance-dependent. Recent works on instance-dependent settings (Cheng et al., 2021; Jiang et al., 2022) also have some structural assumptions, e.g., the noise transition differs...\"}"}
{"id": "TBWA6PLJZQm", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: Summarized information of existed noisy-label benchmarks: the \\\"estimated\\\" noisy levels are obtained through a subset of the dataset with verified clean labels. \\\"Moderate-resolution\\\" means the max image width pixel is less than 250.\\n\\n| Dataset | Train/Test Size | Classes | Noise level |\\n|---------|-----------------|---------|-------------|\\n| Food-101 (Bossard et al., 2014) | 75.75K / 25.25K | 101 | N/A |\\n| Clothing1M (Xiao et al., 2015) | 1M in all | 14 | Estimated 38% |\\n| WebVision (Li et al., 2017) | \u22482.44M / 100K | 1000 | N/A |\\n| Food-101N (Lee et al., 2018) | 310K in all | 101 | Estimated 20% |\\n| Animal-10N (Song et al., 2019) | 50K / 5K | 10 | 8% |\\n| Red Mini-ImageNet (Jiang et al., 2020) | 50K / 5K | 100 | 0%-80% |\\n| Red Stanford Cars (Jiang et al., 2020) | 8K / 8K | 196 | 0%-80% |\\n| CIFAR10H (Peterson et al., 2019) | 50K / 10K | 10 | N/A |\\n| CIFAR-10N-aggregate (Ours) | 50K / 10K | 10 | 9.03% |\\n| CIFAR-10N-random (Ours) | 50K / 10K | 10 | \u224818% |\\n| CIFAR-10N-worse (Ours) | 50K / 10K | 10 | 40.21% |\\n| CIFAR-100N-coarse (Ours) | 50K / 10K | 20 | 25.60% |\\n| CIFAR-100N-fine (Ours) | 50K / 10K | 100 | 40.20% |\\n\\nIn different parts of features (Xia et al., 2020b) or sub-populations (Wang et al., 2021a; Zhu et al., 2021a). Although these statistical assumptions facilitate the derivation of theoretical solutions, it is unclear how the existing models captured the real-world noise scenario.\\n\\nTo empirically validate the robustness of proposed methods, synthetic noisy labels on CIFAR-10 and CIFAR-100 (Krizhevsky et al., 2009) are the most widely accepted benchmarks. The literature has also observed approaches to the simulation of human annotators in data labeling (Hua et al., 2013; Long & Hua, 2015; Liao et al., 2021), and real-world label noise benchmarks, including Food-101 (Bossard et al., 2014), Clothing-1M (Xiao et al., 2015), WebVision (Li et al., 2017), etc.\\n\\nWe summarize the above real-world noisy label datasets in Table 1. While a more detailed description and discussion of the existing datasets can be found in the related works, we want to highlight several outstanding issues in existing benchmarks and evaluations. As noted in Table 1, except for CIFAR related noisy label datasets, all other datasets suffer from at least one of the three caveats:\\n\\n\u2022 Complex task (High-resolution): when learning with large-scale and relative high-resolution data, the complex data pattern, various augmentation strategies (Xiao et al., 2015), the use of extra train or clean data (Bossard et al., 2014; Xiao et al., 2015; Lee et al., 2018), different computation power (for hyper-parameter tuning such as batch-size, learning rate, etc) jointly contribute to the model performance and then result in unfair comparison.\\n\\n\u2022 Missing clean labels: the lack of clean labels for verification in most existed noisy-label datasets makes the evaluation of robust methods intractable.\\n\\n\u2022 Interventions: human interventions in data generation (Jiang et al., 2020) and non-representative data collection process (Song et al., 2019) might disturb the original noisy label pattern.\\n\\nIn addition, despite synthetically labeled CIFAR datasets are popular and highly used benchmarks for evaluating the robustness of proposed methods, there exists no publicly available human annotated labels for CIFAR training datasets to perform either validation of existing methods or verification of popular noise models. A human-annotated version of CIFAR datasets would greatly facilitate the evaluations of existing and future solutions, due to the already standardized procedures for experimenting with CIFAR datasets. All above issues motivate us to revisit the problem of learning with noisy labels and establish accessible and easy-to-use, verifiable datasets that would be broadly usable to the research community. Our contributions can be summarized as follows:\\n\\n\u2022 We present two new benchmarks CIFAR-10N, CIFAR-100N which provide CIFAR-10 and CIFAR-100 with human annotated noisy labels. Jointly we call our datasets CIFAR-N. Our efforts built upon the CIFAR datasets and provide easily usable benchmark data for the weakly supervised learning community (Section 3). We expect to continue to maintain the datasets to facilitate future development of results.\\n\\n\u2022 We introduce new observations for the distribution of human annotated noisy labels on tiny images, i.e., imbalanced annotations, the flipping of noisy labels among similar features, co-existence of multiple clean labels for CIFAR-100 train images (which leads to a new pattern of label noise), etc. We further distinguish noisy labels in CIFAR-10N and CIFAR-100N with synthetic class-dependent label noise, from the aspect of noise transitions for different features qualitatively and quantitatively (via hypothesis testing) (Section 4).\"}"}
{"id": "TBWA6PLJZQm", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We empirically compare the robustness of a comprehensive list of popular methods when learning with CIFAR-10N, CIFAR-100N. We observe consistent performance gaps between human noise and synthetic noise. The different memorization behavior further distinguishes the human noise and synthetic noise (Section 5). The corresponding datasets and the leaderboard are publicly available at http://noisylabels.com.\\n\\n1.1 RELATED WORKS\\n\\nLearning from noisy labels\\n\\nEarlier approaches for learning from noisy labels mainly focus on loss adjustment techniques. To mitigate the impact of label noise, a line of approaches modify the loss of image samples by multiplying an estimated noise transition matrix (Patrini et al., 2017; Hendrycks et al., 2018; Xia et al., 2019; Yao et al., 2020), re-weight the loss to encourage deep neural nets to fit on correct labels (Liu & Tao, 2015), propose robust loss functions (Natarajan et al., 2013; Ghosh et al., 2017; Zhang & Sabuncu, 2018; Amid et al., 2019; Wang et al., 2019; Liu & Guo, 2020), or introduce a robust regularizer (Liu et al., 2020; Xia et al., 2020a; Cheng et al., 2021; Wei et al., 2021). Another line of popular approaches behaves like a semi-supervised manner which begins with a clean sample selection procedure, then makes use of the wrongly-labeled samples. For example, several methods (Jiang et al., 2018; Han et al., 2018; Yu et al., 2019; Wei et al., 2020) adopt a mentor/peer network to select small-loss samples as \u201cclean\u201d ones for the student/peer network. To further explore the benefits of wrongly-labeled samples and improve the model performance, Li et al. (2020) chose the MixMatch (Berthelot et al., 2019) technique which has shown success in semi-supervised learning.\\n\\nBenchmarks noisy labels datasets\\n\\nFood-101 (Bossard et al., 2014), Clothing-1M (Xiao et al., 2015), WebVision (Li et al., 2017) are three large-scale noisy labeled web-image databases which consist of food images, clothes images or other web images, respectively. However, the majority of images in these three datasets do not have a corresponding clean label to perform controlled verification (e.g., verifying the noise levels). Later, a much larger-scale food dataset is collected by Lee et al. (2018), which contains exactly the same classes as Food-101 (Bossard et al., 2014). More recently, Peterson et al. (2019) present a noisily labeled benchmarks on CIFAR-10 test dataset where each test image has 51 human annotated labels in average. Jiang et al. (2020) construct noisily labeled Mini-ImageNet (Vinyals et al., 2016) and Stanford Cars datasets (Krause et al., 2013) with controlled noise levels by substituting human annotated incorrect labels for synthetic wrong labels.\\n\\n2 SYNTHETIC LABEL NOISE\\n\\nIn this section, we discuss a few popular synthetic models for generating noisy labels. We focus on a $K$-class classification task. Denote by $\\\\mathcal{D} := \\\\{(x_n, y_n)\\\\}_{n \\\\in \\\\mathbb{N}}$ the training samples where $\\\\mathbb{N} := \\\\{1, 2, ..., N\\\\}$. $(x_n, y_n)$ are given by random variables $(X, Y) \\\\in X \\\\times Y$ drawn from the joint distribution $\\\\mathcal{D}$, where $X, Y$ can be viewed as the space of feature and label, respectively. In real-world scenarios, a classifier $f$ only has access to noisily labeled training sets $\\\\tilde{\\\\mathcal{D}} := \\\\{(x_n, \\\\tilde{y}_n)\\\\}_{n \\\\in \\\\mathbb{N}}$. We assume the noisy samples $(x_n, \\\\tilde{y}_n)$s are given by random variables $(X, \\\\tilde{Y}) \\\\in X \\\\times \\\\tilde{Y}$ which are drawn from the joint distribution $\\\\tilde{\\\\mathcal{D}}$. Clearly, there may exist $n \\\\in \\\\mathbb{N}$ such that $y_n \\\\neq \\\\tilde{y}_n$. The flipping from clean to noisy label is usually formulated by a noise transition matrix $T(X)$, with elements: $T_{i,j}(X) := P(\\\\tilde{Y} = j | Y = i, X)$. We shall specify different modeling choices of $T(X)$ below.\\n\\n2.1 CLASS-DEPENDENT LABEL NOISE\\n\\nThe first family of noise transition matrix is the class-dependent noise where the label noise is assumed to be conditionally independent of the feature $X$. Mathematically, $T(X) \\\\equiv T$ and $T_{i,j}(X) = P(\\\\tilde{Y} = j | Y = i)$, $\\\\forall i,j \\\\in \\\\{1, 2, ..., K\\\\}$.\\n\\nSymmetric $T$\\n\\nThe symmetric noise transition matrix (Natarajan et al., 2013) describes the scenario where an amount of human labelers maliciously assign a random label for the given task. It assumes that the probability of randomly flipping the clean class to the other possible class with probability $\\\\epsilon$.\\n\\nAssume the noise level is $\\\\epsilon$, the diagonal entry of the symmetric $T$ is denoted as $T_{i,i} = 1 - \\\\epsilon$. For any other off-diagonal entry $T_{i,j}$ where $i \\\\neq j$, the corresponding element is $T_{i,j} = \\\\epsilon(K-1)$. \\n\\n\"}"}
{"id": "TBWA6PLJZQm", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Asymmetric\\n\\nThe asymmetric noise transition matrix (Patrini et al., 2017) simulates the case where there exists ambiguity classes, i.e., human labelers may wrongly annotate the truck as automobile due to the low-resolution images. There are two types of widely adopted asymmetric $T$.\\n\\nThe asymmetric-next $T$ assumes that the clean label flips to the next class with probability $\\\\epsilon$, i.e., $i \\\\rightarrow (i + 1) \\\\mod K$ for $i \\\\in [K]$. The asymmetric-pair $T$ considers $K^2$ disjoint class pairs $(i_c, j_c)$ where $i_c < j_c$. For $c \\\\in [K^2]$, $T_{i_c, j_c} = T_{j_c, i_c} = \\\\epsilon$, and the diagonal entries are $1 - \\\\epsilon$.\\n\\n2.2 Instance-Dependent Label Noise\\n\\nBeyond the feature-independent assumption, recent works pay more attention to a challenging case where the label noise is jointly determined by feature $X$ and clean label $Y$. There are some techniques for synthesizing the instance-dependent label noise, such as the polynomial margin diminishing label noise (Zhang et al., 2021b) where instances near decision boundary are easier to be mislabeled, the part-dependent label noise (Xia et al., 2020b) where different parts of feature may contribute different noise transition matrices, and the group-dependent label noise (Wang et al., 2021a; Zhu et al., 2021a) where different sub-populations may have different noise rates. All of these noise models are proposed with some statistical assumptions, which facilitate the derivation of theoretical solutions.\\n\\n3 Human Annotated Noisy Labels on CIFAR-10, CIFAR-100\\n\\nIn this section, we introduce two new benchmark datasets for learning with noisy labels: CIFAR-10N and CIFAR-100N. Both datasets are built using human annotated labels collected on Amazon Mechanical Turk (M-Turk): we post CIFAR-10 and CIFAR-100 training images as the annotation Human Intelligence Tasks (HITs), and workers receive payments by completing HITs.\\n\\n3.1 CIFAR-10N\\n\\nREAL-WORLD NOISY LABEL BENCHMARK\\n\\nCIFAR-10 (Krizhevsky et al., 2009) dataset contains 60k $32 \\\\times 32$ color images, 50k images for training and 10k images for testing. Each image belongs to one of ten completely mutually exclusive classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\\n\\nDataset collection\\n\\nWe randomly split the training dataset of CIFAR-10 without replacement into ten batches. In the Mturk interface, each batch contains 500 HITs with 10 images per HIT. The training images and test dataset remain unchanged. Each HIT is then randomly assigned to three independent workers. Workers gain base reward $0.03 after submitting the answers of each HIT. We reward workers with huge bonus salary if the worker contributes more HITs than the averaged number of submissions. We did not make use of any ground-truth clean labels to approve or reject submissions. We only block and reject workers who submit answers with fixed/regular distribution patterns. We defer more details of the dataset collection to Appendix A.\\n\\nDataset statistics\\n\\nFor CIFAR-10N dataset, each training image contains one clean label and three human annotated labels. We provide five noisy-label sets as follows.\\n\\n\u2022 Aggregate: aggregation of three noisy labels by majority voting. If the submitted three labels are different for an image, the aggregated label will be randomly selected among the three labels.\\n\u2022 Random $i$ ($i \\\\in \\\\{1, 2, 3\\\\}$): the $i$-th submitted label for each image. Note our collection procedure ensures that one image cannot be repeatedly labeled by the same worker.\\n\u2022 Worst: dataset with the highest noise rate. For each image, if there exist any wrongly annotated labels in three noisy labels, the worst label is randomly selected from wrong labels. Otherwise, the worst label is equal to the clean label.\\n\\nIn CIFAR-10N, 60.27% of the training images have received unanimous label from three independent labelers. The noise rates of prepared five noisy label sets are 9.03% (Aggregate), 17.23% (Random 1), 18.12% (Random 2), 17.64% (Random 3) and 40.21% (Worst). A complete dataset comparison among existing benchmarks and ours are given in Table 1. We defer the noise level of each batch to Table 4 (Appendix). Aggregating the annotated labels significantly decreases the noise rates. All three random sets have $\\\\approx 18\\\\%$ noise level. To provide a challenging noisy setting, we also prepare a worst label set which serves to cover highly possible mistakes from human annotators on CIFAR-10.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.2 CIFAR-100N\\n\\nREAL-WORLD NOISY LABEL BENCHMARK\\n\\nCIFAR-100 (Krizhevsky et al., 2009) dataset contains 60K \\\\(32 \\\\times 32\\\\) color images of 100 fine classes, 50,000 images for training and 10,000 images for testing. Each (fine) class contains 500 training images and 100 test images. The 100 classes are grouped into 20 mutually exclusive super-classes.\\n\\nData collection\\n\\nWe split the training dataset of CIFAR-100 without replacement into ten batches with five images per HIT. Only one worker is assigned to each HIT. We group the 100 classes into 20 disjoint super-classes (see Table 5 in the Appendix) which are slightly different from the 20 \u201ccoarse\u201d categories named in CIFAR-100. The fine label in each super-class is summarized in Table 6 (Appendix). Workers are instructed to firstly select the super-class for each image. And will then be redirected to the best matched fine label. Since some super-classes are hard to recognize without prior knowledge in biology, we provide workers with easy access to re-select the super-class, and every fine class has an example image for references. The rejecting rule and the bonus policy are the same as those in CIFAR-10N. We defer more details of the dataset collection to Appendix B.\\n\\nDataset statistics\\n\\nFor CIFAR-100N dataset, each image contains a coarse label and a fine label given by a human annotator. Most batches have approximately 40% noisy fine labels and 25% noisy coarse labels. The overall noise level of coarse and fine labels are 25.60\\\\% and 40.20\\\\%, respectively. We defer the noise level of each batch to Table 7 (Appendix).\\n\\n4 RELIMINARY OBSERVATIONS ON CIFAR-10N, CIFAR-100N\\n\\nIn this section, we analyze the human annotated labels for CIFAR-10 and CIFAR-100. We will empirically compare the noisy labels in CIFAR-10N and CIFAR-100N with class-dependent label noise both qualitatively and quantitatively.\\n\\n4.1 THE NOISY LABEL DISTRIBUTION\\n\\nObservation 1: Imbalanced annotations\\n\\nOur first observation is the imbalanced contribution of labels. Note that while the number of images are the same for each clean label, across all the five noisy label sets of CIFAR-10N, we observe that human annotators have different preferences for similar classes. For instance, they are more likely to annotate an image to be an automobile rather than the truck, to be the horse rather than the deer (see Figure 8 in the Appendix). The aggregated labels appear more frequently in automobile and ship, and less frequently in deer and cat. This gap of frequency becomes more clear in the worst label set. In CIFAR-100N, human annotators annotate frequently on classes which are outside of the clean-coarse, i.e., 25\\\\% noisy labels fall outside of the super-class and 15\\\\% inside the super-class. And the phenomenon of imbalanced annotations also appears substantially as shown in Figure 1, which presents the distribution of noisy labels for each selected fine class. \u201cMan\u201d appears \\\\(\\\\geq 750\\\\) times, while \u201cStreetcar\u201d only has \\\\(\\\\approx 200\\\\) annotations.\\n\\nObservation 2: Noisy label flips to similar features\\n\\nIn CIFAR-100N, most fine classes are more likely to be mislabeled into less than four fine classes. In Figure 2, we show top three wrongly annotated fine labels for several fine classes that have a relative large noise rate. Due to the low-resolution of images, a number of noisy labels are annotated in pair of classes, i.e, \\\\(\\\\approx 20\\\\%\\\\) of \u201csnake\u201d and \u201cworm\u201d images are mislabeled between each other, similarly for \u201ccockroach\u201d-\u201cbeetle\u201d, \u201cfox\u201d-\u201cwolve\u201d, etc. While some other noisy labels are more frequently annotated within more classes, such as \u201cboy\u201d-\u201cbaby\u201d-\u201cgirl\u201d-\u201cman\u201d, \u201cshark\u201d-\u201cwhale\u201d-\u201cdolphin\u201d-\u201ctrout\u201d, etc, which share similar features.\\n\\nObservation 3: The pattern of noise transition matrices\\n\\nIn the class-dependent label noise setting, suppose the label noise is conditional independent of the feature, the noise transition matrices of CIFAR-10N and CIFAR-100N are best described by a mixture of symmetric and asymmetric.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Random noisy labels\\n\\nWorst noisy labels\\n\\nThe dominant class is the wrong annotation by referring to the officially provided clean label. The most frequent case is best (in Figure 4). The annotated class also appears in the corresponding image while is deemed as a non-negligible amount of the wrongly annotated classes that indeed co-exist in the corresponding class. During the label collection, there exist a complex as the real-world human annotated label noise.\\n\\nObservation 4: Label noise: bad news or good news?\\n\\nRecall that, for the class-dependent label noise, we have $P(\\\\tilde{Y}|Y) = \\\\tilde{P}_k(Y)$, where $\\\\tilde{P}_k$ is the CIFAR-100 clean label (first row) and the human annotated noisy label (second row). Figure 4: Exemplary CIFAR-100 training images with multiple labels. The text below each picture be a more common issue. We leave more explorations for the future work.\\n\\nDuring the label collection, there exist a conjecture that with the increasing label dimension, the phenomenon of multiple clean labels might be a more common issue. We select several exemplary training images of CIFAR-100 where multiple labels appear.\\n\\nIn Figure 2: Top 3 wrongly annotated fine labels in selected fine classes. For \u201cpine tree\u201d, \u201cshrew\u201d, \u201cmaple_tree\u201d, and \u201coak_tree\u201d, the corresponding number of correct annotations is rather than a percentage, which is much larger than that of all other classes.\\n\\nFigure 3: Transition matrix of CIFAR-10N noisy labels (color bar is log-norm transformed). Besides, in the central area of each transition matrix, it is quite obvious that the clean label of animal class flips more often than (symmetric noise model with a low noise rate. For example, \u201ctruck\u201d and \u201cautomobile\u201d flip between each other more than \u201cautomobile\u201d and \u201cairplane\u201d. Similar observations hold in CIFAR-100N, where each class flips to a few misleading classes with much higher probability than that of remaining ones (see Figure 11 in the Appendix). Apparently, current synthetic class-dependent noisy settings are not as complex as the real-world human annotated label noise.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.2 Dataset Collection\\n\\nTo alleviate the impacts of aforementioned phenomena, we randomly split the training dataset of CIFAR-10 without replacement into ten batches. Each batch contains 500 HITs. To ensure most workers do not contribute too few to the annotation task, we include ten $32 \\\\times 32$ images per HIT. Each HIT is then randomly assigned to three independent workers. The worker gains a base reward $0.03 after submitting all annotations of one HIT within 2 minutes. The worker cannot submit the annotations unless all appeared images in the assigned HIT are labeled. The averaged number of submitted HITs per worker is 7. Workers with no less than 7 submissions share $200 bonus rewards. Note that we constrain the time duration for each assignment and re-design the interface, bots are less likely to finish our task either on time or under the procedure. What is more, we didn\u2019t make use of any ground-truth clean labels to approve or reject submissions. We only block and reject workers who submit answers with fixed/regular distribution patterns.\\n\\nA.3 The Workers\u2019 Behaviors\\n\\nThere are 747 independent workers contribute to the construction of CIFAR-10N. As depicted in Figure 7a, most workers can submit the labels for ten images within one minute. Although we do observe that a small amount of assignments ($\\\\leq 0.2\\\\%$) are finished within 10 seconds, which are likely to be low-quality responses. The work time in seconds have the mean 46.7, the standard deviation 21.2 and the interquartile (25th percentile \u2014 75th percentile) range is [31, 58]. Among these 747 workers, most of them annotated more than 80 images. The number of annotated images per worker has the mean 201, the standard deviation 329 and the interquartile range is [30, 220].\\n\\nA.4 More Detailed Dataset Statistics\\n\\nTable 4 includes the summarized statistics of CIFAR-10N for each batch. In Table 4, the statistics \u201cConsensus\u201d means the three labelers have a consensus on the label of the same image. We do observe that several batches tend out to be more challenging for human workers to annotate, i.e., the noise rate appeared in Batch3 is clearly higher than those of Batch4 and Batch5. The difference of noise rate is especially significant on the \u201cWorst\u201d label set. We conjecture that there might exist more human annotators who malicious submit low-quality annotations when working on Batch3.\\n\\nNote that while the number of images are the same for each clean label, across all the five noisy label sets of CIFAR-10N, we observe that human annotators have different preferences for similar classes, i.e., they are more likely to annotate an image to be an automobile rather than the truck, to be the horse rather than the deer (see Figure 8). The aggregated labels appear more frequently in automobile and ship, and less frequently in deer and cat. This gap of frequency becomes more clear in the worst label set.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we introduce the preparation for data collection, collection procedure of CIFAR-100N, and more detailed statistics of the obtained labels.\\n\\n### B.1 Case Studies Before the Formal Collection\\nTo make the collection procedure reasonable and efficient, we firstly upload a few batches (500 images/batch) to test the behaviors of workers. Our observations show that the workers on CIFAR-100 classification tasks may not only have mentioned phenomenons in A, but have following issues as well:\\n\\n- **Hard and time consuming:** directly let workers to find the best matched label for each image from 100 possible classes is time assuming. Our case study shows that finding the label per image takes averaged 5-6 minutes. The work load as well as the difficulty level stop many workers from contributing two or more submissions.\\n\\n- **Lack of background knowledge:** distinguishing several classes require some preliminary knowledge in biology, for example, it is common for workers to select a wrong super-class, especially for animal related ones: \u201caquatic mammals\u201d and \u201cfish\u201d. And the differences among some fine labels are hard to recognize, i.e, \u201ctrees\u201d (oak, palm, pine), \u201cmedium-sized mammals\u201d (porcupine, possum, raccoon, skunk), etc.\\n\\n- **Label aggregation has few effects:** our empirical observations show that the the decrease of noise rates from aggregated labels given by 3 independent workers is less significant than the results on CIFAR-10N.\\n\\n### B.2 Dataset Collection\\nTo deal with above mentioned issues, we firstly split the training dataset of CIFAR-100 without replacement into ten batches. Each batch contains 1000 HITs. We include five $96 \\\\times 96$ images per HIT which are reshaped from $32 \\\\times 32$ ones in CIFAR-100 train images. Only one worker is assigned with each HIT. Instead of requesting workers to find the best matched label from 100 labels directly, we group the 100 classes into 20 super-classes which are slightly different from the 20 raw \u201ccoarse\u201d categories given by Krizhevsky et al. (2009). The 20 newly defined super-classes are summarized in Table 5. And the new division in each super-class is stated in Table 6. In order to reduce the workload of workers, they are instructed to firstly select the super-class for each image.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"They will then be directed to the corresponding 4-6 fine labels. Note that some super-classes are hard to recognize without some prior knowledge in biology, we provide workers with easy access to re-select the super-class for the current image, and every fine label has an example image from Google images for reference. If the worker luckily finds the most suitable fine label from her point of view, we also supply the jumping button so that the worker efficiently goes to the next image or the final submission of this HIT. A worker gains base reward $0.07 after submitting the answers of each HIT within 6 minutes (averaged working time is less than 90 seconds). Similar to the setting in the collection of CIFAR-10N, huge bonus applied to workers who contribute more HITs than the averaged number of submissions. Workers who submit answers with fixed/regular distribution patterns will be blocked and rejected all submitted results.\\n\\n### Table 5: Newly defined super-classes in CIFAR-100N.\\n\\n| Super-class                                |\\n|--------------------------------------------|\\n| (1) Aquatic mammals                        |\\n| (2) Fish                                   |\\n| (3) Flowers                                |\\n| (4) Food containers                        |\\n| (5) Fruit, vegetables and mushrooms        |\\n| (6) Household electrical devices           |\\n| (7) Household furniture                    |\\n| (8) Insects                                |\\n| (9) Large carnivores and bear              |\\n| (10) Large man-made outdoor things         |\\n| (11) Large natural outdoor scenes          |\\n| (12) Large omnivores and herbivores        |\\n| (13) Medium-sized mammals                  |\\n| (14) Non-insect invertebrates               |\\n| (15) People                                |\\n| (16) Reptiles                              |\\n| (17) Small mammals                         |\\n| (18) Trees                                 |\\n| (19) Transportation vehicles               |\\n| (20) Other vehicles                        |\\n\\n### Table 6: Division of each super-class in CIFAR-100N.\\n\\n| Super-class                  | Fine-class                                                                 |\\n|------------------------------|-----------------------------------------------------------------------------|\\n| Aquatic mammals              | beaver, dolphin, otter, seal, whale                                         |\\n| Fish                         | aquarium fish, flatfish, ray, shark, trout                                 |\\n| Flowers                      | orchids, poppies, roses, sunflowers, tulips                               |\\n| Food containers              | bottles, bowls, cans, cups, plates                                         |\\n| Fruit, vegetables and mushrooms | apples, mushrooms, oranges, pears, sweet peppers                        |\\n| Household electrical devices | clock, computer keyboard, lamp, telephone, television                     |\\n| Household furniture          | bed, chair, couch, table, wardrobe                                        |\\n| Insects                      | bee, beetle, butterfly, caterpillar, cockroach                            |\\n| Large carnivores and bear    | bear, leopard, lion, tiger, wolf                                           |\\n| Large man-made outdoor things | bridge, castle, house, road, skyscraper                                   |\\n| Large natural outdoor scenes | cloud, forest, mountain, plain, sea                                       |\\n| Large omnivores and herbivores | camel, cattle, chimpanzee, elephant, kangaroo                           |\\n| Medium-sized mammals         | fox, porcupine, possum, raccoon, skunk                                    |\\n| Non-insect invertebrates     | crab, lobster, snail, spider, worm                                        |\\n| People                       | baby, boy, girl, man, woman                                                |\\n| Reptiles                     | crocodile, dinosaur, lizard, snake, turtle                                |\\n| Small mammals                | hamster, mouse, rabbit, shrew, squirrel                                   |\\n| Trees                        | maple, oak, palm, pine, willow                                            |\\n| Transportation vehicles      | bicycle, bus, motorcycle, pickup truck, train, streetcar                  |\\n| Other vehicles               | lawn-mower, rocket, tank, tractor                                         |\\n\\nB.3 More Detailed Dataset Statistics\\n\\nFor CIFAR-100N dataset, each image contains a coarse label and a fine label given by a human annotator. Most batches have approximately 40% noisy fine labels and 25% noisy coarse labels. The overall noise level of coarse and fine labels are 25.60% and 40.20%, respectively. A detailed summary of noise level is available in Table 7 which covers the statistics of each batch. Human annotators annotate frequently on classes which are outside of the clean-coarse, i.e., 25% noisy labels fall outside of the super-class and 15% inside the super-class.\\n\\n### Table 7: Noise level (%) on CIFAR-100N.\\n\\n| Statistics | Batch1 | Batch2 | Batch3 | Batch4 | Batch5 | Batch6 | Batch7 | Batch8 | Batch9 | Batch10 | Overall |\\n|------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|---------|---------|\\n| 100-class  | 40.30  | 40.76  | 40.84  | 40.16  | 42.50  | 34.44  | 43.26  | 40.34  | 43.66  | 35.84   | 40.20   |\\n| 20-class   | 26.82  | 28.02  | 25.54  | 25.76  | 27.02  | 20.80  | 28.62  | 25.56  | 26.92  | 20.98   | 25.60   |\\n\\nImbalanced annotations.\\n\\nThe phenomenon of imbalanced annotations also appears substantially as shown in Figure 9, which presents the distribution of noisy labels for each fine class. \\\"Man\\\" appears $\\\\geq 750$ times, while \\\"Streetcar\\\" only has $\\\\approx 200$ annotations.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Noisy label flips to similar features. In CIFAR-100N, most fine classes are more likely to be mislabeled into less than four fine classes. In Figure 10, we show top three wrongly annotated fine labels for several fine classes that have a relative large noise rate. Due to the low-resolution of images, a number of noisy labels are annotated in pair of classes, i.e, \u224820% of \u201csnake\u201d and \u201cworm\u201d images are mislabeled between each other, similarly for \u201ccockroach\u201d-\u201cbeetle\u201d, \u201cfox\u201d-\u201cwolve\u201d, etc. While some other noisy labels are more frequently annotated within more classes, such as \u201cboy\u201d-\u201cbaby\u201d-\u201cgirl\u201d-\u201cman\u201d, \u201cshark\u201d-\u201cwhale\u201d-\u201cdolphin\u201d-\u201ctrout\u201d, etc, which share similar features.\\n\\nFigure 10: Top 3 wrongly annotated fine labels for each selected fine classes. For \u201cpine tree\u201d, \u201cshrew\u201d, \u201cstreetcar\u201d, the dominant class is the wrong class. The corresponding number of correct annotations are highlighted with red lines.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"most methods, class-dependent synthetic noise is much easier to learn on CIFAR-10, especially when the noise level is high. The performance difference between human noise and the synthetic noise is less obvious for CIFAR-100.\\n\\nTable 9: Comparison of test accuracies (%) on CIFAR-10 and CIFAR-100 (fine-label) with synthetic noisy labels using different methods. Top 3 performances are highlighted in bold.\\n\\n| Method                      | CIFAR-10 synthetic | CIFAR-100 synthetic | Clean | Aggregate | Random 1 | Random 2 | Random 3 | Worst |\\n|-----------------------------|--------------------|--------------------|-------|-----------|----------|----------|----------|-------|\\n| Clean Noisy                 | 92.92 \u00b1 0.11       | 92.12 \u00b1 0.17       | 91.03 \u00b1 0.64 | 90.96 \u00b1 0.35 | 90.98 \u00b1 0.32 | 86.69 \u00b1 0.16 | 76.70 \u00b1 0.74 | 56.70 \u00b1 1.26 |\\n| CE (Standard)               | 93.02 \u00b1 0.12       | 92.54 \u00b1 0.20       | 91.70 \u00b1 0.22 | 91.00 \u00b1 0.21 | 91.31 \u00b1 0.19 | 86.87 \u00b1 0.44 | 76.18 \u00b1 0.37 | 56.87 \u00b1 1.58 |\\n| Forward T (Patrini et al., 2017) | 93.10 \u00b1 0.05       | 92.31 \u00b1 0.28       | 91.34 \u00b1 0.16 | 91.14 \u00b1 0.41 | 91.36 \u00b1 0.14 | 86.80 \u00b1 0.42 | 76.79 \u00b1 0.60 | 57.68 \u00b1 1.90 |\\n| GCE (Zhang & Sabuncu, 2018) | 92.83 \u00b1 0.16       | 92.44 \u00b1 0.21       | 91.38 \u00b1 0.17 | 91.17 \u00b1 0.07 | 91.49 \u00b1 0.19 | 87.12 \u00b1 0.16 | 76.35 \u00b1 0.48 | 57.17 \u00b1 1.51 |\\n| Co-teaching (Han et al., 2018) | 93.35 \u00b1 0.14       | 91.57 \u00b1 0.32       | 90.99 \u00b1 0.27 | 90.97 \u00b1 0.24 | 91.31 \u00b1 0.14 | 85.74 \u00b1 0.36 | 73.46 \u00b1 0.09 | 59.63 \u00b1 0.27 |\\n| Co-teaching+ (Yu et al., 2019) | 92.41 \u00b1 0.20       | 91.50 \u00b1 0.13       | 90.62 \u00b1 0.16 | 90.33 \u00b1 0.46 | 90.59 \u00b1 0.06 | 85.89 \u00b1 0.25 | 70.99 \u00b1 0.22 | 57.27 \u00b1 0.23 |\\n| T-Revision (Xia et al., 2019) | 93.35 \u00b1 0.23       | 90.01 \u00b1 0.21       | 88.59 \u00b1 0.63 | 88.56 \u00b1 0.88 | 88.22 \u00b1 0.58 | 83.57 \u00b1 0.68 | 82.83 \u00b1 0.21 | 50.91 \u00b1 1.00 |\\n| Peer Loss (Liu & Guo, 2020)  | 93.99 \u00b1 0.13       | 92.65 \u00b1 0.12       | 91.48 \u00b1 0.20 | 91.50 \u00b1 0.14 | 90.52 \u00b1 0.24 | 86.67 \u00b1 0.19 | 74.67 \u00b1 0.36 | 56.74 \u00b1 0.70 |\\n| ELR (Liu et al., 2020)       | 93.45 \u00b1 0.65       | 91.60 \u00b1 0.19       | 90.65 \u00b1 0.03 | 90.64 \u00b1 0.24 | 90.90 \u00b1 0.26 | 81.94 \u00b1 0.27 | 72.78 \u00b1 0.01 | 59.99 \u00b1 0.88 |\\n| ELR+ (Liu et al., 2020)      | 95.39 \u00b1 0.05       | 94.98 \u00b1 0.15       | 94.77 \u00b1 0.18 | 94.60 \u00b1 0.05 | 94.69 \u00b1 0.14 | 87.38 \u00b1 2.66 | 78.57 \u00b1 0.12 | 68.46 \u00b1 0.07 |\\n| Positive-LS (Lukasik et al., 2020) | 94.77 \u00b1 0.17       | 92.13 \u00b1 0.15       | 91.02 \u00b1 0.53 | 91.15 \u00b1 0.16 | 91.30 \u00b1 0.14 | 86.71 \u00b1 0.34 | 76.25 \u00b1 0.35 | 56.51 \u00b1 0.71 |\\n| F-Div (Wei & Liu, 2020)      | 94.88 \u00b1 0.12       | 92.36 \u00b1 0.41       | 91.32 \u00b1 0.29 | 91.12 \u00b1 0.46 | 91.20 \u00b1 0.10 | 86.67 \u00b1 0.38 | 76.14 \u00b1 0.36 | 58.41 \u00b1 0.90 |\\n| Divide-Mix (Li et al., 2020) | 95.36 \u00b1 0.09       | 95.45 \u00b1 0.09       | 95.58 \u00b1 0.07 | 95.51 \u00b1 0.08 | 95.50 \u00b1 0.10 | 93.55 \u00b1 0.40 | 76.94 \u00b1 0.22 | 71.78 \u00b1 0.28 |\\n| Negative-LS (Wei et al., 2021) | 94.92 \u00b1 0.25       | 92.74 \u00b1 0.25       | 91.60 \u00b1 0.30 | 91.45 \u00b1 0.28 | 91.49 \u00b1 0.23 | 86.99 \u00b1 0.14 | 77.06 \u00b1 0.73 | 59.85 \u00b1 1.15 |\\n| JoCoR (Wei et al., 2020)     | 93.40 \u00b1 0.24       | 91.79 \u00b1 0.21       | 91.08 \u00b1 0.20 | 90.89 \u00b1 0.24 | 91.12 \u00b1 0.20 | 85.80 \u00b1 0.33 | 74.07 \u00b1 0.33 | 59.49 \u00b1 0.29 |\\n\\nE.3 EXPERIMENT DETAILS ON CIFAR-10N AND CIFAR-100N\\n\\nThe basic hyper-parameters settings for CIFAR-10N and CIFAR-100N are listed as follows: mini-batch size (128), optimizer (SGD), initial learning rate (0.1), momentum (0.9), weight decay (0.0005), number of epochs (100) and learning rate decay (0.1 at 50 epochs). Standard data augmentation is applied to each dataset.\\n\\nSpecial treatments\\n\\nIn the reproduced experiments, we use the default setting for Cores* (Cheng et al., 2021), ELR+ (Liu et al., 2020) and DivideMix since either advanced data augmentation strategies or two deep neural networks are adopted. And we fix a same pre-trained model for methods that require a CE warm-up or a pre-trained model.\\n\\nE.4 COMPUTING INFRASTRUCTURE\\n\\nAll our experiments run on a GPU cluster (500 GPUs of all kinds, mainly use 2080 Ti) for training and evaluation.\"}"}
{"id": "TBWA6PLJZQm", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"In the class-dependent label noise setting, suppose the label noise is conditional independent of the feature, the noise transition matrices of CIFAR-100N are best described by a mixture of symmetric and asymmetric $T$. For CIFAR-100N, we heatmap the coarse and fine noisy labels w.r.t. the clean labels. In Figure 11, the clean label flips into one or more similar classes more often. And the remaining classes follow the symmetric noise model with a low noise rate. Apparently, current synthetic class-dependent noisy settings are not as complex as the real-world human annotated label noise.\\n\\n| Noisy label      | Clean label | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n|------------------|-------------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|\\n| aquatic mammals  | 0.47        | 0.12 | 0.00 | 0.00 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| fish             | 0.11        | 0.64 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |\\n| flowers          | 0.02        | 0.01 | 0.89 | 0.00 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| food containers  | 0.01        | 0.01 | 0.01 | 0.82 | 0.02 | 0.04 | 0.02 | 0.02 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |\\n| fruit, vegetables and mushroom | 0.01 | 0.01 | 0.01 | 0.01 | 0.82 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| household electrical devices | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.86 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| household furniture | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.74 | 0.01 | 0.00 | 0.00 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |\\n| insects          | 0.02        | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.73 | 0.01 | 0.00 | 0.00 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |\\n| large carnivores and bear | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.79 | 0.09 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| large man-made outdoor things | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.82 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| large natural outdoor scenes | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.82 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| large omnivores and herbivores | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.86 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| medium-sized mammals | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.94 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| non-insect invertebrates | 0.05 | 0.00 | 0.00 | 0.00 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 | 0.01 |\\n| other vehicles   | 0.02        | 0.01 | 0.00 | 0.00 | 0.00 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| people           | 0.14        | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| reptiles         | 0.00        | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| small mammals    | 0.00        | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| transportation vehicles | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n| trees            | 0.02        | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\\n\\n**Figure 11:** Transition matrix of CIFAR-100N noisy labels: coarse labels (left) and fine labels (right).\"}"}
{"id": "TBWA6PLJZQm", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We firstly summarize the main collection procedure of CIFAR-10H, and then move to discuss the difference in the label collection procedure.\\n\\nThe label collection procedure of CIFAR-10H dataset is given below:\\n\\n- **No time limit:** participants were asked to select the label of each image from the surrounding text with no time limit.\\n- **Controlled workload:** Each participant is assigned 200 images (20 per class);\\n- **Attention check (intervention):** Participants with a low accuracy (<75%) on (easy-to-recognize) images were removed.\\n- **Other minor differences:** Label positions are shuffled among participants; 47-63 annotations per image; payment: 0.0075/10 images.\\n\\nWe want to highlight that the central query for CIFAR-10H is to understand the benefits of uncertainty in human annotations to improve the generalization power of the trained model. Therefore, a number of controls and interventions were applied when building CIFAR-10H to control the human noise rates to be not excessive to disturb the above benefit study (details below). We believe this aspect renders the dataset not super appropriate for the relevant studies reported in Section 4 and 5. Our detailed reasons come as follows:\\n\\n- **Interacted real-world human noise pattern:**\\n  - **Purpose of the dataset construction:** CIFAR-10H targets to identify the benefits from increasing the richness of label distributions (hard label $\\\\rightarrow$ soft label) for image classification tasks. The soft labels are constructed by human uncertainty. CIFAR-10H may not fully reveal the real-world human annotation noise due to the check and removal procedure as we described above in attention check.\\n  - While we aim to study the real-world label noise pattern: we only reject uninformative and spamming annotation patterns (e.g., labeling every task as class 1) and we do not restrict the number of annotations required from different workers with different working efficiency. We accept submissions even if a worker has a moderate accuracy (e.g., \\\\(<60\\\\%\\\\)) and meanwhile reward workers that contribute a large number of annotations.\\n\\n- **Noise rate:** we randomly select the i-th (e.g., 1,2,...,10-th) annotated label for each test image in CIFAR-10-H, and there are approximately 5% wrong labels in the annotation. In CIFAR-10N, the random noise rate is around 18%. For CIFAR-100N, the noise rate increased to 40.20%. CIFAR-10H has a much smaller noise rate due to the control intervention, and due to different objects of the collection. We believe that a very low noise rate may deviate from real-world human noise.\\n\\n- **Training data V.S. Test data:**\\n  - Training on CIFAR-10 test data may lead to a model performance drop. It is reported that, when trained using the much smaller test data, the generalization accuracy on training data is only about 83% (Peterson et al., 2019). Note the standard training and testing on CIFAR-10 has an accuracy of about 93%. With added label noise, the substantial drop of the number of training data limits the possibility of fully evaluating the potentials and properties of the competing benchmark methods (e.g., learning and showing some of the established theoretical properties of a particular method might require a sufficient number of training data).\\n\\n- **Looking forward, we think it might be beneficial to let the learning-with-noisy-label community have an option of training using 50k training data and testing on the 10k test data, the same and standard way as other learning communities have developed and evaluated algorithms using CIFAR-10 data. As we benchmarked in Table 2, most of the existing works are tuned (e.g., pre-trained models for representation extraction for CIFAR-10, etc) for the training with 50k training images. This can help the community better align and calibrate the progress, as compared to other learning tasks (e.g., supervised learning, semi-supervised learning, etc).\\\"\"}"}
{"id": "TBWA6PLJZQm", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this section, we include the hypothesis testing results for each class as. As described in Figure 12, the $p$-value of the human noise label w.r.t each clean class (except for \u201cautomobile\u201d) in CIFAR-10N is less than $0.05\\\\,(*).$ Most of the classes (except for three of them) achieve a $p$-value that is smaller than $0.01\\\\,(**).$ Since there exists classes in CIFAR-10N such that the null hypothesis is rejected with the significance value $\\\\alpha,$ hypothesis \u201chuman annotated label noise in CIFAR-10N is feature-dependent\u201d is accepted.\\n\\nWe further statistically test whether the human-noise is feature-dependent or not in CIFAR-100N. The null hypothesis $H_0$ and the corresponding alternate hypothesis $H_1$ are defined as:\\n\\n$H_0$: Human annotated label noise in CIFAR-100N is feature-independent;\\n\\n$H_1$: Human annotated label noise in CIFAR-100N is feature-dependent.\\n\\nNote that the synthetic label noise is supposed to be feature-independent, the above hypotheses are converted to:\\n\\n$H_0$: Human annotated label noise in CIFAR-100N is the same as the corresponding synthetic one;\\n\\n$H_1$: Human annotated label noise in CIFAR-100N is different from the corresponding synthetic one.\\n\\nAs implemented for CIFAR-10N, we adopt the distance between transition vectors $p_{i,\\\\nu}$ across different noise as measure of the difference between human noise and synthetic noise, e.g., $d^{(1)}_{i,\\\\nu} := \\\\| p_{\\\\text{human}} - p_{\\\\text{synthetic}} \\\\|_2^2.$ As contrast, we need to compare $d^{(1)}_{i,\\\\nu}$ with $d^{(2)}_{i,\\\\nu} := \\\\| p_{\\\\text{synthetic}}^\\\\prime - p_{\\\\text{synthetic}} \\\\|_2^2,$ where $p_{\\\\text{synthetic}}^\\\\prime$ denotes the transition vector from the same synthetic noise but different clustering result (caused by random data augmentation). Intuitively, if $d^{(1)}_{i,\\\\nu}$ is much greater than $d^{(2)}_{i,\\\\nu},$ we should accept $H_1.$ The above hypotheses are then equivalent to:\\n\\n$H_0$: $\\\\{d^{(1)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}$ come from the same distribution as $\\\\{d^{(2)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}$;\\n\\n$H_1$: $\\\\{d^{(1)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}$ come from different distributions from $\\\\{d^{(2)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}.$\\n\\nWe repeat the generation of $d_{i,\\\\nu}$ for 10 times, where the images are modified with different data augmentations each time. We choose the significance level $\\\\alpha = 0.05$ and perform a two-sided t-test w.r.t $\\\\{d^{(1)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}$ and $\\\\{d^{(2)}_{i,\\\\nu}\\\\}_{i \\\\in [K], \\\\nu \\\\in [5]}.$ As described in Figure 13, the $p$-value of approximately 50 classes is less than $\\\\alpha = 0.05.$ Thus, the null hypothesis for the human noisy labels in CIFAR-100N is rejected with the significance value $\\\\alpha.$ And we accept the hypothesis: \u201cHuman annotated label noise in CIFAR-100N is feature-dependent.\u201d\"}"}
{"id": "TBWA6PLJZQm", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 8: Comparison of test accuracies\\n\\n| Method                | CIFAR-10N | CIFAR-100N | Clean | Aggregate | Random 1 | Random 2 | Random 3 | Worst |\\n|-----------------------|-----------|------------|-------|-----------|----------|----------|----------|-------|\\n| CE (Standard)         | 94.76     | 93.83      | 94.83 | 93.42     | 94.66    | 91.23    | 91.06    | 90.96 |\\n| PES (Semi)            | 94.92     | 93.93      | 94.92 | 93.44     | 94.68    | 91.24    | 91.08    | 90.97 |\\n| CAL (Zhu et al., 2021)| 94.91     | 93.92      | 94.91 | 93.44     | 94.70    | 91.25    | 91.09    | 90.98 |\\n| VolMinNet (Li et al., 2021) | 94.90 | 93.91      | 94.90 | 93.44     | 94.69    | 91.24    | 91.09    | 90.98 |\\n| CORES                 | 94.90     | 93.91      | 94.90 | 93.44     | 94.69    | 91.24    | 91.09    | 90.98 |\\n| JoCoR (Wei et al., 2020) | 94.90     | 93.91      | 94.90 | 93.44     | 94.69    | 91.24    | 91.09    | 90.98 |\\n| F-Div (Wei & Liu, 2020) | 94.89     | 93.90      | 94.89 | 93.43     | 94.68    | 91.23    | 91.07    | 90.97 |\\n| Negative-LS (Wei et al., 2021) | 94.88     | 93.89      | 94.88 | 93.43     | 94.67    | 91.23    | 91.06    | 90.96 |\\n| ELR (Liu et al., 2020) | 94.87     | 93.88      | 94.87 | 93.43     | 94.67    | 91.23    | 91.06    | 90.96 |\\n| ELR+ (Liu et al., 2020) | 94.86     | 93.87      | 94.86 | 93.43     | 94.67    | 91.23    | 91.06    | 90.96 |\\n| Divide-Mix (Li et al., 2020) | 94.85     | 93.86      | 94.85 | 93.43     | 94.67    | 91.23    | 91.06    | 90.96 |\\n| CORES                 | 94.85     | 93.86      | 94.85 | 93.43     | 94.67    | 91.23    | 91.06    | 90.96 |\\n| Backward              | 94.84     | 93.85      | 94.84 | 93.42     | 94.66    | 91.23    | 91.06    | 90.96 |\\n| Forward               | 94.83     | 93.84      | 94.83 | 93.42     | 94.66    | 91.23    | 91.06    | 90.96 |\\n| Peer Loss (Liu & Guo, 2020) | 94.82     | 93.83      | 94.82 | 93.42     | 94.66    | 91.23    | 91.06    | 90.96 |\\n| Co-teaching (Han et al., 2018) | 94.81     | 93.82      | 94.81 | 93.41     | 94.65    | 91.22    | 91.05    | 90.95 |\\n| Co-teaching+ (Yu et al., 2019) | 94.80     | 93.81      | 94.80 | 93.41     | 94.65    | 91.22    | 91.05    | 90.95 |\\n| GCE (Zhang & Sabuncu, 2018) | 94.79     | 93.80      | 94.79 | 93.41     | 94.65    | 91.22    | 91.05    | 90.95 |\\n| T-Revision (Xia et al., 2019) | 94.78     | 93.79      | 94.78 | 93.40     | 94.64    | 91.21    | 91.04    | 90.94 |\\n\\n### Figure 13: Hypothesis testing results of CIFAR-100N\\n\\n- **(a)** Count-plot of each significance level\\n- **(b)** Count-plot of p-value\\n\\n### Table 9: Significance levels\\n\\n| Significance level | Count |\\n|--------------------|-------|\\n| 10                 | 10    |\\n| 20                 | 10    |\\n| 30                 | 10    |\\n| 40                 | 10    |\\n| 50                 | 10    |\\n\\n### E.1 Performance Comparisons on Additional Datasets\\n\\nBeyond feature dependency, as shown in Figure 13 (b), although the overall noisy fine labels in CIFAR-100 are feature dependent, the noise transition vectors can be viewed as feature independent in certain cases. This suggests that the noise transition vectors might be class dependent by referring to their significance levels. Thus, we can conclude that CIFAR-100 are feature dependent, the noise transition vectors of around 50 classes can indeed be viewed as feature independent.\\n\\n### E.2 Performance Comparisons on CIFAR-N\\n\\nWe include a larger family of robust methods when learning with CIFAR-N in the Table 8. Note that%\\n\\n### Table 9: Significance levels\\n\\n| Significance level | Count |\\n|--------------------|-------|\\n| 10                 | 10    |\\n| 20                 | 10    |\\n| 30                 | 10    |\\n| 40                 | 10    |\\n| 50                 | 10    |\\n\\n### Note\\n\\n- **ns**: Not significant\\n- ********: p < 0.0001\\n- ****: p < 0.01\\n- ****: p < 0.05\\n- ***: p < 0.1\\n\\nWhen removed the class constraint, the performance gap between ELR and ELR+ becomes much larger when the noise level is high. For further details, please refer to Table 8. The same training procedure and batch-size for all implemented methods.\\n\\nContinuing the empirical observations in Section 5.1, in this section, we adopt ResNet-34 (He et al., 2016), the same training procedure and batch-size for all implemented methods. The synthetic CIFAR datasets generate synthetic noisy labels by using the same class-dependent noise transition matrices and the same parameters for the whole data.\"}"}
