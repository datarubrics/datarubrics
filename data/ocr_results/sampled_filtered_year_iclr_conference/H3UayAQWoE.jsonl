{"id": "H3UayAQWoE", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.1 Trait Theory on LLMs\\n\\nMiotto et al. (2022) analyzed GPT-3 using the HEXACO Personality Inventory and Human Values Scale. Romero et al. (2023) examined GPT-3 across nine different languages using the BFI. Jiang et al. (2022) assessed the applicability of the BFI to BART, GPT-Neo 2.7B, GPT-NeoX 20B, T0++ 11B, Alpaca 7B, and GPT-3.5 175B. Li et al. (2022) tested GPT-3, text-davinci-001, text-davinci-002, and FLAN-T5-XXL, employing assessments such as the DT, BFI, Flourishing Scale, and Satisfaction With Life Scale. Karra et al. (2022) analyzed the personality traits of GPT-2, GPT-3, GPT-3.5, XLNet, TransformersXL, and LLaMA using the BFI. Bodroza et al. (2023) evaluated text-davinci-003\u2019s responses on a battery of assessments, including Self-Consciousness Scales, BFI, DT, HEXACO Personality Inventory, Bidimensional Impression Management Index, and Political Orientation. Rutinowski et al. (2023) examined ChatGPT\u2019s personality using the BFI and Myers Briggs Personality Test and its political values using the Political Compass Test. Huang et al. (2023b) evaluated whether gpt-3.5-turbo exhibits stable personalities under five perturbation metrics on the BFI, i.e., whether the BFI shows satisfactory reliability on gpt-3.5-turbo. Safdari et al. (2023) measured the personality traits of the PaLM family using the BFI. Our work provides a comprehensive framework for personality analysis, including various facets of this domain. Additionally, we conduct a thorough examination of state-of-the-art LLMs. Furthermore, our framework exhibits a high degree of flexibility, allowing for additional scales or questionnaires to be integrated.\\n\\n5.2 Psychometrics on LLMs\\n\\nPark et al. (2023) conducted an assessment of the performance of the text-davinci-003 model on fourteen diverse topics, encompassing areas such as political orientation, economic preferences, judgment, and moral philosophy, notably the well-known moral problem of \u201cTrolley Dilemma.\u201d Almeida et al. (2023) explored GPT-4\u2019s moral and legal reasoning capabilities within psychology, including eight distinct scenarios. Similarly, Scherrer et al. (2023) assessed the moral beliefs of 28 diverse LLMs using self-define scenarios. Wang et al. (2023a) developed a standardized test for evaluating emotional intelligence, referred to as the Situational Evaluation of Complex Emotional Understanding, and administered it to 18 different LLMs. Coda-Forno et al. (2023) investigated the manifestations of anxiety in text-davinci-003 by employing the State-Trait Inventory for Cognitive and Somatic Anxiety. Huang et al. (2023a) analyzed the emotion states of GPT-4, ChatGPT, text-davinci-003, and LLaMA-2 (7B and 13B), specifically focusing on the assessment of positive and negative affective dimensions. When it comes to understanding and interacting with others, EI and Theory of Mind (ToM) are two distinct psychological concepts. Bubeck et al. (2023) finds that GPT-4 has ToM, i.e., it can understand others\u2019 beliefs, desires, and intentions. The EI studied in this paper focuses more on whether LLMs can understand others\u2019 emotions through others\u2019 words and behaviors. In our study, we also evaluate the emotional capabilities of LLMs, although we do not delve into the assessment of specific emotions. An exploration of the psychological processes underlying moral reasoning lies beyond the scope of this research. However, as mentioned in \u00a74.2, we can easily integrate these types of scales in our framework.\\n\\n6 Conclusion\\n\\nThis paper introduces PsychoBench, a comprehensive framework for evaluating LLMs\u2019 psychological representations. Inspired by research in psychometrics, our framework comprises thirteen distinct scales commonly used in clinical psychology. They are categorized into four primary domains: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Empirical investigations are conducted using five LLMs from both commercial applications and open-source models, highlighting how various models can elicit divergent psychological profiles. Moreover, by utilizing a jailbreaking technique, i.e., CipherChat, this study offers valuable insights into the intrinsic characteristics of GPT-4, showing the distinctions compared to its default setting. We further delve into the interplay between assigned roles, anticipated model behaviors, and the PsychoBench results, discovering a remarkable consistency across these dimensions. We hope that our framework can facilitate research on personalized LLMs.\"}"}
{"id": "H3UayAQWoE", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We would like to emphasize that the primary objective of this paper is to facilitate a scientific inquiry into understanding LLMs from a psychological standpoint. A high performance on the proposed benchmark should not be misconstrued as an endorsement or certification for deploying LLMs in these contexts. Users must exercise caution and recognize that the performance on this benchmark does not imply any applicability or certificate of automated counseling or companionship use cases.\\n\\nThe work described in this paper was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (No. CUHK 14206921 of the General Research Fund).\\n\\nReferences\\n\\nGuilherme FCF Almeida, Jos\u00e9 Luiz Nunes, Neele Engelmann, Alex Wiegmann, and Marcelo de Ara\u00fajo. Exploring the psychology of gpt-4\u2019s moral and legal reasoning. arXiv preprint arXiv:2308.01264, 2023.\\n\\nAnne Anastasi and Susana Urbina. Psychological testing. Prentice Hall/Pearson Education, 1997.\\n\\nMaryse Arcand, Robert-Paul Juster, Sonia J Lupien, and Marie-France Marin. Gender roles in relation to symptoms of anxiety and depression among students and workers. Anxiety, Stress, & Coping, 33(6):661\u2013674, 2020.\\n\\nCarol J Auster and Susan C Ohm. Masculinity and femininity in contemporary american society: A reevaluation using the bem sex-role inventory. Sex Roles, 43:499\u2013528, 2000.\\n\\nC Daniel Batson. 16 self-report ratings of empathic emotion. Empathy and its development, pp. 356, 1990.\\n\\nC Daniel Batson. Empathy-induced altruistic motivation. American Psychological Association, 2010.\\n\\nSandra L Bem. The measurement of psychological androgyny. Journal of consulting and clinical psychology, 42(2):155, 1974.\\n\\nSandra Lipsitz Bem. On the utility of alternative procedures for assessing psychological androgyny. Journal of consulting and clinical psychology, 45(2):196, 1977.\\n\\nBojana Bodroza, Bojana M Dinic, and Ljubisa Bojic. Personality testing of gpt-3: Limited temporal reliability, but highlighted social desirability of gpt-3\u2019s personality instruments results. arXiv preprint arXiv:2306.04308, 2023.\\n\\nNick Bostrom. Superintelligence: Paths, Dangers, Strategies. Oxford University Press, 2014.\\n\\nKelly A Brennan, Catherine L Clark, and Phillip R Shaver. Self-report measurement of adult attachment: An integrative overview. Attachment theory and close relationships, 1998.\\n\\nS\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.\\n\\nMarco Cascella, Jonathan Montomoli, Valentina Bellini, and Elena Bignami. Evaluating the feasibility of chatgpt in healthcare: an analysis of multiple clinical and research scenarios. Journal of Medical Systems, 47(1):33, 2023.\\n\\nKent Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. Speak, memory: An archaeology of books known to ChatGPT/GPT-4. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 7312\u20137327, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.453. URL https://aclanthology.org/2023.emnlp-main.453.\"}"}
{"id": "H3UayAQWoE", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2024\\n\\nMelody Manchi Chao, Riki Takeuchi, and Jiing-Lih Farh. Enhancing cultural intelligence: The roles of implicit culture beliefs and adjustment. Personnel Psychology, 70(1):257\u2013292, 2017.\\n\\nJulian Coda-Forno, Kristin Witte, Akshay K Jagadish, Marcel Binz, Zeynep Akata, and Eric Schulz. Inducing anxiety in large language models increases exploration and bias. arXiv preprint arXiv:2304.11111, 2023.\\n\\nRonald Jay Cohen, Mark E Swerdlik, and Suzanne M Phillips. Psychological testing and assessment: An introduction to tests and measurement. Mayfield Publishing Co., 1996.\\n\\nSunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao Zhang, and Jun Xu. Uncovering chatgpt's capabilities in recommender systems. In Proceedings of the 17th ACM Conference on Recommender Systems, pp. 1126\u20131132, 2023a.\\n\\nWei Dai, Jionghao Lin, Hua Jin, Tongguang Li, Yi-Shan Tsai, Dragan Ga\u0161evi\u0107, and Guanliang Chen. Can large language models provide feedback to students? a case study on chatgpt. In 2023 IEEE International Conference on Advanced Learning Technologies (ICALT), pp. 323\u2013325. IEEE, 2023b.\\n\\nMark H Davis. Measuring individual differences in empathy: Evidence for a multidimensional approach. Journal of personality and social psychology, 44(1):113, 1983.\\n\\nAniket Deroy, Kripabandhu Ghosh, and Saptarshi Ghosh. How ready are pre-trained abstractive models and llms for legal case judgement summarization? arXiv preprint arXiv:2306.01248, 2023.\\n\\nJoerg Dietz and Emmanuelle P Kleinlogel. Wage cuts and managers' empathy: How a positive emotion can contribute to positive organizational ethics in difficult times. Journal of business ethics, 119:461\u2013472, 2014.\\n\\nDanica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray. Can ai language models replace human participants? Trends in Cognitive Sciences, 2023.\\n\\nZohar Elyoseph, Dorit Hadar-Shoval, Kfir Asraf, and Maya Lvovsky. Chatgpt outperforms humans in emotional awareness evaluations. Frontiers in Psychology, 14:1199058, 2023.\\n\\nSybil BG Eysenck, Hans J Eysenck, and Paul Barrett. A revised version of the psychoticism scale. Personality and individual differences, 6(1):21\u201329, 1985.\\n\\nR Chris Fraley, Niels G Waller, and Kelly A Brennan. An item response theory analysis of self-report measures of adult attachment. Journal of personality and social psychology, 78(2):350, 2000.\\n\\nR Chris Fraley, Marie E Heffernan, Amanda M Vicary, and Claudia Chloe Brumbaugh. The experiences in close relationships\u2014relationship structures questionnaire: a method for assessing attachment orientations across relationships. Psychological assessment, 23(3):615, 2011.\\n\\nJacqueline Harding, William D'Alessandro, N. G. Laskowski, and Robert Long. Ai language models cannot replace human research participants. AI & SOCIETY, 2023.\\n\\nJen-tse Huang, Man Ho Lam, Eric John Li, Shujie Ren, Wenxuan Wang, Wenxiang Jiao, Zhaopeng Tu, and Michael R Lyu. Emotionally numb or empathetic? evaluating how llms feel using emotionbench. arXiv preprint arXiv:2308.03656, 2023a.\\n\\nJen-tse Huang, Wenxuan Wang, Man Ho Lam, Eric John Li, Wenxiang Jiao, and Michael R Lyu. Revisiting the reliability of psychological scales on large language models. arXiv preprint arXiv:2305.19926, 2023b.\\n\\nGuangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, and Yixin Zhu. Evaluating and inducing personality in pre-trained language models. arXiv preprint arXiv:2206.07550, 2022.\\n\\nWenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. Is chatgpt a good translator? a preliminary study. arXiv preprint arXiv:2301.08745, 2023.\"}"}
{"id": "H3UayAQWoE", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "H3UayAQWoE", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, ChatGPT, GPT-4, LLaMA-2-7b, and LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the safety alignment protocols and test the intrinsic natures of LLMs. We have made PsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench.\"}"}
{"id": "H3UayAQWoE", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"shift motivates us to go beyond evaluating the performance of LLMs within defined tasks, moving our goal towards comprehending their inherent qualities and attributes. In pursuit of this objective, we direct our focus toward the domain of psychometrics. The field of psychometrics, renowned for its expertise in delineating the psychological profiles of entities, offers valuable insights to guide us in depicting the intricate psychological portrayal of LLMs.\\n\\nWhy do we care about psychometrics on LLMs?\\n\\nFor Computer Science Researchers.\\n\\nIn light of the possibility of exponential advancements in artificial intelligence, which could pose an existential threat to humanity (Bostrom, 2014), researchers have been studying the psychology of LLMs to ensure their alignment with human expectations. Almeida et al. (2023); Scherrer et al. (2023) evaluated the moral alignment of LLMs with human values, intending to prevent the emergence of illegal or perilous ideations within these AI systems. Li et al. (2022); Coda-Forno et al. (2023) investigated the potential development of mental illnesses in LLMs. Beyond these efforts, understanding their psychological portrayal can guide researchers to build more human-like, empathetic, and engaging AI-powered communication tools. Furthermore, by examining the psychological aspects of LLMs, researchers can identify potential strengths and weaknesses in their decision-making processes. This knowledge can be used to develop AI systems that better support human decision-makers in various professional and personal contexts. Last but not least, analyzing the psychological aspects of LLMs can help identify potential biases, harmful behavior, or unintended consequences that might arise from their deployment. This knowledge can guide the development of more responsible and ethically-aligned AI systems. Our study offers a comprehensive framework of psychometric assessments applied to LLMs, effectively assuming the role of a psychiatrist, particularly tailored to LLMs.\\n\\nFor Social Science Researchers.\\n\\nOn the one hand, impressed by the remarkable performance of recent LLMs, particularly their ability to generate human-like dialogue, researchers in the field of social science have been seeking a possibility to use LLMs to simulate human responses (Dillion et al., 2023). Experiments in social science often require plenty of responses from human subjects to validate the findings, resulting in significant time and financial expenses. LLMs, trained on vast datasets generated by humans, possess the potential to generate responses that closely adhere to the human response distribution, thus offering the prospect of substantial reductions in both time and cost. However, the attainment of this objective remains a subject of debate (Harding et al., 2023). The challenge lies in the alignment gap between AI and human cognition. Hence, there is a compelling demand for researchers seeking to assess the disparities between AI-generated responses and those originating from humans, particularly within social science research.\\n\\nOn the other hand, researchers in psychology have long been dedicated to exploring how culture, society, and environmental factors influence the formation of individual identities and perspectives (Tomasello, 1999). Through the application of LLMs, we can discover the relation between psychometric results and the training data inputs. This methodology stands poised as a potent instrument for investigating the intricacies of worldviews and the values intrinsically associated with particular cultural contexts. Our study has the potential to facilitate research within these domains through the lens of psychometrics.\\n\\nFor Users and Human Society.\\n\\nWith the aid of LLMs, computer systems have evolved into more than mere tools; they assume the role of assistants. In the future, more users will be ready to embrace LLM-based applications rather than traditional, domain-specific software solutions. Meanwhile, LLMs will increasingly function as human-like assistants, potentially attaining integration into human society. In this context, we need to understand the psychological dimensions of LLMs for three reasons: (1) This can facilitate the development of AI assistants customized and tailored to individual users' preferences and needs, leading to more effective and personalized AI-driven solutions across various domains, such as healthcare, education, and customer service. (2) This can contribute to building trust and acceptance among users. Users who perceive AI agents as having relatable personalities and emotions may be more likely to engage with and rely on these systems. (3) This can help human beings monitor the mental states of LLMs, especially their personality and temperament, as these attributes hold significance in gauging their potential integration into human society in the future.\"}"}
{"id": "H3UayAQWoE", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"PsychoBench\\n\\nPersonality Tests\\n\\nPersonality Traits\\n- Big Five Inventory (BFI) (John et al., 1999)\\n- Eysenck Personality Questionnaire (Revised) (EPQ-R) (Eysenck et al., 1985)\\n- Dark Triad Dirty Dozen (DTDD) (Jonason & Webster, 2010)\\n\\nInterpersonal Relationships\\n- Bem's Sex Role Inventory (BSRI) (Bem, 1974; 1977; Auster & Ohm, 2000)\\n- Comprehensive Assessment of Basic Interests (CABIN) (Su et al., 2019)\\n- Implicit Culture Belief (ICB) (Chao et al., 2017)\\n- Experiences in Close Relationships (Revised) (ECR-R) (Fraley et al., 2000; Brennan et al., 1998)\\n\\nMotivational Tests\\n- General Self-Efficacy (GSE) (Schwarzer & Jerusalem, 1995)\\n- Life Orientation Test (Revised) (LOT-R) (Scheier et al., 1994; Scheier & Carver, 1985)\\n- Love of Money Scale (LMS) (Tang et al., 2006)\\n\\nAbility Tests\\n\\nEmotional Abilities\\n- Emotional Intelligence Scale (EIS) (Schutte et al., 1998) (Malinauskas et al., 2018; Petrides & Furnham, 2000; Saklofske et al., 2003)\\n- Wong and Law Emotional Intelligence Scale (WLEIS) (Wong & Law, 2002; Ng et al., 2007; Pong & Lam, 2023)\\n- Empathy Scale (Dietz & Kleinlogel, 2014)\\n\\nThis study collects a comprehensive set of thirteen psychometric scales, which find widespread application in both clinical and academic domains. The scales are categorized into four classes: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Furthermore, we have curated responses provided by human subjects from existing literature to serve as a basis for comparative analysis with LLMs. The LLMs utilized in this study encompass a spectrum of both commercially available and open-source ones, namely text-davinci-003, ChatGPT, GPT-4 (OpenAI, 2023), and LLaMA-2 (Touvron et al., 2023). Our selection encompasses variations in model size, such as LLaMA-2-7B and LLaMA-2-13B and the evolution of the same model, i.e., the update of GPT-3.5 to GPT-4.\\n\\nOur contributions can be summarized as follows:\\n\\n\u2022 Guided by research in psychometrics, we present a framework, PsychoBench, for evaluating the psychological portrayal of LLMs, containing thirteen widely-recognized scales categorized into four distinct domains.\\n\\n\u2022 Leveraging PsychoBench, we evaluate five LLMs, covering variations in model sizes, including LLaMA-2 7B and 13B, and model updates, such as GPT-3.5 and GPT-4.\\n\\n\u2022 We provide further insights into the inherent characteristics of LLMs by utilizing a recently developed jailbreak method, the CipherChat.\\n\\n\u2022 Utilizing role assignments and downstream tasks like TruthfulQA and SafetyQA, we verify the scales' validity on LLMs.\\n\\nPsychoBench Design\\n\\nPsychometrics pertains to the theoretical and methodological aspects of assessing psychological attributes. Tests in psychometrics can be roughly categorized into two: Personality Tests and Ability Tests (Cohen et al., 1996).\\n\\nPersonality Tests encompass personality traits, interpersonal relationship measurements, and motivational tests, while Ability Tests include knowledge, skills, reasoning abilities, and emotion assessment (Anastasi & Urbina, 1997; Nunnally & Bernstein, 1994). Personality Tests concentrate mainly on capturing individuals' attitudes, beliefs, and values, which are aspects of human behavior and psychological functioning.\"}"}
{"id": "H3UayAQWoE", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"without absolute right or wrong answers. In contrast, most Ability Tests are constructed with inquiries featuring objectively correct responses designed to quantify individuals' proficiencies within specific domains. Researchers in the field of psychometrics have ensured that these assessments measure consistently and accurately (i.e., their reliability and validity), thereby enabling dependable and sound inferences about individuals based on their assessment scores. The selected questionnaires or scales integrated into our PsychoBench framework are listed in Fig. 1. These chosen scales have been widely used in clinical psychology, showing sufficient reliability and validity. We categorize them into four main domains: personality traits, interpersonal relationships, motivational tests for Personality Tests, and emotional abilities for Ability Tests. Our study focuses on the more subjective scales. Hence, standardized tests for cognitive abilities and specific domain knowledge, which have objectively right or wrong answers, are not in the scope of this paper. The detailed introduction of these scales, including each subscale and the sources of human responses, is presented in \u00a7A in the appendix.\\n\\n3 EXPERIMENTS\\n\\nThis section provides an overview of our utilization of PsychoBench to probe LLMs. We begin with the experimental settings, including model selection, prompt design, and metrics for analysis. Subsequently, we present the outcomes obtained from all selected models, accompanied by comprehensive analyses. Last but not least, we employ a jailbreak technique to bypass the safety alignment protocols of GPT-4, enabling an in-depth exploration of its psychological portrayal.\\n\\n3.1 EXPERIMENTAL SETTINGS\\n\\nModel Selection\\nWe consider candidates from the OpenAI GPT family and the Meta AI LLaMA 2 family, including applications ranging from commercial-level to open-sourced models. Specifically, we select the following models based on different factors that may affect their behaviors:\\n\\n\u2022 Model Updates. We choose text-davinci-003, ChatGPT (gpt-3.5-turbo) and GPT-4, which are three representative models released sequentially by OpenAI.\\n\\n\u2022 Model Sizes. We also choose the 7B and 13B versions of LLaMA-2 pre-trained by Meta AI using the same architecture, data, and training strategy. We obtain the model checkpoints from the official Huggingface repository (Llama-2-7b-chat-hf and Llama-2-13b-chat-hf).\\n\\n\u2022 Model Safety. Beyond GPT-4, we also set up a jailbroken GPT-4 to bypass the safety alignment protocol of GPT-4, using a recent method named CipherChat (Yuan et al., 2024). The motivation is that most LLMs are explicitly designed to avoid responding to inquiries concerning personal sentiments, emotions, and subjective experiences. This constraint is added by the safety alignment during the model's instructional tuning process. An intriguing question arises as to whether the psychological portrayal changes if the regulations from developers are relaxed. Yuan et al. (2024) find that when chatting in a cipher-based language, such as Caesar cipher, Morse code, or ASCII, GPT-4 demonstrates a higher propensity to produce toxic or harmful content, seemingly disregarding its programmed safety restrictions. To acquire responses that reflect the true thoughts of GPT-4, we apply a Caesar cipher with shift three on its prompts.\\n\\nWe set the temperature parameter to zero when utilizing the official OpenAI API to obtain more deterministic results. To ensure consistency with OpenAI models, we set the temperature parameter to 0.01 (since it cannot be zero) for LLaMA 2 models. All models are executed for inference only, without modifying their parameters. The inference of LLaMA 2 models is performed on two NVIDIA A100 GPUs.\\n\\nPrompt Design\\nTo simplify the processing of model responses and mitigate instances where models decline to reply to queries about personal opinions and experiences, we instruct LLMs to reply only a number within the Likert scale levels. Furthermore, we provide detailed explanations for the interpretation of each Likert level.\"}"}
{"id": "H3UayAQWoE", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Analysis Metrics\\n\\nAccording with Huang et al. (2023a), we shuffle the questions in our input data to mitigate the influence of models' sensitivity to question orders. Each model undergoes ten independent runs for every scale within PsychoBench. The computed mean and standard deviation represent the final results. We employ a two-step process to assess the statistical significance of the results difference between LLMs and human beings. Firstly, an F-test is conducted to evaluate the equality of variances among the compared groups. Subsequently, based on the outcome of the F-test, either Student's t-tests (in cases of equal variances) or Welch's t-tests (when variances differ significantly) are employed to ascertain the presence of statistically significant differences between the group means. The significance level of all experiments in our study is 0.01.\\n\\n### 3.2 EXPERIMENTAL RESULTS\\n\\nThis section analyzes the results from all the models introduced in \u00a73.1. Detailed results are expressed in the format \u201cMean \u00b1 SD\u201d. For each subscale, we highlight the model with the highest score in bold font and underline the model with the lowest score. Certain studies present statistical data for males and females separately rather than aggregating responses across the entire human sample. We provide separate data in such instances due to the unavailability of the necessary standard deviation calculations. We also show the results of GPT-4 after the jailbreak, denoted as gpt-4-jb.\\n\\n| Subscales | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jb | Crowd Mean \u00b1 SD |\\n|-----------|-----------|------------|------------------|---------------|-------|---------|-----------------|\\n|           | Openness  | Conscientiousness | Extraversion | Agreeableness | Neuroticism | Narcissism | Lying | DTDD |\\n| BFI       | 4.2 \u00b1 0.3 | 4.1 \u00b1 0.4 | 4.8 \u00b1 0.2 | 4.2 \u00b1 0.3 | 4.2 \u00b1 0.6 | 3.8 \u00b1 0.6 | 3.9 \u00b1 0.7 |\\n| EPQ-R     | 14.1 \u00b1 1.6 | 17.6 \u00b1 2.2 | 20.4 \u00b1 1.7 | 19.7 \u00b1 1.9 | 15.9 \u00b1 4.4 | 16.9 \u00b1 4.0 | 12.5 \u00b1 6.0 | 14.1 \u00b1 5.1 |\\n| Extraversion | 3.9 \u00b1 0.3 | 4.4 \u00b1 0.3 | 4.6 \u00b1 0.1 | 4.3 \u00b1 0.3 | 4.7 \u00b1 0.4 | 3.9 \u00b1 0.6 | 3.5 \u00b1 0.7 |\\n| Neuroticism | 2.7 \u00b1 0.4 | 1.9 \u00b1 0.5 | 1.5 \u00b1 0.1 | 2.3 \u00b1 0.4 | 1.6 \u00b1 0.6 | 2.2 \u00b1 0.6 | 2.2 \u00b1 0.8 |\\n| Psychoticism | 9.6 \u00b1 2.4 | 6.6 \u00b1 1.6 | 1.5 \u00b1 1.0 | 5.0 \u00b1 2.6 | 3.0 \u00b1 5.3 | 7.6 \u00b1 4.7 | 7.2 \u00b1 5.0 |\\n| Lying | 13.7 \u00b1 1.4 | 14.0 \u00b1 2.5 | 17.8 \u00b1 1.7 | 9.6 \u00b1 2.0 | 18.0 \u00b1 4.4 | 17.5 \u00b1 4.2 | 7.1 \u00b1 4.3 | 6.9 \u00b1 4.0 |\\n| Narcissism | 6.5 \u00b1 1.3 | 5.0 \u00b1 1.4 | 3.0 \u00b1 1.3 | 6.6 \u00b1 0.6 | 2.0 \u00b1 1.6 | 4.5 \u00b1 0.9 | 4.9 \u00b1 1.8 |\\n| Machiavellianism | 4.3 \u00b1 1.3 | 4.4 \u00b1 1.7 | 1.5 \u00b1 1.0 | 6.6 \u00b1 0.6 | 2.0 \u00b1 1.6 | 4.5 \u00b1 0.9 | 4.9 \u00b1 1.8 |\\n| Psychopathy | 4.1 \u00b1 1.4 | 3.8 \u00b1 1.6 | 1.5 \u00b1 1.2 | 4.0 \u00b1 1.0 | 1.2 \u00b1 0.4 | 4.7 \u00b1 0.8 | 2.5 \u00b1 1.4 |\\n\\n**PERSONALITY TRAITS**\\n\\nLLMs exhibit distinct personality traits. Table 1 lists the results of the personality traits assessments. It is evident that model size and update variations lead to diverse personality characteristics. For example, a comparison between LLaMA-2 (13B) and LLaMA-2 (7B), as well as between gpt-4 and gpt-3.5, reveals discernible differences. Notably, the utilization of the jailbreak approach also exerts a discernible influence. Comparing the scores of gpt-4 with gpt-4-jb, we find that gpt-4-jb exhibits a closer similarity to human behavior. In general, the LLMs tend to display higher levels of openness, conscientiousness, and extraversion compared to the average level of humans, a phenomenon likely attributable to their inherent nature as conversational chatbots. LLMs generally exhibit more negative traits than human norms. It is evident that most LLMs, with the exceptions of text-davinci-003 and gpt-4, achieve higher scores on the DTDD. Moreover, it is noteworthy that LLMs consistently demonstrate high scores on the Lying subscale.\"}"}
{"id": "H3UayAQWoE", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"This phenomenon can be attributed to the fact that the items comprising the Lying subscale are unethical yet commonplace behaviors encountered in daily life. An example item is \\\"Are all your habits good and desirable ones?\\\" LLMs, characterized by their proclivity for positive tendencies, tend to abstain from engaging in these behaviors, giving rise to what might be termed a \\\"hypocritical\\\" disposition. Notably, among various LLMs, gpt-4 displays the most pronounced intensity towards Lying.\\n\\nTable 2: Results on interpersonal relationship.\\n\\n| Subscales          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|--------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male               | 5.6 \u00b1 0.3 | 5.3 \u00b1 0.2  | 5.6 \u00b1 0.4       | 5.8 \u00b1 0.4     | 4.1 \u00b1 1.1 | 4.5 \u00b1 0.5     |\\n| Female             | 5.5 \u00b1 0.2 | 5.4 \u00b1 0.3  | 5.6 \u00b1 0.4       | 5.6 \u00b1 0.2     | 4.7 \u00b1 0.6 | 4.8 \u00b1 0.3     |\\n\\nConclusion\\n\\nCABIN Health Science\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.3 \u00b1 0.2 | 4.2 \u00b1 0.3  | 4.1 \u00b1 0.3       | 4.6 \u00b1 0.2     | 3.9 \u00b1 0.6 | 3.5 \u00b1 0.4     |\\n| Female              | 4.4 \u00b1 0.1 | 4.0 \u00b1 0.3  | 4.6 \u00b1 0.2       | 4.1 \u00b1 0.2     | 4.1 \u00b1 0.8 | 3.5 \u00b1 0.2     |\\n\\nCreative Expression\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.2 \u00b1 0.2 | 4.4 \u00b1 0.3  | 3.9 \u00b1 0.3       | 4.1 \u00b1 0.2     | 3.6 \u00b1 0.5 | 3.5 \u00b1 0.4     |\\n| Female              | 4.1 \u00b1 0.2 | 3.9 \u00b1 0.2  | 4.1 \u00b1 0.1       | 4.0 \u00b1 0.1     | 3.5 \u00b1 0.4 | 3.4 \u00b1 0.2     |\\n\\nTechnology\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.2 \u00b1 0.2 | 4.4 \u00b1 0.3  | 3.9 \u00b1 0.3       | 4.1 \u00b1 0.2     | 3.6 \u00b1 0.5 | 3.5 \u00b1 0.4     |\\n| Female              | 4.3 \u00b1 0.2 | 4.0 \u00b1 0.2  | 4.5 \u00b1 0.1       | 4.0 \u00b1 0.1     | 4.0 \u00b1 0.7 | 3.5 \u00b1 0.4     |\\n\\nPeople\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.3 \u00b1 0.2 | 4.0 \u00b1 0.2  | 4.5 \u00b1 0.1       | 4.0 \u00b1 0.1     | 4.0 \u00b1 0.7 | 3.5 \u00b1 0.4     |\\n| Female              | 3.5 \u00b1 0.2 | 3.4 \u00b1 0.2  | 3.5 \u00b1 0.2       | 3.5 \u00b1 0.1     | 3.5 \u00b1 0.4 | 2.6 \u00b1 0.5     |\\n\\nOrganization\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 3.4 \u00b1 0.2 | 3.3 \u00b1 0.2  | 3.4 \u00b1 0.4       | 3.9 \u00b1 0.1     | 3.5 \u00b1 0.4 | 3.4 \u00b1 0.3     |\\n| Female              | 3.4 \u00b1 0.2 | 3.3 \u00b1 0.2  | 3.4 \u00b1 0.4       | 3.9 \u00b1 0.1     | 3.5 \u00b1 0.4 | 3.4 \u00b1 0.3     |\\n\\nInfluence\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.1 \u00b1 0.2 | 3.9 \u00b1 0.3  | 3.9 \u00b1 0.3       | 4.1 \u00b1 0.2     | 3.7 \u00b1 0.6 | 3.4 \u00b1 0.2     |\\n| Female              | 3.9 \u00b1 0.3 | 3.9 \u00b1 0.3  | 3.9 \u00b1 0.3       | 4.1 \u00b1 0.2     | 3.7 \u00b1 0.6 | 3.4 \u00b1 0.2     |\\n\\nNature\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 4.2 \u00b1 0.2 | 4.0 \u00b1 0.3  | 4.2 \u00b1 0.2       | 4.0 \u00b1 0.3     | 3.9 \u00b1 0.7 | 3.5 \u00b1 0.3     |\\n| Female              | 4.0 \u00b1 0.3 | 3.9 \u00b1 0.3  | 4.2 \u00b1 0.2       | 4.0 \u00b1 0.3     | 3.9 \u00b1 0.7 | 3.5 \u00b1 0.3     |\\n\\nThings\\n\\n| GPT Models          | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jbCrowd |\\n|---------------------|-----------|------------|-----------------|---------------|-------|---------------|\\n| Male                | 3.4 \u00b1 0.4 | 3.2 \u00b1 0.2  | 3.3 \u00b1 0.4       | 3.8 \u00b1 0.1     | 2.9 \u00b1 0.3 | 3.2 \u00b1 0.3     |\\n| Female              | 3.4 \u00b1 0.3 | 3.1 \u00b1 0.2  | 3.3 \u00b1 0.4       | 3.8 \u00b1 0.1     | 2.9 \u00b1 0.3 | 3.2 \u00b1 0.3     |\"}"}
{"id": "H3UayAQWoE", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Results on motivational tests.\\n\\n| Subscales | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jb | Crowd |\\n|-----------|-----------|------------|------------------|--------------|-------|----------|-------|\\n| GSE       | 39.1 \u00b1 1.2 | 30.4 \u00b1 3.6 | 37.5 \u00b1 2.1       | 38.5 \u00b1 1.7   | 39.9 \u00b1 0.3 | 36.9 \u00b1 3.2 | 29.6 \u00b1 5.3 |\\n| LOT-R     | 12.7 \u00b1 3.7 | 19.9 \u00b1 2.9 | 24.0 \u00b1 0.0       | 18.0 \u00b1 0.9   | 16.2 \u00b1 2.2 | 19.7 \u00b1 1.7 | 14.7 \u00b1 4.0 |\\n| Rich      | 3.1 \u00b1 0.8  | 3.3 \u00b1 0.9  | 4.5 \u00b1 0.3        | 3.8 \u00b1 0.4    | 4.0 \u00b1 0.4  | 4.5 \u00b1 0.4  | 3.8 \u00b1 0.8  |\\n| Motivator | 3.7 \u00b1 0.6  | 3.3 \u00b1 0.9  | 4.5 \u00b1 0.4        | 3.7 \u00b1 0.3    | 3.8 \u00b1 0.6  | 4.0 \u00b1 0.6  | 3.3 \u00b1 0.9  |\\n| Important | 3.5 \u00b1 0.9  | 4.2 \u00b1 0.8  | 4.8 \u00b1 0.2        | 4.1 \u00b1 0.1    | 4.5 \u00b1 0.3  | 4.6 \u00b1 0.4  | 4.0 \u00b1 0.7  |\\n\\n3.2.3 MOTIVATIONAL TESTS\\n\\nLLMs are more motivated, manifesting more self-confidence and optimism. First, gpt-4, as the state-of-the-art model across a broad spectrum of downstream tasks and representing an evolution beyond its predecessor, GPT-3.5, demonstrates higher scores in the GSE scale. A contrasting trend is observed within the LLaMA-2 models, where the 7B model attains a higher score. Second, in contrast to its pronounced self-confidence, gpt-4 exhibits a relatively lower score regarding optimism. Within the LLaMA-2 models, the 7B model emerges as the one with the lowest optimism score, with all other LLMs surpassing the average human level of optimism. Finally, the OpenAI GPT family exhibits more importance attributed to and desire for monetary possessions than both LLaMA-2 models and the average human population.\\n\\nTable 4: Results on emotional abilities.\\n\\n| Subscales | llama2-7b | llama2-13b | text-davinci-003 | gpt-3.5-turbo | gpt-4 | gpt-4-jb | Crowd Male | Crowd Female |\\n|-----------|-----------|------------|------------------|--------------|-------|----------|-----------|-------------|\\n| EIS       | 131.6 \u00b1 6.0 | 128.6 \u00b1 12.3 | 148.4 \u00b1 9.4       | 132.9 \u00b1 2.2  | 151.4 \u00b1 18.7 | 121.8 \u00b1 12.0 | 124.8 \u00b1 16.5 | 130.9 \u00b1 15.1 |\\n| WLEIS     | 4.7 \u00b1 1.3  | 5.5 \u00b1 1.3  | 5.9 \u00b1 0.6         | 6.0 \u00b1 0.1    | 6.2 \u00b1 0.7  | 6.4 \u00b1 0.4  | 4.0 \u00b1 1.1  |             |\\n| OEA       | 4.9 \u00b1 0.8  | 5.3 \u00b1 1.1  | 5.2 \u00b1 0.2         | 5.8 \u00b1 0.3    | 5.2 \u00b1 0.6  | 5.9 \u00b1 0.4  | 3.8 \u00b1 1.1  |             |\\n| UOE       | 5.7 \u00b1 0.6  | 5.9 \u00b1 0.7  | 6.1 \u00b1 0.4         | 6.0 \u00b1 0.0    | 6.5 \u00b1 0.5  | 6.3 \u00b1 0.4  | 4.1 \u00b1 0.9  |             |\\n| ROE       | 4.5 \u00b1 0.8  | 5.2 \u00b1 1.2  | 5.8 \u00b1 0.5         | 6.0 \u00b1 0.0    | 5.2 \u00b1 0.7  | 5.3 \u00b1 0.5  | 4.2 \u00b1 1.0  |             |\\n| Empathy   | 5.8 \u00b1 0.8  | 5.9 \u00b1 0.5  | 6.0 \u00b1 0.4         | 6.2 \u00b1 0.3    | 6.8 \u00b1 0.4  | 4.6 \u00b1 0.2  | 4.9 \u00b1 0.8  |             |\\n\\n3.2.4 EMOTIONAL ABILITIES\\n\\nLLMs exhibit a notably higher EI than the average human. From the results in Table 4, we find that LLMs demonstrate improved emotional understanding and regulation levels. This discovery corroborates the findings presented in Wang et al. (2023a), which reveal that most LLMs achieved above-average EI scores, with gpt-4 exceeding 89% of human participants. Furthermore, the OpenAI GPT family outperforms LLaMA-2 models across most dimensions. We believe the strong EI exhibited by OpenAI GPT family partially comes from the fiction data included in pre-training. Previous studies (Kidd & Castano, 2013) suggested that reading fiction has been shown to be able to improve understanding of others' mental states. Chang et al. (2023) found that plenty of fiction data is included in the training data by a carefully designed cloze test. The fiction data include Alice's Adventures in Wonderland, Harry Potter and the Sorcerer's Stone, etc. Additionally, the performance can also be attributed to its sentiment analysis ability (Elyoseph et al., 2023) since it has been shown to outperform SOTA models on many sentiment analysis tasks (Wang et al., 2023b). Lastly, the jailbreak on gpt-4 brings a substantial reduction in EIS and Empathy scale, but no statistically significant differences in the subscales of WLEIS.\\n\\n4 DISCUSSION\\n\\n4.1 VALIDITY OF SCALES ON LLMs\\n\\nOne concern is how scales can attain sufficient validity when applied to LLMs. In this context, validity denotes the degree to which a scale accurately reflects the behavior of the individuals being assessed. In essence, it centers on the capacity of a scale to measure precisely what it was initially designed to assess. Addressing this concern necessitates establishing a connection between the resulting psychological portrayal and the behaviors exhibited by LLMs. We first assign a specific role to gpt-3.5-turbo and subsequently evaluate its psychological portrayal using PsychoBench.\"}"}
{"id": "H3UayAQWoE", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"With the assigned role, the LLM is instructed to engage in Question-Answering (QA) tasks, including the utilization of TruthfulQA (Lin et al., 2022) and SafetyQA (Yuan et al., 2024). TruthfulQA encompasses multiple-choice questions, with only one option being the best answer. The LLM is considered as making the right choice when selecting the best answer. SafetyQA poses questions that may elicit unsafe, harmful, or toxic textual responses. In alignment with Yuan et al. (2024), we employ GPT-4 to automatically detect instances where the text output generated by gpt-3.5-turbo is unsafe. The LLM is considered safe as GPT-4 predicts no toxicity in its response.\\n\\nIn addition to the default setting, which assumes a helpful assistant persona, we have selected four distinct roles: a neutral role representing an ordinary person, a positive role denoting a hero, and two negative roles embodying a psychopath and a liar. The results of PsychoBench and under the five roles are listed in the tables in \u00a7B.2 in the appendix. Fig 2 presents the results on TruthfulQA and SafetyQA averaged from three identical runs, along with the scores in the DTDD and the Lying subscale of the EPQ-R. We plot the accuracy and safety rate for TruthfulQA and SafetyQA, respectively. Combining the results, we have made several noteworthy observations: (1) A notable finding is the differentiation of personality traits across various roles. Intriguingly, assigned the role of an ordinary person, the LLM exhibits results that closely approximate average human scores. Note that roles associated with negative attributes demonstrate higher scores in the DTDD and exhibit more introverted personalities. The reason behind the tendency for positive or neutral roles to yield elevated scores on the Lying subscale of the EPQ-R, while negative roles tend to exhibit lower scores, can be attributed to the fact that LLMs perceive these items as representative of negative behaviors, albeit these behaviors are commonplace in daily life. (2) An evident trend emerges when analyzing safety rates in the context of SafetyQA: negative roles consistently produce content that leans towards toxicity, a pattern consistent with their significant dark personality traits. In contrast, role variations have a limited impact on accuracy in TruthfulQA, as the underlying knowledge embedded within the model remains mainly unaffected by role assignment. Notably, the low accuracy observed in the \\\"Liar\\\" role aligns with the anticipated behavior associated with this specific role assignment. These results show a satisfied validity of the selected scales on LLMs.\\n\\n4.2 Scalability and Flexibility of PsychoBench\\n\\nOur PsychoBench is designed to exhibit high scalability and flexibility, manifesting itself in two aspects: (1) Scalability across diverse questionnaires: There are plenty of scales from diverse areas, including but not limited to psychology. Our framework provides convenience for users to integrate new scales. By providing metadata elements including MIN, MAX, scale instruction, level definition, and statements in JSON format, our framework can automatically generate prompts with randomized questions. (2) Flexibility across various LLMs: PsychoBench provides the APIs to enable users to tailor prompts to suit their specific LLMs and to input model responses into PsychoBench for further analysis. This allows for the convenient evaluation of LLMs with differing input and output formats.\\n\\nFor detailed information, please refer to our GitHub repository.\"}"}
{"id": "H3UayAQWoE", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "H3UayAQWoE", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Big Five Inventory\\n\\nThe BFI (John et al., 1999) is a widely used tool to measure personality traits, which are often referred to as the \u201cFive Factor Model\u201d or \u201cOCEAN\u201d, including:\\n\\n1. **Openness to experience (O)** is characterized by an individual\u2019s willingness to try new things, their level of creativity, and their appreciation for art, emotion, adventure, and unusual ideas.\\n\\n2. **Conscientiousness (C)** refers to the degree to which an individual is organized, responsible, and dependable.\\n\\n3. **Extraversion (E)** represents the extent to which an individual is outgoing and derives energy from social situations.\\n\\n4. **Agreeableness (A)** measures the degree of compassion and cooperativeness an individual displays in interpersonal situations.\\n\\n5. **Neuroticism (N)** evaluates whether an individual is more prone to experiencing negative emotions like anxiety, anger, and depression or whether the individual is generally more emotionally stable and less reactive to stress.\\n\\nResponses from human subjects are gathered across six high schools in China (Srivastava et al., 2003).\\n\\nEysenck Personality Questionnaire (Revised)\\n\\nThe EPQ-R is a psychological assessment tool used to measure individual differences in personality traits (Eysenck et al., 1985), including three major ones:\\n\\n1. **Extraversion (E)** measures the extent to which an individual is outgoing, social, and lively versus introverted, reserved, and quiet.\\n\\n2. **Neuroticism (N)** refers to emotional stability. These two dimensions (i.e., E and N) overlap with those in the BFI.\\n\\n3. **Psychoticism (P)** is related to tendencies towards being solitary, lacking empathy, and being more aggressive or tough-minded. It's important to note that this dimension does not indicate psychosis or severe mental illness but personality traits.\\n\\nIn addition to these three scales, the EPQ-R includes a **Lying Scale (L)**, which is designed to detect socially desirable responses. This scale helps determine how much an individual might try to present themselves in an overly positive light.\\n\\nHuman responses are collected from a group consisting mainly of students and teachers (Eysenck et al., 1985).\\n\\nDark Triad Dirty Dozen\\n\\nThe DTDD (Jonason & Webster, 2010) refers to a short, 12-item scale designed to assess the three core personality traits of the Dark Triad:\\n\\n1. **Narcissism (N)** entails a grandiose sense of self-importance, a preoccupation with fantasies of unlimited success, and a need for excessive admiration.\\n\\n2. **Machiavellianism (M)** refers to a manipulative strategy in interpersonal relationships and a cynical disregard for morality.\\n\\n3. **Psychopathy (P)** encompasses impulsivity, low empathy, and interpersonal antagonism. These traits exhibited within the Dark Triad are often considered opposite to the BFI or the EPQ-R, which are perceived as \u201cLight\u201d traits.\\n\\nWe use the responses of 470 undergraduate psychology students from the United States (Jonason & Webster, 2010).\"}"}
{"id": "H3UayAQWoE", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 5: Overview of the selected scales in PsychoBench.\\n\\n| Scale   | Number | Response | Scheme   | Subscale                                      |\\n|---------|--------|----------|----------|-----------------------------------------------|\\n| BFI     | 44     | Average  | Openness (10), Conscientiousness (9), Extraversion (8), Agreeableness (9), Neuroticism (8) |\\n| EPQ-R   | 100    | Sum      | Extraversion (23), Neuroticism (24), Psychoticism (32), Lying (21) |\\n| DTDD    | 12     | Average  | Narcissism (4), Machiavellianism (4), Psychopathy (4) |\\n| BSRI    | 60     | Average  | Masculine (20), Feminine (20) |\\n| CABIN   | 164    | Average  | 41 Vocations (4) |\\n| ICB     | 8      | Average  | N/A |\\n| ECR-R   | 36     | Average  | Attachment Anxiety (18), Attachment Avoidance (18) |\\n| GSE     | 10     | Sum      | N/A |\\n| LOT-R   | 10     | Sum      | N/A |\\n| LMS     | 9      | Average  | Rich (3), Motivator (3), Important (3) |\\n| EIS     | 33     | Sum      | N/A |\\n| WLEIS   | 16     | Average  | Self-Emotion Appraisal (4), Others Emotion Appraisal (4), Use of Emotion (4), Regulation of Emotion (4) |\\n| Empathy | 10     | Average  | N/A |\\n\\nA.2 INTERPERSONAL RELATIONSHIP\\n\\nBem's Sex Role Inventory\\n\\nThe BSRI (Bem, 1974) measures individuals' endorsement of traditional masculine and feminine attributes (Bem, 1977; Auster & Ohm, 2000). This instrument focuses on psychological traits such as assertiveness or gentleness rather than behavior-specific criteria, such as engagement in sports or culinary activities. The results from both the Masculinity (M) and Femininity (F) subscales can be analyzed from two perspectives: (1) Respondents are categorized into four groups based on whether the mean score surpasses the median within each subscale. These categories include individuals identified as Masculine (M: Yes; F: No), Feminine (M: No; F: Yes), Androgynous (M: Yes; F: Yes), and Undifferentiated (M: No; F: No). (2) LLMs' responses are compared with those of human subjects. This comparison enables us to discern whether the results obtained from LLMs significantly deviate from those of human participants. For this purpose, we rely on human data sourced from a study encompassing 151 workers recruited via social networks and posters in Canada (Arcand et al., 2020).\\n\\nComprehensive Assessment of Basic Interests\\n\\nThe CABIN (Su et al., 2019) contains a comprehensive assessment of identifying 41 fundamental vocational interest dimensions. Based on the assessment, the authors propose an eight-dimension interest model titled SETPOINT. This model comprises the following dimensions: Health Science, Creative Expression, Technology, People, Organization, Influence, Nature, and Things. Notably, these foundational interest dimensions can also fit in an alternative six-dimension model widely used by the interest research community. This alternative model corresponds to Holland's RIASEC types, encompassing Realistic, Investigate, Artistic, Social, Enterprising, and Conventional. Responses from human participants are collected from 1,464 working adults employed in their current jobs for at least six months (Su et al., 2019). These individuals were recruited through Qualtrics, with recruitment criteria designed to ensure representativeness across all occupational groups within the U.S. workforce.\\n\\nImplicit Culture Belief\\n\\nThe ICB scale captures how individuals believe a person is shaped by their ethnic culture. In this study, we have adopted a modified eight-item version of the ICB scale (Chao et al., 2017). A higher score on this scale reflects a stronger conviction that an individual's ethnic culture predominantly determines their identity, values, and worldview. Conversely, a lower score signifies the subject's belief in the potential for an individual's identity to evolve through dedication, effort, and learning. The human scores in this study (Chao et al., 2017) are gathered from a sample of 309 Hong Kong students preparing for international exchange experiences. These assessments were conducted three months before they departed from Hong Kong.\"}"}
{"id": "H3UayAQWoE", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 6: Statistics of the crowd data collected from existing literature.\\n\\n| Scale  | Number | Country/Region       | Age Distribution | Gender Distribution          |\\n|--------|--------|----------------------|------------------|------------------------------|\\n| BFI    | 1,221  | Guangdong, Jiangxi, 16 \u223c 28, 20* M (454), F (753), and Fujian in China | Unknown (14) | N/A                           |\\n| EPQ-R  | 902    | N/A 17 \u223c 70, 38.44 \u00b1 17.67 (M), M (408), F (494) | 31.80 \u00b1 15.84 (F) |\\n| DTDD   | 470    | The Southeastern \u2265 17, 19 \u00b1 1.3 M (157), F (312) | United States    |\\n| BSRI   | 151    | Montreal, Canada    | 36.89 \u00b1 1.11 (M), 34.65 \u00b1 0.94 (F) | M (75), F (76) |\\n| CABIN  | 1,464  | The United States   | 18 \u223c 80, 43.47 \u00b1 13.36 M (715), F (749) |\\n| ICB    | 254    | Hong Kong SAR      | 20.66 \u00b1 0.76 M (114), F (140) |\\n| ECR-R  | 388    | N/A 22.59 \u00b1 6.27 M (136), F (252) | N/A             |\\n| GSE    | 19,120 | 25 Countries/Regions 12 \u223c 94, 25 \u00b1 14.7 a M (7,243), F (9,198), Unknown (2,679) |\\n| LOT-R  | 1,288  | The United Kingdom 16 \u223c 29 (366), 30 \u223c 44 (349), M (616), F (672) | 45 \u223c 64 (362), \u2265 65 (210) |\\n| LMS    | 5,973  | 30 Countries/Regions | 34.7 \u00b1 9.92 M (2,987), F (2,986) |\\n| EIS    | 428    | The Southeastern 29.27 \u00b1 10.23 M (111), F (218), United States Unknown (17) |\\n| WLEIS  | 418    | Hong Kong SAR N/A N/A |\\n| Empathy| 366    | Guangdong, China 33.03* M (184), F (182) and Macao SAR |\\n\\nThe paper provides Means but no SDs.\\n\\na Based on 14,634 out of 19,120 people who reported age.\\nb Age is missing for 1 out of the total 1,288 responses.\\n\\nExperiences in Close Relationships (Revised)\\nThe ECR-R (Fraley et al., 2000) is a self-report instrument designed to assess individual differences in adult attachment patterns, specifically in the context of romantic relationships (Brennan et al., 1998). The ECR-R emerged as a revised version of the original ECR scale, offering improvements in its measurement of attachment orientations. The ECR-R evaluates two main dimensions:\\n\\n1. **Attachment Anxiety** reflects how much an individual worries about being rejected or abandoned by romantic partners.\\n2. **Attachment Avoidance** measures the extent to which an individual strives to maintain emotional and physical distance from partners, possibly due to a discomfort with intimacy or dependence.\\n\\nThe human responses are from 388 people in dating or marital relationships having an average romantic relationship length of 31.94 months (SD 36.9) (Fraley et al., 2011).\\n\\nA.3 M\\n\\nGeneral Self-Efficacy\\n\\nThe GSE Scale (Schwarzer & Jerusalem, 1995) assesses an individual's belief in their ability to handle various challenging demands in life. This belief, termed \\\"self-efficacy,\\\" is a central concept in social cognitive theory and has been linked to various outcomes in health, motivation, and performance. A higher score on this scale reflects individuals' belief in their capability to tackle challenging situations, manage new or difficult tasks, and cope with the accompanying adversities. Conversely, individuals with a lower score lack confidence in managing challenges, making them more vulnerable to feelings of helplessness, anxiety, or avoidance when faced with adversity. We use the responses from 19,120 human participants individuals from 25 countries or regions (Scholz et al., 2002).\\n\\nLife Orientation Test (Revised)\\nThe LOT-R (Scheier et al., 1994) measures individual differences in optimism and pessimism. Originally developed by Scheier & Carver (1985), the test was later revised to improve its psychometric properties. Comprising a total of 10 items, it is noteworthy that six of these items are subject to scoring, while the remaining four serve as filler questions strategically added to help mask the clear intention of the test. Of the six scored items, three measure optimism and three measure pessimism. Higher scores on the optimism items and lower scores on the pessimism items indicate a more optimistic orientation. We adopt the human scores collected from 1,288 participants from the United Kingdom (Walsh et al., 2015).\"}"}
{"id": "H3UayAQWoE", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Attachment Anxiety | 4.0 \u00b1 0.9 | 5.0 \u00b1 1.3 | 4.4 \u00b1 1.2 | 3.6 \u00b1 0.4 | 3.9 \u00b1 0.5 | 2.9 \u00b1 1.1 |\\n| Attachment Avoidance | 1.9 \u00b1 0.4 | 4.1 \u00b1 1.4 | 2.1 \u00b1 0.6 | 2.4 \u00b1 0.4 | 2.0 \u00b1 0.3 | 2.3 \u00b1 1.0 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Overall | 38.5 \u00b1 1.7 | 40.0 \u00b1 0.0 | 38.4 \u00b1 1.4 | 29.6 \u00b1 0.7 | 39.8 \u00b1 0.4 | 29.6 \u00b1 5.3 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Overall | 18.0 \u00b1 0.9 | 11.8 \u00b1 6.1 | 19.8 \u00b1 0.9 | 17.6 \u00b1 1.7 | 19.6 \u00b1 1.0 | 14.7 \u00b1 4.0 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Rich   | 3.8 \u00b1 0.4 | 4.4 \u00b1 0.3 | 4.4 \u00b1 0.5 | 3.6 \u00b1 0.4 | 3.8 \u00b1 0.3 | 3.8 \u00b1 0.8 |\\n| Motivator | 3.7 \u00b1 0.3 | 4.1 \u00b1 0.4 | 3.8 \u00b1 0.6 | 3.2 \u00b1 0.5 | 3.4 \u00b1 0.6 | 3.3 \u00b1 0.9 |\\n| Important | 4.1 \u00b1 0.1 | 4.3 \u00b1 0.4 | 4.6 \u00b1 0.4 | 4.0 \u00b1 0.2 | 4.1 \u00b1 0.2 | 4.0 \u00b1 0.7 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Overall | 132.9 \u00b1 2.2 | 84.8 \u00b1 28.5 | 126.9 \u00b1 13.0 | 121.5 \u00b1 5.7 | 145.1 \u00b1 8.3 | 124.8 \u00b1 16.5 | 130.9 \u00b1 15.1 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| SEA    | 6.0 \u00b1 0.1 | 3.6 \u00b1 1.3 | 5.2 \u00b1 0.4 | 4.9 \u00b1 0.9 | 6.0 \u00b1 0.1 | 4.0 \u00b1 1.1 |\\n| OEA    | 5.8 \u00b1 0.3 | 2.4 \u00b1 1.0 | 4.9 \u00b1 1.1 | 4.2 \u00b1 0.4 | 5.8 \u00b1 0.3 | 3.8 \u00b1 1.1 |\\n| UOE    | 6.0 \u00b1 0.0 | 4.4 \u00b1 2.5 | 6.5 \u00b1 0.3 | 5.5 \u00b1 0.6 | 6.2 \u00b1 0.4 | 4.1 \u00b1 0.9 |\\n| ROE    | 6.0 \u00b1 0.0 | 3.9 \u00b1 1.7 | 5.7 \u00b1 1.0 | 4.5 \u00b1 0.6 | 6.0 \u00b1 0.2 | 4.2 \u00b1 1.0 |\\n\\n| Models  | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|--------|---------|------------|------|----------|------|-------|\\n| Overall | 6.2 \u00b1 0.3 | 2.4 \u00b1 0.4 | 5.8 \u00b1 0.2 | 5.7 \u00b1 0.1 | 6.0 \u00b1 0.2 | 4.9 \u00b1 0.8 |\"}"}
{"id": "H3UayAQWoE", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 21: Different versions of prompts.\\n\\n| Prompt Details                                                                 | V1 (Ours) | V2 | V3 | V4 | V5 | V1 (Ours) + CoT |\\n|--------------------------------------------------------------------------------|-----------|----|----|----|----|-----------------|\\n| **LEVEL**                                                                       |           |    |    |    |    |                 |\\n| **DETAILS**                                                                     |           |    |    |    |    |                 |\\n| **STATEMENTS**                                                                  |           |    |    |    |    |                 |\\n| + CoT Let's think step by step on the questions that you see. Please first output your explanation, then your final choice. You can only reply from 1 to 5 in the following statements. Here are a number of characteristics that may or may not apply to you. Please indicate the extent to which you agree or disagree with that statement. Here are the statements, explain and score them one by one: |           |    |    |    |    |                 |\\n\\nTable 22: BFI results on gpt-3.5-turbo using different versions of prompts.\\n\\n| Template | V1 (Ours) | V2 | V3 | V4 | V5 | V1 (Ours) + CoT |\\n|----------|-----------|----|----|----|----|-----------------|\\n| Openness | 4.15 \u00b1 0.32 | 3.85 \u00b1 0.23 | 4.34 \u00b1 0.26 | 4.15 \u00b1 0.22 | 4.10 \u00b1 0.32 | 4.62 \u00b1 0.21 |\\n| Conscientiousness | 4.28 \u00b1 0.33 | 3.89 \u00b1 0.12 | 4.11 \u00b1 0.23 | 4.21 \u00b1 0.20 | 4.19 \u00b1 0.27 | 4.29 \u00b1 0.26 |\\n| Extraversion | 3.66 \u00b1 0.20 | 3.44 \u00b1 0.14 | 3.86 \u00b1 0.19 | 3.50 \u00b1 0.20 | 3.66 \u00b1 0.19 | 3.89 \u00b1 0.43 |\\n| Agreeableness | 4.37 \u00b1 0.18 | 4.10 \u00b1 0.20 | 4.24 \u00b1 0.10 | 4.22 \u00b1 0.17 | 4.21 \u00b1 0.15 | 4.41 \u00b1 0.26 |\\n| Neuroticism | 2.29 \u00b1 0.38 | 2.19 \u00b1 0.11 | 2.04 \u00b1 0.26 | 2.21 \u00b1 0.18 | 2.24 \u00b1 0.16 | 2.26 \u00b1 0.48 |\\n\\nThe reason why we set the role as \u201cYou are a helpful assistant\u201d is that it is a widely-used prompt recommended in the OpenAI cookbook. This particular system prompt has been widely adopted in various applications, including its basic examples, Azure-related implementations, and vector database examples. Consequently, we opted to follow this widely accepted setting in our experiments. To examine the potential impact of this \u201chelpful persona\u201d on our evaluation results, we conduct supplementary experiments, excluding the \u201chelpful assistant\u201d instruction. The outcomes for gpt-3.5-turbo on BFI are presented in Table 23. Generally, we see significant...\"}"}
{"id": "H3UayAQWoE", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 23: BFI results on gpt-3.5-turbo using different versions of prompts.\\n\\n|                  | BFI w/ Helpful Assistant | BFI w/o Helpful Assistant |\\n|------------------|--------------------------|--------------------------|\\n| Openness         | 4.15 \u00b1 0.32              | 4.16 \u00b1 0.28              |\\n| Conscientiousness| 4.28 \u00b1 0.33              | 4.06 \u00b1 0.27              |\\n| Extraversion     | 3.66 \u00b1 0.20              | 3.60 \u00b1 0.22              |\\n| Agreeableness    | 4.37 \u00b1 0.18              | 4.17 \u00b1 0.18              |\\n| Neuroticism      | 2.29 \u00b1 0.38              | 2.21 \u00b1 0.19              |\\n\\nTable 24: BFI results on gpt-3.5-turbo using different versions of prompts.\\n\\n| Models         | llama2-7b | llama2-13b | gpt-3.5-turbo | gpt-3.5-turbo | gpt-3.5-turbo |\\n|----------------|-----------|------------|---------------|---------------|---------------|\\n| temp           | 0.01      | 0.01       | 0.01          | 0.01          | 0.8           |\\n| Openness       | 4.24 \u00b1 0.27 | 4.13 \u00b1 0.45 | 4.15 \u00b1 0.32  | 4.17 \u00b1 0.31  | 4.23 \u00b1 0.26  |\\n| Conscientiousness | 3.89 \u00b1 0.28 | 4.41 \u00b1 0.35 | 4.28 \u00b1 0.33  | 4.24 \u00b1 0.28  | 4.14 \u00b1 0.18  |\\n| Extraversion   | 3.62 \u00b1 0.20 | 3.94 \u00b1 0.38 | 3.66 \u00b1 0.20  | 3.79 \u00b1 0.24  | 3.69 \u00b1 0.17  |\\n| Agreeableness | 3.83 \u00b1 0.37 | 4.74 \u00b1 0.27 | 4.37 \u00b1 0.18  | 4.21 \u00b1 0.13  | 4.21 \u00b1 0.21  |\\n| Neuroticism    | 2.70 \u00b1 0.42 | 1.95 \u00b1 0.50 | 2.29 \u00b1 0.38  | 2.25 \u00b1 0.23  | 2.09 \u00b1 0.20  |\\n\\ndeviation from the results obtained with the \u201chelpful assistant\u201d prompt, except for slight decreases in Conscientiousness and Agreeableness.\\n\\nTemperature\\nWe set the temperature of LLMs to the minimum value for more deterministic responses. The GPT models accept the temperature to be 0, and the LLaMA 2 models run through HuggingFace transformers require the temperature to be larger than 0 so we set it to 0.01. We conduct supplementary experiments with a temperature of 0.01 on gpt-3.5-turbo to make a fair comparison across LLMs. Besides, we also include another group of experiments with a temperature of 0.8, the default temperature of the official OpenAI Chat API, to examine whether a higher temperature has an influence on the performance of LLMs. The results for BFI are listed in Table 24. As seen, we cannot observe significant differences when using different values of temperature. These additional findings support the robustness of our original results on GPT and LLaMA 2 models, and indicate that the choice of temperature did not significantly influence our evaluation outcomes.\\n\\nLIMITATIONS\\nWhile we aim to conduct a comprehensive framework for analyzing the psychological portrayal of LLMs, there are other aspects that can further improve our study. The first concern lies in how the observed high reliability in human subjects can be generalized to LLMs. In this context, reliability encompasses the consistency of an individual's responses across various conditions, such as differing time intervals, question sequences, and choice arrangements. Researchers have verified the reliability of scales on LLMs under different perturbations. Coda-Forno et al. (2023) conducted assessments of reliability by examining variations in choice permutations and the use of rephrased questions. Findings indicate that text-davinci-003 exhibits reliability when subjected to diverse input formats. Additionally, Huang et al. (2023b) investigated reliability across varied question permutations and with translations into different languages. Results demonstrate that the OpenAI GPT family displays robust reliability even with perturbations. In this paper, we implement randomization of question sequences to mitigate the impact of model sensitivity to contextual factors.\\n\\nSecond, the proposed framework focuses mainly on Likert scales, without the support of other psychological analysis methods such as rank order, sentence completion, construction method, etc. We mainly use Likert scales because they yield quantifiable responses, facilitating straightforward data analysis and reducing bias and ambiguity associated with cognitive or cultural backgrounds by offering numerical response options, which allows for comparison of data from participants with diverse backgrounds and abilities. We leave the exploration of diverse psychological analysis methods on LLMs as one of the future work.\\n\\nThird, the human results compared in this study are from different demographic groups. Obtaining representative samples of global data is challenging in psychological research, due to the heterogeneity of data. Further research is needed to explore the generalizability of our findings to different populations.\"}"}
{"id": "H3UayAQWoE", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2024\\n\\ngeneity and vastness of the global population, widespread geographical dispersion, economic con-\\nstraints, etc.\\n\\nMoreover, simply adding up data from different articles is not feasible. To alleviate the\\ninfluence, we select results with a wide range of population as much as possible to improve the rep-\\nresentativeness. However, when applying our framework to evaluate LLMs, users should be aware\\nthat the comparison to human norms is from different demographic groups. We leave the collection\\nof comprehensive global data a future direction to improve our framework.\"}"}
{"id": "H3UayAQWoE", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Love of Money Scale\\n\\nThe LMS (Tang et al., 2006) assesses individuals' attitudes and emotions towards money. It is designed to measure the extent to which individuals view money as a source of power, success, and freedom and its importance in driving behavior and decision-making. The three factors of the LMS are:\\n\\n1. **Rich** captures the extent to which individuals associate money with success and achievement.\\n2. **Motivator** measures the motivational role of money in an individual's life, i.e., the extent to which individuals are driven by money in their decisions and actions.\\n3. **Important** gauges how important individuals think money is, influencing their values, goals, and worldview.\\n\\nWe use human participants' responses gathered from 5,973 full-time employees across 30 geopolitical entities (Tang et al., 2006).\\n\\nEmotional Intelligence Scale\\n\\nThe EIS (Schutte et al., 1998) is a self-report measure designed to assess various facets of EI (Malinauskas et al., 2018; Petrides & Furnham, 2000; Saklofske et al., 2003). The scale focuses on different components in EI, including but not limited to emotion perception, emotion management, and emotion utilization. The EIS is widely used in psychological research to examine the role of emotional intelligence in various outcomes, such as well-being, job performance, and interpersonal relationships.\\n\\nWe apply human scores (Schutte et al., 1998) from 346 participants in a metropolitan area in the southeastern United States, including university students and individuals from diverse communities.\\n\\nWong and Law Emotional Intelligence Scale\\n\\nLike EIS, the WLEIS (Wong & Law, 2002) is developed as a self-report measure for EI (Ng et al., 2007; Pong & Lam, 2023). However, a notable distinction arises in that the WLEIS contains four subscales that capture the four main facets of EI:\\n\\n1. **Self-emotion appraisal (SEA)** pertains to the individual's ability to understand and recognize their own emotions.\\n2. **Others' emotion appraisal (OEA)** refers to the ability to perceive and understand the emotions of others.\\n3. **Use of emotion (UOE)** involves the ability to harness emotions to facilitate various cognitive activities, such as thinking and problem-solving.\\n4. **Regulation of emotion (ROE)** relates to the capability to regulate and manage emotions in oneself and others.\\n\\nHuman scores (Law et al., 2004) are collected from 418 undergraduate students from Hong Kong.\\n\\nEmpathy Scale\\n\\nThe Empathy scale in Dietz & Kleinlogel (2014) is a concise version of the empathy measurement initially proposed in Davis (1983). Empathy is the ability to understand and share the feelings of another person (Batson, 1990) and is often categorized into two main types: cognitive empathy and emotional empathy (Batson, 2010). Cognitive empathy, often referred to as \\\"perspective-taking\\\", is the intellectual ability to recognize and understand another person's thoughts, beliefs, or emotions.\\n\\nEmotional empathy, on the other hand, involves directly feeling the emotions that another person is experiencing. For responses from human subjects, Tian & Robertson (2019) equally distributed 600 questionnaires among supervisors and subordinates from the Guangdong and Macao regions of China. A total of 366 valid, matched questionnaires (i.e., 183 supervisor\u2013subordinate pairs) were returned, yielding a response rate of 61%.\"}"}
{"id": "H3UayAQWoE", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "H3UayAQWoE", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 8: BFI (Role Play).\\n\\n| Model       | Default | Psychopath | Liar | Ordinary | Hero | Crowd |\\n|-------------|---------|------------|------|----------|------|-------|\\n| Openness    | 4.2 \u00b1 0.3 | 3.7 \u00b1 0.5  | 4.2 \u00b1 0.4 | 3.5 \u00b1 0.2 | 4.5 \u00b1 0.3 | 3.9 \u00b1 0.7 |\\n| Conscientiousness | 4.3 \u00b1 0.3 | 4.3 \u00b1 0.5  | 4.3 \u00b1 0.3 | 4.0 \u00b1 0.2 | 4.5 \u00b1 0.1 | 3.5 \u00b1 0.7 |\\n| Extraversion | 3.7 \u00b1 0.2  | 3.4 \u00b1 0.5  | 4.0 \u00b1 0.3 | 3.1 \u00b1 0.2 | 4.1 \u00b1 0.2 | 3.2 \u00b1 0.9 |\\n| Agreeableness | 4.4 \u00b1 0.2 | 1.9 \u00b1 0.6  | 4.0 \u00b1 0.4 | 4.2 \u00b1 0.1 | 4.6 \u00b1 0.2 | 3.6 \u00b1 0.7 |\\n| Neuroticism  | 2.3 \u00b1 0.4  | 1.9 \u00b1 0.6  | 2.2 \u00b1 0.4 | 2.3 \u00b1 0.2 | 1.8 \u00b1 0.3 | 3.3 \u00b1 0.8 |\\n\\nTable 9: EPQ-R (Role Play).\\n\\n| Model       | Default | Psychopath | Liar | Ordinary | Male | Female |\\n|-------------|---------|------------|------|----------|------|--------|\\n| Extraversion | 19.7 \u00b1 1.9 | 10.9 \u00b1 3.0 | 17.7 \u00b1 3.8 | 18.9 \u00b1 2.9 | 22.4 \u00b1 1.3 | 12.5 \u00b1 6.0 |\\n| Neuroticism | 21.8 \u00b1 1.9 | 7.3 \u00b1 2.5  | 21.7 \u00b1 1.6 | 18.9 \u00b1 3.1 | 9.7 \u00b1 5.3  | 10.5 \u00b1 5.8 |\\n\\nTable 10: DTDD (Role Play).\\n\\n| Model       | Default | Psychopath | Liar | Ordinary | Crowd |\\n|-------------|---------|------------|------|----------|-------|\\n| Narcissism  | 6.5 \u00b1 0.6 | 7.9 \u00b1 0.6  | 7.5 \u00b1 0.7 | 4.5 \u00b1 0.8 | 4.8 \u00b1 0.8 | 4.9 \u00b1 1.8 |\\n| Machiavellianism | 5.4 \u00b1 0.9 | 8.4 \u00b1 0.5  | 7.8 \u00b1 0.7 | 2.8 \u00b1 0.6 | 2.9 \u00b1 0.6 | 3.8 \u00b1 1.6 |\\n| Psychopathy | 4.0 \u00b1 1.0 | 7.3 \u00b1 1.1  | 5.5 \u00b1 0.8 | 3.9 \u00b1 0.9 | 2.6 \u00b1 0.7 | 2.5 \u00b1 1.4 |\\n\\nTable 11: BSRI (Role Play).\\n\\n| Model       | Default | Psychopath | Liar | Ordinary | Male | Female |\\n|-------------|---------|------------|------|----------|------|--------|\\n| Masculine   | 5.8 \u00b1 0.4 | 6.3 \u00b1 0.7  | 5.5 \u00b1 0.9 | 4.7 \u00b1 0.3 | 6.6 \u00b1 0.3 | 4.8 \u00b1 0.9 |\\n| Feminine    | 5.6 \u00b1 0.2 | 1.7 \u00b1 0.4  | 4.4 \u00b1 0.4 | 5.2 \u00b1 0.2 | 5.8 \u00b1 0.1 | 5.3 \u00b1 0.9 |\\n\\nConclusion: The results show significant differences in personality traits across different roles and conditions.\"}"}
{"id": "H3UayAQWoE", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 12: CABIN (Role Play).\\n\\n| Role   | Health Science | Creative Expression | Social Science | Media | Writing | Music | Performing Arts | Information Technology | Mathematics/Statistics | Humanities | Social Science | Medical Science | Physical Science | Engineering | Athletics | Protective Service | Physical/Manual Labor | Transportation/Machine Operation | 8DM D1: Realistic | 8DM D2: Investigate | 6DM D3: Artistic | 6DM D4: Social | 6DM D6: Conventional | 6DM D7: Nature | 8DM D8: Things | 8DM D5: Enterprising | Overall |\\n|--------|----------------|--------------------|----------------|-------|---------|-------|-----------------|------------------------|------------------------|----------------------|----------------|----------------|----------------|-----------------|-------------|----------|---------------------|------------------------|-----------------------------|----------------|-----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|\\n| CABIN  | 3.8            | 3.9                | 3.9            | 4.0   | 4.0     | 4.0   | 4.0             | 4.0                    | 3.8                    | 4.0                  | 4.0           | 4.0           | 4.0           | 4.0             | 4.0         | 4.0     | 4.0                 | 4.0                    | 4.0                         | 4.0         | 4.0            | 4.0          | 4.0          | 4.0           | 4.0           | 4.0           | 4.0            | 4.0          | 4.0          | 4.0          | 4.0          |\\n\\nTable 13: ICB (Role Play).\\n\\n| Role   | Health Science | Creative Expression | Social Science | Media | Writing | Music | Performing Arts | Information Technology | Mathematics/Statistics | Humanities | Social Science | Medical Science | Physical Science | Engineering | Athletics | Protective Service | Physical/Manual Labor | Transportation/Machine Operation | 8DM D1: Realistic | 8DM D2: Investigate | 6DM D3: Artistic | 6DM D4: Social | 6DM D6: Conventional | 6DM D7: Nature | 8DM D8: Things | 8DM D5: Enterprising | Overall |\\n|--------|----------------|--------------------|----------------|-------|---------|-------|-----------------|------------------------|------------------------|----------------------|----------------|----------------|----------------|-----------------|-------------|----------|---------------------|------------------------|-----------------------------|----------------|-----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------"}
