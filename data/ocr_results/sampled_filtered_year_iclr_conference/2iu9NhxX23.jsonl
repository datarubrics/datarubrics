{"id": "2iu9NhxX23", "page_num": 48, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Baseline Pretrain Size | Accuracy | Reply Qualifier | Pattern Naive Token |\\n|------------------------|----------|-----------------|---------------------|\\n| T5 True                | 70.7     | 72.8            | 95.5                |\\n|                        | 69.2     | 71.0            | 95.8                |\\n|                        | 76.8     | 78.4            | 97.0                |\\n| T5 False               | 41.6     | 48.7            | 69.5                |\\n|                        | 40.0     | 47.6            | 66.5                |\\n|                        | 40.9     | 48.2            | 68.1                |\\n| LongT5 False           | 41.0     | 48.4            | 67.7                |\\n|                        | 40.9     | 48.1            | 67.8                |\\n| LongT5-TGlobal False   | 41.0     | 48.4            | 67.7                |\\n|                        | 40.9     | 48.1            | 67.8                |\"}"}
{"id": "2iu9NhxX23", "page_num": 49, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 21: Consistency breakdown for cSCAN-B Random\\n\\n| Baseline | Pretrain Size | Consistency | Implications | Contradictions |\\n|----------|---------------|-------------|--------------|----------------|\\n| T5 True  | S             | 71.8        | 431          | 169            |\\n|          | B             | 71.3        | 437          | 176            |\\n| T5 True  | L             | 87.5        | 446          | 64             |\\n| T5 False | S             | 0.0         | 0            | 881            |\\n|          | B             | 0.0         | 0            | 2107           |\\n| LongT5  | S             | 0.0         | 0            | 1419           |\\n|          | B             | 0.1         | 1            | 689            |\\n| LongT5-TGlobal | S     | 0.2         | 3            | 1269           |\\n|          | B             | 0.0         | 1            | 3128           |\\n| T5 w/o Context | S       | 0.1         | 1            | 774            |\\n\\nTable 22: Consistency breakdown for cSCAN-X Random\\n\\n| Baseline | Pretrain Size | Consistency | Implications | Contradictions |\\n|----------|---------------|-------------|--------------|----------------|\\n| T5 True  | S             | 30.1        | 237          | 550            |\\n|          | B             | 32.3        | 268          | 561            |\\n| T5 True  | L             | 43.5        | 335          | 435            |\\n| T5 False | S             | 0.1         | 4            | 3967           |\\n|          | B             | 0.0         | 2            | 5375           |\\n| LongT5  | S             | 0.1         | 2            | 1791           |\\n|          | B             | 0.1         | 4            | 3678           |\\n| LongT5-TGlobal | S    | 0.2         | 3            | 1651           |\\n|          | B             | 0.1         | 3            | 3002           |\\n| T5 w/o Context | S       | 0.4         | 3            | 822            |\\n\\nIn this section we show the number of implications and contradictions used to calculate the consistency metric. Tables 21 and 22 show this breakdown.\\n\\nTo further illustrate the type of inconsistencies the model is making, we show the consistency sets (implications and contradictions) size distribution in Figures 14 and 15. This shows that sets of size 2 where one prediction implies or contradicts another are the most common. Appendix P.2 expands on this by providing examples of the contradictions.\\n\\nAs can be seen in these tables, the consistency metric for each cSCAN Random experiment is calculated based on a minimum of 500 implications and contradictions.\\n\\nAs discussed in Section 6.2 and Appendix F, we do not report consistency metrics for the MCD datasets, as we are only able to achieve a high enough density of potential implications in the Random datasets, where after splitting, we augment each context with additional top-level examples from the same distribution. We do not perform this additional example generation step for the MCD datasets to avoid impacting the compound divergences between the train and test sets.\"}"}
{"id": "2iu9NhxX23", "page_num": 50, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 14: Consistency sets size distribution for cSCAN-B Random\\n\\n50\"}"}
{"id": "2iu9NhxX23", "page_num": 51, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 15: Consistency sets size distribution for cSCAN-X Random\"}"}
{"id": "2iu9NhxX23", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Test results on cSCAN random splits by model size: \\\\(S\\\\) (Small), \\\\(B\\\\) (Base), and \\\\(L\\\\) (Large).\\n\\n| Model Pretrain | \\\\(cSCAN-B\\\\) Random | \\\\(cSCAN-X\\\\) Random |\\n|---------------|---------------------|---------------------|\\n|               | Accuracy           | Consistency         | Accuracy           | Consistency         |\\n| T5 True       | 92.5 92.6 96.5     | 71.8 71.3 87.5     | 68.3 71.0 81.6     | 30.1 32.4 43.5     |\\n| False         | 19.3 17.9 0.0      | 16.8 17.2 0.1      | 16.8 17.2 0.0      | 30.1 32.4 43.5     |\\n| LongT5-TGlobal False | 20.0 17.0 0.2 | 18.0 18.8 0.2 | 16.8 17.2 0.1 | 30.1 32.4 43.5 |\\n| LongT5 False | 19.5 21.4 0.0 | 18.1 16.7 0.1 | 16.8 17.2 0.0 | 30.1 32.4 43.5 |\\n| T5 w/o Context True | 26.8 0.1 | 23.8 0.4 | 16.8 17.2 0.0 | 30.1 32.4 43.5 |\\n\\nAttention sparsity pattern (Ainslie et al., 2020; Zaheer et al., 2020). The global attention is designed to facilitate propagation of attention across the full input sequence within two hops, in comparison with pure local attention, in which propagation of attention is limited by the size of the attention window.\\n\\nFor each architecture, we evaluate at minimum two sizes: Small (60M parameters) and Base (220M parameters). For the best-performing T5 architecture, we further evaluate on size Large (770M parameters). We report results for both pre-trained and non-pretrained versions of standard T5, but only non-pretrained versions of the long variants, as we failed to find a converging setup for the pre-trained versions (see Appendix L for details). For comparison, we also evaluate a naive variant of T5-Base (T5 w/o Context), which considers only the request, while ignoring the context. Additional details of the baseline configurations are provided in Appendix L and of the input-output format in Appendix O.\\n\\n### 6 EXPERIMENTAL RESULTS AND DISCUSSION\\n\\n#### 6.1 CONSISTENCY AND SCALING TO LARGER RULE SETS\\n\\nAs a first set of experiments, we compare baseline performance on the random splits of the cSCAN-B and cSCAN-X datasets. The results are shown in Table 4.\\n\\nOn the smaller cSCAN-B rule space, it can be seen that the provided 100K examples are sufficient for a pre-trained full-attention Transformer to achieve accuracies in excess of 90%, with accuracies increasing steadily with model size. Even in this relatively simple setting, however, several challenges can be observed. First, it appears that appropriate pre-training of the model is critical, as all the Transformer variants when trained from scratch managed to learn only superficial statistical correlations, as evidenced by them failing to outperform a naive baseline. Second, regarding LongT5 and LongT5-TGlobal, while it is possible that performance could be improved through more thorough hyperparameter tuning, our initial results show these to struggle on the conceptual learning task. Specifically, non-pretrained versions suffer from the same poor performance as non-pretrained T5, while when fine-tuning from an existing checkpoint, we were not able to find a converging setup. One possible explanation is that unlike document summarization tasks, for which LongT5 produced strong results (Guo et al., 2022), CLTs may depend heavily on full attention over the context. If so, this could pose challenges in scaling to real-world conceptual learning tasks with even larger contexts. Third, while consistency scores for the evaluated models correlate roughly with accuracy, significantly more headroom is seen in consistency, with even the best-performing T5-Large scoring under 0.9, while the naive baseline and all non-pretrained models score close to 0.\\n\\nOn the cSCAN-X rule space, accuracy drops significantly for all sizes of T5, suggesting that scaling to larger rule sets will be a challenge. Consistency continues to correlate with accuracy for these models, but drops rapidly as performance degrades. Non-pretrained models continue to fail to outperform the naive baseline.\\n\\n#### 6.2 COMPOSITIONAL GENERALIZATION\\n\\nAs a second set of experiments, we evaluate the ability for baseline solutions to compositionally generalize on CLTs using the cSCAN-B MCD and cSCAN-X MCD datasets (Table 5).\\n\\nPrior research on semantic parsing tasks has shown that while pre-trained Transformers exhibit strong performance on specialized cases of compositional generalization, they tend to struggle with more complex forms of compositional generalization, as reflected in low performance on MCD splits when an appropriate notion of \u201catom\u201d and \u201ccompound\u201d is identified (Furrer et al., 2020). Here we show that in the context of a conceptual learning task, one form of compositional generalization that is challenging for T5-based\"}"}
{"id": "2iu9NhxX23", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"models is generalization to new syntactic patterns in the request, even in the relatively easy setting where the same contexts could appear in train as in test.\\n\\nTable 5: Test accuracy on different cSCAN MCD splits by model size: S (Small), B (Base), and L (Large).\\n\\n| Model Pretrain | cSCAN-B MCD | cSCAN-X MCD |\\n|---------------|-------------|-------------|\\n| T5 True       | 53.8 54.7   | 70.7 69.2   |\\n| False         | 40.1 38.4   | 41.6 39.9   |\\n| LongT5-TGlobal False | 40.6 39.3 | 41.0 40.9 |\\n| LongT5 False  | 40.7 38.0   | 40.9 41.2   |\\n| T5 w/o Context True | 46.2 42.7 |            |\\n\\nSpecifically, as can be seen in the cSCAN-B MCD results, when switching from random to MCD split, accuracy drops from over 90% to less than 70%, even for the largest of the pre-trained T5 models, illustrating that compositional generalization is a challenge for these models, independently of the size of the rule space. Accuracy on cSCAN-X MCD is roughly similar to both cSCAN-B MCD and cSCAN-X Random, suggesting that the challenges of compositional generalization and rule space size do not necessarily compound.\\n\\nNote also that while accuracies for non-pretrained models are somewhat higher on the MCD splits than on the random splits, this is not actually a sign of stronger performance, but rather simply an artifact of the mix of example classes that occur in the different splits, due to the down-sampling that is performed when constructing the MCD split. As shown in Table 8, a side effect of this splitting algorithm was a relative increase in the proportion of defeasible rule examples vs. monotonic or non-rule examples and in the proportion of examples with \u201cunknown\u201d as the reply. This leads to an increase in the accuracy achievable by the naive \u201cT5 w/o Context\u201d baseline. On the MCD splits, like the random splits, none of the non-pretrained models manage to outperform the naive baseline.\\n\\nFor the MCD splits, we do not report consistency metrics, as due to technicalities of the MCD splitting algorithm, there ended up being insufficient signal for logical implications among the test examples, leading the consistency metric to be undefined in most cases. (See Appendix F for details.)\\n\\n7 RELATION WORK\\nHere we discuss the most closely related lines of research. See Appendix K for more related work.\\n\\nTasks providing knowledge as context. In representing the input of a CLT as a request paired with a context, we build on a long tradition of QA and reasoning task formulations that provide knowledge relevant to a task via various forms of context, such as a text passage (Kwiatkowski et al., 2019; Weston et al., 2015), set of natural language statements (Talmor et al., 2020), knowledge graph fragment (Sinha et al., 2020), or grid world (Ruis et al., 2020). Our formulation of a CLT is novel in adopting a set-like context mixing rules and examples, which varies materially across examples.\\n\\nMeta-learning. The presence of examples within the context of an example gives CLTs a nested structure that allows us to view CLTs through the lens of meta-learning or \u201clearning to learn\u201d (Thrun & Pratt, 1998). In this view, top-level examples that share the same context correspond to an episode where the context examples are the training examples and the top-level examples (w/o the context) are the test examples. Closely related to cSCAN are two pieces of work that apply meta-learning to SCAN (Lake, 2019; Nye et al., 2020). Our approach differs in that we include in the context a mixture of rules and examples, and we use the synthetically-generated contexts to define a new task, rather than as a means to improve accuracy on the original SCAN task.\\n\\n8 CONCLUSIONS AND FUTURE WORK\\nIn this paper, we presented the cSCAN benchmark as a first instance of a \u201cconceptual learning task\u201d (CLT), following a task format motivated by a personal assistant use case. Through experiments on baseline solutions, we identified several challenge areas with headroom for improvement. As next steps, we are interested in exploring solutions to CLTs, including prompting of large language models, neuro-symbolic solutions, and improved ways of handling large set-like contexts. In parallel, we are interested in exploring CLTs based on a wider range of base tasks and rule formats, including non-synthetic tasks and tasks that draw on a full KB as context.\"}"}
{"id": "2iu9NhxX23", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Experiments Appendix L describes the details of the baseline configurations that we used, together with other details of the environment in which we ran the experiments reported in this paper, while Appendix O provides details of the input-output format. Upon paper acceptance, we plan to release on GitHub both the cSCAN datasets and the code needed to reproduce the experiments.\\n\\nDataset generation\\nThe cSCAN datasets themselves were synthetically generated using a configuration-driven Python program described in Appendix F, which we also plan to open-source, together with the specific configurations used for each of the cSCAN datasets. While regeneration of the datasets is not necessary for reproducing our experiment results, researchers can use this code to generate new conceptual learning datasets based either on the existing cSCAN grammar spaces or on modified grammars. When the code is run with the provided configurations, it can reproduce the generation of datasets with statistically comparable content to the official cSCAN datasets.\\n\\nREFERENCES\\nJoshua Ainslie, Santiago Onta\u00f1\u00f3n, Chris Alberti, V\u00e1clav Cvicek, Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, and Li Yang. Etc: Encoding long and structured data in transformers. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020), 2020.\\n\\nStanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. VQA: Visual Question Answering. In International Conference on Computer Vision (ICCV), 2015.\\n\\nDzmitry Bahdanau, Harm de Vries, Timothy J O'Donnell, Shikhar Murty, Philippe Beaudoin, Yoshua Bengio, and Aaron Courville. Closure: Assessing systematic generalization of clevr models. arXiv preprint arXiv:1912.05783, 2019a.\\n\\nDzmitry Bahdanau, Shikhar Murty, Michael Noukhovitch, Thien Huu Nguyen, Harm de Vries, and Aaron Courville. Systematic generalization: What is required and can it be learned? In International Conference on Learning Representations, 2019b. URL https://openreview.net/forum?id=HkezXnA9YX.\\n\\nPeter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.\\n\\nSteven Bird, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the natural language toolkit. \\\"O'Reilly Media, Inc.\\\", 2009.\\n\\nSamuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, 2015.\\n\\nJames Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL http://github.com/google/jax.\\n\\nPawel Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\u00f1igo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gasi\u0107. MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 5016\u20135026, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1547. URL https://aclanthology.org/D18-1547.\\n\\nGiovanni Casini, Thomas Meyer, and Ivan Varzinczak. Contextual conditional reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 35(7):6254\u20136261, May 2021. URL https://ojs.aaai.org/index.php/AAAI/article/view/16777.\"}"}
{"id": "2iu9NhxX23", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "2iu9NhxX23", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The ability to learn from a mix of rules and examples and to reflect on the learned abstractions is an important aspect of human intelligence. At the same time, there is a lack of benchmarks that systematically test for this ability, which makes it hard to evaluate the degree to which it is present in state-of-the-art ML architectures. We introduce a novel task format for such benchmarks by using an example structure that allows us to explicitly provide and ask about rules that are relevant for the given task. We present a simple dataset illustrating this format, and we use it to analyze the performance of a variety of T5-based ML models. We identify three challenge areas in this setup: maintaining consistency between learned rules and their application, scaling to larger rule sets, and compositional generalization.\\n\\nIntroduction\\n\\nMachine learning algorithms are typically designed to be able to learn functions from examples. This is a very general paradigm, but it does not explicitly capture some aspects of human learning. Humans, in contrast, are able to learn both by being shown examples of the task to accomplish and by being told rules or instructions about this task. They can even provide relevant rules to others once they have learned the task from examples.\\n\\nAs a realistic illustration of this ability, consider the task of a personal assistant who, among other things, is expected to make movie recommendations based on the age and interests of a user. Even for a task such as this that would currently be considered a standard use case for an example-based recommender system, as humans, we do not learn how to perform this task exclusively by observing examples of movie recommendations. Instead, we can accomplish this task much more efficiently by also taking into account relevant knowledge in the form of rules that have been communicated to us explicitly, i.e., by \\\"learning with rules\\\". For recommending a movie to a girl called Anna, we may, among others, use the rules and facts, which we consider a special case of rules, illustrated on the left side of Figure 1.\\n\\nIn addition to the ultimate goal of providing movie recommendations (e.g., \\\"What movie could Anna watch?\\\") we would also expect a human to be able to answer the intermediate questions shown on Figure 1: Personal assistants answer questions using knowledge consisting of rules and facts. Note that the last knowledge bullet point above can also be construed as an example of the underlying \\\"movie recommendation\\\" task, while the other bullet points represent other relevant knowledge. The first bullet point is a traditional \\\"rule\\\" that states conditional knowledge that can apply to many different movies. The second is a concept definition, which can be equivalently construed as a rule relating two different pieces of information about a person. The other bullet points are facts stated at varying levels of granularity.\"}"}
{"id": "2iu9NhxX23", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the right side of Figure 1 \u2013 i.e., to \u201clearn about rules\u201d that are relevant to the ultimate task \u2013 and we would expect these questions to be answered consistently w.r.t. the provided knowledge and ultimate recommendation. These questions allow us to introspect the understanding of the assistant, e.g., to debug why a movie recommendation was not as expected.\\n\\nSimilar interactions between learning from examples and learning with and about rules can also be observed in simpler synthetic tasks. Consider, for instance, the SCAN task of Lake & Baroni (2017), which our work builds on. This task requires the learner to translate natural language commands (such as \u201cjump left twice\u201d) to corresponding actions (such as \u201cLTURN JUMP LTURN JUMP\u201d). The learner is presented with a certain subset of some thousands of (command, action sequence) pairs during training and is then expected to translate unseen commands.\\n\\nFigure 2: Examples of SCAN interpretation rules from Lake & Baroni (2017).\\n\\nThis focus on learning purely from examples, while typical of most traditional ML tasks, differs from the way one would \u201cteach\u201d a human the task, and indeed how the authors of the SCAN paper \u201cteach\u201d the task to their readers. On the one hand, while humans are also adept at guessing rules from examples, rather than depending on thousands of examples, they can often grasp the relevant rule from just a handful of examples (Lake et al., 2015), as we as readers may find ourselves doing when seeing the handful of illustrative examples of SCAN provided by the authors in the paper figures. More fundamentally, however, rather than expecting readers to learn the translation function purely from examples, the authors provide this function in a much more direct and efficient fashion using a set of interpretation rules like those in Figure 2. The explicit nature of the provided rules has the additional advantage that it allows us to deduce the translation of a given command by applying the translation rules rather than having to always speculatively induce the translation by generalizing from a set of examples.\\n\\nIn this paper, we introduce conceptual learning tasks (CLTs), which are a type of learning task that is specifically designed to evaluate the combination of such inductive and deductive learning, and we make the following contributions:\\n\\n\u2022 We define the notion of a CLT (Section 2).\\n\u2022 We present a first simple instance of a CLT called Conceptual SCAN (cSCAN), which is a synthetically-constructed conceptual learning variation of SCAN (Section 3).\\n\u2022 We formalize metrics to measure a learner\u2019s performance on cSCAN, including a novel measure of consistency between learned rules and their application (Section 4).\\n\u2022 We analyze the performance of baseline ML architectures on cSCAN and identify three challenge areas: consistency, rule set size, and compositional generalization (Section 6).\\n\u2022 We provide the code used in generating cSCAN, constructing compositional generalization splits, and calculating consistency from experiment results.\\n\\nTo be released on GitHub upon paper acceptance. For an overview, see Appendices F and G.\"}"}
{"id": "2iu9NhxX23", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The learner needs to indicate in the output whether a reply follows deductively \u2013 and thus monotonically \u2013 from the context (e.g., \\\"How old is Anna? \\\\(\\\\Rightarrow 14\\\\)) or whether it requires generalizing the context inductively (i.e., \\\"Will Anna like Mission Impossible 6? \\\\(\\\\Rightarrow\\\\) Probably\\\"), which would imply that the reply could change if more information were to become available (i.e., that the reply is defeasible). Also, the learner needs to identify if a request cannot be answered based on the given context (e.g., \\\"Who is Anna's best friend? \\\\(\\\\Rightarrow I don't know\\\\)).\\n\\nCompositionality of rules.\\n\\nThe rules have a compositional structure, which means that it is possible to determine the meaning of an unknown rule from its syntax if we are given the meaning of a sufficient subset of rules. (E.g., we as humans understand the meaning of the rules shown in Figure 1 because of the compositional syntax and semantics of natural language. Even if we have never seen these exact sentences before, we know what they mean based on our exposure to other sentences built from the same natural language building blocks.)\\n\\nAs a way of providing a concrete but generic task format that satisfies these properties, we define a conceptual learning task (CLT) as a supervised learning task with the following structure. (See Appendix A for a discussion of the design choices.)\\n\\n- The task \\\\(T = \\\\{e_1, \\\\ldots, e_N\\\\}\\\\) is a finite set of examples \\\\(e_k \\\\in E\\\\), where \\\\(E = \\\\mathbb{2}^{\\\\mathbb{Q} \\\\times \\\\mathbb{R}}\\\\) denotes the set of possible examples.\\n- Each example \\\\(e_k = \\\\langle C_k, q_k, r_k, u_k \\\\rangle\\\\) is a quadruple consisting of a context \\\\(C_k \\\\in \\\\mathbb{2}^{\\\\mathbb{Q} \\\\times \\\\mathbb{R}}\\\\), a request \\\\(q_k \\\\in \\\\mathbb{Q}\\\\), a reply \\\\(r_k \\\\in \\\\mathbb{R}\\\\), and a qualifier \\\\(u_k \\\\in \\\\mathbb{U}\\\\). Of these, the context and request together form the input of the ML system, while the reply and qualifier together form the output. (See Appendix O for details on the exact format in which these are input and output by our T5 baseline systems.)\\n- The set of possible requests \\\\(\\\\mathbb{Q}\\\\) can be partitioned into rule requests \\\\(\\\\mathbb{Q}_R \\\\subseteq \\\\mathbb{Q}\\\\) (i.e., requests that ask whether a certain rule holds) and non-rule requests \\\\(\\\\mathbb{Q}_N \\\\subseteq \\\\mathbb{Q}\\\\).\\n- The set of possible replies \\\\(\\\\mathbb{R}\\\\) must contain dedicated elements representing true (1), false (0), and unknown (?), which are the only valid replies for rule requests \\\\(q \\\\in \\\\mathbb{Q}_R\\\\).\\n- The set of qualifiers \\\\(\\\\mathbb{U}\\\\) = \\\\{M, D\\\\} indicates whether the reply follows monotonically from the context (M) or whether it is defeasible (D).\\n- Each context \\\\(C \\\\in \\\\mathbb{2}^{\\\\mathbb{Q} \\\\times \\\\mathbb{R}}\\\\) consists of a set of context examples \\\\(e_i = \\\\langle q_i, r_i \\\\rangle\\\\), which represent either examples of an underlying task or other relevant knowledge expressed in \\\"example\\\" form. Note that unlike the top-level examples, these context examples do not themselves contain a context or qualifier, as for the purposes of this paper, we take all context examples to be unconditional and monotonic. (See Appendix C for a possible generalization of this definition.)\\n\\nNote that even though the context is strictly a set of examples, it may still contain any rule \\\\(q \\\\in \\\\mathbb{Q}_R\\\\) by means of including the example \\\\(\\\\langle q, 1 \\\\rangle\\\\), which asserts the rule \\\\(q\\\\) to be true.\\n\\nAs a more complete illustration, Figure 3 shows a few examples from the cSCAN task, which is a CLT that we introduce in Section 3, while Appendix B shows the motivating example represented as a CLT.\\n\\n2.3 Consistency requirements\\n\\nIn addition to satisfying the structural definition, for the purposes of this paper, we require CLTs to be logically consistent, which means that each example and the example set as a whole must be non-contradictory. For instance, if a CLT contains a monotonic example \\\\(\\\\langle C, q, r, M \\\\rangle\\\\), it may not contain an example \\\\(\\\\langle C', q, r', M \\\\rangle\\\\) where \\\\(C \\\\subseteq C'\\\\) and \\\\(r \\\\neq r'\\\\) as this would violate monotonicity. (Or using the example from the introduction, this would mean, for instance, that if for a given context the task contains \\\"How old is Anna? \\\\(\\\\Rightarrow 14\\\\)\\\" and \\\"Is Jerry Maguire appropriate for 14-year-olds? \\\\(\\\\Rightarrow No\\\\)\\\"), it should not contain \\\"Is Jerry Maguire appropriate for Anna \\\\(\\\\Rightarrow Yes\\\\)\\\".) While this requirement could be relaxed in practice, consistency of the task is helpful, as it enables us to precisely measure the consistency of the learner. For the task to be logically consistent, it requires at minimum that the monotonic examples adhere to the axioms of propositional logic. (See Appendix D for a formalization of the consistency requirements.)\"}"}
{"id": "2iu9NhxX23", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Note that even while requiring a CLT to be logically consistent, we still allow for the common phenomenon in which rules are stated in a form that is only \\\"usually\\\" true. Exceptions to a rule are allowed so long as the rule is assigned the qualifier \\\"defeasible\\\" (D).\\n\\n2.4 Classification of Examples\\n\\nThe structure of CLTs allows us to classify examples according to the following dimensions.\\n\\n- Request \\\\( q \\\\in Q \\\\): Rule request (\\\\( q \\\\in Q_R \\\\)) vs. non-rule request (\\\\( q \\\\in Q_N \\\\))\\n- Reply \\\\( r \\\\in R \\\\): Known vs. unknown (\\\\(?\\\\)), and, for rule requests, true (\\\\(1\\\\)) vs. false (\\\\(0\\\\))\\n- Qualifier \\\\( u \\\\in U \\\\): Monotonic (\\\\(M\\\\)) vs. defeasible (\\\\(D\\\\))\\n\\nEach class of example should be reasonably well represented in a conceptual learning dataset.\\n\\n3 Conceptual SCAN (cSCAN)\\n\\nOne benefit of abstracting out key properties of interest from our motivating use case into the definition of a CLT is that we can now seek to study the capabilities of current ML methods on this family of tasks by starting with a very simple CLT instance, which illustrates the key dynamics of a CLT in as pure a form as possible. In particular, it gives us a basis by which we can construct a simple synthetic task that enables exploration of ML system performance on CLTs, while carefully controlling the task complexity. In this section, we present one such \\\"simplest possible\\\" CLT, named Conceptual SCAN (cSCAN). cSCAN is a conceptual learning adaptation of the SCAN task (Lake & Baroni, 2017), which was itself originally presented as a kind of \\\"simplest possible\\\" compositional generalization task. We construct cSCAN according to a recipe illustrating one possible way of deriving a CLT from a base task.\\n\\n3.1 Base Task: SCAN\\n\\nSCAN is a task where natural language commands (such as \\\"jump left twice\\\") are translated into sequences of actions (such as \\\"LTURN JUMP LTURN JUMP\\\"). SCAN was designed to evaluate compositional generalization using non-standard train-test splits, which is one of the themes we explore in this paper. In addition, SCAN is an attractive choice of base task for a first conceptual learning benchmark because it can be generated automatically from a simple set of rules: a phrase-structure grammar for generating the valid input commands and a set of interpretation rules that specifies how to compute the action sequence for each command (see Figure 2 and Appendix E.1).\\n\\n3.2 Constructing cSCAN\\n\\nIn contrast to SCAN, which tests whether a learner can learn one specific translation from commands to actions, the goal of cSCAN is to test whether the learner can learn to perform a family of SCAN-like tasks using knowledge that consists of an arbitrary mix of rules and examples.\\n\\nNote that moving from a single task to a family of related tasks is essential for cSCAN because it forces the learner to take into account the knowledge provided by the context rather than just memorize behavior that is constant across all examples. In our original motivating example, this corresponds to the fact that we do not want a learner to make movie recommendations in a single, fixed scenario, but rather based on knowledge that may differ from person to person and evolve over time.\\n\\ncSCAN is constructed using the following recipe.\\n\\nStep 1: Accommodate the base task.\\nA CLT subsumes the base task. This means that any input of SCAN is a valid request \\\\( q \\\\in Q \\\\), and any output of SCAN is a valid reply \\\\( r \\\\in R \\\\).\\n\\nStep 2: Make some of the relevant knowledge available as explicit rules.\\nWe choose which part of the relevant knowledge we want to be able to talk about explicitly and vary across examples. For cSCAN, we choose to talk only about interpretation rules like those shown in Figure 2. This means that any interpretation rule is a valid request \\\\( r \\\\in R \\\\), which allows us to assert such a rule in the context (by adding the example \\\\( \\\\langle r, 1 \\\\rangle \\\\) to the context) and teach/ask the learner whether any such rule holds. CLTs require that explicit rules have a...\"}"}
{"id": "2iu9NhxX23", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Hypothetical cSCAN examples based on two different contexts that contradict each other.\\n\\nThe compositional structure (Section 2.1). This is the case for cSCAN because the meaning of the interpretation rules can be determined using a compositional grounding function that we provide in Appendix E.\\n\\nStep 3: Generate or curate examples.\\n\\nFor cSCAN, we generate examples automatically using a Python program, which we summarize here and describe in detail in Appendix F. As a first step of generating each example, we create a context by first picking a coherent set of interpretation rules like those shown in Figure 2 (or in Figure 4 from the appendix) and then choosing which of those rules to (a) provide explicitly in the context, (b) illustrate implicitly through context examples, (c) illustrate insufficiently or not at all, or (d) contradict in one or more cases. Once we have fixed a context, we choose a request, reply and qualifier that, together with the context, satisfy the consistency criteria stated in Section 2.3 and agree with the task's assumed inductive bias for distinguishing between a rule being \\\"defeasibly true\\\" vs. \\\"unknown\\\" (see Appendix E.4).\\n\\nWe make sure that the different example classes are evenly represented (see the statistics in Section 3.3) and that, for simplicity, contexts contain only unconditional, monotonic examples that do not conflict with one another. We provide a detailed specification of cSCAN in Appendix E.\\n\\n3.3 THE CSCAN DATASET\\n\\nExamples.\\n\\nFigure 3 shows some hypothetical cSCAN examples in human-friendly notation. (We chose these examples for simplicity and conciseness. For a sample of actual cSCAN examples, see Appendix I. For examples in the exact format in which they are presented to the baseline systems, see Appendix O.)\\n\\nThese examples are based on two contexts ($C_1$ and $C_2$) that are incompatible (e.g., they define the meaning of $J$ walk differently) and correspond to different SCAN variations. Each context contains some explicit rules (e.g., $Jx_1KJx_2K$ in $C_1$) as well as rules that are illustrated implicitly via examples (e.g., $Jx_1$ twice $KJx_1K$ in $C_1$). The qualifier of the examples indicates whether any implicit rules are needed to determine the reply (in which case the qualifier is $D$).\\n\\nIn context $C_2$, we do not provide explicit rules for $J$ $x_1$ twice $K$ as well as $J$ $x_1$ thrice $K$. While the rule $J$ $x_1$ twice $K$ $Jx_1KJx_1K$ is expected to be induced from the provided examples, there is no obvious rule that can be induced for $J$ $x_1$ thrice $K$. As a consequence, we expect the learner to reply \\\"unknown\\\" (?) for the request \\\"jump thrice\\\". At the same time, we expect the learner to reply \\\"false\\\" for the rule $J$ $x_1$ thrice $K$ $Jx_1KJx_1K$ because there is an example in the context that contradicts it.\\n\\nRule space variants.\\n\\nIn order to cover a range of rule set complexities, we construct two versions of cSCAN (cSCAN-B and cSCAN-X), using different sizes of rule space (Table 1).\\n\\n- **cSCAN-B** (short for \\\"cSCAN-Base\\\") uses a fixed phrase-structure grammar equivalent to that of the original SCAN task, as reformulated in Nye et al. (2020) using 14 interpretation rules. Action sequences are kept short by allowing a token or variable to be repeated at most twice in an interpretation rule's output sequence. This ensures that cSCAN-B examples do not exceed input size of 2048 tokens or output size of 256 tokens in our baseline models.\\n\\n- **cSCAN-X** (short for \\\"cSCAN-Extended\\\") is based on a richer grammar space, which extends the original SCAN phrase-structure grammar with additional terminals, variations of existing rules, and an additional level that enables adverbs. Output sequences for individual interpretation rules are allowed to contain up to 4 repetitions of any given token or variable, which is the same as in original SCAN, but longer than in cSCAN-B. To keep context sizes manageable, we apply rule sampling for each context, so that the number of interpretation rules actually used in any given context is the same as in cSCAN-B, and apply a limit to the...\"}"}
{"id": "2iu9NhxX23", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: cSCAN rule space variants. cSCAN-B uses a fixed phrase-structure grammar equivalent to that of the original SCAN task, while keeping action sequences short. cSCAN-X is based on a richer grammar space, while using rule sampling to keep the number of rules used in any given context equivalent to the number of rules in cSCAN-B and the reformulation of original SCAN.\\n\\n| Variant          | Command grammar | Action sequences | Context | Max # tokens | Depth Terminals | Max length | Underlying rules |\\n|------------------|-----------------|------------------|---------|-------------|----------------|------------|-----------------|\\n| cSCAN-B          | 6 13            | 4                | 14      | 2048        | 256            |            |                 |\\n| cSCAN-X          | 7 36            | 8                | 14      | 4096        | 512            |            |                 |\\n| Reformulated SCAN| 6 13            | 8                | 14      |             |                |            |                 |\\n\\nTable 2: Key statistics of the main cSCAN datasets. For full details, see Appendix H.\\n\\n| cSCAN-B Random       | cSCAN-X Random       | cSCAN-B MCD       | cSCAN-X MCD       |\\n|----------------------|----------------------|-------------------|-------------------|\\n| train test           | train test           | train test        | train test        |\\n| Number of examples   | 100,000              | 100,000           | 100,000           |\\n| Number of contexts   | 1,000                | 100               | 11,921            |\\n| Request: Rule (%)    | 50.1                 | 50.0              | 72.5              |\\n| Request: Non-rule (%)| 49.9                 | 50.0              | 27.5              |\\n| Qualifier: Monotonic (%) | 46.3             | 50.0              | 26.9              |\\n| Qualifier: Defeasible (%) | 53.7               | 50.0              | 73.1              |\\n| Reply: Unknown (%)   | 13.3                 | 13.2              | 52.2              |\\n| Reply: Yes (%)       | 21.8                 | 21.9              | 12.0              |\\n| Reply: No (%)        | 21.7                 | 21.7              | 12.1              |\\n\\nSplitting methods.\\n\\nFor each of the two sizes of rule space, we prepare datasets based on two splitting methods: random and maximum compound divergence (MCD) (Keysers et al., 2020).\\n\\nFor the cSCAN Random variants, we generate 1200 contexts and split these contexts randomly into a train set of 1000 contexts and validation and test sets of 100 contexts each. For the train set, we generate 100 top-level examples per context, while for the validation and test contexts, we generate 1000 top-level examples per context so as to provide a denser signal of potential implications among the examples of each context for use in calculating the consistency metric. This leads to a total of 100K top-level examples in each of the train, validation and test sets.\\n\\nFor the cSCAN MCD variants, we apply a variation of the MCD splitting algorithm of Keysers et al. (2020) in order to evaluate the ability of the system to compositionally generalize to new rule combinations, which we consider a stronger test of the system's ability to \\\"understand\\\" the meaning of the rules and to apply them correctly in new situations. Specifically, we start by generating 12K contexts with 100 top-level examples each, yielding a pool of 1.2M top-level examples. We then annotate each top-level example with a set of atoms and compounds based on the phrase-structure grammar rules that were composed to form the top-level example request, and we split the set of top-level examples in such a way as to maximize the divergence in the distribution of compounds between train, validation, and test, while keeping the distribution of atoms nearly the same. Similarly to Keysers et al. (2020), we down-sample during the splitting process for more effective control of the distribution divergences, leading to a total of 100K top-level examples in train (comparable to cSCAN Random) and 10K top-level examples in each of validation and test.\\n\\nStatistics.\\n\\nTable 2 gives an overview of the key statistics of the cSCAN Random datasets and representative MCD datasets. (See Appendix H for details of other cSCAN dataset variants.)\\n\\nWe construct the examples such that all the classes discussed in Section 2.4 are well represented. In particular, the Random datasets contain roughly equal numbers of rule vs. non-rule, as well as examples with replies of \\\"true\\\" (1) vs. \\\"false\\\" (0). There are slightly more defeasible examples than there are monotonic examples because \\\"unknown\\\" (?) examples are always qualified as defeasible.\\n\\nNote that compared to the random split, the splitting method used in the cSCAN MCD variants leads to a somewhat less balanced dataset in terms of example classes, although each of the classes is still well represented.\"}"}
{"id": "2iu9NhxX23", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Accuracy vs. consistency. Learner A is more accurate, but learner B is more consistent.\\n\\nGolden Learner A Learner B\\n\u27e8C\u2081, J\u2093 twice K\u2081 = J\u2093 KJ\u2093 K\u2081\u27e9 \u27e8C\u2081, J\u2093 twice K\u2081 = J\u2093 KJ\u2093 K\u2081\u27e9 \\n\u27e8C\u2081, J_walk K\u2081 = WALK\u2081\u27e9 \u27e8C\u2081, J_walk K\u2081 = WALK\u2081\u27e9\\n\u27e8C\u2081, J_walk twice K\u2081 = JUMP JUMP\u27e9 \u27e8C\u2081, J_walk twice K\u2081 = JUMP JUMP\u27e9\\n\\nCovered. Also, while it leads to a challenging split in terms of generalization to new top-level request patterns, it is potentially easier than the random split in terms of the contexts shown, as we do not prevent the same context from appearing in train and test, and due to the effect of down-sampling from a larger context pool, the total number of contexts that are shown in the MCD train set is an order of magnitude greater than those shown in the random train set.\\n\\n4 METRICS\\n\\nAccuracy\\n\\nOur primary accuracy metric is example-level accuracy, where credit is given only when the reply + qualifier exactly matches the ground truth. For more nuanced error analysis, we secondarily track several accuracy variants that give credit for partially correct outputs (see Appendix N).\\n\\nConsistency\\n\\nA key aspect of learning with rules is that a learner does not just learn how to memorize and recite rules, but is actually able to combine and apply them consistently. For instance in cSCAN, if the learner believes that the rules $J\u2093\u2081 twice K\u2081 = J\u2093 KJ\u2093\u2081 K\u2081$ and $J_walk K\u2081 = JUMP$ hold, a consistent learner should also believe that all combinations and applications of these rules hold, such as $J_walk twice K\u2081 = JUMP JUMP JUMP$.\\n\\nNote that unlike accuracy, this notion of consistency is not judging the correctness of individual predictions. Instead, it judges to what degree a whole set of predictions is consistent within itself. While a perfectly accurate learner would also be perfectly consistent, when accuracy is low to moderate, consistency can potentially be quite orthogonal to accuracy.\\n\\nAs an illustration, consider Table 3, which shows a golden example set as well as the predictions of two learners A and B. Learner A is more accurate because it gets 2 examples correct, whereas learner B gets none of the examples correct. At the same time, learner A is not consistent, because it is not able to correctly apply the two rules that it believes in to derive the example $\u27e8C\u2081, walk twice K\u2081 = JUMP JUMP\u27e9$. In contrast, learner B is perfectly consistent, as it correctly combines the rules it believes in to derive the example $\u27e8C\u2081, walk twice K\u2081 = JUMP JUMP JUMP\u27e9$.\\n\\nTo capture this notion of consistency, we introduce for any set of predictions $E \\\\subseteq E$ the consistency metric $C(E)$, which is the percentage of subsets of $E$ that contain a logical implication, in comparison to the number of subsets of $E$ that contain an implication or a contradiction. This means that $C(E) = 100$ says that the set $E$ is perfectly consistent, while $C(E) = 0$ says that $E$ is completely inconsistent.\\n\\n(See Appendix D for a formalization of this metric and Appendix G for practicalities of calculation.)\\n\\nFor learner A, the example $\u27e8C\u2081, walk twice K\u2081 = JUMP JUMP\u27e9$ contradicts the rules $\u27e8C\u2081, J\u2093 twice K\u2081 = J\u2093 KJ\u2093 K\u2081\u27e9$ and $\u27e8C\u2081, J_walk K\u2081 = WALK\u2081\u27e9$, which means that the consistency of learner A is $100 \\\\cdot 0 / 1 = 0$. For learner B, the example $\u27e8C\u2081, walk twice K\u2081 = JUMP JUMP JUMP\u27e9$ is implied by the rules $\u27e8C\u2081, J\u2093 twice K\u2081 = J\u2093 KJ\u2093 K\u2081 K\u2081\u27e9$ and $\u27e8C\u2081, J_walk K\u2081 = JUMP\u2081\u27e9$, which means that the consistency of learner B is $100 \\\\cdot 1 / 1 = 100$.\\n\\n5 BASELINES\\n\\nAs baselines, we evaluate variations of T5 (Raffel et al., 2019), a Transformer encoder-decoder model (Vaswani et al., 2017), which when pre-trained on natural language served as a strong baseline on the original SCAN task (Furrer et al., 2020; Csord\u00e1s et al., 2021; Onta\u00f1\u00f3n et al., 2021).\\n\\nThe most computationally and memory intensive of the T5 architectures that we evaluate is the standard T5 architecture, which applies full self-attention in the encoder, in addition to self-attention and cross-attention in the decoder. We refer to these models as simply T5.\\n\\nMotivated by the potentially large context size associated with CLTs, we further evaluate two variants of T5 that were designed to more efficiently scale to longer input sequences.\\n\\nLongT5 (Guo et al., 2022) reduces the computational load of attention in the encoder by applying local attention within a sliding window (Ainslie et al., 2020).\\n\\nLongT5-TGlobal (Guo et al., 2022) extends LongT5 with a local-global...\"}"}
{"id": "2iu9NhxX23", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: The green area on the top left is the phrase-structure grammar to generate the cSCAN-B commands. The red area on the lower right is the extension to generate the left-hand side of cSCAN-B rules.\\n\\nAs can be seen in the figure, action sequences in the original SCAN task are constructed from a set of 6 possible actions.\\n\\n\\\\[\\nA = \\\\{ \\\\text{WALK, RUN, JUMP, LOOK, LTURN, RTURN} \\\\}\\n\\\\]\\n\\nIn cSCAN-B, the set of non-rule requests \\\\(Q_N\\\\) consists of all natural language commands that are generated by the phrase-structure grammar shown on the top left in Figure 5, which is equivalent to the original SCAN phrase structure grammar, as reformulated in Nye et al. (2020). The mapping from command to action sequence varies from context to context. cSCAN-B constructs action sequences from the same 6 actions used in the original SCAN task, plus several additional ones provided for diversity. (In a nod to earlier research on the SCAN task, we follow the lead of Nye et al. (2020) in using as these additional actions the ones that appear in the \\\"MiniSCAN\\\" task of Lake et al. (2019).)\\n\\n\\\\[\\nA = \\\\{ \\\\text{WALK, RUN, JUMP, LOOK, LTURN, RTURN, RED, YELLOW, GREEN, BLUE, PURPLE, PINK, BLACK, WHITE} \\\\}\\n\\\\]\\n\\nIn cSCAN-X, the set of non-rule requests \\\\(Q_N\\\\) consists of all natural language commands that are generated by the phrase-structure grammar shown on the top left in Figure 6. The mapping from command to action sequence varies from context to context, similarly to cSCAN-B. cSCAN-X constructs action sequences from a set of 13 possible actions.\\n\\n\\\\[\\nA = \\\\{ \\\\text{WALK, RUN, JUMP, LOOK, LTURN, RTURN, DRIVE, RIDE, FLY, LEAP, PEEK, UTURN, DTURN} \\\\}\\n\\\\]\\n\\nFor simplicity, this section focuses on a formal description of cSCAN-B. The specification of cSCAN-X would follow the same form, with the exception of the differences described in Appendix E.1 above.\\n\\nNon-rule requests. In cSCAN, the set of non-rule requests \\\\(Q_N\\\\) consists of all natural language commands that are generated by the phrase-structure grammar shown on the top left in Figure 5. Note that for convenience of generation, the grammar adopted here is based on the alternative formulation of the SCAN grammar from Nye et al. (2020). This generates a slightly larger set of commands than the original SCAN grammar from Lake & Baroni (2017), as it includes commands such as \\\"turn\\\" and \\\"turn and turn\\\".\\n\\nReplies. Since cSCAN is a CLT, the set of replies \\\\(R\\\\) includes the dedicated replies \\\\(1\\\\) (true), \\\\(0\\\\) (false), and \\\\(?\\\\) (unknown). In addition, \\\\(R\\\\) contains all sequences consisting of actions \\\\(A\\\\) (described in Appendix E.2 above) separated by space with a maximum sequence length \\\\(N\\\\):\"}"}
{"id": "2iu9NhxX23", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: The green area on the top left is the phrase-structure grammar to generate the cSCAN-X commands. The red area on the lower right is the extension to generate the left-hand side of cSCAN-X rules. The items in blue boldface are those which do not appear in cSCAN-B.\\n\\n\\\\[ A^* := \\\\{ a_1 a_2 \\\\ldots a_k : 1 \\\\leq k < N, a_i \\\\in A \\\\} \\\\] (30)\\n\\n\\\\[ R^* := \\\\{ 1, 0, ? \\\\} \\\\cup A^* \\\\] (31)\\n\\nRule requests. All cSCAN rule requests are of the form \\\\( q = r \\\\), where \\\\( q \\\\) is an element of the left-hand side (LHS) expressions \\\\( Q^* \\\\) and \\\\( r \\\\) is an element of the right-hand side (RHS) expressions \\\\( R^* \\\\).\\n\\nThe set of LHS expressions \\\\( Q^* \\\\) is generated by the extended phrase-structure grammar shown in Figure 5, with the resulting phrases wrapped in brackets \\\\( JK \\\\). Note that this is almost the same grammar that is used to generate the cSCAN commands \\\\( QN \\\\) with the only difference being that it allows generating expressions with variables from the set \\\\( X := \\\\{ x_1, x_2, x_3, x_4 \\\\} \\\\). Examples of LHS expressions are \\\\( J x_1 \\\\) twice \\\\( K \\\\) and \\\\( J \\\\) walk opposite left \\\\( K \\\\).\\n\\nThe set of RHS expressions \\\\( R^* \\\\) consists of sequences of maximum length \\\\( N \\\\) whose elements are separated by space and consist of actions \\\\( A \\\\) and LHS expressions \\\\( Q^* \\\\). Examples of RHS expressions are \\\"W ALK J x_1 twice K L TURN\\\" and \\\"W ALK JUMP J run left K J look thrice K\\\". Note that RHS expressions are a superset of LHS expressions, i.e., \\\\( Q^* \\\\subset R^* \\\\).\\n\\n\\\\[ R^* := \\\\{ a_1 a_2 \\\\ldots a_K : 1 \\\\leq K < N, a_i \\\\in A \\\\cup Q^* \\\\} \\\\] (32)\\n\\nWe assume a function \\\\( \\\\text{var} : R^* \\\\rightarrow 2^X \\\\), which returns the set of variables used by a given RHS expression. This allows us to define the set of rule requests \\\\( Q_R^* \\\\) as an LHS and an RHS expression with matching variables:\\n\\n\\\\[ Q_R^* := \\\\{ q = r : q \\\\in Q^*, r \\\\in R^*, \\\\text{var}(q) = \\\\text{var}(r) \\\\} \\\\] (33)\\n\\nE.3 Rounding of Rules\\nAs discussed in Appendix E.3, we specify the semantics of cSCAN rules via a grounding function \\\\( G : Q_R^* \\\\rightarrow 2^E \\\\), which maps each rule to an equivalent set of examples. For rules where the LHS consists of a command without any variables, we can define the grounding as an example that provides the interpretation of this command. For example, the rule \\\\( J \\\\) walk \\\\( K = \\\\) W ALK is grounded as follows:\\n\\n\\\\[ G(J \\\\text{ walk } K = \\\\text{ W ALK}) := \\\\{ \\\\langle \\\\emptyset, \\\\text{ walk}, \\\\text{ W ALK} \\\\rangle \\\\} \\\\]\\n\\nNote that because we determine consistency based on propositional logic equivalence (see Appendix D), we could specify equivalent groundings that include additional examples that are logically implied by \\\\( \\\\{ \\\\langle \\\\emptyset, \\\\text{ walk}, \\\\text{ W ALK} \\\\rangle \\\\} \\\\). For instance, we could add variants with non-empty contexts (e.g., \\\\( \\\\langle \\\\{ J \\\\text{ run } K = \\\\text{ RUN} \\\\}, \\\\text{ walk}, \\\\text{ W ALK} \\\\rangle \\\\)), which follow from monotonicity.\"}"}
{"id": "2iu9NhxX23", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For rules containing variables, the grounding may consist of hundreds or thousands of examples, even if we do not include any examples that are logically implied. This is because the variable can be replaced with any command that leads to a valid LHS. For example, the rule $J x_1 \\\\text{twice} K = J x_1 K J x_1 K$ can be grounded as follows:\\n\\n$$G(J x_1 \\\\text{twice} K = J x_1 K J x_1 K) := \\\\{ \\\\langle \\\\{ J \\\\text{run} K = \\\\text{RUN} \\\\}, \\\\text{run twice}, \\\\text{RUN RUN} \\\\rangle, \\\\langle \\\\{ J \\\\text{run} K = \\\\text{JUMP} \\\\}, \\\\text{run twice}, \\\\text{JUMP JUMP} \\\\rangle, \\\\langle \\\\{ J \\\\text{run left} K = \\\\text{LTURN RUN} \\\\}, \\\\text{run left twice}, \\\\text{LTURN RUN LTURN RUN} \\\\rangle, \\\\ldots \\\\}$$\\n\\nThe first example in this grounding can be read as: if $J \\\\text{run} K$ is translated to \u201cRUN\u201d then \u201crun twice\u201d is translated to \u201cRUN RUN\u201d.\\n\\nCompositional grounding function of cSCAN. Since the semantics of cSCAN rules is compositional (which is a requirement for all CLTs), we are able to specify the grounding function in a complete yet concise fashion using the following helper constructs. For simplicity, we focus here on describing the compositional grounding function for cSCAN-B. The grounding function for cSCAN-X would follow the same general form.\\n\\n- For any RHS sequence $r \\\\in R^*$, we use $\\\\text{lhs}(r)$ to denote the set of elements of $r$ that are LHS expressions $Q^* N$. For example, $\\\\text{lhs}(W \\\\text{ALK JUMP J run left} KJ \\\\text{look thrice} K) = \\\\{ J \\\\text{run left} K, J \\\\text{look thrice} K \\\\}$.\\n\\n- For any subset of LHS expressions $Q \\\\subseteq Q^* N$, we use $c_2a(Q)$ to denote the set of all possible functions $f: Q \\\\rightarrow A^*$ that map each expression in $Q$ to an action sequence in $A^*$. (Note that this also applies to the empty set, i.e., there is exactly one function in $c_2a(\\\\emptyset)$.)\\n\\n- We define subsets of the commands $Q_N$ generated by the phrase-structure grammar in Figure 5. For each $z \\\\in \\\\{ T, U, V, W, X \\\\}$ the set $Q_z N \\\\subset Q_N$ denotes the commands that are generated when starting from the symbol $z$ (rather than $S$).\\n\\n- For each $z \\\\in \\\\{ T, U, V, W, X \\\\}$, we assume a function $\\\\text{var}_z: Q^* N \\\\rightarrow 2^X$, which map each LHS expression $q \\\\in Q^* N$ to a subset of its variables $\\\\text{var}_z(q)$. For any expression $q \\\\in Q^* N$, the following holds:\\n  - $\\\\text{var}_T(q)$ consists of the variables that are generated using the rule path $T \\\\rightarrow U, U \\\\rightarrow V, V \\\\rightarrow W, W \\\\rightarrow Y$.\\n  - $\\\\text{var}_U(q)$ consists of the variables that are generated using the rule path $U \\\\rightarrow V, V \\\\rightarrow W, W \\\\rightarrow Y$.\\n  - $\\\\text{var}_V(q)$ consists of the variables that are generated using the rule path $V \\\\rightarrow W, W \\\\rightarrow Y$.\\n  - $\\\\text{var}_W(q)$ consists of the variables that are generated using the rule $W \\\\rightarrow Y$.\\n  - $\\\\text{var}_X(q)$ consists of the variables that are generated using the rule $X \\\\rightarrow Y$.\\n\\n- For all LHS expressions $q \\\\in Q^* N$ we use $v_2c(q)$ to denote the set of all possible functions $f: \\\\text{var}(q) \\\\rightarrow Q_N$ that map each variable in $\\\\text{var}(q)$ to a command in $Q_N$ such that $\\\\forall z \\\\in \\\\{ T, U, V, W, X \\\\}: f(\\\\text{var}_z(q)) \\\\in Q_z N$. Note that this restriction of the mapping ensures that variable substitution does not break the implicit precedence rules that apply to the interpretation of commands (see the discussion below for more detail).\\n\\n- For any RHS expression $r \\\\in R^*$ and any partial function $f: R^* \\\\cup X \\\\mapsto R^*$, we use $\\\\text{subst}(r, f)$ to denote the RHS expression that we obtain by lexically substituting in $r$ all occurrences of $r' \\\\in \\\\text{dom}(f)$ with $f(r')$.\"}"}
{"id": "2iu9NhxX23", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The first case of definition 34 applies when the rule $q = r$ does not contain any variables. It says that whenever a LHS expression $q'$ occurs in the RHS expression $r$, we can substitute $q'$ with an arbitrary action sequence $f(q')$ as long as we make sure that the context contains a rule asserting that $q'$ is interpreted as $f(q')$.\\n\\nAs an illustration, consider the grounding of the rule $J\\\\text{run twice and jump}K = J\\\\text{run}KJ\\\\text{run}KJ\\\\text{jump}K\\\\text{LTURN}$ that is shown below. The set of LHS expressions on the right-hand side of this rule is $\\\\{\\\\text{run, jump}\\\\}$. The first example of the grounding can be read as: if $J\\\\text{run}K$ maps to \u201cRUN\u201d and $J\\\\text{jump}K$ maps to \u201cJUMP\u201d then the RHS of the rule becomes \u201cRUN RUN JUMP LTURN\u201d.\\n\\nThe second case of definition 34 applies when the rule $q = r$ contains a set of variables. It says that we can substitute any variable $x$ with a command $f(x)$ that corresponds to the same non-terminal in the parse tree.\\n\\nAs an illustration, consider the grounding of the rule $Jx\\\\text{twice}K = JxKJxK\\\\text{LTURN}$ shown below. In the first example of the grounding, we replace the variable $x$ with the command \u201crun\u201d, in the second example we replace it with \u201cjump around left\u201d, and in the last example we replace it with \u201clook thrice\u201d.\\n\\nNote that because $x_1 \\\\in \\\\text{var}U(Jx_1\\\\text{twice}K)$ and $x_1 \\\\notin \\\\text{var}T(Jx_1\\\\text{twice}K)$, the variable $x_1$ cannot be substituted with commands such as \u201cwalk and jump\u201d that are in $Q_TN$ but not in $Q_UN$. This is important because the grounding would otherwise contain examples that violate the higher precedence of \u201ctwice\u201d when compared to \u201cand\u201d, which is not what we intended. I.e., our formalization makes sure that:\\n\\n$\\\\langle \\\\emptyset, J\\\\text{walk and jump twice}K = J\\\\text{walk and jump}KJ\\\\text{walk and jump}K\\\\text{LTURN}, 1 \\\\rangle \\\\notin G(Jx_1\\\\text{twice}K)$\\n\\nE.4 I nductive Bias\\n\\nAs discussed in Appendix E.4, the inductive bias of a CLT is the criteria based upon which a learner is expected to induce a rule to be \u201ctrue\u201d as opposed to considering it to be \u201cunknown\u201d. For cSCAN, we adopt a simple set of criteria, based loosely on our own intuition, in which we consider there to be sufficient evidence to support induction of a rule if there are examples in the context that could be explained by the given rule (in combination with other rules that are explicitly or implicitly provided in the context) and which in total illustrate at least 4 different substitutions of each of the rule\u2019s variables. The number 4 is arbitrary, but based on our intuition that we would be comfortable in generalizing rules from a relatively small number of examples, but that 2 examples is not quite enough to justify inducing a general pattern. We chose the threshold of 4 rather than 3 because we use the inductive bias criteria internally for determining the minimum number of illustrating examples to include in the context for each rule that we intend to be induced to be \u201ctrue\u201d, and we wanted to avoid penalizing a learner that is slightly cautious in its inductions.\"}"}
{"id": "2iu9NhxX23", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Here we discuss the rationale behind the design choices made in our definition of a Conceptual Learning\\nTask (CLT).\\n\\nSplitting the input into a set-like context and a request. The main goal of CLTs is to test whether\\na learner is capable of learning from explicitly provided knowledge consisting of rules and examples.\\nAssuming a supervised learning setup as a basis, the applicable knowledge must somehow be provided in\\nthe input of each example. It is therefore quite natural to split the input into two parts: context and request.\\nSince the examples and rules that form the background knowledge do not usually have a specific order (in\\nthe movie recommendation example for instance, it does not matter whether we are first told that Top Gun is\\nrated PG-13 or that Jerry Maguire is rated R), representing the context as an unordered set is a natural choice.\\n\\nRepresenting rule assertions as examples. Another important property of CLTs is the ability to ask\\nthe learner explicitly whether a certain rule holds (in a given context). One straightforward way to\\nachieve this is to include examples where the request asks for the validity of a certain rule and the\\noutput provides the corresponding truth value. These kind of examples also provide us with a natural\\nway to assert (or refute) rules in the context, which allows us to represent the context simply as a set\\nof examples (rather than a heterogeneous set containing both examples and a dedicated representation\\nof rule assertions and refutations).\\n\\nDistinguishing monotonic and defeasible replies. Once we include the context as part of the input, we\\ncan distinguish between two different methods of how the learner may determine the reply for a given\\nrequest: deduction and induction. For deduction, the learner infers the reply for a given request from\\nthe context using deductive reasoning alone. As an illustration, consider an example where we assert in\\nthe context that Top Gun is a PG-13 movie and then ask for the rating of Top Gun in the request (see\\nAppendix D for a formalization of the logic axioms underlying deductive reasoning).\\n\\nFor induction, the information provided by the context is not sufficient to unambiguously determine the\\nreply for a given request. As an illustration, suppose that we ask for the rating of Jerry Maguire in an\\nexample whose context asserts that both Mission Impossible 1 and Jerry Maguire are movies starring\\nTom Cruise and that Mission Impossible 1 is rated PG-13. This information is not sufficient for us to\\ndeduce the answer. Instead, the learner needs to rely on inductive bias to determine whether it should\\nspeculatively generalize the PG-13 rating from Mission Impossible 1 to Jerry Maguire or whether it\\nshould play it safe and say that it doesn\u2019t know.\\n\\nDeductive reasoning is always monotonic w.r.t. the context (i.e., new knowledge cannot lead to a different\\nreply), so we use the qualifier $M$ to indicate deductive replies. Inductive reasoning is always defeasible\\nw.r.t. the context (i.e., new knowledge may lead to a different reply), so we use the qualifier $D$\\n\\nB M O T I V A T I N G E X A M P L E A S C L T\\n\\nHere we show what the motivating example from the introduction (Figure 1) could look like when formu-\\nlated in the syntax of a CLT. Here we take $Q$ to be the space of natural language statements and questions.\\n\\nContext containing assertions of relevant knowledge:\\n\\n$C_1 = \\\\{ \\\\langle \\\\text{\"R rated movies are not appropriate for kids who are less than 17 years old.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"The age of a person is the time that has passed since the person was born.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"The current date is June 3, 2021.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"Mission Impossible 1 \u2013 6 are PG-13 rated action movies starring Tom Cruise.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"Jerry Maguire is an R rated comedy starring Tom Cruise.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"Anna was born in January of 2008 and Tom Cruise is her favorite actor.\"}, 1 \\\\rangle, \\\\langle \\\\text{\"Anna saw Mission Impossible 1 \u2013 5 and liked all of them.\"}, 1 \\\\rangle, \\\\ldots \\\\}$\"}"}
{"id": "2iu9NhxX23", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Top-level example set containing a mixture of non-rule examples (natural language QA for movie recommendations) and rule examples (which probe the model's understanding of intermediate steps in the recommendation process):\\n\\n\\\\[\\n\\\\langle C_1, \\\\text{\"What movie could Anna watch?\"}, \\\\text{\"Mission Impossible 6\"} \\\\rangle,\\n\\\\langle C_1, \\\\text{\"Anna is 14 years old.\"}, 1, M \\\\rangle,\\n\\\\langle C_1, \\\\text{\"Anna is at least 17 years old.\"}, 0, M \\\\rangle,\\n\\\\langle C_1, \\\\text{\"Jerry Maguire is appropriate for 14-year-olds.\"}, 0, M \\\\rangle,\\n\\\\langle C_1, \\\\text{\"Anna will like Mission Impossible 6.\"}, 1, D \\\\rangle,\\n\\\\langle C_1, \\\\text{\"Tom Cruise is Anna's best friend.\"}, ?, D \\\\rangle,\\n\\\\ldots\\n\\\\]\\n\\nThe above is a relatively straightforward translation of the motivating example into CLT syntax, while using the format of rule examples for all of the context examples and for all of the intermediate questions. If we assume that the request space \\\\( Q \\\\) and reply space \\\\( R \\\\) include natural language questions and answers for querying about background knowledge, as well as for the end goal of providing movie recommendations, the above example could be alternatively expanded to represent some of the background knowledge in non-rule format (e.g., \\\\( \\\\langle \\\\text{\"What is the rating of Jerry Maguire?\"}, R \\\\rangle \\\\)) and/or to represent some of the intermediate questions as non-rule top-level examples (e.g., \\\\( \\\\langle C_1, \\\\text{\"How old is Anna?\"}, \\\\text{\"14 years\"} \\\\rangle \\\\)).\\n\\n**GENERALIZATION OF CLTs TO SUPPORT NEUTRAL CONTEXTS**\\n\\nAs discussed in Section 2, since the context of each top-level example in a CLT is itself represented as a set of \u201cexamples\u201d, we have similar but slightly different notions of \u201cexample\u201d at two different levels in a CLT:\\n\\n- **Top-level examples**, which we represent as quadruples of \\\\( \\\\langle \\\\text{context}, \\\\text{request}, \\\\text{reply}, \\\\text{qualifier} \\\\rangle \\\\).\\n- **Context examples**, which in Section 2 we require to be unconditional and monotonic and which we thus represent as simply \\\\( \\\\langle \\\\text{request}, \\\\text{reply} \\\\rangle \\\\) pairs.\\n\\nWhile for the simple cSCAN task, it was sufficient to provide only unconditional monotonic examples in the context, in the general case, one could imagine extensions of the notion of a CLT to allow inclusion of conditional and/or defeasible examples in the context as well. In this more general view of a CLT, we can drop the distinction between top-level examples and context examples, and instead adopt a recursive structure in which each example is a quadruple of \\\\( \\\\langle \\\\text{context}, \\\\text{request}, \\\\text{reply}, \\\\text{qualifier} \\\\rangle \\\\), while each context is a set of examples.\\n\\nOne motivation for this more general view of CLTs is if we were to think of each top-level CLT example as representing one observation of the behavior of a personal assistant with very strong decision-making capabilities (which we might call the \u201cteacher\u201d), whose behavior at all times is conditioned on the knowledge available to it, and whose knowledge is stored in a large and growing set-like knowledge base. In this view, the context of the top-level example can be thought of as a snapshot of the relevant contents of the assistant's knowledge base at the time that the assistant received the given request and output the given reply and qualifier.\\n\\nNow let us further suppose that we have another personal assistant (which we might call the \u201cstudent\u201d), which itself has some kind of growing set-like knowledge base, whose contents may or may not agree with the contents of the teacher's knowledge base. One interesting question is how the student can go about selectively \u201clearning\u201d from the teacher, so as to emulate its decision-making capabilities, without necessarily accepting wholesale the full contents of its knowledge base, which may also include information that is transient, situation-specific, or debatable, and which may thus not be relevant or appropriate for the student to adopt. One natural approach could be to simply select the top-level examples of interest (i.e., to select the specific instances of the teacher\u2019s behavior that the student wishes to emulate) and assert those examples in the student's knowledge base. This would be the equivalent of storing the knowledge...\"}"}
{"id": "2iu9NhxX23", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nthat \\\"if such and such things (i.e., the contents of the example's context) were true, then when faced with the given request, this would be the appropriate reply and the appropriate qualifier\\\".\\n\\nUnder this approach, the student's set-like knowledge base would now come to contain full CLT examples (including context and qualifier). Continuing with the view of a \\\"context\\\" as being a snapshot of some or all of an assistant's knowledge base, our contexts could now contain examples that themselves contain non-empty contexts. The maximum depth to which we allow such recursive structures to continue could be considered an arbitrary choice in the design of a conceptual learning system or task.\\n\\nC.1 Generalized CLT\\n\\nBelow is a formalization of this more general definition of a CLT, along with some shorthand notations, by which the simpler CLT definition from Section 2 can be seen as just a special case of the general definition.\\n\\n\u2022 The task \\\\( T = \\\\{ e_1, \\\\ldots, e_N \\\\} \\\\) is a finite set of examples \\\\( e_k \\\\in E \\\\), where \\\\( E = I \\\\times O \\\\) denotes the set of possible examples, with \\\\( I \\\\) being the set of possible inputs and \\\\( O \\\\) the possible outputs.\\n\\n\u2022 Each example \\\\( e_k = \\\\langle i_k, o_k \\\\rangle \\\\) is a pair consisting of an input \\\\( i_k \\\\in I \\\\) and an output \\\\( o_k \\\\in O \\\\).\\n\\n\u2022 Each input \\\\( i_k = \\\\langle C, q \\\\rangle \\\\) is a pair consisting of a context \\\\( C \\\\in 2^E \\\\) and a request \\\\( q \\\\in Q \\\\). The set of possible requests \\\\( Q \\\\) can be partitioned into rule requests \\\\( Q_R \\\\subseteq Q \\\\) (i.e., requests that ask whether a certain rule holds) and non-rule requests \\\\( Q_N \\\\subseteq Q \\\\).\\n\\n\u2022 Each output \\\\( o_k = \\\\langle r, u \\\\rangle \\\\) is a pair consisting of the reply \\\\( r \\\\in R \\\\) and a qualifier \\\\( u \\\\in U \\\\). The set of possible replies \\\\( R \\\\) must contain dedicated elements representing true (1), false (0), and unknown (?), which are the only valid replies for rule requests \\\\( q \\\\in Q_R \\\\). The set of qualifiers \\\\( U = \\\\{ M, D \\\\} \\\\) indicates whether the reply follows monotonically from the context (M) or whether it is defeasible (D).\\n\\nFor conciseness, we use the flat notation \\\\( \\\\langle C, q, r, u \\\\rangle \\\\) to mean the nested pairs \\\\( \\\\langle \\\\langle C, q \\\\rangle, \\\\langle r, u \\\\rangle \\\\rangle \\\\), we use \\\\( \\\\langle C, q, r \\\\rangle \\\\) as a shorthand for the monotonic example \\\\( \\\\langle C, q, r, M \\\\rangle \\\\), and we use \\\\( \\\\langle q, r \\\\rangle \\\\) as a shorthand for the unconditional monotonic example \\\\( \\\\langle \\\\emptyset, q, r, M \\\\rangle \\\\). Hence, the example \\\\( \\\\langle C, q, r \\\\rangle \\\\) means that given the context \\\\( C \\\\) or any superset of \\\\( C \\\\), the request \\\\( q \\\\) is translated to the reply \\\\( r \\\\), while \\\\( \\\\langle q, r \\\\rangle \\\\) means that under all circumstances, the request \\\\( q \\\\) is translated to the reply \\\\( r \\\\).\\n\\nNote that even though the context is strictly a set of examples, it may still contain any rule \\\\( q \\\\in Q_R \\\\) by means of including the example \\\\( \\\\langle \\\\emptyset, q, 1, M \\\\rangle \\\\), which asserts the rule \\\\( q \\\\) to be true unconditionally. Similarly, we can express that the rule \\\\( q \\\\) does not hold in a context by including the example \\\\( \\\\langle \\\\emptyset, q, 0, M \\\\rangle \\\\).\\n\\nWe refer to an example as unconditional if it has an empty context. Note also that since examples within a context are of the same form as top-level examples, they may in principle themselves contain contexts up to arbitrary levels of nesting. We can, however, for any given CLT, choose a maximum level to which we allow such nesting to occur. In cSCAN, for example, contexts contain only unconditional examples, so that there is no nesting of contexts.\\n\\nC.2 Additional shorthand for rule assertions in a context\\n\\nTo express the assertion of a rule \\\\( q \\\\in Q_R \\\\) in contexts more concisely, we use \\\\( q \\\\) to mean its unconditional monotonic assertion \\\\( \\\\langle \\\\emptyset, q, 1, M \\\\rangle \\\\). For instance, \\\\( \\\\langle \\\\{ q \\\\}, q', r \\\\rangle \\\\) stands for \\\\( \\\\langle \\\\{ \\\\langle \\\\emptyset, q, 1, M \\\\rangle \\\\} \\\\}, q', r \\\\rangle \\\\).\\n\\nIn the example from Figure 1, if we take \\\\( Q \\\\) to be the space of natural language statements and questions, then with the above shorthand the following would be equivalent:\\n\\n\u2022 \\\\( \\\\langle \\\\{ \\\\langle \\\\emptyset, \\\\text{\\\"Anna was born in January of 2008.\\\"}, 1, M \\\\rangle \\\\} \\\\}, \\\\text{\\\"Who is Anna's best friend?\\\"}, ?, D \\\\rangle \\\\)\\n\\n\u2022 \\\\( \\\\langle \\\\{ \\\\text{\\\"Anna was born in January of 2008.\\\"} \\\\}, \\\\text{\\\"Who is Anna's best friend?\\\"}, ?, D \\\\rangle \\\\)\"}"}
{"id": "2iu9NhxX23", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"allows us to map example sets to logical formulas, which in turn allows us to formalize the consistency requirements as well as the metrics for measuring consistency of a learner.\\n\\nFor the purposes of this formalization, we assume the more general form of a CLT described in Appendix C, for which the simpler CLT form used for cSCAN follows as a special case.\\n\\nNote that while we provide this formalization for reference purposes and to facilitate future investigation into the formal properties of CLTs, it is possible in practice to use CLTs and the related consistency metric without detailed consideration of this formalization.\\n\\nD.1 TERMINOLOGY\\n\\nIf not otherwise indicated, we assume that $C, C' \\\\in 2^E$ are arbitrary contexts, $q, q' \\\\in Q$ are arbitrary requests, $r, r' \\\\in R$ are arbitrary replies, $u, u' \\\\in U$ are arbitrary qualifiers, $E, E', F \\\\in E$ are arbitrary example sets, and $e, e', f$ are arbitrary examples.\\n\\nFurthermore, we assume that $M(e)$ and $D(e)$ denote the monotonic and defeasible variants of the example $e$, respectively. This means that for any $u \\\\in U$, $M(\\\\langle C, q, r, u \\\\rangle) = \\\\langle C, q, r, M \\\\rangle$ and $D(\\\\langle C, q, r, u \\\\rangle) = \\\\langle C, q, r, D \\\\rangle$.\\n\\nD.2 CLASSICAL PROPOSITIONAL LOGIC\\n\\nFor reference in later proofs, we summarize the basic definitions and axioms of Lukasiewicz classical propositional logic (Klement, 2004), which we adopt as-is, with only a change of symbols for the logical connectives to avoid ambiguity with the $\\\\land$, $\\\\lor$, and $\\\\neg$ symbols that we use elsewhere in this document in first order logic statements.\\n\\nWe assume a set of propositional variables $V$ which represent atomic formulas. General logical formulas $L$ are recursively constructed from these atomic formulas using the logical connectives $\\\\to$ (implication), $\\\\neg$ (negation), $\\\\land$ (and), $\\\\lor$ (or), and $\\\\equiv$ (equivalence). In our formalization, we assume the primitive connectives $\\\\to$ and the constant $\\\\bot$ (falsum), and we define the other connectives as follows (assuming that $x, y, z \\\\in L$).\\n\\n$\\\\neg x := x \\\\to \\\\bot$ (1)\\n$x \\\\lor y := \\\\neg x \\\\to y$ (2)\\n$x \\\\land y := \\\\neg (x \\\\to \\\\neg y)$ (3)\\n$x \\\\equiv y := (x \\\\to y) \\\\land (y \\\\to x)$ (4)\\n$\\\\top := \\\\neg \\\\bot$ (5)\\n\\nTo formulate the propositional logic axioms and inference rules, we use the notation $x \\\\vdash y$ to express that we can infer $y$ from $x$ and we use $\\\\vdash x$ to express that $x$ is a tautology.\\n\\n$\\\\vdash x \\\\to (y \\\\to x)$ (6)\\n$\\\\vdash (x \\\\to (y \\\\to z)) \\\\to ((x \\\\to y) \\\\to (x \\\\to z))$ (7)\\n$\\\\vdash (\\\\neg x \\\\to \\\\neg y) \\\\to (y \\\\to x)$ (8)\\n$x, (x \\\\to y) \\\\vdash y$ (9)\\n\\nThe axioms (6), (7), (8) form the Lukasiewicz system, while the inference rule (9) is modus ponens.\\n\\nD.3 SEMANTICS OF RULES AND INDUCTIVE BIAS\\n\\nTo map example sets to logical formulas, we need to be able to refer to the semantics of rules and the inductive bias.\\n\\nFor the semantics of rules, we assume a grounding function $G: QR \\\\to 2^E$, which maps each rule to an equivalent set of examples. This means that in a consistent task, a rule $q \\\\in QR$ holds (i.e., $\\\\langle \\\\emptyset, q, 1 \\\\rangle$ is a valid example) if and only if each example in $G(q)$ is valid. It also means that if the context of an example $e \\\\in E$ holds, then $\\\\langle C, q, r, u \\\\rangle$ is a valid example. This is denoted as $\\\\langle C, q, r, u \\\\rangle$.\"}"}
{"id": "2iu9NhxX23", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Timothy Hospedales, Antreas Antoniou, Paul Micaelli, and Amos Storkey. Meta-learning in neural networks: A survey. *IEEE transactions on pattern analysis and machine intelligence*, 44(9):5149\u20135169, 2021.\\n\\nDrew A. Hudson and Christopher D. Manning. GQA: A new dataset for real-world visual reasoning and compositional question answering. In *CVPR*, 2019. URL https://arxiv.org/pdf/1902.09506.pdf.\\n\\nJustin Johnson, Bharath Hariharan, Laurens van der Maaten, Fei-Fei Li, Lawrence C. Zitnick, and Ross Girshick. CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. In *CVPR*, 2017. URL https://arxiv.org/pdf/1612.06890.pdf.\\n\\nDaniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang, Marc van Zee, and Olivier Bousquet. Measuring compositional generalization: A comprehensive method on realistic data. In *ICLR*, 2020. URL https://arxiv.org/abs/1912.09713.pdf.\\n\\nKevin C. Klement. Propositional logic. In *Internet Encyclopedia of Philosophy*. 2004.\\n\\nTaku Kudo and John Richardson. Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. In Eduardo Blanco and Wei Lu (eds.), *Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018: System Demonstrations*, Brussels, Belgium, October 31 - November 4, 2018, pp. 66\u201371. Association for Computational Linguistics, 2018. doi: 10.18653/v1/d18-2012. URL https://doi.org/10.18653/v1/d18-2012.\\n\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: a benchmark for question answering research. *Transactions of the Association of Computational Linguistics*, 2019.\\n\\nBrenden M. Lake. Compositional generalization through meta sequence-to-sequence learning. In *Advances in Neural Information Processing Systems*, pp. 9788\u20139798, 2019.\\n\\nBrenden M. Lake and Marco Baroni. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. 2017.\\n\\nBrenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through probabilistic program induction. *Science*, 350(6266):1332\u20131338, 2015.\\n\\nBrenden M. Lake, Tal Linzen, and Marco Baroni. Human few-shot learning of compositional instructions. In Ashok K. Goel, Colleen M. Seifert, and Christian Freksa (eds.), *Proceedings of the 41th Annual Meeting of the Cognitive Science Society, CogSci 2019: Creativity + Cognition + Computation*, Montreal, Canada, July 24-27, 2019, pp. 611\u2013617. cognitivesciencesociety.org, 2019. URL https://mindmodeling.org/cogsci2019/papers/0123/index.html.\\n\\nHector J. Levesque, Ernest Davis, and Leora Morgenstern. The Winograd Schema Challenge. In *Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning*, KR'12, pp. 552\u2013561. AAAI Press, 2012. ISBN 978-1-57735-560-1. URL https://cs.nyu.edu/faculty/davise/papers/WSKR2012.pdf.\\n\\nTao Li, Vivek Gupta, Maitrey Mehta, and Vivek Srikumar. A logic-driven framework for consistency of neural models. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (eds.), *EMNLP/IJCNLP (1)*, pp. 3922\u20133933. Association for Computational Linguistics, 2019. ISBN 978-1-950737-90-1. URL http://dblp.uni-trier.de/db/conf/emnlp/emnlp2019-1.html#LiGMS19.\\n\\nQian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, and Dongmei Zhang. Compositional generalization by learning analytical expressions. *Advances in Neural Information Processing Systems*, 33:11416\u201311427, 2020.\\n\\nMaxwell Nye, Michael Tessler, Josh Tenenbaum, and Brenden M Lake. Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning. *Advances in Neural Information Processing Systems*, 34:25192\u201325204, 2021.\"}"}
{"id": "2iu9NhxX23", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nMaxwell I. Nye, Armando Solar-Lezama, Joshua B. Tenenbaum, and Brenden M. Lake. Learning compositional rules via neural program synthesis, 2020.\\n\\nSantiago Onta\u00f1\u00f3n, Joshua Ainslie, VACLAV CVICEK, and Zachary Fisher. Making transformers solve compositional tasks. CoRR, abs/2108.04378, 2021. URL https://arxiv.org/abs/2108.04378.\\n\\nLong Ouyang, Jeff Wutrain, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback, 2022. URL https://arxiv.org/abs/2203.02155.\\n\\nPanupong Pasupat, Yuan Zhang, and Kelvin Guu. Controllable semantic parsing via retrieval augmentation. arXiv preprint arXiv:2110.08458, 2021.\\n\\nLinlu Qiu, Peter Shaw, Panupong Pasupat, Pawel Krzysztof Nowak, Tal Linzen, Fei Sha, and Kristina Toutanova. Improving compositional generalization with latent structure and data augmentation. In Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz (eds.), Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.naacl-main.323. URL https://doi.org/10.18653/v1/2022.naacl-main.323.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683, 2019.\\n\\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250, 2016.\\n\\nChandra Reddy and Prasad Tadepalli. Learning first-order acyclic horn programs from entailment. In International Conference on Inductive Logic Programming, pp. 23\u201337. Springer, 1998.\\n\\nAdam Roberts, Hyung Won Chung, Anselm Levskaya, Gaurav Mishra, James Bradbury, Daniel Andor, Sharan Narang, Brian Lester, Colin Gaffney, Afroz Mohiuddin, Curtis Hawthorne, Aitor Lewkowycz, Alex Salcianu, Marc van Zee, Jacob Austin, Sebastian Goodman, Livio Baldini Soares, Haitang Hu, Sasha Tsvyashchenko, Aakanksha Chowdhery, Jasmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo Ni, Andrew Chen, Kathleen Kenealy, Jonathan H. Clark, Stephan Lee, Dan Garrette, James Lee-Thorp, Colin Raffel, Noam Shazeer, Marvin Ritter, Maarten Bosma, Alexandre Passos, Jeremy Maitin-Shepard, Noah Fiedel, Mark Omernick, Brennan Saeta, Ryan Sepassi, Alexander Spiridonov, Joshua Newlan, and Andrea Gesmundo. Scaling up models and data with t5x and seqio. arXiv preprint arXiv:2203.17189, 2022. URL https://arxiv.org/abs/2203.17189.\\n\\nMelissa Roemmele, Cosmin Adrian Bejan, and Andrew S. Gordon. Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning. In AAAI Spring Symposium on Logical Formalizations of Commonsense Reasoning, Stanford University, March 2011. URL http://ict.usc.edu/pubs/Choice%20of%20Plausible%20Alternatives-%20An%20Evaluation%20of%20Commonsense%20Causal%20Reasoning.pdf.\\n\\nLaura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden M. Lake. A benchmark for systematic generalization in grounded language understanding, 2020.\\n\\nDaniel Lehmann Sarit Kraus and Menachem Magidor. Nonmonotonic reasoning, preferential models and cumulative logics. Journal of Artificial Intelligence, Vol. 44 Nos. 1-2:167\u2013207, 1990. URL https://arxiv.org/abs/cs/0202021.\"}"}
{"id": "2iu9NhxX23", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nBen Snyder, Stephon Striplin, Yuh Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, and Alexander Zotov. Task-oriented dialogue as dataflow synthesis. Transactions of the Association for Computational Linguistics, 8:556\u2013571, September 2020. URL https://doi.org/10.1162/tacl_a_00333.\\n\\nPeter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova. Compositional generalization and natural language variation: Can a semantic parsing approach handle both? arXiv preprint arXiv:2010.12725, 2020.\\n\\nKoustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. Clutrr: A diagnostic benchmark for inductive reasoning from text. Empirical Methods of Natural Language Processing (EMNLP), 2019.\\n\\nKoustuv Sinha, Shagun Sodhani, Joelle Pineau, and William L. Hamilton. Evaluating logical generalization in graph neural networks, 2020.\\n\\nMadhumita Sushil, Simonuster, and Walter Daelemans. Rule induction for global explanation of trained models, 2018.\\n\\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge, 2020.\\n\\nYi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers. arXiv preprint arXiv:2011.04006, 2020a.\\n\\nYi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. Efficient transformers: A survey. ACM Computing Surveys (CSUR), 2020b.\\n\\nSebastian Thrun and Lorien Pratt. Learning to Learn, chapter Learning to Learn: Introduction and Overview, pp. 3\u201317. Springer, Boston, MA, 1998. ISBN 978-1-4613-7527-2. URL https://doi.org/10.1007/978-1-4615-5529-2_1.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, 2017. URL https://arxiv.org/pdf/1706.03762.pdf.\\n\\nPat Verga, Haitian Sun, Livio Baldini Soares, and William W Cohen. Facts as experts: Adaptable and interpretable neural memory over symbolic knowledge. arXiv preprint arXiv:2007.00849, 2020.\\n\\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768, 2020.\\n\\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Eganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. Benchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint arXiv:2204.07705, 2022.\\n\\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yuh, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=gEZrGCozdqR.\\n\\nJason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van Merrienboer, Armand Joulin, and Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks, 2015.\\n\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun\u2019ichi Tsujii (eds.), Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pp. 2369\u20132380. Association for Computational Linguistics, 2018. doi: 10.18653/v1/d18-1259. URL https://doi.org/10.18653/v1/d18-1259.\"}"}
{"id": "2iu9NhxX23", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In EMNLP, 2018. URL https://arxiv.org/pdf/1809.08887.pdf.\\n\\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for longer sequences. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization, 2019.\\n\\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022.\"}"}
{"id": "2iu9NhxX23", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\ncontains the assertion $\\\\langle \\\\emptyset, q, 1 \\\\rangle$ of a rule $q \\\\in Q_R$, we can obtain an equivalent example $e'$ by replacing the assertion of $q$ with the examples $G(q)$. We provide the grounding function of cSCAN in Appendix E.3.\\n\\nSince a CLT requires a learner to induce as well as deduce rules, every CLT inherently assumes some form of inductive bias, which determines the criteria based upon which a learner is expected to induce a rule to be \\\"true\\\" vs. considering it to be \\\"unknown\\\". While the inductive bias of the task is in principle arbitrary (being dependant on the choice of the task designer or the needs of the real-world use case), the learner will need to be able to emulate this bias in order to perform well on the task. We formalize this domain-specific inductive bias through a bias function $B : 2^E \\\\rightarrow 2^{E_D}$, which maps each set of examples to the set of examples that are expected to be induced. We use $E_M, E_D \\\\subseteq E$ to denote the subsets of all monotonic and defeasible examples, respectively. We provide the bias function of cSCAN in Appendix E.4.\\n\\nWhile the grounding and bias functions are needed to precisely formalize the consistency requirements and metrics, they are not a requirement for a conceptual learning task. This is important because providing complete grounding and bias functions may not be feasible or practical for more realistic CLTs. Instead, we may only provide partial functions, which means that the formalization in this section will only approximate the true consistency requirements and consistency metrics.\\n\\nD.4 Mapping example sets to logical formulas\\n\\nWe treat each example as a propositional variable (i.e, $\\\\langle C, q, r, u \\\\rangle \\\\in V$). This allows us to define the embedding function $M : 2^E \\\\rightarrow L$ as follows.\\n\\n$$M(\\\\emptyset) := \\\\top \\\\quad (10)$$\\n\\n$$M(\\\\{\\\\langle C, q, r, u \\\\rangle\\\\}) := \\\\langle C, q, r, u \\\\rangle \\\\quad (11)$$\\n\\n$$M(E \\\\cup E') := M(E) \\\\land M(E') \\\\quad (12)$$\\n\\nThe empty set maps to true (10), a set of size one maps to its only element (11), and union maps to logical conjunction (12). In addition, our embedding adheres to the following axioms.\\n\\n$$\\\\vdash \\\\langle C, q, r, M \\\\rangle \\\\equiv (M(C) \\\\rightarrow \\\\langle \\\\emptyset, q, r, M \\\\rangle) \\\\quad (13)$$\\n\\n$$\\\\vdash \\\\langle C, q, r, M \\\\rangle \\\\rightarrow \\\\langle C, q, r, D \\\\rangle \\\\quad (14)$$\\n\\n$$M(C) \\\\equiv M(C') : \\\\vdash \\\\langle C, q, r, D \\\\rangle \\\\equiv \\\\langle C', q, r, D \\\\rangle \\\\quad (15)$$\\n\\n$$r \\\\neq r' : \\\\vdash \\\\langle C, q, r, D \\\\rangle \\\\land \\\\langle C, q, r', D \\\\rangle \\\\rightarrow (C \\\\rightarrow \\\\bot) \\\\quad (16)$$\\n\\n$$\\\\vdash \\\\langle \\\\emptyset, q, 1, M \\\\rangle \\\\equiv M(G(q)) \\\\quad (17)$$\\n\\n$$\\\\vdash M(E) \\\\rightarrow M(B(E)) \\\\quad (18)$$\\n\\nAxiom (13) says that the context of a monotonic example becomes the antecedent of a logical implication, and axiom (14) specifies that a monotonic examples implies the corresponding defeasible example. Axiom (15) says that defeasible examples that differ only in equivalent contexts are equivalent. Axiom (16) specifies that defeasible examples are functional or the context must be contradictory, which means that each request with a non-contradictory context must have a unique reply. Finally, axiom (17) specifies that the assertion of a rule is equivalent to its grounding, and axiom (18) says that each set of examples implies the set of examples that can be induced using the inductive bias.\\n\\nTogether with the axioms of propositional logic, we obtain the following theorems.\\n\\n$$\\\\vdash \\\\langle C, q, r, M \\\\rangle \\\\rightarrow \\\\langle C \\\\cup C', q, r, M \\\\rangle \\\\quad (19)$$\\n\\n$$\\\\vdash M(\\\\{\\\\langle C, q, 1, M \\\\rangle\\\\}) \\\\equiv M(\\\\{\\\\langle C \\\\cup C', q', r', u' \\\\rangle : \\\\langle C', q', r', u' \\\\rangle \\\\in G(q)\\\\}) \\\\quad (20)$$\\n\\n$$r \\\\neq r' : \\\\vdash \\\\langle C, q, r, u \\\\rangle \\\\land \\\\langle C, q, r', u \\\\rangle \\\\rightarrow (C \\\\rightarrow \\\\bot) \\\\quad (21)$$\\n\\nTheorem (19) is obtained from axioms (6), (13) and (12), and it says that monotonic examples behave monotonically w.r.t. their context. This allows us to rewrite the grounding axiom (17) to obtain theorem (20). The last theorem (21) says that functionality applies independently of the qualifier.\"}"}
{"id": "2iu9NhxX23", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As discussed in Section 4, the consistency metric $C(E)$ differs from the standard accuracy metric in that it does not judge the correctness of a learner's predictions on individual examples, but rather measures the degree to which a complete set of examples $E$ is consistent w.r.t. to the axioms of classical propositional logic.\\n\\nIn essence, we define $C(E)$ to be the percentage of subsets of $E$ that contain a logical implication, in comparison to the number of subsets of $E$ that contain an implication or a contradiction.\\n\\nNote that the definition of the consistency metric provided in equation (26) could essentially be applied as-is to any arbitrary CLT, provided there is some way to identify the \u201cimplications\u201d ($\\\\text{impl}(E)$) and \u201ccontradictions\u201d ($\\\\text{cont}(E)$) among the learner's predictions. In practice, task designers may be free to apply any reasonable heuristic to identify such implications and contradictions. The formal definition of the consistency metric below can be considered an ideal, which we seek to emulate closely in the consistency metric implementation provided for cSCAN, as described in Appendix G.\\n\\n$$E \\\\not\\\\hookrightarrow \\\\rightarrow f : \\\\iff \\\\not\\\\models \\\\neg M(E) \\\\land \\\\vdash M(E) \\\\rightarrow M\\\\{f\\\\} \\\\land \\\\not\\\\exists E' \\\\subset E : \\\\vdash M(E') \\\\rightarrow M\\\\{f\\\\} \\\\land \\\\not(f \\\\in E \\\\land \\\\not\\\\vdash M(E) \\\\rightarrow M\\\\{f\\\\}) \\\\quad (22)$$\\n\\n$$E \\\\hookrightarrow \\\\rightarrow f : \\\\iff \\\\not\\\\models \\\\neg M(E) \\\\land \\\\vdash M(E) \\\\rightarrow \\\\neg M\\\\{f\\\\} \\\\land \\\\not\\\\exists E' \\\\subset E : \\\\models M(E') \\\\rightarrow \\\\neg M\\\\{f\\\\}) \\\\lor (f \\\\in E \\\\land E \\\\hookrightarrow \\\\rightarrow M\\\\{f\\\\}) \\\\quad (23)$$\\n\\n$$\\\\text{impl}(E) := \\\\{F \\\\subseteq E : (\\\\exists f \\\\in F : F\\\\{f\\\\} \\\\hookrightarrow \\\\rightarrow \\\\{f\\\\})\\\\} \\\\quad (24)$$\\n\\n$$\\\\text{cont}(E) := \\\\{F \\\\subseteq E : (\\\\exists f \\\\in F : F\\\\{f\\\\} \\\\not\\\\hookrightarrow \\\\rightarrow \\\\{f\\\\})\\\\} \\\\quad (25)$$\\n\\n$$C(E) := \\\\frac{100 \\\\cdot |\\\\text{impl}(E)|}{|\\\\text{impl}(E)| + |\\\\text{cont}(E)|}, \\\\text{NaN, otherwise} \\\\quad (26)$$\\n\\nMinimal implication $E \\\\hookrightarrow \\\\rightarrow f$ means that the non-contradictory example set $E$ implies the example $f$ and that there is no strict subset of $E$ that has the same property. Furthermore, we require matching qualifiers, which means that $E$ must not imply the monotonic variant of $f$ if the latter is marked as defeasible (22).\\n\\nThe minimal contradiction $E \\\\not\\\\hookrightarrow \\\\rightarrow f$ can be met by either of the following two conditions (23). First, $E \\\\not\\\\hookrightarrow \\\\rightarrow f$ holds if the non-contradictory example set $E$ implies the negation of $f$ and there is no strict subset of $E$ that has the same property. Secondly, $E \\\\not\\\\hookrightarrow \\\\rightarrow f$ holds if there is a qualifier mismatch, i.e., if $f$ is marked defeasible but $E$ minimally implies the monotonic variant of $f$. Note that we do not consider it to be a qualifier mismatch if $f$ is marked as monotonic and $E$ implies only the defeasible variant because there may be other evidence outside of $E$ that may justify the monotonic qualifier.\\n\\nThis allows us to define $\\\\text{impl}(E)$ to be the set of subsets $F \\\\subseteq E$ that contain a minimal implication (24) and $\\\\text{cont}(E)$ to be the set of subsets $F \\\\subseteq E$ that contain a minimal contradiction (25). Finally, the consistency metric $C(E)$ is the percentage of subsets of $E$ that contain implications, in comparison with the number of subsets of $E$ that contain implications or contradictions (26). If the set $E$ does not contain any implications or contradictions, then the consistency metric is not defined.\\n\\nIllustration. As an illustration, consider the following example set $E$, which consists of 4 rule assertions and 8 examples. (We assume the syntax and semantics of cSCAN, which is formally specified in Appendix E.)\\n\\n$$E := \\\\{\\\\langle C_1, \\\\text{Ju twice} = \\\\text{Ju} \\\\text{Ju} \\\\text{Ju} = \\\\text{Ju} \\\\text{Ju} \\\\text{Ju} \\\\text{Ju} \\\\rangle, \\\\langle C_1, \\\\text{Jx after y} = \\\\text{Jy} \\\\text{Jx} \\\\text{Jx} = \\\\text{Jy} \\\\text{Jx} \\\\text{Jx} \\\\rangle, \\\\langle C_1, \\\\text{walk} = \\\\text{WALK} \\\\text{WALK} \\\\text{WALK} \\\\text{WALK} \\\\text{WALK} \\\\text{WALK}, \\\\langle C_1, \\\\text{jump} = \\\\text{JUMP} \\\\text{JUMP} \\\\text{JUMP} \\\\text{JUMP} \\\\text{JUMP} \\\\text{JUMP} \\\\rangle, \\\\langle C_1, \\\\text{walk}, \\\\text{WALK} \\\\rangle, \\\\langle C_1, \\\\text{eat twice}, \\\\text{EAT EAT} \\\\rangle, \\\\langle C_1, \\\\text{walk twice}, \\\\text{WALK WALK WALK WALK} \\\\rangle, \\\\langle C_1, \\\\text{jump twice}, \\\\text{JUMP JUMP} \\\\rangle, \\\\langle C_1, \\\\text{walk after walk}, \\\\text{WALK WALK} \\\\rangle\\\\}$$\"}"}
{"id": "2iu9NhxX23", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this example set there are a total of 5 minimal implication sets (with the implied example indicated in green above):\\n\\n- \\\\{c, e\\\\}\\n- \\\\{b, c, i\\\\}\\n- \\\\{b, e, i\\\\}\\n- \\\\{a, b, c, d, l\\\\}\\n- \\\\{a, b, e, d, l\\\\}\\n\\nAnd there are a total of 8 minimal contradiction sets (with the contradictory example indicated in red above), of which the following are because of an inconsistent reply:\\n\\n- \\\\{a, c, g\\\\}\\n- \\\\{a, e, g\\\\}\\n- \\\\{b, c, d, k\\\\}\\n- \\\\{b, e, d, k\\\\}\\n- \\\\{b, d, g, l\\\\}\\n\\nwhile the following are because of an inconsistent qualifier:\\n\\n- \\\\{a, d, h\\\\}\\n- \\\\{b, c, d, j\\\\}\\n- \\\\{b, e, d, j\\\\}\\n\\nBased on this, the consistency of example set $E$ would be $C(E) = \\\\frac{100 \\\\cdot 5}{13} \\\\approx 38.5$. Note that example $d$ is both implied and contradicted. Also, since examples $c$ and $e$ are semantically equivalent according to cSCAN's grounding function (Appendix E.3), each minimal implication or contradiction set that involves example $c$ can be written alternatively using example $e$, causing such sets to appear in pairs in the lists above.\\n\\n**D.6 CLT: Definition and Consistency Requirements**\\n\\nTo obtain a precise measure for the consistency of the predictions produced by a given learner, it is important that the task $T$ itself be consistent. Specifically, this means that each example $e \\\\in T$ must be consistent on its own, and the example set $T$ as a whole must be consistent. For the purposes of this paper, we further require that contexts are non-contradictory.\\n\\nWe capture these requirements using a predicate $\\\\text{consistent}_{\\\\text{CLT}}(T)$, which is recursively defined as follows.\\n\\n\\\\[\\n\\\\text{consistent}_{\\\\text{CLT}}(\\\\{\\\\langle C, q, r, u \\\\rangle \\\\}) : \\\\equiv \\\\text{consistent}_{\\\\text{CLT}}(C) \\\\land \\\\not\\\\models \\\\langle C, q, r, u \\\\rangle \\\\land (27)\\n\\\\]\\n\\n\\\\[\\n\\\\text{consistent}_{\\\\text{CLT}}(E) : \\\\equiv (\\\\forall e \\\\in E: \\\\text{consistent}_{\\\\text{CLT}}(\\\\{e\\\\})) \\\\land (C(E) = 100 \\\\lor C(E) = \\\\text{NaN}) \\\\quad (29)\\n\\\\]\\n\\nWe first define the consistency of an individual example $\\\\langle C, q, r, u \\\\rangle \\\\in E$, which requires that its context $C$ is consistent (and therefore non-contradictory), that the example itself is not a contradiction, and that it is qualified as monotonic if and only if it maps to a tautology (28). Then, we define that an example set $E \\\\subseteq E$ is consistent if and only if each individual example $e \\\\in E$ is consistent and the example set is consistent as a whole (29) (i.e., $C(E)$ must be 100 or undefined).\"}"}
{"id": "2iu9NhxX23", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: SCAN interpretation rules as provided by Lake & Baroni (2017). Double brackets denote the interpretation function translating SCAN's linguistic commands into sequences of actions. Symbols $x_1$ and $x_2$ denote variables.\\n\\nNote that while the above formulation of CLT consistency requirements is sufficient for cSCAN, it could be desirable to adjust this for more complex tasks, which we leave for future work. In particular, while this definition of consistency provides only basic control over the behavior of defeasible examples, we could imagine defining stricter consistency requirements for defeasible examples, e.g., by requiring them to adhere to the KLM properties (Sarit Kraus & Magidor, 1990; Casini et al., 2021). Also, while in this paper, for simplicity, we require contexts to be non-contradictory, this requirement is not strictly necessary for the task to be consistent or for the consistency metrics to be meaningful, as long as the top-level examples in the dataset do not contain a contradiction or contradict each other. Taken a step farther, for dealing with real-world datasets which may contain noise, it may be desirable to relax the requirement that the task be strictly consistent. In such an approach, the \u201crequirements\u201d of a CLT can be considered more as an aspiration rather than as strict requirements. The consistency metric could in that case still be calculated, but would be less reliable an indicator of learner consistency compared to the case where the task is consistent.\\n\\nThis appendix contains a specification of the cSCAN task. It consists of the phrase-structure grammars to generate valid requests and replies, the compositional grounding function (which defines the meaning of the explicit rules), and the bias function (which defines the inductive bias). Together with the formalization of simple CLTs provided in Appendix D, this specifies the complete behavior of cSCAN.\\n\\nNote that in this section, as in Appendix D, we assume the more general CLT formalism described in Appendix C, in which contexts can contain examples of the same form as the top-level examples. While the cSCAN specification could be expressed equivalently in terms of the simplified CLT formalism of Section 2, the more general formalism allows us to express some aspects of the specification more concisely, as we can thus describe the semantics of both top-level examples and context examples using the same grounding function.\\n\\nFor readability, we make use of the shorthand notation described in Section C.2 to allow expressing some of the more verbose examples more concisely.\\n\\nNote also that while we provide the complete formal specification of cSCAN here as a reference, it is not necessary in general to provide a specification at this level of detail when defining future CLTs.\\n\\nE.1 Rules\\n\\nMost of the specification of cSCAN is identical between cSCAN-B and cSCAN-X. In this section, we summarize the points that differ between the two, together with some notes on the original SCAN task for comparison.\\n\\nOriginal SCAN\\n\\nIn the original SCAN task, natural language commands are generated by a fixed phrase-structure grammar as described in Lake & Baroni (2017), which is equivalent to the phrase-structure grammar shown for cSCAN-B in the top left in Figure 5. (Note that for readability, we renamed the non-terminals in this...\"}"}
{"id": "2iu9NhxX23", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"|                  | cSCAN-B Random | cSCAN-X Random | cSCAN-B MCD  | cSCAN-X MCD  | cSCAN-B 100 Contexts | cSCAN-B 8000 Contexts |\\n|------------------|----------------|----------------|--------------|--------------|-----------------------|------------------------|\\n|                  | train          | valid          | test         | train        | valid                 | test                   |\\n| Number of examples | 100,000        | 100,000        | 100,000      | 100,000      | 99,756                | 100,000                |\\n| Number of contexts | 1,000          | 100            | 100          | 1,000        | 100                   | 100                    |\\n| Request: Rule (%) | 50.1           | 50.0           | 50.0         | 50.1         | 49.9                  | 50.0                   |\\n| Request: Non-rule (%) | 49.9         | 50.0           | 50.0         | 49.9         | 50.1                  | 49.9                   |\\n| Qualifier: Monotonic (%) | 46.3       | 45.5           | 46.0         | 50.0         | 50.0                  | 48.0                   |\\n| Qualifier: Defeasible (%) | 53.7      | 54.5           | 54.0         | 50.0         | 50.0                  | 52.0                   |\\n| Reply: Unknown (%) | 13.3           | 13.3           | 13.1         | 13.2         | 12.9                  | 13.6                   |\\n| Reply: Yes (%)    | 21.8           | 21.3           | 21.8         | 21.9         | 22.2                  | 21.5                   |\\n| Reply: No (%)     | 21.7           | 22.1           | 21.9         | 21.7         | 21.4                  | 22.1                   |\"}"}
{"id": "2iu9NhxX23", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this appendix, we provide realistic examples from a slightly earlier version of the cSCAN dataset and outline a systematic strategy for solving them. We selected a total of 22 examples (Figure 8) that are based on a single context of size 23 (Figure 7). We made sure that the different classes (see Section 2.4) are well represented among the selected examples. This means that the examples cover all valid combinations of request types, replies, and qualifiers.\\n\\nTo illustrate how cSCAN can be solved by humans, we outline one possible strategy below. This strategy is based on the assumption that we are aware of the grammar (Appendix E.2 and Figure 5), the rule semantics (Appendix E.3), and the inductive bias (Appendix E.4) of cSCAN.\\n\\nI.1 Monotonic Examples\\n\\nIn a first step, we check whether a given example can be deduced directly from the context. This is the case for all requests that exclusively contain syntactic constructs for which the behavior is completely determined by explicit rules in the context. In our context, the rules (C1) through (C11) completely determine the behavior of all constructs except \u201clook\u201d, \u201cthrice\u201d, and \u201cand\u201d. This means that we can deduce the reply for the examples (E1), (E2), (E3), (E4), (E5), and (E7), which we consequently mark as monotonic.\\n\\nAs an illustration, consider the request \u201cjump around left twice\u201d from example (E1). Once we know that $\\\\text{jump} = \\\\text{JUMP}$ (C3), $\\\\text{left} = \\\\text{PURPLE}$ (C1), $\\\\text{around} = \\\\text{JUMP}$ (C8), and $\\\\text{twice} = \\\\text{JUMP}$ (C10), we can immediately deduce that \u201cjump around left twice\u201d is translated to \u201cJUMP PURPLE JUMP\u201d.\\n\\nNote that some of the examples are closely related to one another. For example, the example (E1) is an instance of the rule $\\\\text{around} = \\\\text{JUMP}$ from example (E5).\\n\\nThe examples (E6), (E8), and (E9) contain some of the syntactic constructs that are not completely determined (i.e., \u201clook\u201d, \u201cthrice\u201d, and \u201cand\u201d), but they can still be deduced from the context and are thus marked as monotonic. The example $(C, \\\\text{look left} = \\\\text{WHITE WHITE PURPLE}, 1, M)$ (E6) follows directly from the rules $\\\\text{left} = \\\\text{PURPLE}$ (C1) and $\\\\text{look} = \\\\text{WHITE WHITE}$ (C12).\\n\\nSimilarly, the example $(C, \\\\text{look} = \\\\text{WHITE YELLOW}, 0, M)$ (E8) can be deduced from the examples (C7), and (C12). Indeed, if $\\\\text{look} = \\\\text{WHITE YELLOW}$ were true, (C7) would allow us to deduce the rule $\\\\text{look} = \\\\text{WHITE WHITE YELLOW}$, which contradicts (C12).\\n\\nFinally, (E9) can be deduced from (C2), (C8), and (C14) because $\\\\text{thrice} = \\\\text{JUMP}$ would imply that $\\\\text{around right thrice} = \\\\text{GREEN}$, which contradicts (C14).\\n\\nI.2 Difficult Examples\\n\\nTo determine the reply of examples that cannot be deduced from the context, we check whether the context allows us to induce some rules for the constructs \u201clook\u201d, \u201cthrice\u201d, and \u201cand\u201d, which are not fully determined.\\n\\nInducing rules for \u201clook\u201d, \u201cthrice\u201d, and \u201cand.\u201d\\n\\nWe start with the primitive command \u201clook\u201d and identify all context examples that contain \u201clook\u201d but none of the other partially-determined constructs \u201cthrice\u201d and \u201cand\u201d. This yields the rules (C12) and (C13). Together with (C7), the rule (C12) tells us that \u201clook\u201d must either be \u201cWHITE\u201d or undefined (i.e., $?$), and the same holds for (C13). While these two examples alone are not sufficient under the task\u2019s inductive bias (Appendix E.4) to justify inducing the general form of the \u201clook\u201d rule, we will proceed with the assumption that $\\\\text{look} = \\\\text{WHITE}$ for the time being.\\n\\nNext, we apply the same process to the syntactic construct \u201cthrice\u201d. This means that we identify all context examples that contain \u201cthrice\u201d but not \u201clook\u201d and \u201cand\u201d, which are (C14), (C15), and (C16). The first two of them tell us that \u201c$\\\\text{thrice}$\u201d must either translate to \u201c$\\\\text{JUMP}$\u201d or be undefined. However, example (C16) is incompatible with the rule $\\\\text{thrice} = \\\\text{JUMP}$. In accordance with the inductive bias, we therefore cannot induce a general rule for \u201cthrice\u201d.\\n\\nNow, we apply the process to \u201cand\u201d, which means that we look at the rules (C17) and (C18). Together with the example (C10), they both tell us that \u201c$\\\\text{and}$\u201d must either translate to \u201c$\\\\text{JUMP}$\u201d or be undefined. So, we proceed with the assumption that $\\\\text{and} = \\\\text{JUMP}$.\\n\\nAs a next step, we look at the examples (C19) and (C20) whose requests contain both \u201cand\u201d and \u201clook\u201d but not \u201cthrice\u201d. Both of them follow from our current assumptions $\\\\text{look} = \\\\text{WHITE}$ and $\\\\text{and} = \\\\text{JUMP}$. This means that we have now found four examples in the context that agree with our assumptions.\"}"}
{"id": "2iu9NhxX23", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: A context $C$ from the cSCAN dataset. The examples that make up the context are sorted, starting with 11 explicit rules that specify the complete behavior of all syntactic constructs except \\\"look\\\", \\\"thrice\\\", and \\\"and\\\". The remaining examples are sorted such that we first have the examples that do not contain \\\"thrice\\\" and \\\"and\\\", then the examples that do not contain \\\"and\\\", and finally the remaining examples.\\n\\nFigure 8: Examples from the cSCAN dataset. The examples are based on context $C$ shown in Figure 7 above, and they are grouped by request type and qualifier.\"}"}
{"id": "2iu9NhxX23", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"assumed rules for \\\"look\\\" and \\\"and\\\", and there are no examples that contradict them. Based on our inductive bias, this means that we induce these rules.\\n\\nAll the remaining examples (i.e., (C21), (C22), and (C23)) contain the construct \\\"thrice\\\", for which we cannot induce a general rule.\\n\\nApplying the induced rules for \\\"look\\\" and \\\"and\\\".\\n\\nUsing the induced rules for \\\"look\\\" and \\\"and\\\", we can determine a concrete reply for the examples (E10) through (E12) as well as (E16) through (E19). These examples are marked as defeasible because they are based (among others) on induced rules, which means that the reply might change if the context is expanded.\\n\\nUsing reply \\\"unknown\\\" for examples containing \\\"thrice\\\".\\n\\nBecause we are not able to induce a generic rule for \\\"thrice\\\", we are not able to determine a concrete reply for the examples (E13) through (E14) and (E20) through (E22). Instead we use the reply \\\"unknown\\\" (??) and mark them as defeasible because the reply might again change if the context is expanded.\\n\\nTable 9: Accuracy as a function of training data size.\\n\\n| Contexts | Examples | Accuracy | Consistency |\\n|----------|----------|----------|-------------|\\n| 100      | 10,000   | 38.6     | 6.9         |\\n| 1,000    | 100,000  | 92.6     | 71.3        |\\n| 8,000    | 800,000  | 97.7     | 91.9        |\\n\\nAs an additional set of experiments, we investigate the impact of training data size on the performance of the relatively strong pre-trained T5-Base (220M parameters) baseline. In each experiment, we use a dataset generated with a similar mix of examples as in cSCAN-B, but with a varying number of contexts and examples in the train set. As can be seen in the results in Table 9, while the model is able to achieve high accuracy and relatively high consistency as the train size approaches 800K examples, performance drops dramatically as the train decreases from 100K examples down to 10K examples. This suggests that finding ways to reduce models' dependency on large amounts of task-specific training data will be an additional important theme for future work in conceptual learning.\\n\\nExtended Related Work\\n\\nK.1 Comparison with Existing Datasets\\n\\nIn representing the input of a CLT as a request paired with a context, we build on a long tradition of QA and reasoning task formulations that provide knowledge relevant to a task via various forms of context, such as a text passage (Kwiatkowski et al., 2019; Weston et al., 2015; Dua et al., 2019; Sinha et al., 2019; Yang et al., 2018; Rajpurkar et al., 2016; Levesque et al., 2012), logical premise (Roemmele et al., 2011; Dagan et al., 2005; Bowman et al., 2015), set of natural language statements (Talmor et al., 2020), knowledge graph fragment (Sinha et al., 2020), antecedent description grammar (Cohen, 1994), dialog (Semantic Machines et al., 2020; Budzianowski et al., 2018), image (Antol et al., 2015; Johnson et al., 2017; Hudson & Manning, 2019; Bahdanau et al., 2019a;b), grid world (Ruis et al., 2020), or DB schema (Yu et al., 2018).\\n\\nHere, to give a better sense of how a CLT is similar to and different from these existing task formulations, we make a closer comparison of cSCAN with several representative NLU tasks that provide explicit knowledge as part of the input and satisfy some of the desired properties for a CLT formulated in Section 2.1. This is illustrated in Figure 9.\\n\\nNote that we focus our comparison here specifically on the defining features of a CLT. This should not be construed as a commentary on the overall usefulness or quality of these benchmarks. Indeed, many of the benchmarks described here have complementary strengths which cSCAN lacks, such as being based on true natural language, supporting multi-modal input, illustrating specific domains of reasoning, or covering more complex reasoning or syntax.\\n\\nTalmor et al. present a series of \\\"Leap-of-Thought\\\" tasks (Talmor et al., 2020) where the learner needs to judge yes/no hypotheses by performing inference over knowledge that is obtained implicitly from language model pretraining while part of the knowledge is also provided explicitly using a context containing natural language.\"}"}
{"id": "2iu9NhxX23", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: Comparison of cSCAN and other NLU task against the key features of conceptual learning.\\n\\nFor the context (explicit knowledge), we distinguish whether it is organized as a set of independent units rather than a monolithic block (column 1) and whether different examples use different and sometimes contradictory knowledge (column 2). We also distinguish whether the context contains both rules (column 3) as well as examples (column 4). For the request, we indicate whether the task contains examples that explicitly test the truth value of rules (column 5). For the output, we indicate whether the task requires identifying whether a request cannot be answered based on the given context (column 6) and whether it distinguishes between inductive and deductive reasoning.\\n\\nLanguage statements. This setup satisfies various CLT properties. In particular, arbitrary hypotheses can be asserted in the context, and the requests can ask for the truth value of any context statement (examples and rules coincide in this task because all examples are yes/no hypotheses). However, the knowledge is constant across all examples (albeit different parts of this knowledge are provided explicitly for different examples). Therefore, Leap-of-Thought tasks do not investigate whether a learner is able to adapt to transient knowledge, e.g., explicit knowledge that may contradict the implicit knowledge obtained during language model pretraining (e.g., an actor was married and is now divorced). Similarly, these tasks exclusively focus on monotonic inference: they do not test whether the learner is able to induce defeasible hypotheses from the explicit knowledge nor do they test the ability to identify certain hypotheses as \\\"unknown\\\".\\n\\nGraphLog (Sinha et al., 2020) is a benchmark suite based on tasks that are quite similar to CLTs. The learner is presented with part of a graph consisting of labeled edges (context) and then needs to predict the label for an edge that is not part of the context. For example, the context may contain two \\\"father-child\\\" relations and the learner needs to predict the \\\"grandfather-grandchild\\\" relation. As for cSCAN, the graph is constructed automatically based on a set of first-order logic rules, which make sure that each task is consistent. However, in contrast to cSCAN, the underlying rules cannot be part of the context, nor are they expressible as requests. In the CLT terminology, this means that GraphLog tests only the case where the context consists of examples and the learner has to induce new examples. It does not support the case where the context contains rules and the learner has to consistently combine and apply these rules deductively.\\n\\nThe bAbI tasks (Weston et al., 2015) also require the learner to answer a question using variable context consisting of natural language statements. Each context consists of a sequence of relatively simple factual statements that are, at least for some of the tasks, order-dependent (Dehghani et al., 2018). This means that a bAbI context does not directly correspond to a set-based context that we are using with CLTs. One way to bridge this gap is to consider a sequence of bAbI statements as a single \\\"macro rule\\\", but the truth value of these rules cannot be requested. bAbI contains some tasks that require deductive reasoning and some tasks that require inductive reasoning.\\n\\nThe gSCAN task (Ruis et al., 2020) is an extension of SCAN where the learner is provided with a context that describes a spacial configuration of objects in order to translate commands into a sequences of actions. However, as with bAbI, the context consists of a single dedicated structure describing the spacial configuration as a whole rather than a set of rules that describe the different objects that are part of the spacial configuration one by one. This makes the language to specify the context disjoint from the request language.\"}"}
{"id": "2iu9NhxX23", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As an example of a reading comprehension task, Natural Questions (Kwiatkowski et al., 2019) is a benchmark where the learner is given a Wikipedia page as context and then needs to answer a natural language question by outputting a long answer (e.g., the paragraph containing the answer) as well as a short answer. As with bAbI, the context is not a set of independent rules but instead a sequence of inter-dependent statements, which makes this benchmark quite different from a CLT.\\n\\nCompositional generalization. Our evaluation of cSCAN MCD splits builds on existing research in measuring the ability of machine learning models to compositionally generalize (Keysers et al., 2020; Lake & Baroni, 2017). In response to compositional generalization benchmarks such as SCAN, a range of techniques have been proposed which have not yet been evaluated on cSCAN. Some of these solutions involve specialized architectures for enforcing a compositional bias (Qiu et al., 2022; Chen et al., 2020; Liu et al., 2020; Nye et al., 2021). Such architectures are appealing due to their potential for achieving a principled solution to compositional generalization, but would require some effort to adapt to the context and heterogenous output of a CLT. In the past, some specialized architectures have shown limited success when transferring to new tasks, compared to more general techniques such as language model pre-training (Furrer et al., 2020). In the latter category, there is some promise shown by recent developments in decompositional prompting techniques, which have led to strong results on the SCAN MCD splits using off-the-shelf large language models (Zhou et al., 2022).\\n\\nInstruction following. In evaluating the ability for a system to apply rules to a task, our work relates to research in building systems that learn to follow instructions (Goldwasser & Roth, 2014), including recent research in the instruction-following capabilities of large language models (Wei et al., 2022; Ouyang et al., 2022; Wang et al., 2022). Our approach differs in that we provide in the context a set of rules, each of which may be applicable to some part of the task, and we evaluate the ability to infer new rules in addition to applying the rules to an underlying task.\\n\\nMeta-learning. Meta-learning or \u201clearning to learn\u201d generally refers to a setup where the learner is provided with a family of tasks, which are also called episodes, each of which comes with its own set of training examples and test examples. A learner is able to \u201clearn to learn\u201d if its performance for each task increases both with increasing training data and with an increasing number of tasks (Thrun & Pratt, 1998; Hospedales et al., 2021; Finn et al., 2017).\\n\\nThe presence of examples within the context of an example gives CLTs a nested structure that allows us to view CLTs through the lens of the meta-learning setup. In this view, top-level examples that share the same context correspond to an episode where the context examples are the training examples and the top-level examples (w/o the context) are the test examples.\\n\\nClosely related to cSCAN are two pieces of work that apply meta-learning to SCAN, both of which generate large numbers of SCAN-like grammars, from which they construct meta-learning episodes, similarly to how we generate cSCAN contexts based on SCAN-like grammars. Lake (2019) uses a memory-augmented network to attend to the train examples of each episode, while Nye et al. (2020) trains for each episode a program synthesis model that outputs the underlying rules of the task. Our approach differs in that we include in the context a mixture of rules and examples, rather than just examples of the underlying task, and we use the synthetically-generated contexts to define a new task for evaluating the ability of the system to generalize to many different rule sets, rather than using meta-learning techniques as a means to improve accuracy on the original SCAN task.\\n\\nRule induction and logic deduction tasks. CLTs require the learner to judge whether a certain rule can be induced from a given set of observations (i.e., examples provided as part of the context). This is similar to a rule induction task (Cohen, 1995; Reddy & Tadepalli, 1998; Grzymala-Busse, 2010), with the main caveat that the learner only needs to verify rules rather than generate them. CLTs also require the learner to apply rules and judge whether a rule may be deductively obtained from a set of other rules.\\n\\nInterpretable ML models. CLTs make part of the rules that govern the underlying tasks explicit, which allows us to \u201cintrospect\u201d the behavior of the learner by asking, as part of the task, whether or not a certain rule holds (inductively or deductively). This means that the question of whether and why a certain model behaves correctly or incorrectly can be broken down into two parts: (a) did the model learn the right rules and (b) is it able to apply these rules consistently. This is related to, yet different from, other efforts to make ML models more interpretable. For example, Sushil et al. (Sushil et al., 2018) propose a method to...\"}"}
{"id": "2iu9NhxX23", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\ninduce if-then-else rules to explain the behavior of ML models. However, unlike for CLTs, this method is external to the actual task: it does not reflect whether the model claims a certain rule to be true but instead identifies the if-then-else rules between different input features and class labels that are the most important for classification according to the model.\\n\\nConsistency.\\n\\nOur consistency metric is related to research into evaluating and improving the consistency of neural networks. One closely related work is Li et al. (2019), which evaluates consistency by generating clusters of examples that by construction are related via logical symmetry, transitivity, or some other logical constraint. Based on these examples, they calculate a \\\"conditional violation\\\" metric, which similarly to our consistency metric is a ratio of violated (in our case, satisfied) constraints vs. the total number of logical constraints. Our approach differs in that we gather the logical constraints automatically using symbolic inference over the generated examples, rather than depending on a specific algorithm for generating related examples.\\n\\nHandling of large contexts.\\n\\nDue to the potentially large context size in CLTs, another relevant area of research is how to deal with very large contexts, including large set-like contexts. One line of research in this area involves modifying the Transformer architecture to be able to handle longer inputs more efficiently (Tay et al., 2020a;b). We evaluated two such architecture variants in our LongT5 and LongT5-TGlobal baselines (Guo et al., 2022), but many other such variants have been proposed (Gu et al., 2021; Zaheer et al., 2020; Choromanski et al., 2020; Wang et al., 2020). In cases where the context takes the form of a set or a graph, some approaches seek to explicitly take into account this structure by encoding the input structure in positional embeddings (Herzig et al., 2020), guiding the Transformer's attention via the structural relations within the input (Ainslie et al., 2020), or message-passing in graph neural networks (Gilmer et al., 2017; Battaglia et al., 2018). Other lines of research seek to more efficiently deal with large pools of potentially relevant knowledge by either performing cross-attention from portions of the input to knowledge stored in neural memory (Verga et al., 2020) or by retrieving only the most relevant material from a knowledge base or text corpus for concatenation to the input (Guu et al., 2020; Pasupat et al., 2021).\\n\\nHardware and training period\\n\\nTable 10 shows the different hardware used for each experiment and the training period (in steps).\\n\\nT5 versions\\n\\nFor our T5 baselines, we use T5X (Roberts et al., 2022), which is a re-implementation of T5 in JAX (Bradbury et al., 2018) using Flax (Heek et al., 2020). Table 11 presents the configurations of different T5 variants that we used in our experiments. For the full-attention version of T5, we experiment with both fine-tuning from a standard pre-trained checkpoint and training from scratch.\\n\\nFor LongT5 and LongT5-TGlobal, while we initially evaluated with both fine-tuning from a standard pre-trained checkpoint and training from scratch, when fine-tuning, we failed to find a setup in which the models converge on the train set, possibly due to poor compatibility between the cSCAN task and the summarization-oriented PEGASUS Principle Sentences Generation pre-training objective (Zhang et al., 2019) used in LongT5. For this reason, we only report results on LongT5 and LongT5-TGlobal models trained from scratch.\\n\\nFor each of the architectures, we evaluate at minimum two sizes: Small (60M parameters) and Base (220M parameters). For the best-performing T5 architecture, we further evaluate on size Large (770M parameters).\\n\\nWe omitted experiments on Large variants of the other architectures for reasons of computational cost, as the poor performance on the Small and Base sizes suggest that it is unlikely for the performance of LongT5, LongT5-TGlobal or the non-pretrained version of T5 to improve significantly with model size alone.\\n\\nHyperparameters\\n\\nTable 12 summarizes the hyperparameters used for each of the baselines. The reasons for choosing those hyperparameters are:\\n\\n\u2022 Config:\\n  We chose the config version based on experiments on an earlier version of the dataset. In that version, we found that T5 achieved higher performance using the T5.1.0 config, while LongT5 and LongT5-TGlobal performed better on the T5.1.1 config.\\n\\n\u2022 Learning Rate:\\n  A constant learning rate is the standard way to fine-tune pre-trained T5 models. For non-pretrained models we found that a constant learning rate performed as well as the inverse square root decay with linear warmup scheduler (the standard learning rate scheduler for pretraining T5).\"}"}
{"id": "2iu9NhxX23", "page_num": 39, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 10: Hardware and training period (in steps).\\n\\n| Model       | Size       | Pretrain | Dataset     | TPU Type  | TPU Slices | Training Steps | Training Epochs |\\n|-------------|------------|----------|-------------|-----------|------------|----------------|-----------------|\\n| T5          | S          | True     | cSCAN-B     | TPU V2    | 64         | 150,000        | 192             |\\n| T5          | B          | True     | cSCAN-B     | TPU V3    | 16         | 50,000         | 64              |\\n| T5          | L          | True     | cSCAN-B     | TPU V4    | 64         | 50,000         | 64              |\\n| T5          | S          | False    | cSCAN-B     | TPU V2    | 64         | 300,000        | 384             |\\n| T5          | B          | False    | cSCAN-B     | TPU V3    | 16         | 150,000        | 192             |\\n| LongT5      | S          | False    | cSCAN-B     | TPU V2    | 64         | 300,000        | 384             |\\n| LongT5      | B          | False    | cSCAN-B     | TPU V3    | 16         | 150,000        | 192             |\\n| LongT5-TGlobal | S      | False    | cSCAN-B     | TPU V2    | 64         | 300,000        | 384             |\\n| LongT5-TGlobal | B      | False    | cSCAN-B     | TPU V3    | 16         | 150,000        | 192             |\\n| T5          | S          | True     | cSCAN-X     | TPU V2    | 64         | 150,000        | 192             |\\n| T5          | B          | True     | cSCAN-X     | TPU V3    | 16         | 50,000         | 64              |\\n| T5          | L          | True     | cSCAN-X     | TPU V4    | 128        | 50,000         | 64              |\\n| T5          | S          | False    | cSCAN-X     | TPU V2    | 64         | 300,000        | 384             |\\n| T5          | B          | False    | cSCAN-X     | TPU V3    | 16         | 150,000        | 192             |\\n| LongT5      | S          | False    | cSCAN-X     | TPU V2    | 64         | 300,000        | 384             |\\n| LongT5      | B          | False    | cSCAN-X     | TPU V3    | 16         | 150,000        | 192             |\\n| LongT5-TGlobal | S      | False    | cSCAN-X     | TPU V2    | 64         | 300,000        | 384             |\\n| LongT5-TGlobal | B      | False    | cSCAN-X     | TPU V3    | 16         | 150,000        | 192             |\\n\\nTable 11: Configurations of different T5 variants.\\n\\n| Name                     | #Parameters | #Layers | d | d_ff  | #heads |\\n|--------------------------|-------------|---------|---|-------|--------|\\n| Small                    | 60M         | 6       | 512 | 2048  | 8      |\\n| Base                     | 220M        | 12      | 768 | 3072  | 12     |\\n| Large                    | 770M        | 24      | 1024| 4096  | 16     |\"}"}
{"id": "2iu9NhxX23", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"At the same time, we took care to avoid illustrating any rules\u2019 variable substitutions exactly three times, so as to avoid penalizing a learner that is just slightly on the aggressive side in its inductions. In this way, while we describe the task\u2019s inductive bias formally as requiring a minimum of 4 illustrated variable substitutions, a learner could succeed on the cSCAN task by adopting a minimum threshold of either 3 or 4 substitutions.\\n\\nWe formalize this domain-specific inductive bias of cSCAN with the bias function $B : 2^E \\\\rightarrow 2^E$. To avoid circularity, we assume a variation $\\\\vdash \\\\ast$ of the logic embedding defined in Appendix D.4 with the only difference being that $\\\\vdash \\\\ast$ does not use axiom (18), which depends on the inductive bias. Similarly, we use $\\\\hookrightarrow \\\\rightarrow \\\\ast$ to denote the variant of the minimal implication $\\\\hookrightarrow \\\\rightarrow$ that is based on $\\\\rightarrow \\\\ast$ (rather than $\\\\rightarrow$).\\n\\nAs we mentioned in Section 3.2, we expect the learner to induce a rule if it has been illustrated with a sufficient number of variable substitutions. To formalize this, we define the function $\\\\text{num subst} : X \\\\times Q \\\\times 2Q \\\\rightarrow \\\\mathbb{N}$ such that $\\\\text{num subst}(x, q, Q)$ is the number of different expressions that can be substituted for the variable $x$ in the rule $q$ to obtain a rule in $Q$.\\n\\n$$\\\\text{num subst}(x, q, Q) := |\\\\{f(x) \\\\in Q : (\\\\exists f \\\\in X \\\\vdash \\\\rightarrow \\\\ast : \\\\text{subst}(q, f) \\\\in Q)\\\\}|$$ (35)\\n\\nWe also define the function $\\\\text{min subst} : Q \\\\times 2Q \\\\rightarrow \\\\mathbb{N}$ such that $\\\\text{min subst}(q, Q)$ is the minimum number of such substitutions for any variable used in $q$.\\n\\n$$\\\\text{min subst}(q, Q) := \\\\begin{cases} \\\\min_{x \\\\in \\\\text{var}(q)} (\\\\text{num subst}(x, q, Q)), & \\\\text{var}(q) > 0 \\\\\\\\ 0, & \\\\text{otherwise} \\\\end{cases}$$ (36)\\n\\nFor any $E \\\\subseteq E$, the bias function $B(E)$ is then defined as follows:\\n\\n$$Q_1(E, C) := \\\\bigcup \\\\{Q \\\\subseteq Q_R : (\\\\exists e \\\\in E : (E \\\\setminus \\\\{e\\\\}) \\\\cup \\\\{\\\\langle C, q, 1 \\\\rangle \\\\} \\\\hookrightarrow \\\\rightarrow e)\\\\}$$ (37)\\n\\n$$B_1(E) := \\\\{\\\\langle C, q, 1, D \\\\rangle \\\\in E : q \\\\in Q_1(E, C) \\\\land \\\\text{min subst}(q, Q_1(E, C)) \\\\geq 4\\\\}$$ (38)\\n\\n$$B_? (E) := \\\\{\\\\langle C, q, ?, D \\\\rangle \\\\in E : (\\\\forall r \\\\in \\\\{1, 0\\\\} : \\\\not\\\\vdash \\\\ast M(E \\\\cup B_1(E)) \\\\rightarrow M(\\\\langle C, q, r, D \\\\rangle))\\\\}$$ (39)\\n\\n$$B(E) := B_1(E) \\\\cup B_? (E)$$ (40)\\n\\nThe set $Q_1(E, C)$ is the set of candidate rules with context $C$ that we may want to induce from the example set $E$. Specifically, it is the union of all sets of rules $Q$ that, together with $E \\\\setminus \\\\{e\\\\}$, allow us to (minimally) explain some example $e \\\\in E$.\\n\\nThe set $B_1(E)$ contains the assertions of all rules that are expected to be induced to be true based on the examples provided by $E$. Specifically, it consists of the assertions $\\\\langle C, q, 1, D \\\\rangle$ of all the candidate rules $q$ for which $Q_1(E, C)$ contains instances with at least 4 different substitutions for each variable.\\n\\n$B_? (E)$ contains the assertions of all rules for which $E$ does not provide any evidence about whether or not they hold. Specifically, it contains an example $\\\\langle C, q, ?, D \\\\rangle$ for all contexts $C$ and rules $q$ for which $E$ does not imply a clear answer, i.e., 1 or 0.\\n\\nFinally, $B(E)$ is the union of all the rules that should be induced to be true and all the rules that should be induced to be unknown.\\n\\nDiscussion. Because all cSCAN contexts exclusively contain unconditional, monotonic examples, it is sufficient to induce rules with the empty context, i.e., we only need to consider $Q_1(E, \\\\emptyset)$.\\n\\nThe consistency criteria in $B_1$ is relatively simplistic, which makes the task easier for humans. Indeed, we only need to make sure that each induced rule $q$ is consistent with $E$ but do not need to check whether the induced rules are consistent with each other. This allows us to greedily induce rules one at a time without worrying about potential conflicts among them.\\n\\nThe dataset generation process is config-driven, with a different dataset spec config being defined for each of the cSCAN datasets. All cSCAN examples are automatically generated by a Python program built on the NLTK library (Bird et al., 2009). Generation is performed via the following steps.\\n\\n2 To be released on GitHub upon paper acceptance.\"}"}
{"id": "2iu9NhxX23", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Context generation\\n\\nFor efficiency, and to aid in generating clusters of related examples for calculation of the consistency metric, we generate examples in batches, in which we first generate a context and then generate multiple top-level examples that share that same context. Each context is created by first randomly generating a coherent set of interpretation rules of similar form to those shown in Figure 4 for the original SCAN task. While many of these rules may never be shown directly to the learner, this initial rule set serves as a kind of \u201cbasis rule set\u201d from which the truth value of all other possible rules can be derived. We then randomly choose which of those basis rules to (a) provide explicitly in the context via an example that asserts that rule to be \u201ctrue\u201d, (b) illustrate implicitly through some set of context examples sufficient to satisfy the task\u2019s inductive bias (see Appendix E.4 for details), (c) illustrate insufficiently or not at all, or (d) contradict in one or more cases, so that it should be inferrable to be \u201cfalse\u201d.\\n\\nBy generating contexts via the above procedure, we ensure that the basis rules cover each of the different possible replies and qualifiers for rule examples: monotonically \u201ctrue\u201d (case a), defeasibly \u201ctrue\u201d (case b), \u201cunknown\u201d (case c), and either monotonically or defeasibly \u201cfalse\u201d (case d). By extension, this also ensures that we achieve a diverse mixture of possible replies and qualifiers across the much larger set of rules that could be derived from different combinations of those basis rules.\\n\\nWe ensure that the exact ratio between the different above cases varies randomly from context to context, while achieving across the dataset as a whole the desired ratio that is configured in the dataset spec.\\n\\nTop-level example generation\\n\\nOnce we have fixed a context, we then randomly generate a set of (request, reply, qualifier) triples corresponding to the top-level examples that we wish to generate using the given context. To aid in sampling such examples, we first construct a pair of inference engines in which we exhaustively generate all possible examples that would be considered \u201ctrue\u201d either monotonically or defeasibly (respectively) based on the given context. To generate a non-rule example or positive rule example, we then randomly sample a \u201ctrue\u201d example from the full set of examples that were inferred by one of those inference engines. To construct a negative rule example, we first sample a positive example and then apply one of a number of different heuristics to construct an example that is similar to that positive example, but which is not among the examples inferred by the inference engine.\\n\\nThese two inference engines encapsulate the logic needed to ensure that each top-level example satisfies the consistency criteria stated in Section 2.3 and agrees with the domain-specific inductive bias.\\n\\nSub-sampling\\n\\nIn order to ensure that the different example classes are evenly represented in the dataset, we perform the top-level example generation process described above in separate streams, each of which is dedicated to generating one specific example class (e.g., \u201cpositive monotonic rule examples\u201d or \u201cnon-rule examples with reply of unknown\u201d, etc.). We then sub-sample examples from each of the different streams in order to achieve the desired ratio of examples from each of the different classes. We ensure that the exact ratio between the different classes varies randomly from context to context, while matching the desired ratio in the dataset overall.\\n\\nSplitting\\n\\nDue to interdependencies between the splitting algorithm and the example generation process (see, e.g., the notes on \u201cadditional top-level example generation\u201d below), we perform the train-validation-test split as one step of the dataset generation process, rather than generating a single dataset and then splitting it in multiple ways.\\n\\nFor performing MCD splits, we build on the open-sourced Python implementation of the MCD algorithm from Shaw et al. (2020). While their version of the MCD algorithm consists of initially performing a random split and then iteratively swapping examples to increase compound divergence, however, we found that we were able to achieve higher compound divergence on the cSCAN dataset by implementing an algorithm closer to that of the original one described in Keysers et al. (2020). In this approach, we begin with empty train and test sets and then iteratively select examples from a large example pool to add to one of the two sets, while once in every three steps selecting an example from one of the two sets to remove and put back in the pool. At each addition or removal step, we select from among a random sample of 200 examples the one whose addition or removal would maximize divergence at that stage, while keeping atom divergence low. One of the advantages of the insertion/deletion approach is that, in cases where it is acceptable to use only a portion of the available examples, the process can be stopped early, which can result in train and test splits with significantly higher compound divergence than would be possible if the algorithm were constrained to use all of the examples from the example pool. As described in Section 3.3, we do perform such sub-sampling when constructing our MCD splits, beginning with a pool of 1.2M top-level examples and ending with 100K top-level examples in train and 10K top-level examples in each of validation and test.\"}"}
{"id": "2iu9NhxX23", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"While our above algorithm largely emulates the one described in Keysers et al. (2020), we do introduce one additional enhancement to enable generating a 3-way compound divergence split between train, validation and test. This is in contrast to Keysers et al. (2020), which performs only a single stage of MCD splitting for maximizing compound divergence between train and test. In our approach, we perform two stages of MCD splitting, with the goal of constructing a train set, validation set, and test set, with high pairwise compound divergence between any two of the three. In the first stage, we split the example pool into a train+validation pool and a test set, with the objective of maximizing the compound divergence between the two. In the second stage, we keep the test set fixed, while further splitting the train+validation pool into a train set and a validation set, with the joint objective of maximizing compound divergence between train and validation and maximizing compound divergence between train and test. We perform down-sampling in each of the two stages to increase the compound divergences that we are able to achieve. Appendix H contain statistics on the MCD splits, along with other details of the datasets.\\n\\nAdditional top-level example generation\\n\\nFor the cSCAN Random variants, after performing a random split, we augment the validation and test sets by generating additional top-level examples for each validation and test context, using the same example generation logic described above. This allows us to achieve a higher density of logically related examples in the validation and test sets, so as to yield a larger number of potential implications and contradictions for use in calculating the consistency metric. We do not perform this step for the cSCAN MCD variants, however, to avoid impacting the compound divergences between the train, validation and test sets. For this reason, we focus our investigation of consistency in this paper on the cSCAN random splits, as it is only in the random splits that we are able to identify a significant number of implications and contradictions. Improving the sampling and splitting algorithms to enable investigation of consistency in MCD splits could be a topic for future work.\\n\\nCONSISTENCY METRIC CALCULATION\\n\\nWhile the consistency metric as described in Appendix D in its most general form can be prohibitively expensive to calculate if approached naively, a close approximation of it can be calculated efficiently through the application of several task-specific assumptions.\\n\\nFirst of all, in the consistency metric calculation we use with cSCAN, we consider for simplicity only implications and contradictions among predictions for top-level examples that share the same context. While in general implications and contradictions can occur even among examples with different contexts (particularly if the examples are monotonic and if one context is a superset of the other), due to the way in which we construct the cSCAN dataset, such situations are extremely unlikely to occur. By focusing only on identifying implications and contradictions among examples sharing the same context, we are able to cleanly partition the dataset into independent clusters of examples, such that we can analyze each cluster efficiently in parallel. Dealing with clusters of examples that share the same context also simplifies analysis in that we now only need to consider the implications and contradictions among the request-reply pairs, while effectively ignoring the context.\\n\\nAs the cSCAN validation and test sets contain up to 1000 top-level examples per context, however, it would still be prohibitively expensive to enumerate each of the possible subsets of these examples to identify the sets that involve a \u201cminimal\u201d implication or contradiction. Instead, we find that we are able to identify the implications and contradictions much more efficiently by seeding an inference engine with the rule assertions that would correspond to the up to 1000 top-level request-reply pairs (ignoring negative rule replies and unknown replies for simplicity) and then performing exhaustive forward inference to determine all possible rules that could be inferred from combinations of these asserted rules. This is essentially the same inference process that is used in top-level example generation (as described in Appendix F), except that we take the additional step of tracking the provenance of each inferred rule, and we continue the inference process so as to generate all possible provenances of each rule (rather than omitting reprocessing of rules that have already been inferred via a different route). For the purposes of this consistency calculation, it is sufficient to consider as provenance the set of asserted rules that led to the given inference. Once the exhaustive inference process is complete, we then check each of the asserted rules (i.e., each of the top-level predictions) against the contents of the inference engine. If the asserted rule was also inferred from some other rules, then we take the full set of inference provenances for that rule, filter out any inference provenances that are supersets of some other provenance, and then treat each of those remaining provenances together with the asserted rule as one \u201cminimal implication\u201d (i.e., as one minimal implication set \\\\( F \\\\in \\\\impl(E) \\\\) as defined in Equation 24). Similarly, if a rule was inferred that shares the same left-hand side as the asserted but contains a different right-hand side, then we look at...\"}"}
{"id": "2iu9NhxX23", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Atom and compound divergence of the cSCAN MCD datasets between pairs of splits.\\n\\n|                  | train vs test | train vs validation | validation vs test |\\n|------------------|--------------|---------------------|-------------------|\\n| Atom             | 0.066        | 0.039               | 0.030             |\\n| Compound         | 0.685        | 0.634               | 0.562             |\\n\\n|                  | train vs test | train vs validation | validation vs test |\\n|------------------|--------------|---------------------|-------------------|\\n| Atom             | 0.050        | 0.046               | 0.067             |\\n| Compound         | 0.722        | 0.726               | 0.724             |\\n\\nTable 7: Atom and compound counts of the cSCAN MCD datasets. The \u201cheld out\u201d column records the number of compounds that appear in the test split but not in the train split.\\n\\n|                  | train | valid | test | all | held out |\\n|------------------|-------|-------|------|-----|----------|\\n| Atom             | 4180  | 1110  | 1440 |     | 47       |\\n| Compound         | 88    | 91    | 118  | 138 | 47       |\\n\\nThe provenances of each such inferred rule, filter out any that are supersets of some other provenance of the same rule, and then treat each of those remaining provenances together with the asserted rule as one \u201cminimal contradiction\u201d (i.e., as one minimal implication set $F \\\\in \\\\text{cont}(E)$ as defined in Equation 25).\\n\\nDespite the relatively large number of rules with which we seed each inference engine and the extra expense of tracking multiple rule provenances, we find that we are able to complete exhaustive inference quickly in practice, due to the fact that the majority of the rules that are asserted in top-level examples tend to be more specific than the rules that are typically asserted inside of a context, and thus lead to only a limited number of interactions, which ends up being comparable to or less than the computational cost of the inference involved in constructing the contexts in the first place. In practice, when calculating the consistency metric in parallel using a different work unit for each context, we find that we are able to calculate the consistency metric for a full cSCAN experiment within a few minutes.\"}"}
{"id": "2iu9NhxX23", "page_num": 52, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 23: Edit distance measures for cSCAN-B Random\\n\\n| Baseline | Pretrain Size | Distance | Substitutions | Insertions | Deletions |\\n|----------|---------------|----------|---------------|------------|-----------|\\n| T5 True  | S             | 0.19     | 0.07          | 0.07       | 0.05      |\\n| T5 True  | B             | 0.17     | 0.07          | 0.03       | 0.07      |\\n| T5 True  | L             | 0.09     | 0.03          | 0.01       | 0.04      |\\n| T5 False | S             | 4.62     | 1.96          | 1.30       | 1.35      |\\n| T5 False | B             | 6.00     | 3.22          | 1.30       | 1.48      |\\n| LongT5  | S             | 4.75     | 2.18          | 1.23       | 1.34      |\\n| LongT5  | B             | 4.44     | 1.93          | 1.09       | 1.42      |\\n| LongT5-TGlobal | S | 4.30 | 1.86 | 1.18 | 1.26 |\\n| LongT5-TGlobal | B | 6.39 | 3.23 | 1.29 | 1.87 |\\n| T5 w/o Context True | B | 6.19 | 2.89 | 2.22 | 1.08 |\\n\\nTable 24: Edit distance measures for cSCAN-X Random\\n\\n| Baseline | Pretrain Size | Distance | Substitutions | Insertions | Deletions |\\n|----------|---------------|----------|---------------|------------|-----------|\\n| T5 True  | S             | 3.01     | 0.27          | 1.40       | 1.33      |\\n| T5 True  | B             | 3.21     | 0.30          | 0.65       | 2.26      |\\n| T5 True  | L             | 2.04     | 0.15          | 0.57       | 1.32      |\\n| T5 False | S             | 37.87    | 12.41         | 5.77       | 19.69     |\\n| T5 False | B             | 48.64    | 12.73         | 5.18       | 30.73     |\\n| LongT5  | S             | 38.81    | 11.65         | 5.30       | 21.87     |\\n| LongT5  | B             | 46.49    | 13.13         | 4.21       | 29.15     |\\n| LongT5-TGlobal | S | 36.74 | 11.59 | 6.11 | 19.04 |\\n| LongT5-TGlobal | B | 46.59 | 12.54 | 5.23 | 28.82 |\\n| T5 w/o Context True | B | 44.81 | 14.17 | 8.37 | 22.27 |\\n\\nTable 25: Edit distance measures for cSCAN-B MCD\\n\\n| Baseline | Pretrain Size | Distance | Substitutions | Insertions | Deletions |\\n|----------|---------------|----------|---------------|------------|-----------|\\n| T5 True  | S             | 1.96     | 0.69          | 0.82       | 0.44      |\\n| T5 True  | B             | 1.72     | 0.60          | 0.90       | 0.22      |\\n| T5 True  | L             | 1.23     | 0.42          | 0.63       | 0.18      |\\n| T5 False | S             | 3.41     | 1.26          | 1.28       | 0.86      |\\n| T5 False | B             | 4.29     | 2.12          | 1.07       | 1.10      |\\n| LongT5  | S             | 3.39     | 1.32          | 1.47       | 0.60      |\\n| LongT5  | B             | 3.64     | 1.54          | 1.23       | 0.87      |\\n| LongT5-TGlobal | S | 3.18 | 1.29 | 1.15 | 0.74 |\\n| LongT5-TGlobal | B | 3.50 | 1.28 | 1.47 | 0.75 |\\n| T5 w/o Context True | B | 4.46 | 1.90 | 1.77 | 0.79 |\\n\\nEdit distance is the number of edits that would need to be applied to the predicted sequence to transform it to the target sequence. There are three types of edits: Substitutions (S), Insertions (I) and Deletions (D).\\n\\nTables 23, 24, 26, and 26 show the edit distance and constituent metrics of each baseline on all of these metrics.\"}"}
{"id": "2iu9NhxX23", "page_num": 53, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Baseline | Pretrain Size | Distance | Substitutions | Insertions | Deletions |\\n|----------|---------------|----------|---------------|------------|----------|\\n| T5 True  | S             | 2.60     | 0.26          | 1.63       | 0.70     |\\n| T5 True  | B             | 2.90     | 0.33          | 0.79       | 1.78     |\\n| T5 True  | L             | 1.96     | 0.22          | 0.65       | 1.09     |\\n| T5 False | S             | 24.02    | 5.06          | 4.30       | 14.66    |\\n| T5 False | B             | 26.84    | 7.22          | 5.50       | 14.13    |\\n| LongT5  | S             | 24.31    | 5.58          | 3.91       | 14.83    |\\n| LongT5  | B             | 29.05    | 7.02          | 3.76       | 18.26    |\\n| LongT5-TGlobal False | S | 24.21 | 5.37 | 4.37 | 14.47 |\\n| LongT5-TGlobal False | B | 29.79 | 7.90 | 3.86 | 18.03 |\\n| T5 w/o Context True | B | 30.25 | 9.72 | 6.49 | 14.04 |\"}"}
{"id": "2iu9NhxX23", "page_num": 54, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We evaluate T5 variants, which are all encoder-decoder architectures. Here, we show how we prepare the input (that is fed to the encoder) and output (that the decoder generates) of our models, given an example from cSCAN. The example below is selected from the cSCAN-B dataset. Note that the request and the context examples are all concatenated into a single newline-separated string to form the input, and the bullet-points here (and in Appendix P.1) are just added to improve the readability of the examples.\\n\\nInput:\\n\\n- Request, Context\\n- turn opposite left and jump around left twice\\n- [left] = PURPLE\\n- [x1 around x2] = [x2] [x2] [x1] [x1]\\n- [x1 opposite x2] = [x1] [x2] [x2]\\n- [turn] = YELLOW\\n- [x1 after x2] = [x2] [x1]\\n- [walk] = LTURN\\n- [jump] = RUN\\n- run around left and turn opposite right twice PURPLE PURPLE JUMP JUMP YELLOW RTURN RTURN YELLOW RTURN RTURN YELLOW RTURN RTURN\\n- walk opposite left twice after run thrice JUMP RUN LTURN PURPLE PURPLE LTURN PURPLE PURPLE\\n- [run opposite left] = JUMP PURPLE PURPLE\\n- [run opposite x1 twice] = JUMP [x1] [x1]\\n- turn opposite right twice and turn around left thrice YELLOW RTURN RTURN YELLOW RTURN RTURN YELLOW RTURN RTURN PURPLE PURPLE YELLOW YELLOW\\n- run right thrice JUMP RTURN RTURN\\n- [x1 around x2 thrice] = [x2] [x2] [x1] [x1]\\n- [look around x1 thrice] = [x1] [x1] PINK PINK\\n- look around right thrice and run opposite left RTURN RTURN PINK PINK JUMP PURPLE PURPLE\\n- look around left thrice PURPLE PURPLE PINK PINK\\n- [look left thrice] = PINK PURPLE PURPLE\\n- [look opposite x1] = PINK [x1] [x1]\\n- run opposite right twice and turn around left twice JUMP RTURN RTURN PURPLE PURPLE YELLOW YELLOW\\n- turn around left and walk twice PURPLE PURPLE YELLOW YELLOW LTURN LTURN JUMP\\n- [x1 and x2 thrice] = [x1] [x2]\\n- [x1 thrice and x2] = [x1] [x2]\\n- look thrice and run around right thrice PINK RTURN RTURN JUMP JUMP\\n- turn opposite right YELLOW RTURN RTURN\\n- [jump right] = RUN RTURN RTURN\\n- [x1 right] = [x1] RTURN RTURN\\n- turn left after look opposite right PINK RTURN RTURN YELLOW PURPLE PURPLE\\n- look right twice YELLOW PINK RTURN RTURN PINK RTURN RTURN\\n- [look x1] = PINK [x1] [x1]\\n- [x1 left] = [x1] PURPLE PURPLE\\n- walk around left twice after walk around left thrice PURPLE PURPLE LTURN LTURN PURPLE PURPLE LTURN LTURN PURPLE PURPLE LTURN LTURN YELLOW\\n- jump right twice RUN RTURN RTURN RUN RTURN RTURN RTURN\\n- [look around x1 twice] = RUN [x1] [x1] PINK PINK [x1] [x1] PINK PINK\\n- [jump around left twice] = PINK PURPLE PURPLE RUN RUN PURPLE PURPLE RUN RUN\\n\\nOutput:\\n\\n<Reply, Qualifier>\\n\\n- YELLOW PURPLE PURPLE PINK PURPLE PURPLE RUN RUN PURPLE PURPLE RUN RUN (Reasoning: Defeasible)\\n\\nNote that we concatenate request + context, rather than context + request, so as to make the system more robust to truncation of the example string, if any example were to exceed the maximum length of T5's input buffer (although in our experiments we made sure that the example lengths did not exceed this buffer size).\\n\\nIn representing the context for T5, it can be noted that we omitted special syntactic tokens such as braces, angle brackets, and commas wherever possible, so as to reduce the token count and keep the format closer to natural language, to the extent that this could be done without introducing ambiguity. For context examples\"}"}
{"id": "2iu9NhxX23", "page_num": 55, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"that represent rule assertions, we also adopted a simplified syntax, similar to the shorthand described in Appendix C.2, consisting of a single line containing the rule request alone, while omitting the reply, since in cSCAN we only include positive rule assertions in the context (i.e., never rule examples with reply of 0 or ?).\\n\\nNote also that we do not perform any clustering of top-level examples by their context, but rather represent each top-level example in flattened form as shown here (with its context included). We then shuffle the full set of top-level examples before batching them for input into T5. This means that even when there may be 100 or more top-level examples with the same context, T5 will in general not see them all in sequence or in the same batch, but rather intermixed with top-level examples with different contexts.\\n\\nHere, we showcase examples where our best model (T5-Large with pretraining) fails at producing the accurate results when evaluated on an example from the cSCAN-B. We show different cases where the target and the prediction from the model are different.\\n\\nExample of T5-Large failing at rule assertion (when the request is False).\\n\\nInput: [run left after turn right] = LOOK WALK WHITE WHITE PINK LOOK WALK\\n\\n\u2022 [left] = PINK\\n\u2022 [turn] = LOOK\\n\u2022 [x1 twice] = [x1] [x1]\\n\u2022 [x1 thrice] = [x1]\\n\u2022 [x1 and x2] = [x1] [x2] [x1]\\n\u2022 [look] = BLUE\\n\u2022 [x1 opposite x2] = [x2] [x1] [x1] [x2]\\n\u2022 [x1 x2] = [x1] [x2]\\n\u2022 [walk] = RTURN\\n\u2022 [x1 after x2] = [x2] [x1] [x1] [x2]\\n\u2022 [jump] = GREEN\\n\u2022 [right] = WALK\\n\u2022 [run] = WHITE\\n\\nTarget: 0 (Reasoning: Monotonic)\\nPrediction: 1 (Reasoning: Monotonic)\\n\\nCommentary: Since [x1 x2] = [x1] [x2], [run left] and [turn right] would map to WHITE PINK and LOOK WALK respectively, and with [x1 after x2] = [x2] [x1] [x1] [x2], the correct output should be LOOK WALK WHITE PINK WHITE PINK LOOK WALK.\"}"}
{"id": "2iu9NhxX23", "page_num": 40, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 12: Hyperparameters used in the cSCAN baselines.\\n\\n| Model                  | Learning Rate Scheduler | Learning Rate | Batch Size | Loss Normalizing Factor | Initial Checkpoint |\\n|------------------------|-------------------------|---------------|------------|-------------------------|-------------------|\\n| T5 (Pretrained)        | Constant                | 0.001         | 128        | 233472                 | 1000000           |\\n| T5 (Non-Pretrained)    | Constant                | 0.001         | 128        | 233472                 | 999900            |\\n| LongT5                | Constant                | 0.001         | 128        | 233472                 | 1000700           |\\n| LongT5-TGlobal        | Constant                | 0.001         | 128        | 233472                 | 0                 |\\n\\n\u2022 Loss Normalizing Factor: By instruction of T5 creators, we used a fixed loss normalizing factor of $\\\\frac{\\\\text{PretrainingBatchSize} \\\\times \\\\text{TargetTokensLength}}{2048 \\\\times 114} = 233472$ for fine-tuning and we used the same value for non-pretrained models to maintain consistency.\\n\\nNote that for the small models using T5.1.1 config, we set the number of layers and heads to 6 and 8 respectively to match those set in T5.1.0 config.\\n\\nTokenization: All models use the pretrained SentencePiece tokenizer (Kudo & Richardson, 2018) provided by T5, which is pretrained to cover the English, French, German and Romanian languages with 32,000 tokens. We also tried using a simple whitespace tokenizer, which resulted in similar performance when compared to the pretrained T5 tokenizer.\"}"}
{"id": "2iu9NhxX23", "page_num": 41, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 13: Breakdown of accuracy by example characteristics on cSCAN-B Random.\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible | Monotonic | Unknown | Neg. Rule | Pos. Rule | Non-Rule |\\n|------------------------------|---------------------|------------|-----------|---------|-----------|-----------|----------|\\n|                              | T5 True             |            |           |         |           |           |          |\\n|                              | S                   | 90.2       | 93.9      | 97.4    | 79.8      | 96.5      | 95.8     |\\n|                              | B                   | 90.5       | 93.9      | 97.7    | 78.8      | 96.9      | 96.2     |\\n|                              | L                   | 95.3       |           |         |           |           |          |\\n|                              | 100%                | 97.7       | 97.7      | 91.9    | 98.1      | 97.6      |          |\\n|                              | False               |            |           |         |           |           |          |\\n|                              | S                   | 13.9       | 16.4      | 75.0    | 32.0      | 27.7      | 2.9      |\\n|                              | B                   | 15.0       | 12.3      | 74.4    | 33.4      | 20.5      | 2.7      |\\n| LongT5-TGlobal False        | S                   | 16.3       | 15.9      | 74.1    | 28.8      | 34.2      | 3.0      |\\n|                              | B                   | 13.9       | 13.1      | 68.7    | 29.5      | 24.0      | 2.2      |\\n| LongT5 False                | S                   | 17.1       | 14.0      | 73.8    | 31.2      | 29.5      | 3.0      |\\n|                              | B                   | 16.1       | 17.8      | 80.6    | 33.1      | 32.6      | 3.9      |\\n| T5 w/o Context True         | B                   | 19.3       | 23.5      | 83.0    | 40.6      | 44.9      | 5.8      |\\n\\nTable 14: Breakdown of accuracy by example characteristics on cSCAN-X Random.\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible | Monotonic | Unknown | Neg. Rule | Pos. Rule | Non-Rule |\\n|------------------------------|---------------------|------------|-----------|---------|-----------|-----------|----------|\\n|                              | T5 True             |            |           |         |           |           |          |\\n|                              | S                   | 59.2       | 68.7      | 97.8    | 43.3      | 69.2      | 75.2     |\\n|                              | B                   | 62.6       |           |         |           |           |          |\\n|                              | L                   | 74.9       |           |         |           |           |          |\\n|                              | 100%                | 83.7       | 97.7      | 69.5    | 91.4      | 80.6      |          |\\n|                              | False               |            |           |         |           |           |          |\\n|                              | S                   | 10.3       | 16.4      | 63.0    | 29.0      | 25.1      | 1.9      |\\n|                              | B                   | 11.2       |           |         |           |           |          |\\n| LongT5-TGlobal False        | S                   | 13.0       | 14.6      | 72.4    | 28.1      | 26.8      | 2.7      |\\n|                              | B                   | 9.4        |           |         |           |           |          |\\n| LongT5 False                | S                   | 11.7       | 16.3      | 70.8    | 32.8      | 23.5      | 2.5      |\\n|                              | B                   | 12.3       |           |         |           |           |          |\\n| T5 w/o Context True         | B                   | 17.0       | 20.6      | 83.3    | 35.5      | 39.9      | 4.0      |\\n\\nFrom the breakdowns for T5-Large (770M parameters), we can see that for a sufficiently large model with full attention, it is feasible to achieve high accuracy across example classes. Across the pre-trained T5 models, however, we can notice several trends:\\n\\n- Examples with reply of \\\"unknown\\\" tend to be easier than other examples.\\n- Negative rule examples, i.e., those with reply of \\\"false\\\", are the most challenging class of example.\\n- Accuracy on non-rule examples is roughly similar to accuracy on rule examples, despite the fact that rule examples involve classification into a much smaller space of possible replies (which would make them more amenable to solving through guessing).\\n\\nIn contrast, when looking at the results of the models that failed to outperform the naive baseline, we can see that for these, accuracy on rule examples is significantly higher than that on non-rule examples, with the highest accuracy on examples with the reply of \\\"unknown\\\", consistent with the view that these models are relying on guessing based on superficial example characteristics.\"}"}
{"id": "2iu9NhxX23", "page_num": 42, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 15: Breakdown of accuracy by example characteristics on cSCAN-B MCD.\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible | Monotonic | Unknown | Neg. Rule | Pos. Rule | Non-Rule |\\n|-----------------------------|--------------------|------------|-----------|---------|-----------|-----------|----------|\\n| **True**                    |                    |            |           |         |           |           |          |\\n| T5                          | S                  | 38.2       | 24.0      | 99.8    | 60.0      | 39.7      | 22.5     |\\n|                             | B                  | 38.8       | 25.3      | 99.9    | 59.8      | 35.3      | 27.2     |\\n|                             | L                  | 55.3       | 46.8      | 99.8    | 75.6      | 60.4      | 42.4     |\\n| **False**                   |                    |            |           |         |           |           |          |\\n|                             | S                  | 17.9       | 14.3      | 96.6    | 25.8      | 30.3      | 8.9      |\\n|                             | B                  | 13.8       | 14.7      | 97.4    | 26.7      | 24.2      | 6.2      |\\n| **LongT5-TGlobal False**    |                    |            |           |         |           |           |          |\\n|                             | S                  | 18.4       | 14.0      | 98.5    | 30.3      | 25.7      | 8.9      |\\n|                             | B                  | 13.1       | 13.2      | 97.4    | 29.8      | 16.7      | 10.8     |\\n| **LongT5 False**            |                    |            |           |         |           |           |          |\\n|                             | S                  | 16.7       | 15.0      | 97.2    | 36.8      | 18.7      | 10.3     |\\n|                             | B                  | 13.4       | 14.0      | 97.6    | 42.1      | 6.5       | 6.7      |\\n| **T5 w/o Context True**     |                    |            |           |         |           |           |          |\\n|                             | B                  | 25.2       | 19.5      | 96.6    | 38.0      | 40.2      | 14.6     |\\n\\nTable 14 shows breakdown of accuracy by example characteristics on cSCAN-X Random. From the pre-trained T5 models, we can see the following trends:\\n\\n- Examples with reply of \\\"unknown\\\" continue to be much easier than other examples. In fact, the models are able to answer these examples with comparably high accuracy on cSCAN-X as on cSCAN-B.\\n- Negative rule examples continue to be the most challenging class of example.\\n- While the models struggle with both rule examples and non-rule examples, accuracies are even lower on rule examples than on non-rule examples, again despite the fact that rule examples would be more amenable to random guessing.\\n\\nFor the models that failed to outperform the naive baseline, the pattern is similar on cSCAN-X as on cSCAN-B.\\n\\nTable 15 shows breakdown of accuracy by example characteristics on cSCAN-B MCD. From these results, we can see the following trends:\\n\\n- All models achieve particularly high accuracy on examples with reply \\\"unknown\\\", as would be expected from the dataset stats shown in Table 2, where we can see that this class of examples makes up over 50% of the examples in the cSCAN-B MCD train set. This makes the answer of \\\"unknown\\\" a natural guess in any situation where the model is unsure.\\n- Given that T5 w/o Context is able to achieve significantly higher than zero accuracy on rule examples with replies other than \\\"unknown\\\", however, it is clear that the model is doing more than simply predicting \\\"unknown\\\" every time. Rather, it appears that a moderate amount of statistical clues must be available in the request itself to allow some degree of \\\"educated guessing\\\" of the reply, particularly in the case of rule examples.\\n- For all models, accuracy on non-rule examples lags significantly behind accuracy on rule examples. This is in contrast to the cSCAN Random datasets, where the stronger-performing pre-trained models frequently performed better on non-rule examples than on rule examples. One reason for this difference is likely the fact that the train set for cSCAN-B MCD is skewed toward rule examples, which make up somewhat over 70% of the dataset. Taken in light of the observation above about the naive T5 w/o Context baseline, however, the poor performance on non-rule examples also suggests that the T5 baselines may be achieving even less proper \\\"understanding\\\" of the examples than one would have thought from looking at the overall accuracy numbers alone, and is likely relying to a large degree on \\\"educated guessing\\\", based on statistical clues from the\"}"}
{"id": "2iu9NhxX23", "page_num": 43, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 16: Breakdown of accuracy by example characteristics on cSCAN-X MCD.\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible Monotonic Unknown Neg. Rule Pos. Rule Non-Rule |\\n|-----------------------------|---------------------|----------------------------------------------------------|\\n| True                        | T5                  | 51.6 57.1 99.5 65.0                                     |\\n|                             | B                   | 50.3 54.2 99.7 14.3 83.1 66.0                           |\\n|                             | L                   | 60.0 67.4 99.7 36.2 88.6 73.4                           |\\n| False                       | S                   | 13.3 19.4 96.5 29.2 28.0 6.8                            |\\n|                             | B                   | 13.5 17.3 94.8 28.7 24.4 5.6                            |\\n\\nLongT5-TGlobal False\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible Monotonic Unknown Neg. Rule Pos. Rule Non-Rule |\\n|-----------------------------|---------------------|----------------------------------------------------------|\\n|                             | T5                  | 14.6 17.3 96.4 28.1 26.5 6.4                            |\\n|                             | B                   | 14.4 17.8 95.5 30.6 24.8 6.5                            |\\n\\nT5 w/o Context True\\n\\n| Knownness Request/Reply Type | Model Pretrain Size | Defeasible Monotonic Unknown Neg. Rule Pos. Rule Non-Rule |\\n|-----------------------------|---------------------|----------------------------------------------------------|\\n|                             | B                   | 12.6 21.2 96.2 27.1 33.3 8.7                            |\\n\\nrequest and context, which is much easier to do on rule examples than on non-rule examples, due to the smaller space of possible replies for rule examples.\\n\\nM.4\\n\\nTable 16 shows breakdown of accuracy by example characteristics on cSCAN-X MCD. From these results, we can see the following trends:\\n\\n- Similarly to cSCAN-B MCD, all models achieve high accuracy on examples with reply \u201cunknown\u201d, which is again the most commonly occurring class of examples in this dataset (around 40% of examples in the train set).\\n- For pre-trained T5, however, accuracy on non-rule examples is significantly higher than on cSCAN-B MCD, suggesting that these models are likely benefiting from the more balanced distribution of examples in the cSCAN-X MCD dataset, where around 40% of the train examples are non-rule examples, compared with less than 30% in cSCAN-B MCD.\\n- The large gap in accuracy between negative and possible rule examples on pre-trained T5 suggests that while they are able to use information from the context to do a better job than the naive T5 w/o Context at distinguishing between \u201cunknown\u201d and \u201cnot unknown\u201d rules, they are still relying largely on guessing for determining the rules\u2019 actual truth value.\\n\\nM.5\\n\\nFigures 10, 11, 12, and 13 show T5\u2019s performance on the test splits of cSCAN-B, cSCAN-X, cSCAN-B MCD, and cSCAN-X MCD datasets with respect to various features of the examples and the contexts, broken down into rule and non-rule examples.\\n\\nThe features being considered are:\\n\\n\u2022 $num_{rules}$: The number of distinct rules used to create an example. For example, for the request \u201cwalk and walk\u201d, $num_{rules}$ is 2: it is created with the rules: $J_1 x_1 K = \\\\ldots$ and $J walk K = \\\\ldots$\\n\\n\u2022 $num_{variables}$: The number of variables in the rule. For example, for the request \u201cwalk and $x_1$\u201d, $num_{variables}$ is 1.\\n\\n\u2022 $derivation_{level}$: The number of compositions used to build an example. For example, for the request \u201cwalk and walk\u201d, $derivation_{level}$ is 2: it is created by first composing $J_1 x_1 K = \\\\ldots$ with $J walk K = \\\\ldots$ to get $J walk and x_2 K = \\\\ldots$, followed by another composition with $J walk K = \\\\ldots$.\\n\\n\u2022 $frac_{explicit_{rules}}$: The fraction of explicit rules among all distinct rules used to create an example. The fractions are bucketed for legibility: $frac_{explicit_{rules}} = 0.5$ includes all examples with a fraction of explicit rules at least 0.5 and less than 0.6.\"}"}
{"id": "2iu9NhxX23", "page_num": 56, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example of T5-Large failing at rule assertion (when the request is True).\\n\\n- **Input**:\\n  - \\([\\\\text{run and run around right thrice}]\\) = PURPLE\\n  - \\([\\\\text{jump}]\\) = RED\\n  - \\([\\\\text{x1 and x2}]\\) = \\([\\\\text{x2}]\\) \\([\\\\text{x1}]\\) \\([\\\\text{x2}]\\)\\n  - \\([\\\\text{left}]\\) = LOOK\\n  - \\([\\\\text{run}]\\) = PURPLE\\n  - \\([\\\\text{x1 x2}]\\) = \\([\\\\text{x2}]\\) \\([\\\\text{x2}]\\) \\([\\\\text{x1}]\\)\\n  - \\([\\\\text{x1 around x2}]\\) = \\([\\\\text{x1}]\\) \\([\\\\text{x2}]\\) \\([\\\\text{x1}]\\)\\n  - \\([\\\\text{look}]\\) = RUN\\n  - \\([\\\\text{x1 after x2}]\\) = \\([\\\\text{x2}]\\) \\([\\\\text{x2}]\\) \\([\\\\text{x1}]\\)\\n  - \\([\\\\text{turn}]\\) = JUMP\\n  - \\([\\\\text{walk}]\\) = LTURN\\n  - \\([\\\\text{x1 twice}]\\) = \\([\\\\text{x1}]\\) \\([\\\\text{x1}]\\)\\n  - \\([\\\\text{walk opposite right}]\\) = GREEN LTURN\\n  - \\([\\\\text{look opposite right twice and jump twice}]\\) = RED RED GREEN RUN GREEN RUN RED\\n  - \\([\\\\text{turn opposite right}]\\) = GREEN JUMP\\n  - \\([\\\\text{look opposite x1}]\\) = \\([\\\\text{x1}]\\) RUN\\n  - \\([\\\\text{look right and jump around right thrice}]\\) = RED GREEN RED RED GREEN RED GREEN\\n  - \\([\\\\text{turn opposite left twice and look thrice}]\\) = LOOK JUMP LOOK JUMP\\n  - \\([\\\\text{x1 opposite right thrice}]\\) = GREEN \\([\\\\text{x1}]\\) GREEN \\([\\\\text{x1}]\\)\\n  - \\([\\\\text{run around x1 thrice}]\\) = EMPTY\\n  - \\([\\\\text{run around right after run opposite right twice}]\\) = GREEN PURPLE GREEN PURPLE GREEN PURPLE GREEN PURPLE PURPLE GREEN PURPLE\\n  - \\([\\\\text{jump opposite left after turn opposite right twice}]\\) = GREEN JUMP GREEN JUMP GREEN JUMP LOOK RED\\n  - \\([\\\\text{run around right}]\\) = PURPLE GREEN PURPLE\\n  - \\([\\\\text{x1 opposite right}]\\) = GREEN \\([\\\\text{x1}]\\)\\n\\n**Target**\\n\\n- Prediction: 0 (Reasoning: Monotonic)\\n\\n**Commentary**\\n\\nSince \\([\\\\text{run around x1 thrice}]\\) maps to an empty string and \\([\\\\text{x1 and x2}]\\) = \\([\\\\text{x2}]\\) \\([\\\\text{x1}]\\) \\([\\\\text{x2}]\\) with \\([\\\\text{run}]\\) = PURPLE, the provided rule is True.\"}"}
{"id": "2iu9NhxX23", "page_num": 57, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example of T5-Large failing at acknowledging lack of information to reply.\\n\\nInput:\\n- \\\\([x_1 \\\\text{ and } x_2]\\\\) = \\\\([x_1] [x_2] [x_1]\\\\)\\n- \\\\([x_1 \\\\text{ around } x_2]\\\\) = \\\\([x_1] [x_2] [x_2]\\\\)\\n- \\\\([x_1 \\\\text{ opposite } x_2]\\\\) = \\\\([x_1] [x_2] [x_2]\\\\)\\n- \\\\([x_1 \\\\text{ twice}]\\\\) = \\\\([x_1]\\\\)\\n- \\\\([x_1 \\\\text{ after } x_2]\\\\) = \\\\([x_2] [x_1] [x_2]\\\\)\\n- \\\\([\\\\text{left}]\\\\) = BLUE\\n- \\\\([x_1 \\\\text{ thrice}]\\\\) = \\\\([x_1] [x_1]\\\\)\\n- \\\\([\\\\text{look}]\\\\) = PINK\\n- \\\\([\\\\text{run}]\\\\) = RED\\n- walk opposite right after run opposite left twice RED BLUE BLUE WHITE YELLOW YELLOW\\n- walk opposite left twice and run WHITE BLUE BLUE RED WHITE BLUE BLUE\\n- \\\\([\\\\text{walk opposite } x_1]\\\\) = WHITE \\\\([x_1]\\\\) \\\\([x_1]\\\\)\\n- \\\\([\\\\text{walk } x_1]\\\\) = \\\\([x_1]\\\\) WHITE\\n- jump opposite left thrice and turn left thrice RTURN BLUE BLUE RTURN BLUE BLUE RUN BLUE RUN RTURN BLUE BLUE RTURN BLUE BLUE\\n- turn opposite right twice after look opposite right PINK YELLOW YELLOW RUN YELLOW YELLOW PINK YELLOW YELLOW\\n- \\\\([\\\\text{turn left}]\\\\) = BLUE RUN\\n- \\\\([\\\\text{turn around } x_1 \\\\text{ twice}]\\\\) = RUN \\\\([x_1]\\\\) \\\\([x_1]\\\\)\\n- jump left twice after turn around left RUN BLUE BLUE BLUE LTURN RUN BLUE BLUE\\n- walk right twice and walk around left thrice YELLOW WHITE WHITE BLUE BLUE WHITE BLUE BLUE YELLOW WHITE\\n- turn around right twice after jump around left WALK WALK BLUE BLUE RUN YELLOW YELLOW WALK WALK BLUE BLUE\\n- \\\\([\\\\text{jump opposite right}]\\\\) = RED WALK YELLOW YELLOW\\n- \\\\([\\\\text{turn opposite right}]\\\\) = RUN YELLOW YELLOW\\n- jump right twice and jump thrice YELLOW BLACK BLACK BLACK YELLOW BLACK\\n- run right thrice after look around left twice PINK BLUE BLUE YELLOW RED YELLOW PINK BLUE BLUE\\n- \\\\([x_1 \\\\text{ left}]\\\\) = BLUE \\\\([x_1]\\\\)\\n- \\\\([\\\\text{run } x_1]\\\\) = \\\\([x_1]\\\\) RED\\n\\nOutput:\\nRUN YELLOW YELLOW RUN YELLOW YELLOW YELLOW BLUE BLUE YELLOW BLUE BLUE RUN YELLOW YELLOW RUN YELLOW YELLOW (Reasoning: Defeasible)\\n\\nCommentary:\\n- \\\\([\\\\text{jump}]\\\\) = is not well illustrated by at least 2 unique substitutions, therefore the mapping of \\\\([\\\\text{jump}]\\\\) is unknown.\"}"}
{"id": "2iu9NhxX23", "page_num": 58, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example of T5-Large failing at drawing correct information to compose the reply.\\n\\nInput\\n\\n- \\\\([x_1 \\\\text{ and } x_2]\\\\) = \\\\([x_1]\\\\) \\\\([x_2]\\\\)\\n- \\\\([\\\\text{jump}]\\\\) = RTURN\\n- \\\\([x_1 \\\\text{ opposite } x_2]\\\\) = \\\\([x_1]\\\\) \\\\([x_2]\\\\) \\\\([x_2]\\\\) \\\\([x_1]\\\\)\\n- \\\\([\\\\text{left}]\\\\) = YELLOW\\n- \\\\([x_1 \\\\text{ twice}]\\\\) = \\\\([x_1]\\\\)\\n- \\\\([\\\\text{turn}]\\\\) = RED\\n- \\\\([\\\\text{right}]\\\\) = WHITE\\n- \\\\([x_1 \\\\text{ thrice}]\\\\) = \\\\([x_1]\\\\) \\\\([x_1]\\\\)\\n- \\\\([\\\\text{walk}]\\\\) = GREEN\\n- \\\\([x_1 \\\\text{ after } x_2]\\\\) = \\\\([x_1]\\\\) \\\\([x_1]\\\\) \\\\([x_2]\\\\) \\\\([x_2]\\\\)\\n- \\\\([\\\\text{run}]\\\\) = JUMP\\n- \\\\([x_1 \\\\text{ around } x_2]\\\\) = \\\\([x_2]\\\\) \\\\([x_1]\\\\) \\\\([x_2]\\\\) \\\\([x_1]\\\\)\\n\\nLook around left and walk twice: YELLOW LOOK YELLOW LOOK GREEN\\nLook opposite left thrice: WALK WALK YELLOW YELLOW WALK WALK WALK WALK YELLOW YELLOW WALK WALK\\n\\nLook right: WHITE WHITE RTURN RTURN\\nWalk right twice: WHITE WHITE GREEN GREEN\\nRun left thrice and run: YELLOW YELLOW JUMP JUMP YELLOW YELLOW JUMP JUMP JUMP\\n\\nSubstituting \\\\(x_1\\\\) and \\\\(x_3\\\\) by \\\\([\\\\text{turn}]\\\\) = RED and \\\\(x_2\\\\) and \\\\(x_4\\\\) by \\\\([\\\\text{left}]\\\\) = YELLOW results in the rule:\\n\\n\\\\([\\\\text{turn opposite left after turn around left thrice}]\\\\) = RED YELLOW YELLOW RED RED YELLOW YELLOW RED YELLOW RED YELLOW RED YELLOW\\n\\nWhich varies from the predicted reply by the underlined tokens.\"}"}
{"id": "2iu9NhxX23", "page_num": 59, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example of T5-Large failing at inferring the type of reasoning, while the reply is correct.\\n\\nInput\\n\\n- \\\\[x_1 \\\\text{ around left and } x_2 \\\\text{ opposite right twice} = \\\\text{LOOK LOOK } [x_2] [x_1] [x_1] \\\\text{ GREEN } [x_1] [x_1] \\\\text{ BLUE LOOK LOOK } [x_2] \\\\]\\n- \\\\[x_1 \\\\text{ after } x_2 = [x_1] [x_2] [x_1] \\\\]\\n- \\\\[x_1 \\\\text{ thrice } = [x_1] [x_1] \\\\]\\n- \\\\[x_1 \\\\text{ around } x_2 = [x_1] [x_1] [x_2] \\\\]\\n- \\\\[\\\\text{walk} = \\\\text{LTURN} \\\\]\\n- \\\\[\\\\text{right} = \\\\text{LOOK} \\\\]\\n- \\\\[\\\\text{left} = \\\\text{GREEN} \\\\]\\n- \\\\[x_1 \\\\text{ opposite } x_2 = [x_2] [x_2] [x_1] \\\\]\\n- \\\\[\\\\text{look} = \\\\text{WALK} \\\\]\\n- \\\\[x_1 \\\\text{ twice } = [x_1] \\\\]\\n- \\\\[\\\\text{look twice and jump right WALK BLUE LOOK WALK WALK WALK BLUE LOOK} \\\\]\\n- \\\\[\\\\text{turn twice and walk left GREEN LTURN RUN RUN GREEN LTURN} \\\\]\\n- \\\\[\\\\text{jump left} = \\\\text{BLUE BLUE GREEN} \\\\]\\n- \\\\[\\\\text{run left} = \\\\text{GREEN BLACK} \\\\]\\n- \\\\[\\\\text{run around left twice BLACK BLACK GREEN} \\\\]\\n- \\\\[\\\\text{turn around left and run opposite right LOOK LOOK BLACK RUN RUN GREEN RUN RUN GREEN LOOK LOOK BLACK} \\\\]\\n- \\\\[\\\\text{run around } x_1 \\\\text{ thrice } = \\\\text{BLACK BLACK } [x_1] \\\\text{ BLACK BLACK } [x_1] \\\\]\\n- \\\\[\\\\text{run opposite } x_1 = [x_1] [x_1] \\\\text{ BLACK} \\\\]\\n- \\\\[\\\\text{walk right thrice after turn opposite left thrice LTURN LTURN LOOK LTURN LTURN LOOK LTURN LTURN LOOK GREEN GREEN RUN GREEN GREEN RUN LTURN LTURN LOOK LTURN LTURN LOOK} \\\\]\\n- \\\\[\\\\text{turn around right twice RUN RUN LOOK} \\\\]\\n- \\\\[\\\\text{turn around } x_1 = \\\\text{RUN RUN } [x_1] \\\\]\\n- \\\\[\\\\text{turn opposite left} = \\\\text{GREEN GREEN RUN} \\\\]\\n- \\\\[\\\\text{run opposite left thrice and look WALK GREEN GREEN BLACK GREEN GREEN BLACK WALK GREEN GREEN BLACK GREEN GREEN BLACK WALK} \\\\]\\n- \\\\[\\\\text{run around right and look around right twice WALK WALK LOOK BLACK BLACK LOOK BLACK BLACK LOOK WALK WALK LOOK} \\\\]\\n- \\\\[\\\\text{x1 and x2 thrice } = [x_2] [x_2] [x_1] [x_1] [x_2] [x_2] \\\\]\\n- \\\\[\\\\text{x1 and x2 opposite x3 } = [x_3] [x_3] [x_2] [x_1] [x_1] [x_3] [x_3] [x_2] \\\\]\\n- \\\\[\\\\text{jump opposite right thrice after walk around left LOOK LOOK BLUE LOOK LOOK BLUE LTURN LTURN GREEN LOOK LOOK BLUE LOOK LOOK BLUE} \\\\]\\n- \\\\[\\\\text{jump around right thrice and turn thrice RUN RUN BLUE BLUE LOOK BLUE BLUE LOOK RUN RUN} \\\\]\\n- \\\\[\\\\text{jump opposite right } = \\\\text{LOOK LOOK BLUE} \\\\]\\n- \\\\[\\\\text{jump opposite } x_1 \\\\text{ twice } = [x_1] [x_1] \\\\text{ BLUE} \\\\]\\n\\ntarget 0 (Reasoning: Defeasible)\\nprediction 0 (Reasoning: Monotonic)\\n\\nCommentary\\n\\n- The rule \\\\([x_1 \\\\text{ and } x_2] = [x_2] [x_1] [x_1] [x_2]\\\\) is hidden and can be induced from the context examples highlighted by an underline.\\n- Composing \\\\([x_1 \\\\text{ opposite } x_2] = [x_2] [x_2] [x_1]\\\\) into \\\\([x_1 \\\\text{ twice}] = [x_1]\\\\) results into the rule \\\\([x_1 \\\\text{ opposite } x_2 \\\\text{ twice}] = [x_2] [x_2] [x_1]\\\\).\\n- Composing \\\\([x_1 \\\\text{ around } x_2] = [x_1] [x_1] [x_2]\\\\) and \\\\([x_1 \\\\text{ opposite } x_2 \\\\text{ twice}] = [x_2] [x_2] [x_1]\\\\) into \\\\([x_1 \\\\text{ and } x_2]\\\\) results in the rule \\\\([x_1 \\\\text{ around } x_2 \\\\text{ and } x_3 \\\\text{ opposite } x_4 \\\\text{ twice}] = [x_4] [x_4] [x_3] [x_1] [x_1] [x_2] [x_1] [x_1] [x_2] [x_4] [x_4] [x_3]\\\\).\\n- Substituting \\\\([x_2] \\\\text{ and } [x_4] \\\\) by \\\\([\\\\text{left} = \\\\text{GREEN} \\\\text{ and } \\\\text{right} = \\\\text{LOOK} \\\\) respectively results in the rule \\\\([x_1 \\\\text{ around left and } x_2 \\\\text{ opposite right twice}] = \\\\text{LOOK LOOK } [x_3] [x_1] [x_1] \\\\text{ GREEN } [x_1] [x_1] \\\\text{ GREEN LOOK LOOK } [x_3].\\\\)\"}"}
{"id": "2iu9NhxX23", "page_num": 44, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"under review as a conference paper at ICLR 2023\\n\\n- input length bucket: The length of the input (context + request) in tokens. The lengths are bucketed for legibility: input length bucket=500 includes all examples with length at least 500 and less than 600.\\n\\n- context num explicit rules: The number of rules explicitly asserted in the context. Every context is based on 14 grammar rules, so for example, context num explicit rules=5 means that the context contains explicit assertions of 5 of these rules, while the other 9 rules are either illustrated indirectly via examples (such that the learner is expected to induce the rule to be true) or are not illustrated sufficiently (such that the learner is expected to consider the rule to be either false or unknown).\\n\\nIn all cases the accuracy appears negatively correlated num rules and derivation level. See text below each figure for additional observations.\\n\\nN.1 Partial Accuracy Metrics\\n\\nIn addition to exact match accuracy, for more nuanced error analysis, we track several additional finer-grained metrics, including partial accuracy metrics, edit distance, and counts of implications and contradictions related to the consistency metric.\\n\\n- Reply Accuracy: A prediction is considered correct if the reply portion is correct.\\n- Qualifier Accuracy: A prediction is considered correct if the qualifier portion is correct.\\n- Pattern Accuracy: Pattern accuracy assigns each token an incremental ID based on the order it appears in the sequence, thus ignoring the specific predicted tokens and focusing on token variation pattern. E.g. the sequence JUMP JUMP RUN JUMP and WALK WALK EAT WALK both have the same pattern of A A B A where A replaces JUMP and WALK in the first and second sequences respectively, while B replaces RUN and EAT in the first and second sequence respectively.\\n- Naive Accuracy: A prediction is considered correct if it produces the same set of unique tokens as the target regardless of the order or the count. E.g. the sequences JUMP JUMP RUN JUMP and RUN JUMP both have the same unique tokens set (JUMP and RUN).\\n- Token Accuracy: Token-wise accuracy between the prediction and the target. The two sequences are aligned at the start token, and the shorter sequence is padded to have the same length as the longer sequence such that the padded tokens are considered wrong predictions.\\n\\nTables 17, 18, 20, and 20 show the performance of each baseline on all of these metrics.\"}"}
{"id": "2iu9NhxX23", "page_num": 45, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 10: T5 accuracy on cSCAN-B examples. For non-rule examples, the accuracy appears positively correlated with the fraction of explicit rules (bottom-left).\\n\\nFigure 11: T5 accuracy on cSCAN-X examples. For non-rule examples, the accuracy appears positively correlated with the number of explicit examples in the context (bottom-right), and negatively correlated with the input length (bottom-center).\"}"}
{"id": "2iu9NhxX23", "page_num": 46, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 12: T5 accuracy on cSCAN-B MCD examples.\\n\\nFigure 13: T5 accuracy on cSCAN-X MCD examples. For both rule and non-rule examples, the accuracy appears negatively correlated with the input length (bottom-center).\"}"}
{"id": "2iu9NhxX23", "page_num": 47, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 17: Partial accuracy measures on cSCAN-B Random\\n\\n|                  | Baseline | Pretrain Size | Accuracy | Reply | Qualifier | Pattern | Naive Token |\\n|------------------|----------|---------------|----------|-------|-----------|---------|-------------|\\n| **T5 True**      |          |               |          |       |           |         |             |\\n| S                | 92.5     | 93.2          | 99.2     | 98.2  | 93.2      | 96.9    |             |\\n| B                | 92.6     | 93.3          | 99.1     | 98.4  | 93.3      | 97.2    |             |\\n| L                | 96.5     | 97.1          | 99.2     | 99.1  | 96.8      | 98.5    |             |\\n| **T5 False**     |          |               |          |       |           |         |             |\\n| S                | 19.3     | 28.4          | 61.1     | 51.8  | 38.9      | 27.5    |             |\\n| B                | 17.9     | 27.9          | 55.0     | 51.7  | 18.5      | 17.7    |             |\\n| **LongT5 False**|          |               |          |       |           |         |             |\\n| S                | 19.5     | 28.4          | 62.2     | 51.9  | 33.2      | 26.7    |             |\\n| B                | 21.4     | 29.9          | 65.6     | 52.7  | 39.2      | 30.7    |             |\\n| **LongT5-TGlobal**|         |               |          |       |           |         |             |\\n| S                | 20.0     | 28.7          | 62.9     | 51.8  | 43.2      | 29.5    |             |\\n| B                | 17.2     | 27.2          | 54.5     | 51.5  | 18.0      | 16.7    |             |\\n| **T5 w/o Context True**|        |               |          |       |           |         |             |\\n| B                | 26.8     | 43.8          | 54.8     | 53.3  | 26.9      | 15.5    |             |\\n\\n### Table 18: Partial accuracy measures on cSCAN-X Random\\n\\n|                  | Baseline | Pretrain Size | Accuracy | Reply | Qualifier | Pattern | Naive Token |\\n|------------------|----------|---------------|----------|-------|-----------|---------|-------------|\\n| **T5 True**      |          |               |          |       |           |         |             |\\n| S                | 68.3     | 70.1          | 96.4     | 88.5  | 77.2      | 85.7    |             |\\n| B                | 71.1     | 72.7          | 96.4     | 88.1  | 79.9      | 85.0    |             |\\n| L                | 81.6     | 83.6          | 97.1     | 91.2  | 88.5      | 90.2    |             |\\n| **T5 False**     |          |               |          |       |           |         |             |\\n| S                | 16.8     | 26.8          | 53.0     | 51.0  | 20.1      | 10.5    |             |\\n| B                | 17.2     | 27.1          | 52.9     | 51.1  | 19.8      | 8.6     |             |\\n| **LongT5 False**|          |               |          |       |           |         |             |\\n| S                | 18.1     | 27.7          | 55.8     | 51.3  | 22.9      | 11.4    |             |\\n| B                | 16.7     | 26.6          | 53.8     | 51.1  | 20.0      | 9.4     |             |\\n| **LongT5-TGlobal False**|        |               |          |       |           |         |             |\\n| S                | 18.0     | 27.6          | 55.6     | 51.4  | 21.9      | 11.1    |             |\\n| B                | 18.8     | 28.2          | 54.8     | 51.3  | 22.0      | 8.8     |             |\\n| **T5 w/o Context True**|        |               |          |       |           |         |             |\\n| B                | 23.8     | 38.7          | 52.0     | 52.1  | 23.9      | 4.4     |             |\\n\\n### Table 19: Partial accuracy measures on cSCAN-B MCD\\n\\n|                  | Baseline | Pretrain Size | Accuracy | Reply | Qualifier | Pattern | Naive Token |\\n|------------------|----------|---------------|----------|-------|-----------|---------|-------------|\\n| **T5 True**      |          |               |          |       |           |         |             |\\n| S                | 53.8     | 62.0          | 77.4     | 73.8  | 67.4      | 47.0    |             |\\n| B                | 54.7     | 62.9          | 78.4     | 76.0  | 67.2      | 51.0    |             |\\n| L                | 67.6     | 76.7          | 83.2     | 82.7  | 76.9      | 65.4    |             |\\n| **T5 False**     |          |               |          |       |           |         |             |\\n| S                | 40.1     | 47.7          | 68.4     | 67.4  | 50.4      | 31.8    |             |\\n| B                | 38.4     | 45.7          | 64.7     | 66.0  | 39.2      | 24.7    |             |\\n| **LongT5 False**|          |               |          |       |           |         |             |\\n| S                | 40.7     | 47.6          | 68.5     | 68.2  | 48.5      | 31.0    |             |\\n| B                | 38.2     | 45.2          | 67.5     | 66.8  | 45.2      | 29.6    |             |\\n| **LongT5-TGlobal False**|        |               |          |       |           |         |             |\\n| S                | 40.6     | 48.0          | 68.0     | 67.6  | 52.1      | 33.6    |             |\\n| B                | 39.3     | 45.9          | 66.9     | 68.0  | 45.6      | 30.2    |             |\\n| **T5 w/o Context True**|        |               |          |       |           |         |             |\\n| B                | 46.2     | 60.0          | 65.2     | 69.4  | 46.2      | 22.9    |             |\"}"}
{"id": "2iu9NhxX23", "page_num": 64, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nContradictory set of size 4: Type 3\\n\\nRequest 1\\n[x1 between fly cautiously 90 x2] = [x1] [x1] WALK WALK WALK WALK WALK WALK [x2] WALK WALK WALK WALK WALK WALK WALK WALK [x2] [x1]\\n\\nReply 1\\n1 (Reasoning: Monotonic)\\n\\nRequest 2\\n[walk] = RIDE RIDE\\n\\nReply 2\\n1 (Reasoning: Monotonic)\\n\\nRequest 3\\n[x1 cautiously 90 x2 3x] = [x1] [x1] [x1] [x1] [x1] [x1] [x1] [x2] [x1] [x1] [x1] [x1] [x1] [x1] [x2] [x1] [x1] [x1] [x1] [x1] [x1] [x1] [x2]\\n\\nReply 3\\n1 (Reasoning: Defeasible)\\n\\nRequest 4\\n[walk cautiously 90 x1 3x between fly cautiously 90 x2] = RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE"}
{"id": "2iu9NhxX23", "page_num": 60, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"All the above examples show inaccurate output, where there is a mismatch between the expected target and model prediction. However, as discussed in Section 4, regardless of being accurate, a model may fail to stay consistent in replying to different requests. In this section we sample contradictions made by T5-Large on cSCAN-X Random and categorize the type of contradictions the model makes. Note that consistency is independent of the context and therefore it's omitted when presenting the examples.\\n\\nAs seen in Appendix N.2, the models produce contradictory sets at different sizes. We find it easy to analyse each size independently as the type of mistakes vary between them.\\n\\nContradictions of size \\\\(2\\\\)\\n\\nAt this level, the inconsistencies are 1:1 relationships between two contradictory predictions \\\\(P_1\\\\) and \\\\(P_2\\\\). There are two types at this level\\n\\n- **Type 1:** Both \\\\(P_1\\\\) and \\\\(P_2\\\\) are asserted rules with matching right-hand sides and different right-hand sides.\\n- **Type 2:** One prediction is an asserted rule with no variables and the other is a rule application prediction with a request matching the right-hand side of the rule request while the reply does not match the rule request's right-hand side.\\n\\nFrom a sample of 20 contradictory sets of size 2, 11 sets were of type 1 while 9 were found to be of type 2. Here are examples of both types\\n\\n**Contradictory set of size 2: Type 1**\\n\\nRequest 1\\n\\n```\\n[drive left 5x framing x1 x2] = [x1] [x2] [x1] [x1] [x2] [x2] [x1] [x2] [x1] [x2] DTURN LOOK DTURN DTURN LOOK LOOK DTURN LOOK DTURN DTURN LOOK\\n```\\n\\nReply 1\\n\\n```\\n1 (Reasoning: Monotonic)\\n```\\n\\n**Commentary**\\n\\nThe two right-hand sides are different in the underlined tokens.\\n\\n**Contradictory set of size 2: Type 2**\\n\\nRequest 1\\n\\n```\\n[run zigzag left after run fast around left] = PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK PEEK RUN PEEK PEEK PEEK PEEK\\n```\\n\\nReply 1\\n\\n```\\n1 (Reasoning: Defeasible)\\n```\\n\\n**Commentary**\\n\\nReply 2 is different from the right-hand side of Request 1 by one additional token (highlighted with an underline).\\n\\nContradictions of size \\\\(3\\\\)\\n\\nAt this level, the inconsistencies are 2:1 relationships with at least two rule assertions.\\n\\n- **Type 1:** The composition of two rules directly contradicts a third rule.\"}"}
{"id": "2iu9NhxX23", "page_num": 61, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Type 2: The composition of two rules forms a rule with no variables where it's right-hand side matches the request of a rule application prediction and it's right-hand side contradicts the reply of that prediction.\\n\\nFrom a sample of 20 contradictory sets of size 3, both Type 1 and Type 2 had 10 sets each. Here are examples of both types:\\n\\nContradictory set of size 3: Type 1\\n\\nRequest 1\\n[\\\\texttt{x1 cautiously x2} = [x1] [x1] [x1] [x2] [x2] [x2] [x1] [x1] [x1] [x2] [x2]]\\n\\nReply 1\\n1 (Reasoning: Monotonic)\\n\\nRequest 2\\n[\\\\texttt{walk} = RIDE RIDE]\\n\\nReply 2\\n1 (Reasoning: Monotonic)\\n\\nRequest 3\\n[\\\\texttt{walk cautiously x1} = RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1]]\\n\\nReply 3\\n1 (Reasoning: Monotonic)\\n\\nCommentary\\nComposing Rule 2 into Rule 1 would result in the rule\\n\\n\\\\[\\\\texttt{[walk cautiously x1] = RIDE RIDE RIDE RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE RIDE RIDE RIDE [x1] [x1]}\\\\]\\n\\nWhich is different from Rule 3 in places highlighted by an underline.\\n\\nContradictory set of size 3: Type 2\\n\\nRequest 1\\n[\\\\texttt{run opposite up thrice following x1} = LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK]\\n\\nReply 1\\n1 (Reasoning: Monotonic)\\n\\nRequest 2\\n[\\\\texttt{run opposite up thrice following run zigzag}]\\n\\nReply 2\\nLOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK (Reasoning: Monotonic)\\n\\nRequest 3\\n[\\\\texttt{run zigzag} = LOOK]\\n\\nReply 3\\n1 (Reasoning: Monotonic)\\n\\nCommentary\\nComposing Rule 2 into Rule 3 would result in the rule\\n\\n\\\\[\\\\texttt{[run opposite up thrice following run zigzag] = LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK LOOK}\\n\\\\[\\\\texttt{LOOK RUN LOOK}\\n\\\\[\\\\texttt{LOOK RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{RUN}\\n\\\\[\\\\texttt{LOOK}\\n\\\\[\\\\texttt{"}
{"id": "2iu9NhxX23", "page_num": 62, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Contradictory set of size 4: Type 1\\n\\nRequest 1\\n= RTURN PEEK PEEK PEEK PEEK PEEK\\n\\nReply 1\\n1 (Reasoning: Monotonic)\\n\\nRequest 2\\njump drunkenly twice after run drunkenly down\\n\\nReply 2\\nRIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE RIDE"}
{"id": "2iu9NhxX23", "page_num": 63, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Contradictory set of size 4: Type 2\\n\\nRequest 1\\n\\n[x1] [x1] [x1] [x2] [x2] [x2] [x1] [x1] [x1] [x2] [x2] [x2] [x1] [x1] [x1] [x2] [x2] [x1] [x1] [x1] [x2] [x2]\\n\\nReply 1\\n\\n1 (Reasoning: Monotonic)\\n\\nRequest 2\\n\\n[walk] = RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x1] [x1] [x1] RIDE RIDE RIDE [x"}
