{"id": "L01Nn_VJ9i", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACKNOWLEDGMENTS\\n\\nFor real-time forecasting in domains like public health and macroeconomics, data collection is a non-trivial and demanding task. Often after being initially released, it undergoes several revisions later (maybe due to human or technical constraints) \u2014 as a result, it may take weeks until the data reaches a stable value. This so-called 'backfill' phenomenon and its effect on model performance have been barely addressed in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework, Back2Future, that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of diverse set of top models for COVID-19 forecasting and GDP growth forecasting. Specifically, we show that Back2Future refined top COVID-19 models by 6.65% to 11.24% and yield 18% improvement over non-trivial baselines. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.\\n\\nINTRODUCTION\\n\\nThe current COVID-19 pandemic has challenged our response capabilities to large disruptive events, affecting the health and economy of millions of people. A major tool in our response has been forecasting epidemic trajectories which enabled policymakers to plan interventions (Holmdahl & Buckee, 2020). Broadly two classes of approaches have been devised: traditional mechanistic epidemiological models (Shaman & Karspeck, 2012; Zhang et al., 2017), and the fairly newer statistical approaches (Brooks et al., 2018; Adhikari et al., 2019; Osthus et al., 2019b) including deep learning models (Adhikari et al., 2019; Panagopoulos et al., 2021; Rodr\u00edguez et al., 2021a), which have become among the top-performing ones for multiple forecasting tasks (Reich et al., 2019). These models also use newer digital indicators like search queries (Ginsberg et al., 2009; Yang et al., 2015) and social media (Culotta, 2010). Epidemic forecasting is still a challenging enterprise (Metcalf & Lessler, 2017; Biggerstaff et al., 2018) because it is affected by weather, mobility, strains, and others. However, real-time forecasting also brings new challenges. As noted in multiple CDC real-time forecasting initiatives for diseases like flu (Osthus et al., 2019a) and COVID-19 (Cramer et al., 2021), as well as in macroeconomics (Clements & Galv\u00e3o, 2019; Aguiar, 2015) the initially released public health data is revised many times after and is known as the 'backfill' phenomenon. The various factors that affect backfill are multiple and complex, ranging from surveillance resources to human factors like coordination between health institutes and government organizations within and across regions (Chakraborty et al., 2018; Reich et al., 2019; Altieri et al., 2021; Stierholz, 2017).\\n\\nWhile previous works have addressed anomalies (Liu et al., 2017), missing data (Yin et al., 2020), and data delays (\u017dliobaite, 2010) in general time-series problems, the backfill problem has not been addressed. In contrast, the topic of revisions has not received as much attention, with few exceptions. For example in epidemic forecasting, a few papers have either (a) mentioned about the 'backfill problem' and its effects on performance (Chakraborty et al., 2018; Rodr\u00edguez et al., 2021b; Altieri et al., 2021) or (b) have focused on other issues like improving the quality of predictions by integrating revisions (Cramer et al., 2021). However, it is important to note that the focus has been on improving the quality of predictions rather than on the effects of backfill on models' performance. In this paper, we aim to address this gap by proposing a novel framework, Back2Future, that refines model predictions in real-time, taking into account the backfill phenomenon.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\net al., 2021; Rangarajan et al., 2019) and evaluation (Reich et al., 2019); or (b) proposed to address the problem via simple models like linear regression (Chakraborty et al., 2014) or 'backcasting' (Brooks et al., 2018) the observed targets. The related problem of nowcasting involves prediction of revised stable value of current week's target from sequence of right-truncated past values [Aditya: cite one paper]. Prior works have used data assimilation and sensor fusion from a readily available stable set of features to refine unrevised features for accurate nowcasting (Farrow, 2016; Osthus et al., 2019a). However, most methods focus only on revisions in the target and typically study in the context of influenza forecasting, which is substantially less noisy and more regular than the novel COVID-19 pandemic or assume access to stable values for some features which is not the case for COVID-19. In economics, Clements & Galv\u00e3o (2019) surveys several domain-specific (Carriero et al., 2015) or essentially linear techniques for data revision/correction behavior of several macroeconomic indicators (Croushore, 2011).\\n\\nMotivated from above, we study the challenging problem of multi-variate backfill for both features and targets. We go further beyond prior work and also show how to leverage our insights towards a general neural framework to improve model predictions and performance evaluation (i.e. rectification of current target from the evaluator's perspective). Our specific contributions are the following:\\n\\n\u2022 Multi-variate backfill problem: We introduce the multi-variate backfill problem using real-time epidemiological forecasting as the primary motivating example. In this challenging setting, which generalizes (the limited) prior work, the forecast targets, as well as exogenous features, are subject to retrospective revision. Using a carefully collected diverse dataset for COVID-19 forecasting for the past year, we discover several patterns in backfill dynamics, show that there is a significant difference in real-time and revised feature measurements, and highlight the negative effects of using unrevised features for incidence forecasting in different models both for model performance and evaluation. Building on our empirical observations, we formulate the problem $B_{FRP}$, which aims to 'correct' given model predictions to achieve better performance on eventual fully revised data.\\n\\n\u2022 Spatial and Feature level backfill modeling to refine model predictions: Motivated by the patterns in revision and observations from our empirical study, we propose a deep-learning model Back2Future (B2F) to model backfill revision patterns and derive latent encodings for features. B2F combines Graph Convolutional Networks that capture sparse, cross-feature, and cross-regional backfill dynamics similarity and deep sequential models that capture temporal dynamics of each features' backfill dynamics across time. The latent representation of all features is used along with the history of the model's predictions to improve diverse classes of models trained on real-time targets, to predict targets closer to revised ground truth values. Our technique can be used as a 'wrapper' to improve model performance of any forecasting model (mechanistic/statistical).\\n\\n\u2022 Refined top models' predictions and improved model evaluation: We perform an extensive empirical evaluation to show that incorporating backfill dynamics through B2F consistently improves the performance of diverse classes of top-performing COVID-19 forecasting models (from the CDC COVID-19 Forecast Hub, including the top-performing official ensemble) significantly. B2F also enables forecast evaluators and policy-makers better evaluate the 'eventual' true accuracy of participating models (against revised ground truth). This allows the model evaluators to quickly estimate models that perform better w.r.t revised stable targets instead of potentially misleading current targets. Our methodology can also be further adapted for nowcasting and other general time-series forecasting problems. We also show the generalizability of our framework and model B2F to other domains by significantly improving predictions of non-trivial baselines for US National GDP forecasting (Marcellino, 2008).\\n\\n2 NATURE OF BACKFILL DYNAMICS\\n\\nIn this section, we study important properties of the revision dynamics of our signals. We introduce some concepts and definitions to aid in the understanding of our empirical observations and method. Real-time forecasting. We are given a set of signals $F = Reg \\\\times Feat$, where $Reg$ is the set of all regions (where we want to forecast) and set $Feat$ contains our features and forecasting target(s) for each region. At prediction week $t$, $x(t)$ is a time series from 1 to $t$ for feature $i$, and the set of all signals results in the multi-variate time series $X(t)$ from 1 to $t$. Similarly, $Y(t)$ is the forecasting target(s) time series. In practice, delays are possible too, i.e, at week $t$, we have data for some feature $i$ only until $t - \\\\delta_i$. All our results incorporate these situations. We defer the minor needed notational extensions to Appendix for clarity.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Bijaya Adhikari, Xinfeng Xu, Naren Ramakrishnan, and B Aditya Prakash. Epideep: Exploiting embeddings for epidemic forecasting. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 577\u2013586, 2019.\\n\\nAngel Aguiar. Macroeconomic data. 2015.\\n\\nNick Altieri, Rebecca L Barter, James Duncan, Raaz Dwivedi, Karl Kumbier, Xiao Li, Robert Netzorg, Briton Park, Chandan Singh, Yan Shuo Tan, Tiffany Tang, Yu Wang, Chao Zhang, and Bin Yu. Curating a covid-19 data repository and forecasting county-level death counts in the united states. Harvard Data Science Review, 2 2021. doi: 10.1162/99608f92.1d4e0dae. URL https://hdsr.mitpress.mit.edu/pub/p6isyf0g.\\n\\nApple. Apple mobility trends reports., 2020. URL www.apple.com/covid19/mobility.\\n\\nAlberto Baffigi, Roberto Golinelli, and Giuseppe Parigi. Bridge models to forecast the euro area gdp. International Journal of forecasting, 20(3):447\u2013460, 2004.\\n\\nMatthew Biggerstaff, Michael Johansson, David Alper, Logan C Brooks, Prithwish Chakraborty, David C Farrow, Sangwon Hyun, Sasikiran Kandula, Craig McGowan, Naren Ramakrishnan, et al. Results from the second year of a collaborative effort to forecast influenza seasons in the united states. Epidemics, 24:26\u201333, 2018.\\n\\nLogan C. Brooks, David C. Farrow, Sangwon Hyun, Ryan J. Tibshirani, and Roni Rosenfeld. Nonmechanistic forecasts of seasonal influenza with iterative one-week-ahead distributions. PLOS Computational Biology, 14(6):e1006134, June 2018. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1006134. URL https://dx.plos.org/10.1371/journal.pcbi.1006134.\\n\\nAndrea Carriero, Michael P Clements, and Ana Beatriz Galv\u00e3o. Forecasting with bayesian multivariate vintage-based vars. International Journal of Forecasting, 31(3):757\u2013768, 2015.\\n\\nCDC. Coronavirus Disease 2019 (COVID-19), 2020. URL https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/.\\n\\nPrithwish Chakraborty, Pejman Khadivi, Bryan Lewis, Aravindan Mahendiran, Jiangzhuo Chen, Patrick Butler, Elaine O Nsoesie, Sumiko R Mekaru, John S Brownstein, Madhav V Marathe, et al. Forecasting a moving target: Ensemble models for ili case count predictions. In Proceedings of the 2014 SIAM international conference on data mining, pp. 262\u2013270. SIAM, 2014.\\n\\nPrithwish Chakraborty, Bryan Lewis, Stephen Eubank, John S. Brownstein, Madhav Marathe, and Naren Ramakrishnan. What to know before forecasting the flu. PLOS Computational Biology, 14(10), October 2018. ISSN 1553-734X. doi: 10.1371/journal.pcbi.1005964. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6193572/.\\n\\nJudith A Chevalier, Jason L Schwartz, Yihua Su, Kevin R Williams, et al. Measuring movement and social contact with smartphone data: A real-time application to covid-19. Technical report, Cowles Foundation for Research in Economics, Yale University, 2021.\\n\\nKyunghyun Cho, B. V. Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio. On the properties of neural machine translation: Encoder-decoder approaches. ArXiv, abs/1409.1259, 2014.\\n\\nMichael P Clements and Ana Beatriz Galv\u00e3o. Data revisions and real-time forecasting. In Oxford Research Encyclopedia of Economics and Finance. 2019.\\n\\nCOVID-Tracking. The covid tracking project., 2020. URL https://covidtracking.com.\\n\\nEstee Y Cramer, Velma K Lopez, Jarad Niemi, Glover E George, Jeffrey C Cegan, Ian D Dettwiller, William P England, Matthew W Farthing, Robert H Hunter, Brandon Lafferty, et al. Evaluation of individual and ensemble probabilistic forecasts of covid-19 mortality in the us. medRxiv, 2021.\\n\\nDean Croushore. Forecasting with real-time data vintages. The Oxford handbook of economic forecasting, pp. 247\u2013267, 2011.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "L01Nn_VJ9i", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "L01Nn_VJ9i", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "L01Nn_VJ9i", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Published as a conference paper at ICLR 2022\\n\\nseries. Further, let's call all data available at time \\\\( t \\\\), \\\\( D(t) \\\\)\\n\\\\( 1: t \\\\) as a real-time sequence. For clarity we refer to 'signal' \\\\( i \\\\) \\\\( \\\\in F \\\\) as a sequence of either a feature or a target, and denote it as \\\\( d(t) \\\\).\\n\\nThus, at prediction week \\\\( t \\\\), the real-time forecasting problem is: Given \\\\( D(t) \\\\) \\\\( 1: t \\\\), predict next \\\\( k \\\\) values of forecasting target(s), i.e. \\\\( \\\\hat{y}_{t+1: t+k} \\\\).\\n\\nTypically for CDC settings and this paper, our time unit is week, \\\\( k = 4 \\\\) (up to 4 weeks ahead) and our target is COVID-19 mortality incidence (Deaths).\\n\\nRevisions. Data revisions ('backfill') are common. At prediction week \\\\( t+1 \\\\), the real-time sequence \\\\( D(t+1) \\\\) \\\\( 1: t+1 \\\\) is available. In addition to the length of the sequences increasing by one (new data point), values of \\\\( D(t+1) \\\\) \\\\( 1: t+1 \\\\) already in \\\\( D(t) \\\\) \\\\( 1: t \\\\) may be revised i.e., \\\\( D(t) \\\\) \\\\( 1: t \\\\) \\\\( \\\\neq D(t+1) \\\\) \\\\( 1: t+1 \\\\).\\n\\nNote that previous work has studied backfill limited to \\\\( Y(t) \\\\), while we address it in both \\\\( X(t) \\\\) and \\\\( Y(t) \\\\).\\n\\nAlso, note that the data in the backfill is the same used for real-time forecasting, but just seen from a different perspective.\\n\\nBackfill sequences: Another useful way we propose to look at backfill is by focusing on revisions of a single value. Let's focus on value of signal \\\\( i \\\\) at an observation week \\\\( t' \\\\). For this observation week, the value of the signal can be revised at any \\\\( t > t' \\\\), which induces a sequence of revisions. We refer to revision week \\\\( r \\\\geq 0 \\\\) as the relative amount of time that has passed since the observation week \\\\( t' \\\\).\\n\\nDefn. 1. (Backfill Sequence BS) For signal \\\\( i \\\\) and observation week \\\\( t' \\\\), its backfill sequence is \\\\( BS(i, t') = \\\\langle d(t') \\\\mid i, t', d(t') + 1 \\\\mid i, t', . . . , d(\\\\infty) \\\\mid i, t' \\\\rangle \\\\), where \\\\( d(t') \\\\mid i, t' \\\\) is the initial value of the signal and \\\\( d(\\\\infty) \\\\mid i, t' \\\\) is the final/stable value of the signal.\\n\\nDefn. 2. (Backfill Error BE) For revision week \\\\( r \\\\) of a backfill sequence, the backfill error is \\\\( BE(r, i, t') = \\\\frac{|d(t' + r) \\\\mid i, t' - d(\\\\infty) \\\\mid i, t'|}{|d(\\\\infty) \\\\mid i, t'|} \\\\).\\n\\nDefn. 3. (Stability time STIME) of a backfill sequence \\\\( BS \\\\) is the revision week \\\\( r^* \\\\) that is the minimum \\\\( r \\\\) for which the backfill error \\\\( BE < \\\\epsilon \\\\) for all \\\\( r > r^* \\\\), i.e., the time when \\\\( BS \\\\) stabilizes.\\n\\nNote: We ensured that \\\\( BS \\\\) length is at least 7, and found that in our dataset most signals stabilize before \\\\( r = 20 \\\\).\\n\\nFor \\\\( BS \\\\) \\\\( \\\\{223, 236, 236, 404, . . . , 404\\\\} \\\\), \\\\( BE \\\\) for third week is \\\\( \\\\frac{|236 - 404|}{404} = 0.41 \\\\) and \\\\( STIME \\\\) is 4.\\n\\n2.1 DATASET DESCRIPTION\\n\\nTable 1: List of features in our CoVDS\\n\\n| Type       | Features                  |\\n|------------|---------------------------|\\n| Patient    | Line-List, ERVisits, HospRate, +veInc, HospInc, Recovered, onVentilator, inICU |\\n| Testing    | TestResultsInc, -veInc, Facilities |\\n| Mobility   | RetailRec, Grocery, Parks, Transit, WorkSpace, Resident, AppleMob |\\n| Exposure   | DexA, Social Survey       |\\n| Survey     | FbCLI, FbWiLi             |\\n\\nWe collected and pre-processed important publicly available signals from a variety of trusted sources that are relevant to COVID-19 forecasting to form the COVID-19 Surveillance Dataset (CoVDS).\\n\\nSee Table 1 for the list of 20 features (\\\\( |Feat| = 21 \\\\), including \\\\( Deaths \\\\)). We collected revised features every week from April 2020 to July 2021. Our analysis covers 30 observation weeks from June 2020 to December 2020 (to ensure all our backfill sequences are of length at least 7) for all \\\\( |Reg| = 50 \\\\) US states. The rest of the unseen data from Jan 2021 to July 2021 is used strictly for evaluation.\\n\\nPatient line-list: traditional surveillance signals used in epidemiological models (Chakraborty et al., 2014; Brooks et al., 2018) derived from line-list records e.g. hospitalizations from CDC (CDC, 2020), positive cases, ICU admissions from COVID Tracking (COVID-Tracking, 2020).\\n\\nTesting: measure changes in testing from CDC and COVID-Tracking used by Rodr\u00edguez et al. (2021b).\\n\\nMobility: quantify change in people's movement to several point of interests (POIs); derived from mobility reports released by Google (2020); Apple (2020).\\n\\nExposure: digital signal measuring closeness between people at POIs, (Chevalier et al., 2021)\\n\\nSocial Survey: used by (Wang et al., 2020; Rodr\u00edguez et al., 2021b) CMU/Facebook Symptom Survey Data contains self-reported responses about COVID-19 symptoms.\\n\\n2.2 OBSERVATIONS\\n\\nWe first study different facets of the significance of backfill in CoVDS. Using our definitions, we generate a backfill sequence for every combination of signal, observation week, and region (not all signals are available for all regions). In total, we generate more than 30,000 backfill sequences.\\n\\n3\"}"}
{"id": "L01Nn_VJ9i", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We computed Backfill Error (BE) for the initial values, i.e., \\\\( \\\\text{BE}(r=0, i, t') \\\\), for all signals \\\\( i \\\\) and observation weeks \\\\( t' \\\\).\\n\\n**Obs. 1.** (BE across signals and regions) Compute the average BE for each signal; the median of all these averages is 32%, i.e., at least half of all signals are corrected by 32% of their initial value. Similarly in at least half of the regions the signal corrections are 280% of their initial value. We also found large variation of BE. For features (Figure 1a), compare average BE = 1743% of the five most corrected features with 1.6% of the five least corrected features. Also, in contrast to related work that focuses on traditional surveillance data Yang et al. (2015), perhaps unexpectedly, we found that digital indicators also have a significant BE (average of 108%). For regions (see Figure 1b), compare 1594% of the five most corrected regions with 38% of the five least corrected regions.\\n\\nStability time (STIME) is significant. A similar analysis for STIME found significant variation across signals (from 1 weeks for to 21 weeks for COVID-19, see Figure 1c for STIME across feature types) and regions (from 1.55 weeks for GA to 3.83 weeks for TX, see Figure 1d). This also impacts our target, thus, actual accuracy is not readily available which undermines real-time evaluation and decision making.\\n\\n**Obs. 2.** (STIME of features and target) Compute the average STIME for each signal; the average of all these averages for features is around 4 weeks and for our target Deaths is around 3 weeks, i.e., on average, it takes over 3 weeks to reach the stable values of features.\\n\\nBackfill sequence (BS) shows significant similarity among BSs. We cluster BSs via K-means using Dynamic Time Warping (DTW) as pair-wise distance (as DTW can handle sequences of varying magnitude and length). We found five canonical categories of behaviors (see Figure 2), each of size roughly 11.58% of all BSs. Also, each cluster is not defined only by signal nor region. Hence there is a non-trivial similarity across both signals and regions.\\n\\n**Obs. 3.** (BS similarity and variety) Five canonical behaviors were observed in our backfill sequences (Figure 2). No cluster has over 21% of BSs from the same region, and no cluster has over 14% of BSs from the same signal.\\n\\nModel performance vs BE. To study the relationship between model performance (via Mean Absolute Error MAE of a prediction) and BE, we use \\\\( \\\\text{REV}D\\\\text{IFF} \\\\): the difference between MAE computed against real-time target value and one against the stable target value. We analyze the top-performing real-time forecasting models as per the comprehensive evaluation of all models in COVID-19 Forecast Hub (Cramer et al., 2021). YYG and UM\\\\_ASS-\\\\_MB are mechanistic while CMU-TS and GT-DC are statistical models. The top performing \\\\( \\\\text{ENSEMBLE} \\\\) is composed of all contributing models to the hub. We expect a well-trained real-time model will have higher \\\\( \\\\text{REV}D\\\\text{IFF} \\\\) with larger BE in its target (Reich et al., 2019). However, we found that higher BE does not necessarily mean worse performance. See Figure 3\u2014YYG has even better performance with more revisions. This may be due to the more complex backfill activity/dependencies in COVID in comparison to the more regular seasonal flu.\\n\\n**Obs. 4.** (Model performance and backfill) Relation between BE and \\\\( \\\\text{REV}D\\\\text{IFF} \\\\) can be non-monotonous and positively or negatively correlated depending on model and signal.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Since targets undergo revisions (5% BE on average), we study how this BE affects the real-time evaluation of models. From Figure 4, we see that the scores are not similar with real-time scores over-estimating model accuracy. The average difference in scores is positive which implies that evaluators would overestimate models' forecasting ability.\\n\\n**Obs. 5.** MAE evaluated at real-time overestimates model performance by 9.6 on average, with the maximum for TX at 22.63.\\n\\n---\\n\\n**Overview:** We leverage observations from Section 2 to derive Back2Future (B2F), a deep-learning model that uses revision information from BS_EQ to refine predictions. Obs. 1 and 2 show that real-time values of signals are poor estimates of stable values. Therefore, we leverage patterns in BS_EQ of past signals and exploit cross-signal similarities (Obs. 3) to extract information from BS_EQs. We also consider that the relation of models' forecasts to BE_RR of targets is complex (Obs. 4 and 5) to refine their predictions. B2F combines these ideas through its four modules:\\n\\n1. **G**RAPH**G**EN: Generates a signal graph (where each node maps to a signal in Reg \u00d7 Feat) whose edges are based on BS_EQ similarities.\\n2. **B**SEQ**E**NC: Leverages the signal graph as well as temporal dynamics of BS_EQs to learn a latent representation of BS_EQs using a Recurrent Graph Neural Network.\\n3. **M**ODEL**P**RED**E**NC: Encodes the history of the model's predictions, the real-time value of the target, and past revisions of the target through a recurrent neural network.\\n4. **R**EFINER: Combines encodings from BSEQ and MODELRED to predict the correction to model's real-time prediction.\\n\\nIn contrast to previous works that studies target BE_RR (Reich et al., 2019), we simultaneously model all BS_EQ available till current week using spatial and signal similarities in the temporal dynamics of BS_EQ. Recent works that attempt to model spatial relations for COVID19 forecasting need explicitly structural data (like cross-region mobility) (Panagopoulos et al., 2020) to generate a graph or use attention over temporal patterns of regions' death trends. B2F, in contrast, directly models the structural information of signal graph (containing features from each region) using BS_EQ similarities. Thus, we first generate useful latent representations for each signal based on BS_EQ revision information of that feature as well as features that have shown similar revision patterns in the past. Due to the large number of signals that cover all regions, we cannot model the relations between every pair using fully connected modules or attention similar to (Jin et al., 2020). Therefore, we first construct a sparse graph between signals based on past BS_EQ similarities. Then we inject this similarity information using Graph Convolutional Networks (GCNs) and combine it with deep sequential models to model temporal dynamics of BS_EQ of each signal while combining information from BS_EQs of signals in the neighborhood of the graph.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"we use these latent representations and leverage the history of a model $M$'s predictions to re-fine its prediction. Thus, B2F solves $BFRP_k(M)$ assuming $M$ is a black box, accessing only its past forecasts. Our training process, that involves pre-training on model-agnostic auxiliary task, greatly improves training time for refining any given model $M$. The full pipeline of B2F is also shown in Figure 5. Next, we describe each of the components of B2F in detail. For the rest of this section, we will assume that we are forecasting $k$ weeks ahead given data till current week $t$.\\n\\nFigure 5: B2F pipeline with all components\\n\\n$GRAPH$ generates an undirected signal graph $G_t = (V, E_t)$ whose edges represent similarity in $BS_EQ$s between signals, where vertices $V = \\\\mathbb{F} = \\\\text{Reg} \\\\times \\\\text{Feat}$. We measure similarity using DTW distance due to reasons described in Section 2.\\n\\n$GRAPH$ leverages the similarities across $BS_EQ$ patterns irrespective of the exact nature of canonical behaviors which may vary across domains. We compute the sum of DTW distances of $BS_EQ$s for each pair of nodes summed over $t' \\\\in \\\\{1, 2, \\\\ldots, t - 5\\\\}$. We threshold $t'$ till $t - 5$ to make the $BS_EQ$s to be of reasonable length (at least 5) to capture temporal similarity without discounting too many $BS_EQ$s. Top $\\\\tau$ node pairs with lowest total DTW distance are assigned an edge.\\n\\nWhile we can model backfill sequences for each signal independently using a recurrent neural network, this doesn't capture the behavioral similarity of $BS_EQ$ across signals. Using a fully-connected recurrent neural network that considers all possible interactions between signals also may not learn from the similarity information due to the sheer number of signals ($50 \\\\times 21 = 1050$) while greatly increasing the parameters of the model. Thus, we utilize the structural prior of graph $G_t$ generated by $GRAPH$ and train an autoregressive model $SEQ_NC$ which consists of graph recurrent neural network to encode a latent representation for each of backfill sequence in $B_t = \\\\{BS_EQ(i, t') : i \\\\in F\\\\}$. At week $t$, $SEQ_NC$ is first pre-trained and then it is fine-tuned for a specific model $M$ (more details later in this section).\\n\\nOur encoding process is in Figure 5. Let $BS_EQ_{t' + r(i, t')}\\\\vdash$ be first $r + 1$ values of $BS_EQ(i, t')$ (till week $t' + r$). For a past week $t'$ and revision week $r$, we denote $h(t' + r)_{i, t'} \\\\in \\\\mathbb{R}^m$ to be the latent encoding of $BS_EQ_{t' + r(i, t')}$, where $t' + r \\\\leq t' \\\\leq t' + r$. We initialize $h(0)_{i, t'}$ for any observation week to be a learnable parameter $h(0)_i \\\\in \\\\mathbb{R}^m$ specific to signal $i$. For each week $t'$ we combine latent encoding $h(t' - 1)_{i, t'}$ and signal value $d_{i, t'}$ using a GRU (Gated Recurrent Unit) (Cho et al., 2014) cell to get the intermediate embedding $v_{i, t'}$. Then, we leverage the signal graph $G_t$ and pass the embeddings $\\\\{v_{i, t'} : i \\\\in F\\\\}$ through a Graph Convolutional layer (Kipf & Welling, 2016) to get $h(t' + r)_{i, t'}$:\\n\\n$$v_{i, t'} = \\\\text{GRU}_BE(d_{i, t'}, h(t' - 1)_{i, t'}) \\\\quad \\\\forall \\\\ i \\\\in F = \\\\text{GConv}(G_t, \\\\{v_{i, t'} : i \\\\in F\\\\}).$$\\n\\nThus, $h(t' + r)_{i, t'}$ contains information from $BS_EQ_{t' + r(i, t')}$ and structural priors from $G_t$. Using $h(t' + r)_{i, t'}$, $SEQ_NC$ predicts the value $d_{t' + 1(i, t')} \\\\vdash$ by passing through a 2-layer feed-forward network $FFN_i$:\\n\\n$$\\\\hat{d}_{t' + 1(i, t')} = FFN_i(h(t' + r)_{i, t'}).$$\\n\\nDuring inference, we only have access to real-time values of signals for the current week. We autoregressively predict $h(t + l)_{i, t}$ for each signal by initially passing $\\\\{d_{i, t}\\\\} : i \\\\in F$ through $SEQ_NC$ and using the output $\\\\{\\\\hat{d}_{t + 1(i, t')}\\\\} : i \\\\in F$ as input for $SEQ_NC$. Iterating this $l$ times we get $\\\\{h(t + l)_{i, t}\\\\} : i \\\\in F$ along with $\\\\{\\\\hat{d}_{t + l(i, t')}\\\\} : i \\\\in F$ where $l$ is a hyperparameter.\\n\\n$MODEL_PRED_NC$. To learn from history of a model's predictions and its relation to target revisions, $MODEL_PRED_NC$ encodes the history of model's predictions, previous real-time targets, and revised (up to current week) targets using a Recurrent Neural Network. Given a model $M$, for each observation week $t' \\\\in \\\\{1, 2, \\\\ldots, t - 1 - k\\\\}$, we concatenate the model's predictions $y(M, k)_{t'}$, real-time target $d_{i, t'}$ and revised $\\\\hat{d}_{i, t'}$ targets using a Recurrent Neural Network.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Autoregressive\\n\\nWe leveraged observations (Section 2) from BS.\\n\\nModel specific end-to-end training:\\n\\nGiven the pre-trained B,\\n\\nwe first take attention over BS\\n\\n\u2295\\n\\nwhere\\n\\nThere are two steps of training involved for B2F: 1) model agnostic autoregressive BS\\n\\nSetup:\\n\\nWe perform real-time forecasting of COVID-19 related mortality (www.github.com/AdityaLab/Back2Future)\\n\\nhyperparameters and results for June-Dec 2020 and\\n\\ntypically takes around 1 hour to train for all regions. The appendix contains additional details (all\\n\\nIn this section, we describe a detailed empirical study to evaluate the effectiveness of our framework\\n\\nG\\n\\nuse\\neach week from scratch (including pre-training). Throughout training and forecasting for week\\n\\nfunction:\\n\\nL\\n\\nand finally R\\n\\nt\\n\\ny\\n\\n\u27e8\\n\\nthe parameters of all modules of B2F . The training set consists of past model predictions\\n\\nenabling quick refinement of multiple models in parallel.\\n\\nnext time step. Once we pre-train B\\n\\nthen transition to using output predictions of previous time step by the recurrent module as input to\\n\\net al., 2014) where for initial epochs we use the ground truth inputs at each step (teacher forcing) and\\n\\nwe only use BS\\n\\n2018). We pre-train B\\n\\nembedding is a well-known technique for deep learning methods (Devlin et al., 2019; Radford et al.,\\n\\nthe refinement of prediction to this range.\\n\\naverage BE\\n\\nNote that we limit the correction by B2F by at most the magnitude of model's prediction because the\\n\\ntanh(FFN\\n\\ntanh\\n\\noutputs a 1-dim value followed by\\n\\nmultiplicative attention mechanism with parameter\\n\\nw\\n\\ndifferently, we may need to focus on some signals over others to refine its prediction. Therefore,\\n\\nCoVDS\\n\\nnot be important in some weeks). Moreover, because different models use signals from\\n\\nsignals may not very useful for current week's forecast (e.g., small revisions in mobility signals may\\n\\nPublished as a conference paper at ICLR 2022\\n\\nfrom B\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\n4 B\\n\\nACK\\n\\n2012).\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments were run in an Intel i7 4.8 GHz CPU with Nvidia Tesla A4 GPU. The model\\n\\nB2F . All experiments"}
{"id": "L01Nn_VJ9i", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We achieve substantial avg. improvements of 6.93% and 6.79% in MAE and MAPE respectively\\n\\nWe also found setting\\n\\nWe tuned the model hyperparameters using data from June 2020 to Aug. 2020 and tested it on the rest\\n\\nMAPE scores averaged over all regions from Jan 2021 to June 2021\\n\\nwith low standard deviation across 29 test weeks which shows that the improvements were consistent\\n\\n(une B2F-SEQ)\\n\\nTable 2: B2F\\n\\nGA, CT, MD). The improved predictions ofCMU-TS and GT-DC (ranked 3rd and 4th in COVID-19\\n\\nrefined by B2F show improvement of over 10% in over 25 states and over 15% in 5 states (NJ, LA,\\n\\nacross time and not just over few weeks that experienced large revision anomalies. Candidate models\\n\\nconsistent (Table 2). The poor scores of baselines also shows the necessity of\\n\\nstates. We observe that B2F is the only method, compared to baselines, that improves scores for\\n\\nWe compare the mean percentage improvement (decrease)\\n\\nRefining real-time model-predictions:\\n\\nfrom B\\n\\nmodel bias and only uses B\\n\\nmodel's prediction (d) B2F-N\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack2Future\\n\\nBack"}
{"id": "L01Nn_VJ9i", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B2F, due to B2F, outperform all the models in the hub (except for E\\\\textsuperscript{ENSEMBLE}) with 7.17\\\\% and 4.13\\\\% improvements in MAE respectively. UM\\\\textsuperscript{ASS}-MB, ranked 2nd, is improved by 11.24\\\\%. B2F also improves E\\\\textsuperscript{ENSEMBLE}, the current best-performing model of the hub, by 3.6\\\\% - 5.18\\\\% with over 5\\\\% improvement in 38 states, and with IL and TX experiencing over 15\\\\% improvement.\\n\\nFigure 6: (a) Average \\\\% decrease of MAE (b) \\\\% improve. in MAE for each week\\n\\nFigure 7: B2F rectified MAE are closer to stable MAE\\n\\nB2F adapts to anomalies During real-time forecasting, models need to be also robust to rare events of large anomalous data revisions, like during the initial stages of the pandemic when data collection was not fully streamlined. Consider observation week 5 where there was an abnormally large revision to deaths nationwide (Figure 8a) when the BE\\\\textsuperscript{RR} was 48\\\\%. B2F still provided significant improvements of up to 74.2\\\\% for most model predictions (Figure 8b).\\n\\nB2F refines GDP forecasts To evaluate the extensibility of B2F to other domains that encounter the problem of backfill, we tested on the task of forecasting US National GDP using 25 macroeconomic indicators from past and their revision history for years 2000-2021. We found that B2F improves predictions of candidate models by 6\\\\%-15\\\\% and significantly outperforms baselines. The details of the dataset and results are found in Appendix Sections B, E.2.\\n\\n5 CONCLUSION\\n\\nWe introduced the important and challenging multi-variate backfill problem using COVID-19 and GDP forecasting as examples. We compiled and released the comprehensive CoVDS dataset to study revision patterns in features and targets as well as aid in COVID-19 forecasting. We presented Back2Future (B2F), the novel deep-learning method to model this phenomenon, which exploits our observations of cross-signal similarities using Graph Recurrent Neural Networks to refine predictions and rectify evaluations for a wide range of models. Our extensive experiments showed that leveraging similarity among backfill patterns as well as model bias via our proposed method leads to significant 6 - 11\\\\% improvements in all the top models.\\n\\nAs future work, our work can potentially help improve data collection and alleviate systematic differences in reporting capabilities across regions. For example, B2F provides significant gains consistently across time including when there are large anomalies in data. Therefore, our revision modelling approach can be helpful for anomaly detection (Homayouni et al., 2021). We can also study how backfill can affect uncertainty calibration in time-series analysis (Yoon et al., 2020). Adapting to situations where data revisions can occur at different frequencies is another research direction.\"}"}
{"id": "L01Nn_VJ9i", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The features used in the CoVDS dataset and for GDP forecasting are publicly available and anonymized without any sensitive information. Our backfill refinement framework and B2F is generalizable to any domain that deals with real-time prediction tasks with feature revisions. Due to the relevance of our dataset to public health and macroeconomics, prospects for misuse should not be discounted. The disparities in data collection across features and regions can also have implications on equity of prediction performance and is an interesting direction of research.\\n\\nAs described in Section 4, we evaluated our model over 5 runs with different random seeds to show the statistical significance of our method. We also provide a more extensive description of hyperparameters and data pre-processing in the Appendix. The code for B2F and the CoVDS dataset is publicly available at https://github.com/AdityaLab/Back2Future.\\n\\nThis work was supported in part by the NSF (Expeditions CCF-1918770, CAREER IIS-2028586, RAPID IIS-2027862, Medium IIS-1955883, Medium IIS-2106961, CCF-2115126), CDC MInD program, ORNL, and faculty research awards from Facebook, funds/computing resources from Georgia Tech.\"}"}
