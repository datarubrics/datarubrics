{"id": "mfIX4QpsARJ", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"CylinderFlow: (Right) RMSE on velocity $V$ and pressure $P$ fields. (Left) Normalized RMSE over forecasting horizon. Our mesh transformer overcomes the baselines by a small margin. Yet qualitative results tends to indicate that Cylinder Flow is already a well mastered task.\\n\\nScalarFlow: (Right) RMSE on velocity $V$ and density $D$ fields. (Left) Normalized RMSE over forecasting horizon. Our model shows improvements over the baselines on both fields.\\n\\nEAGLE: (Right) RMSE on velocity $V$ and pressure $P$ fields. (Left) Normalized RMSE over forecasting horizon. Our model largely and consistently and reliably outperforms the competing baselines. While MeshGraphNet and DilResNet show comparable performances during first time-steps, our model succeeds to control error accumulation for reasonable horizons and eventually presents better simulations.\"}"}
{"id": "mfIX4QpsARJ", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 12: Examples of prediction forward in time on Cylinder-Flow\"}"}
{"id": "mfIX4QpsARJ", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mfIX4QpsARJ", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 14: Examples of prediction forward in time on EAGLE\"}"}
{"id": "mfIX4QpsARJ", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C.3 FAILURE CASE\\n\\nDespite the excellent performance of our model against competitive baselines, there is still room for improvement. Some more difficult configurations give rise to very turbulent flows, widely extended in the scene. The evolution of these flows is more difficult to predict and the models we evaluated failed to remain accurate. In these cases, the precision with which the small vortices are simulated is essential, because some of them will grow to become the majority.\\n\\nMoreover, our model suffers from an error accumulation problem, like any auto-regressive model. Experimentally, we observe that the airflow tends to be smoothed by deep learning models when the prediction horizon increases.\\n\\nFigure 15: We expose failure cases of our mesh transformer on Eagle. The error increases when the flow tends to intensify throughout the scene, and when turbulence dominates. Over a longer prediction horizon, the airflow tends to be smoother and less turbulent.\"}"}
{"id": "mfIX4QpsARJ", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Mesh down-sampling. We train our mesh transformer under different regimes of down-sampling by keeping a fixed percentage of points from the initial mesh and removing the others. We evaluate the resulting model on regimes different from training, and observe very little variation in N-RMSE among them.\\n\\nC.4 Generalization to Different Mesh Resolution\\n\\nIn EAGLE, the number of points varies from one simulation to another, forcing the model to generalize on meshes of different sizes. We explicitly demonstrate the performance of our mesh transformer on this task in Table 4. Four instances of the model are trained on a particular regime in which the simulation mesh is randomly down-sampled, respectively at 90%, 80%, 70%, and 60% of the initial mesh resolution. These models are then evaluated in a different regime from the one used for training, either higher (more points on average during testing than during training) or lower (fewer points in testing than in training). We show that our model generalizes well to these different regimes by giving relatively close N-RMSE measurements for a given down-sampling regime.\\n\\nD. Extension to 3D Fluid Simulation\\n\\nWhile we think that 3D simulations are indeed the long-term future on this subject, we argue that the complexity in factors of variation we need for large-scale machine learning is currently not possible in 3D simulations, and this has motivated our choice for a challenging 2D dataset. In this section, we discuss the possible extension of our dataset and the mesh transformer method to problems in three dimensions. We address two aspects: data generation itself, and the extension of the method.\\n\\nD.1 Data Generation\\n\\nFluids datasets in 3D are very limited, due to the computation time required for simulation. Mesh-based simulation in three dimensions greatly increases the number of points in the mesh, and thus exponentially increases the computing time (see numerical evidences in Kim (2019); Dantan et al. (2017)). Classical workarounds rely on relaxing physical accuracy or versatility of the solver, e.g. with SPH simulations. Accurate 3D simulations are mostly conducted on grid-based meshes, and for rather simple, theoretical problems (Mohan et al., 2020a; Chen et al., 2021b; Stachenfeld et al., 2021).\\n\\nThe John Hopkins Turbulent Database (Li et al., 2008) contains nine direct numerical simulation datasets (i.e. direct resolution of Navier-Stokes equations) but with only a single scene per dataset simulated on a very fine grid and low time resolution.\\n\\nTherefore, extending EAGLE to 3D simulations is very difficult without sacrificing one of the fundamental principles on which our dataset relies: (i) accuracy, guaranteed by the resolution of RANS equations with demanding turbulence model on a very fine mesh; (ii) irregular meshes, which are much more versatile and widespread in engineering; (iii) large scale, with nearly 1200 different scene configurations.\\n\\nD.2 Models and Methods\\n\\nForecasting models in the literature mostly focus on 2D simulations (Li et al., 2019; Kashefi et al., 2021; Han et al., 2022; Thuerey et al., 2020). To the best of our knowledge, there is no published work on large-scale machine learning models performing flow prediction on irregular 3D meshes. Therefore, publishing a 3D version of EAGLE seems premature, not to mention the difficulty of distributing such a dataset and training models on reasonable setups. For grid-based simulation on the other hand, few works leverage CNN-like structures for flow prediction (Stachenfeld et al., 2021; 2022).\"}"}
{"id": "mfIX4QpsARJ", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Mohan et al., 2020b; Fonda et al., 2019) or computer graphics (Wiewe et al., 2020); Chu & Thuerey (2017), yielding the limitations discussed in the main paper.\\n\\nHowever, we emphasize that GNN-based models are theoretically not restricted to 2D and can readily manage 3D simulations. The main challenge is the memory requirements to train graph neural networks on larger point-clouds. We argue that our mesh transformer is a step towards handling larger meshes by reducing the number of features using clustering.\"}"}
{"id": "mfIX4QpsARJ", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"EAGLE: LARGE-SCALE LEARNING OF TURBULENT FLUID DYNAMICS WITH MESH TRANSFORMERS\\n\\nSteeven Janny  \\nLIRIS, INSA Lyon, France  \\nsteeven.janny@insa-lyon.fr\\n\\nAur\u00e9lien B\u00e9neteau  \\nSupAero, France  \\naurelien.beneteau@student.isae-supaero.fr\\n\\nMadiha Nadri  \\nLAGEPP, Univ. Lyon 1, France  \\nmadiha.nadri-wolf@univ-lyon1.fr\\n\\nJulie Digne  \\nLIRIS, CNRS, France  \\njulie.digne@cnrs.fr\\n\\nNicolas Thome  \\nSorbonne University, CNRS, ISIR, Paris, France  \\nnicolas.thome@isir.upmc.fr\\n\\nChristian Wolf  \\nNaver Labs Europe, France  \\nchristian.wolf@naverlabs.com\\n\\nABSTRACT\\nEstimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variant strained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE, a large-scale dataset of \\\\( \\\\sim 1.1 \\\\) million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure, comprised of 600 different scenes of three different types. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE. Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single iteration.\\n\\n1 INTRODUCTION\\nDespite consistently being at the center of attention of mathematics and computational physics, solving the Navier-Stokes equations governing fluid mechanics remains an open problem. In the absence of an analytical solution, fluid simulations are obtained by spatially and temporally discretizing differential equations, for instance with the finite volume or finite elements method. These simulations are computationally intensive, take up to several weeks for complex problems and require expert configurations of numerical solvers.\\n\\nNeural network-based physics simulators may represent a convenient substitute in many ways. Beyond the expected speed gain, their differentiability would allow for direct optimization of fluid mechanics problems (airplane profiles, turbulence resistance, etc.), opening the way to replace traditional trial-and-error approaches. They would also be an alternative for solving complex PDEs where numerical resolution is intractable. Yet, the development of such models is slowed down by the difficulty of collecting data in sufficient quantities to reach generalization. Velocity and pressure field measurements on real world systems require large and expensive devices, and simulation faces the problems described above. For all these reasons, few datasets are freely available for training high-capacity neural networks, and the existing ones either address relatively simple problems which can be simulated in reasonable time and exhibiting very similar behaviors (2D flow on a cylinder, airfoil, etc.).\"}"}
{"id": "mfIX4QpsARJ", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: We introduce EAGLE, a large-scale dataset for learning complex fluid mechanics, accurately simulating the airflow created by a 2D drone in motion and interacting with scenes of varying 2D geometries. We address the problem through an autoregressive model and self-attention over tokens in a coarser resolution, allowing to integrate long-range dependencies as shown in the given example by the attention distributions for \u25fc, which follows the airflow. (Pfaff et al., 2021; Han et al., 2022) or simulations of very high precision, but limited to a few different samples only (Graham et al., 2016; Wu et al., 2017).\\n\\nIn this paper, we introduce EAGLE, a large-scale dataset for learning unsteady fluid mechanics. We accurately simulate the airflow produced by a two-dimensional unmanned aerial vehicle (UAV) moving in 2D environments with different boundary geometries. This choice has several benefits. It models the complex ground effect turbulence generated by the airflow of an UAV following a control law, and, up to our knowledge, is thus significantly more challenging than existing datasets. It leads to highly turbulent and non-periodic eddies, and high flow variety, as the different scene geometries generate completely different outcomes. At the same time, the restriction to a 2D scene (similar to existing datasets) makes the problem manageable and allows for large-scale amounts of simulations (~1.1m meshes). The dataset will be made publicly available upon publication.\\n\\nAs a second contribution, we propose a new multi-scale attention-based model, which circumvents the quadratic complexity of multi-head attention by projecting the mesh onto a learned coarser representation yielding fewer but more expressive nodes. Conversely to standard approaches based on graph neural networks, we show that our model dynamically adapts to the airflow in the scene by focusing attention not only locally, but also over larger distances. More importantly, attention for specific heads seems to align with the predicted airflow, providing evidence of the capacity of the model to integrate long-range dependencies in a single hop\u2014see Figure 1. We evaluate the method on several datasets and achieve state-of-the-art performance on two public fluid mechanics datasets (Cylinder-Flow, (Pfaff et al., 2021) and Scalar-Flow (Eckert et al., 2019)), and on EAGLE.\\n\\n2 RELATED WORK\\n\\nFluids datasets for deep learning\u2014 are challenging to produce in many ways. Real world measurement is complicated, requiring complex velocimetry devices (Wang et al., 2020; Discetti & Coletti, 2018; Erichson et al., 2020). Remarkably, (Eckert et al., 2019; De B\u00e9zenac et al., 2019) leverage alignment with numerical simulation to extrapolate precise GT flows on real-world phenomena (smoke clouds and sea surface temperature). Fortunately, accurate simulation data can be acquired through several solvers, ranging from computer graphics-oriented simulators (Takahashi et al., 2021; Pfaff & Thuerey, 2016) to accurate computational fluid dynamics solvers (OpenFOAM\u00a9, Ansys\u00a9 Fluent, ...). A large body of work (Chen et al., 2021a; Pfaff et al., 2021; Han et al., 2022; Stachenfeld et al., 2021; Pfaff et al., 2021) introduces synthetic datasets limited to simple tasks, such as 2D flow past a cylinder. EAGLE falls into this synthetic category, but differs in two main points: (a) simulations rely on hundreds of procedurally generated scene configurations, requiring several weeks of calculations on a high-performance computer, and (b) we used an engineer-grade fluid solver with demanding turbulence model and a fine domain discretization. For a comparison, see Table 1.\\n\\nLearning of fluid dynamics\u2014 is mainly addressed with message passing networks. Recent work focuses in particular on smoothed-particle hydrodynamics (SPH) (Shao et al., 2022; Ummenhofer et al., 2020; Shlomi et al., 2021; Li et al., 2019; Allen et al., 2022), somehow related to a Lagrangian representation of fluids. Sanchez-Gonzalez et al. (2020) proposes to chain graph neural networks in an Encode-Process-Decode pipeline to learn interactions between particles. SPH simulations are\"}"}
{"id": "mfIX4QpsARJ", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mfIX4QpsARJ", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mfIX4QpsARJ", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "mfIX4QpsARJ", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The EAGLE dataset is composed of exactly 1,184 simulations of 990 time-steps (33 seconds at 30 fps). Scene geometries are arranged in three categories based on the order of the interpolation used to generate the ground structure: 197 Step scenes, 199 Triangular and 196 Spline. A geometry gives two simulations depending on whether the drone is crossing the left or the right part of the scene. A proper train/valid/test splitting is provided ensuring that each geometry type is equally represented. The train split contains 948 simulations, while test and valid splits each contain 118 simulations.\\n\\nSimulation details \u2013 The scene is described as a $5m \\\\times 2.5m$ 2D surface. Wall boundary conditions (zero velocity) are applied to the frontiers, except for the top edge, which is an outlet (zero diffusion of flow variables). The propellers are modeled as two squares starting in the middle of the scene, with wall boundary conditions on the left, right and top edges, and inlet condition for the bottom edge (normal velocity of intensity proportional to the rotation speed of the propeller). We mesh the scene with triangular cells of an average size of $15mm$, and add inflation near wall boundaries. We let the simulator updates the mesh during time with default parameters.\\n\\nDronetrajectorycontrol \u2013 has received special care, and is obtained using model predictive control (MPC) of a dynamical model of a 2D drone allowing realistic trajectory tracking. The model is obtained by constraining the dynamics of a 3D drone model (Romero et al., 2022) to motion in a 2D plane and reducing the number of rotors to two. The drone can therefore move along the axis $x$ and $y$, and pivot around the $z$-axis perpendicular to the simulation plane as follows:\\n\\n$$\\n\\\\begin{align*}\\n\\\\ddot{x} &= -K_1 (\\\\Omega_2^1 + \\\\Omega_2^2) \\\\sin(\\\\theta) + K_2 (\\\\Omega_1^1 + \\\\Omega_1^2) \\\\\\\\\\n\\\\ddot{y} &= K_1 (\\\\Omega_2^1 + \\\\Omega_2^2) \\\\cos(\\\\theta) - g + K_2 (\\\\Omega_1^1 + \\\\Omega_1^2) \\\\\\\\\\n\\\\dot{\\\\theta} &= K_3 (\\\\Omega_2^2 - \\\\Omega_2^1),\\n\\\\end{align*}\\n$$\\n\\nwhere $x, y$ is the 2D position of the drone and $\\\\theta$ its orientation, $\\\\Omega_1$ and $\\\\Omega_2$ the left/right propeller rotations speed, $g = 9.81m/s$ is acceleration (gravity), and $K_1 = 10^{-4}$, $K_2 = 5 \\\\times 10^{-5}$, $K_3 = 5.5 \\\\times 10^{-3}$ are physical constants depending on drone geometry. The resulting trajectories represent physically plausible outcomes, taking into account inertia and gravity.\\n\\nMesh down-sampling \u2013 consists in simplifying the raw simulation data, as they are not suitable for direct deep learning applications, and require post-processing (see Figure 8a). The simulation software leverages a very fine-grained mesh dynamically updated in order to accurately solve the Navier-Stokes equations. The main step thus consists in simplifying the mesh to a reasonable number of nodes. Formally, our goal is to construct a new coarser mesh $(\\\\bar{\\\\mathbf{u}}(t), \\\\bar{\\\\mathbf{v}}(t))$ based upon the raw mesh proposed by the simulation software $(\\\\mathbf{u}(t), \\\\mathbf{v}(t))$. To cope with the dynamic nature of the simulation mesh, our approach consists in dividing the target node set into a static and a dynamic part $\\\\mathbf{u}(t) = \\\\mathbf{u} + \\\\mathbf{v}(t)$.\\n\\n\u2022 The static mesh is obtained by subsampling the simulation point cloud using Poisson Disk Sampling (Cook, 1986). However, the spatial density of $\\\\mathbf{u}(t)$ evolves over time (certain areas of space are more densely populated at the end of the simulation than at the start). To preserve finer resolution near relevant regions, we thus concatenated 5 regularly spaced point clouds $\\\\mathbf{u}(t_k)$ into a single set. We then sub-sample the resulting set by randomly selecting a point, and deleting all neighbors in a sphere of radius $R$ around the chosen point. This operation is repeated until no more point is at a distance less than $R$ from another. We used an adaptive radius $R$ correlated to the density map: when the original point cloud is dense, the radius is smaller. Conversely, the radius increases in sparse areas. An example of the density map is provided in Figure 8b.\\n\\n\u2022 The dynamic mesh is mandatory to track drone motion accurately. We therefore complete the static mesh with a dynamical part that follows the boundaries of the UAV. To do so, we used 14\"}"}
{"id": "mfIX4QpsARJ", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Qualitative comparisons with the state of the art on EAGLE. We color code the norm of the velocity field.\\n\\n| Dataset          | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |"}
{"id": "mfIX4QpsARJ", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Locality of reasoning. (a) velocity of an example flow and a selected point; (b) the receptive field for this point for the MeshGraphNet model (Pfaff et al., 2021) is restricted to a local neighborhood, also illustrated through the overlaid gradients. (c) the receptive field of our method covers the whole field and the gradients indicate that this liberty is exploited; (d) the attention distributions for point, certain maps correlate with airflow. Attention maps can be explored interactively using the online tool at https://eagle-dataset.github.io.\\n\\nDilResNet shows competitive performances on EAGLE, consistent with the claims of the original paper. However, it fails to predict details of the vortices (cf. Figure 4). This model leverages grid-based data, hence we are constrained on a voxel-level simulation, finally projected back on the triangular mesh during testing. This requires precaution in assessment. We try to limit projection error by setting images to contain ten times more pixels than nodes in the actual mesh. Yet, even at that scale, we measure that the reconstruction error represents roughly a third of the final N-RMSE. This points out that grid-based are not suited for complex fluid problems such as EAGLE, which require finer spatial resolution near sensitive areas. We expose failure cases in appendix C.3.\\n\\nAblation studies indicate how global attention impacts performance: (a) closer to MeshGraphNet, we replace the attention layers by GNNs operating on the coarser mesh, allowing message passing between nearest cluster only; (b) we limit the receptive field of MHA to the one-ring of the cluster;\"}"}
{"id": "mfIX4QpsARJ", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: Impact of cluster size. Left: We color code RMSE in logarithmic scale on the velocity field near a relatively turbulent area at a horizon of $h = 400$ steps of forecasting. Right: Error (+50), inference time and FLOPs for different cluster sizes and the baselines.\\n\\n| Model          | Ours | MGN |\\n|----------------|------|-----|\\n|                | Stp  | Spl | Tri |\\n|                | 0.927 | 0.865 | 1.132 |\\n|                | 0.828 | 2.062 | 1.236 |\\n|                | 0.595 | 0.584 | 0.857 |\\n|                | 0.488 | 1.257 | 0.941 |\\n|                | 0.730 | 0.732 | 1.049 |\\n|                | 0.647 | 1.685 | 1.100 |\\n\\nTable 3: Generalization to unseen geometries: we evaluate our model and MeshGraphNet in different setups, evaluating on all geometry types but removing one from training. Our model shows satisfactory generalization, also highlighting the complementarity of each simulation type.\\n\\nWe enforce uniform attention by replacing it with an average operation. As shown in table 6, attention is a key design choice. Disabling attention to distant points has a negative impact on RMSE, indicating that the model leverages efficient long-ranged dependencies. Agnostic attention to the entire scene is not pertinent either: to be effective, attention needs to dynamically adapt to the predicted airflow. We also conduct a study on generalization to down-sampled meshes in appendix C.4.\\n\\nThe role of clustering is to summarize a set of nodes into a unique feature vector. Arguably, with bigger clusters, more node-wise information must be aggregated in a finite dimensional vector. We indeed observe a slight increase in N-RMSE when the cluster size increases (Figure 7a). Nonetheless, our model appears to be robust to even aggressive graph clustering as the drop remains limited and still outperforms the baselines. A qualitative illustration is shown figure 7 (left), where we simulate the flow up to 400 time-steps forward and observe the error on a relatively turbulent region.\\n\\nClustering also acts on the complexity of our model by reducing the number of tokens on which attention is computed. We measure a significant decrease in inference time and number of operations (FLOPs) even when we limit clusters to a small size (Figure 7b and c).\\n\\nGeneralization experiments highlight the complementarity of the geometry types in EAGLE, since the removal of one geometry in the training set impacts the performances on the others. MeshGraphNet suffers the most, resulting in a drop ranging from 10% in average (ablation of Spline) to 67% (ablation of Step). On our model, the performance losses are limited for the ablation of Step and Spline. The most challenging geometry is arguably Triangular, as the ground profile tends to generate more turbulent and convoluted flows.\\n\\nConclusion:\\nWe presented a new large-scaledataset for deep learning in fluid mechanics. EAGLE contains accurate simulations of the turbulent airflow generated by a flying drone in different scenes. Simulations are unsteady, highly turbulent and defined on dynamic meshes, which represents a real challenge for existing models. To the best of our knowledge, we released the first publicly available dataset of this scale, complexity, precision and variety. We proposed a new model leveraging mesh transformers to efficiently capture long distance dependencies on a coarser scale. Through graph pooling, we show that our model reduces the complexity of multi-head attention and outperforms the competing state-of-the-art on, both, existing datasets and EAGLE. We showed across various ablations and illustration that global attention is a key design choice and observed that the model naturally attends to airflow. Future work will investigate the impact of implicit representations on fluid mechanics, and we discuss the possibility of an extension to 3D data in appendix D.\\n\\nAcknowledgements: We recognize support through French grants \\\"Delicio\\\" (ANR-19-CE23-0006) of call CE23 \\\"Intelligence Artificielle\\\" and \\\"Remember\\\" (ANR-20-CHIA0018), of call \\\"Chaires IA hors centres\\\".\"}"}
{"id": "mfIX4QpsARJ", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Kelsey R. Allen, Tatiana Lopez-Guevara, Kimberly Stachenfeld, Alvaro Sanchez-Gonzalez, Peter Battaglia, Jessica Hamrick, and Tobias Pfaff. Physical design using differentiable learned simulators. In arXiv, 2022.\\n\\nPeter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interaction networks for learning about objects, relations and physics. In Neural Information Processing Systems (NeurIPS), 2016.\\n\\nP.W. Battaglia, J.B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V.F. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner, \u00c7. G\u00fcl\u00e7ehre, F. Song, A.J. Ballard, J. Gilmer, G.E. Dahl, A.V. Vaswani, K. Allen, C. Nash, V/L Langston, C. Dyer, N. Heess, D. Wierstra, P. Kohli, M. Botvinick, O. Vinyals, Y. Li, and R. Pascanu. Relational inductive biases, deep learning, and graph networks. In arXiv:1807.09244, 2018.\\n\\nMichael M. Bronstein, Joan Bruna, Taco Cohen, and Petar Veli\u010dkovi\u0107. Geometric deep learning: Grids, groups, graphs, geodesics, and gauges, 2021.\\n\\nJ. Chen, E. Hachem, and J. Viquerat. Graph neural networks for laminar flow prediction around random two-dimensional shapes. In Physics of Fluids, 2021a.\\n\\nShengyu Chen, Shervin Sammak, Peyman Givi, Joseph P Yurko, and Xiaowei Jia. Reconstructing high-resolution turbulent flows using physics-guided neural networks. In International Conference on Big Data (Big Data), 2021b.\\n\\nKyunghyun Cho, Bart van Merrienboer, \u00c7aglar G\u00fcl\u00e7ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP, 2014.\\n\\nMengyu Chu and Nils Thuerey. Data-driven synthesis of smoke flows with CNN-based feature descriptors. In ACM Transactions on Graphics (TOG), 36(4):1\u201314, 2017.\\n\\nRobert L. Cook. Stochastic sampling in computer graphics. ACM Trans. Graph., 1986. URL https://doi.org/10.1145/7529.8927.\\n\\nJean-Yves Dantan, Zhicheng Huang, Edoh Goka, Lazhar Homri, Alain Etienne, Nicolas Bonnet, and Mickael Rivette. Geometrical variations management for additive manufactured product. In CIRP Annals - Manufacturing Technology, 2017.\\n\\nEmmanuel De B\u00e9zenac, Arthur Pajot, and Patrick Gallinari. Deep learning for physical processes: Incorporating prior scientific knowledge. In Statistical Mechanics: Theory and Experiment, 2019.\\n\\nStefano Discetti and Filippo Coletti. Volumetric velocimetry for fluid flows. In Measurement Science and Technology, 2018.\\n\\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representation (ICLR), 2021.\\n\\nMarie-Lena Eckert, Kiwon Um, and Nils Thuerey. Scalarflow: A large-scale volumetric data set of real-world scalar transport flows for computer animation and machine learning. In Transactions on Graphics (TOG), 2019.\\n\\nN. Benjamin Erichson, Lionel Mathelin, Zhewei Yao, Steven L Brunton, Michael W Mahoney, and J. Nathan Kutz. Shallow neural networks for fluid flow reconstruction with limited sensors. In Royal Society A, 2020.\\n\\nEnrico Fonda, Ambrish Pandey, J\u00f6rg Schumacher, and Katepalli R Sreenivasan. Deep learning in turbulent convection networks. In National Academy of Sciences, 2019.\\n\\nS. Geman and D. Geman. Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. In IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6):721\u2013741, 1984.\"}"}
{"id": "mfIX4QpsARJ", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 8: (a) sample of raw simulation measurements obtained on a high resolution mesh. This single snapshot contains 158,961 nodes. (b) example of node density map controlling the sampling disk radius. The raw mesh is more dense near the boundaries and on the left side, as this sample is taken from a simulation where the drone explores the left region of the scene. (c) Mesh simulation at final resolution. We drastically simplified the mesh while maintaining a satisfactory level of details.\\n\\nThe ground truth trajectory to track drone position and orientation across time and extrapolate bounding boxes, which are then transformed into point clouds by sub-dividing the box into several points.\\n\\nFinally, the edge set $E'(t)$ is computed using constrained Delaunay triangulation to prevent triangles to spawn outside of the domain. Once $(\\\\mu'(t), E'(t))$ has been computed, we evaluate the pressure and velocity field $\\\\Pi(t), \\\\varphi(t)$ on the nodes by averaging the three nearest points in raw simulation data. We illustrate the final result in figure 8c. Better mesh simplification algorithms exist, notably minimizing the interpolation error, yet such algorithms rely on the simulated flow to compute the mesh, which may embed unwanted biases or shortcuts in the mesh geometry.\\n\\nA.2 GRID BASED DATASET\\n\\nOne of the baselines, DilResNet (Stachenfeld et al., 2021), relies on convolutional layers for future forecasting of turbulent flows, and therefore requires projecting EAGLE and Cylinder-Flow on a uniform rectangular grid. However, such a discretization scheme cannot adapt its spatial resolution as a function of the geometry of the scene, which therefore constitutes a disadvantage with respect to an irregular triangular mesh. To limit this effect, the resolution of the grid is chosen such that the number of pixels is at least ten times larger than the number of points in the triangular mesh.\\n\\nWe project Cylinder-Flow onto a uniform $256 \\\\times 64$ grid and EAGLE onto a $256 \\\\times 128$ grid (the dimensions were chosen to respect the height-width ratio of the original data). The value of the pressure and velocity fields at each point in the grid is extrapolated from the nearest point in the raw simulated data. We illustrate this projection in figure 9. While the grid-based simulation (figure 9b) seems visually more accurate than the mesh-based simulation (figure 9d), we observed that the re-projection error (i.e., the error obtained after projecting the grid-based data onto the triangular mesh) is greater near sensible regions, as for example near the scene boundaries.\\n\\nB MODEL DETAILS\\n\\nB.1 CLUSTERING\\n\\nWe use our own implementation of the same size K-means algorithm described here. Using equally sized clusters has two main advantages:\\n\\n---\\n\\n2 https://elki-project.github.io/tutorial/same-size_k_means\"}"}
{"id": "mfIX4QpsARJ", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: Illustration of the pixellisation process. The left column (a and b) shows snapshots of simulations from the grid-based datasets, used to train DilResNet. For comparison, we show the same snapshots in the mesh-based datasets (c and d). While resolution seems better on grid-based simulation, it lacks precision near sensible region, which are primordial for accurate forecasts.\\n\\n\u2022 Areas of high density will be covered by a greater number of clusters, allowing the adaptive resolution of irregular meshes to be preserved on the coarser mesh.\\n\u2022 The model can be implemented efficiently, maximizing parallelization, since clusters can be easily stored as batched tensors.\\n\\nSince the clustering depends solely on the geometric properties of the mesh (and not on the prediction of the neural network), it is possible to apply the clustering algorithm as a pre-processing step to reduce the computational burden during training. Note that since the mesh is dynamic, so are the clusters: the \\\\( k \\\\) cluster at time \\\\( t \\\\) will not necessarily contain the same points at time \\\\( t + 1 \\\\).\\n\\nB.2 ARCHITECTURE AND TRAINING DETAILS\\n\\nWe kept the same training setup for all datasets and trained our model for 10,000 steps with the Adam optimizer and a learning rate of \\\\( 10^{-4} \\\\) to minimize equation 6 with \\\\( \\\\alpha = 10^{-1} \\\\) and \\\\( H = 8 \\\\). Velocity and pressure are normalized with statistics computed on the train set, except for Scalar-Flow, where better results are obtained without normalization.\\n\\nEncoder \u2013 \\\\( \\\\phi_{\\\\text{node}} \\\\) and \\\\( \\\\phi_{\\\\text{edge}} \\\\) are one-layer MLPs with ReLU activations, hidden size and output size of 128 (\\\\( (\\\\eta_i, e_{ij}) \\\\in \\\\mathbb{R}^{128} \\\\)). We used \\\\( L = 4 \\\\) chained graph neural network layers composed of two identical MLPs \\\\( \\\\phi_{\\\\text{edge}} \\\\) and \\\\( \\\\phi_{\\\\text{node}} \\\\) with two hidden layers of dimension 128, ReLU activated, followed by layer normalization. The positional encoding function \\\\( F \\\\) is defined as follows:\\n\\n\\\\[\\nF(x) = [\\\\cos(2i\\\\pi x), \\\\sin(2i\\\\pi x)] \\\\quad i = -3, ..., 3\\n\\\\]\\n\\nwhere \\\\( x \\\\) is a 2D vector modeling the position of node \\\\( i \\\\).\\n\\nGraph Pooling \u2013 we used a single layer gated recurrent unit with hidden size of dimension \\\\( W \\\\) followed by a single layer MLP with hidden and output size of \\\\( W \\\\). This step produces a cluster feature representation \\\\( w_k \\\\in \\\\mathbb{R}^W \\\\). For Cylinder-Flow and EAGLE, \\\\( W = 512 \\\\). For Scalar-Flow, \\\\( W = 128 \\\\).\"}"}
{"id": "mfIX4QpsARJ", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Attentional module \u2013 Following (Xiong et al., 2020) an attention block is defined as follows for an input \\\\( w \\\\in \\\\mathbb{R}^W \\\\):\\n\\n\\\\[\\n\\\\begin{align*}\\n    w_1 &= LN(w) | \\\\overline{f}(\\\\overline{x}_k) \\\\\\\\\\n    w_2 &= MHA(w_1, w_1, w_1) \\\\\\\\\\n    w_3 &= w_1 + Linear(w_2) \\\\\\\\\\n    w_4 &= LN(w_3) \\\\\\\\\\n    w_5 &= MLP(w_4) \\\\\\\\\\n    w_6 &= w_3 + w_5\\n\\\\end{align*}\\n\\\\]\\n\\nwhere LN are layer norm functions, Linear is linear function (with bias), MHA is multi-head attention and MLP is a multi-layer perceptron with one hidden layer of size \\\\( W \\\\).\\n\\nWe denote the barycenter of cluster \\\\( k \\\\) as \\\\( \\\\overline{x}_k \\\\). We used \\\\( M = 4 \\\\) chained attention block, with four attention head each. The last attention layer is followed by a final layer norm.\\n\\nDecoder \u2013 The decoder takes as input the node embeddings \\\\( \\\\eta_i \\\\), the cluster features updated by the attentional module \\\\( w_M \\\\) and then node-wise positional encoding \\\\( f_i \\\\). We applied a graph neural network composed of two identical MLP (two hidden layers with hidden size of 128, ReLU activated and layer norm). The resulting node embeddings are fed to a final MLP with two hidden layers and hidden size of 128, with TanH as activation function.\\n\\nB.3 BSELINES TRAINING DETAILS\\n\\nAfter performing a grid search to select the best options, we found that training each baseline to minimize equation 6 with Adam optimizer and learning rate of \\\\( 10^{-4} \\\\) produces best results. We vary the weighting factor \\\\( \\\\alpha \\\\) to maintain balance between pressure and velocity. For Cylinder-Flow and EAGLE, we trained the baselines over \\\\( H = 5 \\\\) time-steps. For Scalar-Flow, we set \\\\( H = 20 \\\\).\\n\\nMeshGraphNet \u2013 we performed grid search over the number of GNN layers to fit to each dataset, but best results were obtained with the recommended depth \\\\( L = 15 \\\\) for each dataset. Conversely to what is suggested in Pfaff et al. (2021), we found that training MeshGraphNet over a longer horizon improves the general performances. We used our own implementation of the baseline and make sure to reproduce the results presented in the main paper (for Cylinder-Flow only). We get the best trade-off between velocity and pressure with \\\\( \\\\alpha = 10 \\\\).\\n\\nGAT \u2013 we performed a grid-search over the number of heads per layer and the number of layers. Best results were obtained for 10 layers of graph attention transformer and two attention heads per layer (except for Cylinder-Flow, where four heads slightly improves the performances).\\n\\nDilResNet \u2013 we found that increasing the number of blocks improves overall performance, setting the number of convolutional blocks from 4 to 20.\\n\\nThe baselines are structurally built to predict pressure field \\\\( \\\\hat{\\\\pi}'(t + h) \\\\) and velocity field \\\\( \\\\hat{\\\\gamma}'(t + h) \\\\) described on the mesh geometry at current time \\\\( \\\\pi(t) \\\\). Auto-regressive forecasting on a longer horizon thus requires interpolation of the predicted flow to the (provided) future mesh \\\\( \\\\pi(t + h) \\\\). We do not want interpolation to disturb our problem of interest, which is turbulent flow prediction. Therefore, we made the interpolation from \\\\( \\\\pi(t) \\\\) to time \\\\( \\\\pi(t + 1) \\\\) straightforward. As the vast majority of the mesh remains static (see previous section), only the nodes linked to the UAV need to be interpolated. Since they can readily be associated in a one-to-one relation, nearest point interpolation can be performed automatically by assigning \\\\( \\\\hat{\\\\gamma}'(t + h) \\\\) at these points to \\\\( \\\\hat{\\\\gamma}(t + h) \\\\).\\n\\nC.1 DETAILS METRICS\\n\\nFormally, we used the following metrics to report our results on the test set \\\\( \\\\pi \\\\):\\n\\n\\\\[\\nN-RMSE = \\\\frac{1}{H} \\\\sum_{t=1}^{H} \\\\frac{1}{|\\\\pi|} \\\\left( \\\\| v(t) - \\\\hat{v}(t) \\\\|_2 + \\\\| p(t) - \\\\hat{p}(t) \\\\|_2 \\\\right)\\n\\\\]\\n\\nC.2 RESULTS\"}"}
{"id": "mfIX4QpsARJ", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 10: The maps show the k-number computed for each cluster, that is, the number of nodes required to reach 90% of the attention. A low k-number indicates a very specialized head (attending to few nodes), while a high k-number indicates uniform attention.\\n\\nwhere $\\\\tilde{v}$ and $\\\\tilde{p}$ are standard deviation of velocity and pressure field computed on the train set. Detailed metric \u2013 raw root mean squared error (RMSE) on each field is reported in figure 11 as well as temporal evolution of N-RMSE across prediction horizon. On Cylinder-Flow (Figure 11a), velocity error is very similar between MeshGraphNet and ours. Our model slightly outperforms the baseline on the pressure field, yielding overall better performances. However, temporal evolution of the N-RMSE indicated that both models converge to the same accuracy for very long roll-out prediction. On EAGLE, our model shows excellent stability over long horizon, and produces accurate velocity and pressure estimates.\\n\\nK-number \u2013 is a property which can be calculated for attention maps, and which consists in the number of tokens required to reach 90% of attention (Kervadec et al., 2021). This property can be used to characterize the shape of attention maps, varying from peaky attention (requiring few tokens to reach 90%) to more uniform attention heads. We show k-numbers in Figure 10. Interestingly, the k-number maps can be compared with attention maps figure 5d: peaky heads (in blue) are correlated with relatively local attention maps, and conversely, more uniform heads (in red) correspond to attention maps focusing on larger distances, often following the airflow. Some heads have different behavior depending on the selected cluster, and are peaky in some areas (mainly around the boundaries of scene), but more uniform elsewhere. These cues support the importance of global attention in our model.\"}"}
{"id": "mfIX4QpsARJ", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Dataset            | Size  | Public | Dyn. | Scene | Dyn. | Mesh  | # nodes | # of meas. | # of meas. | Purpose |\\n|-------------------|-------|--------|------|-------|------|-------|---------|------------|------------|---------|\\n| CylinderFlow      | 15Gb  | \u2713      | \u2717    | \u2717     | \u2713    | \u2717     | 1,885   | 0.72M      |            |         |\\n| Pfaff et al. (2021)| AirFoil | 56Gb  |  \u2713   | \u2717    | \u2717    |       | 5,233   | 0.72M      |            |         |\\n| KS Equation       | N.A   | \u2717      | \u2717    | \u2717     | \u2713    | \u2717     | 64      | 1,200      | 2,304      |         |\\n| Incomp. Dec.      |       |        |      |       |      |       |         |            | 3,204      |         |\\n| Comp. Dec.        |       |        |      |       |      |       |         |            | 3,204      |         |\\n| Stachenfeld et al. (2021) | Rad. Cooling | 32,768 |  \u2713   | \u2717    | \u2717    | \u2713     | 3,204   | 0.1M       |            |         |\\n| Han et al. (2022)  | Vascular Flow | N.A.  |  \u2713   | \u2717    | \u2717    | \u2713     | 7,561   | 5,250      |            |         |\\n| Eckert et al. (2019)| 351Gb | \u2713      | \u2717    | \u2717     | \u2713    | \u2717     | 1.7M    | 0.015M     |            |         |\\n| De B\u00e9zenac et al. (2019) | SST | \u2713      | \u2717    | \u2717     | \u2713    | \u2717     | 4,096   | 0.1M       |            |         |\\n| EAGLE             | 270Gb | \u2713      | \u2713    | \u2713     | \u2713    | \u2713     | 3,388   | 1.18M      |            |         |\\n\\nTable 1: Fluid mechanics datasets in the literature. To the best of our knowledge, EAGLE is the first dataset of such scale, complexity and variety. Smaller-scale datasets such as Li et al. (2008); Wu et al. (2017) have been excluded, as they favor simulation accuracy over size. The datasets in Stachenfeld et al. (2021) are not public, but can be reproduced from the information in the paper.\\n\\nIn fluid mechanics, Eulerian representations are more regularly used, where the flow of quantities are studied on fixed spatial cells. The proximity to images makes uniform grids appealing, which lead to the usage of convolutional networks for simulation and learning (De B\u00e9zenac et al., 2019; Ravuri et al., 2021; Ren et al., 2022; Liu et al., 2022; Le Guen & Thome, 2020). For instance, Stachenfeld et al. (2021) takes the principles introduced in Sanchez-Gonzalez et al. (2020) applied to uniform grids for the prediction of turbulent phenomena. However, uniform grids suffer from limitations that hinder their generalized use: they adapt poorly to complex geometries, especially strongly curved spatial domains and their spatial resolution is fixed, requiring a large number of cells for a given precision.\\n\\nDeep Learning on non-uniform meshes are a convenient way of solving the issues raised by uniform grids. Nodes can then be sparser in some areas and denser in areas of interest. Graph networks (Battaglia et al., 2016) are well suited for this type of structure. The task was notably introduced in Pfaff et al. (2021) with MeshGraphNet, an Encode-Process-Decode pipeline solving mesh-based physics problems. (Lienen & G\u00fcnnemann, 2022) introduced a graph network structure algorithmically aligned with the finite element method and show good performances on several public datasets. Close to our work, Han et al. (2022) leverages temporal attention mechanism on a coarser mesh to enhance forecasting accuracy over longer horizon. In contrast, our model is based on a spatial transformer, allowing a node to communicate not only with its neighbors but also over greater distances by dynamically adapting attention to the airflow.\\n\\nEAGLE is comprised of fine-grained fluid simulations defined on irregular triangle meshes, which we argue is more suited to a broad range of applications than regular grids and thus more representative of industrial standards. Compared to grid-based datasets De B\u00e9zenac et al. (2019); Stachenfeld et al. (2021), irregular meshes provide better control over the spatial resolution, allowing for finer discretization near sensitive areas. This property is clearly established for most fluid mechanics solvers (Versteeg & Malalasekera, 2007) and seems to transfer well to simulators based on machine learning (Pfaff et al. (2021)). However, using triangular meshes with neural networks is not as straightforward as regular grids. Geometric deep learning (Bronstein et al., 2021) and graph networks (Battaglia et al., 2018) have established known baselines but this remains an active domain of research. Existing datasets focus on well-studied tasks such as the flow past an object (Chen et al., 2021a; Pfaff et al., 2021) or turbulent flow on an airfoil (Thuerey et al., 2020; Sekar et al., 2019). These are well-studied problems, for some of which analytical solutions exist, and they rely on a large body of work from the physics community. However, the generated flows, while being turbulent, are merely steady or periodic despite variations in the geometry. With EAGLE, we propose a complex task, with convoluted, unsteady and turbulent air flow with minimal resemblance across each simulation.\\n\\n3 T\\n\\nTHE EAGLE DATASET AND BENCHMARK\\n\\nPurpose \u2013 we built EAGLE in order to meet a growing need for a fluid mechanics dataset in accordance with the methods used in engineering, i.e. reasoning on irregular meshes. To significantly increase the complexity of the simulations compared to existing datasets, we propose a proxy task consisting in studying the airflow produced by a dynamically moving UAV in many scenes with...\"}"}
{"id": "mfIX4QpsARJ", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Velocity field norm over time for three episodes, one for each geometry type. Turbulence is significantly different from one simulation to another and strongly depends on the ground surface. This is motivated by the highly non-steady turbulent outcomes that this task generates, yielding challenging airflow to be forecasted. Particular attention has also been paid to the practical usability of EAGLE with respect to the state-of-the-art in future forecasting of fluid dynamics by controlling the number of mesh points, and limiting confounders variables to a moderate amount (i.e. scene geometry and drone trajectory).\\n\\nSimulation and task definition \u2013 we simulate the complex airflow generated by a 2D unmanned aerial vehicle maneuvering in 2D scenes with varying floor profiles. While the scene geometry varies, the UAV trajectory is constant: the UAV starts in the center of the scene and navigates, hovering near the floor surface. During the flight, the two propellers generate high-paced airflows interacting with each other and with the structure of the scene, causing convoluted turbulence. To produce a wide variety of different outcomes, we procedurally generate a large number of floor profiles by interpolating a set of randomly sampled points within a certain range. The choice of interpolation order induces drastically different floor profiles, and therefore distinct outcomes from one simulation to another.\\n\\nEAGLE contains three main types of geometry depending on the type of interpolation (see Figure 2):\\n\\n(i) Step: surface points are connected using step functions (zero-order interpolation), which produces very stiff angles with drastic changes of the airflow when the UAV hovers over a step.\\n\\n(ii) Triangular: surface points are connected using linear functions (first-order interpolation), causing the appearance of many small vortices at different locations in the scene.\\n\\n(iii) Spline: surface points are connected using spline functions with smooth boundaries, causing long and fast trails of air, occasionally generating complex vortices.\\n\\nEAGLE contains about 600 different geometries (200 geometries of each type) corresponding to roughly 1,200 flight simulations (one geometry gives two flight simulations depending on whether the drone is going to the right or to the left of the scene), performed at 30 fps over 33 seconds, resulting in 990 time steps per simulation. Physically plausible UAV trajectories are obtained through MPC control of a (flow agnostic) dynamical system we design for a 2D drone. More details and statistics are available in appendix A.\\n\\nWe simulated the temporal evolution of the velocity field as well as the pressure field (both static and dynamic) defined over the entire domain. Due to source motion, the triangle mesh on which these fields are defined need to be dynamically adapted to the evolving scene geometry. More formally, the mesh is a valued dynamical graph \\\\( \\\\mathcal{G} = (\\\\mathcal{V}, \\\\mathcal{E}, \\\\mathcal{U}, \\\\mathcal{P}) \\\\) where \\\\( \\\\mathcal{V} \\\\) is the set of nodes, \\\\( \\\\mathcal{E} \\\\) the edges, \\\\( \\\\mathcal{U} \\\\) is a field of velocity vectors and \\\\( \\\\mathcal{P} \\\\) is a field of scalar pressure values. Both physical quantities are expressed at node level. Note that the dynamical mesh is completely flow-agnostic, thus no information about the flow can be extrapolated directly from the future node positions. Time dependency will be omitted when possible for sake of readability.\\n\\nNumerical simulations \u2013 were carried out using the software Ansys \\\\( \\\\text{\u00a9} \\\\) Fluent, which solves the Reynolds Averaged Navier-Stokes equations of the Reynolds stress model. It uses five equations to model turbulence, more accurate than standard \\\\( k-\\\\epsilon \\\\) or \\\\( k-\\\\omega \\\\) models (two equations). This resulted in...\"}"}
{"id": "mfIX4QpsARJ", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: The mesh transformer encodes the input mesh node values (positions, pressure and velocity), reduces the spatial resolution through clustering + graph pooling, and performs multi-head self-attention on the coarser level of cluster centers. A decoder upsamples the token embeddings to the original resolution and predicts pressure and velocity at time step $t+1$.\\n\\n3.9TB of raw data with $\\\\sim 162,760$ control points per mesh. We downsampled this to 3,388 points on average, and compressed it to 270GB. Details and illustrations are given in appendix A.\\n\\nTask \u2013 for what follows, we define $x_i$ as the 2D position of node $i$, $v_i$ its velocity, $p_i$ pressure and $n_i$ is the node type, which indicates if the node belongs to a wall, an input or an output boundary. We are interested in the following task: given the complete simulation state at time $t$, namely $\\\\mathcal{U}_t$, as well as future mesh geometry $\\\\mathcal{U}_{t+h}$, $\\\\mathcal{V}_{t+h}$, forecast the future velocity and pressure fields $\\\\hat{v}_{t+h,i}, \\\\hat{p}_{t+h,i}$, i.e. for all positions $i$ we predict $\\\\hat{v}_{t+h,i}, \\\\hat{p}_{t+h,i}$ over a horizon $h$. Importantly, we consider the dynamical remeshing step $\\\\mathcal{V}_t \\\\rightarrow \\\\mathcal{V}_{t+h}$ to be known during inference and thus is not required to be forecasted.\\n\\n4 Learning Unsteady Airflow\\n\\nAccurate flow estimations require data on a certain minimum spatial and temporal scale. Deviations from optimal resolutions, i.e. data sampled with lower spatial resolutions or lower frame rates, are typically very hard to compensate through models of higher complexity, in particular when the estimation is carried out through numerical simulations with an analytical model. The premise of our work is that machine learning can compensate loss in resolution by picking up longer rate regularities in the data, trading data resolution for complexity in the modeled interactions. Predicting the outcome for a given mesh position may therefore require information from a larger neighborhood, whose size can depend on factors like resolution, compressibility, Reynolds number etc.\\n\\nRegularities and interactions on meshes and graphs have classically been modeled with probabilistic graphical models (MRFs (Geman & Geman, 1984), CRFs (Lafferty et al., 2001), RBMs (Smolensky, 1986) etc.), and in the DL era through geometric DL (Bronstein et al., 2021) and graph networks (Battaglia et al., 2018), or through deep energy-based models. These models can capture long-range dependencies between distant nodes, but need to exploit them through multiple iterations. In this work we argue for the benefits of transformers and self-attention Vaswani et al. (2017), which in principle are capable of integrating long-range interactions in a single step.\\n\\nHowever, the quadratic complexity of transformers in terms of number of tokens makes its direct application to large meshes expensive. While low-complexity variants do exist, e.g. (Katharopoulos et al., 2020), we propose a different Ansatz, shown in Figure 3: we propose to combine graph clustering and learned graph pooling to perform full attention on a coarser scale with higher-dimensional node embedding. This allows the dot-product similarity of the transformer model\u2014 which is at the heart of the crucial attention operations\u2014to operate on a semantic representation instead of on raw input signals, similar to the settings in other applications. In NLP, attention typically operates on word embeddings Vaswani et al. (2017), and in vision either on patch embeddings Dosovitskiy et al. (2021) or on convolutional feature map cells Wang et al. (2018). In the sequel, we present the main modules of our model; further details are given in appendix B.\\n\\nOffline Clustering \u2013 we down-scale mesh resolution through geometric clustering, which is independent of the forecasting operations and therefore pre-computed offline. A modified k-means clustering is applied to the vertices $\\\\mathcal{U}_t$ of each time step and creates clusters with a constant number of nodes, details are given in appendix B.1. The advantages are twofold: (a) the irregularity and adaptive resolution of the original mesh is preserved, as high density region will require more clusters, and (b)\"}"}
{"id": "mfIX4QpsARJ", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"constant cluster sizes facilitate parallelization and allow to speed up computations. In what follows, let $\\\\mathcal{Y}_k$ be the $k$-th cluster computed on mesh $\\\\mathcal{Y}_t$.\\n\\nEncoder \u2013 the initial mesh $\\\\mathcal{Y}_t$ is converted into a graph $\\\\mathcal{G}$ using the encoder in Pfaff et al. (2021). More precisely, node and edge features are computed using MLPs $\\\\phi_{\\\\text{node}}$ and $\\\\phi_{\\\\text{edge}}$, giving\\n\\n$$\\\\eta_1(i) = \\\\phi_{\\\\text{node}}(v_i, p_i, n_i),$$\\n\\n$$e_1(ij) = \\\\phi_{\\\\text{edge}}(x_i - x_j, \\\\|x_i - x_j\\\\|).$$\\n\\n(1)\\n\\nThe encoder also computes an appropriate positional encoding based on spectral projection $F(x)$.\\n\\nWe also average the local position of each node in its cluster. Let $\\\\bar{x}_k$ be the barycenter of cluster $\\\\mathcal{Y}_k$, then the local encoding of node $i$ belonging to cluster $k$ is the concatenation $f_i = [F(x_i) F(\\\\bar{x}_k - x_i)]^T$.\\n\\nFinally, a series of $L$ Graph Neural Networks (GNN) extracts local features through message passing:\\n\\n$$e_{l+1}(ij) = e_{l}(ij) + \\\\phi_{\\\\text{edge}}([\\\\eta_{l}(i) f_i], [\\\\eta_{l}(j) f_j], e_{l}(ij)),$$\\n\\n$$e_{l+1}(i) = \\\\eta_{l}(i) + \\\\phi_{\\\\text{node}}([\\\\eta_{l}(i) f_i], \\\\sum_j e_{l}(ij)).$$\\n\\n(2)\\n\\nThe superscript $l$ indicates the layer, and $\\\\phi_{\\\\text{node}}$ and $\\\\phi_{\\\\text{edge}}$ are MLPs which encode nodes and edges, respectively. The exact architecture hyper-parameters are given in appendix B. For the sake of readability, in what follows, we will note $\\\\eta_i = \\\\eta_L(i)$ and $e_{ij} = e_L(ij)$.\\n\\nGraph Pooling \u2013 summarizes the state of the nodes of the same cluster $\\\\mathcal{Y}_k$ in a single high-dimensional embedding $w_k$ on which the main neural processor will reason. This is performed with a Gated Recurrent Unit (GRU) Cho et al. (2014) where the individual nodes are integrated sequentially in a random order. This allows learning a more complex integration of features than a sum. Given an initial GRU state $h_0 = 0$, node embeddings are integrated iteratively, indicated by superscript $n$,\\n\\n$$h_{n+1}(k) = \\\\text{GRU}([\\\\eta_i f_i], h_{n}(k)), i \\\\in \\\\mathcal{Y}_k, w_k = \\\\phi_{\\\\text{cluster}}(h_N),$$\\n\\n(3)\\n\\nwhere $N = |\\\\mathcal{Y}_k|$ and $\\\\phi_{\\\\text{cluster}}$ is an MLP. GRU($\\\\cdot$) denotes the update equations of a GRU, where we omitted gating functions from the notation. The resulting set of cluster embeddings $\\\\mathcal{W} = \\\\{w_k | k = 1..K\\\\}$ significantly reduces the spatial complexity of the mesh.\\n\\nAttention Module \u2013 consists of a transformer with $M$ layers of multi-head attention (MHA) Vaswani et al. (2017) working on the embeddings $\\\\mathcal{W}$ of the coarse graph. Setting $w_1(k) = w_k$, we get for layer $m$:\\n\\n$$w_{m+1}(k) = \\\\text{MHA}(Q = [w_m(k) F(\\\\bar{x}_k)], K = \\\\mathcal{W}, V = \\\\mathcal{W}),$$\\n\\n(4)\\n\\nwhere $Q, K$ and $V$ are, respectively, the query, key and value mappings of a transformer. We refer to Vaswani et al. (2017) for the details of multi-head attention, denoted as MHA($\\\\cdot$).\\n\\nDecoder \u2013 the output of the attention module is calculated on the coarse scale, one embedding per cluster. The decoder upsamples the representation and outputs the future pressure and velocity field on the original mesh. This upsampling is done by taking the original node embedding $\\\\eta_i$ and concatenating with the cluster embedding $w_M(k)$, followed by the application of a GNN, whose role is to take the information produced on a coarser level and correctly distribute it over the nodes $i$. To this end, the GNN has access to the positional encoding of the node, which is also concatenated:\\n\\n$$\\\\hat{v}_{t+1} = v_t + \\\\delta v,$$\\n\\n$$\\\\hat{p}_{t+1} = p_t + \\\\delta p,$$\\n\\n$$(\\\\delta v, \\\\delta p) = \\\\text{GNN}([\\\\eta_i w_M(k)]),$$\\n\\n(5)\\n\\nwhere $i \\\\in \\\\mathcal{Y}_k$ and GNN($\\\\cdot$) is the graph network variant described in equation (2), parameters are not shared. Our model is trained end-to-end, minimizing the forecasting error over horizon $H$ where $\\\\alpha$ balances the importance of pressure field over velocity field:\\n\\n$$\\\\mathcal{E} = H \\\\sum_i \\\\text{MSE}(v(t+i), \\\\hat{v}(t+i)) + \\\\alpha H \\\\sum_i \\\\text{MSE}(p(t+i), \\\\hat{p}(t+i)).$$\\n\\n(6)\\n\\n5 EXPERIMENTS\\n\\nWe compare our method against three competing methods for physical reasoning: MeshGraphNet (Pfaff et al., 2021) (MGN) is a Graph Neural Network based model that relies on multiple chained message passing layers. GAT is based upon MGN where the GNNs interactions are replaced by\"}"}
