{"id": "5XrQ2mskPQz", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Matrix factorization is a popular method to investigate the hidden elements in observed data for tasks such as speech separation and muscle synergy analysis. The hidden elements may be closely related to the source phenomenon that cause the observed phenomenon. However, conventional methods do not always factorize the observed phenomenon elements with the connectivity between the observed and source phenomena because they only use the observed phenomenon. This paper proposes a matrix decomposition method that constrains the connectivity between observed and source data by using the representations from a decoding model from source data to observed data. The proposed method factorizes matrices by extracting and combining representations and weights from the regression model in the regression process. We applied our method to the corticomuscular system, which is made up of corticospinal pathways between the primary motor cortex and muscles in the body and creates muscle synergies that enable efficient connections between the brain and muscles. In this context, muscle activities are the observed phenomenon and brain activities are the source. Many previous studies have analyzed muscle synergies using only observed muscle activity, but there may be unrevealed muscle synergies under the constraint of the connectivity between brain and muscle activity. We therefore simultaneously recorded the brain activity from multiple regions of an extensive cortical area and the activity of multiple muscles of a monkey's forelimb while it performed a reach and grasp task throughout the course of recovery from a partial spinal cord injury (SCI). Analysis from a dataset of the monkey before SCI showed that some of the muscle synergies calculated from the proposed method using brain and muscle activities, did not exhibit a high degree of similarity to synergies obtained from the conventional method. The proposed method results obtained from the monkey after SCI showed an adaptive change in the number of muscle synergies associated with the degree of functional recovery. Specifically, the numbers of muscle synergies obtained by the proposed method initially increased immediately after SCI and then gradually decreased, while those obtained by a conventional method maintained the same number before and after SCI. These results suggest that our method is able to capture the unrevealed connectivity in the corticomuscular system that contributes to functional recovery: in other words, that it can factorize the observed data under the constraint of the connectivity between the observed and source data. Our work thus demonstrates the importance of using not only observed data but also source data to reveal unknown hidden elements.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nnomena. For example, a specific speech sound can be extracted from a sound containing a mixture of multiple sounds (Smaragdis, 2007), the appropriate recommendation can be calculated from a customer's purchase history (Li et al., 2006), and muscle synergies can be extracted from multiple muscle activities (Shourijeh et al., 2016).\\n\\nIn some cases, the observed phenomenon is caused by a functional connection with the source phenomenon. This connectivity is a functional connection that causes an observed phenomenon from a source phenomenon, and the factors of connectivity include such as human connections and anatomical connections. In the case of muscle synergy analysis, the corticospinal pathways between the primary motor cortex and muscles function as a corticomuscular system (Liu et al., 2019), and cortical events normally propagate to the peripheral muscles. Studies on humans and monkeys have reported that brain and muscle activity are closely associated with cortico-motoneuronal connections (Lemon, 2008; Baldissera & Cavallari, 1993; Lemon & Griffiths, 2005). In this case, muscle activities are the observed phenomenon and brain activities are the source. The corticomuscular system enables us to perform complex body movements by neurologically combining sets of simpler movements. These sets are observed as the basic pattern of muscle activity, namely, muscle synergies. Muscle activity can be observed by using electromyography (EMG), a technique that reveals bioelectric potential signals. Since the framework of conventional matrix factorization uses only observed data to factorize observed data, it might not factorize the observed phenomenon elements with the connectivity between the observed and source phenomena.\\n\\nWe have therefore developed a method to capture the elements in the observed data by considering the connectivity between both the observed data and the source data. Our basic idea is to use the representations in a deep neural network (DNN) model to predict the observed data from the source data. In this paper, we assume both source and observed data can be measured. Specifically, the factorized matrices can function as an activation scalar value and a vector of weights for the observed data at each sample. We can then obtain the factorized matrix under the connectivity constraints between the observed and source data by extracting these values.\\n\\nIn this paper, we report the results of applying the proposed method to muscle synergy analysis. As stated earlier, the corticomuscular system is composed of corticospinal pathways between the primary motor cortex and muscles (Liu et al., 2019), and we can consider the muscle activities as observed data and the brain activities as source data. To obtain brain activities closely related to muscle activity, we simultaneously measured a monkey\u2019s brain signals using both electrocorticography (ECoG) and electromyography (EMG). We measured the muscle and brain activities of a monkey before and after partial spinal cord injury to investigate the potential of the proposed method under the conditions of a stable and a dynamically changing nervous system.\\n\\nOur main contributions are as follows.\\n\\n\u2022 We show a novel matrix factorization framework under the constraint of connectivity between both observed data and source data, in contrast to the conventional approach that uses only observed data.\\n\\n\u2022 We propose a method that utilizes a model representation to predict the observed data from the source data as a factorization matrix.\\n\\n\u2022 We demonstrate the potential of the proposed method to capture unrevealed matrix factors by applying it to muscle synergy analysis with a comparison to the non-negative matrix approach.\\n\\n2 RELATED WORKS\\n\\nMatrix Factorization in Statistics:\\n\\nOne approach taken in statistics is to factorize the data by extracting the components that best represent the variation in the data. Principal component analysis (PCA) is typically used for this, where the dimensionality-reduced data representation is a factorized matrix (Lee & Seung, 1999). Another approach is to separate independent components by assuming that the data contains multiple data originating from independent sources. Independent component analysis (ICA) separates signals by independence on the basis of higher-order statistics or temporal correlations (Comon, 1994). The fast fixed-point algorithm for independent component analysis (FastICA) was proposed as a method to improve the convergence of ICA (Hyv\u00e4rinen & Oja, 2000). Non-negative matrix factorization (NMF) factorizes the matrix and restricts it to be positive.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "5XrQ2mskPQz", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nSilk Smita, Sharmila Biswas, and Sandeep Solanki. Audio signal separation and classification: A review paper. 3297, 12 2007.\\n\\nHyun Ah Song, Bo-Kyeong Kim, Thanh Luong Xuan, and Soo-Young Lee. Hierarchical feature extraction by multi-layer non-negative matrix factorization network for classification task. Neurocomputing, 165:63\u201374, 2015. ISSN 0925-2312. doi: https://doi.org/10.1016/j.neucom.2014.08.095. URL https://www.sciencedirect.com/science/article/pii/S0925231215004580.\\n\\nKatherine Steele, Matthew Tresch, and Eric Perreault. The number and choice of muscles impact the results of muscle synergy analyses. Frontiers in Computational Neuroscience, 7, 2013. ISSN 1662-5188. doi: 10.3389/fncom.2013.00105. URL https://www.frontiersin.org/articles/10.3389/fncom.2013.00105.\\n\\nJ\u00e1nos Szalai and Ferenc Emil Mozes. Determining fetal heart rate using independent component analysis. In 2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP), pp. 11\u201316, 2014. doi: 10.1109/ICCP.2014.6936973.\\n\\nGeorge Trigeorgis, Konstantinos Bousmalis, Stefanos Zafeiriou, and Bj\u00f6rn W. Schuller. A deep semi-nmf model for learning hidden representations. In Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, ICML'14, pp. II\u20131692\u2013II\u20131700. JMLR.org, 2014.\\n\\nJianyu Wang and Xiao-Lei Zhang. Deep NMF topic modeling. CoRR, abs/2102.12998, 2021. URL https://arxiv.org/abs/2102.12998.\\n\\nYu-Xiong Wang and Yu-Jin Zhang. Nonnegative matrix factorization: A comprehensive review. IEEE Transactions on Knowledge and Data Engineering, 25(6):1336\u20131353, 2013. doi: 10.1109/TKDE.2012.51.\\n\\nHong-Jian Xue, Xin-Yu Dai, Jianbing Zhang, Shujian Huang, and Jiajun Chen. Deep matrix factorization models for recommender systems. In Proceedings of the 26th International Joint Conference on Artificial Intelligence, IJCAI'17, pp. 3203\u20133209. AAAI Press, 2017. ISBN 9780999241103. doi: 10.1145/3269206.3271697. URL https://doi.org/10.1145/3269206.3271697.\\n\\nA Appendix A.1 Ethics\\nAll animal experimental procedures were performed in accordance with the guidelines of the National Institute of Health and the Ministry of Education, Culture, Sports, Science, and Technology of Japan, and were approved by the Institutional Animal Care and Use Committee of the Tokyo Metropolitan Institute of Medical Science (Approval No. 18034). The monkey was monitored closely, and animal welfare was assessed daily or, if necessary, several times a day.\\n\\nA.2 EEG and EMG Signals\\nWe implanted a 15-channel grid electrode array in which the diameter of each electrode was 1 mm and the inter-electrode distance was 5 mm (Unique Medical, Japan) beneath the dura mater. To implant the grid electrode array on the cortical surface over the sensorimotor cortex, the cortices around the arcuate sulcus and the central sulcus on the right side were exposed by a craniotomy. As to the muscle activity, electrodes were implanted in 14 muscles of the left forelimb: three elbow muscles [triceps brachii (TRI), biceps brachii (BB), brachialis (BR)], five wrist muscles [extensor carpi radialis (ECR), extensor carpi ulnaris (ECU), flexor carpi radialis (FCR), flexor carpi ulnaris (FCU),...\"}"}
{"id": "5XrQ2mskPQz", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Palmaris longus (PL), five digit muscles [extensor digitorum communis (EDC), extensor digiti-rum 4,5 (ED45), flexor digitorum superficialis (FDS), flexor digitorum profundus (FDP), abductor pollicis longus (APL)], and one intrinsic hand muscle [adductor pollicis (ADP)]. ECoG and EMG signals were recorded simultaneously using a CerebusTM data acquisition system (BLACKROCK MICROSYSTEMS, Utah, USA) at a sampling rate of 2,000 Hz.\\n\\nA.3 Behavior Task\\nThe monkey performed the task of reaching and grasping for a piece of food multiple times in one experimental day. On each day, the decision to perform the measurement experiment and the number of trials were determined on the basis of the monkey's condition. In total, we conducted the measurement experiment for 41 days. Each recording session consisted of approximately 100 trials.\\n\\nA.4 VAF Calculation\\nVariance accounted for (VAF) is a metric of the degree of reconstruction. This calculation uses true value vectors $y_m = [y_{m1}, \\\\ldots, y_{mT}]$, $m \\\\in \\\\{1, \\\\ldots, 14\\\\}$ and reconstructed vectors $\\\\hat{y}_m = [\\\\hat{y}_{m1}, \\\\ldots, \\\\hat{y}_{mT}]$, $m \\\\in \\\\{1, \\\\ldots, 14\\\\}$, where $m$ is the number of measure muscles. The VAF is calculated as following\\n\\n$$VAF = 1 - \\\\frac{\\\\sum_{m=1}^{14} \\\\text{Var}(y_m - \\\\hat{y}_m)}{\\\\sum_{m=1}^{14} \\\\text{Var}(y_m)},$$\\n\\n(6)\\n\\nwhere $\\\\text{Var}(y_m - \\\\hat{y}_m)$ is the variance of $y_m - \\\\hat{y}_m$, the square of the standard deviation. $\\\\text{Var}(y_m)$ is the variance of $y_m$.\\\\text{\\\\textcopyright}13\"}"}
{"id": "5XrQ2mskPQz", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\ntory\\nty = [y\u2081, ..., y\u2081\u2084]\\n\\nand the output is also supposed to be y\u209c without changing the architecture as following\\n\\n\\\\[ \\\\hat{y}_t = r \\\\sum_{i=1}^{M} (y_t) \\\\] (5)\\n\\nWe used data from a one-day experiment that included 90 trials in the intact state (no neurological disorders). In the proposed method, the number of filters \\\\( c \\\\) of the temporal convolutional networks in the activation layer is a key parameter to determine the potential of synergy acquisition. Thus, we experimentally tested eight types of filters here: [1, 1], [2, 2], [4, 4], [8, 8], [16, 16], [32, 32], [64, 64], and [128, 128]. The vector length of the number of filters is the number of dilations in the temporal convolutional network, which is two in all eight types. For example, in the case of [8, 8], the first \\\\( \\\\uparrow 8 \\\\downarrow \\\\) is the number of filters at the first dilation, and the second \\\\( \\\\uparrow 8 \\\\downarrow \\\\) is the number of filters for the second dilation.\\n\\nFigure 3 shows the V AF results of the proposed method (eight different numbers of filters) and NMF by increasing the synergy number for the same data. Most of the V AF results calculated by the proposed method increased with the synergy number, as did those of NMF. The dashed horizontal line indicates a V AF of 0.9, which determines the muscle synergy number. For the same number of muscle synergies, V AF tended to be higher for a larger number of filters. By confirming that V AF increases with increasing the number of synergies, we verified the possibility that the proposed method can analyze muscle synergies.\\n\\n4.3 NUMBER OF FILTERS\\n\\nFigure 4: Muscle synergy analysis by factorization using brain and muscle activities in the proposed method.\\n\\nWe also tested whether the proposed method can acquire muscle synergy under connectivity constraints between brain and muscle activity. Fig. 4 shows the V AF per muscle synergy number for the proposed method and NMF. Most of the proposed method\u2019s V AF values increased with the number of muscle synergies not depending on the number of filters. The higher number of filters tended to make V AF higher. We can see that the determined number of muscle synergies, where V AF exceeds 0.9 at first, depends on the number of filters. At the numbers of filters [32, 32] and [64, 64], the determined number of muscle synergies is eight. At the number of filters [128, 128], the determined number of muscle synergies is six. Defining the number of filters depends on how the muscle synergies are used. To compare the components of muscle synergies from the proposed method and NMF, we set the number of filters to [32, 32], which is the minimum number of filters when the number of muscle synergies is eight.\\n\\n4.4 COMPARISON OF MUSCLE SYNERGY COMPONENTS\\n\\nWe examined whether the proposed method can capture the unrevealed muscle synergy components that are difficult for the conventional approach to extract. As a muscle synergy component, a vector of weights and activations is obtained from a muscle synergy. A, B, and C in Fig. 5 respectively indicate the eight components from the proposed method using only EMG, NMF, and the proposed method using ECoG and EMG. The left panels in the figure show the weight of the muscles of each synergy, while the right panels show the activation of each synergy, which is calculated by averaging all trials. To compare the similarity of each component, we calculate the similarity matrix. D in Fig. 5 shows the similarity matrix using the weights from these three approaches. The upper panel in D shows the similarity matrix of the weights between the proposed method (only using EMG) and the NMF method, while the lower panel in D shows that between the proposed method and NMF. The similarity matrix of the weights from the proposed method (only using EMG) and NMF method is presented in the upper panel of D, while the lower panel of D shows the similarity matrix between the proposed method and NMF.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5:\\n\\nWeights and activations of muscle synergy components from the proposed method (using only EMG), NMF (using only EMG), and the proposed method (using EMG and ECoG). Using only EMG data, the similarity of almost all components of muscle synergy was close to 1, meaning that they were all identical for the proposed and NMF methods. The averaged computation times of the proposed method (basically using GPU: NVIDIA RTX3090) and NMF (CPU: AMD Ryzen Threadripper 3970X) are 6209.3 sec and 12.0 sec, respectively. The computational complexity of the proposed method is higher than that of the NMF. The low similarity of synergies of 6 in both the proposed method (using only EMG) and NMF may have been due to the high degree of freedom of activation in the proposed method. As a result, synergies 4 and 7 of the proposed method represent the corresponding synergies in NMF, while also representing synergy 6 in NMF by the cooperative activation of the two synergies. It may be possible to solve this problem by setting a constraint term such that the activation acts independently between the synergies.\\n\\nSome of the similarities between the proposed components (using ECoG and EMG) and NMF did not exhibit a high degree of similarity. For example, the similarities of the proposed method\u2019s synergy 1 and 2 to synergy 1 in NMF were 0.76 and 0.82, respectively. The results indicate that the proposed method separates synergy 1 of NMF into two synergies. These separated components may be the result of capturing the connectivity between brain and muscle activities. The same can be said for synergy 2 and 3 of the proposed method.\\n\\n4.5 A\\n\\nDAPTIVE CHANGE ANALYSIS\\n\\nWe next investigated whether the proposed method can capture the adaptive change of muscle synergy components during nervous recovery. First, brain and muscle activity was measured from an intact (no neurological disorders) monkey. Then, we performed partial SCI surgery on the monkey and measured its activity for 30 days (not every day) after the surgery. We explored the number of components of each of the experiment days in the proposed and NMF methods.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6 shows the number of components (upper panel) and task precision (lower panel) in each day. We can see the precisions during the intact period were almost 100\\\\%, then moved to nearly 0\\\\% for a month after the surgery, and then improved to around 80\\\\% after three months. These results suggest that the monkey performed the task before the surgery based on the pathways between the brain and muscles acquired so far. Immediately after the partial SCI surgery, it was difficult for the monkey to use the pathways because many of the previously acquired pathways were disconnected and it was more difficult to move the upper limb. The monkey regained the function to perform the task by adaptively changing the pathways using the residual nervous connections, and improved the precision of the task. The numbers of components of the proposed and NMF methods are plotted in red and blue lines, respectively. The days dashed in red (proposed) are days where muscle synergy was not calculated below 14 (the number of measured muscles).\\n\\nThe numbers of components of NMF\u2019s muscle synergy were stable both before and after SCI (Fig. 6). While those of the proposed method were similar during the intact period, they exceeded 14 about a month after the surgery and then gradually decreased and converged around three months after the surgery. We presume that the number of components increased immediately after the surgery because the monkey could not use the pathways obtained so far, and had to use the residual pathways (not sophisticated). The number of components decreases and converges in the adaptive change of the nervous system, so the transition of the proposed method\u2019s results might be explainable from the neurological point of view. This result indicates that the proposed method can potentially be used to analyze muscle synergy with adaptive nervous change, which is difficult to extract in the conventional approach.\\n\\nConclusion\\nIn this paper, we proposed a matrix factorization method under the constraint of connectivity between observed and source data. The core idea of our method is to use the representation in a model that predicts the observed data from the source data as a factored matrix. Applying the proposed method to muscle synergy analysis using a monkey\u2019s brain and muscle activities demonstrated its potential to reveal unknown muscle synergy components, which are difficult for the conventional approach to capture. Specifically, the proposed method\u2019s transitions of the number of components after partial SCI surgery indicated the adaptive changes in the corticomuscular system. Through two analysis experiments, we demonstrated the importance of using not only observed data but also source data to extract the elements hidden in observed data, and showed that the proposed method\u2019s potential to capture these hidden elements.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional\\nand recurrent networks for sequence modeling, 2018. URL https://arxiv.org/abs/1803.01271.\\n\\nF Baldissera and P Cavallari. Short-latency subliminal effects of transcranial magnetic stimulation\\non forearm motoneurones. Experimental brain research, 96(3):513\u2013518, 1993.\\n\\nJean-Philippe Brunet, Pablo Tamayo, Todd R. Golub, and Jill P. Mesirov. Metagenes and molecular\\npattern discovery using matrix factorization. Proceedings of the National Academy of Sciences,\\n101(12):4164\u20134169, 2004. doi: 10.1073/pnas.0308531101. URL https://www.pnas.org/doi/abs/10.1073/pnas.0308531101.\\n\\nJoshua C Chang, Patrick Fletcher, Jungmin Han, Ted L Chang, Shashaank Vattikuti, Bart Desmet,\\nAyah Zirikly, and Carson C Chow. Sparse encoding for more-interpretable feature-selecting rep-\\nresentations in probabilistic matrix factorization. In International Conference on Learning Rep-\\nresentations, 2021. URL https://openreview.net/forum?id=D_KeYoqCYC.\\n\\nJen-Tzung Chien and Bo-Cheng Chen. A new independent component analysis for speech recog-\\nnition and separation. IEEE Transactions on Audio, Speech, and Language Processing,\\n14(4):1245\u20131254, 2006. doi: 10.1109/TSA.2005.858061.\\n\\nStacie Chvatal and Lena Ting. Common muscle synergies for balance and walking. Frontiers in\\nComputational Neuroscience, 7, 2013. ISSN 1662-5188. doi: 10.3389/fncom.2013.00048. URL\\nhttps://www.frontiersin.org/articles/10.3389/fncom.2013.00048.\\n\\nPierre Comon. Independent component analysis, a new concept? Signal Processing, 36(3):287\u2013314,\\n1994. ISSN 0165-1684. doi: https://doi.org/10.1016/0165-1684(94)90029-9. URL https://www.sciencedirect.com/science/article/pii/0165168494900299. Higher\\nOrder Statistics.\\n\\nIoannis Delis, Bastien Berret, Thierry Pozzo, and Stefano Panzeri. Quantitative evaluation of mus-\\ncle synergy models: a single-trial task decoding approach. Frontiers in Computational Neuro-\\nscience, 7, 2013. ISSN 1662-5188. doi: 10.3389/fncom.2013.00008. URL https://www.frontiersin.org/articles/10.3389/fncom.2013.00008.\\n\\nKarthik Devarajan. Nonnegative matrix factorization: An analytical and interpretive tool in compu-\\ntational biology. PLOS Computational Biology, 4(7):1\u201312, 07 2008. doi: 10.1371/journal.pcbi.1000029. URL https://doi.org/10.1371/journal.pcbi.1000029.\\n\\nJulien Fr `ere and Franc \u00b8ois Hug. Between-subject variability of muscle synergies during a com-\\nplex motor skill. Frontiers in Computational Neuroscience, 6, 2012. ISSN 1662-5188. doi:\\n10.3389/fncom.2012.00099. URL https://www.frontiersin.org/articles/10.3389/fncom.2012.00099.\\n\\nKai Gui and Dingguo Zhang. Influence of locomotion speed on biomechanical subtask and muscle\\nsynergy. Journal of Electromyography and Kinesiology, 30:209\u2013215, 2016. ISSN 1050-6411.\\ndoi: https://doi.org/10.1016/j.jelekin.2016.07.010. URL https://www.sciencedirect.com/science/article/pii/S1050641116301122.\\n\\nWatanabe Hidenori, Sato Masa-aki, Suzuki Takafumi, Nambu Atsushi, Nishimura Yukio, Kawato\\nMitsuo, and Isa Tadashi. Reconstruction of movement-related intracortical activity from micro-\\nelectrocorticogram array signals in monkey primary motor cortex. Journal of Neural Engineering,\\n9(3):036006, 05 2012. ISSN 1741-2560. doi: 10.1088/1741-2560/9/3/036006. URL https://cir.nii.ac.jp/crid/1360004234437506176.\\n\\nFranc \u00b8ois Hug, Nicolas A. Turpin, Arnaud Gu \u00b4evel, and Sylvain Dorel. Is interindividual variability\\nof emg patterns in trained cyclists related to different muscle synergies? Journal of Applied\\nPhysiology, 108(6):1727\u20131736, 2010. doi: 10.1152/japplphysiol.01305.2009. URL https://doi.org/10.1152/japplphysiol.01305.2009. PMID: 20299611.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023 (Lee & Seung, 2000; Wang & Zhang, 2013). Since the real-world events we observe are often composed of linear sums of non-negative values, they have a high affinity with NMF analysis, so it has accordingly been used in a variety of applications (Rajapakse & Wyse, 2003; Smaragdis, 2007; Shourijeh et al., 2016). One study on muscle synergy analysis showed that NMF is the most popular method for analysis (Rabbi et al., 2020). However, these methods factorize the observed data using only the observed data.\\n\\nDeep Matrix Factorization: The deep matrix factorization approach has shown promise in studies that focus on interpretability. Several methods to improve the interpretability by using representations in an autoencoder process as multi-factorized matrices have been proposed (Ye et al., 2018; Song et al., 2015; Wang & Zhang, 2021). To ensure meaning in the multilayered factor matrix, Trigeorgis et al. (2014) proposed a method that pre-trains each layered factor matrix to represent elements such as facial pose, expressions, and identity. Sparseness is also essential to capture the essence of the data. Chang et al. (2021) proposed making the factorized matrix sparse in not only decoding but also encoding. One concept similar to our own is the use of implicit feedback (e.g., purchase history and unobserved ratings) in recommendation systems (Xue et al., 2017). While we feel that such feedback can contribute to improving accuracy, it is not the same as a source phenomenon. And technically, there are few approaches for matrix factorization to use both parameters in the regression process and the weights inside the model.\\n\\nApplications: There are a variety of general applications of the matrix factorization approach. In the biological field, metagenes and molecular pattern discovery have been studied by applying NMF (Brunet et al., 2004; Devarajan, 2008). In the engineering field, image processing tasks such as face recognition (Rajapakse & Wyse, 2003), acoustic processing (e.g., speech-music separation) (Smita et al., 2007), and speech separation (Chien & Chen, 2006) have been studied. As for medical applications, fetal heart rate determination has been explored (Szalai & Mozes, 2014). In the kinematics and kinetics field, muscle synergy analysis is a significant application of matrix factorization (Shourijeh et al., 2016). Matrix factorization has also been applied to community structure detection (e.g., social networks, collaboration networks, and citation networks) to study interaction (Ye et al., 2018).\\n\\n3 Matrix Factorization Under Constraints Between Observed and Source Data\\n\\nSuppose that the observed data are arranged as a matrix $Y = [y_1, \\\\ldots, y_T]^T \\\\in \\\\mathbb{R}^{n \\\\times T}$, which is $n$ channels sampled $T$ times in time series. The observed vector at time $t$ represents $y_t = [y_1, y_2, \\\\ldots, y_n]$. The goal of the proposed method is to approximately factorize the observed data as $Y \\\\approx VU$. (1)\\n\\nwhere $V = [v_1, \\\\ldots, v_r]^T \\\\in \\\\mathbb{R}^{n \\\\times r}$ and $U = [u_1, \\\\ldots, u_r] \\\\in \\\\mathbb{R}^{r \\\\times T}$ are the factor matrices to reconstruct the matrix $Y$, and $r$ is the number of factorized components. Suppose the source data is the $m$ channels sampled $T$ times in time series, and the source data at time $t$ is represented as the matrix $X_t = [x_{(1:t)}, \\\\ldots, x_{(m:t)}] \\\\in \\\\mathbb{R}^{m \\\\times T}$, which is $m$ channels sampled $T$ times in time series.\\n\\nConsidering the time difference ($\\\\tau$) between observed and source data, the vector of source data at time $t$ consists of data from time $t$ to $t - \\\\tau$. The $i$-th source data vector at time $t$ is $x_{(i,t)} = [x_{(i,t)}, x_{(i,t-1)}, x_{(i,t-2)}, \\\\ldots, x_{(i,t-\\\\tau)}]$.\\n\\nThe basic idea underlying the factorization of matrices under constraints between observed and source data is to factor matrices from a model that includes connectivity constraints between observed and source data. We obtain this model by constructing a DNN prediction model from the source data to the observed data, where the factorized vectors $v$ and $u$ can be assigned as the weight for each channel of observed data and the activation for the weights, respectively.\\n\\n3.1 Framework and Architecture\\n\\nWe designed a regression model $M$ that computes the observed data $y_t$ from the source data $X_t$.\\n\\nAs shown in the Fig. 1, the representation in the model is designed to contain activation (scalar) and weights (vector).\"}"}
{"id": "5XrQ2mskPQz", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023\\n\\nFigure 1: Network architecture of proposed method. Activation \\\\( u_t \\\\) is obtained from the Sigmoid layer. Vector \\\\( v \\\\) is obtained from the weights in the Linear layer.\\n\\nIt is not only the source data that contributes to the factorization at time \\\\( t \\\\); data over a certain time range up to \\\\( t \\\\) is also considered to be involved in some cases. Temporal convolutional networks (TCN) have outperformed recurrent networks such as LSTM and GRU (Bai et al., 2018) for handling multi-channel time-series data and have been applied to gesture recognition using muscle activity (Rahimian et al., 2021; 2022). Inspired by such research, we utilize TCN to incorporate the time-series features in our method.\\n\\n**TCNet**: We implement TCNet as the TCN in the regression model to capture the features from sequence data. As in (Bai et al., 2018; Rahimian et al., 2021; 2022), the TCNet layer consists of a sequence of TBlock layers, as shown in Fig. 2.\\n\\n![Figure 2: Architecture of temporal convolutional network.](image)\\n\\nThe TBlock is the dilated causal convolution, with the dilation factor exponentially increased (1, 2, 4, ...) and the number of filters \\\\( c \\\\) and the kernel size \\\\( k \\\\). Each TBlock consists of two repeated sequences consisting of extended causal convolutions (\\\"DCconv\\\"), weight norm, ReLU and Dropout, and finally a residual connection.\\n\\nThe parameters for TCNet are the number of filters \\\\( c \\\\), the kernel size \\\\( k \\\\), and the number of dilations \\\\( d \\\\). When \\\\( d \\\\) is set to three, the dilation of TBlock is 1, 2, and 4 sequentially. This layer outputs a matrix \\\\( \\\\mathbf{R}^{(c \\\\times r)} \\\\) to Mean for each input data \\\\( X_t \\\\).\\n\\n**Mean, Scalarization, and Sigmoid layers**: We designed these layers so that the captured features from TCNet would have a positive scalar value (activation \\\\( u_t \\\\)). The Mean layer calculates a vector \\\\( \\\\mathbf{R}^c \\\\) by averaging each filter's result. The Scalarization layer is a linear layer to calculate a scalar value from a vector. The Sigmoid layer is set to keep the computed scalar value \\\\( u_t \\\\) within a positive range. This scalar value \\\\( u_t \\\\) is calculated at each time by sliding the window of the source data.\\n\\n**Linear layer**: The Linear layer inputs a positive scalar value and calculates the reconstructed observed vector \\\\( \\\\hat{y}_t = [\\\\hat{y}_1, \\\\hat{y}_2, \\\\ldots, \\\\hat{y}_n] \\\\) as\\n\\n\\\\[\\n\\\\hat{y}_t = u_t \\\\mathbf{w},\\n\\\\]\\n\\nwhere \\\\( \\\\mathbf{w} = [w_1, w_2, \\\\ldots, w_n] \\\\) is the weight for each element of an observed vector. When acquiring a vector of non-negative weights, the weights are clipped so that they are between 0 and 1 during training.\\n\\n### 3.2 MATRIX FACTORIZATION THROUGH REGRESSION CALCULATIONS\\n\\nFirst, the regression model \\\\( M \\\\) is trained using \\\\( X_t \\\\) and \\\\( y_t \\\\in (1, \\\\ldots, T) \\\\). Similar to the previous approach (Shourijeh et al., 2016; Rajapakse & Wyse, 2003), the proposed matrix factorization is verified by the restoration degree of the observed data, so there is no need to separate source and observed data into training and test data. The regression model \\\\( M \\\\) predicts the observed data \\\\( y_t \\\\) from the source data \\\\( X_t \\\\) as \\\\( M(X_t) \\\\).\\n\\nAn activation \\\\( u_t \\\\) is obtained from the representation (scalar) from the layer of Sigmoid, and a weights vector \\\\( v \\\\) is obtained by extracting the weights at the Linear.\"}"}
{"id": "5XrQ2mskPQz", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"under review as a conference paper at ICLR 2023\\n\\n\\\\(X_t\\\\) is a sample extracted from the time series source data with a \\\\(\\\\tau\\\\)-width time window. When the window locates at \\\\(t = 1\\\\), \\\\(X_1\\\\) is extracted from the time series source data. Regression model \\\\(M\\\\) inputs \\\\(X_1\\\\) and outputs \\\\(y_1\\\\), and \\\\(u_1\\\\) is obtained from this calculation process. By sliding the window, regression model \\\\(M\\\\) inputs \\\\(X_t, t \\\\in (1, \\\\ldots, T)\\\\) and outputs \\\\(y_t, t \\\\in (1, \\\\ldots, T)\\\\). \\\\(u_t, t \\\\in (1, \\\\ldots, T)\\\\) is obtained from each time.\\n\\nBy concatenating \\\\(u_t\\\\) from each time, we get the activation vector \\\\(u = [u_1, u_2, \\\\ldots, u_T]\\\\). In this way, we can obtain an activation and a weight vector of a component.\\n\\nAlgorithm 1\\n\\n```\\nInput: \\\\(X_t\\\\) and \\\\(y_t, t \\\\in \\\\{1, \\\\ldots, T\\\\}\\\\), and \\\\(r\\\\).\\nrepeat\\n  Update parameters in \\\\(M_i, i \\\\in \\\\{1, \\\\ldots, r\\\\}\\\\),\\n  Clip \\\\(w\\\\) in Linear: \\\\(0 < w < 1\\\\),\\nuntil objective function is converged\\n\\\\(u_i \\\\leftarrow [u_t]\\\\), \\\\(t \\\\in \\\\{1, \\\\ldots, T\\\\}\\\\), from Sigmoid in \\\\(M_i\\\\)\\n\\\\(v_i \\\\leftarrow w\\\\) from Linear in \\\\(M_i\\\\)\\n\\\\(V \\\\leftarrow [v_i], i \\\\in \\\\{1, \\\\ldots, r\\\\}\\\\)\\n\\\\(U \\\\leftarrow [u_i], i \\\\in \\\\{1, \\\\ldots, r\\\\}\\\\)\\nOutput: \\\\(\\\\hat{Y} = VU\\\\)\\n```\\n\\nAlgorithm 1 explains the factorization procedure. The reconstructed observed data \\\\(\\\\hat{y}_t\\\\) can be more accurately reconstructed by ensembling \\\\(M\\\\) as \\\\(\\\\hat{y}_t = r \\\\sum_{i=1}^{r} M_i(X_t)\\\\). (3)\\n\\nwhere \\\\(r\\\\) is the number of factorized components and \\\\(M_i\\\\) is the \\\\(i\\\\)-th model. In computing matrix factorization, the number of components \\\\(r\\\\) needs to be given. The appropriate number of factorized components \\\\(r\\\\) is determined according to evaluation indices such as the degree of restoration. \\\\(M_i, i \\\\in \\\\{1, \\\\ldots, r\\\\}\\\\) are trained in parallel to minimize the objective function using the same dataset across models. From each \\\\(M_i\\\\), we obtain the activation vector \\\\(u_i\\\\) and the weight vector \\\\(v_i\\\\). The factorized matrix \\\\(V\\\\) is obtained by combining the weight vectors as \\\\([v_1, \\\\ldots, v_r]\\\\). The factorized matrix \\\\(U\\\\) is also obtained by combining the activation vectors as \\\\([u_1, \\\\ldots, u_r]\\\\).\\n\\nThe objective function is\\n\\n\\\\[\\n\\\\min_L(y_t, r \\\\sum_{i=1}^{r} M_i(X_t)) + R(w)\\n\\\\]\\n\\nwhere \\\\(L(y_t, \\\\sum_{i=1}^{r} M_i(X_t))\\\\) is the reconstruction loss and \\\\(R(w)\\\\) is the regularization term for the weight. The parameters of the models are updated to minimize the objective function are denoted as \\\\(M_i\\\\). At each iteration of learning model, each element of the weights is clipped from 0 to 1 to obtain the positive factors of the matrix. The weight vector \\\\(w\\\\) in \\\\(M_i\\\\) is used as \\\\(v_i\\\\). \\\\(V\\\\) and \\\\(U\\\\) are obtained by concatenating of vectors \\\\(v_i\\\\) and \\\\(u_i, i \\\\in \\\\{1, \\\\ldots, r\\\\}\\\\), respectively. Reconstructed observed data \\\\(\\\\hat{Y} = [y_t], t \\\\in \\\\{1, \\\\ldots, T\\\\}\\\\) is reconstructed by \\\\(V\\\\) and \\\\(U\\\\).\\n\\n4 EXPERIMENT\\n\\nWe applied the proposed method to muscle synergy analysis. As stated in the introduction, our bodies contain corticospinal pathways between the primary motor cortex and muscles that function as a corticomuscular system (Liu et al., 2019). Normally, cortical events propagate to the peripheral muscles, and the corticomuscular system enables us to perform complex body movements by neurologically combining sets of simpler movements. These simpler movements are observed as the basic pattern of muscle activity, namely, muscle synergies. Muscle synergy analysis is designed to capture this efficient neural connection between the brain and muscle. However, the conventional approach uses only muscle activities (observed phenomena) to capture the muscle synergies, and there may still be unexplored muscle synergies that remain hidden. In applying the proposed method to muscle synergy analysis in this experiment, we consider the muscle activities as the observed phenomenon and the brain activities as the source phenomenon. To test the proposed method, we measured the muscle and brain activities simultaneously in a monkey.\\n\\n4.1 DATA MEASUREMENT\\n\\nWe measured the biopotential signals derived from the muscles and brain activities. The invasively measured electrocorticographic (ECoG) signal was selected as the brain activity data because it...\"}"}
{"id": "5XrQ2mskPQz", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2023.\\n\\ncontains more detailed brain activity than a non-invasively measured signal. Thus, to obtain both the brain activity and the muscle activity, we recorded ECoG and electromyographic (EMG) signals simultaneously from the contralateral hemisphere and the ipsilateral forelimb muscles of a monkey, respectively.\\n\\nThe monkey used in this experiment was an adult Japanese macaque monkey (Macaca fuscata; Monkey D: female, 6.0 kg, 7 years old). The Ethical description is in A.1.\\n\\nProcessing: ECoG signals were down-sampled to 500 samples per second, similar to previous works (Shin et al., 2012; Hidenori et al., 2012). Fourth-order Butterworth bandpass filters were applied to each ECoG signal, dividing them into multiple specific bands ($\\\\delta$ (1.5\u22124 Hz), $\\\\theta$ (4\u22128 Hz), $\\\\alpha$ (8\u221214 Hz), $\\\\beta_1$ (14\u221220 Hz), $\\\\beta_2$ (20\u221230 Hz), $\\\\gamma_1$ (30\u221250 Hz), $\\\\gamma_2$ (50\u221290 Hz), $\\\\gamma_3$ (90\u2212120 Hz), $\\\\gamma_4$ (120\u2212150 Hz)).\\n\\nThe nine bandpass filters split each of the 15-channel ECoG signals into nine signals to produce 135 channels of bandpass-filtered signals. We performed normalization and smoothing the same as in (Shin et al., 2012; Hidenori et al., 2012). A bandpass filter that passes a 20\u2013500-Hz frequency was applied to the EMG signals for removing motion artifacts. Bandpassed signals were then rectified and passed through a fourth-order low-pass filter with a cut-off frequency of 4 Hz. Finally, the signals were down-sampled to 500 Hz. To account for the nerve signal transmission delay between brain and muscles, delayed signal values is also used. The value of discrete-time step-size $\\\\Delta t$ is set to 20 ms as in the previous study (Shin et al., 2012).\\n\\nThe muscle activity at time $t$ is predicted using 10 time points starting 200 ms before the target time $t$. The $i$-th ECoG data vector at time $t$ is $x(i,t) = [x(i,t), x(i,t\u221220), x(i,t\u221240), \\\\ldots, x(i,t\u2212200)]$, and the ECoG data matrix at time $t$ is $X_t = [x(1,t), \\\\ldots, x(135,t)]$.\\n\\nBaseline: We utilized non-negative matrix factorization (NMF) as a baseline and used the Python library scikit-learn. All parameters were set to the same as those for the pre-set.\\n\\nMetric: Variance accounted for (VAF) is the main metric of the degree of reconstruction and used to determine the number of synergies (Steele et al., 2013; Delis et al., 2013), where the dimension of factors is determined when VAF exceeds 0.9. The dimension of factors is used as the synergy number in some cases (Hug et al., 2010; Fr\u00e9re & Hug, 2012; Chvatal & Ting, 2013). The specific calculation is described in A.4. In our analysis, the similarity of the muscle synergy components resulting from the two methods (proposed and NMF) is calculated by the cosine similarity of the weights of the synergies.\\n\\nModel selection: We performed three times optimization and adopted the model with the largest VAF because the VAF of the proposed method varies slightly each time.\\n\\n4.2 MUSCLE SYNERGY ACQUISITION POTENTIAL USING ONLY MUSCLE ACTIVITY (CONVENTIONAL FRAMEWORK)\\n\\nFigure 3: VAF of proposed and NMF methods for each number of synergies. In the proposed method, we experimentally explored the number of filters from \\\\([1, 1]\\\\) to \\\\([128, 128]\\\\). First, we examined the proposed method's availability of muscle synergies by using only muscle activities (conventional framework). The muscle synergies were determined based on the degree of reconstruction (VAF) and the number of synergies. Theoretically, as the number of synergies increases, the VAF becomes higher because the reconstruction accuracy improves. Researchers have shown that the VAF of NMF increases with the increase of the number of muscle synergies in the case of using only muscle activities (Rabbi et al., 2020; Gui & Zhang, 2016). If the proposed method can calculate muscle synergies by factorizing the input matrix, the VAF should increase with the number of muscle synergies. We tested the VAF of the proposed method to see if it would increase and exceed 0.9, as the number of synergies increases only when using muscle activity. The proposed method inputs an EMG vector...\"}"}
