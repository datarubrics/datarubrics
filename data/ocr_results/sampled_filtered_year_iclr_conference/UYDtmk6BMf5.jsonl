{"id": "UYDtmk6BMf5", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Out-of-distribution (OOD) detection has made significant progress in recent years because the distribution mismatch between the training and testing can severely deteriorate the reliability of a machine learning system. Nevertheless, the lack of precise interpretation of the in-distribution limits the application of OOD detection methods to real-world system pipelines. To tackle this issue, we decompose the definition of the in-distribution into texture and semantics, motivated by real-world scenarios. In addition, we design new benchmarks to measure the robustness that OOD detection methods should have. To achieve a good balance between the OOD detection performance and robustness, our method takes a divide-and-conquer approach. That is, the model first tackles each component of the texture and semantics separately, and then combines them later. Such design philosophy is empirically proven by a series of benchmarks including not only ours but also the conventional counterpart.\\n\\n![Textural discrepancy](image1)\\n\\n![Semantic discrepancy](image2)\\n\\n![Training dataset](image3)\\n\\n![In-distribution manifold](image4)\\n\\n(a) Traditional definition of the in-distribution\\n\\n(b) Decomposed definition of the in-distribution\\n\\nFigure 1: How to define the in-distribution? (a) Traditional out-of-distribution detection studies have managed the in-distribution in an entangled view. However, this assumption could be na\u00efve considering the complex nature of the real environment. (b) We decompose the definition of the in-distribution to the texture and semantic aspects. This provides the flexibility to handle complicated scenarios by determining which definition of the in-distribution is suitable for a given scenario.\\n\\n## Introduction\\n\\nThe out-of-distribution (OOD) detection is the task that recognizes whether the given data comes from the distribution of training samples (also known as in-distribution) or not. Any machine learning-based system could receive input samples that have a completely disparate distribution from the training environments (e.g., dataset). Since the distribution shift can severely degrade the model performance (Amodei et al., 2016), it is a potential threat for a reliable real-world AI system. However, an ambiguous definition of the \u201cin-distribution\u201d limits the feasibility of the OOD detection method in real-world applications, considering the various OOD scenarios. For example, subtle corruption is a clear signal of the OOD in the machine vision field while a change in semantic information might not be. On the other hand, an autonomous driving system may assume the in-distribution from the semantic-oriented perspective; e.g., an unseen traffic sign is the OOD. Interestingly, the interpretations of the in-distribution described in the above scenarios are not correlated; rather, they are contradicted. Unfortunately, most of the conventional OOD detection methods (Zhang et al., 2018) do not provide a clear solution to these issues.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To tackle this issue, we revisit the definition of the in-distribution by decomposing it into two different factors: texture and semantics (Figure 1b). For the texture OOD case, we define the OOD as the textural difference between the in- and out-of-distribution datasets. On the contrary, the semantic OOD focuses on the class labels that do not exist in the in-distribution environment. Note that the two aspects have a trade-off relationship, thus detecting both OOD problems with a single model is challenging with the (conventional) entangled OOD point of view.\\n\\nSimilar to ours, Geirhos et al. (2018) investigated the texture-shape cue conflict in the network, and a series of following studies (Hermann et al., 2019; Li et al., 2020; Ahmed & Courville, 2020) explored the way to find a balance between these perspectives. However, aforementioned works utilize texture-shape to analyze the bias inherited in deep networks. In this work, instead, we focus on analyzing the texture and semantic nature underlying the in-distribution to build a more practically applicable OOD detection method.\\n\\nHowever, to the best of our knowledge, none of the studies on the OOD detection benchmark have thoroughly investigated the definition of the in-distribution. This can be problematic when the OOD detection method judges the image corrupted by minor distortion as OOD, even when the environment is tolerant to the small changes in texture. Because of such a complicated scenario, it is important to evaluate the OOD detection method in a comprehensive way that goes beyond the simple benchmarks. In this work, we propose a new approach to measuring the performance of the method according to the decomposed definition of the in-distribution. One notable observation in our benchmark is that most of the previous OOD detection methods are highly biased to the texture information and ignore the semantic clues in many cases.\\n\\nTo mitigate this issue, our method tackles the texture and semantic information separately and aggregates these at the final module (Figure 2). To effectively extract the texture information, we use the 2D Fourier transform motivated by the recent frequency domain-driven deep method (Xu et al., 2020). For the semantic feature, we design an extraction module upon the Deep-SVDD (Ruff et al., 2018) with our novel angular distance-based initialization strategy. We then combine two features using the normalizing flow-based method (Dinh et al., 2016), followed by our factor control mechanism. This control module provides the flexibility to handle various OOD scenarios by choosing which decomposed feature is more important in the given surrounding OOD circumstance.\\n\\nThe main contributions of this work are as follows:\\n\\n\u2022 We decompose the \u201cunclear\u201d definition of the in-distribution into texture & semantics. To the best of our knowledge, this is the first attempt to clarify the OOD itself in this field.\\n\u2022 Motivated by real-world problems, we create new OOD detection benchmark scenarios to evaluate the models based on the decomposed in-distribution factors.\\n\u2022 We propose a novel OOD detection method that is effective on both texture & semantics as well as the conventional benchmark setups. In addition, our method does not require any auxiliary datasets or class labels unlike the previous models.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"PCA\\n\\nFigure 2: Model overview. Our framework first extracts the texture and semantic information with the corresponding modules, and then combines them via the normalizing flow-based method.\\n\\n(a) Texture feature $T(x)$ is distilled by the Fourier spectrum-based component.\\n(b) We use a multi-SVDD method with a novel angular initialization to extract the semantic information $S(x)$.\\n(c) Output features are merged by the explicit probability inference method, RealNVP. Here, we introduce the user control parameter $\\\\lambda$ to determine which feature is more suitable for a given OOD scenario.\\n\\nConventional OOD detection has an assumption that in-distribution data are sampled from the distribution of the training dataset, $x \\\\sim p_{\\\\text{data}}$. We decompose the image with two factors and calculate the anomaly score based on each factor's likelihood. The texture information $T(x)$ extracted rigorous Fourier analysis process from input $x$. The semantic information $S(x)$ extracts the content label features such as shape. Our framework calculates the likelihood of these two factors and then combines these likelihoods. Since we use the Normalizing flow model that trains the exact likelihood, the extracted information is adjusted using a lambda that the user can control.\\n\\n3.1 Model Overview\\n\\nWe aim to train our method with the decomposed in-distribution likelihood, $p(T(x)|x)$ and $p(S(x)|x)$ (Figure 2). With the given input image $x$, we extract the features for each variable with different approaches. In detail, we distil the information from the texture and semantic information with $T(x)$ and $S(x)$, respectively. The extracted features are combined by the controllable normalizing flow method. Since our normalizing flow-based model explicitly calculates the negative log-likelihood, we model each extracted information as $\\\\log p_{\\\\theta}(T(x)|x)$ and $\\\\log p_{\\\\phi}(S(x)|x)$, where $\\\\theta$ and $\\\\phi$ are trainable parameters of the networks. In addition, we introduce the control parameter $\\\\lambda \\\\in [0,1]$ to model the final probability as $\\\\lambda \\\\cdot \\\\log p(x|T(x)) + (1 - \\\\lambda) \\\\cdot \\\\log p(x|S(x))$. With this control mechanism, a user can determine the appropriate model \u201cmode\u201d by referring to the prior knowledge. For example, in the case where the texture information overwhelms the semantic one for detecting OOD, we can overweight $\\\\lambda$ for better performance. By default, we use the $\\\\lambda$ value of 0.5 (no prior knowledge).\"}"}
{"id": "UYDtmk6BMf5", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\n3.2 EXTRACTING THE SEMANTIC INFORMATION\\n\\nMulti-SVDD.\\n\\nBeyond the one-class anomaly detection that considers the normal data as a single class (e.g., DeepSVDD (Ruff et al., 2018)), recent studies have viewed the normal data as the union of the multiple hidden semantic information (Ghafoori & Leckie, 2020; Park et al., 2021). Inspired by this idea, we use the multi-SVDD method to extract the semantic information in an unsupervised manner for the OOD detection task.\\n\\nMulti-SVDD embeds the samples to the multiple center vectors as close as possible. Suppose the set of center vectors $C = \\\\{c_1, ..., c_K\\\\}$ is initialized via K-means and the radius of each center is $r = [r_1, ..., r_K]$. In multi-SVDD, the objective function is defined as follows.\\n\\n$$\\n\\\\min W, r_K \\\\sum_{k=1}^{K} r_k^2 + \\\\nu n \\\\sum_{i=1}^{n} \\\\max \\\\{0, \\\\|\\\\phi(x_i; W) - c_j\\\\|_2 - r_j^2\\\\} + \\\\eta_2 \\\\sum \\\\|W\\\\|_2.\\n$$\\n\\nHere, $\\\\phi(x_i; W)$ is the deep network with a set of weight parameters $W$ and $c_j$ is assigned to $\\\\phi(x_i; W)$. As the set $r$ is decreased, the samples are condensed into the center vectors. By using the distance between the center vectors and the samples, we get an anomaly score.\\n\\nAngular distance initialization.\\n\\nThe SVDD method is originally introduced for the anomaly detection task. Because of the disparity between the OOD and the anomaly detection scenarios, direct application of the SVDD-based model to OOD detection causes unexpected performance degradation. In anomaly detection, even though the abnormal samples lie in the in-distribution manifold, it is possible to detect them as abnormal unless they are close to the center vectors $c_j$. For example, as shown in Figure 3a, the OOD samples (red) that are located inside of the in-distribution manifold (light blue shade) can be detected as abnormal since they are outside of the tight cluster boundary (dark blue shade). Because of such characteristics, a mixture of Gaussian probability density is a reasonable density space for the anomaly detection model.\\n\\nUnlike the anomaly detection task, the definition of the OOD detection task is to find the samples that are not the \u201cin-distribution\u201d. In Figure 3a, all the OOD samples placed in the in-distribution manifold (light dark shade) are recognized as the in-distribution. To tackle this issue, we propose an angular distance-based center vector initialization strategy:\\n\\n$$\\nc_k = \\\\gamma v \\\\|v\\\\|, \\\\quad v \\\\in \\\\mathbb{R}^h \\\\sim N(0, 1)\\n$$\\n\\nwhere $h$ is the dimension of the embedding space and $\\\\gamma$ is the hyper-parameter for the radius of the sphere. After $\\\\phi(x_i; W)$ is trained based on angular initialization, semantic features are extracted through this model; $S(x_i) = \\\\phi(x_i; W)$. By setting the $\\\\gamma$ value as large enough, we ensure that all sample data are within a radius of the sphere as illustrated in Figure 3b. While Equation 1 drives the training samples to be embedded around the center vectors on the sphere, the OOD samples remain near the origin. This embedding space may be weak to recognize the semantic label of a given sample, but it is sufficient to identify whether the sample is OOD or not.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Method Resolution\\n32 \u2192 36 (\u2193)\\n32 \u2192 40 (\u2193)\\n32 \u2192 44 (\u2193)\\n32 \u2192 48 (\u2193)\\n\\nTable 3: Robustness on the texture discrepancy.\\nWe use 32 \u00d7 32 CIFAR-10 as the ID and vary the resolution to make test datasets. Note that 50.0 is the best score since the test datasets are from the in-distribution but with different image resolutions.\\n\\nMethod MNIST \u2192 K-MNIST (\u2193) F-MNIST (\u2191)\\nMaha 91.6 96.8\\nOE 97.6 99.8\\nSSL 99.9 100.\\n\\nTable 4: Robustness on the semantic discrepancy.\\nIn the K-MNIST scenario, 50.0 is the best since no textural difference exists between the ID and OOD, in contrast to the F-MNIST (higher is better).\\n\\nIn the resolution change scenario (Table 3), our method with \\\\( \\\\lambda = 1.0 \\\\) (semantics mode) outperforms the others in all the settings. All the methods except ours with semantics mode are extremely sensitive to the image resolution change, although no other information is modified.\\n\\n4.2.2 Robustness on Semantic Discrepancy of the In-Distribution\\nSetups. To evaluate the robustness that may arise from the semantic discrepancy, we use MNIST, K-MNIST, and F-MNIST datasets. K-MNIST comprises of Japanese characters while F-MNIST is a collection of fashion objects. In this experiment, we set both MNIST and K-MNIST as the in-distribution datasets since they are similar in terms of the texture aspect (only the character labels are different, as shown in Figure 6b). On the other hand, MNIST \u2194 F-MNIST is the conventional OOD scenario since they have both disparate semantics and textures.\\n\\nResult. In Table 4, we compare our method with the OOD methods that use class labels or with a self-supervision based approach. For MNIST \u2192 K-MNIST scenario, our method with \\\\( \\\\lambda = 0.0 \\\\) successfully determines that K-MNIST is the in-distribution (e.g., AUC is 50.6). In contrast, our model with other \\\\( \\\\lambda \\\\) values (0.5 and 1.0) cannot, since these mostly depend on the semantic information to detect the OOD. This behavior also appears in the other OOD detection methods because they use entangled information. Not surprisingly, all the methods identify that given test samples are OOD in the MNIST \u2192 F-MNIST case, where the texture information is the crucial component. A series of experiments prove that the texture and semantic cues should be viewed as disentangled factors.\\n\\n5 Conclusion\\nIn this work, we introduce a novel viewpoint of the in-distribution for the practically applicable OOD detection in the real world. To do that, we separate the definition of the \u201csingle-mode\u201d in-distribution to the \u201ctexture\u201d or \u201csemantics\u201d factors by following the requirements of the real-world applications. To effectively handle both aspects, we take a divide-and-conquer strategy that extracts the features using the appropriate method in each factor, then combines these with the normalizing flow-based model. By doing so, our method outperforms previous models on not only our newly proposed benchmark scenarios but also the conventional OOD detection cases.\\n\\nWe hope that our work provides useful guidance for future OOD detection work. In the future, we aim to investigate more diverse factors beyond the textures and the semantics that complicated datasets can have, such as multi-object scenes.\\n\\nREFERENCES\\nFaruk Ahmed and Aaron Courville. Detecting semantic anomalies. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 3154\u20133162, 2020.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pp. 1597\u20131607. PMLR, 2020.\\n\\nLaurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv preprint arXiv:1605.08803, 2016.\\n\\nTarik Dzanic, Karan Shah, and Freddie Witherden. Fourier spectrum discrepancies in deep network generated images. arXiv preprint arXiv:1911.06465, 2019.\\n\\nRobert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. arXiv preprint arXiv:1811.12231, 2018.\\n\\nZahra Ghafoori and Christopher Leckie. Deep multi-sphere support vector data description. In Proceedings of the 2020 SIAM International Conference on Data Mining, pp. 109\u2013117. SIAM, 2020.\\n\\nKaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9729\u20139738, 2020.\\n\\nDan Hendrycks, Mantas Mazeika, and Thomas Dietterich. Deep anomaly detection with outlier exposure. arXiv preprint arXiv:1812.04606, 2018.\\n\\nDan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. Using self-supervised learning can improve model robustness and uncertainty. arXiv preprint arXiv:1906.12340, 2019.\\n\\nKatherine L Hermann, Ting Chen, and Simon Kornblith. The origins and prevalence of texture bias in convolutional neural networks. arXiv preprint arXiv:1911.09071, 2019.\\n\\nYen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10951\u201310960, 2020.\\n\\nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\\n\\nAlex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research). URL http://www.cs.toronto.edu/kriz/cifar.html, 5:4, 2010.\\n\\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. Advances in neural information processing systems, 31, 2018.\\n\\nYingwei Li, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan Yuille, and Cihang Xie. Shape-texture debiased neural network training. arXiv preprint arXiv:2010.05981, 2020.\\n\\nShiyu Liang, Yixuan Li, and Rayadurgam Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. arXiv preprint arXiv:1706.02690, 2017.\\n\\nSina Mohseni, Mandar Pitale, JBS Yadawa, and Zhangyang Wang. Self-supervised learning for generalizable out-of-distribution detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 5216\u20135223, 2020.\\n\\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nAristotelis-Angelos Papadopoulos, Mohammad Reza Rajati, Nazim Shaikh, and Jiamian Wang. Outlier exposure with confidence control for out-of-distribution detection. *Neurocomputing*, 441:138\u2013150, 2021.\\n\\nJuneKyu Park, Jeong-Hyeon Moon, Namhyuk Ahn, and Kyung-Ah Sohn. What is wrong with one-class anomaly detection? *arXiv preprint arXiv:2104.09793*, 2021.\\n\\nJie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. In *Advances in Neural Information Processing Systems*, 32:14707\u201314718, 2019.\\n\\nDanilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In *International conference on machine learning*, pp. 1530\u20131538. PMLR, 2015.\\n\\nLukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel M\u00fcller, and Marius Kloft. Deep one-class classification. In *International conference on machine learning*, pp. 4393\u20134402. PMLR, 2018.\\n\\nChandramouli Shama Sastry and Sageev Oore. Detecting out-of-distribution examples with grammatrices. In *International Conference on Machine Learning*, pp. 8491\u20138501. PMLR, 2020.\\n\\nJihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin. Csi: Novelty detection via contrastive learning on distributionally shifted instances. *arXiv preprint arXiv:2007.08176*, 2020.\\n\\nAntonio Torralba, Rob Fergus, and William T Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. *IEEE transactions on pattern analysis and machine intelligence*, 30(11):1958\u20131970, 2008.\\n\\nKai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, and Fengbo Ren. Learning in the frequency domain. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pp. 1740\u20131749, 2020.\\n\\nFisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. *arXiv preprint arXiv:1506.03365*, 2015.\\n\\nMingtian Zhang, Andi Zhang, and Steven McDonagh. On the out-of-distribution generalization of probabilistic image modelling. *arXiv preprint arXiv:2109.02639*, 2021.\"}"}
{"id": "UYDtmk6BMf5", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.3 Extracting the Texture Information\\n\\nTo effectively extract the texture property of the in-distribution, we interpret the image in the frequency space. With a given input image $x \\\\in \\\\mathbb{R}^{3 \\\\times h \\\\times w}$, we first convert it into the frequency domain using Discrete Fourier Transform (DFT) as shown below.\\n\\n$$F(f_x, f_y) = \\\\frac{1}{hw} \\\\sum_{p=0}^{w-1} \\\\sum_{q=0}^{h-1} I(p,q) \\\\cdot e^{-i 2\\\\pi (f_x p/h + f_y q/w)}, \\\\quad (3)$$\\n\\nHere, $I(p,q)$ denotes the pixel value of the image at the $(p,q)$-coordinate and $F(f_x, f_y)$ is the output of the DFT at the Cartesian coordinate $(f_x, f_y)$ in the frequency space. In order to construct a scale and rotation invariant frequency information in 2D image, we modify the coordinate system from Cartesian $(f_x, f_y)$ to polar $(f_r, \\\\theta)$, following Dzanic et al. (2019).\\n\\n$$F(f_r, \\\\theta) = F(f_x, f_y) : f_r = \\\\sqrt{f_x^2 + f_y^2}, \\\\quad \\\\theta = \\\\text{atan2}(f_y, f_x). \\\\quad (4)$$\\n\\nSince directly computing the polar coordinate is computationally expensive and tricky, we iteratively calculate the rotation invariant frequency feature. To do that, we only utilize the first channel of the image as $x \\\\in \\\\mathbb{R}^{1 \\\\times h \\\\times w}$ and assume that the image is square (i.e., $h = w$). Let $T(x) \\\\in \\\\mathbb{R}^{2/w}$ be the texture feature vector of the image $x$. Then, the $i$-th element of the feature $T_i(x)$ is calculated as:\\n\\n$$T_i(x) = R_i - R_{i-1} : R_w = \\\\frac{w}{2} \\\\sum_{f_x = -w}^{w} F(f_x, f_y), \\\\quad R_0 = F(0, 0) \\\\quad (5)$$\\n\\nDiscussion.\\n\\nWe compare the power spectrum density (PSD) of CIFAR-10 (Krizhevsky et al., 2009), distorted CIFAR-10 and CIFAR-100 (Krizhevsky et al., 2010) datasets (Figure 4). The PSD discrepancy between the corrupted CIFAR-10 and the vanilla one indicates that the image feature acquired from the frequency domain is adequate to represent the texture cue. In contrast, CIFAR-10 and CIFAR-100 are not distinguishable in the frequency domain since they have very similar image texture due to the small resolution. These observations support our assumption that the OOD detection model should couple the texture and semantic information to properly handle the uncorrelated cues.\\n\\n3.4 Feature Composition Via Normalizing Flow\\n\\nSince we design our framework to directly sample the probability, any ad-hoc scoring functions are not required. Instead, we use a normalizing flow-based method (Dinh et al., 2014; Rezende & Mohamed, 2015; Dinh et al., 2016) that uses the probability of given samples as a loss function. In the following, we will describe how to get the probability of samples from the prior probability (Normal distribution) using normalizing flow.\\n\\nGiven sample $x$, a normal prior probability distribution $p_Z$ on a latent variable $z \\\\in Z$, and a bijection $f : X \\\\rightarrow Z$ (with $g = f^{-1}$), the change of variables defines a model distribution on $X$ by\\n\\n$$p_X(x) = p_Z(f(x)) \\\\left| \\\\det \\\\left( \\\\frac{\\\\partial f(x)}{\\\\partial x} \\\\right)^T \\\\right|, \\\\quad (6)$$\\n\\nwhere $\\\\frac{\\\\partial f(x)}{\\\\partial x}^T$ is the Jacobian of $f$ at $x$. The bijection function $f$ can be decomposed as $f = f_1 \\\\circ \\\\cdots \\\\circ f_k$. We use a flow-based RealNVP with coupling layers (Dinh et al., 2016). To provide the input to RealNVP, we apply PCA for the dimension reduction of each extracted features. Finally, given the...\"}"}
{"id": "UYDtmk6BMf5", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Comparison of the benchmark scenarios. (a, b) Out-of-distribution detection scenario. The training dataset is in-distribution (ID), while test datasets are out-of-distribution (OOD). Note that texture and semantic OODs are entangled in the conventional benchmark. (c, d) Evaluation on the robustness. Unlike (a, b), it provides the ID samples at test time. An oracle in this scenario produces AUC as 50.0 (cannot distinguish as OOD at all) since the given samples are from ID.\\n\\nin-distribution training dataset $D$, the objective of the RealNVP model with the trainable parameters $\\\\theta$ and $\\\\phi$ is to minimize the following equations.\\n\\n$$L_{\\\\text{texture}}(D) = \\\\frac{1}{N} \\\\sum_{i=1}^{N} -\\\\log p_{\\\\theta}(T(x_i)|x_i),$$\\n\\n$$L_{\\\\text{semantics}}(D) = \\\\frac{1}{N} \\\\sum_{i=1}^{N} -\\\\log p_{\\\\phi}(S(x_i)|x_i),$$\\n\\n(7)\\n\\nBy decomposing to the texture and semantic components based on probabilistic modeling, one nice side-effect is that we can adjust the contribution of these components by referring to the given OOD environment. Since we designed the feature components to be separate, we combine them with a simple linear interpolation as follows.\\n\\n$$\\\\lambda \\\\cdot \\\\log p_{\\\\phi}(S(x_i)|x_i) + (1-\\\\lambda) \\\\cdot \\\\log p_{\\\\theta}(T(x_i)|x_i),$$\\n\\n(8)\\n\\nwhere $\\\\lambda \\\\in [0, 1]$ is the control parameter (default is 0.5).\\n\\n4 EXPERIMENTS\\n\\nIn this section, we demonstrate the effectiveness of our proposed method on various benchmark setups. In Section 4.1, we report the performance on the conventional OOD detection task and discuss the limitation of the previous OOD detection studies. We use the area under the curve (AUC) for the receiver operating characteristic (ROC) curve to evaluate the OOD detection performance. Then, we will discuss on how to evaluate the robustness that the OOD detection method should have and show the robustness of the previous and ours models (Section 4.2).\\n\\n4.1 CONVENTIONAL OUT-OF-DISTRIBUTION DETECTION\\n\\nSetups. We evaluate out-of-distribution detection methods on the widely used OOD detection benchmark. Here, we use SVHN (Netzer et al., 2011), CIFAR-10 (Krizhevsky et al., 2009) and CIFAR-100 (Krizhevsky et al., 2010) as the in-distribution dataset. To simulate the OOD samples, LSUN (Yu et al., 2015) and Tiny-ImageNet (Torralba et al., 2008) datasets are additionally used.\\n\\nBaselines. We compare our approach to the methods belonging to three different OOD detection groups.\\n\\n1) Methods that use class labels of the training samples. Feature based methods such as Maha (Lee et al., 2018) and Gram (Sastry & Oore, 2020) fall into this category.\\n\\n2) Methods that utilize additional distribution (dataset) such as OE (Hendrycks et al., 2018) and OEC (Papadopoulos et al., 2021).\\n\\n3) Self-supervised based methods. Rotation-based (Rot) (Hendrycks et al., 2019), SSL (Mohseni et al., 2020), and CSI (Tack et al., 2020) are in this group.\\n\\nResults. As shown in Table 1, our proposed method surpasses the competitors on the conventional OOD detection task without using any extra information such as class labels, other datasets, or image transformation techniques that the other methods required. In detail, ours with $\\\\lambda = 0.0$ (semantic mode) achieves the best performance in all the cases with the exception of two scenarios.\\n\\nDiscussion. As we have discussed, it is often risky to assume that the input samples of the real-world system have a single and entangled characteristic. We argue that it is more natural to consider...\"}"}
{"id": "UYDtmk6BMf5", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Conventional OOD detection benchmark. We evaluate the detection performance by AUC (in- vs. out-distribution detection based on confidence/score) in percent (higher is better). C10 and C100 stand for the CIFAR-10 and CIFAR-100. * indicates the high-resolution dataset.\\n\\n| Datasets  | C10         | C100        | SVHN        | TinyImageNet | LSUN*       |\\n|-----------|-------------|-------------|-------------|--------------|-------------|\\n|           | 99.3        | 97.3        | 99.3        | 99.8         | -           |\\n|           | 99.0        | -           | 99.8        | 99.8         | 93.9        |\\n| C100      | -           | 99.9        | 99.8        | 99.9         | 91.1        |\\n|           | -           | -           | 99.9        | 99.9         | 91.1        |\\n| TinyImageNet | 99.5        | 99.7        | -           | -            | 65.4        |\\n|           | 99.9        | -           | -           | -            | 99.9        |\\n| LSUN*     | 99.3        | 99.9        | 96.4        | 98.9         | 99.9        |\\n|           | -           | -           | 99.9        | 99.9         | 99.8        |\\n| C100      | 88.2        | 79.0        | 92.9        | 93.8         | 82.3        |\\n|           | 99.9        | -           | 93.8        | 93.8         | 55.7        |\\n| TinyImageNet | 97.4        | 99.0        | -           | -            | 91.7        |\\n|           | 99.9        | -           | -           | -            | 100.        |\\n| LSUN*     | 98.2        | 99.3        | 79.5        | 88.8         | 99.9        |\\n|           | -           | -           | 99.9        | 99.9         | 100.        |\\n\\nUnfortunately, conventional OOD detection benchmarks are not developed to measure the disentangled view of the in-distribution. Here, we dissect the traditional benchmark to quantify the effect of each property we decompose. We first categorized the datasets into the high- and low-resolution groups by the image resolution: C10, C100, SVHN, and TinyImageNet belong to the low-resolution (LR) group while LSUN is high-resolution (HR). Table 1 shows that previous studies achieve high performance on the LR \u2192 HR scenarios and label-based methods produce outstanding results. However, in Section 4.2.1, we will show that the superior performance of these methods is because they abuse the texture information (e.g., detect as OOD by highly referring to the image resolution).\\n\\nOn the other hand, we argue that the semantic property is the key component to identity the OOD of the LR \u2192 LR scenarios. For example, C10 \u2194 C100 solely requires semantic information to detect OOD since these datasets use very similar images (in terms of the texture and image resolution). This is the reason why ours with $\\\\lambda = 0$ (texture mode) is not able to detect OOD at all (55.7 and 49.4 AUC). Note that other competitors also show the inferior performance, especially C10 \u2194 C100 case, which demonstrate that these methods have weakness in handling semantic information.\\n\\n### 4.2 Evaluating the Robustness of the OOD Detection Method\\n\\nIn this section, we evaluate the robustness of the OOD detection method. The following experiments are motivated by the real-world demands that the OOD detection framework focused on the semantic discrepancy should be tolerant to the minor changes in the image space (such as the texture shown in Figure 5c), and vice versa (Figure 5d). However, how can we evaluate the robustness of the OOD detection method in texture and semantic perspectives?\\n\\nTo quantify the robustness of the OOD method, we introduce the AUC score-based measurement. The evaluation protocol is as follow:\\n\\n1. We first train the OOD detection method with the in-distribution training dataset.\\n2. We provide the in-distribution samples as test dataset. Here, contrary to the conventional benchmark, AUC = 50% is the best performance. This is because 50% AUC indicates that the detection method cannot distinguish the test samples as OOD (determines as in-distribution). In Section 4.2.1, we evaluate the robustness on the texture discrepancy by providing the textually different (but marginally) in-distribution dataset at test time (Figure 5c). Then, in Section 4.2.2, we benchmark the robustness on the semantic discrepancy (Figure 5d).\"}"}
{"id": "UYDtmk6BMf5", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Robustness on the texture discrepancy produced by the mild corruptions. We use CIFAR-10 as the in-distribution dataset, and corrupt this using mild distortions. In this benchmark, an OOD detection method should not determine the corrupted images as OOD (i.e., 50.0% AUC is the best score). This scenario is motivated by the real-world applications that context information is the key factor in OOD but the mild corruptions are acceptable.\\n\\n4.2.1 Robustness on Texture Discrepancy of the In-Distribution\\n\\nSetups. Here, we experiment on two benchmark scenarios: 1) distortion and 2) image resolution. Both cases assume that the definition of the OOD is in the disparity of semantic information. That is, a mild change presented in the image space should not be considered as a signal of the OOD. For the distortion scenario, we corrupt the CIFAR-10 dataset with frost, shot noise, haze, and motion blur distortions with diverse (but mild) corruption levels (Figure 6a). To make the resolution change case, we first perform center-crop and resize it back to the original resolution (32\u00d732). We carefully adjust the cropping operation not to harm the semantic information.\\n\\nResult. Table 2 shows the AUC score of the OOD detection. Since this experiment focuses on detecting the test samples as the in-distribution, 50.0% AUC is the best score. We observe that the deep feature-based methods (Maha and Gram) do not have robustness against the texture discrepancy at all. They are not appropriate for real-world applications that do not treat a mild corruption as OOD. On the contrary, our method with $\\\\lambda = 1.0$ (semantics mode) achieves the best performance in all the scenarios because this concentrates on the semantic information alone.\"}"}
