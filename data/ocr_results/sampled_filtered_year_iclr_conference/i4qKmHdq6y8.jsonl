{"id": "i4qKmHdq6y8", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: (MNIST - Partial Dataset - Unknown) Criteria\\n\\n| Criterion | Recall | Confidence | SelectiveNet | DeepGambler |\\n|-----------|--------|------------|--------------|-------------|\\n|           | 99     | 0.62       | 0.24         | 0.87        |\\n|           | 94     | 0.77       | 0.86         | 1.00        |\\n|           | 89     | 0.67       | 0.97         | 0.87        |\\n|           | 88     | 0.97       | 0.86         | 1.00        |\\n|           | 85     | 0.24       | 0.67         | 0.87        |\\n\\nTable 4: (SVHN - Partial Dataset - Unknown) Criteria\\n\\n| Criterion | Recall | Confidence | SelectiveNet | DeepGambler |\\n|-----------|--------|------------|--------------|-------------|\\n|           | 98     | 0.01       | 0.00         | 0.00        |\\n|           | 97     | 0.01       | 0.00         | 0.00        |\\n|           | 96     | 0.00       | 0.00         | 0.00        |\\n|           | 89     | 0.00       | 0.00         | 0.00        |\\n|           | 88     | 0.00       | 0.00         | 0.00        |\\n|           | 85     | 0.00       | 0.00         | 0.00        |\\n\\nIn this work, we propose a natural noisy generative process to model a problem where a significant proportion of datapoints are purely random. We solve it by learning both a predictor for classification and a selector to abstain from the uninformative data. We propose a novel selector loss to learn jointly learns the predictor and selector. Our empirical study shows promising results of our method.\\n\\nWe train a fully connected network with 256 hidden units and 0.00025 dropout rate and a Liblinear SVM. The network is trained with an exponentially decaying learning rate of 0.001. We perform 100 epochs per target dataset. We train the predictor network for 100 epochs and the selector for another 100 epochs. We use the following loss functions: classification loss (CrossEntropy), selector loss (SVM), and joint loss (WeightedSqrtSvm). The network is trained with an exponentially decaying learning rate of 0.001. We perform 100 epochs per target dataset. We train the predictor network for 100 epochs and the selector for another 100 epochs. We use the following loss functions: classification loss (CrossEntropy), selector loss (SVM), and joint loss (WeightedSqrtSvm).\"}"}
{"id": "i4qKmHdq6y8", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We describe a synthetic data generation procedure, evaluation metrics and experiment setting in section 4. For the convenience of the reader to reproduce the experiment, we also summarize the setting and give implementation details in section D.3. The source code as well as parameters to reproduce the experimental results will be made available together with the publication of the paper.\\n\\nThis paper focuses on a theoretical discussion about learning from data that contains different portion of non-informative samples. Our experiments only use publicly available datasets. Our discussion, analysis, or data shouldn\u2019t raise any ethics-related issues. The learning method proposed in this paper, however, can be potentially used in applications with fairness and privacy concerns. It our future efforts in this area, we aim to address and resolve possible negative impact.\\n\\nREFERENCES\\n\\nSanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: a meta-algorithm and applications. Theory of Computing, 8(1):121\u2013164, 2012.\\n\\nPranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner. Efficient learning of linear separators under bounded noise. In Conference on Learning Theory, pp. 167\u2013190. PMLR, 2015.\\n\\nPranjal Awasthi, Maria Florina Balcan, and Philip M Long. The power of localization for efficiently learning linear separators with noise. Journal of the ACM (JACM), 63(6):1\u201327, 2017.\\n\\nMaria-Florina Balcan, Avrim Blum, and Santosh Vempala. A discriminative framework for clustering via similarity functions. In Proceedings of the fortieth annual ACM symposium on Theory of computing, pp. 671\u2013680, 2008.\\n\\nPeter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. JMLR, 9(8), 2008.\\n\\nPeter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, 101(473):138\u2013156, 2006.\\n\\nAvrim Blum, John Hopcroft, and Ravindran Kannan. Foundations of data science. Vorabversion eines Lehrbuchs, 5, 2016.\\n\\nAnselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K Warmuth. Learnability and the vapnik-chervonenkis dimension. Journal of the ACM (JACM), 36(4):929\u2013965, 1989.\\n\\nTom Bylander. Learning linear threshold functions in the presence of classification noise. In Proceedings of the seventh annual conference on Computational learning theory, pp. 340\u2013347, 1994.\\n\\nNicolo Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university press, 2006.\\n\\nMoses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pp. 47\u201360, 2017.\\n\\nChi-Keung Chow. An optimum character recognition system using decision functions. IRE Transactions on Electronic Computers, (4):247\u2013254, 1957.\\n\\nCorinna Cortes, Giulia DeSalvo, and Mehryar Mohri. Learning with rejection. In ICALT, pp. 67\u201382, 2016.\\n\\nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pp. 248\u2013255. Ieee, 2009.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\\n\\nIlias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation and learning mixtures of spherical gaussians. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, pp. 1047\u20131060, 2018.\\n\\nIlias Diakonikolas, Themis Gouleakis, and Christos Tzamos. Distribution-independent pac learning of halfspaces with massart noise. arXiv preprint arXiv:1906.10075, 2019.\\n\\nIlias Diakonikolas, Vasilis Kontonis, Christos Tzamos, and Nikos Zarifis. Learning halfspaces with massart noise under structured distributions. In Conference on Learning Theory, pp. 1486\u20131513. PMLR, 2020.\\n\\nAndrzej Ehrenfeucht, David Haussler, Michael Kearns, and Leslie Valiant. A general lower bound on the number of examples needed for learning. Information and Computation, 82(3):247\u2013261, 1989.\\n\\nRan El-Yaniv et al. On the foundations of noise-free selective classification. JMLR, 11(5), 2010.\\n\\nGiorgio Fumera and Fabio Roli. Support vector machines with embedded reject option. In International Workshop on Support Vector Machines, pp. 68\u201382, 2002.\\n\\nYarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In ICML, pp. 1050\u20131059, 2016.\\n\\nYonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. In NeurIPS, 2017.\\n\\nYonatan Geifman and Ran El-Yaniv. Selectivenet: A deep neural network with an integrated reject option. In ICML, pp. 2151\u20132159, 2019.\\n\\nYves Grandvalet, Alain Rakotomamonjy, Joseph Keshet, and St\u00e9phane Canu. Support vector machines with a reject option. In NeurIPS, 2008.\\n\\nBo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor W Tsang, and Masashi Sugiyama. Co-teaching: robust training of deep neural networks with extremely noisy labels. In NeurIPS, pp. 8536\u20138546, 2018.\\n\\nSteve Hanneke. The optimal sample complexity of pac learning. The Journal of Machine Learning Research, 17(1):1319\u20131333, 2016.\\n\\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770\u2013778, 2016a.\\n\\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pp. 770\u2013778, 2016b.\\n\\nGao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700\u20134708, 2017.\\n\\nHeinrich Jiang, Been Kim, Melody Y Guan, and Maya R Gupta. To trust or not to trust a classifier. In NeurIPS, pp. 5546\u20135557, 2018.\\n\\nAdam Tauman Kalai, Adam R Klivans, Yishay Mansour, and Rocco A Servedio. Agnostically learning halfspaces. SIAM Journal on Computing, 37(6):1777\u20131805, 2008.\\n\\nMichael Kearns and Ming Li. Learning in the presence of malicious errors. SIAM Journal on Computing, 22(4):807\u2013837, 1993.\\n\\nMichael J Kearns, Robert E Schapire, and Linda M Sellie. Toward efficient agnostic learning. Machine Learning, 17(2-3):115\u2013141, 1994.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nAlex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? In NeurIPS, pp. 5580\u20135590, 2017.\\n\\nPhilip Klein and Neal E Young. On the number of iterations for dantzig\u2013wolfe optimization and packing-covering approximation algorithms. SIAM Journal on Computing, 44(4):1154\u20131172, 2015.\\n\\nAdam R Klivans, Philip M Long, and Rocco A Servedio. Learning halfspaces with malicious noise. Journal of Machine Learning Research, 10(12), 2009.\\n\\nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\\n\\nYann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.\\n\\nZiyin Liu, Zhikang Wang, Paul Pu Liang, Russ R Salakhutdinov, Louis-Philippe Morency, and Masahito Ueda. Deep gamblers: Learning to abstain with portfolio theory. In NeurIPS, 2019.\\n\\nPascal Massart and \u00c9lodie N\u00e9d\u00e9lec. Risk bounds for statistical learning. The Annals of Statistics, 34(5):2326\u20132366, 2006.\\n\\nMehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT press, 2018.\\n\\nNagarajan Natarajan, Inderjit S Dhillon, Pradeep Ravikumar, and Ambuj Tewari. Learning with noisy labels. In NIPS, volume 26, pp. 1196\u20131204, 2013.\\n\\nDavid F Nettleton, Albert Orriols-Puig, and Albert Fornells. A study of the effect of different types of noise on the precision of supervised learning techniques. Artificial intelligence review, 33(4):275\u2013306, 2010.\\n\\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.\\n\\nTim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural networks: Approximately bayesian ensembling. In AISTATS, pp. 234\u2013244, 2020.\\n\\nNorbert Sauer. On the density of families of sets. Journal of Combinatorial Theory, Series A, 13(1):145\u2013147, 1972.\\n\\nHans U Simon. An almost optimal pac algorithm. In Conference on Learning Theory, pp. 1552\u20131563. PMLR, 2015.\\n\\nRuey S Tsay. Analysis of financial time series, volume 543. John wiley & sons, 2005.\\n\\nLeslie Valiant. Probably approximately correct: nature\u00f5s algorithms for learning and prospering in a complex world. Basic Books (AZ), 2013.\\n\\nLeslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134\u20131142, 1984.\\n\\nVladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. In Measures of complexity, pp. 11\u201330. Springer, 2015.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762, 2017.\\n\\nMarten Wegkamp, Ming Yuan, et al. Support vector machines with a reject option. Bernoulli, 17(4):1368\u20131385, 2011.\\n\\nYair Wiener and Ran El-Yaniv. Agnostic selective classification. NeurIPS, 24:1665\u20131673, 2011.\\n\\nHan Xiao, Kashif Rasul, and Roland V ollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.\\n\\nXingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In ICML, pp. 7164\u20137173, 2019.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ming Yuan and Marten Wegkamp. Classification methods with reject option based on convex risk minimization. *JMLR*, 11(1), 2010.\\n\\nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. In *ICLR*, 2017.\\n\\nChong Zhang, Wenbo Wang, and Xingye Qiao. On reject and refine options in multicategory classification. *JASA*, 113(522):730\u2013745, 2018.\\n\\nYikai Zhang, Songzhu Zheng, Pengxiang Wu, Mayank Goswami, and Chao Chen. Learning with feature-dependent label noise: A progressive approach. In *International Conference on Learning Representations*, 2020.\\n\\nSongzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, and Chao Chen. Error-bounded correction of noisy labels. In *ICML*, pp. 11447\u201311457, 2020.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Illustration of Algorithm 1. By up-weighing the informative datapoints, the algorithm progressively improves the classifier. d) shows the sum weight of all informative data over weight sum of all data, i.e.\\n\\n\\\\[ \\\\sum_{i: x_i \\\\in \\\\Omega} \\\\gamma_i \\\\sum_n \\\\gamma_i \\\\]\\n\\n(See \\\\( \\\\gamma \\\\) in Algorithm 1).\\n\\nThe next lemma provides an upper bound on the empirical risk \\\\( R_S(f^*) \\\\), if enough samples are available.\\n\\nLemma 2. Consider a set of samples \\\\( S = \\\\{(x_1, y_1), \\\\ldots, (x_n, y_n)\\\\} \\\\) drawn i.i.d. from the Noisy Generative Process and \\\\( f^* \\\\) in the hypothesis class \\\\( F \\\\) satisfying \\\\( f(x) \\\\in \\\\{-1, +1\\\\} \\\\).\\n\\nIf:\\n\\n\\\\[ n \\\\geq 3 \\\\log(\\\\frac{1}{\\\\delta}) \\\\epsilon^2 \\\\alpha^2 \\\\]\\n\\nThen we have with probability at least \\\\( 1 - \\\\delta \\\\):\\n\\n\\\\[ R_S(f^*) \\\\leq \\\\frac{1}{2}(1 - \\\\alpha) + \\\\alpha \\\\epsilon \\\\]\\n\\nProof: By definition:\\n\\n\\\\[ R(f) = \\\\mathbb{E}_{(x,y) \\\\sim D} \\\\alpha \\\\left[ 1_{f(x) \\\\neq y} \\\\right] \\\\]\\n\\nand the empirical risk\\n\\n\\\\[ R_S(f^*) = \\\\frac{1}{n} \\\\sum_{i=1}^n 1_{f(x_i) \\\\neq y_i} \\\\]\\n\\nNote that \\\\( 1_{f(x) \\\\neq y} \\\\) is bounded in the interval \\\\([0, 1]\\\\) and given \\\\( f^* \\\\in F \\\\), \\\\( 1_{f(x_i) \\\\neq y_i} \\\\), \\\\( i \\\\in [n] \\\\) form a set of \\\\( n \\\\) independent random variables. By setting \\\\( b - a = 1 \\\\), \\\\( t = \\\\alpha \\\\epsilon \\\\) in Equation 9, the choice of \\\\( n \\\\) ensures that\\n\\n\\\\[ -\\\\frac{2 nt^2}{(b-a)^2} \\\\leq 6 \\\\log(\\\\frac{1}{\\\\delta}). \\\\]\\n\\nThus\\n\\n\\\\[ P_{S \\\\sim D} | R_S(f^*) - R(f^*) | \\\\geq \\\\epsilon \\\\alpha \\\\leq \\\\delta. \\\\]\"}"}
{"id": "i4qKmHdq6y8", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022 where we have\\n\\\\[ R(f^*) = \\\\mathbb{E}_{x,y \\\\sim D} \\\\alpha \\\\{ f(x) \\\\neq y \\\\} = \\\\mathbb{E}_{x,y \\\\sim D} \\\\alpha \\\\{ f^*(x) \\\\neq y \\\\} | x \\\\in \\\\Omega \\\\} P[x \\\\in \\\\Omega] \\\\]\\n\\nSince \\\\( y \\\\) is labeled by coin flipping in \\\\( \\\\Omega \\\\), we have:\\n\\\\[ E_{x,y \\\\sim D} \\\\{ f^*(x) \\\\neq y \\\\} \\\\leq P[x \\\\in \\\\Omega] \\\\]\\n\\nBayes Risk in \\\\( \\\\Omega \\\\) is given by\\n\\\\[ \\\\frac{1}{2} (1 - \\\\alpha) \\\\]\\n\\nThis way we have:\\n\\\\[ P[S_n \\\\sim D \\\\alpha, R_{S_n}(f^*) - \\\\frac{1}{2} (1 - \\\\alpha) \\\\geq \\\\epsilon \\\\alpha] \\\\leq \\\\delta. \\\\]\\n\\nwhich implies that Equation 10 holds with probability at least \\\\( 1 - \\\\delta \\\\).\\n\\nThe proof of Lemma 2 relies on the independence between \\\\( f(x_i) \\\\neq y_i \\\\) across different pairs \\\\( (x_i, y_i) \\\\in S_n \\\\). However, there is no guarantee that such independence holds for the empirical minimizer \\\\( f^*_{S_n} = \\\\arg \\\\min_{f \\\\in F} R_{S_n}(f) \\\\).\\n\\nIn order to prove Theorem 1, we use the growth function in Definition 7 for sets of size \\\\( n \\\\) and the following symmetrization lemma. Here we show its proof for completeness; it can be found in different sources (Mohri et al., 2018; Blum et al., 2016).\\n\\nLemma 3. Suppose \\\\( S_n = \\\\{ (x_1, y_1), \\\\ldots, (x_n, y_n) \\\\} \\\\) are i.i.d sampled, \\\\( L(f, x, y) \\\\in [0, b] \\\\) and \\\\( L_{S_n} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} L(f, x_i, y_i) \\\\). If \\\\( nt^2 \\\\geq 2b^2 \\\\) then we have:\\n\\\\[ P[S_n \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L(f)| \\\\geq t] \\\\leq 2 P[S_n, S_n' \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L_{S_n'}(f)| \\\\geq t/2] \\\\]\\n\\nProof: Since \\\\( |L_{S_n}(f) - L(f)| \\\\geq t \\\\) and \\\\( |L_{S_n'}(f) - L(f)| \\\\leq t/2 \\\\) implies \\\\( |L_{S_n} - L_{S_n'}| \\\\geq t/2 \\\\) thus\\n\\\\[ \\\\sup_{f \\\\in F} |L_{S_n}(f) - L(f)| \\\\geq t \\\\]\\n\\nTaking expectation w.r.t \\\\( S_n \\\\sim D \\\\) and \\\\( S_n' \\\\sim D \\\\) we have\\n\\\\[ P[S_n \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L(f)| \\\\geq t] \\\\leq P[S_n, S_n' \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L_{S_n'}(f)| \\\\geq t/2] \\\\]\\n\\nNext we lower bound\\n\\\\[ P[\\\\sup_{f \\\\in F} |L_{S_n'}(f) - L(f)| \\\\geq t/2] \\\\]\\n\\nSince \\\\( L(f, x, y) \\\\in [0, b] \\\\) and \\\\( \\\\text{Var}(L(f, x, y)) \\\\leq b^2/4 \\\\), we have:\\n\\\\[ P[S_n' \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n'}(f) - L(f)| \\\\leq t/2] \\\\]\\n\\n\\\\[ \\\\leq 4 \\\\text{Var}(L_{S_n}(f)) nt^2 \\\\leq \\\\frac{1}{2} \\\\] Given the choice of \\\\( n \\\\geq 2b^2 \\\\), we have\\n\\\\[ P[\\\\sup_{f \\\\in F} |L_{S_n'}(f) - L(f)| \\\\geq t/2] \\\\geq \\\\frac{1}{2} \\\\] which implies\\n\\\\[ P[S_n \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L(f)| \\\\geq t] \\\\leq 2 P[S_n, S_n' \\\\sim D \\\\sup_{f \\\\in F} |L_{S_n}(f) - L_{S_n'}(f)| \\\\geq t/2] \\\\]\\n\\nTheorem 1. Under Assumption 1, given a set of samples \\\\( S_n = \\\\{ (x_1, y_1), \\\\ldots, (x_n, y_n) \\\\} \\\\) drawn i.i.d from the Noisy Generative Process and \\\\( f^*_{S_n} = \\\\arg \\\\min_{f \\\\in F} R_{S_n}(f) \\\\),\"}"}
{"id": "i4qKmHdq6y8", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\n\\\\[ n \\\\geq 32 \\\\left[ \\\\log(4|G \\\\setminus H(2^n)|) + \\\\log(1/\\\\delta) \\\\right] \\\\]\\n\\nThen with probability at least \\\\( 1 - 2\\\\delta \\\\):\\n\\n\\\\[ R(f^* S_n) \\\\leq \\\\frac{1}{2}(1 - \\\\alpha) + 2\\\\epsilon \\\\alpha. \\\\]\\n\\nFurthermore, \\\\( P_{x \\\\sim D} I \\\\left[ f^* (x) \\\\neq f^* S_n(x) \\\\right] \\\\leq 2\\\\epsilon \\\\).\\n\\n**Proof.** We first bound the probability of the event that \\\\( R(f^* S_n) \\\\leq \\\\frac{1}{2}(1 - \\\\alpha) + 2\\\\epsilon \\\\alpha \\\\).\\n\\nWe start with bounding \\\\( P_{S_n, S'_n \\\\sim D} \\\\left[ |R_{S_n}(f) - R(f) + R(f) - R_{S'_n}(f)| \\\\geq t/2 \\\\right] \\\\) for a fixed \\\\( f \\\\).\\n\\nSince \\\\( |R_{S_n}(f) - R(f) + R(f) - R_{S'_n}(f)| \\\\geq t/2 \\\\) implies \\\\( |R_{S_n}(f) - R(f)| \\\\geq t/4 \\\\) or \\\\( |R(f) - R_{S'_n}(f)| \\\\geq t/4 \\\\), we have:\\n\\n\\\\[ P_{S_n, S'_n \\\\sim D} \\\\left[ |R_{S_n}(f) - R(f) + R(f) - R_{S'_n}(f)| \\\\geq t/2 \\\\right] \\\\leq P_{S_n \\\\sim D} \\\\left[ |R_{S_n}(f) - R(f)| \\\\geq t/4 \\\\right] + P_{S'_n \\\\sim D} \\\\left[ |R(f) - R_{S'_n}(f)| \\\\geq t/4 \\\\right] \\\\leq 2e^{-nt/32}. \\\\]\\n\\nLet \\\\( F_{S_n, S'_n} = \\\\{ f(x) : f \\\\in F, x \\\\in S_n \\\\cup S'_n \\\\} \\\\subseteq \\\\{\\\\pm 1\\\\}^{2n} \\\\) with Lemma 3 and Eq 16 we have:\\n\\n\\\\[ P_{S_n \\\\sim D} \\\\left[ \\\\sup_{f \\\\in F_{S_n}} |R_{S_n}(f) - R(f)| \\\\geq t/2 \\\\right] \\\\leq 2 \\\\sum_{f \\\\in F_{S_n, S'_n}} P \\\\left[ |R_{S_n}(f) - R_{S'_n}(f)| \\\\geq t/2 \\\\right] \\\\leq 2 \\\\sum_{f \\\\in F_{S_n, S'_n}} P \\\\left[ |R_{S_n}(f) - R(f) + R(f) - R_{S'_n}(f)| \\\\geq t/2 \\\\right] \\\\leq 4|F_{S_n, S'_n}|e^{-nt/32}. \\\\]\\n\\nBy setting \\\\( t = \\\\alpha \\\\epsilon \\\\) and \\\\( n \\\\geq 32(4 \\\\log(4|G \\\\setminus H(2^n)|) + \\\\log(1/\\\\delta)) \\\\alpha \\\\epsilon^2 \\\\), we have with probability of at least \\\\( 1 - \\\\delta \\\\):\\n\\n\\\\[ R(f^* S_n) - R_{S_n}(f^* S_n) \\\\leq \\\\alpha \\\\epsilon. \\\\]\\n\\nNext we prove the claim that:\\n\\n\\\\[ P_{x \\\\sim D} I \\\\left[ f^* (x) \\\\neq f^* S_n(x) \\\\right] \\\\leq 2\\\\epsilon. \\\\]\"}"}
{"id": "i4qKmHdq6y8", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learning to abstain in the presence of uninformative data\\n\\nAbstract\\n\\nLearning and decision making in domains with naturally high noise-to-signal ratios \u2013 such as Finance or Public Health \u2013 can be challenging and yet extremely important. In this paper, we study a problem of learning on datasets in which a significant proportion of samples does not contain useful information. To analyze this setting, we introduce a noisy generative process with a clear distinction between uninformative/not learnable/purely random data and a structured/informative component. This dichotomy is present both during the training and in the inference phase. We propose a novel approach to learn under these conditions via a loss inspired by the selective learning theory. By minimizing the loss, our method is guaranteed to make a near-optimal decision by simultaneously distinguishing structured data from the non-learnable and making predictions, even in a highly imbalanced setting.\\n\\nIntroduction\\n\\nDespite the success of machine learning in computer vision (Deng et al., 2009; Krizhevsky et al., 2009; He et al., 2016a; Huang et al., 2017) and natural language processing (Vaswani et al., 2017; Devlin et al., 2018), the power of ML is yet to make significant impact in other areas. One major challenge is the inherently high noise-to-signal ratio in certain domains. For example, in Finance, while stock prices generally reflect the information about financial health of their companies, over the short term, their fluctuations most closely resemble random walks - which are naturally unpredictable - and are usually modeled as such (Tsay, 2005). In biomedical research, the underlying phenomena are often highly complex and are affected by unobservable factors. The outcome may appear highly random to the measurements (gene expression, medical histories), if the true causing factor is not included or is overwhelmed by others.\\n\\nWe are interested in dealing with datasets that may contain large fraction of noisy/uninformative/not learnable data in both training and testing stages. Direct application of standard supervised learning methods to such datasets is both challenging and unwarranted. At the training stage, the uninformative data can significantly bias the model or even completely overwhelm the true signal (Nettleton et al., 2010). Therefore, na\u00efve forecasts in majority-uninformative datasets are doomed to be unreliable.\\n\\nCompared to other learning methods, deep neural networks are even more affected by the presence of noise, due to their strong memorization power (Zhang et al., 2017): they are likely to overfit the noise and make overly confident predictions where no real structure exists.\\n\\nIn this paper, we propose a novel method for learning on datasets where a significant portion of content is pure noise. Instead of forcing the classifier to make predictions for every sample, we learn to decide whether a datapoint is informative or not. If successful, the method abstains from making decisions where no structure exists, and predominantly learns from the remaining predictable data.\\n\\nOur idea is inspired by the classic selective prediction problem (Chow, 1957), in which one learns to select a subset of data and only predict on that subset. However, the goal of selective prediction is very different from ours. A selective prediction method considers all data relevant. It pursues a balance between coverage (i.e. proportion of the data selected) and conditional accuracy on the selected data. In our problem, we assume that uninformative data is an integral part of the data generative process. No learning method, no matter how powerful, can be successful on such data.\\n\\nOur goal is to identify these uninformative samples as well as possible, and at the same time, to train a classifier by minimizing conditional risk on the remaining informative data.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our method learns both a predictor, $f$, that classifies samples, and a selector, $g$, that selects learnable data for the predictor and rejects/abstains from the uninformative data. We are using $g$ to approximate the ground truth indicator function of structured/informative data, $g^*$. We assume that $g^*$ exists as a part of the data generation process, but it is never revealed to us, even during training. Instead of direct supervision, we therefore must rely on the predictor's mistakes to train the selector. To achieve this goal, we propose a novel selector loss enforcing that (1) the selected data best fits the predictor, and (2) the portion of the data where we abstain from forecasting, does not contain many correct predictions. This loss function is quite different from the loss in classic selective prediction, which penalizes all unselected data equally.\\n\\nA major contribution of this paper is the derivation of theoretical guarantees for the empirical minimizer of our loss. We analyze the proposed selector loss function and provide sample complexity for learning a nearly optimal selector. We show that optimizing such loss can recover nearly all the structured/informative data in a PAC fashion (Valiant, 1984; Kearns et al., 1994; Valiant, 2013), i.e. one can approximate the ground truth selector function $g^*$ well with high probability, given sufficient samples. What may be surprising is that this guarantee holds even in a challenging setting where the uninformative data represents the majority of the training set.\\n\\nThis theoretical guarantee lets us expand to a more challenging and realistic setting. When the sample size is limited and the initially learned predictor is not sufficiently close to the ground truth, we extend our method to an iterative algorithm, in which we progressively optimize both the predictor and the selector. The selector is improved by optimizing our novel selector loss. Meanwhile, the predictor is improved by optimizing the empirical risk, reweighted based on the selector's output; uninformative or nearly-uninformative samples identified by the selector will be down-weighed. Experiments on real-world datasets demonstrate superiority of our method to existing baselines. Note that in this paper, we assume that each sample is either informative or not. Extending our method to a more general setting with continuous transitions between informative and uninformative is non-trivial and is left as future work.\\n\\n### 1.1 RELATED WORK\\n\\nLearning with untrusted data aims to recover the ground truth model from a partially corrupted dataset. Different noise models for untrusted data have been studied, including random label noise (Bylander, 1994; Natarajan et al., 2013; Han et al., 2018; Yu et al., 2019; Zheng et al., 2020; Zhang et al., 2020), bounded label noise (Massart & N\u00e9d\u00e9lec, 2006; Awasthi et al., 2015; Diakonikolas et al., 2019; 2020) and adversarial noise (Kearns & Li, 1993; Kearns et al., 1994; Kalai et al., 2008; Klivans et al., 2009; Awasthi et al., 2017). In the most pessimistic setting, if the majority data is corrupted by arbitrary adversarial noise, even mean estimation may be impossible. This is known as List-Decodable problem (Balcan et al., 2008; Charikar et al., 2017; Diakonikolas et al., 2018), where the best one can do when the proportion of trusted data $\\\\alpha$ is less than 0.5, is to return $1/\\\\alpha$ many hypotheses of the mean, knowing one of them is promising. We, on the other hand, aim to produce a single accurate model even in a setting where the majority of the data is uninformative (the noise, of course, must be of a certain type, see next section). While above works assume the presence of noisy data only in the training stage, we study the case where noise is an integral part of the generative process and thus will appear during inference as well, where it must be detected and discarded once more.\\n\\nSelective learning is an active research area. It extends the classic selective prediction problem and studies how to select a subset of data for different learning tasks. We can summarize existing methods into 4 categories: Monte Carlo sampling based methods (Gal & Ghahramani, 2016; Kendall & Gal, 2017; Pearce et al., 2020), margin based methods (Fumera & Roli, 2002; Bartlett & Wegkamp, 2008; Grandvalet et al., 2008; Wegkamp et al., 2011; Zhang et al., 2018), confidence based methods (Wiener & El-Yaniv, 2011; Geifman & El-Yaniv, 2017; Jiang et al., 2018) and customized selective loss (Cortes et al., 2016; Geifman & El-Yaniv, 2019; Liu et al., 2019). Notably, several works propose customized losses, and incorporate them into neural networks. In (Geifman & El-Yaniv, 2019), the network maintains an extra output neuron to indicate rejection of datapoints. Liu et al. (2019) use Gambler loss where a cost term is associated with each output neuron and a doubling-rate-like loss function is used to balance rejections and predictions. Cortes et al. (2016) perform data selection with an extra model and introduce a selective loss that helps maximize the coverage ratio, thus trading off a small fraction of data for a better precision.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Existing works on selective prediction are all motivated from the coverage perspective - i.e. one wants to make safe prediction to achieve higher precision while maintain a reasonable recall (El-Yaniv et al., 2010). Whereas our paper is the first to investigate the case where some (or even majority) of the data is uninformative, and thus must be discarded at prediction time. Unlike with the selective prediction, there is a latent ground truth indicator function of whether a datapoint should be selected or not. Our method is guaranteed to identify those uninformative samples.\\n\\n**Problem Formulation**\\n\\nIn this section, we describe the inherently-noisy data generation process that we aim to study. The model has three important features: 1) the uninformative portion of the data has labels generated by coin flipping; 2) the informative datapoints are labeled with a latent ground truth function; and 3) the uninformative data has a distinguishable support from the informative data. Formally:\\n\\n**Definition 1** *(Noisy Generative Process)*\\n\\nWe define the *Noisy Generative Process* by the following notation:\\n\\n\\\\[\\n\\\\begin{align*}\\n&x \\\\sim D_{\\\\alpha} \\\\\\\\\\n&D_{\\\\alpha} \\\\equiv \\\\\\\\\\n&\\\\begin{cases}\\n  x \\\\sim D_U & \\\\text{with prob. } 1 - \\\\alpha \\\\\\\\\\n  x \\\\sim D_I & \\\\text{with prob. } \\\\alpha\\n\\\\end{cases}\\n\\\\end{align*}\\n\\\\]\\n\\n(1)\\n\\nLet \\\\( \\\\Omega_{D} \\\\subseteq \\\\mathbb{R}^d \\\\) be the support of \\\\( D_{\\\\alpha} \\\\). Suppose \\\\( \\\\{\\\\Omega_U, \\\\Omega_I\\\\} \\\\) is a partition of \\\\( \\\\Omega_D \\\\), the ground truth labeling function \\\\( f^* : X \\\\to \\\\{+1, -1\\\\} \\\\) is in hypothesis class \\\\( F \\\\) and data is sampled according to:\\n\\n\\\\[\\n\\\\begin{align*}\\n&x \\\\sim D_{\\\\alpha}; \\\\\\\\\\n&y \\\\equiv \\\\\\\\\\n&\\\\begin{cases}\\n  \\\\text{Bernoulli}(0.5), & \\\\text{if } x \\\\in \\\\Omega_U \\\\\\\\\\n  f^*(x), & \\\\text{if } x \\\\in \\\\Omega_I\\n\\\\end{cases}\\n\\\\end{align*}\\n\\\\]\\n\\n(2)\\n\\nNote that the \\\\( f^* \\\\) is defined on the whole domain, although only the part within \\\\( \\\\Omega_I \\\\) is relevant. \\\\( \\\\alpha \\\\) represents the fraction of informative or structured data in the population. For the rest of the paper, we abuse the notation and use \\\\((x, y) \\\\sim D_{\\\\alpha}\\\\) to refer to samples generated from this process.\\n\\nNext definition describes a separability condition between informative and uninformative data. It allows to distinguish noise from structure and enables us to approximate the ground truth selector via empirical minimization.\\n\\n**Definition 2** *(H\\\\(-\\\\)Separable)*\\n\\nGiven compact set \\\\( \\\\Omega \\\\) and its partition \\\\( \\\\{\\\\Omega_U, \\\\Omega_I\\\\} \\\\), \\\\( \\\\{\\\\Omega_U, \\\\Omega_I\\\\} \\\\) satisfies the H\\\\(-\\\\)Separable condition if there exists \\\\( g^* \\\\in H \\\\) satisfying:\\n\\n\\\\[\\n\\\\begin{align*}\\n&g^*: X \\\\to \\\\{+1, -1\\\\} \\\\\\\\\\n&g^*(x) \\\\equiv \\\\\\\\\\n&\\\\begin{cases}\\n  -1, & \\\\text{if } x \\\\in \\\\Omega_U \\\\\\\\\\n  1, & \\\\text{if } x \\\\in \\\\Omega_I\\n\\\\end{cases}\\n\\\\end{align*}\\n\\\\]\\n\\n(3)\\n\\nOne can view \\\\( g^*(\\\\cdot) \\\\) in definition 2 as the target selector we wish to recover. Having introduced the data generation process and the separability condition, we now describe our main assumption for the remainder of the paper.\\n\\n**Assumption 1.** Data \\\\( S_n = \\\\{x_i, y_i\\\\}_{i=1}^N \\\\) is i.i.d generated according to the *Noisy Generative Process* (Definition 1), with \\\\( f^* \\\\in F \\\\), support \\\\( \\\\Omega_{D_{\\\\alpha}} = \\\\Omega_U \\\\cup \\\\Omega_I \\\\) where \\\\( \\\\Omega_U, \\\\Omega_I \\\\) are H\\\\(-\\\\)Separable.\\n\\nThroughout this paper, we are interested in the following learning task:\\n\\n**Problem 1** *(Abstain from Uninformative Data)*\\n\\nUnder Assumption 1 with enough i.i.d observations from \\\\( D_{\\\\alpha} \\\\): 1) given hypothesis class \\\\( F \\\\), we aim to learn the underlying ground truth classifier \\\\( f^*(x) \\\\); and 2) given the hypothesis class \\\\( H \\\\), we aim to learn the selector \\\\( g^*(x) \\\\).\\n\\n**Evaluation metrics.** We define metrics to evaluate the quality of both the prediction and the selection. For the prediction, we borrow the selective risk definition from selective learning (El-Yaniv et al., 2010; Geifman & El-Yaniv, 2019; 2017) using our own notation.\\n\\n**Definition 3** *(Selective Risk)*\\n\\nGiven a predictor \\\\( f \\\\in F \\\\) and a selector \\\\( g \\\\in H \\\\), we define the selective risk as:\\n\\n\\\\[\\nCR(f, g) = \\\\mathbb{E}_{(x, y) \\\\sim D_{\\\\alpha}} \\\\left[ 1 \\\\{ f(x) \\\\neq y \\\\} \\\\mid g(x) \\\\geq 0 \\\\right]\\n\\\\]\\n\\nand its empirical version:\\n\\n\\\\[\\nCR_S(f, g) = \\\\frac{1}{N} \\\\sum_{i=1}^{N} 1 \\\\{ f(x_i) \\\\neq y_i \\\\} 1 \\\\{ g(x_i) \\\\geq 0 \\\\}\\n\\\\]\\n\\nSelective risk measures the average risk conditioned on instances that are picked by the selector \\\\( g(x) \\\\). Note here when combined with the ground truth selector \\\\( g^* \\\\), the selective risk of the ground truth selector.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"predictor \\\\( f^* \\\\) goes to zero. Without a selector, however, \\\\( f^* \\\\) has classical classification risk (which will be formally defined in Definition 5 later) of more than \\\\( \\\\frac{1}{2}(1 - \\\\alpha) \\\\).\\n\\nThe metric used to evaluate the quality of a learned selector \\\\( g \\\\) is its false positive/negative rate. When \\\\( g(x) \\\\geq 0 \\\\) and \\\\( g^*(x) < 0 \\\\), the selector \\\\( g \\\\) accepts an uninformative datapoint and thus commits a false positive error. When \\\\( g(x) < 0 \\\\) and \\\\( g^*(x) \\\\geq 0 \\\\), \\\\( g \\\\) rejects/abstains from an informative datapoint resulting in a false negative error.\\n\\n**Definition 4 (Evaluation Metric for the Selector).**\\n\\nGiven distribution \\\\( D_\\\\alpha \\\\) as defined in Definition 1 and \\\\( g^* \\\\) as target selector, we denote the false positive and false negative of a selector \\\\( g \\\\) as\\n\\n- **False Positive:** \\\\( P[g(x) \\\\geq 0 | g^*(x) < 0] \\\\)\\n- **False Negative:** \\\\( P[g(x) < 0 | g^*(x) \\\\geq 0] \\\\)\\n\\nIn this section, we present our approach for learning and abstaining in the presence of uninformative data (Problem 1). The main challenge is that the latent informative/uninformative status of a datapoint is unknown. Our main idea is to introduce a novel selector loss function that trains a selector based on the performance of the best predictor (Section 3.1). In Section 3.2, we present our main theoretical result. We show that by jointly finding a predictor minimizing the classification risk and finding a selector minimizing the proposed selector loss, we can solve Problem 1 with controlled selective risk and selector error rates. During the analysis, we assume an oracle is given for the empirical minimizer. Approximating such empirical minimizer is a different topic beyond the scope of this paper (Bartlett et al., 2006; Yuan & Wegkamp, 2010). Inspired by the theoretical results, in Section 3.3, we propose a heuristic algorithm that iteratively optimizes the predictor and the selector.\\n\\nThroughout the analysis, we focus on the 0-1 classification loss to optimize the predictor. This follows the standard for analyzing generalization performance and sample complexity. Formally:\\n\\n**Definition 5 (Classification Risk).**\\n\\nWe denote the classification risk of a model \\\\( f \\\\) as\\n\\n\\\\[\\nR(f) \\\\equiv E_{(x,y) \\\\sim D_\\\\alpha} \\\\left[ \\\\mathbb{1}\\\\{f(x) \\\\neq y\\\\} \\\\right]\\n\\\\]\\n\\nand the empirical classification risk:\\n\\n\\\\[\\nR_S^n(f) = \\\\frac{1}{n} \\\\sum_{i=1}^{n} \\\\mathbb{1}\\\\{f(x_i) \\\\neq y_i\\\\}\\n\\\\]\\n\\nWe define \\\\( f^*_S \\\\) to be the empirical minimizer of \\\\( R_S^n(f) \\\\):\\n\\n\\\\[\\nf^*_S = \\\\arg \\\\min_{f \\\\in F} R_S^n(f)\\n\\\\]\\n\\n**3.1 Selector Loss**\\n\\nTo learn a selector without direct supervision, we have to leverage the performance of a given predictor, \\\\( f \\\\). We propose the selector loss, which reweighs the 0-1 loss based on the prediction of \\\\( f \\\\).\\n\\nThis loss penalizes when (1) the predictor makes a correct prediction on a datapoint that the selector considers uninformative and abstains from, or (2) the predictor makes an incorrect prediction on a datapoint that the selector considers informative.\\n\\n**Definition 6 (Selector Loss).**\\n\\nGiven \\\\( f \\\\in F \\\\) and its selector \\\\( g \\\\in H \\\\), we define the following weighted 0-1 type risk w.r.t \\\\( g(\\\\cdot) \\\\) as selector risk:\\n\\n\\\\[\\nW(g; f, \\\\theta) \\\\equiv E_{(x,y) \\\\sim D_\\\\alpha} \\\\left[ \\\\theta \\\\alpha \\\\mathbb{1}\\\\{f(x) \\\\neq y\\\\} \\\\mathbb{1}\\\\{g(x) > 0\\\\} + (1 - \\\\theta) \\\\alpha \\\\mathbb{1}\\\\{f(x) = y\\\\} \\\\mathbb{1}\\\\{g(x) \\\\leq 0\\\\} \\\\right]\\n\\\\]\\n\\nand its empirical version:\\n\\n\\\\[\\nW_S^n(g; f, \\\\theta) = \\\\frac{1}{n} \\\\sum_{i=1}^{n} \\\\theta \\\\alpha \\\\mathbb{1}\\\\{f(x_i) \\\\neq y_i\\\\} \\\\mathbb{1}\\\\{g(x_i) > 0\\\\} + (1 - \\\\theta) \\\\alpha \\\\mathbb{1}\\\\{f(x_i) = y_i\\\\} \\\\mathbb{1}\\\\{g(x_i) \\\\leq 0\\\\}\\n\\\\]\\n\\nIntuitively speaking, the loss will drive the selector to partition the domain into informative and uninformative regions. Within the informative region, the predictor is supposed to fit the data well, and should be more accurate. Meanwhile, within the uninformative region, the label is random and the predictor is supposed to be more prone to error. Another view of the loss is that we are learning to fit the selector \\\\( g(x) \\\\) to a pseudo-informative label given by the predictor, \\\\( 1\\\\{f(x) = y\\\\} \\\\). Since such label is \\\\( f \\\\)-dependent, the quality of \\\\( f \\\\) is crucial for successfully learning \\\\( g \\\\). In the theoretical analysis, we leverage the fact that predictor \\\\( f \\\\) is close enough to the ground truth predictor \\\\( f^* \\\\).\"}"}
{"id": "i4qKmHdq6y8", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022\\n\\nTheorem 4. In the case where only an upper bound on $\\\\alpha$ is given\\n\\nTheorem 5. Under Assumption 1, given set of samples $S_n = \\\\{(x_1, y_1), \\\\ldots, (x_n, y_n)\\\\}$ drawn i.i.d. from the Noisy Generative Process with $\\\\alpha \\\\in (0, 1 - \\\\xi)$, $\\\\xi \\\\geq 0$. Hypothesis class $H$ with VC-dimension $d_{vc}(H)$, $F$ with VC-dimension $d_{vc}(F)$ and $f^*_S S_n = \\\\arg\\\\min_{f \\\\in F} R_S(f)$, $g^*_S S_n = \\\\arg\\\\min_{g \\\\in H} W_{S_n}(g, f^*_S S_n, \\\\theta)$.\\n\\nIf $\\\\theta \\\\in \\\\left(\\\\frac{73}{72} \\\\alpha, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\alpha\\\\right)$ and $n \\\\geq 3200 \\\\left[d_{vc}(H) + d_{vc}(F) \\\\log(1/\\\\epsilon) + \\\\log(16/\\\\delta)\\\\right] \\\\epsilon^2 \\\\alpha^2$. We have with probability at least $1 - \\\\delta$:\\n\\nI) $P[g^*_S S_n(x) \\\\geq 0 | g^*_S S_n(x) \\\\leq 0] = O(\\\\epsilon) \\\\ [False Positive]$  \\nII) $P[g^*_S S_n(x) < 0 | g^*_S S_n(x) \\\\geq 0] \\\\leq O(\\\\epsilon) \\\\ [False Negative] (39)$  \\nIII) Further more, to obtain $g^*_S S_n = \\\\arg\\\\min_{g \\\\in H} W_{S_n}(g, f^*_S S_n, \\\\theta)$ it suffices to minimize following loss with $\\\\beta \\\\in \\\\left(1 + \\\\frac{1}{73} \\\\xi - \\\\frac{1}{144}, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\right)$:\\n\\n$$Loss(g; f^*_S S_n, S_n, \\\\beta) = \\\\sum_{i=1}^{n} \\\\left\\\\{ \\\\beta \\\\mathbb{1}\\\\{f^*_S S_n(x_i) \\\\neq y_i\\\\} \\\\mathbb{1}\\\\{g(x_i) > 0\\\\} + \\\\mathbb{1}\\\\{f^*_S S_n(x_i) = y_i\\\\} \\\\mathbb{1}\\\\{g(x_i) \\\\leq 0\\\\} \\\\right\\\\}$$\\n\\nProof. I) above can be proved by picking $c \\\\in \\\\left(\\\\frac{1}{2} + \\\\frac{1}{144}, \\\\frac{1}{2} + \\\\min\\\\{9/2, \\\\xi^4(1 - \\\\xi)\\\\}\\\\right)$ in Theorem 3. Note this range is valid since $\\\\alpha \\\\leq 1 - \\\\xi$, we have $\\\\alpha \\\\leq 1 - \\\\xi \\\\iff \\\\alpha \\\\frac{1}{1 - \\\\xi} \\\\leq 1 \\\\iff \\\\frac{1}{1 - \\\\alpha} \\\\xi \\\\geq 1 \\\\iff \\\\frac{1}{2} \\\\xi \\\\leq 1 - \\\\frac{1}{2} \\\\alpha \\\\iff \\\\frac{1}{2} \\\\xi \\\\leq 1 - \\\\frac{1}{2} \\\\alpha \\n\\n\\\\left(40\\\\right)$\\n\\nBy a procedure similar to Theorem 4 (using the Sauer's Lemma) we have I). Note $c \\\\in \\\\left(\\\\frac{1}{2} + \\\\frac{1}{144}, \\\\frac{1}{2} + \\\\min\\\\{9/2, \\\\xi^4(1 - \\\\xi)\\\\}\\\\right) \\\\iff \\\\theta \\\\in \\\\left(\\\\frac{73}{72} \\\\alpha, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\right)$. II) can be proved by observing that I) implies $P[g^*_S S_n(x) \\\\neq g^*_S S_n(x)] = O(\\\\epsilon)$ and by invoking Theorem 1. Next we prove III). It is easy to verify that the minimizer of $W_{S_n}(g, f^*_S S_n)$ is equivalent to minimizer of $Loss(g; f^*_S S_n, S_n, \\\\beta)$ (by replacing $\\\\beta = \\\\theta(1 - \\\\alpha)$). It suffices to analyze that $\\\\beta \\\\in \\\\left(1 + \\\\frac{1}{73} \\\\xi - \\\\frac{1}{144}, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\right)$ implies that $\\\\theta \\\\in \\\\left(\\\\frac{73}{72} \\\\alpha, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\right)$. First note that $x_1 - x_2$ is monotone increasing in $(0, 1)$, it suffices to compute image of $\\\\theta(1 - \\\\alpha) \\\\alpha (1 - \\\\theta)$ and check if $\\\\beta \\\\in \\\\left(1 + \\\\frac{1}{73} \\\\xi - \\\\frac{1}{144}, \\\\min\\\\{1 + \\\\xi^2(1 - \\\\xi), 10\\\\} \\\\right)$ stays in such range.\\n\\nIt can be easily verified that $\\\\alpha \\\\leq 1 - \\\\xi$ implies the lower bound $1 + \\\\frac{1}{73} \\\\xi - \\\\frac{1}{144}$ and $\\\\alpha > 0$ implies the upper bound $1 + \\\\xi^2(1 - \\\\xi)$.\\n\\nWe provide an ablation study where we vary the hyper-parameter in each baseline. For SelectiveNet, we first fix $\\\\lambda$ to be 32 (default setting that is recommended by the author in the original paper) and then we vary $a$ from 0.1 to 0.7. Then we fix $a$ to be 0.5 (default setting) and then we vary $\\\\lambda$.  \\n\\n\"}"}
{"id": "i4qKmHdq6y8", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Under review as a conference paper at ICLR 2022 from 1 to 66. For DeepGambler, we vary $o$ from 1 to 7. Finally, for our algorithm, we increase the hyper-parameter $\\\\beta$ to 10. We can see that the performance of all baselines are quite sensitive to the choice of hyper-parameter and will experience some large fluctuation. On the contrast, our algorithm is stable against the choice of hyper-parameter. This empirical observation supports that there exists a wide range of $\\\\beta$ so that one can control the FNR and FPR if $\\\\alpha$ is bounded away from 1 as it is implied in Theorem 5. Furthermore, in all scenario, our algorithm's performance is better than these two baselines in two sense. On one hand, our selector has better precision such that we can recover almost all informative data while the other two cannot. These two baseline tend to to select the whole data set indistinguishably (low precision and high recall). On the other hand, these baselines show consistently deteriorated risk performance than ours because of their selector fails to pick informative data.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Ablation Study on Hyper-parameter $a$ and $\\\\lambda$ - SelectiveNet.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"By Theorem 1 we have with failure probability at most $2^{-\\\\alpha} \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow \\\\Rightarrow"}
{"id": "i4qKmHdq6y8", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Combining Equations 25, 26, 28, 29 we have:\\n\\n\\\\[ W(g^* S_n, f^* S_n, \\\\theta) \\\\geq \\\\left\\\\{ \\\\theta \\\\left(1 - \\\\alpha \\\\right) - 1 - \\\\theta^2 \\\\right\\\\} P_{x \\\\sim D}[g^* S_n(x) > 0 | g^* (x) \\\\leq 0] + 1 - \\\\theta^2 + \\\\alpha \\\\left(1 - \\\\theta \\\\right) 1 - \\\\alpha P_{x \\\\sim D}[g^* S_n(x) \\\\leq 0 | g^* (x) > 0] - 2(1 - \\\\theta) \\\\alpha \\\\epsilon \\\\]\\n\\nand by part I in the theorem, we have with probability at least \\\\(1 - 3\\\\delta\\\\):\\n\\n\\\\[ W(g^* S_n, f^* S_n, \\\\theta) \\\\leq 2\\\\epsilon \\\\theta + 2\\\\alpha \\\\epsilon + (1 - \\\\theta)^2 \\\\]\\n\\nCombined with the failure probability \\\\(2\\\\delta\\\\) in the bound of Term 3 we have the failure probability at most \\\\(5\\\\delta\\\\):\\n\\n\\\\[ \\\\left\\\\{ \\\\theta \\\\left(1 - \\\\alpha \\\\right) - 1 - \\\\theta^2 \\\\right\\\\} P_{x \\\\sim D}[g^* S_n(x) > 0 | g^* (x) \\\\leq 0] + 1 - \\\\theta^2 + \\\\alpha \\\\left(1 - \\\\theta \\\\right) 1 - \\\\alpha P_{x \\\\sim D}[g^* S_n(x) \\\\leq 0 | g^* (x) > 0] - 2(1 - \\\\theta) \\\\alpha \\\\epsilon \\\\]\\n\\nBy picking \\\\(\\\\theta = \\\\frac{2}{c\\\\alpha}\\\\) with \\\\(\\\\frac{1}{2} < c < 1 + \\\\frac{\\\\alpha}{4}\\\\alpha\\\\) we can ensure that 1) \\\\(\\\\theta^2 \\\\alpha - 1 > 0\\\\); 2) \\\\(\\\\alpha \\\\left(1 - \\\\theta \\\\right) 1 - \\\\alpha \\\\geq \\\\alpha^2\\\\). Finally we have:\\n\\n\\\\[ \\\\left\\\\{ c - \\\\frac{1}{2} \\\\right\\\\} P_{x \\\\sim D}[g^* S_n(x) > 0 | g^* (x) \\\\leq 0] \\\\leq 4c\\\\alpha \\\\epsilon + 4\\\\alpha \\\\epsilon \\\\]\\n\\nand\\n\\n\\\\[ \\\\alpha \\\\left(1 - \\\\theta \\\\right) 1 - \\\\alpha P_{x \\\\sim D}[g^* S_n(x) \\\\leq 0 | g^* (x) > 0] \\\\leq 12c\\\\alpha \\\\epsilon \\\\\\\\\\n\\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\quad \\\\"}
{"id": "i4qKmHdq6y8", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"If \\\\( \\\\alpha \\\\in (0, 0.9) \\\\) and:\\n\\n\\\\[\\n\\\\begin{align*}\\n  &n \\\\geq 128, \\\\\\\\\\n  &\\\\left\\\\lfloor (\\\\text{dvc}(H) + \\\\text{dvc}(F)) \\\\log(1/\\\\varepsilon) + \\\\log(16/\\\\delta) \\\\right\\\\rfloor \\\\epsilon^2 \\\\alpha^2\\n\\\\end{align*}\\n\\\\]\\n\\nWe have with probability at least \\\\( 1 - \\\\delta \\\\):\\n\\nI) \\\\( P\\\\left[ g^* \\\\sum x \\\\geq 0 \\\\mid g^*(x) \\\\leq 0 \\\\right] = O(\\\\epsilon) \\\\) (False Positive) (34)\\n\\n\\\\( P\\\\left[ g^* \\\\sum x < 0 \\\\mid g^*(x) \\\\geq 0 \\\\right] \\\\leq O(\\\\epsilon) \\\\) (False Negative) (35)\\n\\nII) \\\\( P_{x \\\\sim D}{\\\\alpha}[f^*(x) \\\\neq f^* x] | g^* x \\\\geq 0] = O(\\\\epsilon) \\\\)\\n\\nProof. I) above can be proved by observing \\\\( c = 1 + \\\\frac{72}{\\\\alpha^2} \\\\) and applying Theorem 3 with Sauer's Lemma to bound the growth function in terms of VC-dimension. Also notice that \\\\( c = 1 + \\\\frac{72}{\\\\alpha^2} \\\\in (\\\\frac{1}{2}, 1 + \\\\frac{\\\\alpha}{4}) \\\\) given \\\\( \\\\alpha < 0.9 \\\\).\\n\\nII) can be proved by observing that I) implies \\\\( P\\\\left[ g^* \\\\sum x \\\\neq g^* x \\\\right] = O(\\\\epsilon) \\\\) and by invoking Theorem 1.\\n\\nRemark 3. Let us point out that our proposed selective strategy is different from the consistent selective strategy in (El-Yaniv et al., 2010). Instead of rejecting by looking for consistent output from all hypothesis in the version space, our approach deals with one single reasonably accurate hypothesis (the empirical minimizer). We leverage empirical mistakes made by the predictor in order to learn a selector, aiming to reject (only) the mistakes in a data driven manner. This avoids dealing with the issues found in Theorem 14 in (El-Yaniv et al., 2010), where the selector fails to select any data points.\\n\\nRemark 4. In (Cortes et al., 2016), a second hypothesis for the selector is introduced and analyzed, and at the same time, multiple commonly used loss functions are scrutinized and generalization results are provided. The major difference between this work and (Cortes et al., 2016; Geifman & El-Yaniv, 2019) is the motivation pertaining to selective learning. While in (Cortes et al., 2016; Geifman & El-Yaniv, 2019) the selective loss is designed from a coverage ratio perspective, i.e. one wants to trade coverage ratio for a higher precision (selective loss), our approach is designed to distinguish data that is naturally unlearnable and unpredictable. This difference leads to an alternative theoretical result. While the analysis in (Cortes et al., 2016) focuses on selective risk, our theoretical analysis focuses on the quality of the selector in terms of both the false positive and false negative errors with the final goal of rejecting uninformative data with high probability.\\n\\nC T I G H T N E S S A N A L Y S E\\n\\nIn this section, we investigate whether it is necessary to have \\\\( \\\\tilde{\\\\Omega}(d_{\\\\text{vc}}(H) + d_{\\\\text{vc}}(F)) \\\\alpha^2 \\\\epsilon^2 \\\\) samples to achieve \\\\( P_{x \\\\sim D}{\\\\alpha}[f^*(x) \\\\neq f^* x] | g^* x \\\\geq 0] = O(\\\\epsilon) \\\\) and\\n\\n\\\\[\\n\\\\max\\\\{P\\\\left[ g^* \\\\sum x \\\\neq g^* x \\\\mid g^*(x) > 0 \\\\right], P\\\\left[ g^* \\\\sum x \\\\neq g^* x \\\\mid g^*(x) \\\\leq 0 \\\\right]\\\\} = O(\\\\epsilon)\\n\\\\]\\n\\nWe will show that there exists a distribution \\\\( D_{\\\\alpha} \\\\) among the Noisy Generative Process family and hypothesis class \\\\( H, F \\\\) such that achieving guarantees in Theorem 4 requires \\\\( \\\\tilde{\\\\Omega}(d_{\\\\text{vc}}(H) + d_{\\\\text{vc}}(F)) \\\\alpha^2 \\\\epsilon^2 \\\\) samples, thus making our analysis tight within logarithmic factor. Note that our lower bound is for empirical minimizers of \\\\( R(f) \\\\) and \\\\( W(g, f, \\\\theta) \\\\); it only illustrates the tightness of our analysis, and thus is not an information theoretic bound for this family of problem - it remains unknown whether strategies other than the empirical minimization of \\\\( R(f) \\\\) and \\\\( W(g, f, \\\\theta) \\\\) can improve sample complexity to a rate of \\\\( \\\\frac{1}{\\\\alpha \\\\epsilon} \\\\), observing that the informative data is realizable, which usually only requires \\\\( \\\\tilde{O}(1/\\\\epsilon) \\\\) samples for an \\\\( \\\\epsilon \\\\) statistical error. Our construction leverages the idea from (Ehrenfeucht et al., 1989) about the support of the informative data. Over the support of uninformative data, noise buries the signal of the informative data, thus misleading the empirical minimizer. In our analysis, we will leverage the anti-concentration results of the Chernoff bound, with the proof idea that comes from (Klein & Young, 2015):\"}"}
{"id": "i4qKmHdq6y8", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Lemma 6\\n(tightness of the Chernoff bound)\\n\\nLet \\\\( X \\\\) be the average of \\\\( k \\\\) independent, 0/1 random variables (r.v.). For any \\\\( \\\\epsilon \\\\in (0, 1/2] \\\\) and \\\\( p \\\\in (0, 1/2] \\\\), assuming \\\\( \\\\epsilon pk \\\\geq 6 \\\\), \\\\( pk \\\\geq 6 \\\\), \\\\( \\\\epsilon \\\\leq 1/3 \\\\), we have:\\n\\n- If each r.v. is 1 with probability \\\\( p \\\\), then\\n  \\\\[\\n  \\\\Pr[X \\\\leq (1 - \\\\epsilon)p] \\\\geq e^{-6\\\\epsilon^2 pk}.\\n  \\\\]\\n\\n- If each r.v. is 1 with probability \\\\( p \\\\), then\\n  \\\\[\\n  \\\\Pr[X \\\\geq (1 + \\\\epsilon)p] \\\\geq e^{-6\\\\epsilon^2 pk}.\\n  \\\\]\\n\\nProof. The proof is similar to Lemma 5.2 in (Klein & Young, 2015) with a different choice of parameters. With Stirling\u2019s approximation,\\n\\n\\\\[\\ni! = \\\\sqrt{2\\\\pi i} \\\\left(\\\\frac{i}{e}\\\\right)^i \\\\text{ with } \\\\lambda \\\\in \\\\left[\\\\frac{1}{(12i + 1)}, \\\\frac{1}{12i}\\\\right]\\n\\\\]\\n\\none can show:\\n\\n\\\\[\\n\\\\binom{k}{\\\\ell} \\\\geq 1 e^{\\\\sqrt{2\\\\pi \\\\ell} \\\\left(\\\\frac{k}{\\\\ell} - \\\\ell - k\\\\right)} (36)\\n\\\\]\\n\\nAlso note:\\n\\n\\\\[\\n\\\\Pr[X \\\\leq (1 - \\\\epsilon)p] = \\\\sum_{i=0}^{(1 - 2\\\\epsilon)p k} (1 - \\\\epsilon)p^i \\\\Pr[X = i k].\\n\\\\]\\n\\nLet \\\\( \\\\ell = \\\\lfloor (1 - 2\\\\epsilon)p k \\\\rfloor \\\\). Given the fact that \\\\( \\\\epsilon pk \\\\geq 6 \\\\), we have \\\\( (1 - 2\\\\epsilon)p k - 1 \\\\leq \\\\ell \\\\leq (1 - 2\\\\epsilon)p k \\\\). It suffices to lower bound\\n\\n\\\\[\\n\\\\sum_{i=(1 - 2\\\\epsilon)p k}^{(1 - 2\\\\epsilon)p k} (1 - \\\\epsilon)p^i \\\\Pr[X = i k] \\\\geq (1 - 2\\\\epsilon)p \\\\Pr[X = \\\\ell k].\\n\\\\]\\n\\nFrom Equation 36 we know that we need to bound\\n\\n\\\\[\\nA = 2 e^{\\\\epsilon pk}/\\\\sqrt{2\\\\pi \\\\ell} \\\\quad \\\\text{and} \\\\quad B = \\\\binom{k}{\\\\ell} \\\\ell \\\\left(\\\\frac{k}{\\\\ell} - \\\\ell - k\\\\right)k^{-\\\\ell} \\\\left(1 - p\\\\right)^{k - \\\\ell}.\\n\\\\]\\n\\nFor term \\\\( A \\\\), since \\\\( \\\\epsilon pk \\\\geq 6 \\\\), \\\\( \\\\ell \\\\leq (1 - 2\\\\epsilon)p k \\\\) thus we need \\\\( pk \\\\geq 9 e - 2\\\\epsilon/\\\\epsilon \\\\) to get \\\\( 2\\\\epsilon \\\\sqrt{pk} e^{\\\\sqrt{2\\\\pi \\\\frac{1}{12i}}} \\\\geq e^{-\\\\epsilon^2 pk} \\\\). Since \\\\( \\\\epsilon \\\\leq 1/3 \\\\), it suffices to have \\\\( pk \\\\geq 16 \\\\).\\n\\nTo bound \\\\( B \\\\) we need to show:\\n\\n\\\\[\\n\\\\binom{k}{\\\\ell} \\\\ell \\\\left(\\\\frac{k}{\\\\ell} - \\\\ell - k\\\\right)k^{-\\\\ell} \\\\left(1 - p\\\\right)^{k - \\\\ell} \\\\geq e^{-4\\\\epsilon^2 pk}.\\n\\\\]\\n\\nSince \\\\( \\\\binom{k}{\\\\ell} \\\\ell \\\\left(\\\\frac{k}{\\\\ell} - \\\\ell - k\\\\right)k^{-\\\\ell} \\\\geq \\\\left(\\\\frac{1}{12i}\\\\right)^{\\\\ell} \\\\) and \\\\( \\\\left(1 - p\\\\right)^{k - \\\\ell} \\\\left(1 - p\\\\right)^{k - \\\\ell} = \\\\left(\\\\frac{1}{12i} + 1\\\\right)^{k - \\\\ell} \\\\), we have:\\n\\n\\\\[\\n(1 - 2\\\\epsilon)p k - 1 \\\\leq \\\\frac{1}{12i} + 1 + 2\\\\epsilon pk - 2\\\\epsilon pk + 4\\\\epsilon^2 pk + 2\\\\epsilon \\\\leq e^{5\\\\epsilon^2 pk} (1 - \\\\epsilon/2).\\n\\\\]\\n\\nWe consider the following distribution. Let \\\\( d_{vc}(F) = d \\\\) and \\\\( e_j \\\\) be the standard basis with \\\\( j \\\\)-th coordinate equal to 1 and 0 otherwise. We set \\\\( \\\\Omega_j U = \\\\{+2, -2\\\\} e_j \\\\), \\\\( \\\\Omega_j I = \\\\{+1, -1\\\\} e_j \\\\), \\\\( \\\\Omega_I U = \\\\bigcup_{d_j=1} \\\\Omega_j U \\\\) and \\\\( \\\\Omega_I I = \\\\bigcup_{d_j=1} \\\\Omega_j I \\\\). Let \\\\( F = \\\\text{sign}(w^\\\\top x) \\\\) and \\\\( H = 2 \\\\prod_{n_i=1} g_j(x) - 1 \\\\), where \\\\( g_j(x) \\\\in \\\\{ |e_j^\\\\top x| \\\\geq c \\\\} \\\\cup \\\\{ 0 \\\\} \\\\).\\n\\nBy Lemma 3.2.3 in (Blumer et al., 1989) we know \\\\( d_{vc}(H) \\\\leq 6 d \\\\log(d) \\\\).\\n\\nWe construct \\\\( D_\\\\alpha \\\\) as follows: in \\\\( \\\\Omega_U \\\\), each standard basis has \\\\( 1 - \\\\alpha d \\\\) mass with sign generated via coin flipping (fair). Having generated \\\\( x, y \\\\in \\\\{+1, -1\\\\} \\\\) is generated via a coin flipping. In \\\\( \\\\Omega_I \\\\), we put \\\\( \\\\alpha (1 - \\\\epsilon) d \\\\) mass on \\\\( e_1 \\\\) and \\\\( \\\\alpha \\\\epsilon d - 1 \\\\) mass on other standard basis \\\\( e_j \\\\), with sign generated via a (fair) coin flipping. Having generated \\\\( x, y \\\\in \\\\{+1, -1\\\\} \\\\) is generated via \\\\( \\\\text{sign}(w^\\\\star \\\\top x) \\\\) where \\\\( w^\\\\star \\\\) denotes a vector of ones. The above construction allows one to calculate the expected error by counting the number of basis that are not learned correctly, i.e., each \\\\( j \\\\in [d] \\\\) s.t. \\\\( w_j < 0 \\\\) implies an error \\\\( \\\\alpha \\\\epsilon^2 (d - 1) \\\\) in expectation. Since:\\n\\n\\\\[\\nE_{S_n \\\\sim D_\\\\alpha} [\\\\|S_n \\\\cap \\\\Omega_I \\\\|] = \\\\alpha \\\\epsilon n d - 1,\\n\\\\]\\n\\nby Markov inequality we have:\\n\\n\\\\[\\nPr_{S_n \\\\sim D_\\\\alpha} [\\\\|S_n \\\\cap \\\\Omega_I \\\\| \\\\geq 6 \\\\alpha \\\\epsilon n d - 1] \\\\leq \\\\frac{1}{6}.\\n\\\\]\"}"}
{"id": "i4qKmHdq6y8", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"interested in the case where\\n\\nNext we analyze the weighted risk in Definition 6 and its empirical version. In particular, we are\\n\\nSince\\n\\n\\\\[ R_{W}(f) = E \\\\theta \\\\]\\n\\n\\\\[ \\\\leq \\\\theta \\\\]\\n\\n\\\\[ \\\\frac{1}{2}(1 - \\\\frac{1}{2} - \\\\frac{1}{2}) \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ E \\\\]\\n\\n\\\\[ E \\\\]\\n\\n\\\\[ E \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\"}
{"id": "i4qKmHdq6y8", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"One can see that if $\\\\theta > \\\\alpha$, then $g(x)$ should reject all $x \\\\in \\\\Omega$ since $\\\\theta > 1 - \\\\theta > 1 - \\\\alpha$. For the informative partition $x \\\\in \\\\Omega_I$, the decomposition suggests acceptance of all $x$ such that $f(x) = y$ and rejection of $f(x) \\\\neq y$. This gives the optimal value $1 - \\\\theta^2(1 - \\\\alpha)P_{x \\\\sim D}\\\\{g^*(x) \\\\leq 0\\\\}$. Note that the optimal value of $W(g,f,\\\\theta)$ is not necessarily achieved at $(f^*, g^*)$. For any fixed $f$, the optimal value of $W(g,f,\\\\theta)$ is achieved for $g$ as long as $g$ accepts all datapoints in $\\\\Omega_I$ that are correctly classified by $f$, and rejects all mistakes made by $f$ in $\\\\Omega_I$ (as well as all datapoints in $\\\\Omega_U$).\\n\\nLemma 4. Given a set of samples $S_n = \\\\{(x_1, y_1), \\\\ldots, (x_n, y_n)\\\\}$ drawn i.i.d. from the Noisy Generative Process. Suppose $\\\\theta \\\\in (\\\\alpha, 1), \\\\alpha \\\\in (0, 1), \\\\epsilon \\\\leq 0.1, n \\\\geq 2\\\\theta^2 \\\\log\\\\left(\\\\frac{1}{\\\\delta}\\\\right) \\\\frac{\\\\epsilon^2}{\\\\alpha^4}$.\\n\\nThen with probability at least $1 - \\\\delta$ we have:\\n\\n$$|W(S_n(g^*, f^*, \\\\theta)) - W(g^*, f^*, \\\\theta)| \\\\leq \\\\epsilon \\\\alpha.$$\"}"}
{"id": "i4qKmHdq6y8", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Proof.\\n\\nFirst we apply Lemma 3 with $L_{SN}(f,g) = W_{Sn}(g,f,\\\\theta)$, $b = \\\\theta\\\\alpha$ and $t = \\\\alpha\\\\epsilon$, and also using the condition $n \\\\geq 32\\\\theta^2\\\\log(4|GH(2n)||GF(2n)|) + \\\\log(5\\\\delta)\\\\epsilon^2\\\\alpha^4 \\\\geq 2\\\\theta^2\\\\epsilon^2\\\\alpha^4$ in the lemma. Then it follows:\\n\\n$$P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 2P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 2P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 2P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 2P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 2P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 4|H_{S_n, S'_n}| |F_{S_n, S'_n}| P_{S_n, S'_n} \\\\sim D$$\\n\\n$$\\\\leq 4|H_{S_n, S'_n}| |F_{S_n, S'_n}|$$\\n\\n$$= 4G_{H}(2n)G_{F}(2n)e^{-n\\\\alpha^2\\\\epsilon^2/32\\\\theta^2\\\\alpha^2}$$\\n\\nNext we bound the FPR and FNR of $g \\\\ast S_n$ leveraging on the fact that $W_{Sn}(g,f \\\\ast S_n)$ is sufficiently small.\\n\\nTheorem 3. Under Assumption 1, given a set of samples $S_n = \\\\{(x_1, y_1), \\\\ldots, (x_n, y_n)\\\\}$ drawn i.i.d. from Noisy Generative Process and $f \\\\ast S_n = \\\\arg\\\\min_{f \\\\in F} R_{S_n}(f)$, $g \\\\ast S_n = \\\\arg\\\\min_{g \\\\in H} W_{S_n}(g, f \\\\ast S_n, \\\\theta)$, if $\\\\theta \\\\in (\\\\alpha, 1)$, $\\\\alpha \\\\in (0, 1)$ and $n \\\\geq 32\\\\theta^2\\\\log(4|GH(2n)||GF(2n)|) + \\\\log(5\\\\delta)\\\\epsilon^2\\\\alpha^4 \\\\geq 2\\\\theta^2\\\\epsilon^2\\\\alpha^4$, we have with probability at least $1 - \\\\delta$\\n\\n$$I) \\\\quad W(g \\\\ast S_n, f \\\\ast S_n, \\\\theta) \\\\leq 2\\\\epsilon\\\\theta + 2\\\\alpha\\\\epsilon + (1 - \\\\theta)^2$$\\n\\n$$II) \\\\quad \\\\text{if } \\\\theta = 2c\\\\alpha \\\\text{ with } \\\\frac{1}{2} < c < 1 + \\\\frac{\\\\alpha}{4\\\\alpha}, \\\\text{ we have with probability at least } 1 - \\\\delta$$\\n\\n$$P[g \\\\ast S_n(x) \\\\geq 0 | g \\\\ast (x) \\\\leq 0] \\\\leq 12c\\\\alpha\\\\epsilon^2 - 1$$\\n\\n$$\\\\text{False Positive}$$\\n\\n(21)\\n\\n$$P[g \\\\ast S_n(x) < 0 | g \\\\ast (x) \\\\geq 0] \\\\leq 20c\\\\epsilon$$\\n\\n$$\\\\text{False Negative}$$\\n\\n(22)\"}"}
{"id": "i4qKmHdq6y8", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Proof.\\n\\n\\\\[ W(g^*, S_n, f^*, S_n, \\\\theta) \\\\leq W(S_n(g^*, S_n, f^*, S_n, \\\\theta)) + \\\\alpha \\\\epsilon \\\\]\\n\\nwith failure probability at most \\\\( \\\\delta \\\\)\\n\\nTheorem 2)\\n\\n\\\\[ W(S_n(g^*, S_n, f^*, S_n, \\\\theta)) + \\\\alpha \\\\epsilon \\\\]\\n\\nOptimality of \\\\( g^* S_n \\\\)\\n\\n\\\\[ \\\\leq W(g^*, f^*, S_n, \\\\theta) + 2 \\\\alpha \\\\epsilon \\\\]\\n\\nWith failure probability at most \\\\( \\\\delta \\\\)(Lemma 4)\\n\\n\\\\[ = E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ \\\\theta \\\\alpha \\\\mathbb{1}_{f^* S_n(x) \\\\neq y} \\\\mathbb{1}_{g^* S_n(x) > 0} \\\\right] + E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ 1 - \\\\theta \\\\alpha \\\\mathbb{1}_{f^* S_n(x) = y} \\\\mathbb{1}_{g^* S_n(x) \\\\leq 0} \\\\right] + 2 \\\\alpha \\\\epsilon \\\\]\\n\\n\\\\[ = \\\\left[ \\\\theta \\\\right] \\\\mathbb{P}_{x \\\\sim D} \\\\mathbb{1}_{g^*(x) \\\\geq 0} + \\\\left[ 1 - \\\\theta \\\\right] \\\\mathbb{P}_{x \\\\sim D} \\\\mathbb{1}_{g^*(x) \\\\leq 0} \\\\]\\n\\n\\\\[ = 2 \\\\epsilon \\\\]\\n\\nwith failure prob at most \\\\( \\\\delta \\\\) (Thm 1)\\n\\n\\\\[ + (1 - \\\\theta) \\\\mathbb{P}_{x \\\\sim D} \\\\mathbb{1}_{f^* S_n(x) = y} \\\\]\\n\\n= 0.5 since all \\\\( y \\\\)'s in \\\\( \\\\Omega \\\\) are coin flipping\\n\\n\\\\[ \\\\leq 2 \\\\epsilon + 2 \\\\alpha \\\\epsilon + (1 - \\\\theta) \\\\]\\n\\n\\\\[ \\\\leq 2 \\\\epsilon \\\\theta + 2 \\\\alpha \\\\epsilon + (1 - \\\\theta) \\\\]\\n\\n(23)\\n\\nProof of II):\\n\\n\\\\[ W(g^* S_n, f^* S_n, \\\\theta) = E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ \\\\theta \\\\alpha \\\\mathbb{1}_{f^* S_n(x) \\\\neq y} \\\\mathbb{1}_{g^* S_n(x) > 0} \\\\right] + E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ 1 - \\\\theta \\\\alpha \\\\mathbb{1}_{f^* S_n(x) = y} \\\\mathbb{1}_{g^* S_n(x) \\\\leq 0} \\\\right] \\\\]\\n\\nTerm 1\\n\\n\\\\[ + E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ \\\\theta \\\\alpha \\\\mathbb{1}_{f^* S_n(x) \\\\neq y} \\\\mathbb{1}_{g^* S_n(x) \\\\leq 0} \\\\right] \\\\]\\n\\nTerm 2\\n\\n\\\\[ + E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ (1 - \\\\theta) \\\\mathbb{1}_{f^* S_n(x) = y} \\\\mathbb{1}_{g^* S_n(x) \\\\leq 0} \\\\right] \\\\]\\n\\nTerm 3\\n\\n\\\\[ + E_{(x,y) \\\\sim D} \\\\alpha \\\\left[ (1 - \\\\theta) \\\\mathbb{1}_{f^* S_n(x) = y} \\\\mathbb{1}_{g^* S_n(x) \\\\geq 0} \\\\right] \\\\]\\n\\nTerm 4\\n\\n\\\\[ + (1 - \\\\theta) \\\\mathbb{P}_{x \\\\sim D} \\\\mathbb{1}_{g^*(x) \\\\geq 0} + \\\\left[ 1 - \\\\theta \\\\right] \\\\mathbb{P}_{x \\\\sim D} \\\\mathbb{1}_{g^*(x) \\\\leq 0} \\\\]\"}"}
{"id": "i4qKmHdq6y8", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Note that there are two types of errors penalized in the selector loss: an incorrect prediction on an informative datapoint, \\n\\\\((f(x) \\\\neq y) \\\\land (g(x) > 0)\\\\), and a correct prediction on an uninformative datapoint, \\n\\\\((f(x) = y) \\\\land (g(x) \\\\leq 0)\\\\). We use \\n\\\\(\\\\beta_I = \\\\theta \\\\alpha\\\\) and \\n\\\\(\\\\beta_U = 1 - \\\\theta (1 - \\\\alpha)\\\\) to weigh these two types of error in the loss. Both \\n\\\\(\\\\beta_I\\\\) and \\n\\\\(\\\\beta_U\\\\) are controlled by a parameter \\n\\\\(\\\\theta\\\\) and the latent informative data proportion \\n\\\\(\\\\alpha\\\\). We show that for a wide range of \\n\\\\(\\\\theta\\\\), the accuracy of the selector is guaranteed, as long as \\n\\\\(\\\\alpha\\\\) is bounded away from \\n1, i.e., when abstention is necessary. In practice, we can adjust \\n\\\\(\\\\beta_I\\\\) and \\n\\\\(\\\\beta_U\\\\) freely without knowing exact value of \\n\\\\(\\\\alpha\\\\), as empirical performance remains stable with regard to \\nthese choices.\\n\\nLearning a selector with the novel loss.\\nIn an ideal setting, to learn a selector, we first estimate\\nthe predictor by minimizing the classification risk,\\n\\\\(f^*_{S_n} = \\\\arg\\\\min_{f \\\\in F} R_{S_n}(f)\\\\). Next, we estimate the selector by minimizing the selector loss, conditioned on the estimated predictor,\\n\\\\(g^*_{S_n} = \\\\arg\\\\min_{g \\\\in H} W_{S_n}(g, f^*_{S_n}, \\\\theta)\\\\).\\nIn Figure 1, we show an example of using the empirical mini-\\nmization strategy with logistic regression and with \\n0-1 loss replaced by cross-entropy loss. In this\\ncase, the losses are all convex and the empirical minimizers\\n\\\\(f^*_{S_n}\\\\) and \\n\\\\(g^*_{S_n}\\\\) can be computed exactly.\\nOur analysis in Section 3.2 will show that the estimated predictor\\n\\\\(f^*_{S_n}\\\\) and selector\\n\\\\(g^*_{S_n}\\\\) has bounded\\nselective risk (as in Definition 3), as well as bounded false positive and false negative selector errors\\n(as in Definition 4).\\nIn practice, however, empirical minimization is not always possible, as optimization for complex\\nmodels (e.g., DNNs) and non-convex losses remains open. We therefore propose a heuristic algorithm\\nin the spirit of our theoretical results - it jointly learns\\n\\\\(f\\\\) and \\n\\\\(g\\\\) by minimizing the selector loss and a\\nreweighed classification risk iteratively (see Section 3.3).\\n\\n3.2 THEORETICAL ANALYSIS\\nIn this section we report our theoretical results. The main result can be summarized in the following\\n(informal) statement.\\nMain Result (Informal)\\nWith sufficient data, the estimated predictor\\n\\\\(f^*_{S_n} = \\\\arg\\\\min_{f \\\\in F} R_{S_n}(f)\\\\)\\nand selector\\n\\\\(g^*_{S_n} = \\\\arg\\\\min_{g \\\\in H} W_{S_n}(g, f^*_{S_n}, \\\\theta)\\\\)\\nare sufficiently close to the targets\\n\\\\(f^*\\\\) and \\n\\\\(g^*\\\\) with\\nhigh probability.\\nThe proof requires the classic growth function definition (Vapnik & Chervonenkis, 2015).\\nDefinition 7\\n(Growth Function).\\nLet\\n\\\\(H\\\\) be the hypothesis class of function \\\\(f\\\\) and \\n\\\\(F_{x_1,\\\\ldots,x_n} = \\\\{f(x_1),\\\\ldots,f(x_n) : f \\\\in F\\\\}\\\\subseteq\\\\{+1,-1\\\\}^n\\\\). The growth function is defined to be the maximum num-\\nber of ways in which \\n\\\\(n\\\\) points can be classified by the function class:\\n\\\\(G_F(n) = \\\\sup_{x_1,\\\\ldots,x_n} |F_{x_1,\\\\ldots,x_n}|\\\\).\\nRoadmap of the proof: Theorem 1 is a standard PAC Learning analysis where we show\\n\\\\(f^*_{S_n}\\\\) is\\nsufficiently close to the ground truth function \\n\\\\(f^*\\\\). Note that our analysis does not imply efficient PAC\\nlearning since optimizing binary loss is NP-hard. In Theorem 2, we bound the statistical error of the\\nselector loss. In Theorem 3, we leverage the fact that informative and uninformative portions of the\\ndata are distinguishable, as well as the fact that \\n\\\\(f^*_{S_n}\\\\) has low risk on informative data. This lets us\\nbound the selector loss of \\n\\\\(g^*_{S_n}\\\\) given by \\n\\\\(W_{S_n}(g^*_{S_n}, f^*_{S_n}, \\\\theta)\\\\). By carefully balancing the weight parameter\"}"}
{"id": "i4qKmHdq6y8", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We first prove a theorem about sample complexity of the learning hypothesis optimized over a given VC-dimension in (Vapnik & Chervonenkis, 2015; Blum et al., 2016; Mohri et al., 2018). We also Under Assumption 1, given set of samples\\n\\nTheorem 4.\\n\\nUnder Assumption 1, given hypothesis class\\n\\nTheorem 2.\\n\\nGiven hypothesis class\\n\\nTheorem 3.\\n\\nUnder Assumption 1, given a set of samples\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ d \\\\]\\n\\ndimension\\n\\n\\\\[ H \\\\]\\n\\nis no need for abstention.\\n\\nNext theorem is a formal statement of the main result. It is worth mentioning that the theorem assumes that \\\\( \\\\alpha \\\\)\\n\\nNext theorem states the sample requirements in order to achieve a small gap between the empirical\\n\\n\\\\[ R \\\\]\\n\\narg min\\n\\n\\\\[ f \\\\]\\n\\ndataset, referred to as\\n\\nwe have with probability at least \\\\( \\\\theta \\\\)\\n\\nif\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ c \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\nrelationship between \\\\( \\\\theta \\\\)\\n\\npositive/negative rate of the selector with high probability. In particular, the analysis points to a trade\\n\\nparameter\\n\\n\\\\[ \\\\theta \\\\]\\n\\noff between false positive and negative rates faced by the selector in terms of\\n\\n\\\\[ \\\\theta \\\\]\\n\\nparameter\\n\\n\\\\[ \\\\theta \\\\]\\n\\nthe false negative rate (FNR) and false positive rate (FPR) are controlled. Intuitively, a larger value\\n\\n\\\\[ \\\\theta \\\\]\\n\\nthe false positive error.\\n\\n\\\\[ \\\\theta \\\\]\\n\\nthe false positive and false negative guarantees in Theorem 3. Theorem 4\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\nthe selector loss and the true selector loss. The proof takes a union bound over all possible pairs of\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\ngrowth function of hypothesis classes in Theorem 3. The toolkit we use is driven by the concept of a\\n\\n\\\\[ \\\\theta \\\\]\\n\\nof selector loss, we derive the false positive and false negative guarantees in Theorem 3. Theorem 4\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\nthe false positive error.\\n\\n\\\\[ \\\\theta \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\[ \\\\alpha \\\\]\\n\\n\\\\"}
{"id": "i4qKmHdq6y8", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Remark 1. We provide a lower bound construction in the appendix to show that our bound in Theorem 4 is tight up to a logarithmic factor. Note that our lower bound is for empirical minimizers of $R(f)$ and $W(g, f, \\\\theta)$, therefore the tightness result is not an information theoretic bound for this family of problems. It remains an open question about whether or not strategies other than the empirical minimization, as in (Hanneke, 2016; Simon, 2015; El-Yaniv et al., 2010), can improve the sample complexity to a rate of $O(1/\\\\alpha \\\\epsilon)$. Note that the informative portion of the data (drawn with probability $\\\\alpha$) by itself only requires $O(1/\\\\epsilon)$ samples for an $\\\\epsilon$-excessive statistical error. It turns out that our analysis for empirical minimizer is nearly tight, and that the number of samples $O(1/\\\\alpha^2 \\\\epsilon^2)$ is indeed necessary because the presence of noisy data makes our problem harder.\\n\\nRemark 2. Theorem 4 says that by minimizing the empirical version of the loss from Definitions 5 and 6, one can achieve the goal of simultaneously selecting and learning with noisy data \u2014 i.e. the classification model $f^*_S$ has sufficiently low selective risk, and the selector $g^*_S$ can distinguish informative data from non-informative. The analysis of the selector loss (Theorem 3) relies on the quality of the classifier $f^*_S$. But since we know that $g^*_S$ is able to abstain from uninformative data, we can retrain $f^*_S$ on the informative portion only, therefore guaranteeing its accuracy. Such circular logic naturally leads to a practical iterative algorithm that we present in the next section.\\n\\n3.3 A Heuristic Algorithm in Practice\\n\\nIn Section 3.2, we analyzed an empirical minimizer of a conceptual 0-1 loss for the classifier $f$ and the selector $g$. Binary loss, however, is impractical from the computational standpoint. In practice, we use cross-entropy loss instead and require that both $f$ and $g$ have continuous-valued output, ranging between 0 and 1. We also relax the requirement for empirical minimization oracles, allowing the practical algorithm to jointly optimize the predictor and the selector in an iterative manner. At each iteration, we update the predictor using the informative data selected by the selector, and then update the selector based on the predictor's output. See Algorithm 1 for the pseudo-code. A pictorial example of Algorithm 1's performance can be found in Figure 2 in the Appendix.\\n\\nDuring the joint optimization process, the predictor is counting on the selector to show it only the informative data. However, the initial selector is not trustworthy. To update the predictor $f$, we turn to a so-called soft abstention scheme: use a weight vector $\\\\gamma$ that progressively down-weights samples abstained by $g$, in the spirit of multiplicative weights algorithms (Cesa-Bianchi & Lugosi, 2006; Arora et al., 2012). Specifically, we increase the weight of $i$-th sample $\\\\gamma_i$ if the selector accepts $x_i$:\\n\\n$$\\n\\\\gamma_i = \\\\gamma_i (1 + \\\\eta \\\\cdot 1\\\\{g(x_i) > 0.5\\\\})\\n$$\\n\\nand then normalize so that $\\\\sum_{i=1}^{n} \\\\gamma_i = 1$. We call this a soft abstention approach because the algorithm decreases the weight of uninformative data gradually.\\n\\nIn the heuristic algorithm, we use cross-entropy loss to fit the selector to pseudo-informative labels output by the predictor. We also use a single hyper-parameter $\\\\beta = \\\\beta_I/\\\\beta_U = \\\\theta (1 - \\\\alpha) / \\\\alpha (1 - \\\\theta)$ to control the ratio of the two types of errors. As suggested by Theorem 3, small selector FPR and small selector FNR can be achieved by a $\\\\beta \\\\in (1, 1 + 1/\\\\alpha)$. For a scenario when abstention is necessary, i.e. when the noisy data ratio is in a reasonable range, we can choose our hyper-parameter from a wide interval.\\n\\n### Algorithm 1\\n\\n**Iterative Soft Abstain**\\n\\n**Require:** Data set $S_n = \\\\{(x_1, y_1), \\\\ldots, (x_n, y_n)\\\\}$, weight parameter: $\\\\beta$, random initial $f_0$ and $g_0$, initial sample weights $\\\\gamma_0^i = 1/n, \\\\forall i \\\\in [n]$, meta learning rate $\\\\eta$, number of iterations $T$\\n\\n1. for $t \\\\leftarrow 1, \\\\ldots, T$\\n2. Optimize loss to update predictor $f_t$: $\\\\sum_{i=1}^{n} \\\\gamma_t^i \\\\{y_i \\\\log(f_t(x_i)) + (1 - y_i) \\\\log(1 - f_t(x_i))\\\\}$\\n3. Approximate the 'pseudo-informative label': $z_t^i = 1\\\\{1\\\\{f_t(x_i) > 0.5\\\\} = y_i\\\\}$\\n4. Optimize loss to update selector $g_t$: $\\\\sum_{i=1}^{n} \\\\{z_t^i \\\\log(g_t(x_i)) + \\\\beta (1 - z_t^i) \\\\log(1 - g_t(x_i))\\\\}$\\n5. Update sample weights using $g_t$: $\\\\gamma_{t+1}^i = \\\\gamma_t^i (1 + \\\\eta \\\\cdot 1\\\\{g_t(x_i) > 0.5\\\\}) / \\\\sum_{j=1}^{n} \\\\gamma_t^j (1 + \\\\eta \\\\cdot 1\\\\{g_t(x_j) > 0.5\\\\})$\\n6. end for\\n7. Output $f_T, g_T$\\n\\n### Experiments\\n\\nDatasets. We test the efficacy of our heuristic algorithm (Algorithm 1), via semi-synthetic experiments. We synthesize the noisy data by mixing datasets from two different domains and uniformly shuffling all labels in one of them. Our first synthetic noisy dataset is composed of MNIST (LeCun 7\"}"}
{"id": "i4qKmHdq6y8", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"et al., 1998) and Fashion-MNIST (Xiao et al., 2017). We uniformly shuffle the labels of MNIST images and keep original labels of Fashion-MNIST. As a result, images from MNIST are uninformative while images from Fashion-MNIST are considered informative. The fact that one dataset has hand-written digits and the other one contains pictures of clothes ensures distinct supports. We mix these two datasets in different proportions to proxy for our Noisy Generative Process.\\n\\nWe also perform experiments on another synthetic dataset, where noisy and informative portions come from similar domains. To achieve this, we use SVHN (Netzer et al., 2011). We uniformly at random flip labels of classes 5-9 into classes 0-4 and mix them with intact data from classes 0-4. In this case, we consider the data from classes 5-9 uninformative. In this mixed dataset, informative and uninformative data have similar domains, which makes it more challenging to correctly identify informative data (and harder to argue separate support).\\n\\nBaselines.\\n\\nWe compare our method to two of the most recently proposed selective learning algorithms. (1) SelectiveNet (Geifman & El-Yaniv, 2019), which integrates an extra neuron as a data selector in the output layer and also introduces a loss term to control the coverage ratio; (2) DeepGambler (Liu et al., 2019), which also maintains an extra neuron for abstention and uses a doubling-rate-like loss term (i.e., gambler loss) to train the model. (3) We also create a third baseline that selects data using model prediction confidence, which we refer to as Confidence. The hypothesis is that informative data should have higher prediction confidence compared to uninformative data.\\n\\nEvaluation Metrics.\\n\\nWe use three criteria to jointly evaluate a selective learning outcome. (1) Selective risk (SR). Selective risk is the empirical risk measured over the datapoints selected by the algorithm. This is a metric that is also adopted in (Geifman & El-Yaniv, 2019; Liu et al., 2019). (2) Precision. Precision is the proportion of true informative datapoints among all the data picked out by the selector. (3) Recall. Recall is the proportion of true informative samples picked out by the selector out of all the informative samples in the dataset. SR evaluates the quality of the classifier, Precision and Recall are the standard ML metrics of the selector. An ideal selective learning algorithm should have low SR, high precision and high recall.\\n\\nExperiment setting.\\n\\nWe assume that the ratio of informative data, $\\\\alpha$, is unknown to all methods. This is necessary in practice; the ratio and strength of noise are not known in most real world scenarios. For SelectiveNet and DeepGambler, such ratio is a required input. To run these baselines, we first run the original backbone for 60 epochs, and then estimate $\\\\alpha$ using backbone's training accuracy. Assume that the backbone fits all of the informative data perfectly and also makes some correct guesses on noisy data with probability $\\\\frac{1}{\\\\text{num of classes}}$, then the frequency estimation of $\\\\alpha$ is $\\\\hat{\\\\alpha} = \\\\frac{\\\\text{num of classes} \\\\times \\\\text{train acc} - 1}{\\\\text{num of classes} - 1}$, which is the value we give to baselines. For more details about the experimental design, please refer to the Appendix (section D).\\n\\nResults and discussion.\\n\\nTable 1 presents the result where we mix the entire uninformative dataset (shuffled MNIST) with different proportions of the informative dataset (Fashion-MNIST). Our algorithm outperforms all the baselines in this setting. If we use partial dataset by decreasing the number of noisy datapoints and repeating previous experiments with the same uninformative-to-informative data ratios, our algorithm wins by an even larger margin (Table 2).\\n\\nWe can see that both SelectiveNet and DeepGambler fall apart in the setting where informative data are sparse. Neither of them achieve a risk below 40% when we mix in only 25% of informative data. The reason is that both of these two methods are only designed to achieve predetermined coverage and cannot dynamically adapt to settings with unknown informative-to-uninformative data ratio. Our algorithm thus gains advantage by learning the underlying uninformative data labeling function in a data-driven manner.\\n\\nOur algorithm also outperforms all the baselines on SVHN dataset where noisy data comes from a similar domain to the informative data. Each experiment is repeated 5 times. Mean and standard deviation are presented in Table 3 and Table 4.\\n\\nWe provide more experimental results in the Appendix (section D). We test the performance of each method in the case where $\\\\alpha$ is given and in the case where datasets contain minority noisy data.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"which implies that\\n\\nTo do so, we consider the following\\n\\n\\\\[ \\\\text{intersection of set of minimizers of } W \\\\in \\\\mathbb{J} \\\\]\\n\\n\\\\[ \\\\text{basis} \\\\]\\n\\n\\\\[ \\\\text{For minimization:} \\\\]\\n\\n\\\\[ \\\\text{If } w_{\\\\text{minimization}} \\\\text{ strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{minimization strategy. Each } \\\\]\\n\\n\\\\[ \\\\text{If } n \\\\text{ and } x \\\\text{ can not be learned correctly, thus resulting in a risk of at least } \\\\]\\n\\n\\\\[ \\\\text{w} \\\\text{ happens with probability at least } 0 \\\\]\\n\\n\\\\[ \\\\text{negative rate. Now lets focus on the case when } \\\\]\\n\\n\\\\[ \\\\text{Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false } \\\\]\\n\\n\\\\[ \\\\text{of coordinates can not be learned correctly, thus resulting"}
{"id": "i4qKmHdq6y8", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Extension to Multi-class. Our method extends to multi-class setting naturally. In the case of \\\\( K \\\\)-class classification, we have predictors \\\\( f(x) = f(x)_{1:K} : \\\\mathbb{X} \\\\rightarrow \\\\Delta^K \\\\) where \\\\( \\\\Delta^K \\\\) is the \\\\( K \\\\)-simplex. In multi-class scenario, our selector loss remains the same. Meanwhile, we use multi-class cross entropy loss to train classifier. The pseudo-informative label becomes \\\\( z_i = \\\\mathbb{1}\\\\{ \\\\arg\\\\max_k f(x_i) = y_i \\\\} \\\\).\\n\\nExperiment setting with Unknown \\\\( \\\\alpha \\\\) (More Details). For MNIST/Fashion-MNIST experiment, the backbone model we use for each candidate is TinyCNN, which is a CNN with two consecutive convolution layers and 3 consecutive fully connected layers. This architecture provides enough model capacity for an MNIST-type dataset. We use 196 as the batch size. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We train with each algorithm for 162 epochs. We use the default hyper-parameters for every method (i.e., internal selective learning-specific defaults, as reported in (Geifman & El-Yaniv, 2019; Liu et al., 2019), and \\\\( \\\\beta = \\\\theta(1 - \\\\alpha) \\\\alpha (1 - \\\\theta) \\\\) for our algorithm). It simulates a practical scenario where hyper-parameter optimization is impossible, since the ground truth regarding which datapoints are actually learnable is never revealed. For the SVHN experiment, the backbone model we use is ResNet18 (He et al., 2016b) for every candidate. We use 128 as the batch size. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We train each algorithm for 162 epochs.\\n\\nWeight of Informative data. From Figure 3, we can see that our algorithm can pick out almost all informative data by the end of training for all informative/uninformative ratios even without knowing the ground-truth \\\\( \\\\alpha \\\\).\\n\\nThe y-axis is the percentage of weight put on the informative data, i.e. \\\\( \\\\frac{\\\\sum_{i: x_i \\\\in \\\\Omega_I} \\\\gamma_i}{\\\\sum_{i} \\\\gamma_i} \\\\) in the notation of Algorithm 1. Each experiment is repeated 3 times, and 3 standard deviations are presented as the shaded gray area.\\n\\nExperiments with Known \\\\( \\\\alpha \\\\). We also test the performance of each method in the idealized case. In this experiment, we give the ground-truth \\\\( \\\\alpha \\\\) to each baseline and perform an exhaustive HPO (Hyper Parameter Optimization). We use the same backbone, optimizer and the number of training epochs as before. We run a random hyper-parameter search 500 times (selective loss weight and parameter \\\\( \\\\lambda \\\\) for SelectiveNet and parameter \\\\( o \\\\) in DeepGambler) and record the best performance of each baseline. In this setting, our method still outperform baselines for most levels of noise ratios. In this experiment, we use two stage training for our algorithm. We first run 120 epochs to finish 1st round data selection and then run 42 epochs to train a classifier only with these selected data. The performance is measured with this refined the classifier.\\n\\nExperiment with Low Ratio of Uninformative Data. We also conduct experiments with datasets that contain minority stochastic data. This experiment is conducted under both practical (unknown \\\\( \\\\alpha \\\\)) and idealized scenario (known \\\\( \\\\alpha \\\\)). In practical setting (unknown \\\\( \\\\alpha \\\\)), our proposed algorithm still wins by a large margin. In the case when \\\\( \\\\alpha \\\\) is known, DeepGambler outperforms other methods in 26.\"}"}
{"id": "i4qKmHdq6y8", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 6: (MNIST - Partial Data Setting - Known uninformative SVHN and informative SVHN using the entire uninformative data)\\n\\n|                  | Ours \u00b1 | Confid. SelectiveNet | DeepGambler \u00b1 |\\n|------------------|--------|----------------------|---------------|\\n| Precision        | 0.34   | 0.33                 | 0.49          |\\n| Recall           | 0.63   | 0.21                 | 0.17          |\\n\\n### Table 8: (SVHN - Partial Data Setting - Known informative)\\n\\n|                  | Ours \u00b1 | Confid. SelectiveNet | DeepGambler \u00b1 |\\n|------------------|--------|----------------------|---------------|\\n| Precision        | 0.00   | 0.35                 | 0.76          |\\n| Recall           | 0.21   | 0.43                 | 0.80          |\\n\\nUnder review as a conference paper at ICLR 2022\"}"}
{"id": "i4qKmHdq6y8", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 9: Results on low noise level for both MNIST and SVHN - Unknown\\n\\n| Data Set | Uninformative Data Num. | Informative Data Num. | Criterion | Standard | SelectiveNet | DeepGambler | Ours |\\n|----------|-------------------------|------------------------|-----------|----------|---------------|-------------|------|\\n| MNIST    | 30000                   | 12000                  | SR(%)     | 21.59 \u00b1 0.33 | 14.97 \u00b1 0.76 | 12.97 \u00b1 2.84 |      |\\n|          | 60000                   | 24000                  | SR(%)     | 18.72 \u00b1 0.98 | 15.00 \u00b1 0.74 | 15.00 \u00b1 0.00 |      |\\n| MNIST    | 75000                   | 30000                  | SR(%)     | 34.73 \u00b1 0.87 | 36.17 \u00b1 0.00 | 34.20 \u00b1 0.01 |      |\\n|          | 150000                  | 60000                  | SR(%)     | 18.72 \u00b1 0.98 | 15.00 \u00b1 0.74 | 15.00 \u00b1 0.00 |      |\\n| SVHN     | 18300                   | 75000                  | SR(%)     | 30.59 \u00b1 0.55 | 8.94 \u00b1 0.00  | 7.32 \u00b1 0.01  |      |\\n|          | 28400                   | 11250                  | SR(%)     | 4.69 \u00b1 0.00  | 4.69 \u00b1 0.00  | 4.69 \u00b1 0.00  |      |\\n\\nTable 10: Results on low noise level for both MNIST and SVHN - Known\\n\\n| Data Set | Uninformative Data Num. | Informative Data Num. | Criterion | Standard | SelectiveNet | DeepGambler | Ours |\\n|----------|-------------------------|------------------------|-----------|----------|---------------|-------------|------|\\n| MNIST    | 30000                   | 8000                   | SR(%)     | 8.19 \u00b1 0.32 | 8.17 \u00b1 0.12  | 8.09 \u00b1 0.11  |      |\\n|          | 60000                   | 24000                  | SR(%)     | 7.97 \u00b1 0.13 | 7.97 \u00b1 0.13  | 7.97 \u00b1 0.13  |      |\\n| MNIST    | 75000                   | 12000                  | SR(%)     | 11.65 \u00b1 0.38 | 11.47 \u00b1 0.21 | 9.75 \u00b1 0.63  |      |\\n|          | 150000                  | 60000                  | SR(%)     | 10.37 \u00b1 0.13 | 10.37 \u00b1 0.13 | 10.37 \u00b1 0.13 |      |\\n| SVHN     | 18300                   | 75000                  | SR(%)     | 11.81 \u00b1 0.29 | 12.18 \u00b1 0.67 | 6.92 \u00b1 0.43  |      |\\n|          | 28400                   | 11250                  | SR(%)     | 9.39 \u00b1 0.28 | 9.39 \u00b1 0.28  | 9.39 \u00b1 0.28  |      |\\n\\nFor all our experiments, we are using NVIDIA Tesla V100 GPUs, and we use AWS Sagemaker service for our HPO processes. We repeat each experiment 5 times with random seed 77, 78, 79, 80, 81. For MNIST/Fashion-MNIST experiment where \\\\(\\\\alpha\\\\) is unknown, the training and testing data set split is listed in Table 11. The backbone we use is TinyCNN (in section 4). We use 196 as our batch size and train for 162 epochs for all listed methods. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We shrink our learning rate at epoch 45 and 90 by half each time. For SVHN experiment where \\\\(\\\\alpha\\\\) is unknown, the training and testing data set split is listed in Table 11. The backbone we use is ResNet18. We use 128 as our batch size and train for 162 epochs for all listed methods. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We shrink our learning rate at epoch 45 and 90 by half each time. For both experiments where \\\\(\\\\alpha\\\\) is known and HPO is enabled, we maintain the same backbone and optimizer. The hyper-parameter setting is documented in the code. The code will be open sourced together with the publication of the paper.\"}"}
