{"id": "ObD_o92z4p", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"LIPS - Learning Industrial Physical Simulation benchmark suite\\nM. Leyli-Abadi, D. Danan, M. Yagoubi, S. Attoui\\nIRT SystemX, Palaiseau, France\\nA. Marot, J. Picault, B. Donnot\\nRTE France, Paris, France\\nP. Dimitrov, C. Etienam, A. Farjallah\\nNvidia\\n\\nAbstract\\nPhysical simulations are at the core of many critical industrial systems. However, today's physical simulators have some limitations such as computation time, dealing with missing or uncertain data, or even non-convergence for some feasible cases. Recently, the use of data-driven approaches to learn complex physical simulations has been considered as a promising approach to address those issues. However, this comes often at the cost of some accuracy which may hinder the industrial use. To drive this new research topic towards a better real-world applicability, we propose a new benchmark suite \u201cLearning Industrial Physical Simulations\u201d (LIPS) to meet the need of developing efficient, industrial application-oriented, augmented simulators. To define how to assess such benchmark performance, we propose a set of four generic categories of criteria. The proposed benchmark suite is a modular and configurable framework that can deal with different physical problems. To demonstrate this ability, we propose in this paper to investigate two distinct use-cases with different physical simulations, namely: the power grid and the pneumatic. For each use case, several benchmarks are described and assessed with existing models. None of the models perform well under all expected criteria, inviting the community to develop new industry-applicable solutions and possibly showcase their performance publicly upon online LIPS instance on Codabench.\\n\\n1 Introduction\\nPhysical simulations constitute today a key enabler for real-world complex industrial systems (power grid management, rail infrastructure, aeronautics, pneumatic, gas production plants, thermal comfort, etc.), and are used at several critical stages of the system life-cycle (system design, solutions exploration, system V&V, etc.) to enhance decision making. Typically, the main drawback of using numerical simulations is their high computational cost to reach satisfactory solutions. It can become prohibitive for complex systems requiring large number of simulations. To tackle this issue, several techniques have been explored in the literature to design simplified physical models [1, 2, 3, 4], dimension reduction, or considering simplified assumptions to linearize the problem. In recent years, there has been a growing interest in using machine learning techniques to solve physical problems [5] for which conventional modeling approaches are very expensive to compute. The main goal is to accelerate the computation time while maintaining an acceptable accuracy of simulation predictions under some specified tasks. Going even further to reach the best trade-off, Deep Neural Networks (DNN) have recently led to promising results in various domains (see e.g., [6, 7, 8, 9, 10]), allowing an important speed-up of simulations by substituting some computational bricks with data-driven numerical models.\"}"}
{"id": "ObD_o92z4p", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"These approaches emulate often existing simulators by learning from them in a supervised fashion and are generally used to complement them. Other approaches also aim at developing new kinds of differential solvers \\\\[11, 12, 13\\\\] in an unsupervised manner, and could possibly directly fit into existing simulator core. They often fall in the class of Physics-informed machine learning \\\\[ 14\\\\], where the learning is performed through a residual loss function and then physical constraints are verified on the learned model to validate the obtained solution. They could lead to stronger convergence and generalization than emulators. Another work in \\\\[15\\\\] provides also a taxonomy of integrating prior knowledge into learning systems. As automated learning of complex physical simulations is still considered as a new field of research, there exists a lack of common benchmarking pipeline, starting from available datasets, across various applications and finally common evaluation criteria as reviewed in section 3. This may allow to rigorously compare these methods and drive further advances into real-world applications, in particular when considering industrial use-cases.\\n\\nIn this paper, we propose a new benchmark suite \u201cLearning Industrial Physical Simulations (LIPS)\u201d to facilitate the use and the assessment of augmented physical systems, when applied on real-world applications. Depending on the application scope, the set of required physical variables to be considered may be different. The trade-off between computation speed and accuracy, as well as the expected generalization capability, may be specific to each industrial domain and the considered application. The compliance to physical laws of the learnt simulations may also be very important to validate them and consequently increase the user trust toward these augmented simulators.\\n\\nTo develop the LIPS benchmark suite over several physical domains, we use a bottom-up approach by investigating two use cases described in section 2 with distinct physics: power grid and pneumatic. These 2 industrial domains both contribute in tackling ongoing real-world challenges, such as Climate Change, by transforming our energy system through electricity decarbonization and gains in transportation energy efficiency, or improving the decision-making efficiency regarding industrial products. They also allow, thanks to their heterogeneity in terms of physics lying behind modeling, a better assessment of our proposed benchmark. Preliminary ML models to benchmark also exist in the respective literatures. Our contributions, described in greater details in section 4, hence lie in:\\n\\n1. defining application-oriented benchmark tasks for industry use cases as opposed to general-purpose simulation tasks;\\n2. proposing four categories of evaluation criteria that generalize to several physical, industrial and application domains and challenges beyond usual ML-only evaluation metrics;\\n3. sharing an open-source benchmarking suite framework (LIPS) with associated datasets;\\n4. opening a publicly available Codabench \\\\[16\\\\] thread providing a shared result table for user\u2019s submission and a fully automated and comparable evaluation.\\n\\nBaseline experiments to demonstrate the usefulness of these benchmarks are run with existing state-of-the-art methods in section 5 and further discussed, highlighting the relevance of our benchmark.\\n\\n2 Use-cases\\n\\n2.1 The power grid case\\n\\nIndustrial context\\n\\nPower System Operators are in charge of managing the security of large critical power grids (thousands electrical lines and substations that can be reconfigured) in real time and coordinate the supply and demand for electricity while avoiding fluctuations in frequency or interruptions of supply. It is of the utmost importance for a grid to be robust to blackouts at any time, which means in particular avoiding powerline overflows that can lead to a cascading failure (Figure 1, left). Operators have to face unexpected events (losing a line for example due to weather constraints) or to anticipate events such as variation of production during the day or as equipment\u2019s maintenance. They do so by assessing the risks, leveraging grid flexibility through simulations and carefully choosing sets of remedial actions which act on the grid topology or on the production levels.\"}"}
{"id": "ObD_o92z4p", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Applications\\n\\nNear real-time operations of a power grid can be classified into three steps with different expected speed and accuracy simulation trade-offs (Table 1):\\n\\n1. Risk assessment, i.e., identifying problematic contingencies over a large number of possible cases while assessing their severity (anticipating for instance lines overloads, maintenance operations...);\\n\\n2. Remedial action search, i.e., exploring for solutions to find a set of remedial actions on the grid such as topology change, to solve a local problem and assess its overall impact;\\n\\n3. Decision making, i.e., selection and validation of one of the best solutions before implementation.\\n\\nPhysical Simulations\\n\\nThe computation of the grid state involves a set of physical laws (see appendix C.1) such as Kirchhoff's law or Joule effect. More specifically, the physical resolution of the problem is derived from a set of powerflow equations [17] described at any node \\\\( k \\\\) of the grid. The power injected at a node of the network \\\\( s_k \\\\) is the sum of active (\\\\( p_k \\\\)) and reactive powers (\\\\( q_k \\\\)):\\n\\n\\\\[\\ns_k = p_k + q_k.\\n\\\\]\\n\\nFrom Kirchhoff energy conservation law, the relation between voltage angle and magnitude can be formulated for node \\\\( k \\\\) and neighboring nodes \\\\( m \\\\) as follows:\\n\\n\\\\[\\n0 = -p_k + P_{K_m} = \\\\frac{1}{|v_k| |v_m|} (g_{k,m} \\\\cdot \\\\cos(\\\\theta_k - \\\\theta_m) + b_{k,m} \\\\cdot \\\\sin(\\\\theta_k - \\\\theta_m)) \\\\quad \\\\text{Active power};\\n\\\\]\\n\\n\\\\[\\n0 = q_k + P_{K_m} = \\\\frac{1}{|v_k| |v_m|} (g_{k,m} \\\\cdot \\\\sin(\\\\theta_k - \\\\theta_m) - b_{k,m} \\\\cdot \\\\cos(\\\\theta_k - \\\\theta_m)) \\\\quad \\\\text{Reactive power},\\n\\\\]\\n\\nwhere phasors \\\\( \\\\theta_k \\\\) are unknown for all node \\\\( k \\\\); either voltage \\\\( |v_k| \\\\) or reactive power \\\\( q_k \\\\) are known input at any given node \\\\( k \\\\); active power \\\\( p_k \\\\) is a known input and \\\\( g_{k,m}, b_{k,m} \\\\) known line characteristics for all nodes. For each line \\\\( l \\\\), active \\\\( p_\\\\ell \\\\) and reactive \\\\( q_\\\\ell \\\\) powerflows or the current \\\\( a_\\\\ell \\\\) can further be derived with Ohm's law.\\n\\nSignificance\\n\\nThe problem is non-linear and non-convex. To estimate these variables, a Newton-Raphson power flow solver such as LightSim2grid [18] can be used. Over the past years, the required amount of simulations has drastically increased due to emerging trends [19] \u2013 mainly driven by Energy Transition initiatives, increasing renewable energy share as well as stronger exchanges with neighboring countries over the whole European grid, which lead to a greater stochasticity. In this context, the complexity of physical solvers becomes an obstacle for upgraded decision support [20]. An acceleration by several order of magnitudes is now expected.\\n\\nFigure 1: Left, illustration of line overloading in a power grid and a proposed solution (topology action) to overcome the cascading failure. Right, cross section of a simplified tire.\\n\\n2.2 The pneumatic domain use case\\n\\nIndustrial Context\\n\\nThe tire performances have been improved over years with the aim to increase their resistance and to provide more comfort to driver\u2019s experience under various conditions. As such, their performance could be assessed with respect to the durability, ground adhesion or robustness. To do so, the tire behavior could be modelled during either rolling cycles or conditions such as crushing forces. Besides, to predict the global behavior, it is crucial to estimate the forces arising from the tire/ground interface which are concentrated on the contact area. Consequently,\"}"}
{"id": "ObD_o92z4p", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"to be able to optimize the underlying processes and deepen our understanding of the physical phenomena, we consider the conditions as near as possible to the real-world situations (considering the vehicle velocity, the tire pressure, the friction, the material behavior, etc.).\\n\\nApplications\\n\\nReal-world tests performed on tires involve in particular two classical configurations depending on the accuracy/computational time simulation trade-offs (Table 1):\\n\\n1. **Wheel sustaining**: assess whether the wheel is able to properly sustain the weight of a vehicle;\\n2. **Rolling cycle**: assess the behavior of the tire during the rolling phase.\\n\\nPhysical Simulations\\n\\nThe computation of the tire state, involving the displacement and the contact stress arising from the contact conditions on the discretized domain (i.e. the mesh), is performed based on the resolution of a set of Partial Differential Equations (PDE) through Finite Element (FE) formalism (see appendix C.2 for more details). As such, the solution for the displacement is evaluated at all the nodes of the domain's mesh, whereas it is evaluated at the nodes on the contact boundary for the contact stress. In these PDEs, several physical considerations are involved: the behavior law, the relation between the stress acting on a body and the displacement, the motion law, the unilateral contact conditions (equivalent to assuming the ground is perfectly rigid), the Coulomb's law of dry friction. For more details about contact mechanics, the readers may refer to [21, 22, 23]. Note that, while the displacements and contact stress at the contact boundary are the actual unknowns of the problem, they may not represent all the required measures depending on the use case. Some physical quantities relevant to a given application can be computed as a post-processing of the unknowns. Figure 1, right, depicts the cross section of a simplified tire. We consider an idealized straight rolling on a non-deformable ground at constant speed.\\n\\nSignificance\\n\\nThe problems mentioned above are strongly nonlinear due to the nonlinearity of the underlying behavior law, the large deformation framework and the frictional contact conditions. In order to estimate the displacement and the stress, the FE solver \\\"Getfem\\\" [24] is used. In practical applications, rolling simulations in particular provides a lot of useful information, such as the contact area, forces, contact pressure and moments. Classical methods exist [25, 26], however, because of the inherent complexity of the problem, the computation time is prohibitively expensive. Running over a day sometimes, it limits the use of such models in industrial applications compared to simpler surrogate models. An order of magnitude acceleration with acceptable accuracy would democratize its usage.\\n\\n| Table 1: Grid and pneumatic apps: speed vs accuracy and physical law compliance trade-offs |\\n|---------------------------------|-------------------------------------------------|---------------------------------|\\n| **Application** | **Variables to predict** | **Accuracy & PL compliance** |\\n|-----------------|--------------------------|-------------------------------|\\n| Use cases       |                          | Speed                        |\\n| (1) Risk assessment | a_\u2113 + + + +                 |                               |\\n| (2) Action Search | a_\u2113, p_\u2113, v_k + ++ + + +   |                               |\\n| (3) Decision Making | a_\u2113, p_\u2113, v_k, q_\u2113, \u03b8_k + + + + |                               |\\n| Tire            |                          |                               |\\n| (1) Wheel sustaining | u_\u03a9 + + + +                 |                               |\\n| (2) Rolling cycle | u_\u03a9, \u03bb_c + + + + + + + + + |                               |\\n\\n2.3 Added value of ML\\n\\nGenerally speaking, ML model can provide more direct and faster predictions than a Newton-Raphson resolution over the non-linearities of both use cases. It can leverage a learning memory of any given grid, mesh or last rolling cycle iteration of interest, without restarting the resolution from scratch as if it was a new system or problem. Additionally, in some of our benchmark tasks, we require the ML models to predict only a subset of the variables such as the flows or contact forces, unlike the physical solvers which usually compute all the variables by design. ML models could finally provide more factorized computation, such as, for instance, for varying grid topologies (varying number of electrical nodes), whereas existing physical solvers do not offer factorization over such dimension.\"}"}
{"id": "ObD_o92z4p", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3 Related works and novelty\\n\\nSimulations and benchmarks in power grids. Although simulation time and convergence have improved over decades thanks to benchmarks based on shared power grid cases and some contests [27, 28], it remains still slow to compute large volumes of simulations. In addition, existing simulators are general purpose and not application specific, that we consider in this work. Some application-oriented simulation-related benchmarks emerged lately in the power system community (SimBench [29], Power Grid Lib [30]). However, they are mostly designed to drive advances in operational research algorithms. In comparison, our benchmark:\\n\\na) stresses the importance of considering the complexity of varying grid topologies for industrial applications;\\nb) unlocks the creation of data-driven models by providing comprehensive data distributions to train them, similarly to [31] for other power grid related applications;\\nc) defines specific metrics to evaluate them such as physics compliance, out-of-distribution generalization over unseen topologies or industrial readiness considering available data volume and scalability. It eventually allows a fair comparison of pre-existing ML models [8, 32, 33, 34, 35, 36] over all necessary dimensions as summarized in Table 2 and detailed in Appendix D. A similar evaluation over defined set of categories is also concurrently advocated by [37] as a first step towards proper benchmarks. Finally, we reference as an analogous initiative this recently published physical simulation-less but application-oriented dataset for power-grid ML [38].\\n\\nTable 2: Comparative table between LIPS and related work for the power grid case.\\n\\n| Evaluation criteria categories | Environment setup | Reference | ML-related Readiness | Industrial Generalization | OOD Compliances | Physics visualization | Thresholding & Dataset Simulator | Ref physical repository | ML model Baselines |\\n|-------------------------------|-------------------|----------|-----------------------|--------------------------|------------------|-----------------------|-----------------------------|-----------------------|------------------|\\n| LeapNet [39] + [40]           | Yes               | Partial  | No                    | No                       | No               | No                    | Fast - Hades2              | (proprietary)        | Fast - Hades2    |\\n| [13, 35, 35]                  | Yes               | No       | Partial               | No                       | No               | Yes                   | No                          | (open source)        | No               |\\n| [13, 33]                      | Fast              | Yes      | Partial               | No                       | No               | Partial               | No                          | (open source)        | No               |\\n| [13, 33]                      | Fast              | Yes      | Partial               | No                       | No               | No                    | No                          | (open source)        | No               |\\n| LIPS                          | Yes               | Yes      | Yes                   | Yes                      | Comprehensive   | Yes                   | LightSim2GridFast         | (open source)        | No               |\\n| SimBench [29] & heuristic)    | Optimization     | No       | Yes                   | Partial                  | No               | No                    | No                          | (open source)        | No               |\\n| Benchmark suites              | [30]              | No       | Partial               | Yes                      | No               | No                    | No                          | (uniform)             | No               |\\n| [30]                          | PowerGridLib      | No       | Partial               | Yes                      | Partial          | No                    | No                          | (open source)        | No               |\\n| PDEs simulations and benchmarks for pneumatic. In the last few years, the success of deep learning techniques has encouraged researchers to investigate their capability to solve PDE problems. Several works were proposed to hybridize PDE-based physical problems with Neural Networks (NN), from black-box resolution on unstructured meshes with graphs NN [42], to more interpretable approaches like the physics informed NN [14]. Some other works have focused on using un-supervised learning techniques to avoid the mesh construction (mesh-free methods)[43, 44]. Regarding pneumatic domain in particular, several attempts to use these techniques have already been made so far: the first tire/pavement contact-stress model based on artificial NN in [45] using a Neuro-Patch Model, tire modeling was investigated in [46] relying on a feedforward back propagation algorithm and [47] proposed a Structure-Preserving NN to predict the stress field within the tire. While providing promising results, none of these works attempt to compare fairly the performances of several ML models with respect to a set of significant application-based criteria and we propose to fill that gap. To our knowledge, this is the first ML-friendly benchmark for pneumatic.\"}"}
{"id": "ObD_o92z4p", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"issue, as well as the proper generalization in regions with high variability, highlighting the need for further advances. A new benchmark is also proposed lately in [48] over four PDEs canonical physical systems to drive forward the development of data-driven time integration solutions. Both focus primarily on scientific needs, with limited evaluation criteria categories, as opposed to industrial needs and applications.\\n\\nIdentified research question (RQ).\\n\\nIn this paper, compared to above-mentioned related works, we address the following research questions: 1) There has been ongoing ML research for physical simulations for several years now. Are current evaluation setup comprehensive enough to actually provide applicable models in industry? If not, what is missing? 2) Can we define an homogeneous evaluation framework, with generic and comprehensive categories of criteria, for different industrial domains that could systematize the creation of such benchmarks and possibly drive cross-domain advances? 3) How can we represent an exhaustive set of benchmark results in an interpretable way?\\n\\nWe also set open research questions (ORQ) yet to be addressed that should be of interest for ML research: 1) What kind of inductive biases could help enforce ood generalization and physical consistency without sacrificing speed? 2) Is there a one-size-fits-all simulation model that performs best for all applications in a given domain or should it be more tailored to achieve better application-specific trade-off? 3) Could we foster the emergence of foundational models across domains?\\n\\nRegarding RQ1, Table 2 shows the heterogeneity and weaknesses of current evaluation setups. Hence, a standardized and comprehensive setup with meaningful categories and targets is needed, driving research towards industrial impact.\\n\\n4 Benchmark suite design\\n\\n4.1 Comprehensive evaluation criteria for benchmarking industrial physical simulations\\n\\nThe first step towards LIPS benchmark is a design of generic and yet comprehensive categories of evaluation criteria. It allows for a comparison within and across physical domains, while being expressive enough to represent industrial needs and expectations. ML-related only metrics are not sufficient in that regard. Thus, we introduce four categories of criteria of importance for industrial applications and illustrate their applicability and utility on 2 use cases in section 5.\\n\\nML-related performance\\n\\nAmong classical ML metrics, we focus on the trade-offs of typical model accuracy metrics such as Mean Absolute Error (MAE) vs computation time (optimal ML inference time without batch size consideration as opposed to application time later).\\n\\nIndustrial Readiness\\n\\nWhen deploying a model in real-world applications, it should consider the real data availability and scale-up to large systems. We hence consider: 1) Scalability: the computational complexity of a surrogate method should scale well with respect to the problem size, e.g. number of nodes in power grid, mesh refinement level in pneumatic; 2) Application Time: as we are looking for a model tailored to a specific application, we measure the computation time when integrated in this application. To this end, we define a realistic application-dependent batch size, which may affect the speed-up.\\n\\nApplication-based out-of-distribution (ood) Generalization\\n\\nFor industrial physical simulation, there is always some expectation to extrapolate over minimal variations of the problem geometry depending on the application. We hence consider ood geometry evaluation such as unseen power grid topology or unseen pneumatic mesh variations.\\n\\nPhysics compliance\\n\\nPhysical laws compliance is decisive when simulation results are used to make consistent real-world decisions. Depending on the expected level of criticality of the benchmark, this criterion aims at determining the type and number of physical laws that should be satisfied.\\n\\n4.2 Power grid application-oriented benchmarking task descriptions and datasets\\n\\nFrom applications in Table 1, we define two application-oriented benchmarks. The Benchmark datasets depart from the same published realistic production and consumption distributions [49, 50], over two widely studied grids (IEEE 14 and IEEE 118 bus-systems) in the power system.\"}"}
{"id": "ObD_o92z4p", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"literature [51]. However, each dataset has its own application-specific grid topologies (applied using Grid2Op [52] framework). The ground-truth for physical variables are further computed using LightSim2Grid [18], a physical solver with industrial-like performance on the selected grids.\\n\\n1. Benchmark 1 - Risk assessment through contingency screening. The problem is to anticipate near real-time potential threats on the power grid and warn the operators accordingly [53]. It simulates incidents (aka contingencies) involving various elements of the grid (such as the disconnection of a line), one by one. For each contingency, a risk is identified when overloads on lines are detected. On a real grid, this scenario means running hundred of thousands of simulations, thereby, computation time is critical, especially since this risk assessment is refreshed every few minutes. We consider large simulation batches and the main physical variable is the line electric current $a_\\\\ell$, because an overload occurs when it exceeds the line capacity.\\n\\nDataset specificity: It presents grid snapshots including all possible line disconnections (N-1) for few different reference grid topologies. An ood topology test set containing N-2 line disconnections (2 line disconnections combined) is also attached to test for such generalization.\\n\\n2. Benchmark 2 - Remedial action search. We need to explore possible solutions (aka \u201cremedial actions\u201d) to identified risks for recommendation to the grid operator as in [54]. A solution consists in a predefined topological change on the grid that alleviates the previous overflow without generating any new problem. Those changes such as node splitting (see Figure 1) bring more non-linearity than line disconnections in benchmark1, making the distributions more complex. We here target medium-sized batches. Additional physical variables are predicted: active power flows $p_\\\\ell$ and voltages $v_k$. A level of compliance with more related physical laws is expected. This allows the operator to better assess the system state in a difficult situation with some consistency.\\n\\nDataset specificity: It presents grid snapshots when applying a topological reconfiguration (among a set of specified ones) on a single substation. It also considers some possible line contingencies that could cause overloads. An ood topology test set containing combination of 2 topological unitary actions is also attached to test for such generalization.\\n\\nFor more details about the datasets (input and output variables and their dimensions) for both industrial use cases, please refer to appendix C. Our \u201cDatasheet for dataset\u201d [55] in appendix A will also provide additional information concerning creation and contents of these datasets. For the power grid use case, we refer the readers to the Grid2op documentation [56]. A visual illustration of the baseline architecture is also provided in appendix F.2.\\n\\n4.3 Pneumatic application-oriented benchmarking task descriptions and datasets\\n\\nIn this article, we focus on the tire mechanics concerning rigid surfaces. As shown in Table 1, we define two application-oriented benchmarks addressed in the literature, for instance in [47] for the rolling. To generate the datasets, we rely on the tire and experiment configurations described in [57]. Both the reference physical solution and the physical criteria of interest are computed by using the FE physical solver Getfem [24] and used as ground truth. Note that, the computation of pure mechanical criteria is performed by the physical solver for convenience, as their calculation rely on the underlying physical model at hand.\\n\\n1. Benchmark 1 - Wheel sustaining. One of the basic function of a pneumatic tire is to support the vehicle weight. When a normal load is applied to a tire, it deflects as the load increases. Then, using the vertical load\u2013deflection curves, we can estimate the so-called static vertical stiffness of tires. Such a criteria is known to have significant impacts on riding comfort, steering stability, and driving performance. Experimentally, this scenario implies running several simulations where different loads are applied on the wheel (inputs) to observe the resulting displacement of the structure (output). To be more specific, the physical variable we are interested in is the displacement $u_\\\\Omega$.\\n\\nDataset specificity: It presents displacement snapshots for different forces applied on the tire. Each displacement field arise from the simulation of a different static problem on a fixed axisymmetric mesh for the same physic.\\n\\n2. Benchmark 2 - Design testing during a rolling cycle. We are also interested in assessing the behavior of the tire under the action of displacement-enforced rolling. Rather than the actual value of the evaluation criteria, we are interested about the relevancy of the design, i.e.\"}"}
{"id": "ObD_o92z4p", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"whether the values are within an acceptable range. Unlike the first scenario, this is a quasi-static configuration. Instead of running static simulations, a single quasi-static problem is run for several time instants within a time interval over rolling cycles. The physical variables we are interested in are the displacement $u$ and the contact stress on the contact boundary $\\\\lambda_c$.\\n\\n**Dataset specificity:**\\nIt presents displacement and contact stresses snapshots evaluated at different instants during the rolling process. The idea is to train the model during $[0, t_1]$ and then evaluate the model for $t > t_1$; as such, it is a pure out of distribution example. Unlike the first case, it involves a single quasi-static problem on a fixed non-axisymmetric mesh with time as input variable.\\n\\n### 4.4 Configurable benchmark suite architecture & resources\\n\\nHerein, we propose a unified extensible platform consisting of three modules combining data management, benchmark core and evaluation metrics. It allows the integration of all the previously mentioned benchmarks. The developed platform is flexible and allow to integrate more benchmarks from other similar domains. Note that this is different but complementary to NVIDIA Modulus framework [58]: one facilitates the design of PINNs models while ours focuses on benchmark design setup.\\n\\n**Figure 2: Benchmarking framework**\\n\\nA Benchmark is instantiated by selecting a dataset, an augmented simulator and an evaluation object, as shown in Figure 2. Each module could be parameterized through a generic configuration file, which helps to relieve the burden for different setups and making it more user-friendly. They further comply with simple interfaces, making it modular to add new evaluation metrics or new physical domains.\\n\\n**Benchmark resources**\\n\\nThe benchmark implementation and corresponding data are provided in open-source via a github repository [1], alongside a starting kit aiming to facilitate the use of main functionalities. In addition, we make LIPS available on Codabench [59] \u2013 an open, public platform that allows to submit easily surrogate models, and to compare fairly submissions, under the same settings and in a fully automated way. The participant will also be able to monitor their progress through a ranking table. We strongly encourage ML community working on physical problems to submit and evaluate their methods on previously-mentioned applications through the proposed platform. The public results could be highlighted and discussed at NeurIPS 2022.\\n\\n### 5 Experiments\\n\\nThis section presents the evaluation results of baseline methods for each scenario of both use cases, alongside the experimental configurations used to obtain them.\\n\\n#### 5.1 Experimental setup\\n\\nRegarding the stochastic nature of the optimisation methods based on gradient descent, 5 trials with different seeds has been executed and the performances reported based on mean and standard deviation of different runs. All the experiments in the following sections are performed using a server equipped with AMD EPYC 7502P 32-Core Processor, NVIDIA RTX A6000 GPU and 128 GB of RAM. All computation time evaluation are run on the CPU with time measured per simulation or prediction.\\n\\n[1] https://github.com/IRT-SystemX/LIPS\"}"}
{"id": "ObD_o92z4p", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Power grid - Our reference simulator LightSim2Grid has comparable speed to the proprietary RTE solver Hades 2 on mentioned IEEE grid cases, and is faster than PandaPower [60]. It is faster than the physical simulator used in SimBench, [29] by at least a factor 30 (see [18]) and also faster than the one used in Power Grid Lib [30] by at least a factor 5 on the hardware setup described above. Hence, the choice of this reference simulator makes our benchmark quite challenging. We have looked at a first baseline with differently tuned reference simulator. We set the maximum solver iteration to 1 to assess the maximum possible speed such solver can reach. Regardless of accuracy, we never go beyond a factor 5 speed-up. Hence, as it is far from expected speed-up, it has not been considered in further experimentation. But it definitely set a lower bound to outperform. We have then considered three different baselines for evaluation: a physics based simplification of power flow calculus which is DC approximation [61] and two augmented simulators which are Fully Connected (FC) architecture and a state-of-the-art LEAP net [39], where contrary to FC, the topology intervenes in the latent space and demonstrate better combinatorial generalization capabilities. Note that we have conducted automated grid search to find the best performing network hyper-parameters for both architectures (see appendix F.4). Through this benchmark suite, we encourage the community to contribute and to suggest approaches aiming to improve the performances of the existing baselines.\\n\\nPneumatic - Our reference simulator Getfem is used to generate data in both benchmarks. Similarly to the Power grid case, we considered a simulation where only 1 nonlinear iteration is allowed for the underlying Newton algorithm used within the simulator. Putting aside the resulting loss of accuracy, the equivalent lower bound to outperform is close to 4.\\n\\nWe have considered two types of augmented simulators within the first benchmark: a FC architecture and a Unet [62] architecture. For the latter, the numerical solution evaluated by the physical solver on an unstructured mesh is projected on a $128 \\\\times 128$ grid then, after the evaluation by the augmented solver, it is projected back to the mesh. For the second benchmark, two FC architecture are used: one to predict the displacement and one to predict the contact stress on the contact boundary.\\n\\n5.2 Benchmark results and experiments\\n\\nTable 3 summarizes the benchmark results for both use cases and their specific applications. In order to enhance the readability, we have made use of three qualitative levels from \\\"not acceptable\\\" to \\\"great\\\", relying on application-relevant threshold values reported in appendix C (tables 3 and 6). The full quantitative table from which this table is derived is also provided in section G.1 of appendix.\\n\\nPower grid - As it can be seen in this Table, the ML based models (FC and LeapNet) show better accuracy for target variables than the baseline DC approximation. However, their performance on out-of-distribution dataset is still challenging and not acceptable. While the LeapNet shows a little better generalization performance, the accuracy is still above 6% error, on par with the reported performance in [39]. Maybe surprisingly, quantitative ood results on the small grid (inner small circles) are worse than the larger one. It can be explained by the fact that, in the smaller grids, any change has overall impact on all lines, hence it is even more challenging. The only possible physical law is also verified for this benchmark. Looking at a more complex benchmark 2, we can observe that further variables should be predicted and other laws should also be verified. The DC approximation respects most of the laws as it is based on physical solver, however it comes with some costs from the accuracy point of view. One order of magnitude speed-up when using ML models can be observed in comparison to a very optimized solver. Two order of magnitude speed-up would be expected at least on even larger grids. We emphasize that such speed-up time depends on the application context which needs to be considered. For more detailed comparison concerning the physics-based criteria, the readers may refer to appendix G.2.\\n\\nPneumatic - Likewise, regarding the pneumatic use case, it seems ML models perform relatively well in the first benchmark using FC architecture for the prediction of the displacement field, despite questionable results regarding the physics. The considered small dataset could also explain not acceptable obtained results using UNet architecture. Further investigations are required to assess its adaptability for this benchmark. For the second benchmark, despite the fact that it is a pure out-of-distribution case, the ML model behaves surprisingly well: the prediction is quite\"}"}
{"id": "ObD_o92z4p", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 3: Benchmark result table for the two use cases under 4 categories of evaluation criteria. The performances are reported using three colors computed on the basis of two thresholds. Colors and symbol meaning:\\n\\n- Not acceptable\\n- Acceptable\\n- Great\\n\\nThe number of circles corresponds to the number of variables or laws that are evaluated. For quantitative values from which this table is derived, please refer to section G.1 of appendix and for a color blind version, please refer to Table 11 of appendix.\\n\\n| Criteria category          | ML-related Readiness | OOD Gen. Physics |\\n|----------------------------|----------------------|------------------|\\n| Methods                    | Quality | Speed-up | Speed-up | Quality | Domain laws |\\n|                            | DC      | FC       | LeapNet   | DC      | NA | 7 (20) |\\n|                            | FC      | 99 (157) | 57 (27)   |\\n|                            | LeapNet | 90 (140) | 54 (24)   |\\n\\nPneumatic\\n\\nBench1\\n\\n| DC | NA | NA |\\n|----|----|----|\\n| FC | NA | NA |\\n\\nBench2\\n\\n| DC | NA | NA |\\n|----|----|----|\\n| FC | NA | NA |\\n\\naccurate for the contact stress. The choice of an adapted scaler is important and could also influence the quality of displacement results. In all the investigated cases, the speed-up observed is at least one order of magnitude for both benchmarks compared to the physical solver, which was precisely our aim for the rolling case in the first place. However, given the accuracy for the displacement field, it is far from satisfactory and only partially met with our requirements.\\n\\nWe have shown with two very distinct industrial and physical domains that we can systematize the creation of comprehensive and yet homogeneous benchmarks for the use of physical simulation in industry, hence answering our RQ2. Our result table displays also a lot of benchmark outcomes, yet in a compact and readable way through the use of meaningful thresholds, colors and symbols: this answers our RQ3 and is an original benchmark result representation in the ML community to the best of our knowledge.\\n\\n6 Conclusion and perspectives\\n\\nThis paper has investigated the definition and the implementation of a new benchmark suite, called LIPS (Learning Industrial Physical Simulations). We have addressed simulation-based industrial use-cases augmented with machine learning techniques. Two distinct industrial use cases (with different physics) have been considered to illustrate the proposed framework, with several application-oriented benchmarks. Experiments have shown several comparative studies based on proposed categories of criteria. The obtained results have also clarified the remaining challenges for existing state-of-the-art augmented simulators to emulate the behavior of a physical simulator in an industrial context. Although, they are much faster for providing the appropriate results, their interesting but yet insufficient out-of-generalization properties and vulnerability vis-\u00e0-vis the physics compliance highlights the requirement for further improvements. This benchmark opens the door for designing more robust and reliable augmented simulators that will find better real-world applicability. Future works will focus on extending the suite to new industrial use cases related to other physical domains (e.g. aeronautics, transport,...), which would help to improve the generalization of LIPS.\"}"}
{"id": "ObD_o92z4p", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments and Disclosure of Funding\\n\\nThis research was supported by IRT SystemX, RTE France, Michelin in the context of HSA project (hybridization of simulation and ML). Thanks to Reynaldo Gomez and Benoit Bastien, it was also supported by NVIDIA through an open collaboration to develop benchmarking framework and baselines for industrial physical simulation. We thank all contributors and colleagues from RTE, Michelin, IRT SystemX and NVIDIA who provided insight and expertise that greatly assisted the research. For the pneumatic usecase, we would like to thank Rapha\u00ebl Meunier, from Michelin, for his involvement regarding the usecase design and relevant industrial applications advices. We are finally very thankful to EDF Exaion for sponsoring through their infrastructure these developments by making GPU servers available for training all baselines as well as for running the Codabench public evaluation thread.\\n\\nReferences\\n\\n[1] Michel Bergmann, Andrea Ferrero, Angelo Iollo, Edoardo Lombardi, Angela Scardigli, and Haysam Telib. A zonal galerkin-free pod model for incompressible flows. Journal of Computational Physics, 352, 10 2017.\\n\\n[2] Fabien Casenave, Nissrine Akkari, Felipe Bordeu, Christian Rey, and D. Ryckelynck. A nonintrusive distributed reduced order modeling framework for nonlinear structural mechanics \u2013 application to elastoviscoplastic computations. International Journal for Numerical Methods in Engineering, 121, 08 2019.\\n\\n[3] J. Kutz, Steven Brunton, Bingni Brunton, and Joshua Proctor. Dynamic Mode Decomposition: Data-Driven Modeling of Complex Systems. 11 2016.\\n\\n[4] Francisco Chinesta, El\u00edas CUETO, Emmanuelle Abisset-Chavanne, Jean Duval, and Fouad Khaldi. Virtual, digital and hybrid twins: A new paradigm in data-based engineering and engineered data. Archives of Computational Methods in Engineering, 27, 11 2018.\\n\\n[5] Giuseppe Carleo, Ignacio Cirac, Kyle Cranmer, Laurent Daudet, Maria Schuld, Naftali Tishby, Leslie Vogt-Maranto, and Lenka Zdeborov\u00e1. Machine learning and the physical sciences. Reviews of Modern Physics, 91(4):045002, 2019.\\n\\n[6] J. Tompson, K. Schlachter, P. Sprechmann, and K. Perlin. Accelerating eulerian fluid simulation with convolutional networks. ArXiv: 1607.03597, 2016.\\n\\n[7] MF Kasim, D Watson-Parris, L Deaconu, S Oliver, P Hatfield, DH Froula, G Gregori, M Jarvis, S Khatiwala, J Korenaga, et al. Building high accuracy emulators for scientific simulations with deep neural architecture search. Machine Learning: Science and Technology, 3(1):015013, 2021.\\n\\n[8] Benjamin Donnot, Balthazar Donon, Isabelle Guyon, Zhengying Liu, Antoine Marot, Patrick Panciatici, and Marc Schoenauer. Leap nets for power grid perturbations. arXiv preprint arXiv:1908.08314, 2019.\\n\\n[9] S. Rasp, M. S. Pritchard, and P. Gentine. Deep learning to represent sub-grid processes in climate models. PNAS, 2018.\\n\\n[10] Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter Battaglia. Learning to simulate complex physics with graph networks. In International Conference on Machine Learning, pages 8459\u20138468. PMLR, 2020.\\n\\n[11] Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differential equations. arXiv preprint arXiv:1806.07366, 2018.\\n\\n[12] Samuel J Greydanus, Misko Dzumba, and Jason Yosinski. Hamiltonian neural networks. 2019.\\n\\n[13] Balthazar Donon, Zhengying Liu, Wenzhuo Liu, Isabelle Guyon, Antoine Marot, and Marc Schoenauer. Deep statistical solvers. In NeurIPS, 2020.\"}"}
{"id": "ObD_o92z4p", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Maziar Raissi, Paris Perdikaris, and George E. Karniadakis. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. *Journal of Computational Physics*, 378:686\u2013707, 2019.\\n\\nLaura Von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev, Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick, Rajkumar Ramamurthy, et al. Informed machine learning\u2014a taxonomy and survey of integrating knowledge into learning systems. *arXiv preprint arXiv:1903.12394*, 2019.\\n\\nZhen Xu, Huan Zhao, Wei-Wei Tu, Magali Richard, Sergio Escalera, and Isabelle Guyon. Codabench: Flexible, easy-to-use and reproducible benchmarking for everyone. *arXiv preprint arXiv:2110.05802*, 2021.\\n\\nDaniel K. Molzahn, Ian A. Hiskens, et al. A survey of relaxations and approximations of the power flow equations. 2019.\\n\\nLightsim2grid. [https://github.com/BDonnot/lightsim2grid](https://github.com/BDonnot/lightsim2grid).\\n\\nAntoine Marot, Adrian Kelly, Matija Naglic, Vincent Barbesant, Jochen Cremer, Alexandru Stefanov, and Jan Viebahn. Perspectives on future power system control centers for energy transition. *Journal of Modern Power Systems and Clean Energy*, 10(2):328\u2013344, 2022.\\n\\nAntoine Marot, Alexandre Rozier, Matthieu Dussartre, Laure Crochepierre, and Benjamin Donnot. Towards an AI assistant for human grid operators. *arXiv preprint arXiv:2012.02026*, 2020.\\n\\nPeter Wriggers. *Computational Contact Mechanics*. 01 2006.\\n\\nPatrick Tallec. Numerical methods for nonlinear three dimensional elasticity. *Handbook of Numerical Analysis*, 3, 12 1994.\\n\\nTod Laursen. *Computational Contact and Impact Mechanics: Fundamentals of Modeling Interfacial Phenomena in Nonlinear Finite Element Analysis*. 01 2003.\\n\\nYves Renard and Konstantinos Poulios. Getfem: Automated FE modeling of multiphysics problems based on a generic weak form language. *ACM Transactions on Mathematical Software*, 47:1\u201331, 12 2020.\\n\\nYves Renard. Generalized Newton\u2019s methods for the approximation and resolution of frictional contact problems in elasticity. *Computer Methods in Applied Mechanics and Engineering*, 256:38\u201355, 04 2013.\\n\\nPeter Wriggers. *Computational Contact Mechanics*. 01 2006.\\n\\nRay Zimmerman, Carlos Murillo-Sanchez, and Defang Gan. Matpower\u2014a MATLAB power system simulation package: User\u2019s manual. 12 1997.\\n\\nZhuo Li, Raju Balasubramanian, Frank Liu, and Sani Nassif. 2011 tau power grid simulation contest: Benchmark suite and results. In *2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, pages 478\u2013481, 2011.\\n\\nSteffen Meinecke, D\u017eanan Sarajli\u010d, Simon Drauz, Annika Klettke, Lars-Peter Lauven, Christian Rehtanz, Albert Moser, and Martin Braun. Simbench\u2014a benchmark dataset of electric power systems to compare innovative solutions based on power flow analysis. *Energies*, 13:3290, 06 2020.\\n\\nSogol Babaeinejadsarookolaee et al. The power grid library for benchmarking AC optimal power flow algorithms, 2021.\\n\\nXiangtian Zheng, Nan Xu, Loc Trinh, Dongqi Wu, Tong Huang, S Sivaranjani, Yan Liu, and Le Xie. Psml: A multi-scale time-series dataset for machine learning in decarbonized energy grids. *arXiv preprint arXiv:2110.06324*, 2021.\"}"}
{"id": "ObD_o92z4p", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Balthazar Donon, Benjamin Donnot, Isabelle Guyon, and Antoine Marot. Graph neural solver for power systems. In 2019 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE, 2019.\\n\\nFlorian Sch\u00e4fer, Jan-Hendrik Menke, and Martin Braun. Evaluating machine learning models for the fast identification of contingency cases. Applied AI Letters, 1(2):e19, 2020.\\n\\nValentin Bolz, Johannes Rue\u00df, and Andreas Zell. Power flow approximation based on graph convolutional networks. In 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), pages 1679\u20131686. IEEE, 2019.\\n\\nBalthazar Donon, R\u00e9my Cl\u00e9ment, Benjamin Donnot, Antoine Marot, Isabelle Guyon, and Marc Schoenauer. Neural networks for power flow: Graph neural solver. Electric Power Systems Research, 189:106547, 2020.\\n\\nLaurent Pagnier and Michael Chertkov. Physics-informed graphical neural network for parameter & state estimations in power systems. arXiv preprint arXiv:2102.06349, 2021.\\n\\nShimiao Li, Amritanshu Pandey, and Larry Pileggi. Gridwarm: Towards practical physics-informed ml design and evaluation for power grid. arXiv preprint arXiv:2205.03673, 2022.\\n\\nXiangtian Zheng, Nan Xu, Loc Trinh, Dongqi Wu, Tong Huang, S Sivaranjani, Yan Liu, and Le Xie. A multi-scale time-series dataset with benchmark for machine learning in decarbonized energy grids. Scientific Data, 9(1):1\u201318, 2022.\\n\\nBalthazar Donon, Benjamin Donnot, Isabelle Guyon, Zhengying Liu, Antoine Marot, Patrick Panciatici, and Marc Schoenauer. Leap nets for system identification and application to power systems. Neurocomputing, 416:316\u2013327, 2020.\\n\\nBenjamin Donnot, Isabelle Guyon, Marc Schoenauer, Antoine Marot, and Patrick Panciatici. Anticipating contingencies in power grids using fast neural net screening. In 2018 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE, 2018.\\n\\nLuis B\u00f6ttcher, Hinrikus Wolf, Bastian Jung, Philipp Lutat, Marc Trageser, Oliver Pohl, Andreas Ulbig, and Martin Grohe. Solving ac power flow with graph neural networks under realistic constraints. arXiv preprint arXiv:2204.07000, 2022.\\n\\nTobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, and Peter W Battaglia. Learning mesh-based simulation with graph networks. arXiv preprint arXiv:2010.03409, 2020.\\n\\nJens Berg and Kaj Nystr\u00f6m. A unified deep artificial neural network approach to partial differential equations in complex geometries. Neurocomputing, 317:28\u201341, 2018.\\n\\nJustin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial differential equations. Journal of computational physics, 375:1339\u20131364, 2018.\\n\\nDevelopment of a Tire/Pavement Contact-Stress Model Based on an Artificial Neural Network, volume Innovations in Vehicle Design and Development of ASME International Mechanical Engineering Congress and Exposition, 11 1999.\\n\\nHoyong Kim and Paul Ro. A tire side force model by artificial neural network. 02 1995.\\n\\nQuercus Hern\u00e1ndez, Alberto Badias, David Gonz\u00e1lez, Francisco Chinesta, and El\u00edas Cueto. Deep learning of thermodynamics-aware reduced-order models from data. Computer Methods in Applied Mechanics and Engineering, 379:113763, 06 2021.\\n\\nKarl Otness, Arvi Gjoka, Joan Bruna, Daniele Panozzo, Benjamin Peherstorfer, Teseo Schneider, and Denis Zorin. An extensible benchmark suite for learning to simulate physical systems. 2021.\\n\\nAntoine Marot, Benjamin Donnot, Camilo Romero, Balthazar Donon, Marvin Lerousseau, Luca Veyrin-Forrer, and Isabelle Guyon. Learning to run a power network challenge for training topology controllers. Electric Power Systems Research, 189:106635, 2020.\"}"}
{"id": "ObD_o92z4p", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Antoine Marot, Benjamin Donnot, Gabriel Dulac-Arnold, Adrian Kelly, A\u00efdan O'Sullivan, Jan Viebahn, Mariette Awad, Isabelle Guyon, Patrick Panciatici, and Camilo Romero. Learning to run a power network challenge: a retrospective analysis. arXiv preprint arXiv:2103.03104, 2021.\\n\\nRay Daniel Zimmerman, Carlos Edmundo Murillo-S\u00e1nchez, and Robert John Thomas. Matpower: Steady-state operations, planning, and analysis tools for power systems research and education. IEEE Transactions on power systems, 26(1):12\u201319, 2010.\\n\\nGrid2op. https://github.com/rte-france/Grid2Op.\\n\\nBenjamin Donnot, Isabelle Guyon, Marc Schoenauer, Antoine Marot, and Patrick Panciatici. Fast power system security analysis with guided dropout. arXiv preprint arXiv:1801.09870, 2018.\\n\\nA Marot, B Donnot, S Tazi, and P Panciatici. Expert system for topological remedial action discovery in smart grids. 2018.\\n\\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9 Iii, and Kate Crawford. Datasheets for datasets. Communications of the ACM, 64(12):86\u201392, 2021.\\n\\nGrid2op documentation. https://grid2op.readthedocs.io/en/latest/observation.html#main-observation-attributes.\\n\\nJulien Gillard. An Efficient Partitioned Coupling Scheme for Tire Hydroplaning Analysis. 05 2018.\\n\\nOliver Hennigh, Susheela Narasimhan, Mohammad Amin Nabian, Akshay Subramaniam, Kaustubh Tangsali, Zhiwei Fang, Max Rietmann, Wonmin Byeon, and Sanjay Choudhry. Nvidia simnet\u2122: An ai-accelerated multi-physics simulation framework. In International Conference on Computational Science, pages 447\u2013461. Springer, 2021.\\n\\nLips codabench. http://htmlpreview.github.io/?https://github.com/IRT-SystemX/LIPS/blob/main/codabench/codabench.html.\\n\\nLeon Thurner, Alexander Scheidler, Florian Sch\u00e4fer, Jan-Hendrik Menke, Julian Dollichon, Friederike Meier, Steffen Meinecke, and Martin Braun. pandapower\u2014an open-source python tool for convenient modeling, analysis, and optimization of electric power systems. IEEE Transactions on Power Systems, 33(6):6510\u20136521, 2018.\\n\\nBrian Stott, Jorge Jardim, and Ongun Alsa\u00e7. Dc power flow revisited. IEEE Transactions on Power Systems, 24(3):1290\u20131300, 2009.\\n\\nOlaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. volume 9351, pages 234\u2013241, 10 2015.\"}"}
{"id": "ObD_o92z4p", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1. For all authors...\\n(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\\n(b) Did you describe the limitations of your work? [Yes]\\nThe conclusion in section 6 includes a discussion about the limitations of our work.\\n(c) Did you discuss any potential negative societal impacts of your work? [N/A]\\nWe do not expect any potential negative societal impacts of this work.\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\\n\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes]\\nYes, via the following github link: https://github.com/IRT-SystemX/LIPS\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes]\\nWe provide the details about the experimental setup in the main paper and in the supplemental material. We also make available some notebooks to reproduce the results. The platform includes a module for hyperparameter tuning which is used for the presented models and is described in supplemental material.\\n(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes]\\nyes, evaluation criteria are reported using the mean and standard deviation over various runs of models\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes]\\nThis information is provided in section 5.1\\n\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\nWe have included the references to the core software libraries and the input dataset used in the benchmarks\\n(b) Did you mention the license of the assets? [Yes]\\nWe are only using open-source assets. The license of the assets we are using is provided at the URL we provide as a reference to the assets.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nThe license (MPL 2.0) is provided with the code of our benchmark framework.\\n(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A]\\nNo human data used or curated.\\n(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]\\nOur data only include the result of numerical simulations.\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]\\nNo human participants\\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]\\nNo human participants\\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]\\nNo human participants\"}"}
