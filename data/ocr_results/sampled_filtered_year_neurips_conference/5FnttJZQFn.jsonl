{"id": "5FnttJZQFn", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.2 Additional Learnings from the 2023 CVPR Competition\\n\\nGenerative Modeling\\n\\nWhile many families of generative models exist, most challenge participants restricted their modeling to a narrow class of such models, namely GMMs. To our knowledge, for the 2023 CVPR challenge, no user submitted sim agent behavior generated by normalizing flow, GAN, or variational autoencoder (VAEs) models, or by denoising diffusion models, although such diffusion techniques have recently become more popular in the simulation agent literature [80, 81]. We expect this may change in the future as more entrants participate in the WOSAC challenge.\\n\\nFurther Quantitative Analysis\\n\\nWe note that the top-four performing methods were executed fully in closed-loop (MVTE [71], MVTA) or in a hybrid fashion (MTR+++ [44], Wayformer [40]), outperforming the two open-loop submissions, JointMultiPath++ [70] and CAD [14], as shown in Table 4. This gap is especially clear between non-open loop methods and open-loop methods in the collision likelihood metric.\\n\\nAmong all baselines we evaluated, the constant velocity baseline is weakest when it comes to angular-based likelihoods. For example, it achieves close to zero likelihood on both angular speed (0.02) and angular acceleration (0.04), as opposed to the MVTE method, which achieves 0.54 and 0.38 likelihoods on the same two component metrics, respectively. This result is intuitive, as our constant velocity model does not account for any yaw rate.\\n\\nA.3 Additional Comparisons with Other Benchmarks for Autonomous Driving Behavior\\n\\nIn Table 4, we compare our WOSAC benchmark with other benchmarks used for evaluation of behavior models for autonomous driving.\\n\\n| BENCHMARK NAME | TASK |\\n|----------------|------|\\n| Argoverse [10] | Trajectory Forecasting |\\n| INTERPRET (INTERACTION) [78] | Trajectory Forecasting |\\n| Argoverse2 [72] | Trajectory Forecasting |\\n| nuScenes [6] | Trajectory Forecasting |\\n| WOMD [22] | Trajectory Forecasting |\\n| CARLA [19] | Motion Planning |\\n| nuPlan [7] | Motion Planning |\\n| WOSAC (Ours) | Multi-Agent Simulation |\\n\\nTable 4: Existing benchmarks for evaluation of behavior models for autonomous driving.\\n\\nA.4 Additional Information about Methods from External Challenge Submissions\\n\\nMultiVerse Transformer for Agent simulation (MVTA) [71]: A method inspired by TrafficSim [60] that is trained and executed in closed-loop and adheres to WOSAC's factorization and autoregressive requirements. It uses a 'receding horizon' policy (i.e. predicting 1 sec. of future motion but using only the next 100 ms). Inspired by MTR [55, 56], MVTA places a Gaussian Mixture Model (GMM) head on top of a transformer-based encoder and decoder (employing the same encoder/decoder layers as implemented in MTR), consuming vector inputs. Rather than utilizing a fixed-length history as context, MVTA uses a variable-length history to potentially use all of the past data. The input agent encoding contains agent history motion state (i.e., position, object size, heading angle, and velocity) and a one-hot category mask of each agent. The prediction heads include a regression head that outputs 5 GMM parameters ($\\\\mu_x, \\\\mu_y, \\\\sigma_x, \\\\sigma_y, \\\\rho$), along with the velocity ($v_x, v_y$) and heading ($\\\\sin(\\\\theta), \\\\cos(\\\\theta)$) predictions for a timestep, and a classification head that outputs probability $p$. Both heads take the query content features ($num_{query} \\\\times hidden$ feature dimension) as input.\\n\\nMVTE: An enhanced version of MVTA [71] wherein 3 variants of MVTA are trained and randomly selected to generate each of the 32 simulations, increasing simulation diversity across rollouts.\\n\\nMTR+++: [44]: A hybrid method with a 0.5Hz replanning rate and a 2 second prediction horizon. We note that MTR+++ does not fully adhere to WOSAC's closed-loop requirement, as it does not replan at a 10 Hz rate. MTR+++ also does not adhere to the policy factorization requirements, as world vs. A V policies are not separated. Inspired by MTR [55, 56], the method addresses two key limitations of MTR: inaccurate heading predictions and excessive collisions incurred by marginal predictions alone. To overcome the first issue, the authors estimate headings from $x/y$ trajectories. Second, in order to minimize collisions, the authors consider $K = 6$ trajectories predicted per agent.\"}"}
{"id": "5FnttJZQFn", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"by MTR, and prune the exponential number of futures in a greedy fashion. As brute-force exhaustive\\nsearch over the $6^N$ combinations is computationally infeasible, MTR+++ searches for the densest\\nsubgraph in a graph of non-colliding future trajectories.\\n\\nFirst, a $6^N \\\\times 6^N$ distance matrix $D$ is constructed, where entry $D_{m+n+i-1, n+j-1}$ indicates the\\nminimum L2 distance between the $i$th-highest trajectories of agent $m$ and the $j$th-highest one of agent $n$.\\nSecond the distance matrix is binarized by evaluating which distances correspond to collisions\\naccording to object extents. Finally, a clique-finding heuristic method finds a dense subgraph of size $N$.\\nAn ensemble of 32 fine-tuned MTR models is employed to create the 32 rollouts, each model\\nproducing a single rollout.\\n\\nCollision Avoidance Detour (CAD) [14]: An open-loop method that builds upon an existing motion\\nforecasting method, MTR [55, 56] to produce marginal trajectory predictions, and resamples the\\nentire future if future agent collisions are anticipated, until a maximum number of trials is exhausted.\\nWhile CAD adheres to the factorization requirement, it does not adhere to WOSAC's closed-loop\\nrequirement. Factorization of world vs. AV policies is accomplished by using different checkpoints\\nof an MTR motion prediction model for the two agent groups, and motion of non-evaluated agents is\\nsimulated using a constant velocity model.\\n\\nJoint-Multipath++ [70]: An open-loop, scene-centric method that builds off of MultiPath++ [66],\\nproducing in a single model pass 32 rollouts, each representing an entire length-80 trajectory.\\nJointMultiPath++ does not factorize AV vs. world policies, and thus does not fully adhere to\\nWOSAC's policy factorization requirements. Agent history information (positions and headings\\nof all agents) are transformed into the AV's coordinate frame, while closest lane information is\\nselected for each agent. In its encoder, JointMultiPath++ concatenates the output of 2 LSTMs and\\none MultiContextGating (MCG) [66] block to form per-agent embeddings; one LSTM is used to\\nencode agent history, another LSTM is used to encode per-step differences in agent history, and an\\nMCG block is used to encode agent history with corresponding timesteps. Subsequent MCG blocks\\nfuse per-agent information with road network (polyline) embeddings. In its decoder, a series of MLP\\nblocks transform $n$ per-agent embeddings to rollouts represented as $n \\\\times 32 \\\\times 80 \\\\times 3$ output tensors.\\n\\nSBTA-ADIA Mo et al. [38]: Builds upon an existing motion prediction method [39]. This hierarchi-\\ncal method splits the problem into a first phase of multi-agent goal prediction, based on a GNN scene\\nencoder, and a simple planning policy which tries to accomplish the goal closed-loop.\\n\\nA.5 Additional Qualitative Results from External Challenge Submissions\\n\\nIn Figure 6 and 7, we provide additional qualitative examples of simulation results from external\\nchallenge submissions.\\n\\nFigure 6: Two-dimensional visualization of simulation results on WOMD's test split. MVTE exhibits\\na collision and MTR+++ produces a near-miss. \u2018Simulation input\u2019 represents the context history\\n$o^{-H-1:0}$, whereas all other columns visualize both ($o^{-H-1:0}, o_{\\\\geq 1}$). One possible future for a single\\nscene is represented, selected from 32 submitted rollouts, where the AV remains stopped at a red traffic\\nsignal. Each rendering in columns 2,3 and 4 depicts the entire duration of the scene. Trajectories\\nof environment sim agents are drawn in a green-blue gradient (each as a sequence of circles in a\\ntemporal color gradient). The AV agent is drawn in orange.\\n\\nCode available at https://github.com/wangwenxi-handsome/Joint-Multipathpp.\"}"}
{"id": "5FnttJZQFn", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 7: Two-dimensional visualization of simulation results on a single scene from WOMD's test split using various baseline methods. Four possible futures for this single scene are represented (one per row), selected from 32 submitted rollouts. \u2018Simulation input\u2019 represents the context history $o_{-H-1:0}$, whereas all other columns visualize both $(o_{-H-1:0}, o_{\\\\geq 1})$. Each rendering in the second, third, and fourth columns depicts the entire duration of the scene. Trajectories of environment agents are drawn in a green-blue gradient, and trajectories of the A V agent are drawn in a red-yellow gradient (each as a sequence of circles in a temporal color gradient). The A V agent is drawn in orange.\"}"}
{"id": "5FnttJZQFn", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.6 Component Metrics Implementation Details\\n\\n1. Linear Speed: Unsigned magnitude of the first derivative\\n\\\\[ \\\\|v\\\\| = \\\\|x_{t+1} - x_t\\\\| \\\\]\\nwhere \\\\( x_t = [x_t, y_t, z_t] \\\\), Linear speed in 3D computed as the 1-step difference between 3D trajectory points. We employ speed, rather than velocity, as velocity can either be defined w.r.t. the ego-agent's heading, or w.r.t. a global coordinate system, where velocity directions may be city-specific, based on orientation of roads w.r.t. North. Although this cannot capture objects moving in reverse, a rare behavior, we omit it for sake of simplicity.\\n\\n2. Linear Acceleration Magnitude: Signed magnitude of second derivative, in 3D computed as the 1-step difference between speeds of objects.\\n\\\\[ \\\\|v_{t+1}\\\\| - \\\\|v_t\\\\| \\\\]\\n\\n3. Angular Speed: Signed first derivative\\n\\\\[ \\\\omega = \\\\frac{d(\\\\theta_{t+1}, \\\\theta_t)}{\\\\Delta t} \\\\]\\ncomputed as the 1-step difference in heading, where \\\\( d(\\\\cdot) \\\\) represents the minimal angular difference between two angles on the unit circle, i.e., \\\\( d(\\\\cdot) \\\\) is a distance metric on \\\\( SO(2) \\\\) computed as\\n\\\\[ \\\\min\\\\{|\\\\theta_{t+1} - \\\\theta_t|, 2\\\\pi - |\\\\theta_{t+1} - \\\\theta_t|\\\\} \\\\]\\nwith \\\\( \\\\theta_t, \\\\theta_{t+1} \\\\in [0, 2\\\\pi) \\\\).\\n\\n4. Angular Acceleration Magnitude: Second derivative, computed as the 1-step difference in angular speed\\n\\\\[ d(\\\\omega_{t+1}, \\\\omega_t) \\\\]\\n\\n5. Distance to nearest object: Signed distance (in meters) to the nearest object in the scene.\\nWe use Minkowski difference of box polygons, according to a simplified version of the Gilbert\u2013Johnson\u2013Keerthi (GJK) distance algorithm [25].\\n\\n6. Collisions: Count indicating objects that collided, at any point in time, with any other object, i.e. when the signed distances to nearest objects, as described above, achieves a negative value.\\n\\n7. Time-to-collision (TTC): Time (in seconds) before the object collides with the object it is following (if one exists), assuming constant speeds. An object is defined as exhibiting object-following (tailgating) behavior based on alignment conditions derived from heading and lateral distance.\\n\\n8. Distance to road edge: Signed distance (in meters) to the nearest road edge in the scene.\\n\\n9. Road departures: Boolean value indicating whether the object went off the road, at any point in time [60].\\n\\nTo prevent undefined scores from histogram bins with zero support, we employ Laplace smoothing with a pseudocount of 0.1.\\n\\nInserted and Deleted Object Handling\\nIn order to prevent object insertion/deletion bias between the logged and simulated data distributions during evaluation, we discard any newly spawned objects (appearing after the history interval) in the logged test set when computing the logged data distribution. The data distribution in the WOMD dataset already includes such object insertion and deletion.\\n\\nA.6.1 Evaluation Source Code References\\nIn this section, we provide pointers to our specific implementations of the 9 metrics discussed in Section 4.2.1 of the main paper:\\n\\n- Kinematic-based features: Linear speed, linear acceleration magnitude, angular speed, and angular acceleration magnitude (metrics 1, 2, 3, 4): [Code]\\n- Interaction-based features: TTC and distance to nearest object (metrics 5, 6, 7): [Code] and modified GJK algorithm implementation [Code]\\n- Map-based features: Road departures and distance to road edge (metrics 8, 9): [Code]\\n\\nAn implementation of our time-series based NLL computation can be found here: [Code].\\n\\nA.6.2 Evaluation Code License and Dependencies\\nThe WOMD [22] dataset itself is licensed under a non-commercial license (www.waymo.com/open/terms) and the evaluation code for our Waymo Open Sim Agents Challenge (WOSAC) is released under a BSD+limited patent license. See\"}"}
{"id": "5FnttJZQFn", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dependencies used include NumPy (numpy), the Waymo Open Dataset repository (waymo-open-dataset-tf-2-11-0==1.5.2), TensorFlow (tensorflow), Tensor-Flow Probability (tensorflow_probability), Matplotlib (matplotlib), TQDM (tqdm), Protocol Buffers (google.protobuf), and Python standard library imports (os, tarfile, dataclasses).\\n\\nA.7 Additional Information about WOMD Splits Used\\n\\nWe exclude 401 run segments from evaluation due to discrepancies in object counts across the Scenario proto and tf.Example formats, due to object count truncation arising from fixed-shape tf.Example tensors with exactly 128 object slots. We also exclude from evaluation 9 test run segments which are missing maps (however, maps are present for each scenario present in the validation set).\\n\\nTable 5: Statistics of WOMD dataset [22] splits used.\\n\\n| DATASET SPLIT | VALIDATION | TESTING |\\n|---------------|------------|---------|\\n| ALL SCENARIO COUNTS | 44097 | 44920 |\\n| EVALUATED SCENARIO COUNTS | 43696 | 44520 |\\n\\nA.8 Submission Format\\n\\nSubmissions must be uploaded as serialized SimAgentsChallengeSubmission protocol buffer data (\\\"protos\\\"). Each ScenarioRollouts proto within the submission must contain 32 8-second rollouts of simulation data from one scenario. A validation or test set submission may be submitted to the evaluation server.\\n\\nWe provide a Jupyter notebook tutorial with additional instructions and examples on how to generate a submission for a dataset split. We recommend storing multiple ScenarioRollout's in each binary proto file (i.e. in each SimAgentsChallengeSubmission file) to prevent creating a tar.gz file with tens of thousands of files; use of 100 to 150 of such shards is recommended. Please refer to the tutorial notebook for the naming convention of these files. Submission data should be compressed as a single .tar.gz archive and uploaded as a single file.\\n\\n3 WOMD download instructions available at https://waymo.com/intl/en_us/open/download.\\n\\n4 https://protobuf.dev/\"}"}
{"id": "5FnttJZQFn", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nSimulation with realistic, interactive agents represents a key task for autonomous vehicle software development. In this work, we introduce the Waymo Open Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to tackle this task and propose corresponding metrics. The goal of the challenge is to stimulate the design of realistic simulators that can be used to evaluate and train a behavior model for autonomous driving. We outline our evaluation methodology, present results for a number of different baseline simulation agent methods, and analyze several submissions to the 2023 competition which ran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains open for submissions and we discuss open problems for the task.\\n\\n1 Introduction\\n\\nSimulation environments allow cheap and fast evaluation of autonomous driving behavior systems, while also reducing the need to deploy potentially risky software releases to physical systems. While generation of synthetic sensor data was an early goal [19, 43] of simulation, use cases have evolved as perception systems have matured. Today, one of the most promising use cases for simulation is system safety validation via statistical model checking [1, 16] with Monte Carlo trials involving realistically modeled traffic participants, i.e., simulation agents.\\n\\nA requirement for modeling realistic behavior in simulation is the ability for sim agents to respond to arbitrary behavior of the autonomous vehicle (AV). \\\"Pose divergence\\\" or \\\"simulation drift\\\" [3] is defined as the deviation between the AV's behavior in driving logs and its behavior during simulation, which may be represented through differing position, heading, speed, acceleration, and more. Directly replaying logged behavior of all other objects in the scene [32, 34, 35]...\"}"}
{"id": "5FnttJZQFn", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: A comparison of three autonomous-vehicle behavior related tasks which involve generation of a desired future sequence of physical states: trajectory forecasting, planning, and simulation. Note that observations $o_t \\\\in O$ include simulated agent and environment properties.\\n\\n| MULTIPLE VEHICLE SYSTEMS | TASK OBJECTS | OUTPUTS | KINEMATIC EVALUATION | OBJECTIVES |\\n|--------------------------|--------------|---------|----------------------|------------|\\n| Multi-Agent Trajectory Forecasting | \u2713 | | OPEN-LOOOP KINEMATIC ACCURACY AND MODE COVERING |\\n| A V Motion Planning | \u2713 | | CLOSED-LOOOP SAFETY, COMFORT, PROGRESS |\\n| Agent and Environment Simulation | \u2713 | | DISTRIBUTIONAL REALISM |\\n\\nunder arbitrary A V planning may have limited realism because of this pose divergence. Such log-playback agents tend to heavily overestimate the aggressiveness of real actors, as they are unwilling to deviate from their planned route under any circumstances. On the other hand, rule-based agents that follow heuristics such as the Intelligent Driver Model (IDM) [65] are overly accommodating and reactive. We seek to evaluate and encourage the development of sim agents that lie in the middle ground, adhering to a definition of realism that implies matching the full distribution of human behavior.\\n\\nTo the best of our knowledge, to date there is no existing benchmark for evaluation of simulation agents. Benchmarks have spurred notable innovation in other areas related to autonomous driving research, especially for perception [6, 10, 24, 58], motion forecasting [6, 10, 22, 72, 78], and motion planning [19]. We believe a standardized benchmark can likewise spur dramatic improvements for simulation agent development. Among these benchmarks, those focused on motion forecasting are perhaps most similar to simulation, but all involve open-loop evaluation, which is clearly deficient compared to our closed-loop evaluation. Furthermore, we introduce realism metrics which are suitable to evaluating long-term futures. Relevant datasets such as the Waymo Open Motion Dataset (WOMD) [22] exist today that contain real-world agent behavior examples, and we build on top of WOMD to build WOSAC. In this challenge, we focus on a subset of the possible perception outputs, e.g., traffic light states or vehicle attributes are not modeled, but we leave this for future work.\\n\\nThe challenges our benchmark raises are unique, and if we can make real progress on it, we can show that we've solved one of the hard problems in self-driving. We have a number of open questions: Are there benefits to scene-centric, rather than agent-centric, simulation methods? What is the most useful generative modeling framework for the task? What degree of motion planning is needed for agent policies, and how far can marginal motion prediction take us? How can simulation methods be made more efficient? How can we design a benchmark and enforce various simulator properties?\\n\\nDuring our first iteration of the WOSAC challenge, user submissions have helped us answer a subset of these questions; for example, we observed that most methods found it most expedient to build upon state-of-the-art marginal motion prediction methods, i.e. operating in an agent-centric manner.\\n\\nIn this work, we describe in detail the Waymo Open Sim Agents Challenge (WOSAC) with the goal of stimulating interest in traffic simulation and world modeling. Our contributions are as follows:\\n\\n\u2022 An evaluation framework for autoregressive traffic agents based on the approximate negative log likelihood they assign to logged data.\\n\u2022 An evaluation platform, an online leaderboard, available for submission at https://waymo.com/open/challenges/2023/sim-agents/.\\n\u2022 An empirical evaluation and analysis of various baseline methods, as well as several external submissions.\\n\\n2 Related Work\\n\\nMulti-Agent Traffic Simulation\\n\\nSimulators have been used to train and evaluate autonomous driving planners for several decades, dating back to ALVINN [43]. While simulators such as CARLA [19], SUMO [33], and Flow [73] provide only a heuristic driving policy for sim agents, they have still enabled progress in the A V motion planning domain [11, 12, 15]. Other recent simulators such as Nocturne [68] use a simplified world representation that consists of a fixed roadgraph and moving agent boxes.\"}"}
{"id": "5FnttJZQFn", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Existing evaluation methods for simulation agents. Entries are ordered chronologically by Arxiv timestamp. There is limited consensus in the literature regarding how multi-agent simulation should be evaluated.\\n\\n| Evaluation Protocol | ADE orminADE | OffroadRate | CollisionRate | Instance-Level Distribution Matching | Dataset-Level Distribution Matching | Spatial Coverage or Diversity | Goal progress or Completion |\\n|---------------------|--------------|-------------|---------------|--------------------------------------|-----------------------------------|-------------------------------|---------------------------|\\n| ConvSocialPool [17] | \u2713 \u2713           |             |               |                                      |                                   |                               |                           |\\n| Trajectron [29]     | \u2713             | \u2713           |               |                                      |                                   |                               |                           |\\n| PRECOG [48]         | \u2713 \u2713           |             |               |                                      |                                   |                               |                           |\\n| BARK [4]            | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| SMARTS [82]         | \u2713 \u2713           |             |               |                                      |                                   |                               |                           |\\n| TrafficSim [60]     | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| SimNet [3]          | \u2713 \u2713           |             |               |                                      |                                   |                               |                           |\\n| Symphony [28]       | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| Nocturne [68]       | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| BITS [74]           | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| InterSim [59]       | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| MetaDrive [34]      | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| TrafficBots [79]    | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n| WOSAC (Ours)        | \u2713 \u2713 \u2713         |             |               |                                      |                                   |                               |                           |\\n\\nSimulation agent modeling is closely related to the problem of trajectory forecasting, as a sim agent could execute a set of trajectory predictions as its plan [4, 59]. However, as trajectory prediction methods are traditionally trained in open-loop, they have limited capability to recover from out of domain predictions encountered during closed-loop simulation [51]. In addition, few forecasting methods produce consistent joint future samples at the scene level [36, 48]. Sim agent modeling is also related to planning, as each sim agent could execute a replica of a planner independently [4]. However, each of these three tasks differ dramatically in objectives, outputs, and constraints (see Table 1).\\n\\nLearned Sim Agents\\n\\nLearned sim agents in the literature differ widely in assumptions around policy coordination, dynamics model constraints, observability, as well as input modalities. While coordinated scene-centric agent behavior is studied in the open-loop motion forecasting domain [8, 9, 57], to the best of our knowledge, TrafficSim [60] is the only closed-loop, learned sim agent work to use a joint, scene-centric actor policy; all others operate in a decentralized manner without coordination [5, 28, 74], i.e., each agent in the scene is independently controlled by replicas of the same model using agent-centric inference. BITS and TrafficBots [74, 79] use a unicycle dynamics model and Nocturne uses a bicycle dynamics model [68] whereas most others do not specify any such constraint; others enforce partial observability constraints, such as Nocturne [68]. Other methods differ in the type of input, whether rasterized [3, 74] or provided in a vector format [28, 79]. Some works focus specifically on generating challenging scenarios [47], and others aim for user-based controllability [81]. Some are trained via pure imitation learning [3], while others include closed-loop adversarial losses [28, 60], or multi-agent RL [4, 34, 82] in order to learn to recover from its mistakes [51]. Some works such as InterSim [4, 28, 59, 74, 79, 82] use a goal-conditioned problem formulation, while others do not [3].\\n\\nEvaluation of Generative Models\\n\\nDistribution matching has become a common way to evaluate generative models [18, 20, 27, 30, 31, 45, 46, 49, 52, 77], through the Fr\u00e9chet Inception Distance (FID) [26]. Previous evaluation methods such as the Inception Score (IS) [53] reason over the entropy of conditional and unconditional distributions, but are not applicable in our case due to the multi-modality of the simulation problem. The FID improves the Inception Score by using statistics of real world samples, measuring the difference between the generated distributions and a data distribution (in the simulation domain, the logged distribution). However, FID has limited sensitivity per example due to aggregation of statistics over entire test datasets into a single mean and covariance.\\n\\nEvaluating Multi-Agent Simulation\\n\\nThere is limited consensus in the literature regarding how multi-agent simulation should be evaluated (see Table 2), and no mainstream existing benchmark exists. Given the importance of safety, almost all existing sim agent works measure some form of collision rate [3, 28, 59, 60, 68, 74], and some multi-object joint trajectory forecasting methods also measure it via trajectory overlap [36]. However, collision rate can be artificially driven to zero by static policies, and thus cannot measure realism. Quantitative evaluation of realism requires comparison with logged data. Such evaluation methods vary widely, from distribution matching of vehicle dynamics [28, 74], to comparison of offroad rates [28, 60, 74], spatial coverage and diversity [60, 74], and progress to goal [59, 68]. However, as goals are not observable, they are thus difficult to extract reliably. Requiring direct reconstruction of logged data through metrics such as Average Displacement Error (ADE) has also been proposed [3, 68], but has limited effectiveness because...\"}"}
{"id": "5FnttJZQFn", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"there are generally multiple realistic actions the AV or sim agents could take at any given moment. To overcome this limitation, one option is to allow the user to provide multiple possible trajectories per sim agent, such as TrafficSim, which uses a minimum average displacement error (minADE) over 15 simulations.\\n\\nRecently, generative-model based evaluation has become more popular in the simulation domain, primarily through distribution matching metrics. Symphony uses Jensen-Shannon distances over trajectory curvature. NeuralNDE compares distributions of vehicle speed and inter-vehicle distance, whereas BITS utilizes Wasserstein distances on agent scene occupancy using multiple rollouts per scene, along with Wasserstein distances between simulated and logged speed and jerk\u2014two kinematic features which can encapsulate passenger comfort. The latter are computed as a distribution-to-distribution comparison on a dataset level, however, this type of metric has shown limited sensitivity in our experiments.\\n\\nLikelihood metrics\\n\\nAn alternative distribution matching framework is to measure point-to-distribution distances. and introduce a metric defined as the average negative log likelihood (NLL) of the ground truth trajectory, as determined by a kernel density estimate (KDE) over output samples at the same prediction timestep. This metric has found some adoption, and we primarily build off of this metric in our work. We note that likelihood-based generative models of simulation such as PRECOG and MFP directly produce likelihoods, meaning that the use of a KDE on sampled trajectories to estimate likelihoods is not needed for such model classes. Concurrent work also measures the NLL of the GT scene under 6 rollouts.\\n\\n3 Traffic Simulation as Conditional Generative Modeling\\n\\nOur goal is to encourage the design of traffic simulators by defining a data-driven evaluation framework and instantiating it with publicly accessible data. We focus on simulating agent behavior in a setting in which an offboard perception system is treated as fixed and given.\\n\\nProblem formulation.\\n\\nWe formulate driving as a Hidden Markov Model\\n\\n$$H = (S, O, p(\\\\text{out} | s), p(s | s_{t-1}))$$\\n\\nwhere $S$ denotes the set of unobservable true world states, $O$ denotes the set of observations, $p(\\\\text{out} | s)$ denotes the sampleable emission distribution, and $p(s | s_{t-1})$ denotes the hidden Markovian state dynamics: the probability of the hidden state transitioning from $s_{t-1}$ at timestep $t-1$ to $s_t$ at time $t$.\\n\\nEach $\\\\text{out}_t \\\\in O$ can be partitioned into AV- and environment-centric components that vary in time:\\n\\n$$\\\\text{out}_t = [\\\\text{out}_{AV}, \\\\text{out}_{env}]$$\\n\\n$\\\\text{out}_{env}$ can in general contain a rich set of features, but for the purpose of our challenge, it contains solely the poses of the non-AV agents. We denote the true observation dynamics as $p_{world}(\\\\text{out} | s_{t-1}) = \\\\mathbb{E}_{p(s | s_{t-1})} p(\\\\text{out} | s)$.\\n\\nThe task.\\n\\nThe task to build a \\\"world model\\\" $q_{world}(\\\\text{out} | \\\\text{oc} < t)$ of $p_{world}(\\\\text{out} | s_{t-1})$, $\\\\text{oc} < t$.\\n\\nTask constraints:\\n\\n1. $q_{world}$ must be autoregressive for $T$ steps, i.e., sim agent models must adhere to a 10Hz resampling procedure, re-observing the updated scene and consuming their previous outputs.\\n\\n2. $q_{world}$ must factorize according to Eq. 1:\\n\\n$$q_{world}(\\\\text{out} | \\\\text{oc} < t) = \\\\pi(\\\\text{out}_{AV} | \\\\text{oc} < t) q(\\\\text{out}_{env} | \\\\text{oc} < t),$$\\n\\nwhere $q(\\\\text{out}_{env} | \\\\text{oc} < t)$ is a traffic simulator, and $\\\\pi(\\\\text{out}_{AV} | \\\\text{oc} < t)$ is an AV policy. Any submission that fails to satisfy both of these properties will not be considered on WOSAC leaderboards, as determined by\\n\\n1 We call this a policy because it is similar to the typical formulation of a policy in a decision process over actions, although not equivalent, because it is defined over next observations rather than current actions. It can be made equivalent to a standard policy $\\\\pi(\\\\text{a}_{AV} | \\\\text{oc} < t)$ by defining the AV's action space $A$ to be equivalent to its component of the observation space, and defining an action-dependent world model $q_{world}(\\\\text{out} | \\\\text{oc} < t, \\\\text{a}_{AV}$_{t-1}) $= \\\\delta(\\\\text{out}_{AV} = \\\\text{a}_{AV}$_{t-1}) q(\\\\text{out}_{env} | \\\\text{oc} < t)$, where $\\\\delta$ denotes the Dirac delta function.\"}"}
{"id": "5FnttJZQFn", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 2: Graphical model of required factorization as a Bayes net: the two distributions from Eq. 1 are autoregressively interleaved: one represents the AV's policy \\\\(\\\\pi(\\\\text{o}_{AV,t} | \\\\text{o}_{<t}^c)\\\\), and another represents the environmental dynamics \\\\(q(\\\\text{o}_{env,t} | \\\\text{o}_{<t}^c)\\\\); the graphical model represent \\\\(T\\\\)-steps of applying these two distributions. Thick outgoing arrows denote passing inputs from all parent nodes to all children.\\n\\nMuch of the challenge of modeling \\\\(p_{world}\\\\) lies in the fact that in many situations \\\\(s_{t-1} \\\\in S\\\\), \\\\(p_{world}\\\\) assigns density to multiple outcomes due to uncertainty from agents in the scene, which means that both \\\\(\\\\pi(\\\\text{o}_{AV,t} | \\\\text{o}_{<t}^c)\\\\) and \\\\(q(\\\\text{o}_{env,t} | \\\\text{o}_{<t}^c)\\\\) often must contain multiple modes in order to perform well. We evaluate distribution-matching of \\\\(p_{world}\\\\) relative to a dataset of logged outcomes. The required factorization into \\\\(p_{world}(\\\\text{o}_t | \\\\text{o}_{<t}^c) = \\\\pi(\\\\text{o}_{AV,t} | \\\\text{o}_{<t}^c)q(\\\\text{o}_{env,t} | \\\\text{o}_{<t}^c)\\\\), is fairly flexible. We are agnostic to their particular structures. One noteworthy choice for the environment observation dynamics is a \u201cmulti-agent\u201d factorization, in which \\\\(q(\\\\text{o}_{env,t} | \\\\text{o}_{<t}^c) = \\\\prod_{Aa=1} \\\\pi_a(\\\\text{o}_{env,a,t} | \\\\text{o}_{<t}^c)\\\\), i.e., the environment observation dynamics factorizes into a sequence of \\\\(A\\\\) observation-space policies, and the environment observation itself is partitioned into \\\\(A\\\\) different components, one for each agent: \\\\(o_{env,t} = [o_{env,1t}, ..., o_{env,At}]\\\\).\\n\\nAlgorithm 1: Valid: Factorized, Closed-Loop, Agent-Centric Simulation\\n\\nInput: Map \\\\(o_{map}\\\\) and traffic signals \\\\(o_{signals}\\\\). Initial actor states \\\\(o_{H-1:0} = \\\\{o_{H-1}, ..., o_0\\\\}\\\\) where each \\\\(o_{env,t} = \\\\{o_{env,1t}, ..., o_{env,At}\\\\}\\\\) for the \\\\(A\\\\) actors in the scene.\\n\\nOutput: Simulated observations \\\\(o_{1:T} = \\\\{o_1, o_2, ..., o_T\\\\}\\\\) for \\\\(T\\\\) simulation timesteps.\\n\\n\\\\[\\\\begin{align*}\\n1: & \\\\text{ for } t = 1, ..., T \\\\\\\\\\n2: & \\\\quad \\\\text{ Simulate for requested number of timesteps} \\\\\\\\\\n3: & \\\\quad o_{AV,t} \\\\leftarrow \\\\pi_{AV}(o_{<t}; o_{map}, o_{signals}) \\\\\\\\\\n4: & \\\\quad \\\\text{ for } a = 1, ..., A \\\\\\\\\\n5: & \\\\quad \\\\quad \\\\text{Produce next state for each actor at each timestep} \\\\\\\\\\n6: & \\\\quad \\\\quad o_{env,a,t} \\\\leftarrow \\\\pi_a(o_{<t}; o_{map}, o_{signals}) \\\\\\\\\\n7: & \\\\quad \\\\quad o_t = \\\\{o_{env,a,t}: \\\\forall a \\\\in 1...A\\\\} \\\\cup \\\\{o_{AV,t}\\\\} \\\\\\\\\\n8: & \\\\text{ return } o_{1:T} = \\\\{o_1, o_2, ..., o_T\\\\}\\n\\\\end{align*}\\\\]\\n\\nAlgorithm 2: Invalid: Factorized, Open-Loop, Agent-Centric Simulation\\n\\nInput: Map \\\\(o_{map}\\\\) and traffic signals \\\\(o_{signals}\\\\). Initial actor states \\\\(o_{H-1:0} = \\\\{o_{H-1}, ..., o_0\\\\}\\\\) where each \\\\(o_{env,t} = \\\\{o_{env,1t}, ..., o_{env,At}\\\\}\\\\) for the \\\\(A\\\\) actors in the scene.\\n\\nOutput: Simulated observations \\\\(o_{1:T} = \\\\{o_1, o_2, ..., o_T\\\\}\\\\) for \\\\(T\\\\) simulation timesteps.\\n\\n\\\\[\\\\begin{align*}\\n1: & \\\\quad o_{AV,1:T} \\\\leftarrow \\\\pi_{AV}(o_{<1}; o_{map}, o_{signals}) \\\\\\\\\\n2: & \\\\quad \\\\text{ for } a = 1, ..., A \\\\\\\\\\n3: & \\\\quad \\\\quad \\\\text{Produce states at all future timesteps for each actor} \\\\\\\\\\n4: & \\\\quad \\\\quad o_{env,a,1:T} \\\\leftarrow \\\\pi_a(o_{<1}; o_{map}, o_{signals}) \\\\\\\\\\n5: & \\\\text{ return } o_{1:T} = \\\\{o_{env,a,1:T}: \\\\forall a \\\\in 1...A\\\\} \\\\cup \\\\{o_{AV,1:T}\\\\}\\n\\\\end{align*}\\\\]\\n\\n4 Benchmark Overview\\n\\n4.1 Dataset\\n\\nFor WOSAC, we use the test data from the v1.2.0 release of the Waymo Open Motion Dataset (WOMD) [22]. We treat WOMD as a set \\\\(D\\\\) of scenarios where each scenario is a history-future\"}"}
{"id": "5FnttJZQFn", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"pair \\\\((o\u2212H\u22121:0, o\u22651)\\\\). This dataset offers a large quantity of high-fidelity object behaviors and shapes produced by a state-of-the-art offboard perception system. We use WOMD's 9 second 10 Hz sequences (comprising \\\\(H=11\\\\) observations from 1.1 seconds of history and 80 observations from 8 seconds of future data), which contain object tracks at 10 Hz and map data for the area covered by the sequence. Across the dataset splits, there exists 486,995 scenarios in train, 44,097 in validation, and 44,920 in test. These 9.1 second windows have been sampled with varying overlap from 103,354 mined segments of 20 second duration. Up to 128 agents (one of which must represent the AV) must be simulated in each scenario for the 8 second future (comprising 80 steps of simulation).\\n\\n**Agent Definition**\\n\\nWe require simulation of all agents that have valid measurements at time \\\\(t=0\\\\), i.e. the last step of logged initial conditions before simulation begins. Because the test split data is sequestered, users will not have access to objects that appear after the time of handover, and so therefore could not be expected to simulate them. We require simulation of all three WOMD object types (vehicles, cyclists, and pedestrians). Objects\u2019 dimensions stay fixed as per the last step of history (while they do change in the original data).\\n\\n**Submission**\\n\\nWe do not enforce any motion model (also because we have multiple agent types), which means users need to directly report \\\\(x/y/z\\\\) centroid coordinates and heading of the objects\u2019 boxes (which could be generated directly or through an appropriate motion model). See the Appendix for additional information on the submission format.\\n\\nBy allowing users to produce the simulations themselves, we reduce the burden on the user by avoiding the need to submit containerized software for an evaluation server.\\n\\n**4.2 Evaluation**\\n\\nAgents should generate realistic driving scenarios stochastically. We define \u201crealistic agents\u201d as those that match the actual distribution of scenarios observed during real-world driving. Unfortunately, we do not know the analytic form of the distribution, but we do have samples from it: the examples that make up WOMD. We therefore evaluate submissions using the approximate negative log likelihood (NLL) of real world samples under the distribution induced by the agents.\\n\\nThe NLL we wish to minimize is given by:\\n\\n\\\\[\\n\\\\text{NLL}^* = -\\\\frac{1}{|D|} \\\\sum_{i=1}^{|D|} \\\\log q_{\\\\text{world}}(o \\\\geq 1, i | o < 1, i)\\n\\\\]\\n\\nHowever, there are two problems with trying to minimize Equation 2 exactly in our problem setting. First, \\\\(o \\\\geq 1\\\\) is high-dimensional. Instead of trying to parameterize the entire ground truth scenario and compute its NLL under a simulated distribution, we therefore parameterize scenarios with a smaller number of component metrics (see Section 4.2.1) and aggregate them together into a composite NLL metric (see Section 4.2.2). Second, agents may support sampling but not pointwise likelihood estimation [41]. In fact, we only require challenge entrants to submit samples from their agents, and therefore have no way of knowing the exact likelihood of logged scenarios under different agent submissions. To avoid this problem, we standardize the NLL computation by fitting histograms to the 32 submitted samples of agent futures, and compute NLLs under the categorical distribution induced by normalizing the histograms.\\n\\n**4.2.1 Component Metrics**\\n\\nBreaking NLL * into component metrics has a few benefits. It mitigates the curse of dimensionality described in Section 4.2. It also adds more interpretability to the evaluation, allowing researchers to trade off between different types of errors.\\n\\n**Time Series NLL**: Given the time series nature of simulation data, two choices emerge for how to treat samples over multiple timesteps for a given object for a given run segment: to treat them as time-independent or time-dependent samples. In the latter case, users would be expected to not only reconstruct the general behaviors present in the logged data in one rollout, but also recreate those behaviors over the exact same time intervals. To allow more flexibility in agent behavior, we use the former formulation when computing NLLs, defining each component metric \\\\(m\\\\) as an average (in log-space) over the time-axis, masked by validity \\\\(v_t\\\\):\\n\\n\\\\[\\nm = \\\\exp \\\\left( -\\\\frac{1}{\\\\sum_{t=1}^{T} \\\\{v_t\\\\}} \\\\sum_{t=1}^{T} \\\\{v_t\\\\} NLL_t \\\\right)\\n\\\\]\"}"}
{"id": "5FnttJZQFn", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Simulation Input Log Playback Wayformer Constant Velocity (Logged Oracle) (Diverse Sample)\\n\\nFigure 3: Visualizations of simulation results on two separate WOMD scenes (top, bottom). Results for various baseline methods are shown on WOMD's validation split, in 2d. 'Simulation input' represents the context history $o_{-H-1:0}$, whereas all other columns visualize both $(o_{-H-1:0}, o_{\u22651})$.\\n\\nTwo scenes are represented: one where the AV completes the execution of a left turn (top row) and another where the AV remains stopped at a red traffic signal (bottom row). Each rendering in the second and third columns depicts the entire duration of the scene. Trajectories of environment agents are drawn in a green-blue gradient, and trajectories of the AV agent are drawn in a red-yellow gradient (each as a sequence of circles in a temporal color gradient).\\n\\nHowever, we note that as a result, a logged oracle will not achieve likelihoods of 1.0, whereas in the latter formulation a logged oracle would.\\n\\nDefinitions\\nWe compute NLLs over 9 measurements: kinematic metrics (linear speed, linear acceleration, angular speed, angular acceleration magnitude), object interaction metrics (distance to nearest object, collisions, time-to-collision), and map-based metrics (distance to road edge, and road departures). Please refer to Section A.6 of the Appendix for a complete description and additional implementation details.\\n\\n4.2.2 Composite Metric\\nAfter obtaining component metrics for each measurement, we aggregate them into a single composite metric $M_K$ for evaluating submissions:\\n\\n$$M_K = \\\\frac{1}{NM_K} \\\\sum_{i=1}^{N} \\\\sum_{j=1}^{M} w_{j,m_{K,i,j}}$$\\n\\nwhere $N$ is the number of scenarios and $M = 9$ is the number of component metrics. The component metrics $m$ and composite metric $M$ are also parameterized by a number of samples $K = 32$. The value $m_{i,j}$ represents the likelihood for the $j$th metric on the $i$th example. The metric $M$ is simply a convex combination (i.e. weighted average) over the component metrics, where the weight $w_j$ for the $j$th metric is set manually. In the interest of promoting safety, the weighting for collision and road departure NLLs are set to be $2 \\\\times$ larger than the weight for the other component metrics.\\n\\n5 Experimental Results\\nIn Figure 4 and Table 3, we present quantitative results for a handful of methods. We describe each method in more detail in the sections below.\"}"}
{"id": "5FnttJZQFn", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.1 Baselines\\nRandom Agent: An agent that produces random trajectories \\\\{(x_t, y_t, \\\\theta_t)\\\\}_{t=1}^T, for \\\\(T = 80\\\\), with \\\\(x, y, \\\\theta \\\\sim N(\\\\mu, \\\\sigma^2)\\\\), with \\\\(\\\\mu = 1.0\\\\) and \\\\(\\\\sigma = 0.1\\\\), in the AV\u2019s coordinate frame.\\n\\nConstant Velocity Agent: An agent that extrapolates the trajectory using the last heading and speed recorded in the provided context/history. If no two-step difference can be computed based on the valid measurements (e.g., the object appeared only at the final step of context), we set a zero speed for such agents.\\n\\nWayformer (Identical Samples) Agent: An agent that produces a hybrid of open-loop and closed-loop data using a Wayformer [40] motion prediction model, by executing model inference autoregressively at 2Hz. The agents execute the policy forward for 5 simulation steps, and then replan. Results with a 10 Hz replan rate instead are also shown in Table 3, and an ablation on the replan rate is provided in the Appendix. The maximum-likelihood trajectory for each agent is identically repeated 32 times to produce 32 samples. Each agent is executed by the same policy in an agent-centric frame, batched together for inference, thus complying with the required factorization.\\n\\nWayformer (Diverse Samples) Agent: An agent that also utilizes Wayformer [40]-generated trajectories, but samples diverse agent plans, from \\\\(K\\\\) possible trajectories according to their likelihood, instead of selecting the maximum-likelihood choice.\\n\\nLogged Oracle: Agent that directly copies trajectories from the WOMD test split, with 32 repetitions.\\n\\n5.2 External Submissions\\n\\nMultiVerse Transformer for Agent simulation (MVTA) [71]: A method inspired by MTR [55, 56] that is trained and executed in closed-loop. MVTA uses a \u2018receding horizon\u2019 policy with a GMM head, and consumes vector inputs.\\n\\nMVTE: An enhanced version of MVTA [71] that samples a MVTA model from a pool of model variants to increase simulation diversity across rollouts.\\n\\nMTR+++: A hybrid open-loop/closed-loop method with a 0.5Hz replanning rate that is inspired by MTR [55, 56] and searches for the densest subgraph in a graph of non-colliding future trajectories.\\n\\nFor a description of other evaluated external submissions, please refer to Section A.4 of the Appendix.\\n\\n5.3 Learnings from the 2023 Challenge\\n\\nDuring the course of our 2023 WOSAC Challenge (March 16, 2023 to May 23, 2023), associated with the CVPR 2023 Workshop on Autonomous Driving, we received 24 test set submissions, and 16 validation set submissions, from 10 teams. We continue to receive submission queries to our evaluation server for our standing leaderboard as new teams submit new methods.\\n\\nTrends\\nWe observed several trends among submissions. First, the challenge champion, MVTA/MVTE [71], was the only method to utilize and benefit from closed-loop training. Other methods that were trained in open-loop, such as MTR+++ [44] or our Wayformer-derived [40] baseline, found operating\"}"}
{"id": "5FnttJZQFn", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Per-component metric results on the test split of WOMD, representing likelihoods. Methods are ranked by composite metric on the V1 Leaderboard, rather than the previous V0 Leaderboard; numbers within 1% of the best are in bold (excluding \u2018logged oracle\u2019). * indicates a method that was received after May 23, 2023, which marked the close of the CVPR 2023 competition.\\n\\n| Method                                  | Linear Speed Likelihood | Angular Speed Likelihood | Distance to Object Likelihood | Road Edge Metric Likelihood | Time To Collision Likelihood | TTC Likelihood | Composite ADE | Min ADE | ADE Difference |\\n|-----------------------------------------|-------------------------|--------------------------|-------------------------------|-----------------------------|------------------------------|----------------|---------------|---------|---------------|\\n| AGENT                                   | 0.002                   | 0.074                    | 0.120                         | 0.000                       | 0.000                        | 0.734          | 0.178         | 0.287   | 0.155         |\\n| CONSTANT VELOCITY                        | 0.074                   | 0.058                    | 0.019                         | 0.035                       | 0.208                        | 0.345          | 0.737         | 0.454   | 0.455         |\\n| CONSTANT VELOCITY (Gaussian Noise)      | 0.157                   | 0.119                    | 0.019                         | 0.035                       | 0.247                        | 0.411          | 0.775         | 0.502   | 0.463         |\\n| WAYFORMER (IDENTICAL SAMPLES, 10 REPLAN) | 0.202                   | 0.144                    | 0.248                         | 0.312                       | 0.192                        | 0.449          | 0.766         | 0.379   | 0.305         |\\n| WAYFORMER (REVERSE SAMPLES, 10 REPLAN)  | 0.233                   | 0.212                    | 0.345                         | 0.330                       | 0.241                        | 0.635          | 0.797         | 0.424   | 0.421         |\\n| MTR+++                                   | 0.414                   | 0.107                    | 0.484                         | 0.436                       | 0.347                        | 0.861          | 0.797         | 0.654   | 0.895         |\\n| MVTA                                     | 0.439                   | 0.220                    | 0.533                         | 0.480                       | 0.374                        | 0.875          | 0.829         | 0.654   | 0.908         |\\n| MVTE                                     | 0.445                   | 0.222                    | 0.535                         | 0.481                       | 0.383                        | 0.893          | 0.832         | 0.664   | 0.908         |\\n| LOGGED ORACLE                           | 0.561                   | 0.330                    | 0.563                         | 0.489                       | 0.485                        | 1.000          | 0.881         | 0.713   | 1.000         |\\n\\nSecond, almost all submissions used Transformer-based methods [67], except for JointMultiPath++, which used LSTM and MCG blocks [66]. Third, all methods built primarily on top of existing motion prediction works, rather than upon existing motion planning works or sim agent methods from the literature. Only one method, MVTA/MVTE [71], incorporated aspects of an existing sim agent work, TrafficSim [60], as well as motion planning techniques, implementing a receding horizon planning policy. Thus, fourth, we observed the benefit of incorporating planning-based methods into a motion prediction framework. Fifth, most methods (excluding JointMultipath++ [70]) built upon the 2022 CVPR Waymo Open Motion Prediction challenge champion, MTR [55, 56], likely due to the open-source availability of its codebase and SOTA performance. Finally, all submissions operated in an agent-centric coordinate frame, rather than jointly sampling from a scene representation simultaneously.\\n\\nLikelihood Metrics Reward Diversity\\nWe found that our likelihood-based metrics reward models that produce diverse futures. For example, generating 32 diverse rollouts per scene with a Wayformer model performs 11% better on our evaluation metrics than a Wayformer model that produces 32 identical rollouts per scene (see Figure 4).\\n\\nCollision Minimization as an Algorithmic Objective\\nSeveral methods designed algorithmic components to determine futures with a minimal number of collisions, e.g., MTR+++ [44] which used clique-finding in an undirected graph of collision-free future trajectories, and CAD [14], which used rejection sampling on open-loop futures that created collisions. This objective aligns with human preference, but as close calls and collisions do occur in real driving data distributions, optimizing for this objective could be seen as trimming the tail of the distribution; distracted drivers generally do exist in everyday real world driving, and in certain scenarios, one would expect a low-quality planner to perform poorly and produce collisions with sim agents, and so such should be taken into consideration for generating realistic simulations. This suggests a limitation of the WOMD [22], which has few examples from the tail distribution of real driving, and efforts to upsample collision data could prove useful. In addition, open-loop methods such as CAD [14] that prune collisions after the fact could prune collisions caused by the AV rather than by the sim agents, yielding a misleadingly optimistic view of the AV\u2019s performance.\\n\\nComposite Metric vs. (min-)ADE and ADE:\\nWe see that among submissions to the test set, rankings by ADE and minADE and ranking by our NLL composite metric disagree. However, methods with lower minADE do tend to achieve higher composite scores; ADE does not exhibit such a trend.\\n\\nComposite Metric Results\\nThe ordinal ranking shown in Figure 4 and Table 3 indicates that learned, stochastic sim agents outperform not only heuristic baselines but also learned, deterministic sim agents. We consider a composite metric score of 0.722 as a practical upper bound on submissions, because it involves access to test data via an oracle.\\n\\nComponent Metric Results\\nIn Table 3, we provide a breakdown of the composite metric into component metric results. As expected, the \u2018logged oracle\u2019 baseline achieves the highest likelihood in each of the 9 component metrics. The top performing method, MVTE [71] scored highest on all but one component metric (linear acceleration likelihood), where CAD [14] outperformed MVTE by 12% (likelihood of 0.253 vs. 0.222). Surprisingly, MVTE [71] has angular acceleration likelihoods within a percentage point of the \u2018logged oracle\u2019 (0.481 vs. 0.489). The gap between the top performing learned method (MVTE) and \u2018logged oracle\u2019 in both collision likelihood (0.893 vs. 1.000) and\"}"}
{"id": "5FnttJZQFn", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"distance-to-nearest object likelihood (0.383 vs. 0.485) indicates significant room for improvement in future work on interactive metrics.\\n\\n5.4 Qualitative Results\\nIn Figure 3, we provide a qualitative comparison of various baselines on two WOMD scenarios. The results indicate that the complexity of behaviors within intersections far exceeds the capability of simple heuristics to predict. Collisions are evident from the constant velocity baselines in both examples. Additional qualitative examples from other sim agent methods are shown in Section A.5 of the Appendix.\\n\\n6 Discussion\\nLimitations.\\nFor our 2023 Challenge, we manually verified the validity of each submission according to factorization and closed-loop requirements discussed in each team's report, and we observed that the technical rules were subtle. Several of the submissions that used open-loop or hybrid open-loop/closed-loop methods may have limited applicability for some simulation applications. Even if we had instituted a benchmark based on Docker-containerized software submissions instead of uploading output trajectory submissions, enforcing our requirements algorithmically and automatically would still be challenging. Although many properties of function calls to Dockerized software can be measured, e.g. latency, as long as any arbitrary state is maintained by the user, the system could not enforce all details of the closed-loop nature of the function call. As a result, user-submitted simulation agent software would have to adhere to strict stateless input and output data APIs. The ability to do so would assist in removing ambiguity regarding whether methods that prune collisions post-hoc qualify as closed-loop.\\n\\nIf a user provides containerized simulator submissions, one approach to encourage adherence to our requirements and to further incentivize closed-loop behavior would be to provide and interact with an A/V policy that the user does not control. In our benchmark, the user was allowed to control the A/V, albeit through an independent policy; the ability to evaluate simulator submissions on separate, held-out A/V motion planning policies and on new scenarios would allow further valuable analysis.\\n\\nFuture Work\\nObject insertion and deletion are important aspects of the simulation problem, yet we intentionally introduced an assumption of no object insertion or deletion in order to reduce the complexity of the first iteration of the WOSAC challenge for users. Motion planners trained or evaluated in a simulator must have the capability to exercise caution regarding areas of occlusion from which new objects may emerge at any timestep. In a future iteration of the challenge, we plan to introduce realism metrics that reward properly-modeled object insertion and deletion, e.g. distributional metrics on the number of vehicles appearing or disappearing at each frame, or the distance of simulated objects from the autonomous vehicle. The data distribution in the WOMD dataset already includes such object insertion and deletion.\\n\\nFurthermore, we intentionally introduced an assumption of time-invariant object dimensions in our first iteration of WOSAC to simplify the modeling challenge for users. Time-variant object dimensions can be considered as a type of vehicle attribute, and object dimensions do actually change in the underlying data distribution provided in the WOMD dataset. We hope to include time-variant object dimension prediction as an aspect of the benchmark in future iterations.\\n\\nAs discussed in Section 5.3, given the prevalence of collision minimization algorithmic components among submissions, one may presume that collisions are not heavily represented in WOMD [22] data, or our metrics are limited in some way. Another approach would be to \\\"fatten the tails\\\" of the evaluation data distribution by generating synthetic, challenging initial conditions [3, 21, 23, 47, 61, 69], or mining more close calls and collisions from real driving data.\\n\\nConclusion.\\nIn this work, we have introduced a new challenge for evaluation of simulation agents, explaining the rationale for the different criteria we require. We invite the research community to continue to participate.\"}"}
{"id": "5FnttJZQFn", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments and Disclosure of Funding\\n\\nNo third-party funding received in direct support of this work. We thank Ben Sapp for his helpful feedback in preparing the challenge. We would like thank Mustafa Mustafa, Kratarth Goel, Rami Al-Rfou for offering consultation, models and infrastructure that accelerated our work. We thank Alexander Gorban for his assistance in developing and maintaining the evaluation server. All the authors are employees of Waymo LLC.\\n\\nReferences\\n\\n[1] Gul Agha and Karl Palmskog. A survey of statistical model checking. ACM Transactions on Modeling and Computer Simulation (TOMACS), 28(1):1\u201339, 2018.\\n[2] Mayank Bansal, Alex Krizhevsky, and Abhijit S. Ogale. ChauffeurNet: Learning to drive by imitating the best and synthesizing the worst. In Robotics: Science and Systems XV, 2019.\\n[3] Luca Bergamini, Yawei Ye, Oliver Scheel, Long Chen, Chih Hu, Luca Del Pero, B\u0142a\u017c Osi\u0144ski, Hugo Grimmet, and Peter Ondruska. SimNet: Learning reactive self-driving simulations from real-world observations. In ICRA, 2021.\\n[4] Julian Bernhard, Klemens Esterle, Patrick Hart, and Tobias Kessler. BARK: Open behavior benchmarking in multi-agent environments. In IROS, 2020.\\n[5] Raunak P Bhattacharyya, Derek J Phillips, Blake Wulfe, Jeremy Morton, Alex Kuefler, and Mykel J Kochenderfer. Multi-agent imitation learning for driving simulation. In IROS, 2018.\\n[6] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuScenes: A multimodal dataset for autonomous driving. In CVPR, pages 11621\u201311631, 2020.\\n[7] Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye Kit Fong, Eric Wolff, Alex Lang, Luke Fletcher, Oscar Beijbom, and Sammy Omari. Nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles. In CVPR ADP3 workshop, 2021.\\n[8] Sergio Casas, Cole Gulino, Renjie Liao, and Raquel Urtasun. SpAGNN: Spatially-aware graph neural networks for relational behavior forecasting from sensor data. In ICRA, pages 9491\u20139497, 2020.\\n[9] Sergio Casas, Cole Gulino, Simon Suo, Katie Luo, Renjie Liao, and Raquel Urtasun. Implicit latent variable model for scene-consistent motion forecasting. In ECCV, 2020.\\n[10] Ming-Fang Chang, John Lambert, Patsorn Sangkloy, Jagjeet Singh, Slawomir Bak, Andrew Hartnett, De Wang, Peter Carr, Simon Lucey, Deva Ramanan, and James Hays. Argoverse: 3d tracking and forecasting with rich maps. In CVPR, June 2019.\\n[11] Dian Chen, Brady Zhou, Vladlen Koltun, and Philipp Kr\u00e4henb\u00fchl. Learning by cheating. In Conference on Robot Learning, pages 66\u201375. PMLR, 2020.\\n[12] Dian Chen, Vladlen Koltun, and Philipp Kr\u00e4henb\u00fchl. Learning to drive from a world on rails. In ICCV, pages 15590\u201315599, 2021.\\n[13] Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan, Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, and Raquel Urtasun. Geosim: Realistic video simulation via geometry-aware composition for self-driving. In CVPR, pages 7230\u20137240, June 2021.\\n[14] Hsu-kuang Chiu and Stephen F. Smith. Collision avoidance detour: A solution for 2023 waymo open dataset challenge - sim agents. Technical report, Carnegie Mellon University, 2023.\\n[15] Felipe Codevilla, Matthias M\u00fcller, Antonio L\u00f3pez, Vladlen Koltun, and Alexey Dosovitskiy. End-to-end driving via conditional imitation learning. In ICRA, pages 4693\u20134700. IEEE, 2018.\\n[16] Anthony Corso, Robert Moss, Mark Koren, Ritchie Lee, and Mykel Kochenderfer. A survey of algorithms for black-box safety validation of cyber-physical systems. Journal of Artificial Intelligence Research, 72:377\u2013428, 2021.\\n[17] Nachiket Deo and Mohan M. Trivedi. Convolutional social pooling for vehicle trajectory prediction. In CVPR Workshops. Computer Vision Foundation / IEEE Computer Society, 2018.\"}"}
{"id": "5FnttJZQFn", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[10] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In NeurIPS, 2021.\\n\\n[19] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun. CARLA: An open urban driving simulator. In CoRL, 2017.\\n\\n[20] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In CVPR, 2021.\\n\\n[21] Nick Roy, Ethan Pronovost, Kai Wang. Generating driving scenes with diffusion. In ICRA Workshop on Scalable Autonomous Driving, June 2023.\\n\\n[22] Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles R. Qi, Yin Zhou, Zoey Yang, Aur\u00e9lien Chouard, Pei Sun, Jiquan Ngiam, Vijay Vasudevan, Alexander McCauley, Jonathon Shlens, and Dragomir Anguelov. Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset. In ICCV, 2021.\\n\\n[23] Lan Feng, Quanyi Li, Zhenghao Peng, Shuhan Tan, and Bolei Zhou. Trafficgen: Learning to generate diverse and realistic traffic scenarios. In ICRA, 2023.\\n\\n[24] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In CVPR, 2012.\\n\\n[25] E.G. Gilbert, D.W. Johnson, and S.S. Keerthi. A fast procedure for computing the distance between complex objects in three-dimensional space. IEEE Journal on Robotics and Automation, 4(2):193\u2013203, 1988.\\n\\n[26] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017.\\n\\n[27] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In NeurIPS, 2020.\\n\\n[28] Maximilian Igl, Daewoo Kim, Alex Kuefler, Paul Mougin, Punit Shah, Kyriacos Shiarlis, Dragomir Anguelov, Mark Palatucci, Brandyn White, and Shimon Whiteson. Symphony: Learning realistic and diverse agents for autonomous driving simulation. In ICRA, 2022.\\n\\n[29] Boris Ivanovic and Marco Pavone. The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs. In ICCV, October 2019.\\n\\n[30] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In CVPR, 2019.\\n\\n[31] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In CVPR, 2020.\\n\\n[32] Parth Kothari, Christian Perone, Luca Bergamini, Alexandre Alahi, and Peter Ondruska. Drivergym: Democratising reinforcement learning for autonomous driving. arXiv preprint arXiv:2111.06889, 2021.\\n\\n[33] Daniel Krajzewicz, Georg Hertkorn, Christian R\u00f6ssel, and Peter Wagner. Sumo (simulation of urban mobility)-an open-source traffic simulation. In Proceedings of the 4th middle East Symposium on Simulation and Modelling (MESM2002), pages 183\u2013187, 2002.\\n\\n[34] Quanyi Li, Zhenghao Peng, Lan Feng, Qihang Zhang, Zhenghai Xue, and Bolei Zhou. Metadrive: Composing diverse driving scenarios for generalizable reinforcement learning. TPAMI, 2022.\\n\\n[35] Yiren Lu, Justin Fu, George Tucker, Xinlei Pan, Eli Bronstein, Becca Roelofs, Benjamin Sapp, Brandyn White, Aleksandra Faust, Shimon Whiteson, et al. Imitation is not enough: Robustifying imitation with reinforcement learning for challenging driving scenarios. In IROS, 2023.\\n\\n[36] Wenjie Luo, Cheol Park, Andre Cornman, Benjamin Sapp, and Dragomir Anguelov. Jfp: Joint future prediction with interactive multi-agent modeling for autonomous driving. In CoRL, 2023.\\n\\n[37] Sivabalan Manivasagam, Shenlong Wang, Kelvin Wong, Wenyuan Zeng, Mikita Sazanovich, Shuhan Tan, Bin Yang, Wei-Chiu Ma, and Raquel Urtasun. Lidarsim: Realistic lidar simulation by leveraging the real world. In CVPR, June 2020.\\n\\n[38] Xiaoyu Mo, Haochen Liu, Zhiyu Huang, and Chen Lv. Simulating behaviors of traffic agents for autonomous driving via interactive autoregression. Technical report, Nanyang Technological University, 2023.\"}"}
{"id": "5FnttJZQFn", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Xiaoyu Mo, Yang Xing, Haochen Liu, and Chen Lv. Map-adaptive multimodal trajectory prediction using hierarchical graph neural networks. IEEE Robotics and Automation Letters, 8(6):3685\u20133692, 2023.\\n\\nNigamaa Nayakanti, Rami Al-Rfou, Aurick Zhou, Kratarth Goel, Khaled S Refaat, and Benjamin Sapp. Wayformer: Motion forecasting via simple & efficient attention networks. In ICRA, 2023.\\n\\nSebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. Advances in neural information processing systems, 29, 2016.\\n\\nEmanuel Parzen. On estimation of a probability density function and mode. The annals of mathematical statistics, 33(3):1065\u20131076, 1962.\\n\\nDean A. Pomerleau. Alvinn: An autonomous land vehicle in a neural network. In Advances in Neural Information Processing Systems, 1988.\\n\\nCheng Qian, Di Xiu, and Minghao Tian. A simple yet effective method for simulating realistic multi-agent behaviors. Technical report, 2023.\\n\\nAditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In ICML, 2021.\\n\\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.\\n\\nDavis Rempe, Jonah Philion, Leonidas J Guibas, Sanja Fidler, and Or Litany. Generating useful accident-prone driving scenarios via a learned traffic prior. In CVPR, June 2022.\\n\\nNicholas Rhinehart, Rowan McAllister, Kris Kitani, and Sergey Levine. Precog: Prediction conditioned on goals in visual multi-agent settings. In ICCV, October 2019.\\n\\nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022.\\n\\nMurray Rosenblatt. Remarks on some nonparametric estimates of a density function. The annals of mathematical statistics, pages 832\u2013837, 1956.\\n\\nStephane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, 2011.\\n\\nChitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In NeurIPS, 2022.\\n\\nTim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Proceedings of the 30th International Conference on Neural Information Processing Systems, 2016.\\n\\nTim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and Marco Pavone. Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data. In ECCV, 2020.\\n\\nShaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele. Mtr-a: 1st place solution for 2022 waymo open dataset challenge \u2013 motion prediction, 2022.\\n\\nShaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele. Motion transformer with global intention localisation and local movement refinement. In Advances in Neural Information Processing Systems, 2022.\\n\\nDiJia Su, Bertrand Douillard, Rami Al-Rfou, Cheolho Park, and Benjamin Sapp. Narrowing the coordinate-frame gap in behavior prediction models: Distillation for efficient and accurate scene-centric motion forecasting. arXiv:2206.03970, 2022.\\n\\nPei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al. Scalability in perception for autonomous driving: Waymo open dataset. In CVPR, 2020.\\n\\nQiao Sun, Xin Huang, Brian Williams, and Hang Zhao. InterSim: Interactive traffic simulation via explicit relation modeling. In IROS, 2022.\"}"}
{"id": "5FnttJZQFn", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Simon Suo, Sebastian Regalado, Sergio Casas, and Raquel Urtasun. Trafficsim: Learning to simulate realistic multi-agent behaviors. In CVPR, 2021.\\n\\nShuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, and Raquel Urtasun. Scenegen: Learning to generate realistic traffic scenes. In CVPR, June 2021.\\n\\nMatthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Pradhan, Ben Mildenhall, Pratul P. Srinivasan, Jonathan T. Barron, and Henrik Kretzschmar. Block-nerf: Scalable large scene neural view synthesis. In CVPR, 2022.\\n\\nCharlie Tang and Russ R Salakhutdinov. Multiple futures prediction. In NeurIPS, 2019.\\n\\nLuca Anthony Thiede and Pratik Prabhanjan Brahma. Analyzing the variety loss in the context of probabilistic trajectory prediction. In ICCV, October 2019.\\n\\nMartin Treiber, Ansgar Hennecke, and Dirk Helbing. Congested traffic states in empirical observations and microscopic simulations. Physical review E, 62(2):1805, 2000.\\n\\nBalakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivastava, Khaled S. Refaat, Nigamaa Nayakanti, Andre Cornman, Kan Chen, Bertrand Douillard, Chi Pang Lam, Dragomir Anguelov, and Benjamin Sapp. Multipath++: Efficient information fusion and trajectory aggregation for behavior prediction. In ICRA, 2022.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, 2017.\\n\\nEugene Vinitsky, Nathan Lichtl\u00e9, Xiaomeng Yang, Brandon Amos, and Jakob Foerster. Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world. In NeurIPS Datasets and Benchmarks Track, 2022.\\n\\nJingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, and Raquel Urtasun. Advsim: Generating safety-critical scenarios for self-driving vehicles. In CVPR, 2021.\\n\\nWenxi Wang and Haotian Zhen. Joint-multipath++ for simulation agents. Technical report, 2023.\\n\\nYu Wang, Tiebiao Zhao, and Fan Yi. Multiverse transformer: 1st place solution for waymo open sim agents challenge 2023. Technical report, Pegasus, 2023.\\n\\nBenjamin Wilson, William Qi, Tanmay Agarwal, John Lambert, Jagjeet Singh, Siddhesh Khandelwal, Bowen Pan, Ratnesh Kumar, Andrew Hartnett, Jhony Kaesemodel Pontes, Deva Ramanan, Peter Carr, and James Hays. Argoverse 2: Next generation datasets for self-driving perception and forecasting. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS Datasets and Benchmarks 2021), 2021.\\n\\nCathy Wu, Aboudy Kreidieh, Kanaad Parvate, Eugene Vinitsky, and Alexandre M Bayen. Flow: Architecture and benchmarking for reinforcement learning in traffic control. arXiv preprint arXiv:1710.05465, 10, 2017.\\n\\nDanfei Xu, Yuxiao Chen, Boris Ivanovic, and Marco Pavone. Bits: Bi-level imitation for traffic simulation. In ICRA, 2023.\\n\\nXintao Yan, Zhengxia Zou, Shuo Feng, Haojie Zhu, Haowei Sun, and Henry X Liu. Learning naturalistic driving environment with statistical realism. Nature Communications, 14(1):2037, 2023.\\n\\nZhenpei Yang, Yuning Chai, Dragomir Anguelov, Yin Zhou, Pei Sun, Dumitru Erhan, Sean Rafferty, and Henrik Kretzschmar. Surfelgan: Synthesizing realistic sensor data for autonomous driving. In CVPR, June 2020.\\n\\nJiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui Wu. Scaling autoregressive models for content-rich text-to-image generation. Transactions on Machine Learning Research, 2022.\\n\\nWei Zhan, Liting Sun, Di Wang, Haojie Shi, Aubrey Clausse, Maximilian Naumann, Julius K\u00fcmmerle, Hendrik K\u00f6nigshof, Christoph Stiller, Arnaud de La Fortelle, and Masayoshi Tomizuka. INTERACTION Dataset: An INTERNATIONAL, Adversarial and COOPERATIVE moTION Dataset in Interactive Driving Scenarios with Semantic Maps. arXiv:1910.03088 [cs, eess], 2019.\"}"}
{"id": "5FnttJZQFn", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, and Luc Van Gool. Trafficbots: Towards world models for autonomous driving simulation and motion prediction. In ICRA, 2023.\\n\\nZiyuan Zhong, Davis Rempe, Yuxiao Chen, Boris Ivanovic, Yulong Cao, Danfei Xu, Marco Pavone, and Baishakhi Ray. Language-guided traffic simulation via scene-level diffusion. In CoRL, 2023.\\n\\nZiyuan Zhong, Davis Rempe, Danfei Xu, Yuxiao Chen, Sushant Veer, Tong Che, Baishakhi Ray, and Marco Pavone. Guided conditional diffusion for controllable traffic simulation. In ICRA, 2023.\\n\\nMing Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu Miao, Weinan Zhang, Montgomery Alban, IMAN FADAKAR, Zheng Chen, Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Zhengbang Zhu, Yihan Ni, Nhat Nguyen, Mohamed Elsayed, Haitham Ammar, Alexander Cowen-Rivers, Sanjeevan Ahilan, Zheng Tian, Daniel Palenicek, Kasra Rezaee, Peyman Yadmellat, Kun Shao, dong chen, Baokuan Zhang, Hongbo Zhang, Jianye Hao, Wulong Liu, and Jun Wang. Smarts: An open-source scalable multi-agent rl training school for autonomous driving. In CoRL, 2020.\"}"}
{"id": "5FnttJZQFn", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In this Appendix, we provide ablations investigating the impact of replan rate of Wayformer-derived sim agent baselines on the test split, as well as additional learnings from the 2023 CVPR competition. We also include additional descriptions of methods from external challenge submissions, corresponding qualitative results for such methods, and implementation details of each of the 9 component metrics we use. Finally, we describe the exact details of the dataset splits we use and give leaderboard submission instructions.\\n\\nBenchmark Versioning\\n\\nIn December 2023, we improved the accuracy of the collision and offroad likelihood calculation, which improved most collision likelihood scores, offroad likelihood scores, and composite metric results. This paper describes the updated scores (the V1 version of the benchmark), rather than the previous V0 scores presented at the Workshop on Autonomous Driving at CVPR 2023. Both versions of the leaderboards are available online (V1 Leaderboard, V0 Leaderboard).\\n\\nA.1 Replanning Rate Ablation Results\\n\\nAs shown in Table 3 of the main paper and as discussed in Section 5, we perform an ablation of the impact of replanning rate on composite metric performance for open-loop trained models on the WOMD test set. We show that a more frequent replan rate negatively impacts Wayformer-based agent, irregardless of whether multiple diverse rollouts per scene are sampled or if 32 identical rollouts per scene are produced. For the identical-sample producing agent, we see a relative performance drop of 41.2% (composite scores of 0.575 vs. 0.338) when transitioning from replanning at 2Hz to 10Hz.\\n\\nIn Figure 5, we visualize several additional data points from a replanning interval of 100 ms to 1100 ms for the same identical-sample producing agent.\"}"}
{"id": "5FnttJZQFn", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Xiaoyu Mo, Yang Xing, Haochen Liu, and Chen Lv. Map-adaptive multimodal trajectory prediction using hierarchical graph neural networks. IEEE Robotics and Automation Letters, 8(6):3685\u20133692, 2023.\\n\\nNigamaa Nayakanti, Rami Al-Rfou, Aurick Zhou, Kratarth Goel, Khaled S Refaat, and Benjamin Sapp. Wayformer: Motion forecasting via simple & efficient attention networks. In ICRA, 2023.\\n\\nSebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. Advances in neural information processing systems, 29, 2016.\\n\\nEmanuel Parzen. On estimation of a probability density function and mode. The annals of mathematical statistics, 33(3):1065\u20131076, 1962.\\n\\nDean A. Pomerleau. Alvinn: An autonomous land vehicle in a neural network. In Advances in Neural Information Processing Systems, 1988.\\n\\nCheng Qian, Di Xiu, and Minghao Tian. A simple yet effective method for simulating realistic multi-agent behaviors. Technical report, 2023.\\n\\nAditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In ICML, 2021.\\n\\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.\\n\\nDavis Rempe, Jonah Philion, Leonidas J Guibas, Sanja Fidler, and Or Litany. Generating useful accident-prone driving scenarios via a learned traffic prior. In CVPR, June 2022.\\n\\nNicholas Rhinehart, Rowan McAllister, Kris Kitani, and Sergey Levine. Precog: Prediction conditioned on goals in visual multi-agent settings. In ICCV, October 2019.\\n\\nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022.\\n\\nMurray Rosenblatt. Remarks on some nonparametric estimates of a density function. The annals of mathematical statistics, pages 832\u2013837, 1956.\\n\\nStephane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, 2011.\\n\\nChitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J. Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In NeurIPS, 2022.\\n\\nTim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Proceedings of the 30th International Conference on Neural Information Processing Systems, 2016.\\n\\nTim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and Marco Pavone. Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data. In ECCV, 2020.\\n\\nShaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele. Mtr-a: 1st place solution for 2022 waymo open dataset challenge \u2013 motion prediction, 2022.\\n\\nShaoshuai Shi, Li Jiang, Dengxin Dai, and Bernt Schiele. Motion transformer with global intention local localization and local movement refinement. In Advances in Neural Information Processing Systems, 2022.\\n\\nDiJia Su, Bertrand Douillard, Rami Al-Rfou, Cheolho Park, and Benjamin Sapp. Narrowing the coordinate-frame gap in behavior prediction models: Distillation for efficient and accurate scene-centric motion forecasting. arXiv:2206.03970, 2022.\\n\\nPei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al. Scalability in perception for autonomous driving: Waymo open dataset. In CVPR, 2020.\\n\\nQiao Sun, Xin Huang, Brian Williams, and Hang Zhao. InterSim: Interactive traffic simulation via explicit relation modeling. In IROS, 2022.\"}"}
{"id": "5FnttJZQFn", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Simon Suo, Sebastian Regalado, Sergio Casas, and Raquel Urtasun. Trafficsim: Learning to simulate realistic multi-agent behaviors. In CVPR, 2021.\\n\\nShuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, and Raquel Urtasun. Scenegen: Learning to generate realistic traffic scenes. In CVPR, June 2021.\\n\\nMatthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Pradhan, Ben Mildenhall, Pratul P. Srinivasan, Jonathan T. Barron, and Henrik Kretzschmar. Block-nerf: Scalable large scene neural view synthesis. In CVPR, 2022.\\n\\nCharlie Tang and Russ R Salakhutdinov. Multiple futures prediction. In NeurIPS, 2019.\\n\\nLuca Anthony Thiede and Pratik Prabhanjan Brahma. Analyzing the variety loss in the context of probabilistic trajectory prediction. In ICCV, October 2019.\\n\\nMartin Treiber, Ansgar Hennecke, and Dirk Helbing. Congested traffic states in empirical observations and microscopic simulations. Physical review E, 62(2):1805, 2000.\\n\\nBalakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivastava, Khaled S. Refaat, Nigamaa Nayakanti, Andre Cornman, Kan Chen, Bertrand Douillard, Chi Pang Lam, Dragomir Anguelov, and Benjamin Sapp. Multipath++: Efficient information fusion and trajectory aggregation for behavior prediction. In ICRA, 2022.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, 2017.\\n\\nEugene Vinitsky, Nathan Lichtl\u00e9, Xiaomeng Yang, Brandon Amos, and Jakob Foerster. Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world. In NeurIPS Datasets and Benchmarks Track, 2022.\\n\\nJingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, and Raquel Urtasun. Advsim: Generating safety-critical scenarios for self-driving vehicles. In CVPR, 2021.\\n\\nWenxi Wang and Haotian Zhen. Joint-multipath++ for simulation agents. Technical report, 2023.\\n\\nYu Wang, Tiebiao Zhao, and Fan Yi. Multiverse transformer: 1st place solution for waymo open sim agents challenge 2023. Technical report, Pegasus, 2023.\\n\\nBenjamin Wilson, William Qi, Tanmay Agarwal, John Lambert, Jagjeet Singh, Siddhesh Khandelwal, Bowen Pan, Ratnesh Kumar, Andrew Hartnett, Jhony Kaesemodel Pontes, Deva Ramanan, Peter Carr, and James Hays. Argoverse 2: Next generation datasets for self-driving perception and forecasting. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS Datasets and Benchmarks 2021), 2021.\\n\\nCathy Wu, Aboudy Kreidieh, Kanaad Parvate, Eugene Vinitsky, and Alexandre M Bayen. Flow: Architecture and benchmarking for reinforcement learning in traffic control. arXiv preprint arXiv:1710.05465, 2017.\\n\\nDanfei Xu, Yuxiao Chen, Boris Ivanovic, and Marco Pavone. Bits: Bi-level imitation for traffic simulation. In ICRA, 2023.\\n\\nXintao Yan, Zhengxia Zou, Shuo Feng, Haojie Zhu, Haowei Sun, and Henry X Liu. Learning naturalistic driving environment with statistical realism. Nature Communications, 14(1):2037, 2023.\\n\\nZhenpei Yang, Yuning Chai, Dragomir Anguelov, Yin Zhou, Pei Sun, Dumitru Erhan, Sean Rafferty, and Henrik Kretzschmar. Surfelgan: Synthesizing realistic sensor data for autonomous driving. In CVPR, June 2020.\\n\\nJiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui Wu. Scaling autoregressive models for content-rich text-to-image generation. Transactions on Machine Learning Research, 2022.\\n\\nWei Zhan, Liting Sun, Di Wang, Haojie Shi, Aubrey Clausse, Maximilian Naumann, Julius K\u00fcmmerle, Hendrik K\u00f6nigshof, Christoph Stiller, Arnaud de La Fortelle, and Masayoshi Tomizuka. INTERACTION Dataset: An INTERnational, Adversarial and Cooperative moTION Dataset in Interactive Driving Scenarios with Semantic Maps. arXiv:1910.03088 [cs, eess], 2019.\"}"}
{"id": "5FnttJZQFn", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, and Luc Van Gool. Trafficbots: Towards world models for autonomous driving simulation and motion prediction. In ICRA, 2023.\\n\\nZiyuan Zhong, Davis Rempe, Yuxiao Chen, Boris Ivanovic, Yulong Cao, Danfei Xu, Marco Pavone, and Baishakhi Ray. Language-guided traffic simulation via scene-level diffusion. In CoRL, 2023.\\n\\nZiyuan Zhong, Davis Rempe, Danfei Xu, Yuxiao Chen, Sushant Veer, Tong Che, Baishakhi Ray, and Marco Pavone. Guided conditional diffusion for controllable traffic simulation. In ICRA, 2023.\\n\\nMing Zhou, Jun Luo, Julian Villella, Yaodong Yang, David Rusu, Jiayu Miao, Weinan Zhang, Montgomery Alban, IMAN FADAKAR, Zheng Chen, Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Zhengbang Zhu, Yihan Ni, Nhat Nguyen, Mohamed Elsayed, Haitham Ammar, Alexander Cowen-Rivers, Sanjeevan Ahilan, Zheng Tian, Daniel Palenicek, Kasra Rezaee, Peyman Yadmellat, Kun Shao, dong chen, Baokuan Zhang, Hongbo Zhang, Jianye Hao, Wulong Liu, and Jun Wang. Smarts: An open-source scalable multi-agent rl training school for autonomous driving. In CoRL, 2020.\"}"}
{"id": "5FnttJZQFn", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Appendix\\n\\nIn this Appendix, we provide ablations investigating the impact of replan rate of Wayformer-derived sim agent baselines on the test split, as well as additional learnings from the 2023 CVPR competition. We also include additional descriptions of methods from external challenge submissions, corresponding qualitative results for such methods, and implementation details of each of the 9 component metrics we use. Finally, we describe the exact details of the dataset splits we use and give leaderboard submission instructions.\\n\\nBenchmark Versioning\\n\\nIn December 2023, we improved the accuracy of the collision and offroad likelihood calculation, which improved most collision likelihood scores, offroad likelihood scores, and composite metric results. This paper describes the updated scores (the V1 version of the benchmark), rather than the previous V0 scores presented at the Workshop on Autonomous Driving at CVPR 2023. Both versions of the leaderboards are available online (V1 Leaderboard, V0 Leaderboard).\\n\\nA.1 Replanning Rate Ablation Results\\n\\nAs shown in Table 3 of the main paper and as discussed in Section 5, we perform an ablation of the impact of replanning rate on composite metric performance for open-loop trained models on the WOMD test set. We show that a more frequent replan rate negatively impacts Wayformer-based agent, irregardless of whether multiple diverse rollouts per scene are sampled or if 32 identical rollouts per scene are produced. For the identical-sample producing agent, we see a relative performance drop of 41.2% (composite scores of 0.575 vs. 0.338) when transitioning from replanning at 2Hz to 10Hz.\\n\\nIn Figure 5, we visualize several additional data points from a replanning interval of 100 ms to 1100 ms for the same identical-sample producing agent.\\n\\n![Graph a) WOSAC Composite Metric vs. replan rate.](image)\\n\\n![Graph b) ADE vs. replan rate.](image)\\n\\n![Graph c) Component likelihood metrics vs. replan rate.](image)\\n\\nFigure 5: Results at various replanning rates on the WOSAC test set for a Wayformer baseline (producing identical samples for the 32 rollouts). As the replanning rate increases from 1 Hz, then to 2 Hz, and then to 10 Hz, we observe a smooth degradation in performance.\"}"}
{"id": "5FnttJZQFn", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dependencies used include NumPy (numpy), the Waymo Open Dataset repository (waymo-open-dataset-tf-2-11-0==1.5.2), TensorFlow (tensorflow), TensorFlow Probability (tensorflow_probability), Matplotlib (matplotlib), TQDM (tqdm), Protocol Buffers (google.protobuf), and Python standard library imports (os, tarfile, dataclasses).\\n\\nA.7 Additional Information about WOMD Splits Used\\n\\nWe exclude 401 run segments from evaluation due to discrepancies in object counts across the Scenario proto and tf.Example formats, due to object count truncation arising from fixed-shape tf.Example tensors with exactly 128 object slots. We also exclude from evaluation 9 test run segments which are missing maps (however, maps are present for each scenario present in the validation set).\\n\\nTable 5: Statistics of WOMD dataset [22] splits used.\\n\\n| DATASET | SPLIT | VALIDATION | TESTING |\\n|---------|-------|------------|---------|\\n|         |       | VCOUNTS    | VCOUNTS |\\n| ALL     |       | 44097      | 44920   |\\n|         |       | EVALUATED  | SCENARIO |\\n|         |       | 43696      | 44520   |\\n\\nA.8 Submission Format\\n\\nSubmissions must be uploaded as serialized SimAgentsChallengeSubmission protocol buffer data (\"protos\"). Each ScenarioRollouts proto within the submission must contain 32 8-second rollouts of simulation data from one scenario. A validation or test set submission may be submitted to the evaluation server.\\n\\nWe provide a Jupyter notebook tutorial with additional instructions and examples on how to generate a submission for a dataset split. We recommend storing multiple ScenarioRollout's in each binary proto file (i.e. in each SimAgentsChallengeSubmission file) to prevent creating a tar.gz file with tens of thousands of files; use of 100 to 150 of such shards is recommended. Please refer to the tutorial notebook for the naming convention of these files. Submission data should be compressed as a single .tar.gz archive and uploaded as a single file.\\n\\n3 WOMD download instructions available at https://waymo.com/intl/en_us/open/download.\\n\\n4 https://protobuf.dev/\"}"}
{"id": "5FnttJZQFn", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.2 Additional Learnings from the 2023 CVPR Competition\\n\\nGenerative Modeling\\n\\nWhile many families of generative models exist, most challenge participants restricted their modeling to a narrow class of such models, namely GMMs. To our knowledge, for the 2023 CVPR challenge, no user submitted sim agent behavior generated by normalizing flow, GAN, or variational autoencoder (VAEs) models, or by denoising diffusion models, although such diffusion techniques have recently become more popular in the simulation agent literature [80, 81]. We expect this may change in the future as more entrants participate in the WOSAC challenge.\\n\\nFurther Quantitative Analysis\\n\\nWe note that the top-four performing methods were executed fully in closed-loop (MVTE [71], MVTA) or in a hybrid fashion (MTR+++ [44], Wayformer [40]), outperforming the two open-loop submissions, JointMultiPath++ [70] and CAD [14], as shown in Table 4. This gap is especially clear between non-open loop methods and open-loop methods in the collision likelihood metric.\\n\\nAmong all baselines we evaluated, the constant velocity baseline is weakest when it comes to angular-based likelihoods. For example, it achieves close to zero likelihood on both angular speed (0.02) and angular acceleration (0.04), as opposed to the MVTE method, which achieves 0.54 and 0.38 likelihoods on the same two component metrics, respectively. This result is intuitive, as our constant velocity model does not account for any yaw rate.\\n\\nA.3 Additional Comparisons with Other Benchmarks for Autonomous Driving Behavior\\n\\nIn Table 4, we compare our WOSAC benchmark with other benchmarks used for evaluation of behavior models for autonomous driving.\\n\\n| Benchmark | Task |\\n|-----------|------|\\n| Argoverse [10] | Trajectory Forecasting |\\n| INTERPRET (INTERACTION) [78] | Trajectory Forecasting |\\n| Argoverse2 [72] | Trajectory Forecasting |\\n| nuScenes [6] | Trajectory Forecasting |\\n| WOMD [22] | Trajectory Forecasting |\\n| CARLA [19] | Motion Planning |\\n| nuPlan [7] | Motion Planning |\\n| WOSAC (Ours) | Multi-Agent Simulation |\\n\\nTable 4: Existing benchmarks for evaluation of behavior models for autonomous driving.\\n\\nA.4 Additional Information about Methods from External Challenge Submissions\\n\\nMultiVerse Transformer for Agent simulation (MVTA) [71]: A method inspired by TrafficSim [60] that is trained and executed in closed-loop and adheres to WOSAC's factorization and autoregressive requirements. It uses a 'receding horizon' policy (i.e. predicting 1 sec. of future motion but using only the next 100 ms). Inspired by MTR [55, 56], MVTA places a Gaussian Mixture Model (GMM) head on top of a transformer-based encoder and decoder (employing the same encoder/decoder layers as implemented in MTR), consuming vector inputs. Rather than utilizing a fixed-length history as context, MVTA uses a variable-length history to potentially use all of the past data. The input agent encoding contains agent history motion state (i.e., position, object size, heading angle, and velocity) and a one-hot category mask of each agent. The prediction heads include a regression head that outputs 5 GMM parameters ($\\\\mu_x, \\\\mu_y, \\\\sigma_x, \\\\sigma_y, \\\\rho$), along with the velocity ($v_x, v_y$) and heading ($\\\\sin(\\\\theta), \\\\cos(\\\\theta)$) predictions for a timestep, and a classification head that outputs probability $p$. Both heads take the query content features (num_query x hidden feature dimension) as input.\\n\\nMVTE: An enhanced version of MVTA [71] wherein 3 variants of MVTA are trained and randomly selected to generate each of the 32 simulations, increasing simulation diversity across rollouts.\\n\\nMTR+++: A hybrid method with a 0.5Hz replanning rate and a 2 second prediction horizon. We note that MTR+++ does not fully adhere to WOSAC's closed-loop requirement, as it does not replan at a 10 Hz rate. MTR+++ also does not adhere to the policy factorization requirements, as world vs. AV policies are not separated. Inspired by MTR [55, 56], the method addresses two key limitations of MTR: inaccurate heading predictions and excessive collisions incurred by marginal predictions alone. To overcome the first issue, the authors estimate headings from $x/y$ trajectories. Second, in order to minimize collisions, the authors consider $K = 6$ trajectories predicted per agent.\"}"}
{"id": "5FnttJZQFn", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"by MTR, and prune the exponential number of futures in a greedy fashion. As brute-force exhaustive search over the $6^N$ combinations is computationally infeasible, MTR+++ searches for the densest subgraph in a graph of non-colliding future trajectories.\\n\\nFirst, a $6^N \\\\times 6^N$ distance matrix $D$ is constructed, where entry $D_{6^m+i-1, 6^n+j-1}$ indicates the minimum L2 distance between the $i$th-highest trajectories of agent $m$ and the $j$th-highest one of agent $n$. Second the distance matrix is binarized by evaluating which distances correspond to collisions according to object extents. Finally, a clique-finding heuristic method finds a dense subgraph of size $N$. An ensemble of 32 fine-tuned MTR models is employed to create the 32 rollouts, each model producing a single rollout.\\n\\nCollision Avoidance Detour (CAD) [14]: An open-loop method that builds upon an existing motion forecasting method, MTR [55, 56] to produce marginal trajectory predictions, and resamples the entire future if future agent collisions are anticipated, until a maximum number of trials is exhausted. While CAD adheres to the factorization requirement, it does not adhere to WOSAC's closed-loop requirement. Factorization of world vs. AV policies is accomplished by using different checkpoints of an MTR motion prediction model for the two agent groups, and motion of non-evaluated agents is simulated using a constant velocity model.\\n\\nJoint-Multipath++ [70]: An open-loop, scene-centric method that builds off of MultiPath++ [66], producing in a single model pass 32 rollouts, each representing an entire length-80 trajectory. JointMultiPath++ does not factorize AV vs. world policies, and thus does not fully adhere to WOSAC's policy factorization requirements. Agent history information (positions and headings of all agents) are transformed into the AV's coordinate frame, while closest lane information is selected for each agent. In its encoder, JointMultiPath++ concatenates the output of 2 LSTMs and one MultiContextGating (MCG) [66] block to form per-agent embeddings; one LSTM is used to encode agent history, another LSTM is used to encode per-step differences in agent history, and an MCG block is used to encode agent history with corresponding timesteps. Subsequent MCG blocks fuse per-agent information with road network (polyline) embeddings. In its decoder, a series of MLP blocks transform $n$ per-agent embeddings to rollouts represented as $n \\\\times 32 \\\\times 80 \\\\times 3$ output tensors.\\n\\nSBTA-ADIA Mo et al. [38]: Builds upon an existing motion prediction method [39]. This hierarchical method splits the problem into a first phase of multi-agent goal prediction, based on a GNN scene encoder, and a simple planning policy which tries to accomplish the goal closed-loop.\\n\\nA.5 Additional Qualitative Results from External Challenge Submissions\\n\\nIn Figure 6 and 7, we provide additional qualitative examples of simulation results from external challenge submissions.\\n\\nSimulation Input Log Playback MTR+++ MVTE (Logged Oracle) Figure 6: Two-dimensional visualization of simulation results on WOMD's test split. MVTE exhibits a collision and MTR+++ produces a near-miss. 'Simulation input' represents the context history $o_{-H-1:0}$, whereas all other columns visualize both $(o_{-H-1:0}, o_{\\\\geq 1})$. One possible future for a single scene is represented, selected from 32 submitted rollouts, where the AV remains stopped at a red traffic signal. Each rendering in columns 2, 3 and 4 depicts the entire duration of the scene. Trajectories of environment sim agents are drawn in a green-blue gradient (each as a sequence of circles in a temporal color gradient). The AV agent is drawn in orange.\\n\\n2 Code available at https://github.com/wangwenxi-handsome/Joint-Multipathpp.\"}"}
{"id": "5FnttJZQFn", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 7: Two-dimensional visualization of simulation results on a single scene from WOMD's test split using various baseline methods. Four possible futures for this single scene are represented (one per row), selected from 32 submitted rollouts. 'Simulation input' represents the context history $o_{H-1}$, whereas all other columns visualize both $o_{H-1}, o_{\\\\geq 1}$). Each rendering in the second, third, and fourth columns depicts the entire duration of the scene. Trajectories of environment agents are drawn in a green-blue gradient, and trajectories of the AV agent are drawn in a red-yellow gradient (each as a sequence of circles in a temporal color gradient). The AV agent is drawn in orange.\"}"}
{"id": "5FnttJZQFn", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.6 Component Metrics Implementation Details\\n\\n1. Linear Speed: Unsigned magnitude of the first derivative\\n\\\\[ \\\\|v\\\\| = \\\\|x_{t+1} - x_t\\\\|_2 \\\\]\\nwhere \\\\(x_t = [x_t, y_t, z_t]\\\\), Linear speed in 3D computed as the 1-step difference between 3D trajectory points. We employ speed, rather than velocity, as velocity can either be defined w.r.t. the ego-agent's heading, or w.r.t. a global coordinate system, where velocity directions may be city-specific, based on orientation of roads w.r.t. North. Although this cannot capture objects moving in reverse, a rare behavior, we omit it for sake of simplicity.\\n\\n2. Linear Acceleration Magnitude: Signed magnitude of second derivative, in 3D computed as the 1-step difference between speeds of objects.\\n\\\\[ \\\\|v_{t+1}\\\\| - \\\\|v_t\\\\| \\\\Delta t \\\\]\\n\\n3. Angular Speed: Signed first derivative\\n\\\\[ \\\\omega = \\\\frac{d(\\\\theta_{t+1}, \\\\theta_t)}{\\\\Delta t} \\\\]\\ncomputed as the 1-step difference in heading, where \\\\(d(\\\\cdot)\\\\) represents the minimal angular difference between two angles on the unit circle, i.e., \\\\(d(\\\\cdot)\\\\) is a distance metric on \\\\(SO(2)\\\\) computed as\\n\\\\[ \\\\min\\\\{|\\\\theta_{t+1} - \\\\theta_t|, 2\\\\pi - |\\\\theta_{t+1} - \\\\theta_t|\\\\} \\\\]\\nwith \\\\(\\\\theta_t, \\\\theta_{t+1} \\\\in [0, 2\\\\pi)\\\\).\\n\\n4. Angular Acceleration Magnitude: Second derivative, computed as the 1-step difference in angular speed\\n\\\\[ d(\\\\omega_{t+1}, \\\\omega_t) \\\\Delta t \\\\]\\n\\n5. Distance to nearest object: Signed distance (in meters) to the nearest object in the scene. We use Minkowski difference of box polygons, according to a simplified version of the Gilbert\u2013Johnson\u2013Keerthi (GJK) distance algorithm [25].\\n\\n6. Collisions: Count indicating objects that collided, at any point in time, with any other object, i.e. when the signed distances to nearest objects, as described above, achieves a negative value.\\n\\n7. Time-to-collision (TTC): Time (in seconds) before the object collides with the object it is following (if one exists), assuming constant speeds. An object is defined as exhibiting object-following (tailgating) behavior based on alignment conditions derived from heading and lateral distance.\\n\\n8. Distance to road edge: Signed distance (in meters) to the nearest road edge in the scene.\\n\\n9. Road departures: Boolean value indicating whether the object went off the road, at any point in time [60].\\n\\nTo prevent undefined scores from histogram bins with zero support, we employ Laplace smoothing with a pseudocount of 0.1.\\n\\nInserted and Deleted Object Handling\\nIn order to prevent object insertion/deletion bias between the logged and simulated data distributions during evaluation, we discard any newly spawned objects (appearing after the history interval) in the logged test set when computing the logged data distribution. The data distribution in the WOMD dataset already includes such object insertion and deletion.\\n\\nA.6.1 Evaluation Source Code References\\nIn this section, we provide pointers to our specific implementations of the 9 metrics discussed in Section 4.2.1 of the main paper:\\n\\n\u2022 Kinematic-based features: Linear speed, linear acceleration magnitude, angular speed, and angular acceleration magnitude (metrics 1, 2, 3, 4): [Code]\\n\u2022 Interaction-based features: TTC and distance to nearest object (metrics 5, 6, 7): [Code] and modified GJK algorithm implementation [Code]\\n\u2022 Map-based features: Road departures and distance to road edge (metrics 8, 9): [Code]\\n\\nAn implementation of our time-series based NLL computation can be found here: [Code].\\n\\nA.6.2 Evaluation Code License and Dependencies\\nThe WOMD [22] dataset itself is licensed under a non-commercial license (www.waymo.com/open/terms) and the evaluation code for our Waymo Open Sim Agents Challenge (WOSAC) is released under a BSD+limited patent license. See\"}"}
{"id": "5FnttJZQFn", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The Waymo Open Sim Agents Challenge\\n\\nNico Montali  John Lambert  Paul Mougin  Alex Kuefler  Nicholas Rhinehart\\nMichelle Li  Cole Gulino  Tristan Emrich  Zoey Yang  Shimon Whiteson\\nBrandyn White  Dragomir Anguelov\\nWaymo LLC\\n\\nAbstract\\nSimulation with realistic, interactive agents represents a key task for autonomous vehicle software development. In this work, we introduce the Waymo Open Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to tackle this task and propose corresponding metrics. The goal of the challenge is to stimulate the design of realistic simulators that can be used to evaluate and train a behavior model for autonomous driving. We outline our evaluation methodology, present results for a number of different baseline simulation agent methods, and analyze several submissions to the 2023 competition which ran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains open for submissions and we discuss open problems for the task.\\n\\n1 Introduction\\nSimulation environments allow cheap and fast evaluation of autonomous driving behavior systems, while also reducing the need to deploy potentially risky software releases to physical systems. While generation of synthetic sensor data was an early goal ([19, 43]) of simulation, use cases have evolved as perception systems have matured. Today, one of the most promising use cases for simulation is system safety validation via statistical model checking ([1, 16]) with Monte Carlo trials involving realistically modeled traffic participants, i.e., simulation agents.\\n\\nFigure 1: WOSAC models the simulation problem as simulation of mid-level object representations, rather than as sensor simulation.\\n\\nSimulation agents are controlled objects that perform realistic behaviors in a virtual world. In this challenge, in order to reduce the computational burden and complexity of simulation, we focus on simulating agent behavior as captured by the outputs of a perception system, e.g., mid-level object representations ([2, 79]) such as object trajectories, rather than simulating the underlying sensor data ([13, 37, 62, 76]) (see Figure 1).\\n\\nA requirement for modeling realistic behavior in simulation is the ability for sim agents to respond to arbitrary behavior of the autonomous vehicle (AV). \\\"Pose divergence\\\" or \\\"simulation drift\\\" ([3]) is defined as the deviation between the AV's behavior in driving logs and its behavior during simulation, which may be represented through differing position, heading, speed, acceleration, and more. Directly replaying logged behavior of all other objects in the scene ([32, 34, 35])...\"}"}
{"id": "5FnttJZQFn", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 1: A comparison of three autonomous-vehicle behavior related tasks which involve generation of a desired future sequence of physical states: trajectory forecasting, planning, and simulation. Note that observations $o_t \\\\in O$ include simulated agent and environment properties.\\n\\n| Task                      | Outputs | Objectives                                      | Constraints          |\\n|---------------------------|---------|-------------------------------------------------|----------------------|\\n| Multi-Agent Trajectory Forecasting | \u2713       | (x<sub>t</sub>, y<sub>t</sub>, \\\\theta<sub>t</sub>, v<sub>x</sub><sub>t</sub>, v<sub>y</sub><sub>t</sub>)<sub><sub>\\\\text{t=1}</sub></sub> | OPEN-LINEAR KINEMATIC ACCURACY AND MODE COVERING |\\n| Motion Planning           | \u2713       | (x<sub>t</sub>, y<sub>t</sub>, \\\\theta<sub>t</sub>)<sub><sub>\\\\text{t=1}</sub></sub> or controls | CLOSED-LINEAR SAFETY, COMFORT, PROGRESS |\\n| Agent and Environment Simulation | \u2713       | o<sub>t</sub><sub><sub>\\\\text{t=1}</sub></sub>; o<sub>t</sub><sub><sub>\\\\in O</sub></sub> | DISTRIBUTIONAL REALISM |\\n\\nUnder arbitrary AV planning may have limited realism because of this pose divergence. Such log-playback agents tend to heavily overestimate the aggressiveness of real actors, as they are unwilling to deviate from their planned route under any circumstances. On the other hand, rule-based agents that follow heuristics such as the Intelligent Driver Model (IDM) [65] are overly accommodating and reactive. We seek to evaluate and encourage the development of sim agents that lie in the middle ground, adhering to a definition of realism that implies matching the full distribution of human behavior.\\n\\nTo the best of our knowledge, to date there is no existing benchmark for evaluation of simulation agents. Benchmarks have spurred notable innovation in other areas related to autonomous driving research, especially for perception [6, 10, 24, 58], motion forecasting [6, 10, 22, 72, 78], and motion planning [19]. We believe a standardized benchmark can likewise spur dramatic improvements for simulation agent development. Among these benchmarks, those focused on motion forecasting are perhaps most similar to simulation, but all involve open-loop evaluation, which is clearly deficient compared to our closed-loop evaluation. Furthermore, we introduce realism metrics which are suitable to evaluating long-term futures. Relevant datasets such as the Waymo Open Motion Dataset (WOMD) [22] exist today that contain real-world agent behavior examples, and we build on top of WOMD to build WOSAC. In this challenge, we focus on a subset of the possible perception outputs, e.g., traffic light states or vehicle attributes are not modeled, but we leave this for future work.\\n\\nThe challenges our benchmark raises are unique, and if we can make real progress on it, we can show that we've solved one of the hard problems in self-driving. We have a number of open questions:\\n\\n- Are there benefits to scene-centric, rather than agent-centric, simulation methods?\\n- What is the most useful generative modeling framework for the task?\\n- What degree of motion planning is needed for agent policies, and how far can marginal motion prediction take us?\\n- How can simulation methods be made more efficient?\\n- How can we design a benchmark and enforce various simulator properties?\\n\\nDuring our first iteration of the WOSAC challenge, user submissions have helped us answer a subset of these questions; for example, we observed that most methods found it most expedient to build upon state-of-the-art marginal motion prediction methods, i.e. operating in an agent-centric manner.\\n\\nIn this work, we describe in detail the Waymo Open Sim Agents Challenge (WOSAC) with the goal of stimulating interest in traffic simulation and world modeling. Our contributions are as follows:\\n\\n- An evaluation framework for autoregressive traffic agents based on the approximate negative log likelihood they assign to logged data.\\n- An evaluation platform, an online leaderboard, available for submission at [https://waymo.com/open/challenges/2023/sim-agents/](https://waymo.com/open/challenges/2023/sim-agents/).\\n- An empirical evaluation and analysis of various baseline methods, as well as several external submissions.\\n\\n### 2 Related Work\\n\\n**Multi-Agent Traffic Simulation**\\n\\nSimulators have been used to train and evaluate autonomous driving planners for several decades, dating back to ALVINN [43]. While simulators such as CARLA [19], SUMO [33], and Flow [73] provide only a heuristic driving policy for sim agents, they have still enabled progress in the AV motion planning domain [11, 12, 15]. Other recent simulators such as Nocturne [68] use a simplified world representation that consists of a fixed roadgraph and moving agent boxes.\"}"}
{"id": "5FnttJZQFn", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Existing evaluation methods for simulation agents. Entries are ordered chronologically by Arxiv timestamp. There is limited consensus in the literature regarding how multi-agent simulation should be evaluated.\\n\\n| Evaluation Protocol                      | ADE orminADE | OffroadRate | CollisionRate | Instance-Level Distribution Matching | Dataset-Level Distribution Matching | Spatial Coverage or Diversity | Goal progress or Completion |\\n|-----------------------------------------|--------------|-------------|---------------|--------------------------------------|-------------------------------------|-----------------------------|-----------------------------|\\n| ConvSocialPool [17]                     | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| Trajectron [29]                         | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| PRECOG [48]                             | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| BARK [4]                                | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| SMARTS [82]                              | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| TrafficSim [60]                          | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| SimNet [3]                               | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| Symphony [28]                           | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| Nocturne [68]                            | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| BITS [74]                                | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| InterSim [59]                            | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| MetaDrive [34]                           | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| TrafficBots [79]                         | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n| WOSAC (Ours)                             | \u2713            | \u2713           |               |                                      |                                     |                             |                             |\\n\\nSimulation agent modeling is closely related to the problem of trajectory forecasting, as a sim agent could execute a set of trajectory predictions as its plan [4, 59]. However, as trajectory prediction methods are traditionally trained in open-loop, they have limited capability to recover from out of domain predictions encountered during closed-loop simulation [51]. In addition, few forecasting methods produce consistent joint future samples at the scene level [36, 48]. Sim agent modeling is also related to planning, as each sim agent could execute a replica of a planner independently [4]. However, each of these three tasks differ dramatically in objectives, outputs, and constraints (see Table 1).\\n\\nLearned Sim Agents\\n\\nLearned sim agents in the literature differ widely in assumptions around policy coordination, dynamics model constraints, observability, as well as input modalities. While coordinated scene-centric agent behavior is studied in the open-loop motion forecasting domain [8, 9, 57], to the best of our knowledge, TrafficSim [60] is the only closed-loop, learned sim agent work to use a joint, scene-centric actor policy; all others operate in a decentralized manner without coordination [5, 28, 74], i.e., each agent in the scene is independently controlled by replicas of the same model using agent-centric inference. BITS and TrafficBots [74, 79] use a unicycle dynamics model and Nocturne uses a bicycle dynamics model [68] whereas most others do not specify any such constraint; others enforce partial observability constraints, such as Nocturne [68]. Other methods differ in the type of input, whether rasterized [3, 74] or provided in a vector format [28, 79]. Some works focus specifically on generating challenging scenarios [47], and others aim for user-based controllability [81]. Some are trained via pure imitation learning [3], while others include closed-loop adversarial losses [28, 60], or multi-agent RL [4, 34, 82] in order to learn to recover from its mistakes [51]. Some works such as InterSim [4, 28, 59, 74, 79, 82] use a goal-conditioned problem formulation, while others do not [3].\\n\\nEvaluation of Generative Models\\n\\nDistribution matching has become a common way to evaluate generative models [18, 20, 27, 30, 31, 45, 46, 49, 52, 77], through the Fr\u00e9chet Inception Distance (FID) [26]. Previous evaluation methods such as the Inception Score (IS) [53] reason over the entropy of conditional and unconditional distributions, but are not applicable in our case due to the multi-modality of the simulation problem. The FID improves the Inception Score by using statistics of real world samples, measuring the difference between the generated distributions and a data distribution (in the simulation domain, the logged distribution). However, FID has limited sensitivity per example due to aggregation of statistics over entire test datasets into a single mean and covariance.\\n\\nEvaluating Multi-Agent Simulation\\n\\nThere is limited consensus in the literature regarding how multi-agent simulation should be evaluated (see Table 2), and no mainstream existing benchmark exists. Given the importance of safety, almost all existing sim agent works measure some form of collision rate [3, 28, 59, 60, 68, 74], and some multi-object joint trajectory forecasting methods also measure it via trajectory overlap [36]. However, collision rate can be artificially driven to zero by static policies, and thus cannot measure realism. Quantitative evaluation of realism requires comparison with logged data. Such evaluation methods vary widely, from distribution matching of vehicle dynamics [28, 74], to comparison of offroad rates [28, 60, 74], spatial coverage and diversity [60, 74], and progress to goal [59, 68]. However, as goals are not observable, they are thus difficult to extract reliably. Requiring direct reconstruction of logged data through metrics such as Average Displacement Error (ADE) has also been proposed [3, 68], but has limited effectiveness because...\"}"}
{"id": "5FnttJZQFn", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"there are generally multiple realistic actions the A V or sim agents could take at any given moment. To overcome this limitation, one option is to allow the user to provide multiple possible trajectories per sim agent, such as TrafficSim, which uses a minimum average displacement error (minADE) over 15 simulations. Recently, generative-model based evaluation has become more popular in the simulation domain, primarily through distribution matching metrics. Symphony uses Jensen-Shannon distances over trajectory curvature. NeuralNDE compares distributions of vehicle speed and inter-vehicle distance, whereas BITS utilizes Wasserstein distances on agent scene occupancy using multiple rollouts per scene, along with Wasserstein distances between simulated and logged speed and jerk\u2014two kinematic features which can encapsulate passenger comfort. The latter are computed as a distribution-to-distribution comparison on a dataset level, however, this type of metric has shown limited sensitivity in our experiments.\\n\\nLikelihood metrics\\n\\nAn alternative distribution matching framework is to measure point-to-distribution distances. Introduce a metric defined as the average negative log likelihood (NLL) of the ground truth trajectory, as determined by a kernel density estimate (KDE) over output samples at the same prediction timestep. This metric has found some adoption, and we primarily build off of this metric in our work. We note that likelihood-based generative models of simulation such as PRECOG and MFP directly produce likelihoods, meaning that the use of a KDE on sampled trajectories to estimate likelihoods is not needed for such model classes. Concurrent work also measures the NLL of the GT scene under 6 rollouts.\\n\\n3 Traffic Simulation as Conditional Generative Modeling\\n\\nOur goal is to encourage the design of traffic simulators by defining a data-driven evaluation framework and instantiating it with publicly accessible data. We focus on simulating agent behavior in a setting in which an offboard perception system is treated as fixed and given.\\n\\nProblem formulation.\\n\\nWe formulate driving as a Hidden Markov Model $H = (S, O, p(o_t|s_t), p(s_t|s_{t-1}))$, where $S$ denotes the set of unobservable true world states, $O$ denotes the set of observations, $p(o_t|s_t)$ denotes the sampleable emission distribution, and $p(s_t|s_{t-1})$ denotes the hidden Markovian state dynamics: the probability of the hidden state transitioning from $s_{t-1}$ at timestep $t-1$ to $s_t$ at time $t$. Each $o_t \\\\in O$ can be partitioned into A V- and environment-centric components that vary in time: $o_t = [o_A V_t, o_{env_t}]$. $O_{env_t}$ can in general contain a rich set of features, but for the purpose of our challenge, it contains solely the poses of the non-A V agents. We denote the true observation dynamics as $p_{world}(o_t|s_{t-1}) = E_{p(s_t|s_{t-1})} p(o_t|s_t)$.\\n\\nThe task.\\n\\nThe task to build a \u201cworld model\u201d $q_{world}(o_t|o_{oc} < t)$ of $p_{world}(o_t|s_{t-1})$, $o_{oc} < t$. = $[o_{map}, o_{signals}, o_{\u2212H\u22121},...,o_{t\u22121}]$, i.e., it denotes a context of a static map observation, traffic signal observations, and the observation history, with history length $H$.\\n\\nTask constraints:\\n\\n1. $q_{world}$ must be autoregressive for $T$ steps, i.e., sim agent models must adhere to a 10Hz resampling procedure, re-observing the updated scene and consuming their previous outputs.\\n2. $q_{world}$ must factorize according to Eq. 1:\\n\\n   $q_{world}(o_t|o_{oc} < t) = \\\\pi(o_{A V_t}|o_{oc} < t) q(o_{env_t}|o_{oc} < t), \\\\tag{1}$\\n\\n   where $q(o_{env_t}|o_{oc} < t)$ is a traffic simulator, and $\\\\pi(o_{A V_t}|o_{oc} < t)$ is an A V policy. Any submission that fails to satisfy both of these properties will not be considered on WOSAC leaderboards, as determined by\\n\\nWe call this a policy because it is similar to the typical formulation of a policy in a decision process over actions, although not equivalent, because it is defined over next observations rather than current actions. It can be made equivalent to a standard policy $\\\\pi(a_{A V_{t-1}}|o_{oc} < t)$ by defining the A V's action space $A$ to be equivalent to its component of the observation space, and defining an action-dependent world model $q_{world}(o_t|o_{oc} < t, a_{A V_{t-1}}) = \\\\delta(o_{A V_t} = a_{A V_{t-1}}) q(o_{env_t}|o_{oc} < t)$, where $\\\\delta$ denotes the Dirac delta function.\"}"}
{"id": "5FnttJZQFn", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Per-component metric results on the test split of WOMD, representing likelihoods. Methods are ranked by composite metric on the V1 Leaderboard, rather than the previous V0 Leaderboard; Numbers within 1% of the best are in bold (excluding 'logged oracle'). * indicates a method that was received after May 23, 2023, which marked the close of the CVPR 2023 competition.\\n\\nA GENT POLICY LINEAR LINEAR ANG DIST COLISION TTC DIST TO OBJ ROAD EDGE METRIC (\u2191) (\u2191) (\u2191) (\u2191) (\u2191) (\u2191) (\u2191) (\u2193) (\u2193)\\n\\n| Method                      | Metric 1 | Metric 2 | Metric 3 | Metric 4 | Metric 5 | Metric 6 | Metric 7 | Metric 8 | Metric 9 |\\n|----------------------------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\\n| RANDOM AGENT               | 0.002    | 0.044    | 0.074    | 0.120    | 0.000    | 0.000    | 0.734    | 0.178    | 0.287    |\\n| CONSTANT VELOCITY          | 0.074    | 0.058    | 0.019    | 0.035    | 0.208    | 0.345    | 0.737    | 0.454    | 0.287    |\\n| CONSTANT VELOCITY (Gaussian Noise) | 0.157    | 0.119    | 0.019    | 0.035    | 0.247    | 0.411    | 0.775    | 0.502    | 0.463    |\\n| WAYFORMER (Identity Samples, 10 Hz REPLAN) [40] | 0.202    | 0.144    | 0.248    | 0.312    | 0.192    | 0.449    | 0.766    | 0.379    | 0.305    |\\n| WBTA-ADIA [38]             | 0.317    | 0.174    | 0.478    | 0.463    | 0.265    | 0.337    | 0.770    | 0.557    | 0.483    |\\n| WAYFORMER (Inverse Samples, 10 Hz REPLAN) [40] | 0.233    | 0.212    | 0.345    | 0.330    | 0.241    | 0.635    | 0.797    | 0.424    | 0.413    |\\n| CAD [14]                   | 0.349    | 0.253    | 0.432    | 0.310    | 0.332    | 0.568    | 0.789    | 0.637    | 0.834    |\\n| JOINT-MULTIPATH++* [70]    | 0.434    | 0.230    | 0.515    | 0.452    | 0.345    | 0.567    | 0.812    | 0.639    | 0.682    |\\n| WAYFORMER (Identity Samples, 2 Hz REPLAN) [40] | 0.331    | 0.098    | 0.413    | 0.406    | 0.297    | 0.870    | 0.782    | 0.592    | 0.866    |\\n| MTR+++ [44]                | 0.414    | 0.107    | 0.484    | 0.436    | 0.347    | 0.861    | 0.797    | 0.654    | 0.895    |\\n| MVTA [71]                  | 0.439    | 0.220    | 0.533    | 0.480    | 0.374    | 0.875    | 0.829    | 0.654    | 0.893    |\\n| MVTE [71]                  | 0.445    | 0.222    | 0.535    | 0.481    | 0.383    | 0.893    | 0.832    | 0.664    | 0.908    |\\n| LOGGED ORACLE              | 0.561    | 0.330    | 0.563    | 0.489    | 0.485    | 1.000    | 0.881    | 0.713    | 1.000    |\\n\\nat slower replan rates necessary to obtain high composite metric results (See Table 3). Second, almost all submissions used Transformer-based methods [67], except for JointMultiPath++, which used LSTM and MCG blocks [66]. Third, all methods built primarily on top of existing motion prediction works, rather than upon existing motion planning works or sim agent methods from the literature. Only one method, MVTA/MVTE [71], incorporated aspects of an existing sim agent work, TrafficSim [60], as well as motion planning techniques, implementing a receding horizon planning policy. Thus, fourth, we observed the benefit of incorporating planning-based methods into a motion prediction framework. Fifth, most methods (excluding JointMultipath++ [70]) built upon the 2022 CVPR Waymo Open Motion Prediction challenge champion, MTR [55, 56], likely due to the open-source availability of its codebase and SOTA performance. Finally, all submissions operated in an agent-centric coordinate frame, rather than jointly sampling from a scene representation simultaneously.\\n\\nLikelihood Metrics Reward Diversity\\nWe found that our likelihood-based metrics reward models that produce diverse futures. For example, generating 32 diverse rollouts per scene with a Wayformer model performs 11% better on our evaluation metrics than a Wayformer model that produces 32 identical rollouts per scene (see Figure 4).\\n\\nCollision Minimization as an Algorithmic Objective\\nSeveral methods designed algorithmic components to determine futures with a minimal number of collisions, e.g., MTR+++ [44] which used clique-finding in an undirected graph of collision-free future trajectories, and CAD [14], which used rejection sampling on open-loop futures that created collisions. This objective aligns with human preference, but as close calls and collisions do occur in real driving data distributions, optimizing for this objective could be seen as trimming the tail of the distribution; distracted drivers generally do exist in everyday real world driving, and in certain scenarios, one would expect a low-quality planner to perform poorly and produce collisions with sim agents, and so such should be taken into consideration for generating realistic simulations. This suggests a limitation of the WOMD [22], which has few examples from the tail distribution of real driving, and efforts to upsample collision data could prove useful. In addition, open-loop methods such as CAD [14] that prune collisions after the fact could prune collisions caused by the AV rather than by the sim agents, yielding a misleadingly optimistic view of the AV's performance.\\n\\nComposite Metric vs. (min-)ADE and ADE:\\nWe see that among submissions to the test set, rankings by ADE and minADE and ranking by our NLL composite metric disagree. However, methods with lower minADE do tend to achieve higher composite scores; ADE does not exhibit such a trend.\\n\\nComponent Metric Results\\nIn Table 3, we provide a breakdown of the composite metric into component metric results. As expected, the 'logged oracle' baseline achieves the highest likelihood in each of the 9 component metrics. The top performing method, MVTE [71] scored highest on all but one component metric (linear acceleration likelihood), where CAD [14] outperformed MVTE by 12% (likelihood of 0.253 vs. 0.222). Surprisingly, MVTE [71] has angular acceleration likelihoods within a percentage point of the 'logged oracle' (0.481 vs. 0.489). The gap between the top performing learned method (MVTE) and 'logged oracle' in both collision likelihood (0.893 vs. 1.000) and...\"}"}
{"id": "5FnttJZQFn", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"distance-to-nearest object likelihood (0.383 vs. 0.485) indicates significant room for improvement in future work on interactive metrics.\\n\\n5.4 Qualitative Results\\nIn Figure 3, we provide a qualitative comparison of various baselines on two WOMD scenarios. The results indicate that the complexity of behaviors within intersections far exceeds the capability of simple heuristics to predict. Collisions are evident from the constant velocity baselines in both examples. Additional qualitative examples from other sim agent methods are shown in Section A.5 of the Appendix.\\n\\n6 Discussion\\nLimitations.\\nFor our 2023 Challenge, we manually verified the validity of each submission according to factorization and closed-loop requirements discussed in each team's report, and we observed that the technical rules were subtle. Several of the submissions that used open-loop or hybrid open-loop/closed-loop methods may have limited applicability for some simulation applications. Even if we had instituted a benchmark based on Docker-containerized software submissions instead of uploading output trajectory submissions, enforcing our requirements algorithmically and automatically would still be challenging. Although many properties of function calls to Dockerized software can be measured, e.g. latency, as long as any arbitrary state is maintained by the user, the system could not enforce all details of the closed-loop nature of the function call. As a result, user-submitted simulation agent software would have to adhere to strict stateless input and output data APIs. The ability to do so would assist in removing ambiguity regarding whether methods that prune collisions post-hoc qualify as closed-loop.\\n\\nIf a user provides containerized simulator submissions, one approach to encourage adherence to our requirements and to further incentivize closed-loop behavior would be to provide and interact with an AV policy that the user does not control. In our benchmark, the user was allowed to control the AV, albeit through an independent policy; the ability to evaluate simulator submissions on separate, held-out AV motion planning policies and on new scenarios would allow further valuable analysis.\\n\\nFuture Work\\nObject insertion and deletion are important aspects of the simulation problem, yet we intentionally introduced an assumption of no object insertion or deletion in order to reduce the complexity of the first iteration of the WOSAC challenge for users. Motion planners trained or evaluated in a simulator must have the capability to exercise caution regarding areas of occlusion from which new objects may emerge at any timestep. In a future iteration of the challenge, we plan to introduce realism metrics that reward properly-modeled object insertion and deletion, e.g. distributional metrics on the number of vehicles appearing or disappearing at each frame, or the distance of simulated objects from the autonomous vehicle. The data distribution in the WOMD dataset already includes such object insertion and deletion.\\n\\nFurthermore, we intentionally introduced an assumption of time-invariant object dimensions in our first iteration of WOSAC to simplify the modeling challenge for users. Time-variant object dimensions can be considered as a type of vehicle attribute, and object dimensions do actually change in the underlying data distribution provided in the WOMD dataset. We hope to include time-variant object dimension prediction as an aspect of the benchmark in future iterations.\\n\\nAs discussed in Section 5.3, given the prevalence of collision minimization algorithmic components among submissions, one may presume that collisions are not heavily represented in WOMD [22] data, or our metrics are limited in some way. Another approach would be to \\\"fatten the tails\\\" of the evaluation data distribution by generating synthetic, challenging initial conditions [3, 21, 23, 47, 61, 69], or mining more close calls and collisions from real driving data.\\n\\nConclusion.\\nIn this work, we have introduced a new challenge for evaluation of simulation agents, explaining the rationale for the different criteria we require. We invite the research community to continue to participate.\"}"}
{"id": "5FnttJZQFn", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments and Disclosure of Funding\\n\\nNo third-party funding received in direct support of this work. We thank Ben Sapp for his helpful feedback in preparing the challenge. We would like to thank Mustafa Mustafa, Kratarth Goel, Rami Al-Rfou for offering consultation, models and infrastructure that accelerated our work. We thank Alexander Gorban for his assistance in developing and maintaining the evaluation server. All the authors are employees of Waymo LLC.\\n\\nReferences\\n\\n[1] Gul Agha and Karl Palmskog. A survey of statistical model checking. ACM Transactions on Modeling and Computer Simulation (TOMACS), 28(1):1\u201339, 2018.\\n\\n[2] Mayank Bansal, Alex Krizhevsky, and Abhijit S. Ogale. ChauffeurNet: Learning to drive by imitating the best and synthesizing the worst. In Robotics: Science and Systems XV, 2019.\\n\\n[3] Luca Bergamini, Yawei Ye, Oliver Scheel, Long Chen, Chih Hu, Luca Del Pero, B\u0142a\u017cej Osi\u0144ski, Hugo Grimmet, and Peter Ondruska. SimNet: Learning reactive self-driving simulations from real-world observations. In ICRA, 2021.\\n\\n[4] Julian Bernhard, Klemens Esterle, Patrick Hart, and Tobias Kessler. BARK: Open behavior benchmarking in multi-agent environments. In IROS, 2020.\\n\\n[5] Raunak P Bhattacharyya, Derek J Phillips, Blake Wulfe, Jeremy Morton, Alex Kuefler, and Mykel J Kochenderfer. Multi-agent imitation learning for driving simulation. In IROS, 2018.\\n\\n[6] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuScenes: A multimodal dataset for autonomous driving. In CVPR, pages 11621\u201311631, 2020.\\n\\n[7] Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye Kit Fong, Eric Wolff, Alex Lang, Luke Fletcher, Oscar Beijbom, and Sammy Omari. Nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles. In CVPR ADP3 workshop, 2021.\\n\\n[8] Sergio Casas, Cole Gulino, Renjie Liao, and Raquel Urtasun. SpAGNN: Spatially-aware graph neural networks for relational behavior forecasting from sensor data. In ICRA, pages 9491\u20139497, 2020.\\n\\n[9] Sergio Casas, Cole Gulino, Simon Suo, Katie Luo, Renjie Liao, and Raquel Urtasun. Implicit latent variable model for scene-consistent motion forecasting. In ECCV, 2020.\\n\\n[10] Ming-Fang Chang, John Lambert, Patsorn Sangkloy, Jagjeet Singh, Slawomir Bak, Andrew Hartnett, De Wang, Peter Carr, Simon Lucey, Deva Ramanan, and James Hays. Argoverse: 3d tracking and forecasting with rich maps. In CVPR, June 2019.\\n\\n[11] Dian Chen, Brady Zhou, Vladlen Koltun, and Philipp Kr\u00e4henb\u00fchl. Learning by cheating. In Conference on Robot Learning, pages 66\u201375. PMLR, 2020.\\n\\n[12] Dian Chen, Vladlen Koltun, and Philipp Kr\u00e4henb\u00fchl. Learning to drive from a world on rails. In ICCV, pages 15590\u201315599, 2021.\\n\\n[13] Yun Chen, Frieda Rong, Shivam Duggal, Shenlong Wang, Xinchen Yan, Sivabalan Manivasagam, Shangjie Xue, Ersin Yumer, and Raquel Urtasun. Geosim: Realistic video simulation via geometry-aware composition for self-driving. In CVPR, pages 7230\u20137240, June 2021.\\n\\n[14] Hsu-kuang Chiu and Stephen F. Smith. Collision avoidance detour: A solution for 2023 waymo open dataset challenge - sim agents. Technical report, Carnegie Mellon University, 2023.\\n\\n[15] Felipe Codevilla, Matthias M\u00fcller, Antonio L\u00f3pez, Vladlen Koltun, and Alexey Dosovitskiy. End-to-end driving via conditional imitation learning. In ICRA, pages 4693\u20134700. IEEE, 2018.\\n\\n[16] Anthony Corso, Robert Moss, Mark Koren, Ritchie Lee, and Mykel Kochenderfer. A survey of algorithms for black-box safety validation of cyber-physical systems. Journal of Artificial Intelligence Research, 72:377\u2013428, 2021.\\n\\n[17] Nachiket Deo and Mohan M. Trivedi. Convolutional social pooling for vehicle trajectory prediction. In CVPR Workshops. Computer Vision Foundation / IEEE Computer Society, 2018.\"}"}
{"id": "5FnttJZQFn", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In NeurIPS, 2021.\\n\\nAlexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun. CARLA: An open urban driving simulator. In CoRL, 2017.\\n\\nPatrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In CVPR, 2021.\\n\\nNick Roy Ethan Pronovost, Kai Wang. Generating driving scenes with diffusion. In ICRA Workshop on Scalable Autonomous Driving, June 2023.\\n\\nScott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles R. Qi, Yin Zhou, Zoey Yang, Aur\u00e9lien Chouard, Pei Sun, Jiquan Ngiam, Vijay Vasudevan, Alexander McCauley, Jonathon Shlens, and Dragomir Anguelov. Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset. In ICCV, 2021.\\n\\nLan Feng, Quanyi Li, Zhenghao Peng, Shuhan Tan, and Bolei Zhou. Trafficgen: Learning to generate diverse and realistic traffic scenarios. In ICRA, 2023.\\n\\nAndreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In CVPR, 2012.\\n\\nE.G. Gilbert, D.W. Johnson, and S.S. Keerthi. A fast procedure for computing the distance between complex objects in three-dimensional space. IEEE Journal on Robotics and Automation, 4(2):193\u2013203, 1988.\\n\\nMartin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017.\\n\\nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In NeurIPS, 2020.\\n\\nMaximilian Igl, Daewoo Kim, Alex Kuefler, Paul Mougin, Punit Shah, Kyriacos Shiarlis, Dragomir Anguelov, Mark Palatucci, Brandyn White, and Shimon Whiteson. Symphony: Learning realistic and diverse agents for autonomous driving simulation. In ICRA, 2022.\\n\\nBoris Ivanovic and Marco Pavone. The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs. In ICCV, October 2019.\\n\\nTero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In CVPR, 2019.\\n\\nTero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In CVPR, 2020.\\n\\nParth Kothari, Christian Perone, Luca Bergamini, Alexandre Alahi, and Peter Ondruska. Drivergym: Democratising reinforcement learning for autonomous driving. arXiv preprint arXiv:2111.06889, 2021.\\n\\nDaniel Krajzewicz, Georg Hertkorn, Christian R\u00f6ssel, and Peter Wagner. Sumo (simulation of urban mobility)-an open-source traffic simulation. In Proceedings of the 4th middle East Symposium on Simulation and Modelling (MESM20002), pages 183\u2013187, 2002.\\n\\nQuanyi Li, Zhenghao Peng, Lan Feng, Qihang Zhang, Zhenghai Xue, and Bolei Zhou. Metadrive: Composing diverse driving scenarios for generalizable reinforcement learning. TPAMI, 2022.\\n\\nYiren Lu, Justin Fu, George Tucker, Xinlei Pan, Eli Bronstein, Becca Roelofs, Benjamin Sapp, Brandyn White, Aleksandra Faust, Shimon Whiteson, et al. Imitation is not enough: Robustifying imitation with reinforcement learning for challenging driving scenarios. In IROS, 2023.\\n\\nWenjie Luo, Cheol Park, Andre Cornman, Benjamin Sapp, and Dragomir Anguelov. Jfp: Joint future prediction with interactive multi-agent modeling for autonomous driving. In CoRL, 2023.\\n\\nSivabalan Manivasagam, Shenlong Wang, Kelvin Wong, Wenyuan Zeng, Mikita Sazanovich, Shuhan Tan, Bin Yang, Wei-Chiu Ma, and Raquel Urtasun. Lidarsim: Realistic lidar simulation by leveraging the real world. In CVPR, June 2020.\\n\\nXiaoyu Mo, Haochen Liu, Zhiyu Huang, and Chen Lv. Simulating behaviors of traffic agents for autonomous driving via interactive autoregression. Technical report, Nanyang Technological University, 2023.\"}"}
{"id": "5FnttJZQFn", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Graphical model of required factorization as a Bayes net: the two distributions from Eq. 1 are autoregressively interleaved: one represents the A V\u2019s \u201cpolicy\u201d $\\\\pi(o_{AVt}|o_{c}<t)$, and another represents the environmental dynamics $q(o_{envt}|o_{c}<t)$; the graphical model represent $T$-steps of applying these two distributions. Thick outgoing arrows denote passing inputs from all parent nodes to all children.\\n\\nMuch of the challenge of modeling $p_{world}$ lies in the fact that in many situations $s_{t-1} \\\\in S$, $p_{world}$ assigns density to multiple outcomes due to uncertainty from agents in the scene, which means that both $\\\\pi(o_{AVt}|o_{c}<t)$ and $q(o_{envt}|o_{c}<t)$ often must contain multiple modes in order to perform well. We evaluate distribution-matching of $p_{world}$ relative to a dataset of logged outcomes. The required factorization into a A V observation-space policy and environment observation dynamics, $q_{world}(o_{t}|o_{c}<t) = \\\\pi(o_{AVt}|o_{c}<t)q(o_{envt}|o_{c}<t)$, is fairly flexible. We are agnostic to their particular structures. One noteworthy choice for the environment observation dynamics is a \u201cmulti-agent\u201d factorization, in which $q(o_{envt}|o_{c}<t) = \\\\prod_{A}a=1 \\\\pi_{a}(o_{env,a_{t}}|o_{c}<t)$, i.e., the environment observation dynamics factorizes into a sequence of $A$ observation-space policies, and the environment observation itself is partitioned into $A$ different components, one for each agent: $o_{env_{t}} = [o_{env,1_{t}},...,o_{env,A_{t}}]$.\\n\\nAlgorithm 1: Valid: Factorized, Closed-Loop, Agent-Centric Simulation\\n\\nInput: Map $o_{map}$ and traffic signals $o_{signals}$. Initial actor states $o_{-H-1:0} = \\\\{o_{-H-1},...,o_{0}\\\\}$ where each $o_{env_{t}} = \\\\{o_{env,1_{t}},...,o_{env,A_{t}}\\\\}$ for the $A$ actors in the scene.\\n\\nOutput: Simulated observations $o_{1:T} = \\\\{o_{1},o_{2},...,o_{T}\\\\}$ for $T$ simulation timesteps.\\n\\n1: for $t = 1,...,T$ do\\n2: $o_{AV_{t}} \\\\leftarrow \\\\pi_{AV}(o_{<t};o_{map},o_{signals})$\\n3: for $a = 1,...,A$ do\\n4: $o_{env,a_{t}} \\\\leftarrow \\\\pi_{a}(o_{<t};o_{map},o_{signals})$\\n5: $o_{t} = \\\\{o_{env,a_{t}}: \\\\forall a \\\\in 1...A\\\\} \\\\cup \\\\{o_{AV_{t}}\\\\}$\\n6: return $o_{1:T} = \\\\{o_{1},o_{2},...,o_{T}\\\\}$\\n\\nAlgorithm 2: Invalid: Factorized, Open-Loop, Agent-Centric Simulation\\n\\nInput: Map $o_{map}$ and traffic signals $o_{signals}$. Initial actor states $o_{-H-1:0} = \\\\{o_{-H-1},...,o_{0}\\\\}$ where each $o_{env_{t}} = \\\\{o_{env,1_{t}},...,o_{env,A_{t}}\\\\}$ for the $A$ actors in the scene.\\n\\nOutput: Simulated observations $o_{1:T} = \\\\{o_{1},o_{2},...,o_{T}\\\\}$ for $T$ simulation timesteps.\\n\\n1: $o_{AV_{1:T}} \\\\leftarrow \\\\pi_{AV}(o_{<1};o_{map},o_{signals})$\\n2: for $a = 1,...,A$ do\\n3: Produce states at all future timesteps for each actor\\n4: $o_{env,a_{1:T}} \\\\leftarrow \\\\pi_{a}(o_{<1};o_{map},o_{signals})$\\n5: return $o_{1:T} = \\\\{o_{env,a_{1:T}}: \\\\forall a \\\\in 1...A\\\\} \\\\cup \\\\{o_{AV_{1:T}}\\\\}$\\n\\n4 Benchmark Overview\\n\\n4.1 Dataset\\n\\nFor WOSAC, we use the test data from the v1.2.0 release of the Waymo Open Motion Dataset (WOMD) [22]. We treat WOMD as a set $D$ of scenarios where each scenario is a history-future...\"}"}
{"id": "5FnttJZQFn", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This dataset offers a large quantity of high-fidelity object behaviors and shapes produced by a state-of-the-art offboard perception system. We use WOMD's 9 second 10 Hz sequences (comprising $H = 11$ observations from 1.1 seconds of history and 80 observations from 8 seconds of future data), which contain object tracks at 10 Hz and map data for the area covered by the sequence. Across the dataset splits, there exists 486,995 scenarios in train, 44,097 in validation, and 44,920 in test. These 9.1 second windows have been sampled with varying overlap from 103,354 mined segments of 20 second duration. Up to 128 agents (one of which must represent the AV) must be simulated in each scenario for the 8 second future (comprising 80 steps of simulation).\\n\\n**Agent Definition**\\n\\nWe require simulation of all agents that have valid measurements at time $t = 0$, i.e. the last step of logged initial conditions before simulation begins. Because the test split data is sequestered, users will not have access to objects that appear after the time of handover, and so therefore could not be expected to simulate them. We require simulation of all three WOMD object types (vehicles, cyclists, and pedestrians). Objects' dimensions stay fixed as per the last step of history (while they do change in the original data).\\n\\n**Submission**\\n\\nWe do not enforce any motion model (also because we have multiple agent types), which means users need to directly report $x/y/z$ centroid coordinates and heading of the objects' boxes (which could be generated directly or through an appropriate motion model). See the Appendix for additional information on the submission format.\\n\\nBy allowing users to produce the simulations themselves, we reduce the burden on the user by avoiding the need to submit containerized software for an evaluation server.\\n\\n### 4.2 Evaluation\\n\\nAgents should generate realistic driving scenarios stochastically. We define \u201crealistic agents\u201d as those that match the actual distribution of scenarios observed during real-world driving. Unfortunately, we do not know the analytic form of the distribution, but we do have samples from it: the examples that make up WOMD. We therefore evaluate submissions using the approximate negative log likelihood (NLL) of real world samples under the distribution induced by the agents.\\n\\nThe NLL we wish to minimize is given by:\\n\\n$$NLL^* = -\\\\frac{1}{|D|} \\\\sum_{i=1}^{|D|} \\\\log q_{\\\\text{world}}(o_{\\\\geq 1}, i)$$\\n\\nHowever, there are two problems with trying to minimize Equation 2 exactly in our problem setting. First, $o_{\\\\geq 1}$ is high-dimensional. Instead of trying to parameterize the entire ground truth scenario and compute its NLL under a simulated distribution, we therefore parameterize scenarios with a smaller number of component metrics (see Section 4.2.1) and aggregate them together into a composite NLL metric (see Section 4.2.2). Second, agents may support sampling but not pointwise likelihood estimation [41]. In fact, we only require challenge entrants to submit samples from their agents, and therefore have no way of knowing the exact likelihood of logged scenarios under different agent submissions. To avoid this problem, we standardize the NLL computation by fitting histograms to the 32 submitted samples of agent futures, and compute NLLs under the categorical distribution induced by normalizing the histograms.\\n\\n#### 4.2.1 Component Metrics\\n\\nBreaking NLL$^*$ into component metrics has a few benefits. It mitigates the curse of dimensionality described in Section 4.2. It also adds more interpretability to the evaluation, allowing researchers to trade off between different types of errors.\\n\\n**Time Series NLL**: Given the time series nature of simulation data, two choices emerge for how to treat samples over multiple timesteps for a given object for a given run segment: to treat them as time-independent or time-dependent samples. In the latter case, users would be expected to not only reconstruct the general behaviors present in the logged data in one rollout, but also recreate those behaviors over the exact same time intervals. To allow more flexibility in agent behavior, we use the former formulation when computing NLLs, defining each component metric $m$ as an average (in log-space) over the time-axis, masked by validity $v_t$:\\n\\n$$m = \\\\exp \\\\left( -\\\\frac{1}{\\\\sum_{t=1}^{T} v_t} \\\\sum_{t=1}^{T} NLL_t \\\\right).$$\"}"}
{"id": "5FnttJZQFn", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Simulation Input Log Playback Wayformer Constant Velocity\\n\\nFigure 3: Visualizations of simulation results on two separate WOMD scenes (top, bottom). Results for various baseline methods are shown on WOMD's validation split, in 2d. 'Simulation input' represents the context history $o_{-H:-1}$, whereas all other columns visualize both $(o_{-H:-1}, o_{\\\\geq 1})$.\\n\\nTwo scenes are represented: one where the A V completes the execution of a left turn (top row) and another where the A V remains stopped at a red traffic signal (bottom row). Each rendering in the second and third columns depicts the entire duration of the scene. Trajectories of environment sim agents are drawn in a green-blue gradient, and trajectories of the A V agent are drawn in a red-yellow gradient (each as a sequence of circles in a temporal color gradient).\\n\\nHowever, we note that as a result, a logged oracle will not achieve likelihoods of 1.0, whereas in the latter formulation a logged oracle would.\\n\\nDefinitions\\n\\nWe compute NLLs over 9 measurements: kinematic metrics (linear speed, linear acceleration, angular speed, angular acceleration magnitude), object interaction metrics (distance to nearest object, collisions, time-to-collision), and map-based metrics (distance to road edge, and road departures). Please refer to Section A.6 of the Appendix for a complete description and additional implementation details.\\n\\n4.2.2 Composite Metric\\n\\nAfter obtaining component metrics for each measurement, we aggregate them into a single composite metric $M_K$ for evaluating submissions:\\n\\n$$M_K = \\\\frac{1}{N} \\\\sum_{i=1}^{N} \\\\sum_{j=1}^{M} w_j m_{K,i,j},$$\\n\\nwhere $N$ is the number of scenarios and $M = 9$ is the number of component metrics. The component metrics $m$ and composite metric $M$ are also parameterized by a number of samples $K = 32$. The value $m_{i,j}$ represents the likelihood for the $j$th metric on the $i$th example. The metric $M$ is simply a convex combination (i.e. weighted average) over the component metrics, where the weight $w_j$ for the $j$th metric is set manually. In the interest of promoting safety, the weighting for collision and road departure NLLs are set to be $2 \\\\times$ larger than the weight for the other component metrics.\\n\\n5 Experimental Results\\n\\nIn Figure 4 and Table 3, we present quantitative results for a handful of methods. We describe each method in more detail in the sections below.\"}"}
{"id": "5FnttJZQFn", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.1 Baselines\\n\\nRandom Agent: An agent that produces random trajectories \\\\{(x_t, y_t, \\\\theta_t)\\\\}_{t=1}^T\\\\, for \\\\, T=80, with \\\\, x,y,\\\\theta \\\\sim N(\\\\mu, \\\\sigma^2), with \\\\, \\\\mu=1.0\\\\, and \\\\, \\\\sigma=0.1, in the A V's coordinate frame.\\n\\nConstant Velocity Agent: An agent that extrapolates the trajectory using the last heading and speed recorded in the provided context/history. If no two-step difference can be computed based on the valid measurements (e.g. the object appeared only at the final step of context), we set a zero speed for such agents.\\n\\nWayformer (Identical Samples) Agent: An agent that produces a hybrid of open-loop and closed-loop data using a Wayformer [40] motion prediction model, by executing model inference autoregressively at 2Hz. The agents execute the policy forward for 5 simulation steps, and then replan. Results with a 10 Hz replan rate instead are also shown in Table 3, and an ablation on the replan rate is provided in the Appendix. The maximum-likelihood trajectory for each agent is identically repeated 32 times to produce 32 samples. Each agent is executed by the same policy in an agent-centric frame, batched together for inference, thus complying with the required factorization.\\n\\nWayformer (Diverse Samples) Agent: An agent that also utilizes Wayformer [40]-generated trajectories, but samples diverse agent plans, from \\\\, K\\\\, possible trajectories according to their likelihood, instead of selecting the maximum-likelihood choice.\\n\\nLogged Oracle: Agent that directly copies trajectories from the WOMD test split, with 32 repetitions.\\n\\n5.2 External Submissions\\n\\nMultiVerse Transformer for Agent simulation (MVTA) [71]: A method inspired by MTR [55, 56] that is trained and executed in closed-loop. MVTA uses a 'receding horizon' policy with a GMM head, and consumes vector inputs.\\n\\nMVTE: An enhanced version of MVTA [71] that samples a MVTA model from a pool of model variants to increase simulation diversity across rollouts.\\n\\nMTR+++: A hybrid open-loop/closed-loop method with a 0.5Hz replanning rate that is inspired by MTR [55, 56] and searches for the densest subgraph in a graph of non-colliding future trajectories. For a description of other evaluated external submissions, please refer to Section A.4 of the Appendix.\\n\\n5.3 Learnings from the 2023 Challenge\\n\\nDuring the course of our 2023 WOSAC Challenge (March 16, 2023 to May 23, 2023), associated with the CVPR 2023 Workshop on Autonomous Driving, we received 24 test set submissions, and 16 validation set submissions, from 10 teams. We continue to receive submission queries to our evaluation server for our standing leaderboard as new teams submit new methods.\\n\\nTrends\\n\\nWe observed several trends among submissions. First, the challenge champion, MVTA/MVTE [71], was the only method to utilize and benefit from closed-loop training. Other methods that were trained in open-loop, such as MTR+++ [44] or our Wayformer-derived [40] baseline, found operating...\"}"}
