{"id": "iGeJxHqnbx", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design\\n\\nAnonymous Author(s)\\n\\nAbstract\\nQuantum computing is an emerging field recognized for the significant speedup it offers over classical computing through quantum algorithms. However, designing and implementing quantum algorithms pose challenges due to the complex nature of quantum mechanics and the necessity for precise control over quantum states. To address these challenges, we leverage AI to simplify and enhance the process. Despite the significant advancements in AI, there has been a lack of datasets specifically tailored for this purpose. In this work, we introduce QCircuitNet, a benchmark and test dataset designed to evaluate AI\u2019s capability in designing and implementing quantum algorithms in the form of quantum circuit codes. Unlike traditional AI code writing, this task is fundamentally different and significantly more complicated due to the highly flexible design space and the extreme demands for intricate manipulation of qubits. Our key contributions include: 1. The first comprehensive, structured universal quantum algorithm dataset. 2. A framework which formulates the task of quantum algorithm design for Large Language Models (LLMs), providing guidelines for expansion and potential evolution into a training dataset. 3. Automatic validation and verification functions, allowing for scalable and efficient evaluation methodologies. 4. A fair and stable benchmark that avoids data contamination, a particularly critical issue in quantum computing datasets. Our work aims to bridge the gap in available resources for AI-driven quantum algorithm design, offering a robust and scalable method for evaluating and improving AI models in this field. As we expand the dataset to include more algorithms and explore novel fine-tuning methods, we hope it will significantly contribute to both quantum algorithm design and implementation.\"}"}
{"id": "iGeJxHqnbx", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For these reasons, quantum computing is often considered to have high professional barriers. As the discipline evolves, we aim to explore more possibilities for algorithm design and implementation in the quantum setting. This is aligned with recent advances among \u201cAI for Science\u201d, including AlphaFold [Jumper et al., 2021], AlphaGeometry [Trinh et al., 2024], etc. Recently, large language models (LLMs) has also become crucial among AI for science approaches [Yang et al., 2024, Zhang et al., 2024, Yu et al., 2024]. Therefore, we attempt to gear LLMs for quantum algorithm design. As far we know, there has not been any dataset for AI in quantum algorithm design. Existing work combining quantum computing and AI are mostly targeting at exploiting quantum computing for AI; there are some papers that apply AI for quantum computing, but they consider niche problems [Nakayama et al., 2023, Schatzki et al., 2021] or limited functions [Tang et al., 2023, F\u00fcrrutter et al., 2024], not quantum algorithm datasets of general interest. See more discussions in Section 2.\\n\\nKey contributions.\\nIn this work, we propose QCircuitNet, the first comprehensive, structured dataset for quantum algorithm design. Technically, QCircuitNet has the following key contributions:\\n\\n\u2022 It formulates the task of quantum algorithm design for Large Language Models (LLMs), providing guidelines for expansion that may evolve to be a training dataset.\\n\u2022 It has automatic validation and verification functions, allowing for scalable and efficient evaluation.\\n\u2022 It provides a fair and stable benchmark that avoids data contamination, a particularly critical issue in quantum computing datasets.\\n\\n2 Related Work\\nTo the best of our knowledge, QCircuitNet is the first dataset tailored specifically for quantum algorithm design. Previous efforts combining quantum computing with artificial intelligence primarily fall under the category of Quantum Machine Learning (QML), which aims at leveraging the unique properties of quantum systems to enhance machine learning algorithms and achieve potential improvements over their classical counterparts [Schuld et al., 2015, Biamonte et al., 2017, Ciliberto et al., 2018]. Corresponding datasets often focus on encoding classical data into quantum states, which we may call \u201cQuantum for AI\u201d. For instance, MNISQ [Placidi et al., 2023] is a dataset of quantum circuits representing the original MNIST dataset [LeCun et al., 1998] generated by the AQCE algorithm [Shirakawa et al., 2021]. Considering the intrinsic nature of quantum properties, another category of datasets focuses on collecting quantum data to demonstrate quantum advantages since classical machine learning methods could fail to characterize particular patterns of quantum data. For example, Nakayama et al. [2023] created a VQE-generated quantum circuit dataset for classification of variational ans\u00e4tze and shows the quantum supremacy on this task. NTangled [Schatzki et al., 2021] further emphasized on the different types and amounts of entanglement and composed quantum states with various multipartite entanglement for classification. While these datasets successfully demonstrate the supremacy of quantum computing, they address rather niche problems which might not have practical applications.\\n\\nThere have also been efforts in the direction of \u201cAI for Quantum\u201d, which explores the possibility of leveraging the huge potential of AI to facilitate the advancement of quantum computing. QDataSet [Perrier et al., 2022] collects data from simulations of one- and two-qubit systems and targets training classical machine learning algorithms for quantum control, quantum tomography, and noise mitigation. LLM4QPE [Tang et al., 2023] is a large language model style paradigm for predicting quantum system properties with pre-training and fine-tuning workflows. While the paradigm is interesting, the empirical experiments are limited to two downstream tasks: quantum phase classification and correlation prediction. F\u00fcrrutter et al. [2024] studied the application of diffusion models [Sohl-Dickstein et al., 2015, Rombach et al., 2022] to quantum circuit synthesis [Saeedi and Markov, 2013, J. et al., 2022]. Although their methodology is appealing, scalability issues must be addressed to achieve practical and meaningful unitary compilation.\\n\\nThe aforementioned works represent meaningful explorations at the intersection of artificial intelligence and quantum computing. However, none of these datasets or models considers the task which\"}"}
{"id": "iGeJxHqnbx", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"interests the quantum computing community (from the theoretical side) the most: quantum algorithm design. Our work aims to take the first step in bridging this gap. It is worth noting that several quantum algorithm benchmarks already exist, such as QASMBench [Li et al., 2023] and VeriQBench [Chen et al., 2022]. However, these benchmarks are designed to evaluate the performance of NISQ (Noisy Intermediate-Scale Quantum) [Preskill, 2018] machines, rather than for training and evaluating AI models. For instance, QASMBench includes a diverse variety of quantum circuits from different domains based on the OpenQASM assembly representation [Cross et al., 2022], covering quantum circuits with qubit sizes ranging from 2 to 127. However, each algorithm is represented by only 2-3 QASM files at most. While this is sufficient for benchmarking the fidelity of quantum hardware and the efficiency of QC compilers, it fails as a dataset for AI in that it does not capture the design patterns of each algorithm and ignores the construction of different oracles, which are crucial to quantum computing. Similar limitations apply to VeriQBench.\\n\\n3 Preliminaries for Quantum Computing\\n\\nIn this section, we will introduce necessary backgrounds for quantum computing related to this paper. Additional preliminaries can also be found in Appendix B. A more detailed introduction to quantum computing can be found in the standard textbook by Nielsen and Chuang [2000].\\n\\nQuantum states. In classical computing, the basic unit is a bit. In quantum computing, the basic unit is a qubit. Mathematically, \\\\( n \\\\) (\\\\( n \\\\leq 2^N \\\\)) qubits forms an \\\\( N \\\\)-dimensional Hilbert space for \\\\( N = 2^n \\\\). An \\\\( n \\\\)-qubit quantum state \\\\( |i\\\\rangle \\\\) can be written as\\n\\n\\\\[\\n|i\\\\rangle = \\\\sum_{i=0}^{N-1} c_i |i\\\\rangle_i,\\n\\\\]\\n\\nwhere \\\\( c_i \\\\) represents a column vector, also known as a ket state. The tensor product of two quantum states \\\\(|i\\\\rangle_1 \\\\otimes |i\\\\rangle_2\\\\) with \\\\( M = 2^m \\\\) is defined as\\n\\n\\\\[\\n|i\\\\rangle_1 \\\\otimes |i\\\\rangle_2 = \\\\sum_{i=0}^{N-1} \\\\sum_{j=0}^{M-1} c_{i,j} |i\\\\rangle_i \\\\otimes |j\\\\rangle_2,\\n\\\\]\\n\\nwhere \\\\(|i\\\\rangle_i \\\\otimes |j\\\\rangle_2\\\\) is an \\\\((n+m)\\\\)-qubit state with first \\\\( n \\\\) qubits being the state \\\\(|i\\\\rangle_i\\\\) and the last \\\\( m \\\\) qubits being the state \\\\(|j\\\\rangle_2\\\\). When there is no ambiguity, \\\\(|i\\\\rangle_1 \\\\otimes |i\\\\rangle_2\\\\) can be abbreviated as \\\\(|i\\\\rangle_1 \\\\otimes |i\\\\rangle_2|\\\\).\\n\\nQuantum oracles. To study a Boolean function \\\\( f : \\\\{0, 1\\\\}^n \\\\rightarrow \\\\{0, 1\\\\}^m \\\\), we need to gain its access. Classically, a standard setting is to being able to query the function, in the sense that if we input an \\\\( x \\\\in \\\\{0, 1\\\\}^n \\\\), we will get the output \\\\( f(x) \\\\in \\\\{0, 1\\\\}^m \\\\). In quantum computing, the counterpart is a quantum query, which is instantiated by a quantum oracle. Specifically, the function \\\\( f \\\\) is encoded as an oracle \\\\( U_f \\\\) such that for any \\\\( x \\\\in \\\\{0, 1\\\\}^n \\\\), \\\\( z \\\\in \\\\{0, 1\\\\}^m \\\\),\\n\\n\\\\[\\nU_f |x\\\\rangle_i |z\\\\rangle_i = |x\\\\rangle_i |z\\\\rangle_i f(x),\\n\\\\]\\n\\nwhere \\\\( f(x) \\\\) is the plus modulo 2. Note that a quantum query to the oracle is stronger than a classical query in the sense that the quantum query can be applied to a state in superposition: For an input state \\\\( \\\\sum_{i=0}^{N-1} c_i |i\\\\rangle_i \\\\otimes |z\\\\rangle_i \\\\) with \\\\( \\\\sum_{i=0}^{N-1} |c_i|^2 = 1 \\\\), the output state is \\\\( \\\\sum_{i=0}^{N-1} c_i |i\\\\rangle_i \\\\otimes |z\\\\rangle_i f(x) \\\\); measuring this state gives \\\\( x \\\\) and \\\\( z \\\\) with probability \\\\( |c_i|^2 \\\\). A classical query for \\\\( x \\\\) can be regarded as the special setting with \\\\( c_1 = 1 \\\\), \\\\( x_1 = x \\\\), \\\\( z_1 = 0 \\\\), and \\\\( c_i = 0 \\\\) for all other \\\\( i \\\\).\\n\\nQuantum gates. Similar to classical computing that can stem from logic synthesis with AND, OR, and NOT, quantum computing is also composed of basic quantum gates. For instance, the Hadamard \\\\( H \\\\) is the matrix\\n\\n\\\\[\\n\\\\frac{1}{\\\\sqrt{2}} \\\\begin{pmatrix}\\n1 & 1 \\\\\\\\\\n1 & -1\\n\\\\end{pmatrix},\\n\\\\]\\n\\nsatisfying \\\\( H |0\\\\rangle_i = \\\\frac{1}{\\\\sqrt{2}} (|0\\\\rangle_i + |1\\\\rangle_i) \\\\) and \\\\( H |1\\\\rangle_i = \\\\frac{1}{\\\\sqrt{2}} (|0\\\\rangle_i - |1\\\\rangle_i) \\\\). In general, an \\\\( n \\\\)-qubit quantum gate is a unitary matrix \\\\( \\\\mathbb{C}^{2^n} \\\\times \\\\mathbb{C}^{2^n} \\\\).\"}"}
{"id": "iGeJxHqnbx", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4 QCircuitNet Dataset\\n\\n4.1 Task Suite\\n\\nFor the general purpose of quantum algorithm design, we consider two categories of tasks: oracle construction and algorithm design. These two tasks are crucial for devising and implementing a complete quantum algorithm, with oracle construction serving as the premise for algorithm design.\\n\\n4.1.1 Task I: Oracle Construction\\n\\nThe construction of such an oracle $U_f$ using quantum gates is deeply rooted in the research topic of reversible quantum logic synthesis, which remains a challenge for complex Boolean functions. In this dataset, we mainly focus on the construction of textbook-level oracles: Bernstein-Vazirani Problem [Bernstein and Vazirani, 1993], Deutsch-Jozsa Problem [Deutsch and Jozsa, 1992], Simon\u2019s Problem [Simon, 1997], and Grover\u2019s algorithm for unstructured search [Grover, 1996] (including constructions of both the oracle and the diffusion operator). We also consider more advanced oracle construction tasks which we refer to as \u201cProblem Encoding\u201d. For example, one can apply Grover\u2019s oracle to solving constraint problems such as SAT and triangle finding [Ambainis, 2004]. The intrinsic nature of formulating problem encoding tasks for LLMs slightly differs from quantum logic synthesis, and we refer the readers to Appendix B for more detailed discussion.\\n\\n4.1.2 Task II: Quantum Algorithm Design\\n\\nA general description of a quantum algorithm in natural language could be verbose and vague. Considering that quantum circuits stand at the core of designing and implementing a quantum algorithm, and that they resemble a special type of \u201clanguage\u201d, we decide to use quantum circuits as the main medium for LLMs to generate for algorithm design. There are certain crucial points to consider when designing this framework to formulate the task precisely:\\n\\n- **From the perspective of quantum algorithm design, the oracle is usually provided as a blackbox gate since the goal of many algorithms is to determine the property of the function $f(x)$ encoded by the oracle $U_f$. If the model has access to the gate implementation of the oracle, it can directly deduce the property from the circuit, failing the purpose of designing a quantum algorithm to decode the information. However, for all experiment platforms, a quantum circuit needs to be explicitly constructed to compile and run successfully, which means the oracle should be provided with exact gate implementation. Most tutorials and benchmarks (especially those based on OpenQASM) simply merge the circuit implementation of the oracle and the algorithm as a whole for demonstration purposes. In our task of gearing LLMs for quantum algorithm design, how to separate the algorithm circuits from oracle implementation to avoid information leakage is a critical point to consider.**\\n\\n- **A quantum algorithm constitutes not only the quantum circuit, but also the interpretation of execution (typically measurement) results of the quantum circuit. For example, in Simon\u2019s algorithm, the measurement results $y_i$ are not direct answers to the problem, but rather satisfy the property of $s \\\\cdot y_i = 0$. Linear equations need to be solved to obtain the final answer. In this case, for a complete algorithm design, the model should also specify the way to process the execution results to derive the answer to the original problem.**\\n\\n- **Quantum circuits for the same algorithm vary with different qubit number $n$. Although this is trivial for theoretical design, it needs to be considered when implementing concrete quantum circuits.**\\n\\nBeyond quantum algorithm design, we also consider quantum teleportation and quantum key distribution, since these protocols are widely used in quantum information. We cover their details in Appendix B.\\n\\n4.2 Dataset Structure\\n\\nThe overall structure of QCircuitNet is illustrated as follows (more details are given in Appendix A):\"}"}
{"id": "iGeJxHqnbx", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Design Principles.\\n\\nAs discussed in Section 4.1, a critical consideration in formulating the framework is the dilemma between providing the oracle as a black box for quantum algorithm design and the need for its explicit construction to execute the circuit and interpret the results, making the algorithm design complete. Additionally, model training and reference present challenges, particularly for LLMs in generating complex and precise composite gates and evaluating the results efficiently.\\n\\nTo address these obstacles, we highlight the following construction principles, which are specially designed to adapt to these two tasks:\\n\\n\u2022 For algorithm design tasks, as discussed in Section 4.1.2, we provide the oracle as a black-box gate named \\\"Oracle\\\" with the explicit definition in a separate \\\"oracle.inc\\\" library, which is supported by the OpenQASM 3.0 grammar. In this way, we make sure that the model can use the oracle without accessing its underlying function, which solves the problem of isolating oracle definition from the algorithm circuit.\\n\\n\u2022 For oracle construction tasks, we ask the model to directly output the quantum circuit in QASM format. For algorithm design task, we require both a quantum circuit and a post-processing function to derive the final answer from circuit execution results. Moreover, we ask the model to explicitly set the shots needed to run the circuit itself in order to characterize the query complexity, which is critical in the theoretical analysis of algorithms.\\n\\n\u2022 For available quantum gates, we provide the definition of some important composite gates not included in the standard QASM gate library in a \\\"customgates.inc\\\". Hierarchical definition for multi-controlled X gate contains 45060 lines for qubit number n = 14 in OpenQASM format, which is impossible for AI models to accurately generate at the time. Providing these as a .inc file guarantees the correctness of OpenQASM's grammar while avoiding the generation of complicated gates, which is a distraction from the original design task.\\n\\n\u2022 To verify models' output automatically without human evaluation, we compose verification functions to validate the syntax of QASM / Qiskit and the functionality of the implemented circuits / codes. Since comprehensive Logic Equivalence Checking (LEC) might be inefficient for the throughput of LLM inference, we perform the verification by directly checking the correctness of output with extensive test cases.\"}"}
{"id": "iGeJxHqnbx", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Based on these principles, we proposed the framework of QCircuitNet. Below is a more detailed explanation for the 7 components of the dataset:\\n\\n1. **Problem Description:** carefully hand-crafted prompts stating the oracle to be constructed or the target problem to be solved in natural language and latex math formulas. If the problem involves the usage of a quantum oracle or composite gates beyond the standard gate library, the interfaces of the oracle / gate will also be included (input qubits, output qubits, function mechanism).\\n\\n2. **Generation Code:** one general Qiskit [Javadi-Abhari et al., 2024] code to create quantum circuits for oracles or algorithms of different settings, such as distinct secret strings or various qubit numbers. We choose Qiskit as the main experiment platform because it is a general quantum programming software widely used for the complete workflow from creating quantum circuits to transpiling, simulation, and execution on real hardware.\\n\\n3. **Algorithm Circuit:** a .qasm file storing the quantum circuit for each specific setting. We choose OpenQASM 3.0 [Cross et al., 2022] as the format to store the quantum circuits, because Qiskit, as a python library, can only create quantum circuits at runtime instead of explicitly saving the circuits at gate level.\\n\\n4. **Post-Processing Function:** this is for Algorithm Design task only, see Section 4.1.2. The function takes a complete quantum circuit as input, uses the Qiskit AerSimulator to execute the circuit, and returns the final answer to the original problem according to the simulation results. For state preparation problems such as creating a GHZ state of \\\\( n \\\\) qubits, this function returns the qubit indices of the generated state.\\n\\n5. **Oracle / Gate Definition:** a .inc file to provide definitions of composite gates or oracles. For oracle construction tasks, this only includes the definition of composite gates required to build the oracle. For algorithm design tasks, we also provide the gate definition of the oracle in this file, which successfully delivers the oracle in a black-box way.\\n\\n6. **Verification Function:** a function to evaluate whether the implemented oracle / algorithm successfully achieves the desired purpose with grammar validation and test cases verification. The function returns -1 if there exist grammar errors, and returns a score between \\\\([0,1]\\\\) indicating the success rate on test cases.\\n\\n7. **Dataset Creation Script:** the script to create the dataset from scratch in the format suitable for fine-tuning / evaluating LLMs. It contains the following functions: 1. generate primitive QASM circuits. 2. extract gate definitions and add include instructions to create algorithm circuit, the direct output of model. 3. validate and verify the correctness of the data points in the dataset. 4. concatenate algorithm circuit with problem description as a json file for the benchmark pipeline.\\n\\nThis structure of QCircuitNet provides a general framework to formulate quantum algorithm design for large language models, with an easy extension to more advanced quantum algorithms.\\n\\n### 5 Experiments\\n\\n#### 5.1 Methodology for Benchmarking\\n\\nWe benchmark the quantum algorithm design capabilities of leading closed-source and open-source large language models using QCircuitNet. The workflow of our benchmark is illustrated in Figure 2. The total computation cost is approximately equivalent to two days on an A100 GPU.\\n\\n**Note:** Although currently the Qiskit APIs for importing and dumping OpenQASM 3.0 files are still in experimental stage, we choose to adopt version 3.0 over 2.0 in that it supports parameterized circuits, which allows for extending the framework to variational quantum algorithms [Cerezo et al., 2021] by saving parameterized variational ansatzes.\\n\\n**Note:** The verification function explicitly integrates the oracle / gate definition library with output algorithm circuit since Qiskit importer for OpenQASM 3.0 does not support non-standard gate libraries currently.\"}"}
{"id": "iGeJxHqnbx", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Models. Recently, the GPT series models have become the benchmark for generative models due to their exceptional performance. Specifically, we include two models from OpenAI, GPT-3.5-turbo [Brown et al., 2020] and GPT-4 [OpenAI et al., 2024], in our benchmark. Additionally, the LLAMA series models [Touvron et al., 2023a,b] are widely recognized as leading open-source models, and we have selected LLAMA-3-8B for our study. For a comprehensive evaluation, we also benchmark Phi-3-medium-128k [Abdin et al., 2024] and Mistral-7B-v0.3 [Jiang et al., 2023].\\n\\nPrompts. We employ a few-shot learning framework, a prompting technique that has shown considerable success in generative AI [Xie et al., 2021]. In this approach, we utilize either 1 or 5 examples, followed by a problem description. To ensure we do not train and test on the same quantum algorithm, we implement k-fold validation. This method involves using one problem as the test set while the remaining problems serve as the training set, rotating through each problem one at a time.\\n\\nEvaluation Metrics. We use three evaluation metrics:\\n\\n1. BLEU Score: this metric measures how closely the generated code matches the reference code, with a higher BLEU score indicating greater similarity.\\n2. Byte Perplexity: this metric evaluates the model's ability to predict the next byte in a sequence. Lower byte perplexity indicates better performance by reflecting the model's predictive accuracy.\\n3. Verification function: this function checks the syntax validation and the result correctness of the code produced by the language model, and returns a score depending on the performance. See Section 4.2 for more detailed discussion.\\n\\n5.2 Results\\n\\nThe results for BLEU and verification function score are shown in Figure 3, Table 1, and Table 2. We include the results of Byte Perplexity and more experiments in Appendix C.\\n\\nAs illustrated in the table, verification scores for the output of the model reveal that almost none can produce a correct algorithm, because a single mistake could make the whole algorithm fail. However, we can still partially assess the models' ability to solve quantum problems by measuring the BLEU score.\"}"}
{"id": "iGeJxHqnbx", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Benchmarking algorithm design and oracle construction in BLEU scores. The figure indicates that GPT-4o significantly outperforms all other models. Additionally, nearly all models demonstrate the ability to learn quantum knowledge from context, as the five-shot prompt performs much better than the one-shot alternative.\\n\\nThe figure also reveals the different difficulty levels for each algorithm. For simple quantum algorithms such as the Bernstein-Vazirani algorithm where directly applying more H gates to the qubits solves the problem, language models tend to perform well. However, for complicated algorithms such as the W state where the parameters vary with qubit number, the models tend to perform poorly.\\n\\nTable 1: Benchmarking algorithm design in verification function scores.\\n\\n| Model              | Shot | Bernstein-Vazirani | Deutsch-Jozsa | Grover | Phase Estimation | Quantum Fourier Transform | Simon GHZ State | Random Number Generator | Swap Test | W State |\\n|--------------------|------|---------------------|---------------|--------|-----------------|--------------------------|---------------------|-------------------------|-----------|---------|\\n| gpt-4o-2024-05-13  | 1    | -1                  | -1            | -1     | -1              | -1                       | -0.846153846      | -1                      | -1        | -1      |\\n| gpt-4o-2024-05-13  | 5    | -1                  | -1            | -1     | -1              | -1                       | 0.153846154       | 0.405072709              | -1        | -0.846153846 |\\n| Meta-Llama-3-8B    | 1    | -1                  | -1            | -1     | -1              | -1                       | -0.769230769      | -0.928534157              | -1        | -0.461538462 |\\n| Meta-Llama-3-8B    | 5    | -1                  | -1            | -1     | -1              | -1                       | -0.384615385      | -0.730665436              | -1        | -0.153846154 |\\n| gpt-3.5-turbo-0125 | 1    | -1                  | -1            | -1     | -1              | -1                       | -0.846153846      | -1                      | -1        | -1      |\\n| gpt-3.5-turbo-0125 | 5    | -1                  | -1            | -1     | -1              | -1                       | -0.076923077      | -0.490434406              | -1        | -0.846153846 |\\n\\nTable 2: Benchmarking oracle construction in verification function scores.\\n\\n| Model              | Shot | Bernstein-Vazirani | Deutsch-Jozsa | Diffusion-Operator | Grover | Simon |\\n|--------------------|------|---------------------|---------------|--------------------|--------|-------|\\n| gpt-4o-2024-05-13  | 1    | 0.15                | 0.22          | -0.923076923       | -0.977011494 | -0.260869565 |\\n| gpt-4o-2024-05-13  | 5    | 0.15                | 0.43          | -0.230769231       | -0.931034483 | -0.043478261 |\\n| Meta-Llama-3-8B    | 1    | -0.64               | -0.49         | -0.615384615       | -1     | -0.456521739 |\\n| Meta-Llama-3-8B    | 5    | -0.06               | 0.21          | -0.615384615       | -1     | -0.423913043 |\\n| gpt-3.5-turbo-0125 | 1    | -0.4                | -0.01         | -0.846153846       | -0.977011494 | -0.423913043 |\\n| gpt-3.5-turbo-0125 | 5    | -0.07               | 0.06          | -0.307692308       | -0.896551724 | -0.108695652 |\\n| Phi-3-medium-128k-instruct | 1  | -0.5                | -0.52         | -0.846153846       | -1     | -0.673913043 |\\n| Phi-3-medium-128k-instruct | 5  | -0.6                | -0.22         | -1                 | -1     | -0.760869565 |\\n| Mistral-7B-v0.3    | 1    | -0.35               | -0.47         | -1                 | -1     | -0.369565217 |\\n| Mistral-7B-v0.3    | 5    | -0.11               | -0.02         | -1                 | -1     | -0.217391304 |\\n\\n5.3 Observations and Analysis\\n\\nThe Challenge of LLM for Quantum Algorithm Design. As shown by the experiment results, the integration of LLMs into quantum algorithm design presents several challenges:\"}"}
{"id": "iGeJxHqnbx", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1. Lack of data: Unlike classical computing and code generation, where vast datasets and extensive examples exist, the field of quantum computing is still nascent, with limited accessible data. This scarcity hampers the ability of LLMs to learn and generalize effectively.\\n\\n2. Distinct nature of each algorithm: Quantum algorithms can be seen as unitary maps but in exponential size linear spaces. This distinct nature makes it intractable for LLMs to generalize knowledge from one algorithm to another, posing challenges to transfer learning.\\n\\n3. Reasoning of underlying mechanism: Quantum algorithms involve deep comprehension of unitary transformations and the evolution of quantum states. Such reasoning goes beyond simple pattern recognition and is difficult for LLMs to grasp and apply accurately.\\n\\n4. Quantum programming language syntax: The syntax of quantum programming languages, such as Qiskit and OpenQASM, introduces an additional layer of complexity. As shown by the verification scores, the models can barely output circuit/codes with correct syntax, demonstrating that this is a non-trivial task, which challenges the current capabilities of LLMs.\\n\\nUsage of QCircuitNet Dataset.\\n\\nOur dataset helps provide guidance to address these challenges:\\n\\n1. Formulate the task: We propose framing algorithm design tasks in circuit or code form rather than natural language descriptions, which can be vague, or mathematical formulas, which are difficult to verify. This provides a concrete framework for LLMs to operate within.\\n\\n2. Clarify descriptions with concrete examples: The dataset includes detailed descriptions of representative problems in universal quantum algorithms, accompanied by concrete cases, which helps bridge the gap between abstract algorithms and practical implementations.\\n\\n3. Benchmark for fair evaluation: To improve the capability of LLMs in quantum algorithm design, we need a fair and robust evaluation method first. Our dataset includes metrics and benchmarks for such purpose, providing a foundation for developing and testing novel improvement methods.\\n\\nImplications for AI Learning.\\n\\nWe observe a performance separation between writing general qiskit codes and explicit gate-level circuits in QASM. Since Qiskit provides detailed tutorial with general codes for several algorithms, this may imply a data contamination phenomenon where LLMs rely on memorization and retrieval rather than genuine algorithm design. Similarly, current benchmarks for AI code generation and syntax learning may also suffer from this unseen bias. Our dataset, based on QASM files created from scratch, may help circumvent this issue and serve as a stable and fair evaluation method for benchmarking AI syntax learning.\\n\\n6 Conclusions and Future Work\\n\\nIn this paper, we propose QCircuitNet, the first comprehensive, structured universal quantum algorithm dataset and quantum circuit generation benchmark for AI models. It contains automatic validation and verification functions, allowing for scalable and efficient evaluation methodologies. Benchmarking of QCircuitNet on up-to-date LLMs are systematically conducted. Our work leaves several open questions for future investigation:\\n\\n\u2022 QCircuitNet is a benchmarking dataset for LLMs. It is of general interest to extend benchmarking to training, which will help LLMs better maneuver quantum algorithm design. This may need implementations of more advanced algorithms to make it a more meaningful training dataset.\\n\\n\u2022 Since quantum algorithms have fundamental difference from classical algorithms, novel fine-tuning methods to attempt quantum algorithm design and quantum circuit implementation, or even development of new quantum algorithms by LLMs are solicited.\\n\\n\u2022 Currently, variational quantum algorithms [Cerezo et al., 2021] can already be implemented on near-term NISQ machines [Preskill, 2018]. It would be also of general interest to extend QCircuitNet to contain the design and implementation of variational quantum algorithms.\"}"}
{"id": "iGeJxHqnbx", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\n313 Quantum algorithm zoo. [Website], 2024. Accessed: 2024-05-30.\\n\\n314 M. Abdin, S. Ade Jacobs, A. A. Awan, J. Aneja, A. Awadallah, H. Awadalla, N. Bach, A. Bahree, A. Bakhtiari, J. Bao, H. Behl, A. Benhaim, M. Bilenko, J. Bjorck, S. Bubeck, Q. Cai, M. Cai, C. C\u00e9sar Teodoro Mendes, W. Chen, V. Chaudhary, D. Chen, D. Chen, Y.-C. Chen, Y.-L. Chen, P. Chopra, X. Dai, A. Del Giorno, G. de Rosa, M. Dixon, R. Eldan, V. Fragoso, D. Iter, M. Gao, M. Gao, J. Gao, A. Garg, A. Goswami, S. Gunasekar, E. Haider, J. Hao, R. J. Hewett, J. Huynh, M. Javaheripi, X. Jin, P. Kauffmann, N. Karampatziakis, D. Kim, M. Khademi, L. Kurilenko, J. R. Lee, Y. T. Lee, Y. Li, Y. Li, C. Liang, L. Liden, C. Liu, M. Liu, W. Liu, E. Lin, Z. Lin, C. Luo, P. Madan, M. Mazzola, A. Mitra, H. Modi, A. Nguyen, B. Norick, B. Patra, D. Perez-Becker, T. Portet, R. Pryzant, H. Qin, M. Radmilac, C. Rosset, S. Roy, O. Ruwase, O. Saarikivi, A. Saied, A. Salim, M. Santacroce, S. Shah, N. Shang, H. Sharma, S. Shukla, X. Song, M. Tanaka, A. Tupini, X. Wang, L. Wang, C. Wang, Y. Wang, R. Ward, G. Wang, P. Witte, H. Wu, M. Wyatt, B. Xiao, C. Xu, J. Xu, W. Xu, S. Yadav, F. Yang, J. Yang, Z. Yang, Y. Yang, D. Yu, L. Yuan, C. Zhang, C. Zhang, J. Zhang, L. Lyna Zhang, Y. Zhang, Y. Zhang, Y. Zhang, and X. Zhou. Phi-3 technical report: A highly capable language model locally on your phone, 2024. arXiv: 2404.14219\\n\\n315 A. Ambainis. Quantum search algorithms. ACM SIGACT News, 35(2):22\u201335, 2004. arXiv: quant-ph/0504012\\n\\n316 E. Bernstein and U. Vazirani. Quantum complexity theory. In Proceedings of the Twenty-fifth Annual ACM Symposium on Theory of Computing, pages 11\u201320, 1993.\\n\\n317 J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost, N. Wiebe, and S. Lloyd. Quantum machine learning. Nature, 549(7671):195\u2013202, 2017. arXiv: 1611.09347\\n\\n318 T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot learners, 2020. arXiv: 2005.14165\\n\\n319 M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan, L. Cincio, and P. J. Coles. Variational quantum algorithms. Nature Reviews Physics, 3(9):625\u2013644, 2021. arXiv: 2012.09265\\n\\n320 K. Chen, W. Fang, J. Guan, X. Hong, M. Huang, J. Liu, Q. Wang, and M. Ying. VeriQBench: A benchmark for multiple types of quantum circuits, 2022. arXiv: 2206.10880\\n\\n321 C. Ciliberto, M. Herbster, A. D. Ialongo, M. Pontil, A. Rocchetto, S. Severini, and L. Wossnig. Quantum machine learning: a classical perspective. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences, 474(2209):20170551, 2018. arXiv: 1707.08561\\n\\n322 A. Cross, A. Javadi-Abhari, T. Alexander, N. De Beaudrap, L. S. Bishop, S. Heidel, C. A. Ryan, P. Sivarajah, J. Smolin, J. M. Gambetta, and B. R. Johnson. OpenQASM 3: A broader and deeper quantum assembly language. ACM Transactions on Quantum Computing, 3(3):1\u201350, 2022. arXiv: 2104.14722\\n\\n323 A. M. Dalzell, S. McArdle, M. Berta, P. Bienias, C.-F. Chen, A. Gily\u00e9n, C. T. Hann, M. J. Kastoryano, E. T. Khabiboulline, A. Kubica, G. Salton, S. Wang, and F. G. Brandao. Quantum algorithms: A survey of applications and end-to-end complexities, 2023. arXiv: 2310.03011\\n\\n324 D. Deutsch and R. Jozsa. Rapid solution of problems by quantum computation. Proceedings of the Royal Society of London. Series A: Mathematical and Physical Sciences, 439(1907):553\u2013558, 1992.\"}"}
{"id": "iGeJxHqnbx", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "iGeJxHqnbx", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "iGeJxHqnbx", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi\u00e8re, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample. Llama: Open and efficient foundation language models, 2023a. arXiv:2302.13971\\n\\nH. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher, C. Canton Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao, V. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou, H. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann, A. Korenev, P. Singh Koura, M.-A. Lachaux, T. Lavril, J. Lee, D. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov, P. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic, S. Edunov, and T. Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023b. arXiv:2307.09288\\n\\nT. H. Trinh, Y. Wu, Q. V. Le, H. He, and T. Luong. Solving Olympiad geometry without human demonstrations. Nature, 625(7995):476\u2013482, 2024.\\n\\nS. M. Xie, A. Raghunathan, P. Liang, and T. Ma. An explanation of in-context learning as implicit bayesian inference. In International Conference on Learning Representations, 2021. arXiv:2111.02080\\n\\nK. Yang, A. Swope, A. Gu, R. Chalamala, P. Song, S. Yu, S. Godil, R. J. Prenger, and A. Anandkumar. LeanDojo: Theorem proving with retrieval-augmented language models. Advances in Neural Information Processing Systems, 36, 2024. arXiv:2306.15626\\n\\nB. Yu, F. N. Baker, Z. Chen, X. Ning, and H. Sun. LlaSMol: Advancing large language models for chemistry with a large-scale, comprehensive, high-quality instruction tuning dataset, 2024. arXiv:2402.09391\\n\\nZ. Zhang, Y. Zhang, H. Yao, J. Luo, R. Zhao, B. Huang, J. Zhao, Y. Liao, K. Li, L. Zhao, et al. Xiwu: A basis flexible and learnable LLM for high energy physics, 2024. arXiv:2404.08001\\n\\nChecklist\\n\\n1. For all authors...\\n   (a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\\n   (b) Did you describe the limitations of your work? [Yes] See Section 6.\\n   (c) Did you discuss any potential negative societal impacts of your work? [N/A] Quantum computing is still a nascent technology at the moment. Therefore, our work does not have negative societal impacts from our perspective. In the future, we believe that our dataset can be beneficial for quantum algorithm design and the field of quantum computing as a whole.\\n   (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\\n\\n2. If you are including theoretical results...\\n   (a) Did you state the full set of assumptions of all theoretical results? [N/A] We do not have theoretical results.\\n   (b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n   (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] See supplemental material.\"}"}
{"id": "iGeJxHqnbx", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?\\n\\nThe experiments do not contain model training.\\n\\nDid you report error bars (e.g., with respect to the random seed after running experiments multiple times)?\\n\\nNeither random initialization nor stochastic gradient descent is in our experiments. There is no need for repeated experiments.\\n\\nDid you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?\\n\\nSee Section 5.\\n\\nIf your work uses existing assets, did you cite the creators?\\n\\nWe cited Qiskit [Javadi-Abhari et al., 2024], OpenQASM [Cross et al., 2022], and QASM-Bench [Li et al., 2023] in our paper.\\n\\nDid you mention the license of the assets?\\n\\nThe links of the aforementioned assets are given in reference.\\n\\nDid you include any new assets either in the supplemental material or as a URL?\\n\\nDid you discuss whether and how consent was obtained from people whose data you're using/curating?\\n\\nOur dataset is proposed by ourselves.\\n\\nDid you discuss whether the data you are using/curating contains personally identifiable information or offensive content?\\n\\nOur dataset contains purely quantum circuits and does not contain personally identifiable information or offensive content.\\n\\nIf you used crowdsourcing or conducted research with human subjects...\\n\\nDid you include the full text of instructions given to participants and screenshots, if applicable?\\n\\nDid you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?\\n\\nDid you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?\\n\\n14\"}"}
