{"id": "wiw5mnja8W", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"AllSim: Simulating and Benchmarking Resource Allocation Policies in Multi-User Systems\\n\\nJeroen Berrevoets\\nUniversity of Cambridge\\n\\nDaniel Jarrett\\nUniversity of Cambridge\\n\\nAlex J. Chan\\nUniversity of Cambridge\\n\\nMihaela van der Schaar\\nUniversity of Cambridge\\n\\nAbstract\\nNumerous real-world systems, ranging from healthcare to energy grids, involve users competing for finite and potentially scarce resources. Designing policies for repeated resource allocation in such real-world systems is challenging for many reasons, including the changing nature of user types and their (possibly urgent) need for resources. Researchers have developed numerous machine learning solutions for determining repeated resource allocation policies in these challenging settings. However, a key limitation has been the absence of good methods and test-beds for benchmarking these policies; almost all resource allocation policies are benchmarked in environments which are either completely synthetic or do not allow any deviation from historical data. In this paper we introduce AllSim, which is a benchmarking environment for realistically simulating the impact and utility of policies for resource allocation in systems in which users compete for such scarce resources. Building such a benchmarking environment is challenging because it needs to successfully take into account the entire collective of potential users and the impact a resource allocation policy has on all the other users in the system. AllSim's benchmarking environment is modular (each component being parameterized individually), learnable (informed by historical data), and customizable (adaptable to changing conditions). These, when interacting with an allocation policy, produce a dataset of simulated outcomes for evaluation and comparison of such policies. We believe AllSim is an essential step towards a more systematic evaluation of policies for scarce resource allocation compared to current approaches for benchmarking such methods.\\n\\n1 Introduction\\nThe problem of repeated resource allocation to users with timeliness constraints is ubiquitous in settings ranging from healthcare to engineering systems and even labour markets. This problem becomes even more challenging when the resources are diverse and users may derive different benefits from obtaining a specific resource. In these applications, a resource coordinator or decision maker, is tasked with allocating these diverse resources to a pool of diverse users which arrive or leave over time. When a new resource arrives, it is the decision maker's task to assign this coveted resource to one of the users in their current pool. Making such a decision has an enormous impact on the complete system: (i) when a resource is allocated to a user, other users now need to wait for the next resource to arrive, thereby impacting their utility (since they are delay-sensitive), (ii) the match between the resource and the user recipient has different valuations, (iii) assigning a resource to a specific user in the pool influences the utilities of all the other users in the pool as well, and thereby impacting any subsequent\"}"}
{"id": "wiw5mnja8W", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Learned\\nSect.\\n2.1\\nSect.\\n2.3\\nSect.\\n2.2\\nSect.\\n2.4\\n\\nFigure 1: AllSim overview. We illustrate how AllSim takes as input a dataset ($D$) which comprises a set of users ($\\\\pi$) and resources ($\\\\nu$) and outcomes ($Y$). Each of these objects is confounded by an allocation policy $\\\\varphi$. From this highly complex dataset, AllSim learns a set of separate components (in green): a distribution for users ($p(\\\\pi)$) and resources ($p(\\\\nu)$), an associated arrival time based on $t(\\\\pi)$ and $t(\\\\nu)$, and a utility ($u$). AllSim then exposes an interface where a decision maker can perturb and influence each component separately, included the allocation policy itself. We highlight these perturbations in blue, resulting in a new dataset ($D_0$) used to measure the effect of each perturbation.\\n\\nAllocations. We note that the above problem scenario is incredibly general. To have an idea of the diversity of situations described as such, we refer to Table 1 where we list a few example situations.\\n\\nResource allocation. We identify three main challenges one has to overcome when solving problems described by the above. (i) Resources and users are described by multiple (possibly continuous) variables resulting in them being diverse and having complex interactions. (ii) The above are dynamic non-steady-state scenarios, which means that at any time the arrival of resources and users may change, the user-specific as well as system-wide utility may change, and even the users and resources themselves may change. (iii) These are multi-user problems, which means that each decision needs to take into account the resource recipient alongside every other user in the system.\\n\\nEvaluation. Given the complex interactions between diverse resources and users, more and more we have to rely on machine learning based allocation policies which model these interactions to optimise a (system-wide) utility $[1\u20134]$ (cfr. Table 1). While these novel policies receive a lot of research attention, the way in which they are evaluated seems to receive much less while being equally important. In fact, literature introducing these new methods fail to evaluate them against the challenges listed above. We believe the reason is the lack of proper evaluation tools; to our knowledge, there only exist tools that: Have no diverse resources/users $[5, 6]$, Remain steady-state $[7]$, or Model single-user systems $[8]$. None of them capture the challenges described above.\\n\\nSynthetic versus real data. Another major consideration is the usage of data when evaluating policies. Whenever a real-world dataset is available\u2014comprising users, resources, assignments and outcomes\u2014we have to consider the fact that this dataset is tainted by an observational (in-place) policy. We have illustrated this as $\\\\pi t \\\\varphi$ in Figure 1, where the policy is denoted as $\\\\varphi$. The moment we want to test a policy which is different from the observational policy (e.g. $\\\\varphi_0$ in Figure 1), we deviate from the original dataset as the resource to user assignments are (by definition) different. A solution could be a completely synthetic simulation to evaluate policies. However, given the detailed and diverse descriptions of resources and users, this would introduce too much bias into our evaluation as every detail needs to be manually specified $[9]$. The latter is of particular importance when testing these novel ML-based policies, as this is exactly what they were built for in the first place.\\n\\nOur solution is AllSim. Illustrated in Figure 1, AllSim learns separate (unbiased) components from historical data which was biased by a previous observational policy, $\\\\varphi$. These components are exposed as an interface which a decision maker can use to modify the system to fit their purpose. An obvious example of such a modification is to replace the past policy with a different policy. Other examples could be changing the arrival rates of users, resources, changing user and resource types, or even resource efficacy by changing the outcomes ($Y$) while still maintaining detail and realism.\\n\\nThese perturbations are illustrated in blue in Figure 1. From AllSim, we sample a new dataset to measure the effect of the practitioner's modifications on utilities such as fairness, survival, waste, etc.\"}"}
{"id": "wiw5mnja8W", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 1: Example situations\\n\\n| Problem Setting | Users | Resources | Allocation Policy | Utility |\\n|-----------------|-------|-----------|-------------------|---------|\\n| Headhunting     | Openings | Applicants | Assignment | Hires (retention) |\\n| Project staffing| Projects  | Workers    | Staffing          | Project success |\\n| Organ transplantation | Patients  | Donors | Matching | Post/Pre TX survival |\\n| Mechanical ventilation | Patients | Ventilators | Triaging | ICU Discharge |\\n| Bicycle sharing | Docks    | Bicycles   | Redistribution | Idle times |\\n\\nWhy are such simulators important for ML research?\\n\\nThe successes in other subareas in machine learning are driven largely by the existence of capable and qualitative simulators [10][11][12]. With an easy-to-use interface and easily customisable environments, simulators allow researchers to focus on model development rather than creating their own (often conflicting) evaluation protocols. With AllSim, we hope to drive innovation for resource allocation in multi-user problems in healthcare, engineering, economics, etc. The aforementioned simulators are great examples of systematic evaluation across entire research communities, however, they do not: learn realistic and unbiased simulation objects from data, allow for multi-user simulation, or model dynamic non-steady-state scenarios.\\n\\n**Desiderata.**\\n\\nFrom Figure 1 we identify three important desiderata: (1) A simulation should extract unbiased components from historical data which was tainted by existing policies; (2) The simulation should infer unbiased outcomes despite having access to only these biased data, which includes long-term impact on system-wide utilities since present allocations influence future allocations, requiring counterfactual inference (to determine outcomes under different allocations). (3) Using the extracted components from (1), a user must be able to perturb and change the components to fit their specific needs to evaluate different policies and settings before being deployed in the real world.\\n\\n**Contributions**\\n\\nIn this work, we present AllSim (Allocation Simulator), a general-purpose open-source framework for performing data-driven simulation of scarce resource allocation policies for pre-deployment evaluation. We use modular environment mechanisms to capture a range of environment conditions (e.g. varying arrival rates, sudden shocks, etc.), and provide for componentwise parameters to be learned from historical data, as well as allowing users to further configure parameters for stress testing and sensitivity analysis. Potential outcomes are evaluated using unbiased causal effects methods: Upon interaction with a policy, AllSim outputs a batch dataset detailing all of the simulated outcomes, allowing users to draw their own conclusions over the effectiveness of a policy. Compared to existing work, we believe this simulation framework takes a step towards more methodical evaluation of scarce resource allocation policies.\\n\\nIn Appendix B we compare against other strategies used to evaluate allocation policies. AllSim itself is built using ideas from various fields in machine learning which we also review in Appendix B.\\n\\nFurthermore, in Appendix B.1 we review some medical simulations which seem related, but are not.\\n\\nLet $X \\\\in \\\\mathbb{R}^d$ denote the feature vector of a user, and let $X(t) = \\\\{X_i\\\\}_{i=0}^N(t) \\\\sim X(t)$ give the arrival set of (time-varying) size $N(t)$. Likewise, let $R \\\\in \\\\mathbb{R}^e$ be the feature vector of a resource, and let $R(t) = \\\\{R_j\\\\}_{j=0}^M(t) \\\\sim R(t)$ give the arrival set of (time-varying) size $M(t)$.\\n\\nWhile we make no assumptions on how users are modelled, we assume that resources are immediately perishable\u2014that is, each incoming resource cannot be kept idle, and must be consumed by some user in the same time step. In organ transplantation, for instance, the time between harvesting an organ and transplanting it (\\\"cold ischemia time\\\") must be minimized to prevent degradation [14][15][16].\\n\\nLet $Y^+ \\\\in \\\\mathbb{R}$ be the outcome of a matched user, drawn from the distribution $Y(X, R)$ induced by assigning a resource $R$ to a user $X$. At each time $t$, let $Y^+(t) = \\\\{Y^+ \\\\sim Y(X_i, R_j) : R(t) \\\\sim R\\\\}$ give the set of outcomes that result from matching each incoming $R(t)$ with its assigned $X_i$.\\n\\nLikewise, let $Y \\\\in \\\\mathbb{R}$ be the outcome of an unmatched user, drawn from the distribution $Y(X, ?)$.\\n\\nAt each time $t$, let the set of outcomes for users who are never assigned a resource be given by...\"}"}
{"id": "wiw5mnja8W", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Y(t) = Y\u21e0Y(X, ?) : X \u22c8 X(t), \u00ac(9t \u2264 t0)(R2 \u21e0 R(t0), X = X(R))}.\\n\\n(Note that we focus on discrete-time settings (e.g. hours or days), and leave continuous time for future work).\\n\\nThen we have:\\n\\nDefinition 1 (Repeated Resource Allocation)\\n\\nDenote an environment with the tuple \\\\( E = (X, R, Y) \\\\). The repeated resource allocation problem is to decide which users to assign each incoming resource to\u2014that is, to come up with a repeated allocation policy \\\\( \\\\pi : R \\\\times P(Rd) \\\\rightarrow Rd \\\\), perhaps to optimize some utility defined on the basis of (un-)matched outcomes. For instance, if \\\\( Y \\\\) is a patient's post-transplantation survival time, we might wish to maximize the average survival time.\\n\\nWith the necessary notation, and a formal definition of a policy's input and output in Definition 1, we are equipped to introduce each component of AllSim as illustrated in Figure 1. In Sect. 2.4 we also discuss how AllSim's output can be used to evaluate a new policy (or any other modification from the decision maker). Details regarding the simulation life-cycle can be found in Appendix A.\\n\\n2.1 Arrival of users and resources\\n\\nThere are two necessary ingredients that comprise the arrival of new users, and new resources: the amount \\\\( N(t) \\\\) and \\\\( M(t) \\\\), respectively, and the description \\\\( X_i \\\\) and \\\\( R_j \\\\), respectively. Each is modelled differently. Before we sample the user and resource description, we first sample the amount of each arriving at time \\\\( t \\\\) from an associated arrival process\u2014 i.e., in this subsection we will focus on \\\\( N(t) \\\\) and \\\\( M(t) \\\\). We first introduce the structure of the arrival processes, and explain how their parameters can be learned from data and modified by a decision maker to setup the environment.\\n\\nFirst, we stress that \\\\( N(t) \\\\) and \\\\( M(t) \\\\) are not necessarily sampled from constant arrival processes. Instead, we want the user and resource arrivals to change over time either completely or per user/re-source type, which we will explain in more detail below. To accommodate this, we split each arrival process into a product of separate arrival processes which we combine into \\\\( X(t) \\\\) and \\\\( R(t) \\\\) as:\\n\\n\\\\[\\n\\\\hat{X}(t, x_k) = \\\\hat{X}_1(t, x_1) \\\\cdot \\\\cdots \\\\cdot \\\\hat{X}_K(t, x_K),\\n\\\\]\\n\\n\\\\[\\n\\\\hat{R}(t, r_l) = \\\\hat{R}_1(t, r_1) \\\\cdot \\\\cdots \\\\cdot \\\\hat{R}_L(t, r_L),\\n\\\\]\\n\\nwhere each individual arrival process in \\\\( \\\\hat{X}_k \\\\) and \\\\( \\\\hat{R}_l \\\\) is parameterised with (learnable) parameters \\\\( x_k \\\\) and \\\\( r_l \\\\) with \\\\( k \\\\in [K] \\\\) and \\\\( l \\\\in [L] \\\\), respectively. Each factor corresponds with some (learned or predefined) user-type (Equation (1)) and resource-type (Equation (2)). Having these factors allows us to model increasing numbers of, for example, older/younger patients entering a transplant wait-list.\\n\\nIn order for \\\\( X(t) \\\\) and \\\\( R(t) \\\\) to change over time, we let their parameterisation, \\\\( x_k \\\\) and \\\\( r_l \\\\), change in \\\\( t \\\\).\\n\\nAs an example, we can set the arrival processes to Poisson processes (we refer to Appendix E for other examples) with arrival rates \\\\( x_k = k(t) \\\\) and \\\\( r_l = l(t) \\\\), which we can both model over time as,\\n\\n\\\\[\\nk(t) = \\\\bar{\\\\nu}_k k(0) g_k(t),\\n\\\\]\\n\\n\\\\[\\nl(t) = \\\\bar{\\\\nu}_l l(0) g_l(t),\\n\\\\]\\n\\nwith \\\\( k(t), \\\\ l(t) \\\\in R^+ \\\\), and \\\\( \\\\bar{\\\\nu}_k, \\\\ \\\\bar{\\\\nu}_l \\\\in R^+ \\\\) as a normalising constant such that the sum of all \\\\( k \\\\) equal some overall arrival rate \\\\( a_x \\\\), and similarly, the sum of all \\\\( l \\\\) equal some overall arrival rate \\\\( a_r \\\\). Lastly, \\\\( g_k \\\\) and \\\\( g_l \\\\) are continuous functions that simulate a user-specified drift. Note that these \\\\( g \\\\) can also be a combination of multiple drift scenarios, or can be shared across different \\\\( k, l \\\\). Having \\\\( g \\\\), allows practitioners to very accurately describe the non-stationarity they wish to test for. Optionally, \\\\( \\\\bar{\\\\nu}_k \\\\) and \\\\( \\\\bar{\\\\nu}_l \\\\) can be kept fixed throughout the simulation such that \\\\( a_x \\\\) and \\\\( a_r \\\\) vary as does \\\\( g_k, l(t) \\\\), or it can be recomputed for every step \\\\( t \\\\), such that \\\\( a_x \\\\) and \\\\( a_r \\\\) are kept fixed throughout the simulation.\\n\\nAs such, we have a set of arrival rates, \\\\( \\\\bar{\\\\nu}_x = [1, \\\\ldots, K] \\\\), with \\\\( P_k k = \\\\bar{\\\\nu}_x \\\\) with \\\\( \\\\bar{\\\\nu}_x \\\\in R^+ \\\\) as the total arrival rate of recipients. The advantage of splitting \\\\( \\\\bar{\\\\nu}_x \\\\) into multiple \\\\( k \\\\), is that we can finetune the arrival of certain recipient types, yet allow comparison between \\\\( \\\\bar{\\\\nu}_x \\\\) and \\\\( \\\\bar{\\\\nu}_r \\\\) (the total arrival rate for resources). For example, the \\\\( k \\\\)th recipient type may be completely absent when a policy is launched, but over time it gradually enters the system, increasing \\\\( \\\\bar{\\\\nu}_x \\\\) as a whole. Naturally, we also model the arrival of resources as we have for recipients, but left it out of discussion for clarity.\\n\\nLearning \\\\( \\\\bar{\\\\nu}_x, r \\\\) naturally depends on the choice of arrival process. In our setups below we use a Poisson process and have either: (i) learned the dynamic parameters \\\\( k, l(t) \\\\) as in Equations (3) and (4) using polynomial regression over a time-windowed average of incoming users and resources\u2014 over all\"}"}
{"id": "wiw5mnja8W", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"data to compute a correct $k, l$, as well as per predefined condition; or (ii) have predefined an arrival function and drift functions, $g$, to illustrate a scenario where one wishes to test a prespecified scenario.\\n\\n2.2 New users and resources\\n\\n$p(X(t))$ and $p(R(t))$ From $\\\\hat{X}(t)$ and $\\\\hat{R}(t)$ we sample $N(t)$ and $M(t)$, respectively. Of course, we need to provide the tested policies with more than just an amount of users and resources arriving at time $t$. Furthermore, when working with user and resource types (using the decomposition in Equations (1) and (2)), we have $N(t) = P_k N_k(t)$ and $M(t) = P_l M_l(t)$, where each $N_k(t)$ and $M_l(t)$ represents an amount of users and resources per type. As such, we need these types to sample detailed descriptions of each.\\n\\nWhen a recipient or a resource arrives, we sample them from a distribution denoted $p(x|X)$ for the recipients, and $p(x|R)$ for the resources. These distributions are either learnt from data, or shared as an open-source (but privatised) distribution. For the user-distributions we learn from $S_{tX}$, and similarly, for the resource-distributions we learn from $S_{tR}$. Since both remain independent from the past policy (no policy determines which users and resources arrive in the system), we can use any (conditional) generative model to learn these distributions as we are not required to de-bias these data.\\n\\nOf course, we need to be able to sample specific user and resource types. For this we require conditional generative models, where the condition corresponds with a type: $p(x|X)$ becomes $p(x|X|k)$, and similarly $p(x|R)$ becomes $p(x|R|l)$. In case we wish to use an unconditional generative model, we can simply learn multiple: $p(x,k|X)$ for each $k \\\\in [K]$, and similarly for $p(x,l|R)$ for each $l \\\\in [L]$.\\n\\nInterestingly, we do not need to account for any variability (learned nor specified) over time, since this is completely modelled through the arrival processes in Sect. 2.1. In particular, whenever we wish one type, $k$, to dominate others, we simply increase $g_k(t)$ in Equations (3) and (4). In case we only want one type to appear after $t$ in the simulation, we set $g_k(t) = 0$ for $t_0 < t$ and increase it for $t_0 > t$.\\n\\n2.3 Utility\\n\\nThe final component in AllSim, as per Figure 1, are the utilities: functions of the policy ($\\\\pi$), the users and resources ($X$ and $R$), and crucially, the allocation outcomes ($Y$). Given the previous sections, all that remains are the outcomes and how we can combine each element into a new dataset, $D_0$, with counterfactual outcomes, $Y_0$.\\n\\nAs the outcome is a function of the resource and its recipient, inference is a hard problem as allocations suggested by the tested policy deviate from historical data which was collected under a different policy (i.e., they are counterfactual). Consequentially, some combinations are less observed in the original data, illustrated in Figure 2.\\n\\nIn Figure 2 we illustrate two policies, $\\\\pi$ and $\\\\pi_0$ which result in different datasets $D$ and $D_0$. The latter ($D_0$) is what we wish to provide with AllSim, using only data from the former ($D$). Counterfactual inference. AllSim handles this difficult problem by using a counterfactual estimator. Counterfactual methods correct for allocation bias explicitly [2]. In particular, these methods aim to make an unbiased prediction of the potential outcome, associated with some treatment (or resource). We are interested in counterfactual methods that model the potential outcomes for the recipients when they are (not) allocated a resource. A counterfactual estimator then \\\"completes\\\" the dataset ($D_0$) as,\\n\\n$$Y(t) = E[\\\\hat{Y}(R(t))|X_{\\\\pi}(t)]$$\\n\\n(5)\\n\\nwhere $\\\\hat{Y}(R(t))$ is the estimated potential outcome, using methodology known in the potential outcomes literature [17\u201322], and $X_{\\\\pi}(t)$ are the recipients selected by a policy $\\\\pi$ at time $t$. The potential outcome is a random variable depicting the (possibly alternative) outcome when the user receives the resource, $R(t)$. Note that this is not the same as simply conditioning the outcome.\"}"}
{"id": "wiw5mnja8W", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"variables on the users, for the reasons outlined above: conditioning using only biased data will lead to biased estimates for the outcome variable. Hence, literature on counterfactual inference introduced the potential outcomes notation in Equation (5) to differentiate between \\\\( Y(R(t)) \\\\) and \\\\( Y|R(t) \\\\).\\n\\nWe provide a comprehensive overview of counterfactual methods and literature in Appendix H.\\n\\n2.4 Putting it all together\\n\\nDecision maker\\n\\nWe have now discussed each component in the middle section of Figure 1. What remains are the decision maker's perturbations, and finally, combining each component into a new dataset, \\\\( D_0 \\\\).\\n\\nPerturbations.\\n\\nFrom Figure 1 we learn that a decision maker can make three types of perturbations: (i) they can replace the original policy, \\\\( \\\\pi \\\\), with a new (alternative) policy, \\\\( \\\\pi_0 \\\\); (ii) they can change the utility function, \\\\( u \\\\), which takes as argument a dataset comprised of users, resources, outcomes, and a policy; and lastly, (iii) they can change the types, as well as the amount, of users and resources entering the system. Given these perturbations, the policy is allowed to act in a different environment. Changing the policy in (i) is done simply by implementing the new policy according to the simulation interface (discussed in the next section). We stress once more that this paper does not provide guidance for allocation policies nor does it propose a new policy of any kind. In fact, the policies used in the following section are tried and tested policies, currently in use in practice. Changing the utility function for (ii) is easily done in AllSim as running the simulation does not depend at all on the chosen utility function! As AllSim provides a completely counterfactual dataset, \\\\( D_0 \\\\), the utility is computed post-hoc which allows us to always fall back on the generated dataset. Finally, perturbing arrivals (iii) is already discussed in Sect. 2.1; the arrival processes are perturbed through \\\\( g \\\\).\\n\\nSampling data.\\n\\nEquations (1) to (4) provides us with \\\\( X(t) \\\\) and \\\\( R(t) \\\\). Equation (5) provides us with an estimated potential outcome given \\\\( X(t), R(t) \\\\) and their allocations using \\\\( \\\\pi_0 \\\\). AllSim then carefully indicates a timestamp for each combination and then presents the decision maker with a new dataset: \\\\( D_0 = \\\\{ (X, R, \\\\hat{Y}(R), t) : i = 1, ..., N \\\\} \\\\).\\n\\nHaving a new (counterfactual) dataset based on \\\\( \\\\pi_0, D_0 \\\\), allows to easily calculate various performance utilities of interest, which the decision maker can use to evaluate the allocation policy, pre-deployment:\\n\\nDefinition 2 (Pre-Deployment Evaluation)\\n\\nLet \\\\( f : Q_k \\\\times R_k \\\\times ... \\\\rightarrow M \\\\) denote an evaluation metric mapping a sequence of outcomes \\\\( \\\\{Y(t)\\\\} \\\\) \\\\( t = 1, ... \\\\) to some space of evaluation outcome \\\\( M \\\\) (e.g. for the average survival time, this would simply be \\\\( R \\\\)), where \\\\( Y(t) = Y + \\\\left[ Y(t) \\\\right] \\\\). Given a problem \\\\( E \\\\) and policy \\\\( \\\\pi \\\\), the pre-deployment evaluation problem is to compute statistics of the distribution \\\\( F_{E, \\\\pi} \\\\) of evaluation outcomes \\\\( f(\\\\{Y(t)\\\\}) \\\\); commonly, this would be the mean \\\\( \\\\mathbb{E}[f(\\\\{Y(t)\\\\})] \\\\).\\n\\nNote that we have defined \\\\( f \\\\) in terms of the sequence of per-period outcomes such that it gives maximum flexibility: Depending on how individual outcomes \\\\( Y \\\\) are defined, we can measure point estimates (e.g. the mean survival), compare subpopulations (e.g. whether some types of recipients systematically receive more favourable outcomes), examine trends (e.g. whether outcomes degrade as the types of recipients arriving change), or potentially investigate more complex hypotheses.\\n\\n3 AllSim Interface & Examples\\n\\nGiven the formal definition of AllSim presented in Sect. 2 (and further in Appendix A), we now introduce AllSim's programming interface and use it directly to provide some experimental results. We split this section in two major parts: first, we show the type of analysis AllSim can do for us, as well as how to tailor AllSim to the decision maker's needs; and then, we show how realistic the AllSim simulations are, compared to the factual data; we show that AllSim models realistic systems.\\n\\n3.1 Example analysis and decision-maker specifications\\n\\nAs a first example, let us showcase an analysis to illustrate the possible impact AllSim may have in practice. Throughout this section, we will use the open-access United Network for Organ Sharing (UNOS) dataset which comprises 25 years of liver-to-patient allocation. Importantly, we had to make zero adjustments to our framework to fully capture these data, showcasing the generality of the...\"}"}
{"id": "wiw5mnja8W", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Donor arrival rates\\n\\nDonor\\nRecipient\\nAverage age\\n\\nFigure 4: Specifying a simulation using AllSim.\\n\\nIn the above, a decision maker defines a set of donor arrival rates, based on age ($\\\\theta$ and $\\\\theta'$). Using these very simple, but custom, arrival rates, we see a direct influence in the user and resource distributions ($p(\\\\theta)$ and $p(\\\\theta')$). These perturbations constitute as perturbations of type (iii) as per Sect. 2.4. Finally, the decision maker tries out three different policies: MELD, MELD-na, and FIFO, which constitute as perturbation type (i). The result of these policies is shown on the right. The reported averages are windowed over 300 samples.\\n\\nAllSim framework. We only use UNOS data until 2019 which, interestingly, predates the COVID-19 global pandemic. As such, it is impossible to evaluate policies using only these data: we need AllSim to model a counterfactual scenario that mimics what we saw during the pandemic to test a policy.\\n\\nFigure 3: Two hypothetical scenarios.\\n\\nWe require AllSim to evaluate a policy (e.g. MELD-Na) in hypothetical (counterfactual) scenarios. The x-axis is time, and the y-axis indicates survival time.\\n\\nIn Figure 3 we ran the MELD-Na policy in two hypothetical scenarios: one where COVID-19 happens (which resulted in a 50% drop in the donor liver arrival rates $[23\u201325]$), and one where it doesn\u2019t. With AllSim we can model each scenario confidently. For this particular example, we fix the seed of AllSim and only change the supply of organs by giving two different resource arrival processes:\\n\\n```python\\ndef covid(t):\\n    if t < 600:\\n        return 0.5\\n    else:\\n        return 0.25\\n\\ndef no_covid(t):\\n    return 0.5\\n```\\n\\nHaving illustrated the power of AllSim, let us now show how a decision maker may introduce their perturbations (such as the `covid` and `no_covid` arrival processes from above) into the AllSim simulator. For this, we will provide the donor-organ system with two specific perturbations: (1) we will change the policies (from MELD, to MELD-na, and a simple FIFO policy), and (2) we will increase the user age and decrease the donor age. These two perturbations respectively illustrate perturbation types (i) and (iii), listed in Sect. 2.4 (recall that perturbation type (ii) was changing the utility which is done after a counterfactual dataset is sampled and hence does not require testing).\\n\\nConsider Figure 4 which shows the resulting simulation and the found utility when perturbing the organ arrival rates as well as the allocation policies. The take-away from this experiment is not the performance of the policy (although, reassuringly, MELD and MELD-na do outperform FIFO). Instead, we learn that increasing user age results in dropping the survival time, regardless of the donor age which is decreasing. This is not surprising, as older transplant patients simply have less time to live, whether they get an organ or not. Which leads to the next question: is AllSim realistic?\"}"}
{"id": "wiw5mnja8W", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Simulation configuration:\\n\\n```python\\nimport allsim as asim\\n\\nsimulation = asim.init(**kwargs)\\n\\n# Kwargs:\\n# - resource arrival process type (defined in API)\\n# - user arrival process type (defined in API)\\n# - counterfactual model type (defined in API)\\n\\n# Object columns (X, R, Y)\\n\\nsimulation.add_dataset(X, R, Y)\\n```\\n\\n**Figure 5:** AllSim (easily) simulates realistic environments. Using real-world data on donor organs, we let AllSim model 3 years of organ arrivals and compare it with the actual arrival as reported in the data. In Figures 5a and 5b we show AllSim's output (in donor age and BMI), given the code on the right. With minimal code, a simple condition (4 age brackets), and conservative models (polynomial regression to fit the arrival rates, and a Gaussian kernel density to model the organ densities), we find that AllSim accurately models the actual (real-world) arrival of organs as reported in the UNOS data.\\n\\n### 3.2 AllSim's realism\\n\\nIn this section, we will learn an AllSim configuration purely from the UNOS data (i.e. without a decision maker's input), such that we can compare AllSim's output side-by-side with what actually happened in UNOS. If they match up, we confirm that AllSim can output realistic scenarios (as UNOS is a real dataset). However, before we do so, we first show how we use AllSim from a programming perspective and configure appropriate arrival processes and densities for this particular use case.\\n\\nFirst we determine how many users and resources we need to sample, once we know the amount we sample them from a generative model. The former is modeled through a Poisson arrival rate that changes over time, and the second is sampled from some learnt density. Of course, a user can implement their own arrival process by inheriting from the abstract `ArrivalProcess` class. Importantly, we need to be able to condition the density on some pre-specified characteristic of the object of interest. For example, one may be interested in modelling the arrival of harvested organs of older patients distinctly from younger patients. An example of this is provided in Figure 5, where we show the changing resources coming in the system, alongside the code that generated the result.\\n\\n#### Object densities\\n\\nBefore discussing a temporal arrival rate, we first discuss modelling the object's densities. Consider lines 3-12 in the righthand side of Figure 5. Using this code, we first define what we want to condition on, using a `Condition` object: in this case we formulate age brackets. With the `KDEDensity` class, which is a subclass of the abstract `Density` class, we can automatically model a density, conditioned on these age brackets. Each `Density` object implements a `fit` and `sample` function, which is used to sample new objects by the `System`, which we discuss next.\\n\\n#### Arrival processes\\n\\nUsing a `Density`, we move on to lines 14-26, where we first build a system of multiple arrival processes, one for each discrete condition as in Equations (1) and (2). In particular, we define a `PoissonProcess` for each condition (or age bracket), which is then provided to a `PoissonSystem`. Using the `PoissonSystem`, we can sample the arriving objects for each $t$ in Equations (1) and (2).\"}"}
{"id": "wiw5mnja8W", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Note that we also model $\\\\alpha$, returning the overall arrival rate, such that the system can calculate an appropriate $\\\\lambda$. Figure 5a shows that AllSim accurately models the arriving objects.\\n\\nWith the arrival processes coded above together with a counterfactual Inference object, we compose a Simulation object\u2014the main interaction interface. In particular, one defines a set of arrival rates (such as in Figure 5b) for both users and resources (cfr. ln 13-17) to create a simulation:\\n\\n```python\\nsimulation = asim.init(resource_process, patient_process, inference, columns)\\n```\\n\\nWith that simulation, a practitioner can instantiate a Policy, which implements the add and select methods. For example, we have implemented the MELD policy $^2^6$, which is a widely known and used ScRAP for liver allocation. Using the simulation, we can generate a simulated dataset:\\n\\n```python\\ndf = simulation.evaluate(policy=meld_policy, T=T)\\n```\\n\\nWhere $df$ is a Pandas DataFrame $^2^7$, $^2^8$. Naturally, $df$ contains an enormous amount of information w.r.t. the policy\u2019s allocations in our environment. As such, we have included only a subset of the potential results in Figure 4. Additional results and details can be found in Appendices C and H. Ultimately, the practitioner determines appropriate analysis, settings, and performance metrics.\\n\\n### 3.3 Beyond Organs\\n\\nAllSim is a general purpose simulator which evaluates scarce resource allocation policies. While we have mainly focused on organ-transplantation so far, AllSim is also applicable in other settings.\\n\\nTo illustrate, we show how one can implement a vaccine distribution policy evaluation system in AllSim. This use-case illustrates the few adjustments one has to make compared to the organ-allocation problem. Specifically, in vaccine distribution, each resource is the same and arrives in batches. Furthermore, the type of patient-in-need is also much broader (in fact, they cover the entire population). Yet, AllSim is perfectly capable of modelling this scenario given the following:\\n\\n- Batch arrival requires a multiplier: if the Poisson process samples a value of 2 on one day, we could simply interpret this as two batches of 1000 doses, i.e. multiply by batch content.\\n- We no longer require a resource density as vaccines are not unique, contrasting organ allocation. This is implemented as a dummy-density that always returns 1 (or the vaccine amount).\\n- The broader patient-type is achieved by retraining the recipient-density on the entire population.\\n\\nThese implementation details are relatively simple to implement using AllSim\u2019s modular API. While not necessarily a problem in vaccine distribution, recipient arrival in the ICU in a setting of infectious disease (such as COVID-19), is definitely different compared to the organ-allocation setting. With organ-allocation, we can safely assume a Poisson process for recipient arrival as recipients enter the system independently. This is not true for infectious diseases: one recipient arriving may indicate higher infection rates. As such, recipients do not arrive independently, motivating AllSim\u2019s design.\\n\\nIt is clear that above scenario can no longer rely on a Poisson arrival process for new recipients entering the system. Instead, accurately modelling a situation of infectious disease could be done using a Hawkes process. To illustrate, we include some code below showing exactly how one may go about including such a Hawkes process in AllSim (replacing the Poisson processes used earlier).\\n\\n```python\\nclass HawkesProcess(PoissonProcess):\\n    def __init__(self,\\n        lam: float = 0.1,\\n        update_lam: Callable[[int], float] = lambda t: t,\\n        delta: float = 0.1,\\n        a: float = 0.2):\\n        assert a >= 0, \\\"a should be larger than or equal to 0\\\"\\n        assert delta > 0, \\\"delta should be larger than 0\\\"\\n        super().__init__(lam, update_lam)\\n        self.a, self.delta, self._samples = a, delta, []\\n```\\n\\n```\"}"}
{"id": "wiw5mnja8W", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"def get_lam_unnormalized(self, t: int) -> float:\\n    return self._baseline_lam + np.sum(self.a * self.beta * np.exp(-self.beta * (t - self._samples[self._samples < t])))\\n\\ndef progress(self, t: int, neu: float = 1) -> int:\\n    self.lam = neu * self.get_lam_unnormalized(t)  # eqs. (5, 6)\\n    sample = np.random.poisson(lam=self.lam)\\n    self._samples.append(sample)\\n    return sample\\n\\nAllocation policies from machine learning and OR. It seems that both the ML [1\u20133, 29\u201334] and OR [35\u201341] community is focused more and more on this important class of problems\u2013 which is fantastic! But it also warrants careful evaluation. Furthermore, if we find that the evaluation strategies in medicine (which generally propose linear combinations of features [26, 42] or simple CoxPH models [43\u201346]) have shortcomings, then this is certainly the case for much more complicated strategies introduced in ML or OR. In fact, a recent survey confirmed exactly this concern: [47, cfr. Limitations of ML in transplant medicine]. It is in these extended scenarios where AllSim could help.\\n\\nNaturally, problems solved by the OR community concern a variant of the general problem presented in this paper. For example, Balseiro et al. [40] are concerned with distributing a fixed set of resources, to a varying set of incoming users. While different, such problems can still be modelled in AllSim. In the specific case of Balseiro et al. [40], resources are not unique (they represent an amount) and require much less machinery than what we require to model the varying resource scenario. Specifically, one can model the remaining amount of resources as an attribute in our Policy class.\\n\\nConclusion\\n\\nAllSim provides the means to perform standardised evaluation of repeated resource allocation policies in non-steady-state environments. While our experiments focus on organ-transplantation for the sake of exhibition, Appendix G illustrates AllSim for COVID-19 vaccine distribution, an example outside organ-transplantation. We believe that AllSim's generality and modularity allows for sensible adoption in a wide range of application areas. Furthermore, having standardised evaluation will encourage research in this very important and impactful domain spanning many application areas.\\n\\nConducting research in repeated resource allocation requires consideration of a policy's societal impact. While we believe AllSim will aid (rather than negatively impact) in this respect (by offering more than simple aggregate statistics), in Appendix F we provide a section dedicated to this topic.\\n\\nEthical research. We envisage AllSim as a tool to help accurate and standardised evaluation of repeated resource allocation policies, however emphasise that any finding would need to be further verified by a human expert or in some cases by a clinical trial. Ultimately, the decision on whether or not to trust a decision making tool is up to the acting decision-maker and ethics board. We hope that AllSim can help in any way to facilitate that decision, but stress that suggestions or evaluation always require critical assessment, as is the case for any research. We also refer the reader to Appendix F for a more thorough discussion on the potential societal impact of systems such as AllSim.\\n\\nReproducibility. To encourage reproducibility, we have included all our code to reproduce the presented results (as well as those in Appendix C). It should be clear from this paper, that reproducibility is actually one of the main reasons for doing this type of research in the first place. Furthermore, we have included a detailed discussion on how to use our simulation in Appendices D and E.\\n\\nAcknowledgements\\n\\nWe would like to thank our many collaborating clinicians, and in particular, Alexander Gimson, for many interesting discussions leading to this work. JB is funded by the W.D. Armstrong Trust, DJ is funded by Alzheimer's Research UK (ARUK), and AC is funded by Microsoft Research.\"}"}
{"id": "wiw5mnja8W", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Jeroen Berrevoets, Ahmed Alaa, Zhaozhi Qian, James Jordon, Alexander ES Gimson, and Mihaela Van Der Schaar. Learning queueing policies for organ transplantation allocation using interpretable counterfactual survival analysis. In *International Conference on Machine Learning*, pages 792\u2013802. PMLR, 2021.\\n\\nJeroen Berrevoets, James Jordon, Ioana Bica, Alexander Gimson, and Mihaela van der Schaar. OrganITE: Optimal transplant donor organ offering using an individual treatment effect. In *Advances in Neural Information Processing Systems*, volume 33, pages 20037\u201320050. Curran Associates, Inc., 2020.\\n\\nJinsung Yoon, Ahmed Alaa, Martin Cadeiras, and Mihaela Van Der Schaar. Personalized donor-recipient matching for organ transplantation. In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 31, 2017.\\n\\nJinsung Yoon, William R Zame, Amitava Banerjee, Martin Cadeiras, Ahmed M Alaa, and Mihaela van der Schaar. Personalized survival predictions via trees of predictors: An application to cardiac transplantation. *PloS one*, 13(3):e0194985, 2018.\\n\\nMichael Balmer, Marcel Rieser, Konrad Meister, David Charypar, Nicolas Lefebvre, and Kai Nagel. Matsim-t: Architecture and simulation times. In *Multi-agent systems for traffic and transportation engineering*, pages 57\u201378. IGI Global, 2009.\\n\\nRajkumar Buyya, Rajiv Ranjan, and Rodrigo N Calheiros. Modeling and simulation of scalable cloud computing environments and the CloudSim toolkit: Challenges and opportunities. In *2009 international conference on high performance computing & simulation*, pages 1\u201311. IEEE, 2009.\\n\\nKartik Ahuja and Mihaela Van der Schaar. Dynamic matching and allocation of tasks. *ACM Transactions on Economics and Computation (TEAC)*, 7(4):1\u201327, 2019.\\n\\nAlex J. Chan, Ioana Bica, Alihan H\u00fcy\u00fck, Daniel Jarrett, and Mihaela van der Schaar. The medkit-learn(ing) environment: Medical decision modelling through simulation. In *Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track*, 2021. URL https://openreview.net/forum?id=Ayf90B1yESX.\\n\\nJeroen Berrevoets, Krzysztof Kacprzyk, Zhaozhi Qian, and Mihaela van der Schaar. Causal deep learning. *arXiv preprint arXiv:2303.02186*, 2023.\\n\\nGreg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym, 2016.\\n\\nEmanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In *2012 IEEE/RSJ International Conference on Intelligent Robots and Systems*, pages 5026\u20135033. IEEE, 2012.\\n\\nCharles Beattie, Joel Z Leibo, Denis Teplyashin, Tom Ward, Marcus Wainwright, Heinrich K\u00fcttler, Andrew Lefrancq, Simon Green, V\u00edctor Vald\u00e9s, Amir Sadik, et al. Deepmind lab. *arXiv preprint arXiv:1612.03801*, 2016.\\n\\nCharles Beattie, Thomas K\u00f6ppe, Edgar A Du\u00e9\u00f1ez-Guzm\u00e1n, and Joel Z Leibo. Deepmind lab2d. *arXiv preprint arXiv:2011.07027*, 2020.\\n\\nAgnes Debout, Yohann Foucher, Katy Tr\u00e9bern-Launay, Christophe Legendre, Henri Kreis, Georges Mourad, Val\u00e9rie Garrigue, Emmanuel Morelon, Fanny Buron, Lionel Rostaing, et al. Each additional hour of cold ischemia time significantly increases the risk of graft failure and mortality following renal transplantation. *Kidney international*, 87(2):343\u2013349, 2015.\\n\\nJ Adam van der Vliet and Michiel C Warl\u00e9. The need to reduce cold ischemia time in kidney transplantation. *Current opinion in organ transplantation*, 18(2):174\u2013178, 2013.\\n\\nJames E Stahl, Jennifer E Kreke, Fawaz Ali Abdul Malek, Andrew J Schaefer, and Joseph Vacanti. Consequences of cold-ischemia time on primary nonfunction and patient and graft survival in liver transplantation: a meta-analysis. *PloS one*, 3(6):e2468, 2008.\\n\\nJersey Neyman. Sur les applications de la th\u00e9orie des probabilit\u00e9s aux experiences agricoles: Essai des principes. *Roczniki Nauk Rolniczych*, 10:1\u201351, 1923.\\n\\nDonald B Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies. *Journal of educational Psychology*, 66(5):688, 1974.\"}"}
{"id": "wiw5mnja8W", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Jeroen Berrevoets, Fergus Imrie, Trent Kyono, James Jordon, and Mihaela van der Schaar. To impute or not to impute? missing data in treatment effect estimation. In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent, editors, Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 3568\u20133590. PMLR, 25\u201327 Apr 2023. URL https://proceedings.mlr.press/v206/berrevoets23a.html.\\n\\nJeroen Berrevoets, Alicia Curth, Ioana Bica, Eoin McKinney, and Mihaela van der Schaar. Disentangled counterfactual recurrent networks for treatment effect inference over time. arXiv preprint arXiv:2112.03811, 2021.\\n\\nAlicia Curth and Mihaela van der Schaar. Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms. In International Conference on Artificial Intelligence and Statistics, pages 1810\u20131818. PMLR, 2021.\\n\\nIoana Bica, Ahmed Alaa, and Mihaela Van Der Schaar. Time series deconfounder: Estimating treatment effects over time in the presence of hidden confounders. In International Conference on Machine Learning, pages 884\u2013895. PMLR, 2020.\\n\\nC Ahn, H Amer, D Anglicheau, N Ascher, C Baan, B Bat-Ireedui, Thierry Berney, MGH Betjes, S Bichu, H Birn, et al. Global transplantation covid report march 2020. Transplantation, 2020.\\n\\nEzekiel J. Emanuel, Govind Persad, Ross Upshur, Beatriz Thome, Michael Parker, Aaron Glickman, Cathy Zhang, Connor Boyle, Maxwell Smith, and James P. Phillips. Fair allocation of scarce medical resources in the time of covid-19. New England Journal of Medicine, 382(21):2049\u20132055, 2020. doi: 10.1056/NEJMsb2005114. URL https://doi.org/10.1056/NEJMsb2005114.\\n\\nMarco Vergano, Guido Bertolini, Alberto Giannini, Giuseppe R. Gristina, Sergio Livi-gnini, Giovanni Mistraletti, Luigi Riccioni, and Flavia Petrini. Clinical ethics recommendations for the allocation of intensive care treatments in exceptional, resource-limited circumstances: the italian perspective during the COVID-19 epidemic. Critical Care, 24(165), 2020. doi: https://doi.org/10.1186/s13054-020-02891-w. URL https://doi.org/10.1186/s13054-020-02891-w.\\n\\nPatrick S Kamath, Russell H Wiesner, Michael Malinchoc, Walter Kremers, Terry M Therneau, Catherine L Kosberg, Gennaro D'Amico, E Rolland Dickson, and W Ray Kim. A model to predict survival in patients with end-stage liver disease. Hepatology, 33(2):464\u2013470, 2001.\\n\\nWes McKinney. Data Structures for Statistical Computing in Python. In St\u00e9fan van der Walt and Jarrod Millman, editors, Proceedings of the 9th Python in Science Conference, pages 56 \u2013 61, 2010. doi: 10.25080/Majora-92bf1922-00a.\\n\\nThe pandas development team. pandas-dev/pandas: Pandas, February 2020. URL https://doi.org/10.5281/zenodo.3509134.\\n\\nKatie L Connor, Eoin D O'Sullivan, Lorna P Marson, Stephen J Wigmore, and Ewen M Harrison. The future role of machine learning in clinical transplantation. Transplantation, 105(4):723\u2013735, 2021.\\n\\nDennis Medved, Pierre Nugues, and Johan Nilsson. Simulating the outcome of heart allocation policies using deep neural networks. In 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pages 6141\u20136144. IEEE, 2018.\\n\\nManuel Dorado-Moreno, Mar\u00eda P\u00e9rez-Ortiz, Pedro A Guti\u00e9rrez, Rub\u00e9n Ciria, Javier Brice\u00f1o, and C\u00e9sar Herv\u00e1s-Mart\u00ednez. Dynamically weighted evolutionary ordinal neural network for solving an imbalanced liver transplantation problem. Artificial Intelligence in Medicine, 77:1\u201311, 2017.\\n\\nDennis Medved, Mattias Ohlsson, Peter H\u00f6glund, Bodil Andersson, Pierre Nugues, and Johan Nilsson. Improving prediction of heart transplantation outcome using deep learning techniques. Scientific reports, 8(1):1\u20139, 2018.\\n\\nKyung Don Yoo, Junhyug Noh, Hajeong Lee, Dong Ki Kim, Chun Soo Lim, Young Hoon Kim, Jung Pyo Lee, Gunhee Kim, and Yon Su Kim. A machine learning approach using survival statistics to predict graft survival in kidney transplant recipients: a multicenter cohort study. Scientific reports, 7(1):1\u201312, 2017.\"}"}
{"id": "wiw5mnja8W", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Alex J. Chan, Alicia Curth, and Mihaela van der Schaar. Inverse online learning: Understanding non-stationary and reactionary policies. In International Conference on Learning Representations, 2021.\\n\\nDimitris Bertsimas, Vivek F Farias, and Nikolaos Trichakis. Fairness, efficiency, and flexibility in organ allocation for kidney transplantation. Operations Research, 61(1):73\u201387, 2013.\\n\\nDimitris Bertsimas, Vivek F Farias, and Nikolaos Trichakis. On the efficiency-fairness trade-off. Management Science, 58(12):2234\u20132250, 2012.\\n\\nAmir Elalouf, Yael Perlman, and Uri Yechiali. A double-ended queueing model for dynamic allocation of live organs based on a best-fit criterion. Applied Mathematical Modelling, 60:179\u2013191, 2018.\\n\\nJohn P Dickerson, Ariel D Procaccia, and Tuomas Sandholm. Failure-aware kidney exchange. In Proceedings of the fourteenth ACM conference on Electronic commerce, pages 323\u2013340, 2013.\\n\\nMustafa Akan, Oguzhan Alagoz, Baris Ata, Fatih Safa Erenay, and Adnan Said. A broader view of designing the liver allocation system. Operations research, 60(4):757\u2013770, 2012.\\n\\nSantiago Balseiro, Haihao Lu, and Vahab Mirrokni. Dual mirror descent for online allocation problems. In International Conference on Machine Learning, pages 613\u2013628. PMLR, 2020.\\n\\nJeroen Berrevoets, Sam Verboven, and Wouter Verbeke. Treatment effect optimisation in dynamic environments. Journal of Causal Inference, 10(1):106\u2013122, 2022. doi: doi:10.1515/jci-2020-0009. URL https://doi.org/10.1515/jci-2020-0009.\\n\\nAndres E Ruf, Walter K Kremers, Lila L Chavez, Valeria I Descalzi, Luis G Podesta, and Federico G Villamil. Addition of serum sodium into the meld score predicts waiting list mortality better than meld alone. Liver Transplantation, 11(3):336\u2013343, 2005.\\n\\nUri Kartoun. Towards optimally replacing the current version of meld. Journal of Hepatology, 2022.\\n\\nJames Neuberger, Alex Gimson, Mervyn Davies, Murat Akyol, John O'Grady, Andrew Burroughs, Mark Hudson, UK Blood, et al. Selection of patients for liver transplantation and allocation of donated livers in the uk. Gut, 57(2):252\u2013257, 2008.\\n\\nDavid Goldberg, Alejandro Mantero, Craig Newcomb, Cindy Delgado, Kimberly Forde, David Kaplan, Binu John, Nadine Nuchovich, Barbara Dominguez, Ezekiel Emanuel, et al. Development and validation of a model to predict long-term survival after liver transplantation. Liver transplantation, 27(6):797\u2013807, 2021.\\n\\nW Ray Kim, Ajitha Mannalithara, Julie K Heimbach, Patrick S Kamath, Sumeet K Asrani, Scott W Biggins, Nicholas L Wood, Sommer E Gentry, and Allison J Kwong. Meld 3.0: the model for end-stage liver disease updated for the modern era. Gastroenterology, 161(6):1887\u20131895, 2021.\\n\\nNeta Gotlieb, Amirhossein Azhie, Divya Sharma, Ashley Spann, Nan-Ji Suo, Jason Tran, Ani Orchanian-Cheff, Bo Wang, Anna Goldenberg, Michael Chass\u00e9, et al. The promise of machine learning applications in solid organ transplantation. NPJ digital medicine, 5(1):1\u201313, 2022.\\n\\nTennison Liu, Zhaozhi Qian, Jeroen Berrevoets, and Mihaela van der Schaar. Goggle: Generative modelling for tabular data by learning relational structure. In The Eleventh International Conference on Learning Representations, 2022.\\n\\nDoina Precup. Eligibility traces for off-policy policy evaluation. Computer Science Department Faculty Publication Series, page 80, 2000.\\n\\nPhilip S Thomas. Safe reinforcement learning. PhD thesis, University of Massachusetts Libraries, 2015.\\n\\nMiroslav Dud\u00edk, John Langford, and Lihong Li. Doubly robust policy evaluation and learning. arXiv preprint arXiv:1103.4601, 2011.\\n\\nJohn Hammersley. Monte carlo methods. Springer Science & Business Media, 2013.\\n\\nMichael JD Powell and J Swann. Weighted uniform sampling\u2014a monte carlo technique for reducing variance. IMA Journal of Applied Mathematics, 2(3):228\u2013236, 1966.\\n\\nYash Chandak, Scott Niekum, Bruno Castro da Silva, Erik Learned-Miller, Emma Brunskill, and Philip S Thomas. Universal off-policy evaluation. arXiv preprint arXiv:2104.12820, 2021.\"}"}
{"id": "wiw5mnja8W", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Aliz\u00e9e Pace, Alex J. Chan, and Mihaela van der Schaar. Poetree: Interpretable policy learning with adaptive decision trees. In International Conference on Learning Representations, 2021.\\n\\nKeisuke Hirano, Guido W Imbens, and Geert Ridder. Efficient estimation of average treatment effects using the estimated propensity score. *Econometrica*, 71(4):1161\u20131189, 2003.\\n\\nDonald B Rubin. Estimating causal effects from large data sets using propensity scores. *Annals of internal medicine*, 127(8_Part_2):757\u2013763, 1997.\\n\\nGuido W Imbens and Donald B Rubin. *Causal inference in statistics, social, and biomedical sciences*. Cambridge University Press, 2015.\\n\\nGuido W Imbens and Donald B Rubin. Rubin causal model. In *Microeconometrics*, pages 229\u2013241. Springer, 2010.\\n\\nSteven Piantadosi. *Clinical trials: a methodologic perspective*. John Wiley & Sons, 2017.\\n\\nStuart J Pocock. *Clinical trials: a practical approach*. John Wiley & Sons, 2013.\\n\\nLawrence M Friedman, Curt D Furberg, David L DeMets, David M Reboussin, and Christopher B Granger. *Fundamentals of clinical trials*. Springer, 2015.\\n\\nRebecca DerSimonian and Nan Laird. Meta-analysis in clinical trials. *Controlled clinical trials*, 7(3):177\u2013188, 1986.\\n\\nAhmed Alaa, Alex J. Chan, and Mihaela van der Schaar. Generative time-series modeling with fourier flows. In International Conference on Learning Representations, 2020.\\n\\nJoel Z. Leibo, Edgar Duenez Guzman, Alexander Sasha Vezhnevets, John P. Agapiou, Peter Sunehag, Raphael Koster, Jayd Matyas, Charles Beattie, Igor Mordatch, and Thore Graepel. Scalable evaluation of multi-agent reinforcement learning with melting pot. In *International Conference on Machine Learning*, pages 6187\u20136199. PMLR, 2021.\\n\\nOriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K\u00fcttler, John Agapiou, Julian Schrittwieser, et al. Starcraft ii: A new challenge for reinforcement learning. *arXiv preprint arXiv:1708.04782*, 2017.\\n\\nTom Stepleton. The pycolab game engine, 2017.\\n\\nAlex J. Chan and Mihaela van der Schaar. Scalable bayesian inverse reinforcement learning. In International Conference on Learning Representations, 2020.\\n\\nPaul W Holland. Statistics and causal inference. *Journal of the American statistical Association*, 81(396):945\u2013960, 1986.\\n\\nVikram Kilambi, Kevin Bui, and Sanjay Mehrotra. Livsim: an open-source simulation software platform for community research and development for liver allocation policies. *Transplantation*, 102(2), 2018.\\n\\nMohd Shoaib, Utkarsh Prabhakar, Sumit Mahlawat, and Varun Ramamohan. A discrete-event simulation model of the kidney transplantation system in Rajashtan, India. *Health Systems*, 11(1):30\u201347, 2022.\\n\\nShoaib Mohd, Navonil Mustafee, Karan Madan, and Varun Ramamohan. Leveraging healthcare facility network simulations for capacity planning and facility location in a pandemic. Available at SSRN 3794811, 2021.\\n\\nCecilia Nardini. The ethics of clinical trials. *Ecancermedicalscience*, 8, 2014.\\n\\nJack Cuzick, Robert Edwards, and Nereo Segnan. Adjusting for non-compliance and contamination in randomized clinical trials. *Statistics in medicine*, 16(9):1017\u20131029, 1997.\\n\\nDavid Maxwell Chickering and Judea Pearl. A clinician's tool for analyzing non-compliance. In *Proceedings of the National Conference on Artificial Intelligence*, pages 1269\u20131276, 1996.\\n\\nOsvald Nitski, Amirhossein Azhie, Fakhar Ali Qazi-Arisar, Xueqi Wang, Shihao Ma, Leslie Lilly, Kymberly D Watt, Josh Levitsky, Sumeet K Asrani, Douglas S Lee, et al. Long-term mortality risk stratification of liver transplant recipients: real-time application of deep learning algorithms on longitudinal data. *The Lancet Digital Health*, 3(5):e295\u2013e305, 2021.\\n\\nIna Jochmans, Marieke van Rosmalen, Jacques Pirenne, and Undine Samuel. Adult liver allocation in Eurotransplant. *Transplantation*, 101(7):1542\u20131550, 2017.\"}"}
{"id": "wiw5mnja8W", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "wiw5mnja8W", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1. For all authors...\\n\\n(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\\n\\n(b) Did you describe the limitations of your work? [Yes]\\n\\n(c) Did you discuss any potential negative societal impacts of your work? [Yes]\\n\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\\n\\n2. If you are including theoretical results...\\n\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n\\n(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes]\\n\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes]\\n\\n(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes]\\n\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [N/A]\\n\\nThese are non compute-intensive experiments\\n\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\n\\n(b) Did you mention the license of the assets? [Yes]\\n\\nWhen using the code\\n\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\n\\n(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A]\\n\\n(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]\\n\\nAll used data is public\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n\\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]\\n\\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]\\n\\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]\"}"}
