{"id": "XfQbPqRPXi", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Towards Better Evaluation of GNN Expressiveness with BREC Dataset\\n\\nYanbo Wang Muhan Zhang\\nInstitute for Artificial Intelligence, Peking University\\nyanxwb202@gmail.com, muhan@pku.edu.cn\\n\\nAbstract\\nResearch on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often limited to distinguishing certain families of non-isomorphic graphs, leading to difficulties in quantitatively comparing their expressiveness. In contrast to theoretical analysis, another way to measure expressiveness is by evaluating model performance on certain datasets containing 1-WL-indistinguishable graphs. Previous datasets specifically designed for this purpose, however, face problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only a few essentially different graphs in each dataset). To address these limitations, we propose a new expressiveness dataset, BREC, which includes 400 pairs of non-isomorphic graphs carefully selected from four primary categories (Basic, Regular, Extension, and CFI). These graphs have higher difficulty (up to 4-WL-indistinguishable), finer granularity (able to compare models between 1-WL and 3-WL), and a larger scale (400 pairs). Further, we synthetically test 23 models with higher-than-1-WL expressiveness on our BREC dataset. Our experiment gives the first thorough comparison of the expressiveness of those state-of-the-art beyond-1-WL GNN models. We expect this dataset to serve as a benchmark for testing the expressiveness of future GNNs. Our dataset and evaluation code are released at: https://github.com/GraphPKU/BREC.\"}"}
{"id": "XfQbPqRPXi", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"et al. [15] unify recent subgraph GNNs and establish that their expressiveness upper bound is 3-WL. Zhang et al. [16] construct a comprehensive expressiveness hierarchy for subgraph GNNs, providing counterexamples for each pairwise distinction. Nonetheless, the magnitude of the gaps remains unknown. Furthermore, there exist methods that are difficult to categorize within the $k$-WL hierarchy. For instance, Papp and Wattenhofer [17] propose four extensions of GNNs, each of which cannot strictly compare with the other. Similarly, Feng et al. [18] propose a GNN that is partially stronger than 3-WL yet fails to distinguish many graphs that are distinguishable by 3-WL. In a different approach, Huang et al. [19] propose evaluating expressiveness by enumerating specific significant substructures, such as 6-cycles. Zhang et al. [20] introduces graph biconnectivity to test expressiveness.\\n\\nWithout a unified theoretical characterization of expressiveness, employing expressiveness datasets for testing proves valuable. Notably, three expressiveness datasets, EXP, CSL, and SR25, have been introduced by Abboud et al. [21], Murphy et al. [22], Balcilar et al. [9] and have found widespread usage in recent studies. However, these datasets exhibit notable limitations. Firstly, they lack sufficient difficulty. The EXP and CSL datasets solely consist of examples where 1-WL fails, and most recent GNN variants have achieved perfect accuracy on these datasets. Secondly, the granularity of these datasets is too coarse, which means that graphs in these datasets are generated using a single method, resulting in a uniform level of discrimination difficulty. Consequently, the performance of GNN variants often falls either at random guessing (completely indistinguishable) or 100% (completely distinguishable), thereby hindering the provision of a nuanced measure of expressiveness. Lastly, these datasets suffer from small sizes, typically comprising only a few substantially different graphs, raising concerns of incomplete measurement.\\n\\nTo overcome the limitations of current expressiveness datasets, we propose a new dataset, BREC, including 400 pairs of non-isomorphic graphs in 4 major categories: Basic graphs, Regular graphs, Extension graphs, and CFI graphs. Compared to previous ones, BREC has a greater difficulty (up to 4-WL-indistinguishable), finer granularity (able to compare models between 1-WL and 3-WL), and larger scale (800 non-isomorphic graphs organized as 400 pairs), addressing the shortcomings. Due to the increased size and diversity of the dataset, the traditional classification task may not be suitable for training-based evaluation methods which rely on generalization ability. Thus, we propose a novel evaluation procedure based on directly comparing the discrepancies between model outputs to test pure practical expressiveness. Acknowledging the impact of numerical precision owing to tiny differences between graph pairs, we propose reliable paired comparisons building upon a statistical method [23, 24], which offers a precise error bound. Experiments verify that the evaluation procedure aligns well with known theoretical results.\\n\\nFinally, we comprehensively compared 23 representative beyond-1-WL models on BREC. Our experiments first give a reliable empirical comparison of state-of-the-art GNNs' expressiveness. The currently most thorough investigation is a good start for gaining deeper insights into various schemes to enhance GNNs' expressiveness. On BREC, GNN accuracies range from 41.5% to 70.2%, with $I^2$-GNN [19] performing the best. The 70.2% highest accuracy also implies that the dataset is far from saturation. We expect BREC can serve as a benchmark for testing future GNNs' expressiveness. We also welcome contributions and suggestions to improve BREC. Our dataset and evaluation code are included in https://github.com/GraphPKU/BREC.\"}"}
{"id": "XfQbPqRPXi", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Given the significance of GI and WL, several expressiveness datasets have been introduced, with the following three being the most frequently utilized. We selected a pair of graphs from each dataset, which are illustrated in Figure 1. Detailed statistics for these datasets are presented in Table 1.\\n\\n**EXP Dataset.** This dataset comprises 600 pairs of non-isomorphic graphs where the 1-WL test fails. Graphs are generated pair-wise, and each graph comprises two disconnected components. The first component, the \\\"core component,\\\" is designed to be non-isomorphic with the other graph's \\\"core component,\\\" each satisfying distinct SAT conditions in the two graphs. The second component, referred to as the \\\"planar component,\\\" is identical in both graphs and introduces noise into the dataset. However, it is important to note that there are only three substantially different core pairs, which can truly evaluate the expressiveness of the models. Each graph in EXP is labeled 0/1 based on whether its core component satisfies the SAT condition for a binary classification problem. Although EXP addresses the issue of semantic labeling by introducing the SAT problem and enhances the dataset's size and complexity by including planar components, the simplicity of core component generation and the insufficient number of different core pairs result in most recent GNNs achieving nearly 100% accuracy on EXP, making it difficult for detailed comparisons.\\n\\n**CSL Dataset.** This dataset consists of 150 Circulant Skip Links (CSL) graphs, where the 1-WL test fails. A CSL graph is defined as follows: Let $r$ and $m$ be co-prime natural numbers with $r < m - 1$. $G(m,r) = (V,E)$ is an undirected 4-regular graph with $V = [m]$, where the edges form a cycle and include skip links. Specifically, for the cycle, $(j,j+1) \\\\in E$ for $j \\\\in [m-1]$, and $(m,1) \\\\in E$. For the skip links, the sequence is recursively defined as $s_1 = 1$, $s_{i+1} = (s_i + r) \\\\mod m + 1$, and $(s_i, s_{i+1}) \\\\in E$ for any $i \\\\in \\\\mathbb{N}$. In CSL, we consider CSL graphs with $m = 41$ and $r = 2, 3, 4, 5, 6, 9, 11, 12, 13, 16, \\\\ldots$, resulting in 10 distinct CSL graphs. For each distinct CSL graph, we generate 14 corresponding graphs by randomly reindexing the nodes. As a result, the dataset contains a total of 150 graphs. In CSL, each of the 10 distinct CSL graphs is treated as a separate class, and the task is to train a 10-way classification model. While the dataset allows for the generation of 4-regular graphs with any number of nodes, the final dataset contains only ten essentially different regular graphs with the\"}"}
{"id": "XfQbPqRPXi", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Due to the nature of regular graphs and their fixed structure, many recent expressive GNN models perform well on this dataset, achieving close to 100% accuracy.\\n\\nSR25 Dataset. It consists of 15 strongly regular graphs (SR) where the 3-WL test fails. Each graph is an SR with 25 nodes and a degree of 12. In these graphs, connected nodes have 5 common neighbors, while non-connected nodes have 6. In practice, SR25 is transformed into a 15-way classification problem for mapping each graph into a different class where the training and test graphs overlap. Indeed, 3-WL serves as an upper bound for most recent expressive GNNs. Thus most methods only obtain 6.67% (1/15) accuracy. While some models partially surpassing 3-WL easily achieve completely distinguishable (100%) performance [18], since each graph is an SR with the same parameters. This binary outcome can hardly provide a fine-grained expressiveness measure.\\n\\nSummary. These three datasets have limitations regarding difficulty, granularity, and scale. In terms of difficulty, these datasets are all bounded by 3-WL, failing to evaluate models (partly) beyond 3-WL [18, 19]. In terms of granularity, the graphs are generated in one way, and the parameters of the graphs are repetitive, which easily leads to a 0/1 step function of model performance and cannot measure subtle differences between models. In terms of scale, the number of substantially different graphs in the datasets is small, and the test results may be incomplete to reflect expressiveness measurement.\\n\\n### BREC: A New Dataset for Expressiveness\\n\\nWe propose a new expressiveness dataset, BREC, to address the limitations regarding difficulty, granularity, and scale. It consists of four major categories of graphs: Basic, Regular, Extension, and CFI. Basic graphs include relatively simple 1-WL-indistinguishable graphs. Regular graphs include four types of subcategorized regular graphs. Extension graphs include special graphs that arise when comparing four kinds of GNN extensions [17]. CFI graphs include graphs generated by CFI methods [28] with high difficulty. Some samples are shown in Fig 2.\\n\\n#### 3.1 Dataset Composition\\n\\nBREC includes 800 non-isomorphic graphs arranged in a pairwise manner to construct 400 pairs, with detailed composition as follows: (For a more detailed generation process, please refer to AppendixK)\\n\\n**Basic Graphs.** Basic graphs consist of 60 pairs of 10-node graphs. These graphs are collected from an exhaustive search and intentionally designed to be non-regular. Although they are 1-WL-indistinguishable, most can be distinguished by expressive GNN variants. Basic graphs can also be regarded as an augmentation of the EXP dataset, as they both employ non-regular 1-WL-indistinguishable graphs. Nevertheless, Basic graphs offer a greater abundance of instances and more intricate graph patterns. The relatively small size also facilitates visualization and analysis.\\n\\n**Regular Graphs.** Regular graphs consist of 140 pairs of regular graphs, including 50 pairs of simple regular graphs, 50 pairs of strongly regular graphs, 20 pairs of 4-vertex condition graphs, and 20 pairs of graphs generated by CFI methods [28].\"}"}
{"id": "XfQbPqRPXi", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of distance regular graphs. Each pair of graphs shares identical parameters. A regular graph refers to a graph where all nodes possess the same degree. Regular graphs are 1-WL-indistinguishable, and some studies delve into the analysis of GNN expressiveness from this perspective [29, 13]. We denote regular graphs without any special properties as simple regular graphs. When exploring more intricate regular graphs, the concept of strongly regular graphs (where 3-WL fails) is often introduced. Strongly regular graphs further require that the number of neighboring nodes shared by any two nodes depends solely on their connectivity. Notable examples of strongly regular graphs include the $4 \\\\times 4$-Rook's graph and the Shrikhande graph (Fig 2(c)). Additionally, the $4 \\\\times 4$-Rook's graph satisfies the 4-vertex condition property, which signifies that the number of connected edges between the common neighbors of any two nodes is solely determined by their connectivity [30]. It is worth mentioning that the diameter of a connected strongly regular graph is always 2 [31]. A more challenging type of graph known as the distance regular graphs [32] is proposed aiming for extending the diameter. Please refer to Appendix A for a more comprehensive exploration of their relationship.\\n\\nRegular graphs can also as an enriching addition to the CSL and SR25 datasets. By expanding upon the existing subdivisions of regular graphs, this section widens the range of difficulty and raises the upper bound of complexity. Moreover, unlike the previous datasets, regular graphs are not limited to sharing identical parameters for all graphs within each category, greatly enhancing diversity.\\n\\nExtension Graphs. Extension graphs include 100 pairs of graphs inspired by Papp and Wattenhofer [17]. They proposed 4 types of theoretical GNN extensions: $k$-WL hierarchy-based, substructure-counting-based, $k$-hop-subgraph-based, and marking-based methods. The authors reveal that most of them are not strictly comparable. Leveraging the insights from theoretical analysis and some empirically derived findings, we generated 100 pairs of 1-WL-indistinguishable and 3-WL-distinguishable graphs to improve the granularity. Noting that it was not considered in any of the previous datasets.\\n\\nCFI Graphs. CFI graphs consist of 100 pairs of graphs inspired by Cai et al. [28]. They developed a method to generate graphs distinguishable by $k$-WL but not by $(k-1)$-WL for any $k$. We utilized this method to create 100 pairs of graphs spanning up to 4-WL-indistinguishable, even surpassing the current research's upper bounds. Specifically, 60 pairs are solely distinguishable by 3-WL, 20 are solely distinguishable by 4-WL, and 20 are even 4-WL-indistinguishable. Similar to the previously mentioned parts, CFI graphs were not considered in the previous datasets. As the most challenging part, it pushes the upper limit of difficulty even higher. Furthermore, the graph sizes in this section are larger than other parts (up to 198 nodes). This aspect intensifies the challenge of the dataset, demanding a model's ability to process graphs with heterogeneous sizes effectively.\\n\\n3.2 Advantages\\n\\nDifficulty. By utilizing the CFI method, we specifically provide graphs being 4-WL-indistinguishable. Additionally, we include 4-vertex condition graphs and distance regular graphs, which are variants of strongly regular graphs (3-WL-indistinguishable) but pose greater challenges in terms of complexity.\\n\\nGranularity. The different classes of graphs in BREC exhibit varying difficulty levels, each contributing to the dataset in distinct ways. Basic graphs contain fundamental 1-WL-indistinguishable graphs, similar to the EXP dataset, as a starting point for comparison. Regular graphs extend the CSL and SR25 datasets. The major components of regular graphs are simple regular graphs and strongly regular graphs, where 1-WL and 3-WL fail, respectively. Including 4-vertex condition graphs and distance regular graphs further elevates the complexity. Extension graphs bridge the gap between 1-WL and 3-WL, offering a finer-grained comparison for evaluating models beyond 1-WL. CFI graphs span the spectrum of difficulty from 1-WL to 4-WL-indistinguishable. By comprehensive graph composition, BREC explores the boundaries of graph pattern distinguishability.\\n\\nScale. While previous datasets relied on only tens of different graphs to generate the dataset, BREC utilizes a collection of 800 different graphs. This significant increase in the number of graphs greatly enhances the diversity. The larger graph set in BREC also contributes to a more varied distribution of graph statistics. In contrast, previous datasets such as CSL and SR25 only have the same number of nodes and degrees across all graphs. For detailed statistics of BREC, please refer to Appendix D.\"}"}
{"id": "XfQbPqRPXi", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This section introduces a novel training framework and evaluation method for BREC. Unlike previous datasets, BREC departs from the conventional classification setting, where each graph is assigned a label, a classification model is trained, and the accuracy on test graphs serves as the measure of expressiveness. The labeling schemes used in previous datasets like semantic labels based on SAT conditions in EXP, or distinct labels for essentially different graphs in CSL and SR25, do not apply to BREC. There are two primary reasons. First, BREC aims to enrich the diversity of graphs, which precludes using a semantic label tied to SAT conditions, as it would significantly limit the range of possible graphs. Second, assigning a distinct label to each graph in BREC would result in an 800-class classification problem, where performance could be influenced by factors other than expressiveness. Our core idea is to measure models' \u201cseparating power\u201d directly. Thus BREC is organized in pairs, where each pair is individually tested to determine whether a GNN can distinguish them. By adopting a pairwise evaluation method, BREC provides a more focused measure of models' expressiveness, aligning to assess distinguishing ability. Nevertheless, how can we say a pair of graphs is successfully distinguished? Previous researchers tend to set a small threshold (like 1E-4) manually. If the embedding distance between them is larger than the threshold, the GNN is considered can distinguish them. However, this method lacks reliability due to numerical precision, especially when graphs vary in size. In order to yield dependable outcomes, we propose an evaluation method measuring both external difference and internal fluctuations. Furthermore, we introduce a training framework for pairwise data, employing the siamese network design [33] and contrastive loss [34, 35]. The pipeline is depicted in Fig 3(a).\\n\\n4.1 Training Framework\\n\\nWe adhere to the siamese network design [33] to train a model to distinguish each pair of graphs. The central component consists of two identical models that maintain identical parameters. When a pair of graphs is inputted, it produces a corresponding pair of embeddings. Subsequently, the difference between them is assessed using cosine similarity. The loss function is formulated as follows:\\n\\n\\\\[\\nL(f, G, H) = \\\\text{Max}(0, \\\\|f(G)\\\\| \\\\cdot \\\\|f(H)\\\\| - \\\\gamma),\\n\\\\]\\n\\nwhere the GNN model \\\\(f: \\\\{G\\\\} \\\\rightarrow \\\\mathbb{R}^d\\\\), \\\\(G\\\\) and \\\\(H\\\\) are two non-isomorphic graphs, and \\\\(\\\\gamma\\\\) is a margin hyperparameter (set to 0 in our experiments). The loss function aims to promote the cosine similarity value lower than \\\\(\\\\gamma\\\\), thereby encouraging a greater separation between the two graph embeddings. The training process yields several benefits for the models. Firstly, it enables the GNN to achieve its theoretical expressiveness. The theoretical analysis of GNN expressiveness focuses primarily on the network's structure without imposing any constraints on its parameters, which means we are exploring the expressiveness of a group of functions. If a model with particular parameters can distinguish a pair of graphs, the model's design and structure possess sufficient expressiveness. However, it is impractical to iterate all possible parameter combinations to test the real upper bound. Hence, training can realize searching in the function space, enabling models to achieve better practical expressiveness. Furthermore, training aids components to possess specific properties, such as injectivity and universal approximation, which are vital for attaining theoretical expressiveness. These properties require specific parameter configurations, and randomly initialized parameters may not satisfy these requirements. Moreover, through training, model-distinguishable pairs are more easily discriminated from model-indistinguishable pairs, which helps reduce the false negative rate.\"}"}
{"id": "XfQbPqRPXi", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"caused by numerical precision. The difference between their embeddings is further magnified in the pairwise contrastive training process if the model distinguishes them. However, the difference remains unaffected mainly and is only influenced by numerical errors for model-indistinguishable pairs. The training framework is illustrated in Fig 3(a).\\n\\n4.2 Evaluation Method\\n\\nRecall that our approach involves comparing the outputs on a pair of non-isomorphic graphs. If there exists a notable disparity between them, we consider the GNN to be able to distinguish them. However, determining an appropriate threshold poses a challenge. A large threshold may yield false negatives where the model is expressive enough, but the observed difference falls short of the threshold. Conversely, a small threshold may result in false positives, where the model fails to distinguish the graphs. However, the fluctuating or numerical errors cause the difference to exceed the small threshold.\\n\\nTo address the issue of fluctuating errors, we draw inspiration from Paired Comparisons \\\\[23\\\\]. It involves comparing two groups of results instead of a single pair. The influence of random errors is mitigated by repeatedly generating results and comparing the two groups of results. Building upon it, we introduce a method called Reliable Paired Comparison (RPC) to verify whether a GNN genuinely produces distinct outputs for a pair of graphs. The pipeline is depicted in Fig 3(b).\\n\\nRPC consists of two main components: Major procedure and Reliability check. The Major procedure is conducted on a pair of non-isomorphic graphs to measure their dissimilarity. In comparison, the Reliability check is conducted on graph automorphisms to capture internal fluctuations with numerical precision.\\n\\nMajor procedure.\\n\\nFor two non-isomorphic graphs $G$ and $H$, we create $q$ copies of each by randomly reindexing (operate permutation on node indexes, thus generating an isomorphic graph but with different node orders) them. It results in two groups of graphs, where each copy is represented as: $G_i, H_i, i \\\\in [q]$.\\n\\nSupposing the GNN $f: \\\\{G\\\\} \\\\rightarrow \\\\mathbb{R}^d$, we first calculate $q$ differences utilizing Paired Comparisons.\\n\\n$$d_i = f(G_i) - f(H_i), i \\\\in [q].$$\\n\\nAssumption 4.1. $d_i$ are independent $N(\\\\mu, \\\\Sigma)$ random vectors.\\n\\nThe above assumption is based on a more basic assumption that $f(G_i), f(H_i)$ follow Gaussian distributions, which presumes that random reindexing only introduces Gaussian noise to the result. The mean difference between two graph embeddings $\\\\mu = 0$ implies the GNN cannot distinguish them. Therefore, we can obtain the distinguishing result by conducting an $\\\\alpha$-level Hotelling's T-square test, comparing the hypotheses $H_0: \\\\mu = 0$ against $H_1: \\\\mu \\\\neq 0$. We calculate the $T_2$-statistic for $\\\\mu$ as:\\n\\n$$T_2 = q \\\\left( \\\\frac{d - \\\\mu}{\\\\sqrt{\\\\frac{q-1}{q} \\\\sum_{i=1}^{q}(d_i - d)(d_i - d)^T}} \\\\right),$$\\n\\nwhere\\n\\n$$d = \\\\frac{1}{q} \\\\sum_{i=1}^{q} d_i,$$\\n\\n$$S = \\\\frac{1}{q-1} \\\\sum_{i=1}^{q} (d_i - d)(d_i - d)^T.$$\\n\\nHotelling's T-square test proves that $T_2$ is distributed as an $(q-1)_{d,q-d}$ random variable, whatever the true $\\\\mu$ and $\\\\Sigma$ [36]. The theorem establishes a connection between the unknown parameter $\\\\mu$ and a definite probability distribution $F_{d,q-d}$, allowing us to confirm the confidence interval of $\\\\mu$ by testing the distribution fit. In order to test the hypothesis $H_0: \\\\mu = 0$, we substitute $\\\\mu = 0$ into Equation (4) to obtain $T_2$ test $= \\\\frac{q d T}{S - 1}$.\\n\\nThen, for a specific $\\\\alpha$, an $\\\\alpha$-level test of $H_0: \\\\mu = 0$ versus $H_1: \\\\mu \\\\neq 0$ for a population following $N(\\\\mu, \\\\Sigma)$ distribution accepts $H_0$ (the GNN cannot distinguish the pair) if:\\n\\n$$T_2^{\\\\text{test}} = \\\\frac{q d T}{S - 1} < (q-1)_{d,q-d} F_{d,q-d} - d(\\\\alpha),$$\\n\\nwhich indicates the distinction between the graphs.\"}"}
{"id": "XfQbPqRPXi", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"where $F_{d,q}^{\\\\alpha}$ is the upper $(100\\\\alpha)$th percentile of the $F$-distribution $F_{d,q}$ with $d$ and $q - d$ degrees of freedom. Similarly, we reject $H_0$ (the GNN can distinguish the pair) if\\n\\n$$T_2^{\\\\text{test}} = q_d T_s^{-1} d > (q - 1)d F_{d,q}^{-d}(\\\\alpha).$$\\n\\n(7)\\n\\nReliability check. Although the above test is theoretically valid for evaluating the expressiveness of GNNs, in practice, it is susceptible to computational precision limitations. These limitations can manifest in various scenarios, such as comparing numbers close to zero or inverting a matrix close to zero, making it difficult to rely on the test constantly. We incorporate the Reliability check to monitor abnormal results to address this concern. This step effectively bridges the external difference between two graphs and the internal fluctuations within a single graph.\\n\\nWLOG, we replace $H_0$ by reindexing of $G$, i.e., $G_\\\\pi$. Thus, we can obtain the internal fluctuations within $G$ by comparing it with $G_\\\\pi$, and the external difference between $G$ and $H$ by comparing $G$ and $H$. We utilize the same step as Major procedure on $G$ and $G_\\\\pi$, calculating the $T_2^{\\\\text{reliability}}$-statistics as follows:\\n\\n$$T_2^{\\\\text{reliability}} = q_d T_s^{-1} d,$$\\n\\n(8)\\n\\nwhere $d_i = f(G_i) - f(G_\\\\pi i), i \\\\in [q]$, $S = 1/(q - 1) \\\\sum_{i=1}^q (d_i - d)(d_i - d)$.\\n\\n(9)\\n\\nRecalling that $G$ and $G_\\\\pi$ are isomorphic, the GNN should not distinguish between them, implying that $\\\\mu = 0$. Therefore, the test result is considered reliable only if\\n\\n$$T_2^{\\\\text{reliability}} < (q - 1)d (q - d) F_{d,q}^{-d}(\\\\alpha).$$\\n\\n(8)\\n\\nCombining the reliability and distinguishability results, we get the complete RPC (Fig 3) as follows:\\n\\nFor each pair of graphs $G$ and $H$, we first calculate the threshold value, denoted as $\\\\text{Threshold} = (q - 1)d (q - d) F_{d,q}^{-d}(\\\\alpha)$. Next, we conduct the Major procedure on $G$ and $H$ for distinguishability and perform the Reliability check on $G$ and $G_\\\\pi$ for Reliability. Only when the $T_2^{\\\\text{test}}$-statistic from the Major procedure, denoted as $T_2^{\\\\text{test}}$, and the $T_2^{\\\\text{reliability}}$-statistic from the Reliability check, denoted as $T_2^{\\\\text{reliability}}$, satisfying\\n\\n$$T_2^{\\\\text{reliability}} < \\\\text{Threshold} < T_2^{\\\\text{test}},$$\\n\\ndo we conclude that the GNN can distinguishing $G$ and $H$.\\n\\nWe further propose Reliable Adaptive Pairwise Comparison (RAPC), aiming to adaptively adjust the threshold and provide an upper bound for false positive rates. In practice, we use RPC due to its less computational time and satisfactory performance. For more about RAPC, please refer to Appendix E.\\n\\n5 Experiment\\n\\nIn this section, we evaluate the expressiveness of 23 representative models using our BREC dataset.\\n\\nModel selection. We evaluate six categories of methods: non-GNN methods, subgraph-based GNNs, $k$-WL-hierarchy-based GNNs, substructure-based GNNs, transformer-based GNNs, and random GNNs. Our primary focus will be on the first three categories. We implement four types of non-GNN baselines based on Papp and Wattenhofer [17], Ying et al. [38], including WL test (3-WL and SPD-WL), counting substructures ($S_3$ and $S_4$), neighborhood up to a certain radius ($N_1$ and $N_2$), and marking ($M_1$). We implemented them by adding additional features during the WL test update or using heterogeneous message passing. It is important to note that they are more theoretically significant than practical since they may require exhaustive enumeration or exact isomorphism encoding of various substructures. We additionally included 16 state-of-the-art GNNs, including NGNN [13], DE+NGNN [29], DS/DSS-GNN [10], SUN [15], SSWL_P [16], GNN-AK [39], KP-GNN [18], I$_2$-GNN [19], PPGN [40], $\\\\delta$-k-LGNN [41], KC-SetGNN [42], GSN [43], DropGNN [44], OSAN [45], and Graphormer [38].\\n\\nTable 2 presents the primary results. $N_2$ achieves the highest accuracy among non-GNNs, and I$_2$-GNN achieves the highest among GNNs. We detail each method's accuracy on different graphs, showing that it matches theoretical results well. Detailed experiment settings are included in Appendix J.\\n\\nNon-GNN baselines. 3-WL successfully distinguishes all Basic graphs, Extension graphs, simple regular graphs and 60 CFI graphs as expected. $S_3$, $S_4$, $N_1$, and $N_2$ demonstrate excellent performance on small-radius graphs such as Basic, Regular, and Extension graphs. However, due to their limited receptive fields, they struggle to distinguish large-radius graphs like CFI graphs. Noting that the\"}"}
{"id": "XfQbPqRPXi", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model                  | Number | Accuracy | Number | Accuracy | Number | Accuracy | Number | Accuracy | Number | Accuracy |\\n|------------------------|--------|----------|--------|----------|--------|----------|--------|----------|--------|----------|\\n| 3-WL                   | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 60     | 60.0%    | 270    | 67.5%    |\\n| SPD-WL                 | 16     | 26.7%    | 14     | 11.7%    | 41     | 41%      | 12     | 12%      | 83     | 20.8%    |\\n| S3                     | 52     | 86.7%    | 48     | 34.3%    | 5      | 5%       | 0      | 0%       | 105    | 26.2%    |\\n| S4                     | 60     | 100%     | 99     | 70.7%    | 84     | 84%      | 0      | 0%       | 243    | 60.8%    |\\n| N1                     | 60     | 100%     | 99     | 85%      | 93     | 93%      | 0      | 0%       | 252    | 63%      |\\n| N2                     | 60     | 100%     | 138    | 98.6%    | 100    | 100%     | 0      | 0%       | 298    | 74.5%    |\\n| M1                     | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 41     | 41%      | 251    | 62.8%    |\\n| NGNN                   | 59     | 98.3%    | 48     | 34.3%    | 59     | 59%      | 0      | 0%       | 166    | 41.5%    |\\n| DE+NGNN                | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 21     | 21%      | 231    | 57.8%    |\\n| DS-GNN                 | 58     | 96.7%    | 48     | 34.3%    | 41     | 41%      | 10     | 10%      | 248    | 62%      |\\n| GNN-AK                 | 60     | 100%     | 50     | 35.7%    | 97     | 97%      | 15     | 15%      | 222    | 55.5%    |\\n| KP-GNN                 | 60     | 100%     | 106    | 75.7%    | 98     | 98%      | 11     | 11%      | 275    | 68.8%    |\\n| I2-GNN                 | 60     | 100%     | 100    | 71.4%    | 100    | 100%     | 21     | 21%      | 281    | 70.2%    |\\n| PPGN                   | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 23     | 23%      | 233    | 58.2%    |\\n| \u03b4-k-LGNN               | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 6      | 6%       | 216    | 54%      |\\n| KC-SetGNN              | 60     | 100%     | 50     | 35.7%    | 100    | 100%     | 1      | 1%       | 211    | 52.8%    |\\n| GSN                    | 60     | 100%     | 99     | 70.7%    | 95     | 95%      | 18     | 18%      | 203    | 50.5%    |\\n\\nExpressiveness of $S_3$ and $S_4$ is bounded by $N_1$ and $N_2$, respectively, as analyzed by Papp and Wattenhofer [17]. Conversely, $M_1$ is implemented by heterogeneous message passing, which makes it unaffected by large graph diameters, thus maintaining its performance across different graphs. SPD-WL is another 1-WL extension operated on a complete graph with shortest path distances as edge features. It may degrade to 1-WL on low-radius graphs, causing its relatively poor performance. Subgraph-based GNNs. Regarding subgraph-based models, they can generally distinguish almost all Basic graphs, simple regular graphs, and Extension graphs. However, an exception lies with NGNN, which performs poorly in Extension graphs due to its simplicial node selection policy and lack of node labeling. Two other exceptions are KP-GNN and I$^2$-GNN, both exhibiting exceptional performance in Regular graphs. KP-GNN can differentiate a substantial number of strongly regular graphs and 4-vertex condition graphs, surpassing the 3-WL partially. And I$^2$-GNN surpasses the limitations of 3-WL partially through its enhanced cycle-counting power. An influential aspect that impacts the performance is the subgraph radius. Approaches incorporating appropriate encoding functions are expected to yield superior performance as the subgraph radius increases. However, in practice, enlarging the radius may result in the smoothness of information, wherein the receptive field expands, encompassing some irrelevant or noisy information. Hence, we treat the subgraph radius as a hyperparameter, fine-tuning it for each model, and present the best results in Table 2. Please refer to Appendix F for further details regarding the radius selection. When comparing various subgraph GNNs, KP-GNN can discriminate part of the strongly regular graphs by peripheral subgraphs. Additionally, distance encoding in DE+NGNN and I$^2$-GNN enables better discrimination among different hops within a given subgraph radius, enhancing the discriminative ability, particularly in larger subgraph radii. As for DS-GNN, DSS-GNN, GNN-AK, SUN and SSWL_P, they employ similar aggregation schemes with slight variations in their operations. These models exhibit comparable performance, with SSWL_P outperforming others, which aligns with expectations since SSWL_P is more expressive but with the least components. \\\\(k\\\\)-WL hierarchy-based GNNs. For the \\\\(k\\\\)-WL-hierarchy-based models, we adopt two implemented approaches: high-order simulation and local-WL simulation. PPGN serves as the representative work for the former, while \\\\(\\\\delta\\\\)-\\\\(k\\\\)-LGNN and KCSet-GNN embody the latter. PPGN aligns its performance with 3-WL across all graphs except for CFI graphs. For CFI graphs with large radii, more WL iterations (layers of GNNs) are required. However, employing many layers may lead to over-smoothing, resulting in a gap between theoretical expectations and actual performance. Nonetheless, PPGN still surpasses most GNNs in CFI graphs due to global \\\\(k\\\\)-WL's global receptive field. For \\\\(\\\\delta\\\\)-\\\\(k\\\\)-LGNN, we set \\\\(k=2\\\\), while for KCSet-GNN, we set \\\\(k=3\\\\), adhering to the original configuration. By comparing the output results with relatively small diameters, we observed that local WL matches the performance of general \\\\(k\\\\)-WL. However, local WL exhibits lower performance for CFI graphs with larger radii due to insufficient receptive fields.\"}"}
{"id": "XfQbPqRPXi", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Substructure-based GNNs\\n\\nFor substructure-based GNNs, we select GSN, which incorporate substructure isomorphism counting as features. The best result obtained for GSN-e is reported when setting $k = 4$. For further exploration of policy and size, please refer to Appendix H.\\n\\nRandom GNNs\\n\\nRandom GNNs are unsuitable for GI problems since even identical graphs can yield different outcomes due to inherent randomness. However, the RPC can quantify fluctuations in the randomization process, thereby enabling the testing of random GNNs. We test DropGNN and OSAN. For more information regarding the crucial factor of random samples, please refer to Appendix I.\\n\\nTransformer-based GNNs\\n\\nFor transformer-based GNNs, we select graphormer, which is anticipated to possess a level of expressiveness comparable to SPD-WL. The experimental results verify that.\\n\\nConclusion and Future Work\\n\\nThis paper proposes a new dataset, BREC, for GNN expressiveness comparison. BREC addresses the limitations of previous datasets, including difficulty, granularity, and scale, by incorporating 400 pairs of diverse graphs in four categories. A new evaluation method is proposed for principled expressiveness evaluation. Finally, a thorough comparison of 23 baselines on BREC is conducted. Apart from the expressiveness comparison based on GI, there are various other metrics for GNN expressiveness evaluation, such as substructure counting, diameter counting, and biconnectivity checking. However, it's worth noting that these tests are often conducted on datasets not specifically designed for expressiveness [19, 39, 46], which can lead to biased results caused by spurious correlations. In other words, certain methods may struggle to identify a particular substructure, but they can capture another property that correlates with substructures, resulting in false high performance. This problem can be alleviated in BREC because of the difficulty. We reveal the data generation process of BREC in Appendix K, hoping that researchers can utilize them in more tasks. We also hope the test of practical expressiveness will aid researchers in exploring its effects on performance in real datasets and other domains.\\n\\nReferences\\n\\n[1] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. Advances in neural information processing systems, 28, 2015.\\n[2] Albert-L\u00e1szl\u00f3 Barab\u00e1si, Natali Gulbahce, and Joseph Loscalzo. Network medicine: a network-based approach to human disease. Nature reviews genetics, 12(1):56\u201368, 2011.\\n[3] Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. Graph neural networks for social recommendation. In The world wide web conference, pages 417\u2013426, 2019.\\n[4] Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo. Ripplenet: Propagating user preferences on the knowledge graph for recommender systems. In Proceedings of the 27th ACM international conference on information and knowledge management, pages 417\u2013426, 2018.\\n[5] Rianne van den Berg, Thomas N Kipf, and Max Welling. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263, 2017.\\n[6] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. Graph neural networks: A review of methods and applications. AI open, 1:57\u201381, 2020.\\n[7] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, Conference Track Proceedings. OpenReview.net, 2019.\\n[8] Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. Weisfeiler and leman go neural: Higher-order graph neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 4602\u20134609, 2019.\"}"}
{"id": "XfQbPqRPXi", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Muhammet Balcilar, Pierre H\u00e9roux, Benoit Gauzere, Pascal Vasseur, S\u00e9bastien Adam, and Paul Honeine. Breaking the limits of message passing graph neural networks. In International Conference on Machine Learning, pages 599\u2013608. PMLR, 2021.\\n\\nBeatrice Bevilacqua, Fabrizio Frasca, Derek Lim, Balasubramaniam Srinivasan, Chen Cai, Gopinath Balamurugan, Michael M. Bronstein, and Haggai Maron. Equivariant subgraph aggregation networks. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id=dFbKQaRk15w.\\n\\nLeonardo Cotta, Christopher Morris, and Bruno Ribeiro. Reconstruction for powerful graph representations. Advances in Neural Information Processing Systems, 34:1713\u20131726, 2021.\\n\\nJiaxuan You, Jonathan M Gomes-Selman, Rex Ying, and Jure Leskovec. Identity-aware graph neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 10737\u201310745, 2021.\\n\\nMuhan Zhang and Pan Li. Nested graph neural networks. Advances in Neural Information Processing Systems, 34:15734\u201315747, 2021.\\n\\nHaggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph networks. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. URL https://openreview.net/forum?id=Syx72jC9tm.\\n\\nFabrizio Frasca, Beatrice Bevilacqua, Michael Bronstein, and Haggai Maron. Understanding and extending subgraph gnns by rethinking their symmetries. Advances in Neural Information Processing Systems, 35:31376\u201331390, 2022.\\n\\nBohang Zhang, Guhao Feng, Yiheng Du, Di He, and Liwei Wang. A complete expressiveness hierarchy for subgraph GNNs via subgraph weisfeiler-lehman tests. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 41019\u201341077. PMLR, 23\u201329 Jul 2023. URL https://proceedings.mlr.press/v202/zhang23k.html.\\n\\nP\u00e1l Andr\u00e1s Papp and Roger Wattenhofer. A theoretical comparison of graph neural network extensions. In International Conference on Machine Learning, pages 17323\u201317345. PMLR, 2022.\\n\\nJiarui Feng, Yixin Chen, Fuhai Li, Anindya Sarkar, and Muhan Zhang. How powerful are k-hop message passing graph neural networks. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=nN3aVRQsxGd.\\n\\nYinan Huang, Xingang Peng, Jianzhu Ma, and Muhan Zhang. Boosting the cycle counting power of graph neural networks with i$\\\\hat{2}$-gnns. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/pdf?id=kDSmxOspsXQ.\\n\\nBohang Zhang, Shengjie Luo, Liwei Wang, and Di He. Rethinking the expressive power of gnns via graph biconnectivity. In The Eleventh International Conference on Learning Representations, 2023.\\n\\nRalph Abboud, \u02d9Ismail \u02d9Ilkan Ceylan, Martin Grohe, and Thomas Lukasiewicz. The surprising power of graph neural networks with random node initialization. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, pages 2112\u20132118. ijcai.org, 2021. doi: 10.24963/ijcai.2021/291. URL https://doi.org/10.24963/ijcai.2021/291.\\n\\nRyan Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Relational pooling for graph representations. In International Conference on Machine Learning, pages 4663\u20134673. PMLR, 2019.\"}"}
{"id": "XfQbPqRPXi", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "XfQbPqRPXi", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Christopher Morris, Gaurav Rattan, and Petra Mutzel. Weisfeiler and leman go sparse: Towards scalable higher-order graph embeddings. Advances in Neural Information Processing Systems, 33:21824\u201321840, 2020.\\n\\nLingxiao Zhao, Neil Shah, and Leman Akoglu. A practical, progressively-expressive gnn. Advances in Neural Information Processing Systems, 35:34106\u201334120, 2022.\\n\\nGiorgos Bouritsas, Fabrizio Frasca, Stefanos Zafeiriou, and Michael M Bronstein. Improving graph neural network expressivity via subgraph isomorphism counting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(1):657\u2013668, 2022.\\n\\nP\u00e1l Andr\u00e1s Papp, Karolis Martinkus, Lukas Faber, and Roger Wattenhofer. Dropgnn: Random dropouts increase the expressiveness of graph neural networks. Advances in Neural Information Processing Systems, 34:21997\u201322009, 2021.\\n\\nChendi Qian, Gaurav Rattan, Floris Geerts, Mathias Niepert, and Christopher Morris. Ordered subgraph aggregation networks. Advances in Neural Information Processing Systems, 35:21030\u201321045, 2022.\\n\\nZhengdao Chen, Lei Chen, Soledad Villar, and Joan Bruna. Can graph neural networks count substructures? Advances in neural information processing systems, 33:10383\u201310395, 2020.\\n\\nL\u00e1szl\u00f3 Babai and Ludik Kucera. Canonical labelling of graphs in linear average time. In 20th Annual Symposium on Foundations of Computer Science (sfcs 1979), pages 39\u201346. IEEE, 1979.\\n\\nRyoma Sato. A survey on the expressive power of graph neural networks. arXiv preprint arXiv:2003.04078, 2020.\\n\\nNingyuan Teresa Huang and Soledad Villar. A short tutorial on the weisfeiler-lehman test and its variants. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 8533\u20138537. IEEE, 2021.\\n\\nChecklist\\n1. For all authors...\\n   (a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] We elucidate the constraints inherent in prior datasets pertaining to expressiveness and present a novel dataset along with comprehensive experiments.\\n   (b) Did you describe the limitations of your work? [Yes] We refer to alternative metrics for assessing expressiveness and welcome additional experiments on our foundational dataset (shown in Section 6).\\n   (c) Did you discuss any potential negative societal impacts of your work? [N/A] All data points are synthetic.\\n   (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\\n\\n2. If you are including theoretical results...\\n   (a) Did you state the full set of assumptions of all theoretical results? [Yes] Please refer to assumption 4.1.\\n   (b) Did you include complete proofs of all theoretical results? [Yes] Please refer to proof E.\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n   (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] Please refer to https://github.com/GraphPKU/BREC\\n   (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] Please refer to Appendix J.\"}"}
{"id": "XfQbPqRPXi", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\n\\n(b) Did you mention the license of the assets? [Yes] All assets were openly accessible, and the licenses for each asset were retained in the corresponding repositories. For more details, please refer to https://github.com/GraphPKU/BREC.\\n\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes] Please refer to https://github.com/GraphPKU/BREC.\\n\\n(d) Did you discuss whether and how consent was obtained from people whose data you\u2019re using/curating? [N/A] All assets were openly accessible.\\n\\n(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A] All data points are synthetic.\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n\\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] No utilization of crowdsourcing or engagement in research with human subjects took place.\\n\\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A] No utilization of crowdsourcing or engagement in research with human subjects took place.\\n\\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A] No utilization of crowdsourcing or engagement in research with human subjects took place.\"}"}
