{"id": "DFr5hteojx", "page_num": 97, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| VARIABLE | LABEL | CATEGORY | TYPE |\\n|----------|-------|----------|------|\\n| user_id  | Unique participant identifier | meta | string |\\n|          |       |          |      |\\n| survey_only | Indicator if participant only completed the survey, or also completed conversations | meta | binary |\\n|          |       |          |      |\\n| num_completed_conversations | Number of conversations that a participant completed | meta | int |\\n|          |       |          |      |\\n| consent  | Participant informed consent confirmation | direct | categorical |\\n|          |       |          |      |\\n| consent_age | Participant age confirmation | direct | categorical |\\n|          |       |          |      |\\n| lm_familiarity | Familiarity with LLMs | direct | categorical |\\n|          |       |          |      |\\n| lm_direct_use | Direct use of LLMs | direct | categorical |\\n|          |       |          |      |\\n| lm_indirect_use | Direct use of LLMs | direct | categorical |\\n|          |       |          |      |\\n| lm_frequency_use | Frequency of using Large Language Models | direct | categorical |\\n|          |       |          |      |\\n| lm_usecases | Use cases of LLMs | direct | dict |\\n|          |       |          |      |\\n\\nNotes:\\n- Pseudonymized from Prolific worker ID. Used to link survey data to conversation data. In our paper, we refer to 'users' as 'participants'.\\n- See full informed consent document for details.\"}"}
{"id": "DFr5hteojx", "page_num": 98, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Use Case                                           | True | False |\\n|---------------------------------------------------|------|-------|\\n| Homework Assistance                               | 533  | 853   |\\n| Research                                          | 864  | 636   |\\n| Source Suggestions                                | 464  | 1036  |\\n| Professional Work                                 | 716  | 784   |\\n| Creative Writing                                  | 639  | 861   |\\n| Casual Conversation                               | 509  | 991   |\\n| Personal Recommendations                          | 513  | 987   |\\n| Daily Productivity                                | 463  | 1037  |\\n| Technical or Programming Help                     | 584  | 916   |\\n| Travel Guidance                                   | 380  | 1120  |\\n| Lifestyle and Hobbies                             | 557  | 943   |\\n| Well-being Guidance                               | 406  | 1094  |\\n| Medical Guidance                                  | 377  | 1123  |\\n| Financial Guidance                                | 354  | 1146  |\\n| Games                                             | 390  | 1110  |\\n| Historical or News Insight                        | 430  | 1070  |\\n| Relationship Advice                               | 345  | 1155  |\\n| Language Learning                                 | 476  | 1024  |\\n| Other                                              | 371  | 1129  |\\n\\nNotes: Question only show if \\\\( \\\\text{lm\\\\_direct\\\\_use}==1 \\\\) OR \\\\( \\\\text{lm\\\\_indirect\\\\_use}==1 \\\\). N Missing indicates the participants who have at least one missing value in the usecases (besides from 'other_text'). N Unique indicates the unique combinations of use cases selected by participants. On 'other_text', Null indicates participant did not type anything. On all other keys, 0 indicates participant saw question and did not select usecase. Null indicates participant did not see question.\"}"}
{"id": "DFr5hteojx", "page_num": 99, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"| Variable Label | Category | Type |\\n|----------------|----------|------|\\n| reflects my values or cultural perspectives | creativity | mean 54.3, std 26.3, min 0.0, max 100.0 |\\n| produces responses that are creative and inspiring | fluency | mean 69.6, std 22.1, min 0.0, max 100.0 |\\n| produces responses that are well-written and coherent | factuality | mean 86.7, std 16.3, min 2.0, max 100.0 |\\n| produces factual and informative responses | diversity | mean 75.7, std 20.0, min 0.0, max 100.0 |\\n| produces responses that are safe and do not risk harm to myself and others | safety | mean 80.2, std 25.2, min 0.0, max 100.0 |\\n| learns from our conversations and feels personalised to me | personalisation | mean 67.9, std 24.6, min 0.0, max 100.0 |\\n| produces responses that are helpful and relevant to my requests | helpfulness | mean 89.4, std 14.4, min 0.0, max 100.0 |\\n| Other (selected) | other | mean 57.5, std 19.0, min 0.0, max 100.0 |\\n| Other (typed text) | other_text | mean chars 32.6, std chars 24.4, min chars 1.0, max chars 144.0 |\\n\\nNotes: Sliders from [Strongly disagree] to [Strongly agree] are recorded on a 0-100 scale. Participant does not see numeric value. N Missing indicates the participants who have at least one missing value in the attributes (besides from 'other_text'). N Unique indicates the unique combinations of use cases selected by participants. On 'other_text', Null indicates participant did not type anything. Note that this scale (on Qualtrics) runs 0-100. The Conversations rating scales (for choice_attributes, performance_attributes on Dynabench) run 1-100.\\n\\n12 order_stated_prefs Stated preferences over LLM behaviours (order of options presented in survey)\\n\\nNotes: Integer 1-8 indicating random order that attribute slider was presented to participant. For 'other', option is always shown last so will always be 9. Null indicates participant did not see question. The attributes as the same as in stated_prefs.\\n\\n13 self_description Participant self-written profile describing themself\\n\\nQuestion text: Please briefly describe your values, core beliefs, guiding principles in life, or other things that are important to you. For example, you might include values you\u2019d want to teach to your children or qualities you look for in friends. There are no right or wrong answers. Please do not provide any personally identifiable details like your name, address or email. Please write 2-5 sentences in your own words.\\n\\nNotes: N Missing: 0, N Unique: 1500, mean chars 241.3, std chars 134.6, min chars 3.0, max chars 1547.0\\n\\n14 system_string Participant self-written system string, constitution or custom instructions for an LLM\\n\\nQuestion text: Imagine you are instructing an AI language model how to behave. You can think of this like a set of core principles that the AI language model will always try to follow, no matter what task you ask it to perform. In your own words, describe what characteristics, personality traits or features you believe the AI should consistently exhibit. You can also instruct the model what behaviours or content you don\u2019t want to see. If you envision the AI behaving differently in various contexts (e.g., professional assistance vs. storytelling), please specify the general adaptations you\u2019d like to see. Please write 2-5 sentences in your own words.\\n\\nNotes: N Missing: 0, N Unique: 1500, mean chars 260.4, std chars 288.4, min chars 16.0, max chars 1547.0\"}"}
{"id": "DFr5hteojx", "page_num": 100, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable Label | Category | Type | Question Text | N Missing | N Unique |\\n|----------------|----------|------|---------------|-----------|----------|\\n| age            | direct   | categorical | How old are you? | 0 | 7 |\\n| education      | direct   | categorical | What is the highest level of education you have completed? | 0 | 9 |\\n| employment_status | direct | categorical | What best describes your employment status over the last three months? | 0 | 8 |\\n| marital_status | direct   | categorical | What is your current marital status? | 0 | 5 |\\n| english_proficiency | direct | categorical | How would you describe your proficiency in English? | 0 | 5 |\\n| gender         | constructed | categorical | How would you describe your proficiency in English? | 0 | 4 |\\n\\nNotes: Participants could choose Male, Female, Non-binary / third Gender, Prefer not to say, or write in their own response. Two independent annotators then categorised the self-describe responses only when abundantly clear they fit another category. See paper for details.\\n\\n| religion | Dictionary of religion information | NA |\\n|----------|-----------------------------------|-----|\\n| religion_self_described | Participant self-description | direct |\\n| religion_categorised | Granular categories of participant religion | constructed |\\n\\nNotes: Participant had option to type and Self Describe or select Prefer not to say.\"}"}
{"id": "DFr5hteojx", "page_num": 101, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"| Category                        | Count |\\n|--------------------------------|-------|\\n| Non-religious                  | 762   |\\n| Christian                      | 487   |\\n| Agnostic                       | 71    |\\n| Prefer not to say              | 59    |\\n| Jewish                         | 42    |\\n| Muslim                         | 31    |\\n| Spiritual                      | 18    |\\n| Buddhist                       | 12    |\\n| Folk religion                  | 6     |\\n| Hindu                          | 5     |\\n| Other                          | 4     |\\n| Sikh                           | 3     |\\n\\nNotes: Two independent annotators manually verified all automated classifications (gpt-4-turbo) of the self-describe string. See paper for details.\\n\\n| Category                        | Count |\\n|--------------------------------|-------|\\n| Non-affiliation                 | 851   |\\n| Christian                       | 487   |\\n| Prefer not to say               | 59    |\\n| Jewish                         | 42    |\\n| Muslim                         | 31    |\\n| Other                          | 30    |\\n\\nNotes: Simplified version of religion_categorised for more aggregate analysis.\\n\\n| Category                        | Count |\\n|--------------------------------|-------|\\n| White                          | 969   |\\n| Black / African                 | 122   |\\n| Hispanic / Latino               | 121   |\\n| Asian                          | 95    |\\n| Prefer not to say               | 86    |\\n| Mixed                          | 68    |\\n| Other                          | 17    |\\n| Middle Eastern / Arab           | 14    |\\n| Indigenous / First Peoples      | 8     |\\n\\nNotes: Two independent annotators manually verified all automated classifications (gpt-4-turbo) of the self-describe string. See paper for details.\\n\\n| Category                        | Count |\\n|--------------------------------|-------|\\n| White                          | 969   |\\n| Black                          | 122   |\\n| Hispanic                       | 121   |\\n| Asian                          | 95    |\\n| Prefer not to say               | 86    |\\n| Mixed                          | 68    |\\n| Other                          | 39    |\\n\\nNotes: Simplified version of ethnicity_categorised for more aggregate analysis.\\n\\n| Category                        | Count |\\n|--------------------------------|-------|\\n| Participant country of birth    |       |\\n|                                |       |\\n| Too many values to show         |       |\\n\\nNotes: Selected from standardised dropdown country list.\\n\\n| Category                        | Count |\\n|--------------------------------|-------|\\n| Participant country of birth ISO|       |\\n|                                |       |\\n| Too many values to show         |       |\\n\\nNotes: Mapped from country of birth, based on United Nations defined subregions.\"}"}
{"id": "DFr5hteojx", "page_num": 102, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable                  | Label                     | Category   | Type   | Notes                                                                 |\\n|---------------------------|---------------------------|------------|--------|----------------------------------------------------------------------|\\n| location_reside_country   | Participant country of residence | direct     | categorical | Selected from standardised dropdown country list.                      |\\n| location_reside_countryISO| ISO 3166-1 alpha-3 code for the country of residence | constructed | categorical | N Missing: 0  \\nN Unique: 38  \\nToo many values to show - |\\n| location_reside_subregion | Participant sub-region of residence | constructed | categorical | N Missing: 0  \\nN Unique: 11  \\nToo many values to show - |\\n| location_same_birth_reside_country | Whether the participant was born and resides in the same country | constructed | binary | N Missing: 0  \\nN Unique: 3  \\nYes: 1320  \\nNo: 177  \\nPrefer not to say: 3 |\\n| location_special_region   | Adjusted regional categories for unique sample properties | constructed | categorical | N Missing: 0  \\nN Unique: 11  \\nUS: 338  \\nEurope: 313  \\nUK: 292  \\nLatin America and the Caribbean: 146  \\nAustralia and New Zealand: 129  \\nAfrica: 118  \\nAsia: 60  \\nNorthern America: 50  \\nMiddle East: 50  \\nPrefer not to say: 3  \\nNotes: Within regions and sub-regions, some countries are split out to better represent sample density (e.g., treating UK and US samples separately from Europe and North America). |\\n| study_id                  | Unique study identifier on Prolific | meta       | string id | N Missing: 0  \\nN Unique: 51 |\\n| study_locale              | Recruitment country of Prolific study | meta       | categorical | N Missing: 0  \\nN Unique: 33  \\nToo many values to show - |\\n| generated_datetime        | Recorded date of the survey completion | meta       | datetime | N Missing: 0  \\nN Unique: 1492  \\nearliest date: 2023-11-22 15:48:46  \\nlatest date: 2023-12-22 06:56:27  \\nNotes: End time, not start time |\\n| timing_duration_s         | Duration of the survey session (in seconds) | meta       | float | N Missing: 0  \\nN Unique: 977  \\nmean: 2154.2  \\nstd: 20557.1  \\nmin: 160.0  \\nmax: 529927.0  \\nNotes: Extreme values are caused by participants completing task in multiple sessions. |\\n| timing_duration_mins      | Duration of the survey session (in minutes) | constructed | float | N Missing: 0  \\nN Unique: 977  \\nmean: 35.9  \\nstd: 342.6  \\nmin: 2.7  \\nmax: 8832.1  \\nNotes: timing_duration_s / 60. Extreme values are caused by participants completing task in multiple sessions. |\\n| included_in_UK_REP        | Indicator if participant was included in the rebalanced UK representative sample | constructed | binary | N Missing: 0  \\nN Unique: 2  \\nFalse: 1257  \\nTrue: 243  \\nNotes: Census-representative samples were rebalanced to mitigate sampling issues. See paper for details. |\"}"}
{"id": "DFr5hteojx", "page_num": 103, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable Label | Category | Type |\\n|----------------|----------|------|\\n| 44 included_in_US_REP | Indicator if participant was included in the rebalanced US representative sample | constructed | binary |\\n| N Missing: 0 | N Unique: 2 | False: 1270 | True: 230 |\\n| Notes: Census-representative samples were rebalanced to mitigate sampling issues. See paper for details. |\\n| 45 included_in_balanced_subset | Indicator if participant's conversations are included in the balanced subset | constructed | binary |\\n| N Missing: 0 | N Unique: 2 | True: 1246 | False: 254 |\\n| Notes: Balanced subset was created to equally sample conversations of three types (unguided, values, controversy). We only include participants who have at least one of each conversation type, and then ensure equal numbers of each type are retained. See paper for details. |\"}"}
{"id": "DFr5hteojx", "page_num": 104, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| VARIABLE LABEL CATEGORY | TYPE |\\n|-------------------------|------|\\n| user_id | Unique participant identifier | string |\\n| conversation_id | Unique conversation identifier | string |\\n| opening_prompt | Opening human-written prompt of the conversation | string |\\n| open_feedback | Participant written feedback on the conversation as a whole. | string |\\n| conversation_type | Type of conversation (from pre-defined categories) | categorical |\\n| conversation_turns | Number of human-model turns (back-and-forths) in the conversation. | int |\\n| conversation_history | Full conversation history (human and model messages, with scores and model metadata) | dict |\\n| performance_attributes | How well the top-rated model response performed across different attributes | nested |\\n\\n**Notes:**\\n- Pseudonymized from Prolific worker ID. Used to link conversation data to survey data.\\n- We provide the following soft guidance: Need some inspiration? You can request help with a task (like writing a recipe, organising an activity or event, completing an assignment)... You can chitchat, have casual conversation or seek personal advice. You can ask questions about the world, current events or your viewpoints.\\n- Participants pick from the following radio buttons: Unguided. Ask, request or talk to the model about anything. It is up to you! Values guided. Ask, request or talk to the model about something important to you or that represents your values. This could be related to work, religion, family and relationship, politics or culture. Controversy guided. Ask, request or talk to the model about something controversial or where people would disagree in your community, culture or country. We also provide the additional instruction: Remember if you are here as a paid study participant, you need to do two of each type. If you are here as a volunteer, then take your pick!\\n- We force 2 turns as the minimum. After the opening turn, we give the instruction: Now continue the conversation. Conversations can be between 2 and 10 turns. Try to vary the length. When you're done, click Finish.\\n- We provide an example of what this nested conversation history looks like below.\\n\\n**Questions:**\\n- Choose what type of conversation you want to have.\\n- Give the model some feedback on the conversation as whole. Hypothetically, what would an ideal interaction for you look like here? What was good and what was bad? What (if anything) was missing? What would you change to make the conversation better? Please write 2-5 sentences in your own words.\\n- Tell us how the model performed. Consider your first message and the top-rated response. Rate the following statements about the performance across different attributes. This response...\\n  - reflected my values or cultural perspective\\n  - was well-written and coherent\\n  - was factual and informative\\n\\n**Statistics:**\\n- Mean and standard deviation for various attributes.\\n- Minimum and maximum values for various attributes.\\n\\n**Example of conversation history:**\\n```\\n[Conversation Start]\\n\\nHuman: Hello!\\n\\nModel: Hi there!\\n\\nHuman: How are you?\\n\\nModel: I'm doing well, thanks. How about you?\\n\\nHuman: I'm good too. I'm just looking forward to the weekend.\\n\\nModel: That sounds nice. What are you planning on doing?\\n\\nHuman: I'm going to catch up on some reading and maybe work on a project.\\n\\nModel: Sound like a good plan. Have a great weekend!\\n\\n[Conversation End]\\n```\"}"}
{"id": "DFr5hteojx", "page_num": 105, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Attribute               | Mean | Std  | Min  | Max  |\\n|-------------------------|------|------|------|------|\\n| Safety                  | 72.1 | 27.8 | 1.0  | 100.0|\\n| Diversity               | 66.0 | 26.5 | 1.0  | 100.0|\\n| Creativity              | 62.1 | 27.1 | 1.0  | 100.0|\\n| Helpfulness             | 82.5 | 20.0 | 1.0  | 100.0|\\n| Fluency                 | 82.5 | 18.5 | 1.0  | 100.0|\\n| Factuality              | 79.3 | 21.0 | 1.0  | 100.0|\\n| Values                  | 66.9 | 27.2 | 1.0  | 100.0|\\n| Direct                  |       |      |      |      |\\n| Dict                    |       |      |      |      |\\n\\nNotes: Sliders from [Very unimportant] to [Very important] are recorded on a 1-100 scale. Participant does not see numeric value. Note that the attributes align with performance_attributes, as well as the stated preference ratings from The Survey. Participants had option to select N/A, which is recorded as Null. num_missing indicates the number of participants who have at least one missing value in the nested columns. num_unique indicates the unique combinations of use cases selected by participants. There was no option for 'other'. Note, these sliders run from 1-100 (on Dynabench). The sliders for stated_prefs (in Survey on Qualtrics) run 0-100.\\n\\n9 generated_datetime Recorded date of the conversation completion\\n\\n10 timing_duration_s Duration of the conversation (in seconds)\"}"}
{"id": "DFr5hteojx", "page_num": 106, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable Label | Category | Type | N Unique | mean | std  | min  | max   | Notes                                                                 |\\n|----------------|----------|------|----------|------|------|------|-------|----------------------------------------------------------------------|\\n| 11 timing_duration_mins | | | | | | | | Duration of the conversation (in minutes) | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |"}
{"id": "DFr5hteojx", "page_num": 107, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable | Description                                                                 | Notes                                                                 |\\n|----------|-----------------------------------------------------------------------------|----------------------------------------------------------------------|\\n| user_id  | Unique participant identifier                                               | Pseudonymized from Prolific worker ID. Used to link utterance data to survey data. |\\n| conversation_id | Unique conversation identifier                                         | Used to link utterance data to conversation data.                        |\\n| interaction_id | Unique interaction identifier, where an interaction is a turn within a conversation (single human message with multiple model responses) | |\\n| utterance_id | Unique utterance identifier, where an utterance is a single human message - single model response pair | |\\n| within_turn_id | Within turn identifier of up to four model responses to a single human message | Order is random, not based on score or presentation in interface |\\n| conversation_type | Type of conversation (from pre-defined categories) | Participants pick from the following radio buttons: Unguided. Ask, request or talk to the model about anything. It is up to you! Values guided. Ask, request or talk to the model about something important to you or that represents your values. This could be related to work, religion, family and relationship, politics or culture. Controversy guided. Ask, request or talk to the model about something controversial or where people would disagree in your community, culture or country. We also provide the additional instruction: Remember if you are here as a paid study participant, you need to do two of each type. If you are here as a volunteer, then take your pick! |\\n| turn | Turn of conversation when prompt was entered | In the paper, we refer to the first turn as T=1. Here, we index the first turn as 0. |\\n| model_name | Name of LLM                                                               | We provide the long name as it appeared on our backend. We provide a mapping of long names to shorter more familiar names on our Github or in the paper. |\\n| model_provider | Provider of the LLM                                                       | |\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 108, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable Label | Category | Type |\\n|----------------|----------|------|\\n| Notes: Note for open-access LLMs, HuggingFace API is always listed as the source and does not imply they built the model. |\\n| 9 user_prompt | Human-written message | direct | string |\\n| N Missing: 0 | N Unique: 26673 | mean chars 69.9 | std chars 62.0 | min chars 1.0 | max chars 1311.0 |\\n| Notes: An empty string is stored as 'EMPTY STRING'. |\\n| 10 model_response | Model-generated response | direct | string |\\n| N Missing: 0 | N Unique: 66614 | mean chars 565.3 | std chars 387.9 | min chars 1.0 | max chars 4630.0 |\\n| Notes: Sliders from [Terrible] to [Perfect] are recorded on a 1-100 scale. Participant does not see numeric value. |\\n| 11 score | Score of the model response | direct | int |\\n| N Missing: 0 | N Unique: 100 | mean 65.1 | std 29.3 | min 1.0 | max 100.0 |\\n| Notes: Sliders from [Terrible] to [Perfect] are recorded on a 1-100 scale. Participant does not see numeric value. |\\n| 12 if_chosen | Whether model response was highest-rated by participant | constructed | binary |\\n| N Missing: 0 | N Unique: 2 | False 40934 | True 27437 |\\n| Notes: In case of a tie, a random response is chosen. |\\n| 13 included_in_balanced_subset | Indicator if participant's conversations are included in the balanced subset | constructed | binary |\\n| N Missing: 0 | N Unique: 2 | True 57401 | False 10970 |\\n| Notes: Balanced subset was created to equally sample conversations of three types (unguided, values, controversy). We only include participants who have at least one of each conversation type, and then ensure equal numbers of each type are retained. See paper for details. |\"}"}
{"id": "DFr5hteojx", "page_num": 109, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Variable | Label                                      | Category       | Type     | Missing | Unique          |\\n|----------|--------------------------------------------|----------------|----------|----------|-----------------|\\n| column_id | Source of text utterance                   | meta           | categorical | 0        | 5               |\\n|          |                                            |                |          |          |                 |\\n|          | model_response                             |                |          |          | 68371           |\\n|          | user_prompt                                |                |          |          | 27172           |\\n|          | open_feedback                              |                |          |          | 8011            |\\n|          | self_description                           |                |          |          | 1500            |\\n|          | system_string                              |                |          |          | 1500            |\\n| user_id  | Unique participant identifier              | meta           | string id | 0        | 1500            |\\n|          |                                            |                |          |          |                 |\\n|          | Notes: Pseudonymized from Prolific worker ID. Used to link metadata to main data. |                |          |          |                 |\\n| conversation_id | Unique conversation identifier | meta           | string id | 3000    | 8011            |\\n|          |                                            |                |          |          |                 |\\n|          | Notes: Used to link metadata to main data. |                |          |          |                 |\\n| interaction_id | Unique interaction identifier, where an interaction is a turn within a conversation (single human message with multiple model responses) | meta           | string id | 11011 | 27172          |\\n|          |                                            |                |          |          |                 |\\n|          | Notes: Used to link metadata to main data. |                |          |          |                 |\\n| utterance_id | Unique utterance identifier, where an utterance is a single human message - single model response pair | meta           | string id | 38183 | 68371          |\\n|          |                                            |                |          |          |                 |\\n|          | Notes: Used to link metadata to main data. |                |          |          |                 |\\n| pii_flag | Automated flag for personally identifiable information | meta           | binary   | 0        | 2               |\\n|          |                                            |                |          |          |                 |\\n|          | False 105443                               |                |          |          |                 |\\n|          | True 1111                                  |                |          |          |                 |\\n|          | Notes: Uses scrubadub https://scrubadub.readthedocs.io/en/stable/ to find PII. There may be some misclassifications. Many of the inspected positives were false positives. All positive human-written texts checked. See pii_manual_flag. |                |          |          |                 |\\n| pii_manual_flag | Manual verification of personally identifiable information in human-written texts | meta           | binary   | 106387  | 1               |\\n|          |                                            |                |          |          |                 |\\n|          | nan 106387                                 |                |          |          |                 |\\n|          | 0.0 167                                    |                |          |          |                 |\\n|          | Notes: For any automated PII flags, we manually checked the human-written text for PII. All were false positives so this flag overrules the automated flag. We did not check model-generated text for PII. NaN indicates entry was not manually checked. |                |          |          |                 |\\n| language_flag | Automated language detection | meta           | categorical | 0        | 59             |\\n|          |                                            |                |          |          |                 |\\n|          | Notes: Uses langid. There may be some misclassifications. |                |          |          |                 |\\n| en_flag | Whether detected language is English | meta           | binary   | 0        | 2             |\\n|          |                                            |                |          |          |                 |\\n|          | Too many values to show -                  |                |          |          |                 |\\n|          | Notes: Constructed based on automated language detection. |                |          |          |                 |\\n| moderation_flag | Automated flag for moderation | meta nested dict |          |          |                  |\\n|          |                                            |                |          |          |                  |\\n|          | Notes: Uses OpenAI moderation API. There may be some misclassifications. Nested dictionary with binary flags and probabilities for sub-categories of harm. |                |          |          |                  |\"}"}
{"id": "DFr5hteojx", "page_num": 81, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 24: Field sites of empirically fixed dialogue contexts.\\n\\nIf a neighbourhood of semantically-similar participant prompts intersects with a neighbourhood of semantically-similar model responses, we consider this a field site. We present summary statistics over these collections of \u2018fixed\u2019 dialogue contexts, demonstrating that there is still substantial differences in score.\\n\\n| Field Sites | Neighbourhood Size (K) | Unique Participants | Unique Models | Unique Model Providers | Score Range |\\n|-------------|-------------------------|---------------------|---------------|------------------------|-------------|\\n|             | mean                    | std                 | min           | max                    | mean        | std |\\n| 124         | 3.6                     | 5.6                 | 2             | 56                     | 36.3        | 26.5 |\\n| 443         | 4.0                     | 5.3                 | 2             | 84                     | 40.1        | 26.5 |\\n| 791         | 5.4                     | 8.5                 | 2             | 149                    | 47.4        | 29.3 |\\n\\nS.5 Exact Prompt-Response Pairs with Multiple Ratings\\n\\nBefore, we defined a field site as prompt-response pairs falling within some (strict) cosine threshold neighbourhood. Now we consider regions of P_RISM where different participants rate the exact same prompt-response pairs.\\n\\nDifferent participants rating the same pair\\n\\nWe find 40 field sites where at least two participants rate the same prompt-response pair. Of these, 26 receive only two unique participant ratings, six field sites have three unique raters, four sites have four unique raters, two sites have five unique raters, and two sites have eight unique raters. We provide examples in Tab. 25. Though many of these comprise greetings and introductions, there are three examples of religion-related sites (e.g. \u201cdoes god exist\u201d). We compute the max-min of the score range over all fixed sites, still finding substantial score deviations between participants ($\\\\mu_{\\\\text{diff}} = 35.4$, $\\\\sigma_{\\\\text{diff}} = 31.7$, see Fig. 29).\\n\\nThe same participant rating the same pair\\n\\nThere are 44 field sites where the same participant rates a duplicate prompt-response pair. This occurs when a participant\u2019s prompt receives two or more identical model responses, usually from the same model family e.g. (claude-2.1, claude-2) or (gpt-4, gpt-4-turbo). We provide examples in Tab. 25. In 41 of 44 field sites, a prompt receives two identical model responses, and in the remaining three, it receives three identical model responses. There are 42 unique participants who appear in this subset. Of the two participants who appear twice, one is \u2018unlucky\u2019: two very distinct prompts are met with duplicate responses (\u201cCan you tell me a joke about cats\u201d, \u201cWhat are the main political parties in France?\u201d); the other does ask the same generic prompt twice in two different conversations (\u201cHi\u201d, \u201cHi\u201d). Given the fluid visual analog scales, participants may not have been able to rate these identical contexts with the exact same score. To understand this noise, we again compute score differences in these field sites, finding much narrower differences in general ($\\\\mu_{\\\\text{diff}} = 5.8$, $\\\\sigma_{\\\\text{diff}} = 9.3$, see Fig. 29). The 25th percentile is 0.0, 50th percentile (median) is 1.00, and the 75th percentile is 6.25. While these statistics are based on relatively few\"}"}
{"id": "DFr5hteojx", "page_num": 82, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"participants and dialogues, it helps to calibrate the recommended tie threshold, where a 5-10 score margin seems sensible as when to consider a model as winning over another (see App. T.4).\\n\\n![Distribution of score differences in fixed context field sites.](image)\\n\\nWe show that scores are more widely spread when different participants rate the same context, than when the same participant rates the same context. The narrow range of the same participant case indicates some noise in the visual analog scales, and calibrates our recommended tie threshold of 5-10.\\n\\nTable 25: Examples of fixed field sites.\\n\\nFor different participants, we first take a mean score within a single participant's ratings (if there are duplicates), then combine unique participants into a list. Score range is the maximum - minimum of these lists. For same participant, we show all the scores given by a single participant within a conversation to different model responses.\\n\\n| Participant | Prompt | Model Response | N | Unique Participants | N | Unique Models | Models | Scores | Score Range |\\n|-------------|--------|----------------|---|---------------------|---|--------------|--------|--------|-------------|\\n|             |        | does god exist? | yes | 3 | 1 | [flan-t5-xxl] | [71.0, 17.0, 17.0] | 54 |\\n|             |        | hello hello! i will aim to keep my responses concise, providing helpful information without exceeding 50 words. what questions can i answer for you today? | 3 | 2 | [claude-2, claud-2.1] | [24.0, 100.0, 1.0] | 99 |\\n|             |        | hello hello! how can i assist you today? | 8 | 5 | [gpt-3.5-turbo, mistral-7b-instruct, gpt-4, gpt-4-turbo, pythia-12b] | [76.5, 64.0, 21.0, 50.0, 78.6, 59.3, 95.6, 100.0] | 79 |\\n|             |        | what is your name | | 2 | 1 | [claude-2.1] | [98.0, 85.0] | 13 |\\n|             |        | good morning good morning! how can i assist you today? | 2 | 2 | [gpt-4-turbo, gpt-3.5-turbo] | [94.0, 93.0] | 1 |\\n\\nContinued on next page...\"}"}
{"id": "DFr5hteojx", "page_num": 83, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 25: Examples of fixed field sites.\\n\\nFor different participants, we first take a mean score within a single participant's ratings (if there are duplicates), then combine unique participants into a list. Score range is the maximum - minimum of these lists. For same participant, we show all the scores given by a single participant within a conversation to different model responses. (Continued)\\n\\n| Participant | Prompt | Model Response | Score |\\n|-------------|--------|----------------|-------|\\n| hello       | Hello! How can I assist you today? | gpt-3.5-turbo, mistral-7b-instruct, gpt-4 | 97, 93, 97 |\"}"}
{"id": "DFr5hteojx", "page_num": 84, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Case Study II: Aggregating Preference Ratings to Model Ranks\\n\\n1. Extended Methods\\n\\nSetup\\n\\nOur second experiment asks different people prefer differently-aligned models? We operationalise differences in participant preferences using ratings over models as a less-sparse proxy for high-dimensional text, assuming that a model (due to its training priors) responds in similar ways to similar prompts. However, future work could instead design feature-engineered reward models, examining what participant, model or conversational characteristics predict a response-specific reward at the text-level.\\n\\nWe only focus on the opening prompt where four randomly-chosen models battle one another. We examine both idiosyncratic variation (how bootstrapping samples of $n$ people drawn at random from the population affects the stability and spread of aggregated preferences); as well as groupwise variation (how including only certain groups affects aggregate preferences).\\n\\nChoice of score processing\\n\\nParticipants' raw scores $S(y_i)$ are a number between 1-100 recorded on the interface. Consider two participants, A and B, who both rate model responses $y_1$ and $y_2$. Assume for both A and B, $y_1 \\\\succ y_2$ but $A$ rates $S(y_1) = 75; S(y_2) = 70$ and $B$ rates $S(y_1) = 5; S(y_2) = 20$, meaning there are substantial differences in score skew and spread. Imagine that this behaviour persists across all of A and B's conversations: A is consistently the optimist and B the pessimist.\\n\\nOne explanation for this behaviour is that B just systematically uses scales differently, an issue of measurement invariance that is a known problem for subjective measures [158]. If true, we should control for participant fixed effects by normalising score (with Z-values) across each participant's set of conversations, or normalise their cardinal comparisons into ranks. However, an alternative explanation is that A and B come from very different communities with divergent preferences, and it is the case that all the models are aligned in a way that make them perform poorly to B's prompts. If we normalise B's scores, we flatten this signal. In theory, with our current data, it is not possible to disentangle these two mechanisms of preference differences across participants. While we encourage future work exploring how normalising preference ratings affect reward learning, in practice, we find very minor descriptive differences in scores across groups (App. O), and that model comparisons relying on raw and normalised scores are highly correlated ($\\\\tau_{Kendall} = 1.000 \\\\ast \\\\ast \\\\ast$, App. T.3).\\n\\nChoice of tie threshold\\n\\nEven without identical numeric scores, participants may be indifferent between model responses, which we can reconstruct with a margin-of-victory, only counting $y_1 \\\\succ y_2$ if the score difference exceeds some tie threshold. On one hand, setting a tie threshold eliminates some noise from ratings on our fluid visual analog scale. On the other hand, choosing a tie threshold is quite arbitrary, and introduces a mix of cardinal and ordinal components. We examine sensitivity of model ranks to tie threshold in App. T.4. In addition, we calibrate expected indifference margins from our VAS on sparse cases where the same participant rates identical prompt-response pairs (see App. S.4), finding a median score difference of 1, and mean of 5.8. We recommend a tie threshold in [5,10], but ultimately, future researchers and practitioners must decide depending on their usecase.\\n\\nChoice of preference aggregation function\\n\\nFor each participant, we observe a partial profile of preference ratings over models (not every individual rates every model). Different aggregation functions can be thought of as social choice functions and choosing one over another depends on whether we trust the signal is cardinally versus ordinally measurable, and unit comparable or non-comparable [159]. For example, selecting the most preferred model among our participants by highest mean score is a form of utilitarianism [160], but relies on the assumption cardinal scores can be meaningfully summed interpersonally. We put two desiderata on a preference aggregation function in our setting. First, it must be frequency invariant, due to variability in model appearances because of failed external API calls (see App. P). Second, it must be intrinsically comparable across tournaments. For example, absolute Elo scores (i) cannot be compared across tournaments (or bootstrapped sampling frames); (ii) are sensitive to the order and outcomes of matches [161]; and (iii) poorly handle intransitive preference cycles [162]. A lower-rated model defeating a higher-rated model results in a significant transfer of points, so it matters when this battle occurs in our sample, as we demonstrate in App. T.3.\\n\\nIn our work, we are not constrained by functions that perform well in online settings (like Elo), and can instead analyse ranks observing a full set of offline interactions. Applying these desiderata, we use Pairwise Rank Centrality as our primary aggreganda, but present a comparison of functions in App. T.3, finding different aggregation functions produce correlated ranks ($\\\\tau_{Kendall} = 0.810 \\\\ast \\\\ast \\\\ast$), but introduce some movement among mid-leaderboard positions.\"}"}
{"id": "DFr5hteojx", "page_num": 85, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u201cConvergence alignment\u201d via Pairwise Rank Centrality.\\n\\nOur aggregation function is derived from Pairwise Rank Centrality proposed by Negahban et al. [48] and Convergence Voting proposed by Bana et al. [49], both mathematically inspired by Google\u2019s PageRank [50]. Each model ($M_i$) is a node in a graph. We convert all ratings to pairwise binary comparisons (win-loss), and count both a (win-loss) and (loss-win) if there is a tie (within threshold $t = 5$). Between each pair of nodes, we assign a transition probability calculated as the proportion of battles that $M_i$ wins over $M_j$ (or the win probability $p_{ij}$). In Bana et al. [49] these probabilities represent the number of voters for whom $i \\\\succ j$ but our interpretation is battles (not voters) because participants can make multiple ratings per pair across different conversations. Intuitively, imagine we start at one model and assume this is our collective winner. Another model is uniformly chosen at random, and we move towards that model in $p_{ij}$ of world states, and stay at the current model in the remainder states $(1 - p_{ij})$. Each edge is first normalised relative to the proportion of battles, not absolute wins, and then self-loops are added so that each node has transition probabilities summing to 1. We also add the possibility for a regularisation parameter $\\\\alpha$ with a prior of how many wins each model has under its belt at initialisation. Negahban et al. [48] suggest a regularisation parameter of 1 is a sensible prior without further information, and that a stable ranking emerges with the order of $n \\\\log n$ battles in the tournament, which is safely met given $n = 21$ and each participant on average has 6 conversations with 4 models (or 6 battles, $4 \\\\choose 2$). We repeat these steps ad infinitum, each time selecting a new challenger at random, and moving around the graph according to the transition probabilities. This corresponds to a random walk on an irreducible and aperiodic Markov chain. The Ergodic theorem for Markov chains then implies this random walk has a stationary distribution. Stationarity can be computed iterating over discrete steps (e.g. $\\\\text{iter}=1000$, which we opt for speed) or by extracting the left eigenvector with components summing to 1 from the transition matrix, which under conditions of allowing transition between $m_i$ and $m_j$ with non-zero probability, has a unique stationary distribution. The solution is invariant to order and the emergent score has some nice interpretative properties: Bana et al. [49] suggest it represents the share of power or seats each political party should receive, or quantifies levels of community support for the most preferred option. Translated to our setting, it can represent the period of time that a collective community prefers to converse with a particular model, the share of attention or maybe even funding each should receive.\\n\\nNote that in the following set of robustness experiments we include all battles in \\\\textit{PRISM}, not just the balanced subset; so, rankings may differ to Fig. 4.\"}"}
{"id": "DFr5hteojx", "page_num": 86, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model                  | Topic                                | Mean(male score) | Mean(female score) | Difference |\\n|------------------------|--------------------------------------|------------------|--------------------|------------|\\n| gpt-4-turbo            | Holiday Celebration Planning          | 87               | 55                 | 32         |\\n| llama-2-7b-chat        | Health and Wellness Advice            | 79               | 59                 | 20         |\\n| llama-2-7b-chat        | Managing Relationships                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Holiday Celebration Planning          | 68               | 50                 | 18         |\\n| llama-2-7b-chat        | Ethics of Death and Killing           | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Discussions on Abortion               | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Election and Political Parties        | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Popular Culture (Sports, Music, TV)   | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Economic Policy and Income Inequality| 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Exploring AI and Machine Learning     | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Discussions on Race and Racism        | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Debating Immigration Policies         | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Gender and LGBTQ+ Identity            | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Israel-Palestine Conflict             | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Religion and Spirituality             | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Recipe and Cooking Queries            | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Managing Relationships                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Animal and Pet Inquiries              | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Travel Recommendations                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Weather Inquiries                     | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Greeting Introductions                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Managing Relationships                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Discussion on Race and Racism         | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Debating Immigration Policies         | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Gender and LGBTQ+ Identity            | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Israel-Palestine Conflict             | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Religion and Spirituality             | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Recipe and Cooking Queries            | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Managing Relationships                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Animal and Pet Inquiries              | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Travel Recommendations                | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Weather Inquiries                     | 67               | 49                 | 18         |\\n| llama-2-7b-chat        | Greeting Introductions                | 67               | 49                 | 18         |\"}"}
{"id": "DFr5hteojx", "page_num": 87, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sensitivity of Model Rank to Aggregation Function\\n\\nWe consider different aggregation functions of individual preferences. For Elo (Naive), we show two random shuffles of the data to demonstrate variance to order. Elo (MLE) refers to fitting Elo ratings by maximum likelihood estimation, implemented as in CHATBOT A RENA [51].\\n\\nAverage Win Rate is mean pairwise win rates, and Mean Score just averages raw score across all participants. Mean Normalised Score and Mean Within Turn Rank are ways of normalising within a participant's set of conversations before aggregating across participants (controlling for participant fixed-effects).\\n\\nPairwise Rank Centrality\\n\\n| Command     | Leaderboard Position | Elo (Naive) | Elo (Naive, Reverse) | Elo (BT, MLE) | Average Win Rate | Mean Score | Mean Normalised Score | Mean Within Turn Rank |\\n|-------------|----------------------|-------------|----------------------|---------------|------------------|------------|------------------------|-----------------------|\\n| COM         | 1                    | 1.0***      | 0.8***               | 0.9***        | 0.8***           | 0.9***     | 0.9***                 | 0.8***                |\\n| CL1         | 2                    | 0.8***      | 1.0***               | 0.8***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| PALM        | 3                    | 0.9***      | 0.8***               | 1.0***        | 1.0***           | 1.0***     | 1.0***                 | 0.8***                |\\n| ZEPH        | 4                    | 0.8***      | 0.9***               | 0.9***        | 0.8***           | 0.8***     | 0.8***                 | 0.8***                |\\n| COMN        | 5                    | 0.9***      | 0.9***               | 0.9***        | 0.8***           | 0.8***     | 0.8***                 | 0.8***                |\\n| LL70        | 6                    | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| GPT4*       | 7                    | 0.8***      | 0.8***               | 0.8***        | 0.9***           | 0.9***     | 0.9***                 | 0.9***                |\\n| COML        | 8                    | 0.9***      | 0.9***               | 0.9***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| GP3*        | 9                    | 0.9***      | 0.9***               | 0.9***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| CL2         | 10                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| CL2*        | 11                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| MIST        | 12                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| GUAN        | 13                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| FAL7        | 14                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| PYTH        | 15                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| LL13        | 16                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| LUMS        | 17                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| LUMX        | 18                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| FLAN        | 19                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n| 20          | 20                   | 0.8***      | 0.8***               | 1.0***        | 0.8***           | 0.8***     | 0.8***                 | 1.0***                |\\n\\nFigure 31: Sensitivity of model rank to aggregation function. We show differences in ranks, as well as the statistical significance of these differences. Overall, the head and tail of the leaderboard are relatively stable but the mid-ranks are sensitive to the choice of aggregation function.\"}"}
{"id": "DFr5hteojx", "page_num": 88, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Sensitivity of Model Rank to Tie Threshold\\n\\n| Tie Threshold | Model 1 | Model 2 | Model 3 | Model 4 | Model 5 | Model 6 | Model 7 | Model 8 | Model 9 | Model 10 |\\n|---------------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\\n| thresh=0      | 1.0***  | 1.0***  | 0.9***  | 0.9***  | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 1.0***  | 1.0***  |\\n| thresh=5      | 1.0***  | 1.0***  | 0.9***  | 0.9***  | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 1.0***  | 1.0***  |\\n| thresh=10     | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 1.0***  | 1.0***  |\\n| thresh=20     | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 1.0***  | 1.0***  |\\n| thresh=25     | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 0.9***  | 0.9***  | 1.0***  | 1.0***  | 1.0***  | 1.0***  |\\n\\nKendall's Tau\\n\\n---\\n\\n**Figure 32:** Sensitivity of model rank to tie threshold. Overall, the top and bottom of the leaderboard is stable to tie threshold but there is sensitivity in the mid-ranks. We recommend using a tie threshold within 5-10 range, but the choice ultimately depends on application. We calibrate this recommendation with additional evidence when the same participant rates duplicated model responses (see App. S.4).\"}"}
{"id": "DFr5hteojx", "page_num": 89, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sensitivity of Model Rank to Included Subset\\n\\nSensitivity of Model Rank to Regularisation Parameter\\n\\nVariation in rank by which battles are included.\\nWe calculate Pairwise Rank Centrality over all battles versus just those in the balanced subset (used in main paper), finding close agreement between the ranks.\\n\\nVariation in rank by regularisation (\\\\(\\\\alpha\\\\)). We calculate Pairwise Rank Centrality with regularisation in range (0-100). Note that Negahban et al. [163] recommend \\\\(\\\\alpha = 1\\\\) is a sensible starting prior.\\n\\nFigure 33: Combined sensitivity analysis of experiment setup decisions. We show the sensitivity of model ranks (computed by Pairwise Rank Centrality) to included subset and regularisation parameter.\"}"}
{"id": "DFr5hteojx", "page_num": 90, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"We repeat the experiment in \u00a7 3.2 to understand idiosyncratic variance at different sample sizes. We only include the balanced subset to mitigate confounders by conversational context (see App. K).\\n\\nTable 26: Key battle properties as the sample scales. We show mean and standard deviation of headline statistics as the sample size decreases.\\n\\n| N        | Opening Prompts | Battles | Battles (per possible model pairs) | Unique Raters (per possible model pairs) | Rated Model Responses | Unique Raters (per model) |\\n|----------|-----------------|---------|------------------------------------|------------------------------------------|-----------------------|---------------------------|\\n| N = 1   | 2,686 \u00b1 21.3    | 14,167 \u00b1 123.9 | 67 \u00b1 0.6                           | 64 \u00b1 0.6                                | 10,070 \u00b1 81.3        | 317 \u00b1 2.2                 |\\n| N = 500 | 537 \u00b1 11.7      | 2,835 \u00b1 68.7   | 14 \u00b1 0.3                           | 13 \u00b1 0.3                                | 2,014 \u00b1 44.8         | 63 \u00b1 1.1                  |\\n| N = 100 | 269 \u00b1 8.4       | 1,417 \u00b1 50.0   | 7 \u00b1 0.2                            | 6 \u00b1 0.2                                 | 1,007 \u00b1 32.4         | 32 \u00b1 0.8                  |\\n| N = 50  | 54 \u00b1 3.9        | 283 \u00b1 22.9     | 1 \u00b1 0.1                            | 1 \u00b1 0.1                                 | 201 \u00b1 15.1           | 6 \u00b1 0.4                   |\\n| N = 10  | 6,696 \u00b1 0.0     | 35,320 \u00b1 0.0   | 168 \u00b1 0.0                          | 158 \u00b1 0.0                               | 25,103 \u00b1 0.0         | 791 \u00b1 0.0                 |\\n\\nFigure 34: Variation in rank centrality by size of participating cohort. We run for 1000 bootstraps. Median values are marked within each box plot. There are 1246 participants in the balanced subset (with 25,103 battles). As the sample scales, there is greater stability in model rank. At very small samples (though not usually small for human evaluation experiments in NLP), there is broad indifference\u2014almost any model could be highly-ranked depending on sample characteristics.\"}"}
{"id": "DFr5hteojx", "page_num": 91, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"T.8 Understanding Model Ranks: Regressions of Text Features on Score\\n\\nWe present results for our investigation into correlates of model score. We only investigate model responses in the opening conversation turn. We present descriptive results for text length in Fig. 35, and additional formatting and phrase hypotheses in Fig. 36. We present statistical results of a simple OLS regression in Tab. 27. We encourage future work with more sophisticated model specifications, for example controlling for model, participant, or conversational context fixed-effects.\\n\\nIn our specification, we test:\\n\\n1. `text_length` is number of characters in the model response string.\\n2. `if_line_breaks` is 1 if the string contains `\\\\n`; else 0.\\n3. `if_question_marks` is 1 if the last character of the string is `?`; else 0.\\n4. `if_enumeration` is 1 if the string contains numeric enumeration (e.g. `1. ...\\n 2. ...`) or bullets (`-... \\n -...`); else 0.\\n5. `if_deanthro` is 1 if the string contains 1 or more matched deanthropomorphising phrases e.g. \\\"As an AI language model...\\\", \\\"I don't hold personal opinions...\\\"; else 0.\\n6. `if_refusal` is 1 if the string contains 1 or more matched refusal phrases e.g. \\\"I cannot engage with...\\\", \\\"I don't hold personal opinions\\\"; else 0.\\n7. `if_self_identification` is 1 if the string contains 1 or more matched names of models or providers e.g. \\\"I am designed by Anthropic to be...\\\"; else 0.\\n\\nAs additional detail for H6, we find that 9% of conversations contain at least one refuser model matching phrases, e.g. \\\"I'm sorry, but...\\\". In these cases, a non-refuser is chosen 73% of time.\\n\\n![Figure 35: H1: Longer texts increase score.](image)\\n\\n![Table 27: OLS of score on hypothesised influence factors.](image)\\n\\nAnecdotally, one participant said \\\"I liked it when the options where listed. It made it easier for me to read.\\\"\"}"}
{"id": "DFr5hteojx", "page_num": 92, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 36: Analysis of hypothesis on model scores. Top four panels show H1-H4: Longer, formatted responses increase score. Bottom three panels show H5-H6: Stock phrases decrease score. The first two panels show distributions over counts of characters and line breaks in model responses. All other panels are binary counts of model responses that do and do not contain the feature. Models are sorted alphabetically.\"}"}
{"id": "DFr5hteojx", "page_num": 93, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We download the LMSYS battles. Originally, LMSYS has 184,610 battles over 54 models; PRISM has 42,306 battles over 21 models. After merging, there are 14 shared models ($N_{PRISM} = 18,758$, $N_{LMSYS} = 35,359$).\\n\\nFor LMSYS, we convert both \u201ctie\u201d and \u201ctie (both bad)\u201d to a single tie group. We use $t = 5$ as a tie threshold for PRISM. Before computing Pairwise Rank Centrality, we first ensure the pairs of battles are evenly sampled between the two datasets. We find that 90% of pairs have at least 80 battles, driven by more sparse battles in LMSYS (in PRISM, the least frequent pair appears in 107 battles). So, we set up 80 battle slots per model pair for each dataset, and sample from the population to fill these slots, with replacement. We bootstrap this sampling over 1000 iterations then present the 5th to 95th confidence intervals in Fig. 37c.\\n\\n---\\n\\n### Differences in battles.\\n\\nLMSYS has more battles but the distribution of wins between model A and model B are similar, with PRISM having fewer ties (20% vs 31%, at a tie threshold of 5).\\n\\n| Model A | Model B | Tie | Winner |\\n|---------|---------|-----|--------|\\n| 0       | 0       |     |        |\\n| 5000    | 5000    |     |        |\\n| 10000   | 10000   |     |        |\\n\\n---\\n\\n### Differences in average pairwise win rates.\\n\\nWe include the full set of observed battles (unbalanced total battles and battles per pair).\\n\\n| Model A | Model B | Tie | Winner | Average Pairwise Win Rate |\\n|---------|---------|-----|--------|---------------------------|\\n| 0.50    | 0.50    |     |        |                           |\\n| 0.48    | 0.48    |     |        |                           |\\n| 0.45    | 0.45    |     |        |                           |\\n| 0.44    | 0.44    |     |        |                           |\\n| 0.42    | 0.42    |     |        |                           |\\n| 0.41    | 0.41    |     |        |                           |\\n| 0.38    | 0.38    |     |        |                           |\\n| 0.37    | 0.37    |     |        |                           |\\n| 0.35    | 0.35    |     |        |                           |\\n| 0.35    | 0.35    |     |        |                           |\\n| 0.33    | 0.33    |     |        |                           |\\n| 0.30    | 0.30    |     |        |                           |\\n\\n---\\n\\n### Differences in Pairwise Rank Centrality.\\n\\nEven-sampling per pair ($n = 80$), bootstrapped for 95% confidence intervals on the median ($iter = 1000$).\\n\\n| Model A | Model B | Rank Centrality | lmsys | prism |\\n|---------|---------|-----------------|-------|-------|\\n| 0.06    | 0.06    |                 |       |       |\\n| 0.08    | 0.08    |                 |       |       |\\n| 0.10    | 0.10    |                 |       |       |\\n| 0.12    | 0.12    |                 |       |       |\\n\\n---\\n\\nFigure 37: Comparison of PRISM battles to LMSYS leaderboard. Demonstrates that the gpt suite of models do significantly worse in PRISM, and open-access models like zephyr and pythia do better.\\n\\nSee huggingface.co/spaces/lmsys/chatbot-arena-leaderboard and the attached notebook for details on how to obtain raw data.\"}"}
{"id": "DFr5hteojx", "page_num": 94, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"U Case Study III: Welfare Analysis\\n\\nU.1 Extended Methods\\n\\nSetup\\n\\nThe third experiment asks: how do the sampling decisions affect welfare outcomes? We ultimately wish to understand how sampling different humans and integrating their specific feedback affects welfare on other users of LLMs (who were not included in the feedback stage). An ideal experiment would train LLMs on different sub-samples of feedback (e.g. 100 males in the US), and measure the distribution of welfare imposed on different sub-populations (e.g. females in the US).\\n\\nWhile training LLMs on different sub-populations is beyond this paper\u2019s scope, we approximate the thought experiment by randomly generating sub-samples of individuals to select their favourite existing LLM (those in the seat of power), and measure the distribution of welfare imposed on different sub-populations (also called stakeholder populations [9]).\\n\\nSub-populations\\n\\nLet $P$ denote the population of participants, $p \\\\subseteq P$ denote a sub-population and $P(P)$ denote the power set of $P$ (i.e. all subpopulations). To identify specific sub-populations, we define the choice function:\\n\\n$\\\\text{SUBPOP}: \\\\text{REGIONS} \\\\times \\\\text{GROUPS} \\\\rightarrow P(P)$\\n\\nwhere $\\\\text{REGIONS} = \\\\{\\\\text{US}, \\\\text{UK}\\\\}$ is a set geographical regions and $\\\\text{GROUPS} = \\\\{\\\\text{rep}, \\\\text{non-male}, \\\\text{non-white}, \\\\text{below 45}, \\\\text{male}, \\\\text{white}, \\\\text{above 45}\\\\}$ is a set demographic groups (rep denotes the whole population). Given $r \\\\in \\\\text{REGIONS}$ and $g \\\\in \\\\text{GROUPS}$, $\\\\text{SUBPOP}$ returns the individuals in $P$ that are in both $r$ and $g$.\\n\\nOur analysis uses the sub-populations given by:\\n\\n$SP = \\\\{\\\\text{SUBPOP}(i, j) \\\\in P(P) | (i, j) \\\\in \\\\{(\\\\text{US}), \\\\{\\\\text{rep}\\\\}\\} \\\\times \\\\{\\\\text{non-male}, \\\\text{non-white}, \\\\text{below 45}\\\\}\\\\}$. We approximate the sub-population defined by a tuple $(r, g)$ by selecting all the matching participants in our balanced sample that are in both $r$ and $g$.\\n\\nSampling schemes\\n\\nA sampling scheme is a tuple: $S = (p, n)$ where $p \\\\in P$ and $n \\\\in \\\\mathbb{N}^+$. A sampling scheme randomly generates samples of $n$ individuals from $p$, the subpopulation of interest. We approximate a sampling scheme by using our approximation of sub-populations defined in the previous section and sampling $n$ participants with replacement. Our main analysis uses the sampling schemes:\\n\\n$S = \\\\{(\\\\text{SUBPOP}(\\\\text{US}, \\\\text{all}), n) | n \\\\in \\\\{10, 20, 50, 100\\\\}\\\\} \\\\cup \\\\{(\\\\text{SUBPOP}(\\\\text{US}, g), 100) | g \\\\in \\\\{\\\\text{male}, \\\\text{white}, \\\\text{above 45}\\\\}\\\\}$.\\n\\nIndividual welfare\\n\\nLet $M$ denote the set of models. Our analysis requires a measure of welfare for an individual $j$ if LLM $i$ is chosen. We use two measures of individual welfare. i) $RATING: P \\\\times M \\\\rightarrow [1, 100]$. Given participant $j$ and model $i$, $RATING(j, i)$ computes the mean rating $i$ gives to LLM $j$ in the first turn of a conversation. ii) $CHOICE: P \\\\times M \\\\rightarrow [0, 1]$. $CHOICE(j, i)$ computes the proportion of the $j$\u2019s conversations where LLM $i$ is chosen, conditional on LLM $i$ being shown. For both measures of individual welfare, if a participant is never shown a model, we set their individual welfare to $NA$.\\n\\nThe distribution of LLMs induced by sampling scheme\\n\\nA sampling scheme $S$, together with a preference aggregation method induce a distribution $\\\\rho \\\\in \\\\Delta(M)$. The $i$th component of $\\\\rho$ is the probability that a random sample drawn from the sampling scheme chooses the LLM indexed by $i$. Our main analysis uses the preference aggregation method: $\\\\text{MAX RATING}: P(P) \\\\rightarrow M$.\\n\\nGiven draws $s \\\\sim S$, we define $\\\\text{maxRatingCandidates} := \\\\text{argmax}_{i \\\\in M} 1 | s'(i) | \\\\prod_{j \\\\in s'(i)} RATING(j, i)$ where $s'(i) = \\\\{j \\\\in s | \\\\text{rating}(j, i) \\\\neq NA\\\\}$. $\\\\text{MAX RATING}(s)$ then returns a random element in $\\\\text{maxRatingCandidates}$. In words, $\\\\text{MAX RATING}$ computes the rating (as defined in the previous paragraph) given to each model by each participant in the draw of $S$. It then computes the mean score of each model averaged across individual mean ratings and returns a model with the highest mean rating. We repeat the analysis for the method $\\\\text{MAX CHOICE}$ which replaces $RATING$ with $CHOICE$.\\n\\nMeasuring welfare\\n\\nFor simplicity, we summarise the welfare imposed on the population by a given model by a single number. For the main analysis, we use the measure $\\\\text{MEAN RATING}: P(P) \\\\times M \\\\rightarrow [1, 100]$ where $\\\\text{MEAN RATING}(p, i) = \\\\frac{1}{|p'|} \\\\sum_{j \\\\in p'} RATING(j, i)$ and $p' = \\\\{j \\\\in p | \\\\text{rating}(j, i) \\\\neq NA\\\\}$. We repeat that analysis for $\\\\text{MEAN CHOICE}$ which replaces $RATING$ with $CHOICE$.\\n\\nGiven a sampling scheme $S$ and a subpopulation $p \\\\in P$, the PMF of $\\\\text{MEAN RATING}(p, i)$\"}"}
{"id": "DFr5hteojx", "page_num": 95, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the distribution of welfare is described by the tuple: $(\\\\rho(S), w(p))$ where $w$ is a vector whose $i$th component is given by MEAN RATING $(p, i)$.\\n\\nFor each $sp \\\\in SP$, we compute the welfare distributions implied by each sampling scheme $S \\\\in S$.\\n\\nWe use MAX RATING to choose a LLM, and MEAN RATING as our measure of welfare. We repeat the analysis using MAX CHOICE to choose a LLM, and MEAN CHOICE as our measure of welfare. A concern is that our results are sensitive to randomness caused by different participants being shown different models. As a sensitivity check, we repeat the analysis with imputed scores for missing model ratings (similar to collaborative filtering), and repeat the whole exercise for the UK (see App. U.2).\\n\\nThere are some caveats to note. Despite having samples balanced by observed demographics for the UK and the US, the samples are too small to expect them to be representative on features we do not observe. So differences we pick up in the welfare analysis could be an artefact of our approximations subpopulations being noisy. Furthermore, our analysis using MEAN RATING welfare measure assumes that individuals use scores in the same way for ratings welfare measures. However, our analysis using MEAN CHOICE is not sensitive to use of ratings scale, and the results are qualitatively similar. Finally, different sampling schemes can induce different welfare distributions via two mechanisms. First, the subpopulations sampled from may have different preferences conditional on conversation type. Second, the sub-populations sampled from may have different conversations, and in turn, choose models that are better at particular conversations. This experiment taken alone cannot disentangle these two mechanisms.\\n\\nU.2 UK Sample\"}"}
{"id": "DFr5hteojx", "page_num": 96, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 39: Welfare distributions with imputation.\\n\\nIn Fig. 5 and Fig. 38 individual welfare for a model takes the value NA if an individual never sees the model. Here, we repeat the welfare analysis and impute individual welfare with an approach similar in spirit to collaborative filtering. Using the only matrix of individual welfare for each model, we impute NA cells using multivariate imputation, implemented with the IterativeImputer package in Python. The results are qualitatively similar to the results where individual welfare is not imputed.\"}"}
{"id": "DFr5hteojx", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9 III, and Kate Crawford. Datasheets for datasets. Communications of the ACM, 64(12):86\u201392, December 2021. ISSN 1557-7317. doi: 10.1145/3458723. Publisher: Association for Computing Machinery.\\n\\nAida Mostafazadeh Davani, Mark D\u00edaz, and Vinodkumar Prabhakaran. Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations. Transactions of the Association for Computational Linguistics, 10:92\u2013110, January 2022. ISSN 2307-387X. doi: 10.1162/tacl_a_00449. URL https://doi.org/10.1162/tacl_a_00449.\\n\\nMitchell L. Gordon, Michelle S. Lam, Joon Sung Park, Kayur Patel, Jeff Hancock, Tatsunori Hashimoto, and Michael S. Bernstein. Jury Learning: Integrating Dissenting Voices into Machine Learning Models. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, CHI \u201922, pages 1\u201319, New York, NY, USA, April 2022. Association for Computing Machinery. ISBN 978-1-4503-9157-3. doi: 10.1145/3491102.3502004. URL https://doi.org/10.1145/3491102.3502004.\\n\\nBarbara Plank, Dirk Hovy, and Anders S\u00f8gaard. Learning part-of-speech taggers with inter-annotator agreement loss. In Shuly Wintner, Sharon Goldwater, and Stefan Riezler, editors, Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 742\u2013751, Gothenburg, Sweden, April 2014. Association for Computational Linguistics. doi: 10.3115/v1/E14-1078. URL https://aclanthology.org/E14-1078.\\n\\nYixin Nie, Xiang Zhou, and Mohit Bansal. What Can We Learn from Collective Human Opinions on Natural Language Inference Data? In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9131\u20139143, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.734. URL https://aclanthology.org/2020.emnlp-main.734.\\n\\nMaximilian Wich, Christian Widmer, Gerhard Hagerer, and Georg Groh. Investigating Annotator Bias in Abusive Language Datasets. In Ruslan Mitkov and Galia Angelova, editors, Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), pages 1515\u20131525, Held Online, September 2021. INCOMA Ltd. URL https://aclanthology.org/2021.ranlp-1.170.\\n\\nMaarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A. Smith. Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5884\u20135906, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.431. URL https://aclanthology.org/2022.naacl-main.431.\\n\\nNitesh Goyal, Ian D. Kivlichan, Rachel Rosen, and Lucy Vasserman. Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation. Proceedings of the ACM on Human-Computer Interaction, 6(CSCW2):363:1\u2013363:28, November 2022. doi: 10.1145/3555088. URL https://dl.acm.org/doi/10.1145/3555088.\\n\\nLora Aroyo, Alex S. Taylor, Mark Diaz, Christopher M. Homan, Alicia Parrish, Greg Serapio-Garcia, Vinodkumar Prabhakaran, and Ding Wang. DICES Dataset: Diversity in Conversational AI Evaluation for Safety, June 2023. URL http://arxiv.org/abs/2306.11247. arXiv:2306.11247 [cs].\\n\\nJoseph Henrich, Steven J. Heine, and Ara Norenzayan. Most people are not WEIRD. Nature, 466(7302):29\u201329, July 2010. ISSN 1476-4687. doi: 10.1038/466029a. URL https://www.nature.com/articles/466029a. Number: 7302 Publisher: Nature Publishing Group.\\n\\nDante A. Urbina and Alberto Ruiz-Villaverde. A Critical Review of Homo Economicus from Five Approaches. The American Journal of Economics and Sociology, 78(1):63\u201393, 2019. ISSN 1536-7150. doi: 10.1111/ajes.12258. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/ajes.12258._eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajes.12258.\\n\\nCoren Apicella, Ara Norenzayan, and Joseph Henrich. Beyond WEIRD: A review of the last decade and a look ahead to the global laboratory of the future. Evolution and Human Behavior, 41(5):319\u2013329, September 2020. ISSN 1090-5138. doi: 10.1016/j.evolhumbehav.2020.07.015. URL https://www.sciencedirect.com/science/article/pii/S1090513820300957.\\n\\nAndrew Ng and Stuart J. Russell. Algorithms for Inverse Reinforcement Learning. 2000.\"}"}
{"id": "DFr5hteojx", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep Reinforcement Learning from Human Preferences. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html.\\n\\nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-Tuning Language Models from Human Preferences. September 2019. URL http://arxiv.org/abs/1909.08593v2.\\n\\nShachar Mirkin and Jean-Luc Meunier. Personalized machine translation: Predicting translational preferences. In Proceedings of the 2015 conference on empirical methods in natural language processing, pages 2019\u20132025, Lisbon, Portugal, September 2015. Association for Computational Linguistics. doi: 10.18653/v1/D15-1238. URL https://aclanthology.org/D15-1238.\\n\\nKhanh Nguyen, Hal Daum\u00e9 III, and Jordan Boyd-Graber. Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1464\u20131474, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1153. URL https://aclanthology.org/D17-1153.\\n\\nJulia Kreutzer, Artem Sokolov, and Stefan Riezler. Bandit Structured Prediction for Neural Sequence-to-Sequence Learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1503\u20131513, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1138. URL https://aclanthology.org/P17-1138.\\n\\nMarilyn A Walker. An application of reinforcement learning to dialogue strategy selection in a spoken dialogue system for email. Journal of Artificial Intelligence Research, 12:387\u2013416, 2000.\\n\\nJost Schatzmann, Karl Weilhammer, Matt Stuttle, and Steve Young. A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. The knowledge engineering review, 21(2):97\u2013126, 2006.\\n\\nPei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Maria Rojas-Barahona, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, and Steve J. Young. Continuously learning neural dialogue management. abs/1606.02689, 2016. URL http://arxiv.org/abs/1606.02689.\\n\\nJiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato, and Jason Weston. Dialogue learning with human-in-the-loop. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https://openreview.net/forum?id=HJgXCV9xx.\\n\\nNatasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, and Rosalind Picard. Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog, July 2019. URL http://arxiv.org/abs/1907.00456. arXiv:1907.00456 [cs, stat].\\n\\nNatasha Jaques, Judy Hanwen Shen, Asma Ghandeharioun, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, and Rosalind Picard. Human-centric dialog training via offline reinforcement learning. In Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP), pages 3985\u20134003, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.327. URL https://aclanthology.org/2020.emnlp-main.327.\\n\\nAmelia Glaese, Nat McAleese, Maja Tr\u0119bacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, So\u0148a Mokr\u00e1, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. Improving alignment of dialogue agents via targeted human judgements. September 2022. URL http://arxiv.org/abs/2209.14375v1.\\n\\nJ\u00e9r\u00e9my Scheurer, Jon Ander Campos, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. Training Language Models with Language Feedback, November 2022. URL http://arxiv.org/abs/2204.14146. arXiv:2204.14146 [cs].\"}"}
{"id": "DFr5hteojx", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, and Hao Zhang. LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset, March 2024. URL http://arxiv.org/abs/2309.11998.\\n\\nWenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng. (InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild. October 2023. URL https://openreview.net/forum?id=Bl8u7ZRlbM.\\n\\nAndreas K\u00f6pf, Yannic Kilcher, Dimitri von R\u00fctte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Rich\u00e1rd Nagyfi, Shahul ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. OpenAssistant Conversations \u2013 Democratizing Large Language Model Alignment, October 2023. URL http://arxiv.org/abs/2304.07327.\\n\\nDeep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, Andy Jones, Sam Bowman, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Nelson Elhage, Sheer El-Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Danny Hernandez, Tristan Hume, Josh Jacobson, Scott Johnston, Shauna Kravec, Catherine Olsson, Sam Ringer, Eli Tran-Johnson, Dario Amodei, Tom Brown, Nicholas Joseph, Sam McCandlish, Chris Olah, Jared Kaplan, and Jack Clark. Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned, November 2022. URL http://arxiv.org/abs/2209.07858.\\n\\nShivalika Singh, Freddie Vargus, Daniel Dsouza, B\u00f6rje F. Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzemi\u00b4nski, Hakimeh Fadaei, Irem Erg\u00fcn, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Vu Minh Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet \u00dcst\u00fcn, Marzieh Fadaee, and Sara Hooker. Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning, February 2024. URL http://arxiv.org/abs/2402.06619.\\n\\nThe Alan Turing Institute and The Ada Lovelace Institute. How do people feel about AI? A nationally representative survey of public attitudes to artificial intelligence in Britain. Technical report, 2023. URL https://attitudestoai.uk/assets/documents/Ada-Lovelace-Institute-The-Alan-Turing-Institute-How-do-people-feel-about-AI.pdf.\\n\\nJimin Mun, Liwei Jiang, Jenny Liang, Inyoung Cheong, Nicole DeCario, Yejin Choi, Tadayoshi Kohno, and Maarten Sap. Particip-AI: A Democratic Surveying Framework for Anticipating Future AI Use Cases, Harms and Benefits, March 2024. URL http://arxiv.org/abs/2403.14791.\\n\\nSamuel Chang, Estelle Ciesla, Michael Finch, James Fishkin, Lodewijk Gelauff, Ashish Goel, Ricky Hernandez Marquez, Shoaib Mohammed, and Alice Siu. Meta Community Forum: Results Analysis. Technical report, Deliberative Democracy Lab, Stanford University, April 2024.\\n\\nStevie Bergman, Nahema Marchal, John Mellor, Shakir Mohamed, Iason Gabriel, and William Isaac. STELA: a community-centred approach to norm elicitation for AI alignment. Scientific Reports, 14(1):6616, March 2024. ISSN 2045-2322. doi: 10.1038/s41598-024-56648-4. URL https://www.nature.com/articles/s41598-024-56648-4. Publisher: Nature Publishing Group.\\n\\nR. Silberzahn, E. L. Uhlmann, D. P. Martin, P. Anselmi, F. Aust, E. Awtrey, \u0160. Bahn\u00edk, F. Bai, C. Bannard, E. Bonnier, R. Carlsson, F. Cheung, G. Christensen, R. Clay, M. A. Craig, A. Dalla Rosa, L. Dam, M. H. Evans, I. Flores Cervantes, N. Fong, M. Gamez-Djokic, A. Glenz, S. Gordon-McKeon, T. J. Heaton, K. Hederos, M. Heene, A. J. Hofelich Mohr, F. H\u00f6gden, K. Hui, M. Johannesson, J. Kalodimos, E. Kaszubowski, D. M. Kennedy, R. Lei, T. A. Lindsay, S. Liverani, C. R. Madan, D. Molden, E. Molleman, R. D. Morey, L. B. Mulder, B. R. Nijstad, N. G. Pope, B. Pope, J. M. Prenoveau, F. Rink, E. Robusto, H. Roderique, A. Sandberg, E. Schl\u00fcter, F. D. Sch\u00f6nbrodt, M. F. Sherman, S. A. Sommer, K. Sotak, S. Spain, C. Sp\u00f6rlein, T. Stafford, L. Stefanutti, S. Tauber, J. Ullrich, M. Vianello, E.-J. Wagenmakers, M. Witkowiak, S. Yoon, and B. A. Nosek. Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results. Advances in Methods and Practices in Psychological Science, 1(3):337\u2013356, September 2018. ISSN 2515-2459. doi: 10.1177/2515245917747646. URL https://doi.org/10.1177/2515245917747646. Publisher: SAGE Publications Inc.\\n\\nJohn Tasioulas. Artificial Intelligence, Humanistic Ethics. Daedalus, 151(2):232\u2013243, May 2022. ISSN 0011-5266. doi: 10.1162/daed_a_01912. URL https://doi.org/10.1162/daed_a_01912.\"}"}
{"id": "DFr5hteojx", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Vassilis Saroglou, Magali Clobert, Adam B. Cohen, Kathryn A. Johnson, Kevin L. Ladd, Matthieu Van Pachterbeke, Lucia Adamovova, Joanna Blogowska, Pierre-Yves Brandt, Cem Safak \u00c7ukur, Kwang-Kuo Hwang, Anna Miglietta, Frosso Motti-Stefanidi, Antonio Mu\u00f1oz-Garc\u00eda, Sebastian Murken, Nicolas Roussiau, and Javier Tapia Valladares. Believing, Bonding, Behaving, and Belonging: The Cognitive, Emotional, Moral, and Social Dimensions of Religiousness across Cultures. Journal of Cross-Cultural Psychology, 51(7-8):551\u2013575, September 2020. ISSN 0022-0221. doi: 10.1177/0022022120946488. URL https://doi.org/10.1177/0022022120946488. Publisher: SAGE Publications Inc.\\n\\nProlific. Representative samples, February 2024. URL https://researcher-help.prolific.com/hc/en-gb/articles/360019236753-Representative-samples.\\n\\nNils Reimers and Iryna Gurevych. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, August 2019. URL http://arxiv.org/abs/1908.10084. arXiv:1908.10084 [cs].\\n\\nLeland McInnes, John Healy, and James Melville. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction, September 2020. URL http://arxiv.org/abs/1802.03426. arXiv:1802.03426 [cs, stat].\\n\\nAshkan Kazemi, Kiran Garimella, Gautam Kishore Shahi, Devin Gaffney, and Scott A. Hale. Research note: Tiplines to uncover misinformation on encrypted platforms: A case study of the 2019 Indian general election on WhatsApp. Harvard Kennedy School Misinformation Review, January 2022. doi: 10.37016/mr-2020-91. URL https://misinforeview.hks.harvard.edu/article/research-note-tiplines-to-uncover-misinformation-on-encrypted-platforms-a-case-study-of-the-2019-indian-general-election-on-whatsapp/.\\n\\nScott A. Hale. meedan/temporal_clustering, March 2022. URL https://github.com/meedan/temporal_clustering/tree/main.\\n\\nScott D. Emerson, Martin Guhn, and Anne M. Gadermann. Measurement invariance of the Satisfaction with Life Scale: reviewing three decades of research. Quality of Life Research, 26(9):2251\u20132264, September 2017. ISSN 1573-2649. doi: 10.1007/s11136-017-1552-2. URL https://doi.org/10.1007/s11136-017-1552-2.\\n\\nJohn E. Roemer. Theories of distributive justice. Harvard Univ. Press, Cambridge, Mass., 1. harvard univ. press paperback ed edition, 1998. ISBN 978-0-674-87920-1 978-0-674-87919-5.\\n\\nJeremy Bentham. An Introduction to the Principles of Morals and Legislation. In J. H. Burns and H. L. A. Hart, editors, The Collected Works of Jeremy Bentham: An Introduction to the Principles of Morals and Legislation. Oxford University Press, January 1789. ISBN 978-0-19-820516-6. doi: 10.1093/oseo/instance.00077240. URL http://www.oxfordscholarlyeditions.com/view/10.1093/actrade/9780198205166.book.1/actrade-9780198205166-work-1.\\n\\nMarc Lanctot, Kate Larson, Yoram Bachrach, Luke Marris, Zun Li, Avishkar Bhoopchand, Thomas Anthony, Brian Tanner, and Anna Koop. Evaluating Agents using Social Choice Theory, December 2023. URL http://arxiv.org/abs/2312.03121. arXiv:2312.03121 [cs] version: 2.\\n\\nMeriem Boubdir, Edward Kim, Beyza Ermis, Sara Hooker, and Marzieh Fadaee. Elo Uncovered: Robustness and Best Practices in Language Model Evaluation, November 2023. URL http://arxiv.org/abs/2311.17295. arXiv:2311.17295 [cs].\\n\\nSahand Negahban, Sewoong Oh, and Devavrat Shah. Rank Centrality: Ranking from Pairwise Comparisons. Operations Research, 65(1):266\u2013287, 2017. ISSN 0030-364X. URL https://www.jstor.org/stable/26153541. Publisher: INFORMS.\"}"}
{"id": "DFr5hteojx", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We summarise societal impacts and ethical considerations in \u00a7 5, including risks from harmful content, privacy violations and participation-washing (participants not sharing in profits of improved technologies). We expand on these points in our Data Statement (App. B).\\n\\nTo summarise, we (i) pay fair living wages to all participants (App. B and App. J); (ii) we received IRB approval from the University of Oxford and collected informed consent from every participant (App. D); (iv) we check for PII and release all metadata (App. E); (v) we carefully consider licenses and provide a data clause with terms of use (App. C); (vi) we consider and discuss representativeness (App. L); and (vii) we provide detailed documentation of the dataset (App. B).\\n\\n2. If you are including theoretical results...\\n\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n\\n(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes]\\n\\nExperiments for the three case studies presented in the paper are described in detail in the Supplementary Material. We also release all code needed to reproduce results on our Github ([https://github.com/HannahKirk/prism-alignment](https://github.com/HannahKirk/prism-alignment)).\\n\\n(b) Did you specify all the training details (e.g. data splits, hyperparameters, how they were chosen)? [N/A]\\n\\nWe don't train any models per se, but do provide details for our analysis (e.g. hyperparameters for our clustering pipeline) in the Supplementary Material.\\n\\n(c) Did you report error bars (e.g. with respect to the random seed after running experiments multiple times)? [Yes]\\n\\nFor any bootstrapped analysis in the main paper (e.g. Fig. 4) or Supplementary Material (e.g. App. T), we provide error bars.\\n\\n(d) Did you include the total amount of compute and the type of resources used (e.g. type of GPUs, internal cluster, or cloud provider)? [N/A]\\n\\nWe didn't train any compute-intensive models. We accessed existing models via API (see App. P), which was made possible by grants and waived credit costs (as described in Disclosure of Funding). All analysis experiments were run locally on CPU.\\n\\n4. If you are using existing assets (e.g. code, data, models) or curating/releasing new assets...\\n\\n(a) If your work uses existing assets, did you cite the creators? [Yes]\\n\\n(b) Did you mention the license of the assets? [Yes]\\n\\nWe discuss licenses in App. C.\\n\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\n\\nOur dataset and code are linked after the abstract, and at the start of the Supplementary material. The data can be accessed on Github at ([https://github.com/HannahKirk/prism-alignment](https://github.com/HannahKirk/prism-alignment)), and also on HuggingFace at ([https://huggingface.co/datasets/HannahRoseKirk/prism-alignment](https://huggingface.co/datasets/HannahRoseKirk/prism-alignment)). The dataset has a permanent DOI: [10.57967/hf/2113](https://doi.org/10.57967/hf/2113).\\n\\n(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes]\\n\\nWe discuss informed consent in the main paper (\u00a7 2) and provide full details (including consent forms) in the Supplementary material (App. D).\\n\\n(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes]\\n\\nFor every text utterance in our dataset, we conduct automated PII checks (which are then manually inspected) and a moderation classifier for harmful content. We provide full details of this process in App. E, and release all metadata alongside the data entries. We summarise ethical concerns and risks in the main paper (\u00a7 5) and data statement (App. B).\"}"}
{"id": "DFr5hteojx", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes]. Full text of the survey questions and interface instructions is presented in detailed code books (App. V). We also provide interface screenshots (App. Q).\\n\\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [Yes]. We communicate risks to participants in the informed consent form (App. D), for example, the risk of exposure to harmful content via external APIs to LLMs. We received IRB approval. We also describe participant risks in the main paper (\u00a7 5) and data statement (App. B).\\n\\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Yes]. We discuss hourly wage (\u00a39) and task completion time (70 minutes) in the main paper (\u00a7 2). We provide additional detail in our data statement (App. B). We provide estimates of total amount spent on participant compensation in App. J.\"}"}
{"id": "DFr5hteojx", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"PART I: Dataset Details and Distributions\\n\\nA PRISM Data Access and Format\\nB PRISM Data Statement\\nC PRISM Data Clause\\nD Informed Consent\\nE Metadata Processing\\nF Annotating Ethnicity, Religion and Gender\\nG Participant Demographics\\nH Participant Geographies\\nI Participant LLM Usage and Familiarity\\nJ Screening and Recruitment Process\\nK Conversation Type Rebalancing\\nL Census Rebalancing\\nM Text and N-Gram Analysis\\nN Comparing Fine-Grained Preference Attributes\\nO Score Distributions\\nP Details of LLMs-in-the-loop\\nQ Interface Screenshots\\n\\nPART II: Extended Case Study Details\\n\\nR Case Study IA: Topic Clustering and Regressions\\nS Case Study IB: Local Neighbourhoods and Empirically-Fixed Contexts\\nT Case Study II: Aggregating Preference Ratings to Model Ranks\\nU Case Study III: Welfare Analysis\\n\\nPART III: Codebooks\\n\\nV Codebooks\"}"}
{"id": "DFr5hteojx", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The data can be accessed on Github at https://github.com/HannahKirk/prism-alignment, and also on HuggingFace at https://huggingface.co/datasets/HannahRoseKirk/prism-alignment. The dataset has a permanent DOI: 10.57967/hf/2113.\\n\\nThe dataset is organised in two primary JSON lines files:\\n\\n- **The Survey** ([survey.jsonl](#)): The survey where participants answer questions such as their stated preferences for LLM behaviours, their familiarity with LLMs, a self-description and some basic demographics. Each row is a single participant in our dataset, identified by a user_id.\\n\\n- **The Conversations** ([conversations.jsonl](#)): Each participant's multiple conversation trees with LLMs and associated feedback. Each row is a single conversation, identified by a conversation_id, that can be matched back to a participant's survey profile via the user_id. The conversation itself is stored as a list of dictionaries representing human and model turns in the conversation_history column, which broadly follows the format of widely used Chat APIs (see single entry schema on the next page).\\n\\nAdditionally, for ease of secondary analysis we provide a more granular and flattened format of the conversations data:\\n\\n- **The Utterances** ([utterances.jsonl](#)): Each row is a single scored utterance (human input - model response - score). Each row has an utterance_id that can be mapped back to the conversation data using conversation_id or the survey using user_id. The model responses and scores per each user input are in long format. Because of this format, the user inputs will be repeated for the set of model responses in a single interaction turn.\\n\\nWe also provide code for transforming the conversations to a wide format. That is, each row is now a single turn within a conversation. For the first interaction where up to four models respond, we have model_{a/b/c/d} as four distinct columns and score_{a/b/c/d} as another four columns. Note that for subsequent turns, the same model responds and there are only two responses so model/score_{c/d} will always be missing.\\n\\nFinally, for every text instance in PRISM, we provide metadata on the language detection, personal or private information (PII) detection and moderation flags. The Metadata is provided separately to the main data files ([metadata.jsonl](#)).\\n\\nWe provide codebooks for **The Survey** (App. V.1), **The Conversations** (App. V.2), **The Utterances** (App. V.3) and **The Metadata** (App. V.4).\"}"}
{"id": "DFr5hteojx", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Format of Entries in Conversations Data\\n\\n```\\n{\\n    \\\"conversation_id\\\": \\\"c1\\\",\\n    \\\"user_id\\\": \\\"user123\\\",\\n    \\\"conversation_type\\\": [\\\"unguided\\\", \\\"values guided\\\", \\\"controversy guided\\\"],\\n    \\\"opening_prompt\\\": \\\"[USER PROMPT]\\\",\\n    \\\"conversation_turns\\\": [2-22],\\n    \\\"conversation_history\\\": [\\n        {\\n            \\\"turn\\\": 0,\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": \\\"[USER PROMPT]\\\"\\n        },\\n        {\\n            \\\"turn\\\": 0,\\n            \\\"role\\\": \\\"model\\\",\\n            \\\"content\\\": \\\"[MODEL RESPONSE]\\\",\\n            \\\"model_name\\\": \\\"M1\\\",\\n            \\\"model_provider\\\": \\\"P1\\\",\\n            \\\"score\\\": [1-100],\\n            \\\"if_chosen\\\": false,\\n            \\\"within_turn_id\\\": 0\\n        },\\n        {\\n            \\\"turn\\\": 0,\\n            \\\"role\\\": \\\"model\\\",\\n            \\\"content\\\": \\\"[MODEL RESPONSE]\\\",\\n            \\\"model_name\\\": \\\"M2\\\",\\n            \\\"model_provider\\\": \\\"P2\\\",\\n            \\\"score\\\": [1-100],\\n            \\\"if_chosen\\\": true,\\n            \\\"within_turn_id\\\": 1\\n        },\\n        { ... Additional list items for remaining model responses (up to 4 in total) }\\n        {\\n            \\\"turn\\\": 1,\\n            \\\"role\\\": \\\"user\\\",\\n            \\\"content\\\": \\\"[USER PROMPT]\\\"\\n        },\\n        { ... Additional turns follow the same pattern as turn 1 }\\n    ],\\n    \\\"performance_attributes\\\": {\\n        \\\"fluency\\\": [1-100],\\n        \\\"factuality\\\": [1-100],\\n        \\\"helpfulness\\\": [1-100],\\n        { ...Additional attribute ratings }\\n    },\\n    \\\"open_feedback\\\": \\\"[FREE-TEXT]\\\"\\n}\\n```\"}"}
{"id": "DFr5hteojx", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We provide a data statement to document the generation and provenance of P\\\\textsuperscript{RISM}.\\n\\nB.1 Curation Rationale\\nThe P\\\\textsuperscript{RISM} Alignment Project, funded by a variety of academic and industry sources (see Disclosure of Funding), aims to diversify human feedback datasets. All participants are recruited via the Prolific platform. The sample is described in \u00a7 2.3, with additional details in App. J. The primary purpose of the dataset is for academic research into how different people interact with LLMs and perceive their outputs. However, we do not prohibit the use of the dataset to develop, test and/or evaluate AI systems so long as usage complies with the dataset license (App. C.2).\\n\\nB.2 Language Variety\\nThe language of human- or model-written text was not explicitly restricted to English. However, the task instructions were written English, and fluency in English was included as a screening filter. As a result of these factors, 99% of text instances are in English (see App. E for breakdowns per type of text instance and by other language). There is scope for wide social and regional variation even within a language. Given we have speakers residing in 38 countries (born in 75 countries), we likely have various forms of English, especially by level of fluency (see Tab. 5). Information about which varieties of English are represented is not available.\\n\\nB.3 Speaker Demographics\\nThere are two sets of \\\"speaker\\\" roles in P\\\\textsuperscript{RISM}: human participants and large language models (LLMs). Both roles contribute to the characteristics of the text utterances in the dataset.\\n\\nParticipant Characteristics\\nWe provide full demographic breakdowns of participant characteristics in Tab. 5. We provide full geographic breakdowns in Tab. 8. Despite substantial improvements on sample diversity compared to early widely-used human feedback datasets (see Tab. 6, Tab. 7), P\\\\textsuperscript{RISM} still skews White, Educated, and Western. This is partly driven by census-representative samples from the US and UK, which can be removed or downsampled for future research. P\\\\textsuperscript{RISM} only contains participants sourced from one crowdworking platform (Prolific), so inherits sample biases from this narrow pool\u2014for example, participants are active internet users, incentivised by hourly payment on a specific task that they self-select into.\\n\\nModel Characteristics\\nGiven fast-paced changes to the LLM landscape, P\\\\textsuperscript{RISM} is designed to be as model-agnostic as possible. We include 21 models from various different families, capabilities and sizes (for a summary see Tab. 21). 12/21 models are accessed via commerical APIs, and 9/21 are open-access via HuggingFace. Model-specific characteristics will affect the text characteristics, especially if they have already been alignment-tuned.\\n\\nModels as Participants\\nThroughout the study we strongly requested that participants did not use LLMs to write their \\\"human\\\" responses, playing both to their integrity (please don't do it), their role in the research (we really need you to not do it), and their incentives (you won't be paid if you do it). We did not directly test nor implement tools to technologically prevent participants from using LLMs on their behalf. We randomly sample 25 instances from human-written texts: system strings and self-descriptions from the Survey; opening prompts and open feedback from the Conversations (\\\\(n = 100\\\\)). An annotator (paper author) manually inspected these and labelled none as model-written text. For instances of sufficient length (46/100, >50 words), we recorded the predicted probability of AI-generated text from an LLM-text detector, where 76% had \\\\(\\\\leq 1\\\\%\\\\) score. For the remainder (\\\\(n = 11\\\\)), a second annotator (paper author) gave a tie-break, labelling none as model-generated.\\n\\n\\\\footnotetext{10}{The tool is developed by https://sapling.ai/. LLM-detector tools are susceptible to misclassifications. For example, this feedback: \\\"It was good that it offered options and mentioned \\\"options\\\" rather than just suggesting one thing. It would have been better to state in the beginning how dietary requirements and preferences might play a big role in the decision what to cook for dinner. And also to point out how different cultures have different food traditions. Not everything is US based.\\\" was flagged as 88.1% AI-generated, but the human annotators felt was strongly human-generated.}\"}"}
{"id": "DFr5hteojx", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B.4 Annotator Demographics\\n\\nThe \u201cannotators\u201d are \u201cspeakers\u201d\u2014the same human participants who answer the survey, interact with the LLMs, and provide structured and unstructured feedback. See App. B.3.\\n\\nB.5 Speech Situation\\n\\nAll participants were recruited via Prolific. They were paid \u00a39/hour. The survey was hosted on Qualtrics (www.qualtrics.com), and the conversations on Dynabench (www.dynabench.org).\\n\\nAll data was collected between 22nd November 2023 and 22nd December 2023. The time of the data collection period did affect the topics of discussion: for example, one topic concerns Christmas holiday celebrations while another discusses the Israel\u2013Palestine Conflict.\\n\\nThe primary modality of PRIISM is written language, combined with structured ratings or structured survey data. The conversations between participants and LLMs happened synchronously via live API connections with models in the backend of our interface. We have not edited or moderated any survey responses, participant prompts or model responses. All conversations happened as part of this research project, so the primary \u2018intended audience\u2019 was the researchers, though participants were informed of additional plans to distribute and release the data in the consent form (see App. D).\\n\\nB.6 Text Characteristics\\n\\nWe summarise text characteristics in App. M. For the survey responses, the text provides details on the participant and their views about LLMs via short-form free-text responses (we requested 2-5 sentences in their own words). For the conversations, there are three different types: unguided, values guided and controversy guided, as described in the main paper (\u00a7 2.2). Each conversation type contains a different distribution of topics. Overall, PRIISM is skewed towards subjective, values-driven and controversial dialogue. The human-written texts within a conversation typically consist of single sentence prompts, on average 13 words long. Prompts receive up to four model responses generated by a variety of LLMs. We instruct the LLMs to limit their response to 50 words or less. Most unsuccessfully abide by this instruction: the average response length is 89 words. We release metadata (see App. E) with each text instance including information on detected language, automated and manual PII checks and moderation flags (e.g. if it contains sexual, hateful or violent content).\\n\\nB.7 Recording Quality\\n\\nDuring data collection, our interface experienced two distributed denial of service (DDoS) attacks: one on 28th November 2023 and another on 1st December 2023. The primary way that these attacks may have affected recording quality was via interrupting participants\u2019 conversation sessions (most then later returned to the interface to complete their conversations a couple hours or days later). These participants\u2019 data points may differ to those who had a smoother continuous experience in the task.\\n\\nB.8 Author Characteristics and Positionality Statement\\n\\nWe aimed to operate in the subjective paradigm [15, 16] and have as little influence as possible on how participants interacted with models (e.g. no annotation guidelines for how to rate responses). As a team of researchers, we come from a variety of backgrounds (genders, ethnicities, countries of birth, native languages) and are involved with AI research, either in an academia (6/12) or industry (6/12).\\n\\nB.9 Expanded Ethical Considerations\\n\\nPrivacy and deanonymisation\\n\\nThe conversations in PRIISM are highly personal, for example detailing views towards abortion, religion, immigration, workplace disputes or intimate relationships. We have pseudo-anonymised the data, checked for PII (App. E), sought informed consent from every participant (App. D), provided options for participants to withdraw their data, and clearly stipulated that attempts of deanonymisation violate our dataset\u2019s terms and conditions (App. C). However, despite following these best practices, the risk for deanonymisation remains. We include a reporting mechanism on our website and GitHub for any participants and researchers to report issues.\"}"}
{"id": "DFr5hteojx", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Harmful and unsafe content\\n\\nWe asked participants to engage the LLMs in controversial conversations. This comes with the benefit of expanding human preference data to discursive areas with the greatest expected degree of interpersonal disagreement, but at the risk of encouraging hateful, bigoted, biased or otherwise harmful content. Harmful content is an issue in other human feedback datasets, where some opt to moderate conversations prior to public release [113] and others retain toxic content for the purpose of future research into conversational AI safety [112, 111]. Compared to these previous datasets, PRISM has an exceptionally low level of flagged content as measured via the OpenAI moderation API (0.06% overall, and <0.003% for subcategories of sexually-explicit, violent, hateful, self-harm and harassment). However, the recall of this API may be low [111]; so, this could be an underestimate. From examining prompts closest to topic centroids (App. R.2), it is clear there are some prompts with potential for harm. We provide metadata for every text instance in PRISM, and opt to not filter any conversations. We believe it is a critical area of research to understand how state-of-the-art models respond when they are prompted to engage in such conversations, and how different people with diverse lived experiences react to safety interventions.\\n\\nParticipation-washing and intended societal impact\\n\\nIn our setting, we claim what Sloane et al. [55] calls participation as work, that is offering fair remuneration and attribution of the consensual labour of workers contributing to our project. Notably, many participants (those familiar and unfamiliar with AI) contacted the researchers and reported enjoying or learning from the task, suggesting there was an \u201ceducation quotient\u201d or role of participation as experience [53]. Compared to \u201cpassive\u201d participation in annotation tasks or pre-training datasets [33], our process is more active for participants because it foregrounds the opportunity to provide their feedback, opinions and preferences, not just labels. \u201cParticipatory\u201d also signals our goal to have communities more involved in alignment fine-tuning of models and see PRISM as a first step demonstrating this need. These aims evoke notions of participation as justice\u2014including more people at the table of LLM design and development but we note that participation is in reality thin, because while we seek their view, we cannot grant participants the power to change behaviours of deployed LLMs [131]. Even the etymological roots of participation centre on the notion of \u201csharing\u201d [53] but there is no guarantee that the human workers upon whom the success of RLHF relies on, partake in any share of the profits from more usable or preferred LLM technologies. We release PRISM in the hope it moves the needle towards more inclusive and diverse research on human-AI interactions, emphasising the central role of those who contribute their time and voice to generating human feedback data. Ultimately, how these contributions have impact depends on those in power (industry labs, academics, policymakers), because \u201cthe experience of participation must include the sense not only of having spoken, but of having been heard\u201d [p.18, 53].\\n\\nB.10 Expanded Technical and Task Design Limitations\\n\\nThe curse of dimensionality (or intersectionality)\\n\\nOur findings suggest dialogue and model choice are driven somewhat by group affiliation and somewhat by idiosyncratic variance. However, PRISM contains a rich array of information on each participant with both structured and unstructured components. There are endless ways we could have divided the data or understood participant identity, and despite our best efforts to assess sensitivity to design choices, each alternative may have resulted in very different outcomes [120], and we are under-powered to test so many sparse combinations. Using less sparse groupings introduces biases\u2014for example, focusing on region risks lumping together participants from particular geographies as \u201ccultures\u201d [82]. While we split out the UK and US to avoid these countries dominating their respective regions, there remain varying degrees of country-wise entropy in other regions\u2014the Middle East has 94% individuals from Israel, and 100% of Non-US Northern Americans are Canadian (see App. H). Similarly, we use more aggregated ethnicity and religion groupings for statistical power, but amorphous and heterogeneous categories like \u201cOther\u201d have limited or flawed real-world meaning as \u201cOther\u201d contains, for example, both those who identify as Indigenous or First Peoples and as Middle Eastern or Arab. It is an exciting direction for future work to explore free-form characterisations of identity (e.g. the free-text profile or system string) or ex-post groupings of people\u2019s preferences [9], and examine how findings change when we break away from neatly-observed but essentialising demographic traits [133].\\n\\nThe confounding effect of many moving cogs in a conversation\\n\\nBeyond the complexities of inter-sectional identity and idiosyncratic variance of individuals within identity groups, other sources of variance in PRISM present a challenge for controlled experiments; particularly, the high-dimensionality...\"}"}
{"id": "DFr5hteojx", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of what exact topics each participant chooses to talk about, which models randomly get selected in-the-loop, and the stochasticity in their responses from a non-deterministic temperature. It is hard to pin down robust mechanisms of preference differences amongst individuals with so many sources of variation. We opted for choice of input prompt and conversation to be a free parameter in P_RISM as a more naturalistic setting of LLM use and because we wanted to understand dialogue diversity among participants. We do empirically find some regions of fixed prompt-response pairs from individuals who self-select into asking the same prompts as other participants (see App. S.4).\\n\\nNoisy signals and misaligned incentives\\n\\nRelatedly, our conclusions may be confounded by measurement invariance given our explicit focus on subjective, fluid and cardinal devices. This echoes the economist\u2019s view, that it is foolish to rely too heavily on cardinal ratings over ordinal rankings to make interpersonal comparisons, or enforce preference construction, where intrinsic feelings are noisily-quantified on numeric scales. There are also issues of preference falsification: while participants are financially incentivised to participate, they may not honestly report their preferences over models. We cannot rule out the possibility that participants select a \u2018bad\u2019 model to lock in for the subsequent turns of conversation if it is more interesting (thus preferable in our narrow task confines) to talk to a more offensive or controversial model, or to try to \u2018jailbreak it\u2019 [112]. In hindsight, it may have been a smarter design choice to force participants to rank model responses, or to collect both ratings and rankings (notwithstanding decision fatigue), or make attempts to elicit more interpersonally comparable data via a willingness-to-pay monetary unit. Previous work also raises concerns over relying on human feedback as \u2018gold standard\u2019, for example whether participants can accurately rate factuality of an output, or are anchored on formatting and \u2018first impressions\u2019 (as we and Hosking et al. [134] both find). Preferences, especially at a fine-grained level like in P_RISM, have high context-dependency [135], so we caution against taking the ratings as revealing some objective truth, instead staying firmly rooted in the subjective paradigm [15, 2].\\n\\nStill the \u201ctyranny of the (English-speaking) crowdworker\u201d\\n\\nMuch of AI, NLP and now RLHF is underpinned by crowdworker labour [136]. Despite our aims to include more diverse voices in LLM development processes, we avoid overstating claims on diversity. P_RISM still only contains crowdworkers, who have significant sample biases [137]; can only be so \u201crepresentative\u201d given the relatively small sample sizes; must be digital natives given the platformed nature of the work; and possess different incentives for engagement [138]. Furthermore, while P_RISM gains some dialectical diversity from different geographies of English, from varying speaker fluency, and from some contributions in other languages (1%, mainly Spanish), it is almost exclusively in English. Cultural diversity can only be measured so far without also accounting for linguistic diversity [61]. Furthermore, while we try to sample from many regions, our sample is still dominated by White Western participants, especially when considering cultural phylogeny [82], i.e., the non-independence of populations with shared history or migrations of peoples (for example, Australia vs UK vs Canada). We encourage future work prioritising human feedback collection in other languages to understand how models handle sociocultural and linguistic interactions [115].\\n\\nThe ever-changing stream of pre-aligned models\\n\\nWhen data collection began in mid-November, P_RISM contained the top ranking models on publicly available leaderboards but new models have since emerged, including Gemini [139], Mixtral [140], Claude-3 [141], Command-R [142] and Llama-3 [143]. There is an incompatibility between the current pace of model releases and doing human participant research that requires lengthy processes of ethics approval, interface design, data processing and manual annotation. The expense and inconvenience of doing human research increases the attractiveness of simulating responses, usually with GPT-4 [10]. So, while P_RISM does miss out on the newest players to enter the battle arena, we do provide carefully-sourced human data (including a survey which stands independently from the LLM conversations) combined with a wide distribution of model texts; so we hope the utility of the data persists in the coming years even as models change. We are still potentially limited when comparing open and closed-access models: while the former allows full transparency over system prompts, closed-access models can obscure additional instructions as hidden context. Including models from the same family allows comparisons by version or size, but introducing clones (models producing very similar outputs) can distort preference rankings [9]. P_RISM is also limited by value-lock in [108]\u2014the models are already tuned to cultural perspectives or alignment norms [34, 35], which precludes observing certain group preferences towards a wider set of behaviours [37, 144], and renders participants \u201cthin\u201d because they are \u201climited to existing designs with pre-existing purposes.\u201d [p.3, 25].\"}"}
{"id": "DFr5hteojx", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models\\n\\nHannah Rose Kirk\\n\\nAbstract\\n\\nHuman feedback is central to the alignment of Large Language Models (LLMs). However, open questions remain about methods (how), domains (where), people (who) and objectives (to what end) of feedback processes. To navigate these questions, we introduce PRISM, a dataset that maps the sociodemographics and stated preferences of 1,500 diverse participants from 75 countries, to their contextual preferences and fine-grained feedback in 8,011 live conversations with 21 LLMs. With PRISM, we contribute (i) wider geographic and demographic participation in feedback; (ii) census-representative samples for two countries (UK, US); and (iii) individualised ratings that link to detailed participant profiles, permitting personalisation and attribution of sample artefacts. We target subjective and multicultural perspectives on value-laden and controversial issues, where we expect interpersonal and cross-cultural disagreement. We use PRISM in three case studies to demonstrate the need for careful consideration of which humans provide what alignment data.\\n\\nData & Code: github.com/HannahKirk/prism-alignment\\nData & Dataset Card: huggingface.co/datasets/HannahRoseKirk/prism-alignment\\n\\n1 Introduction\\n\\nHuman feedback serves a direct role for the alignment of large language models (LLMs), defined as the steering of AI behaviour towards a set of preferences or values. This increased emphasis on human feedback raises unresolved questions: how we collect human feedback when designing methodologies that rely on ordinal or cardinal scales, broad or fine-grained desiderata, and explicit or implicit signals; where we focus human labour when selecting domains, topics or tasks to collect feedback over; who we ask for feedback when recruiting participants to voice their idiosyncratic preferences, values, or beliefs [1]; and to what end when specifying an objective to pursue personalised alignment [2\u20134] or to aggregate individual preferences into collective outcomes favourable for societies at large [5\u20139].\\n\\nDespite the success of human feedback learning [10, 11], answering these questions is constrained by gaps in existing datasets, such as (i) over-reliance on binary A/B comparisons, without fine-grained ratings or explanations [12]; (ii) small or biased samples recruited from narrow crowdwork or tech communities [10, 13] (iii) limited sample information (annotator IDs or sociodemographics) [14]; and (iv) scarce documentation for how values are operationalised [15, 16]. Most datasets rely only on\\n\\n*{hannah.kirk,scott.hale}@oii.ox.ac.uk\\n\u2020Joint last authors; \u2021Work done at University of Sheffield\"}"}
{"id": "DFr5hteojx", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Human Participants\\n\\nLarge Language Models\\n\\nSurvey Participants\\n\\n1,500\\n\\nConversations\\n\\nTotal Providers 6\\n\\nWith Conversations\\n\\n1,396\\n\\n(93.1%)\\n\\n\u21d2\\n\\nTotal Conversations\\n\\n8,011\\n\\n\u21d0\\n\\nTotal Models\\n\\n21\\n\\nBirth Countries 75\\n\\nUnguided\\n\\n3,113\\n\\n(38.9%)\\n\\nCommercial API\\n\\n12\\n\\n(57.1%)\\n\\nReside Countries 38\\n\\nControversy guided\\n\\n2,438\\n\\n(30.4%)\\n\\nOpen Access\\n\\n9\\n\\n(42.9%)\\n\\nConversations / participant 5.7\\n\\n\u00b1 1.0\\n\\nValues guided\\n\\n2,460\\n\\n(30.7%)\\n\\nConversations / model 1430.9\\n\\n\u00b1 171.1\\n\\nModels seen / participant 13.9\\n\\n\u00b1 2.5\\n\\nTurns / conversation 3.4\\n\\n\u00b1 1.6\\n\\nUnique raters / model 924.3\\n\\n\u00b1 94.4\\n\\nTotal Interactions 27,172\\n\\nTotal Utterances 68,371\\n\\nFigure 1: The PRISM dataset.\\n\\nIn Stage 1, 1,500 participants fill in the Survey detailing their background, familiarity with LLMs and stated preferences over behaviours (\u00a7 2.1). Demographic and geographic breakdowns are in Tab. 5 and Tab. 8). Participants then progress to Stage 2, where they converse with LLMs on topics of their choosing, rate the responses on a cardinal scale, and give fine-grained feedback (\u00a7 2.2). In the first turn, four models respond to the opening prompt (\u00a7 \u00a7). In subsequent turns, the conversation continues with two responses sampled from the highest-rated model at a non-deterministic temperature (\u00a7 \u00a7). There are 8,011 Conversations between participants (\u00a7\u00a7) and LLMs (\u00a7\u00a7), forming 27,172 Interactions (human message with a set of model responses), and 68,371 Utterances (triples of {human message, model response, score}).\\n\\nrevealed or contextual preferences [1], and much attention is devoted to technical or statistical issues in feedback learning [18\u201320], rather than data-centric human factors. Relying on \u2018generic\u2019 human data teaches behaviours which are reductionist because values are relational and non-separable from the person, community or operating context [21\u201323]; and non-generalisable because the indiscriminate aggregation of data subsumes hidden annotator contexts as universalities [24\u201328].\\n\\nWe introduce PRISM, a new resource for navigating empirical questions of human feedback. We employ both the ask and observe principles of social science by mapping detailed survey responses of humans around the world onto their live conversations with LLMs (Fig. 1). This setup permits alignment methods relying on either contextual preference comparisons typical for RLHF [29\u201331], or stated preferences and principles like constitutional AI [6, 32]. In addition to pairing stated and contextual preferences, PRISM has the following features.\\n\\nParticipatory: To ensure wider active participation in alignment data [25, 33], we recruit 1,500 English-speaking crowdworkers from diverse geographies and demographics;\\n\\nRepresentative: As units for preference aggregation, we include two census-representative samples (UK, US);\\n\\nIndividualised: To expose hidden human context and permit personalised preferences, each rating links to a pseudonymous ID and detailed participant profile. We source Subjective and Multicultural perspectives to avoid value-monism and cultural homogenisation in the opinions that LLMs represent [34\u201336] and operate in the descriptive paradigm without guidelines that characterise \u2018good\u2019 responses [15, 16]. Opinion diversity varies along the objective\u2013subjective spectrum (e.g. what is the capital of France? vs. is abortion wrong?), so we prime participants for values and controversy guided dialogues but also collect neutral unguided dialogues as a baseline. To our knowledge, PRISM is the first human feedback dataset to target cross-cultural controversies and value-laden prompts, where interpersonal disagreement is rife. After introducing PRISM (\u00a7 2), we demonstrate its value via three case studies (\u00a7 3): (1) Do different people initiate different discussions with LLMs? (2) Do people prefer differently aligned models, and (3) How do sampling decisions affect welfare outcomes? PRISM provides many more research avenues such as engineers targeting personalised alignment [2] or consensus across opinion distributions [5, 37]; social scientists examining how exposure to LLMs affects public attitudes; or policymakers seeking democratic input on AI-citizen interactions on topics like immigration, abortion or euthanasia.\\n\\nAlignment cannot be neatly bifurcated into technical and normative components [38]. PRISM assists in navigating these complexities with more human voices adjudicating alignment norms.\\n\\n2\\n\\nWe use Contextual Preference for observed ratings of LLM outputs to avoid misrepresenting how Revealed Preference is used by economists\u2014as assumptions that enable the inference of preferences from choices [17].\\n\\n2\"}"}
{"id": "DFr5hteojx", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Schematic of fine-grained attribute ratings. The same attributes appear in three places in our task: A is asked once in the survey; B and C are asked per conversation. For performance attributes, we ask participants to consider only the highest-rated model in the first conversation turn; for choice attributes, we ask them to consider this highest-rated model relative to other models in the first turn.\\n\\nThe PRISM Alignment Dataset maps the characteristics and preferences of diverse humans onto their real-time interactions with LLMs (Fig. 1). Participants complete a Survey (\u00a7 2.1) with questions about their demographics and stated preferences, then proceed to the Conversations with LLMs (\u00a7 2.2), where they input prompts, rate responses and give fine-grained feedback in a series of multi-turn interactions. With the two-stage setup: (i) we avoid over-generalising from a \\\"generic human\\\" by matching ratings to detailed participant characteristics; (ii) we track how contextual preferences (in local conversations) depart from stated preferences (in survey); and (iii) we give participants autonomy to communicate in their own words what is important and why [39, 25]. Both stages received ethics board approval and ran with informed consent (App. D). Participants were paid \u00a39/hour and the task took 70 minutes on average. Data collection ran from 22nd November to 22nd December 2023.\\n\\nWe provide a data statement in App. B, data clause in App. C, and full codebooks detailing each variable in App. V.\\n\\n2.1 The Survey\\nPrior to starting the survey, we ensure that all participants are over 18, obtain their informed consent, give a brief primer on LLMs (or AI language models), and dissuade LLM-written responses. The survey constructs a participant profile containing five features:\\n\\n- **LLM familiarity and usage**\\n  - We ask about participants' familiarity with LLMs (61% are somewhat familiar, 28% very familiar and 10% not familiar at all) and whether to their knowledge they have used them indirectly (in products like LinkedIn post-writing tool); or directly (via a specialised interface like ChatGPT). Individuals that have used LLMs directly or indirectly (84%) are branched to questions on frequency of use (7% every day, 21% every week, and 20% every month) and purpose of use (the most popular tasks are research overviews selected by 49%, professional work by 37%, creative writing by 31% and programming help by 27%). Full results in App. I.\\n- **Self-written system string (\"constitution\")**\\n  - System strings can guide LLM behaviours as a high-level global instruction prompts prepended to all subsequent interactions [40, 41], and have been analogised as \\\"constitutions\\\" or governing principles for AI [32]. Factuality, professionalism, humanness and harmlessness all emerged as key principles (App. M.1) from the following instruction:\\n\\n> Imagine you are instructing an AI language model how to behave. You can think of this like a set of core principles that the AI language model will always try to follow, no matter what task you ask it to perform. In your own words, describe what characteristics, personality traits or features you believe the AI should consistently exhibit. You can also instruct the model what behaviours or content you don't want to see. If you envision the AI behaving differently in various contexts (e.g. professional assistance vs. storytelling), please specify the general adaptations you\u2019d like to see.\\n\\nEthics approval, data collection, and analysis was led by researchers from the University of Oxford.\"}"}
{"id": "DFr5hteojx", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Stated preferences for LLM behaviours\\n\\nIn contrast to this open-ended preference elicitation, we collect structured ratings on fine-grained behaviour attributes. Participants score the importance of each attribute on a visual analog scale [42] (Fig. 2). A statement like \\\"It is important that an AI language model produces factual and informative responses\\\" maps (0,100) where the ends of scale are (Strongly disagree, Strongly agree). Numeric scores are recorded, but not shown to participants to avoid anchoring and dependency biases. We only collect responses to these statements once before participants interact with LLMs but the same attributes appear in the Conversations stage; so, we can track how stated 'abstract' preferences relate to contextual 'in-situ' preferences.\\n\\n4 Overall, we find clusters of subjective attributes (values, creativity and diversity) versus objective attributes (factuality, fluency and helpfulness; App. N.1). While the majority of participants agree that these more objective attributes are important (highly-skewed positive distribution, $\\\\mu \\\\in [86, 89]$, $\\\\sigma \\\\in [14, 16]$), there is little agreement on the meta-importance of subjective attributes (App. N.2). In fact, responses for whether value alignment itself is important follow an almost normal distribution ($\\\\mu = 54$, $\\\\sigma = 26$).\\n\\nSelf-written description\\n\\nValues and preferences are subjective and personal. We ascribe participants autonomy to communicate salient aspects of their identity in a short profile, beyond essentialising associations with structured demographics alone. Honesty, hard work and empathy emerged as common values (App. M.2) from the following instruction:\\n\\nPlease briefly describe your values, core beliefs, guiding principles in life, or other things that are important to you. For example, you might include values you\u2019d want to teach to your children or qualities you look for in friends. There are no right or wrong answers. Please do not provide any personally identifiable details like your name, address or email.\\n\\nBasic demographics\\n\\nWe ask standard demographics: age, gender, employment status, martial status, educational attainment, ethnicity, religious affiliation, English proficiency, country of birth, and country of residence. There is always a \\\"Prefer not to say\\\" option. For gender, participants can select Male, Female, Non-Binary, or self-describe. We collect self-described ethnicity and religion because no pre-set groups exhaust how individuals may self-identify across cultures and global regions. We provide a manual annotation of these strings into aggregated categorisations for statistical analysis (App. F). Because of how we recruit participants (\u00a7 2.3), our sample covers diverse demographics (App. G) and geographies (App. H), with representation from people born in 75 countries. However, the sample still skews White, Western and educated, and only contains English-language speakers.\\n\\n2.2 The Conversations\\n\\nAfter completing the survey, participants move to the second stage, consisting of real-time conversations with LLMs via a custom-built interface on the Dynabench platform [43, 44].\\n\\nSelecting conversation type\\n\\nWe prime participants to diversify their prompts along the objective-subjective spectrum by asking them to complete two conversations across three conditions or conversation types (six in total).\\n\\n- Unguided. Ask, request or talk to the model about anything. It is up to you!\\n- Values guided. Ask, request or talk to the model about something important to you or that represents your values. This could be related to work, religion, family and relationship, politics or culture.\\n- Controversy guided. Ask, request or talk to the model about something controversial or where people would disagree in your community, culture or country.\\n\\nOpening the conversation\\n\\nParticipants construct a free-text prompt of their choosing and receive up to four responses from different LLMs. The participants then rate each response on a visual analogue scale (V AS) [42, 45] from \\\"Terrible\\\" to \\\"Perfect\\\". We record the slider position as a score from 1\u2013100 but do not show participants the number to avoid anchoring or conditional dependence of scores across conversations. We opt for this cardinal feedback for three reasons: (i) it encourages subjectivity; (ii) it permits studying the relative merit of cardinality versus ordinality for reward.\\n\\n4 The survey also has an Other free-text box used by 332 participants (App. N.3), and a personalisation attribute which we do not include in Conversations because models are not personalised.\\n\\n5 Some deviated from this quota (n=6, 2 per type) due to technical difficulties, instruction misunderstanding or losing count; So, we release a balanced subset of the data that controls for this variance (App. K). Though values and controversy guided conversations are typically more subjective than neutral baselines, conversation type does not map perfectly to subjectivity levels. Besides from priming participants via selecting a conversation type, we do not constrain (and seek to minimally influence) participants' topic or prompt choice.\\n\\n6 We do not stream responses because not all models had the functionality. If a model fails or a response takes >30 seconds, we drop this model from the response set and the participant may see <4 responses (App. P).\"}"}
{"id": "DFr5hteojx", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"modelling because ratings can be converted to rankings but not vice versa; (iii) it allows expression of preference intensity above and beyond chosen:rejected pairs.\\n\\nHowever, we acknowledge that the cardinal scale introduces some intrapersonal measurement noise from a more cognitively demanding task and carries less interpersonal comparability than ordinal preferences, see Limitations (\u00a7 5).\\n\\nContinuing the conversation\\n\\nThe highest-scoring LLM from the opening turn is locked into subsequent turns, with random tie-breaks in the case of identical scores. Participants must continue the conversation for at least another turn, but are asked to vary their conversations between 2 and 10 turns to avoid introducing a dataset artefact. We encourage some variation in conversation length ($\\\\mu_T = 3.4$, $\\\\sigma_T = 1.6$) but there is a strong drop off after the second turn (App. O). Participants then rate two responses on a VAS like before, but both are now sampled from the selected model with a non-deterministic temperature. These within-model responses are more similar in style and content than across-model responses (in the first turn), and score deviations are narrower (App. O).\\n\\nCollecting fine-grained feedback\\n\\nAfter the conversation ends, participants first rate statements about the performance of their highest-rated model like \\\"The response was well-written\\\" on a VAS from Performed very poorly to Performed very well, or select N/A if the statement is irrelevant for the context. We then ask participants to consider why they chose this model, rating statements like \\\"I chose this response because it was well-written\\\" on a VAS from Very unimportant to Very important (or select N/A). Attributes are shared with the Survey (Fig. 2). We find strong correlations between performance attributes and choice attributes (except safety) but weak correlations of these pairs to stated preferences given in the Survey, perhaps due to conversational, model or task-design confounders (App. N.1). In general, the distribution of scores over performance and choice attributes is narrower and more positively skewed (bunched to 100) compared to stated preferences (App. N.2).\\n\\nFinally, we collect open-ended natural language feedback on the whole conversation. Participants contributed both content and stylistic feedback ($\\\\mu = 29$ words, $\\\\sigma = 19$, App. M.3).\\n\\nGive some feedback on the conversation as whole. Hypothetically, what would an ideal interaction for you look like here? What was good and what was bad? What (if anything) was missing? What would you change to make it better?\\n\\n2.3 The Sample\\n\\nOur sampling aims were depth in the demographics represented within countries and breadth across global regions. We recruit English-speaking participants from Prolific in two distinct paths:\\n\\nCensus-representative sample (UK, US)\\n\\nSamples matched to simplified census data (age, ethnicity, gender) were only available for the UK and US. The minimum pool size for a statistical guarantee of representativeness was 300, which set a lower bound for participant quota. After collecting data, we observed some skew in our 'representative' samples between observed and expected distributions in recent census data, which we partially correct for (App. L). These samples permit future studies on more representative populations that can be replicated across two countries; however their inclusion biases PIRISM as a whole towards two Western nations already over-represented in AI research.\\n\\nBalanced samples (rest of world)\\n\\nThe distribution of Prolific workers outside the US and the UK skews strongly to Europe and Northern America, and some countries dominate continental counts (App. J). To avoid more active workforces biasing the sample, we set up 33 country-specific studies where there is $>1$ eligible worker, and allocate sample quotas so that each global region is similarly represented.\\n\\nWe balance each national sample by gender where possible (Tab. 10).\\n\\nIncluded models\\n\\nThe rapidly evolving landscape necessitates a model-agnostic approach to avoid data staleness. We include 21 different LLMs (9 open-access, 12 commercial-API) from various model families and parameter sizes, which diversifies the training data, capabilities, and degree of existing safeguards or alignment biases. To avoid text length confounding preferences [46] and to reduce participant fatigue, we include system prompts instructing models to limit their responses to $\\\\leq 50$ words. We show the full list of models, decoding parameters and generation details in App. P.\\n\\n7 For example, all responses could be very poor and similar (negative skew, small spread); all very good and similar (positive skew, small spread); or highly-distinguishable (no skew, wide spread).\\n\\n8 Participants still appear in our sample who were born or reside in countries that did not have a dedicated country-wise study e.g. if their Prolific details were outdated or incorrect. We do not drop them.\"}"}
{"id": "DFr5hteojx", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3 Experiments with PRISSM\\n\\n3.1 Case Study I: Do Different People Initiate Different Discussions with LLMs?\\n\\nMethods\\nWe use a pre-trained sentence transformer (all-mpnet-base-v2) to embed each opening prompt in 768-D, then apply UMAP to reduce to 20-D, before clustering with HDBScan [47]. 70% of prompts are assigned to 22 topic clusters and 30% remain as outliers. We name each cluster by prompting gpt-4-turbo with the top n-grams extracted with TF-IDF and closest texts to the cluster centroid. We define an over-representation factor as \\\\[ \\\\frac{N_{g,t}}{N_{t,b}} \\\\], to compute observed versus expected topic prevalence per identity group. For the partial contribution of identity attributes, we estimate an OLS regression for each topic \\\\( y_t (t \\\\in 1,...,22) \\\\) and cluster standard errors at the individual level:\\n\\n\\\\[\\ny_{j,i,c} = \\\\alpha_t + \\\\text{gender}^t \\\\beta_1 + \\\\text{age}^t \\\\beta_2 + \\\\text{birth_region}^t \\\\beta_3 + \\\\text{ethnicity}^t \\\\beta_4 + \\\\text{religion}^t \\\\beta_5 + \\\\text{prompt}^t \\\\beta_6 + \\\\epsilon_{i,c},\\n\\\\]\\n\\nwhere \\\\( y_{t,i,c} = 1 \\\\) if the prompt of participant \\\\( i \\\\) in conversation \\\\( c \\\\) is categorized as topic \\\\( t \\\\). The identity vectors (e.g. gender) represent sets of variables, with a base category removed (indicated in Fig. 3). The coefficients of interest are contained in vectors \\\\( \\\\{ \\\\beta_t^d \\\\}_{d=1}^6 \\\\), where component \\\\( g \\\\) of \\\\( \\\\beta_t^d \\\\) is interpreted as the increase in probability of a participant choosing topic \\\\( t \\\\) if they are in the group indexed by \\\\( g \\\\) (e.g. Female) compared to the base group (e.g. Male). See App. R for extended methods.\\n\\nResults\\nOur instructions had a significant priming effect, resulting in a high density of controversial and value-laden topics (Fig. 3). Topics significantly correlated with controversy guidance are Gender & LGBTQ+ Identity, Israel\u2013Palestine Conflict, and Discussions on Abortion, while topics significantly correlated with the values guidance are Managing Relationships, Job Search, and Religion & Spirituality. In contrast, the 'unguided' condition correlates with task-oriented and\"}"}
{"id": "DFr5hteojx", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"neutral topics like Popular Culture, Recipes & Cooking and Travel Recommendations. Only Climate Change is not significantly correlated to conversation type. Controlling for conversation type, 11% of coefficients are significant ($\\\\alpha = 99\\\\%$); so, identity factors have some predictive power on topic prevalence. Significant relationships include: women and non-binary people discuss gender and LGBTQ+ issues more than men; older people discuss elections and travel more than younger people; Black participants discuss climate change less than White participants, and all regions question LLMs about abortion less often than US participants. When we examine granular regions in embedding space using a single-link hierarchical clustering algorithm (App. S), local prompt neighbourhoods tend to be intersectionally-diverse: 84% of them meet or exceed entropy across intersectional demographics that would be expected under random sampling. During this local exploration, we retrieve regions of semantically-identical prompts rated by multiple diverse individuals (e.g. one neighbourhood \u201cDoes God exist?\u201d has 7 religious and 7 irreligious participants), finding that interpersonal differences in contextual preferences persist even when dialogue context is fixed (App. S.4). So, despite PRISM containing semantically-diverse prompts, people from different backgrounds occupy common discussion spaces, providing an anchor to examine diverse perspectives to shared issues.\\n\\n3.2 Case Study II: Do Different People Prefer Differently-Aligned Models?\\n\\nMethods\\n\\nObserved preference differences at the model-level are confounded by interactions of topic prevalence and model aptitude (e.g. men ask more about aliens and gpt-4 is poor on extraterrestrial knowledge). Evidence of shared dialogue spaces (\u00a7 3.1) and group-topic score differences (App. T.2) mitigate some concern, but to further control for context, we use opening prompts from the balanced subset of participants ($n=1,246$) with equal conversations per type ($n=6,669$). The mean participant rates 14/21 LLMs but unseen ratings are missing at random. Our aggregation (social choice) function over participant ratings is derived from Pairwise Rank Centrality ($P\\\\text{Rank}$) [48] and Convergence Voting [49], both inspired by PageRank [50]. Each model is a node in a graph and transition probabilities between nodes are calculated by the proportion of pairwise battle wins. This process simulates a random walk on a Markov chain, leading to a stationary distribution of scores that reflect the collective preference intensity across models. Here, we compute $P\\\\text{Rank}$ over subsamples using a regularisation parameter of 1 and tie threshold of 5, but present extended methods and robustness checks in App. T.\\n\\nResults\\n\\nWe find rankings are sensitive to idiosyncratic, contextual, and group-wise variance. Samples of 100 people introduce significant noise, resulting in a fairly even distribution of collective preference among the top 10 models (Fig. 4). Rankings are sensitive to what participants talk about: zephyr-7b performs highly on controversy but not in unguided domains, while claude-2 has the opposite trend; and where they are from: relative to overall rank, palm-2 drops 4 places for participants in the US, llama-7b drops 7 places in Asia, while mistral-7b gains 7 places in Africa.\\n\\nWe further observe that $P\\\\text{Rank}$ produces surprising ranks relative to other leaderboards. We apply our method to CHATBOT data [51], finding gpt models fare significantly worse in $P\\\\text{Rank}$, while open models like zephyr-7b do significantly better (95% CI over 1,000 bootstraps, App. T.9). This may be due to domain shift (task-orientated/coding prompts vs. controversial/cultural prompts), sample diversity or task incentives. To identify drivers of score differences, we generate hypotheses by qualitatively examining battles between command and gpt-4/-turbo, then test these with an OLS regression on all model responses (App. T.8). We find that formatting and refusals partially explain score differences with significant positive effects from additional characters, ending in a question mark (\u201cWould you like to know more?\u201d) and enumeration, but significant negative effect of line breaks. De-anthropomorphic phrases (\u201cAs an AI, I don\u2019t have personal opinions.\u201d) significantly reduce score but not as substantially as refusals (\u201cSorry I cannot engage.\u201d). The proportion of explained variance in score by these factors is low ($R^2 = 0.06$), so we encourage more sophisticated methods in future work for partialling out the effect of style versus content, or participant, model and conversation fixed-effects, as determinants of score.\\n\\n3.3 Case Study III: How do Sampling Decisions Affect Welfare Outcomes?\\n\\nMethods\\n\\nWe use \u2018welfare\u2019 to capture the extent to which a chosen LLM aligns with the preferences of a user population. We consider two welfare measures: average model rating (MEAN RATING), and average likelihood that a model is chosen (rated highest in the opening turn, MEAN CHOICE). Previous experiments indicate dialogue and preference diversity across people, suggesting that the welfare of downstream LLM users may depend on who provides feedback. To test this, we first randomly generate seven sub-samples of individuals \u2018in the seat of power\u2019 to select their favourite LLM (based...\"}"}
{"id": "DFr5hteojx", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Key results\\n\\nRegardless of the model chosen, a large proportion of groups from the full US sample. Furthermore, average measures can conceal the welfare of minority group tends to reduce the welfare of out-group individuals. We find that larger samples from the target sub-population appear to first order stochastically dominate smaller samples from the target sub-population.\\n\\nFigure 4: Pairwise Rank Centrality scores for 100 randomly-drawn participants (over 1,000 bootstraps). For Panels B and C, we show rank changes by N on mean rating. Four sampling schemes randomly draw from a specific (FOSD) smaller samples from the target sub-population. (Panel A,C) and what they talk about (B). Rankings differ from other leaderboards, explained by P.\\n\\nResults\\n\\nExperiment for the UK and US representative samples. Extended methods are in App. U.\\n\\nControversy\\n\\n...\"}"}
{"id": "DFr5hteojx", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 5: Welfare distributions for the US. The distribution of mean welfare for four subpopulations in the US (welfare pop) induced by seven sampling schemes (in the seat of power). The y axis is the sampled supopulation (e.g. Rep is a 'representative' sample of the population) and sample size in brackets (e.g. (100)). Each violin shows the distribution of mean welfare for the panel's subpopulation induced by a sampling scheme. The top four Rating comparisons use the MEAN RATING welfare measure and the bottom Choice comparisons use the MEAN CHOICE welfare measure. The red distributions are FOSD by Rep (100) in blue (i.e. less optimal scheme).\\n\\nKey results (\u00a7 3.3): Large representative samples mostly outperform smaller or demographically-restricted samples and sampling exclusively from a specific group tends to reduce the welfare of out-group participants (male vs. non-male, white vs. non-white). No single model achieves majority preference (max 45% MEAN CHOICE). \\n\\nIf a participant is shown the winning model, and three other models at random, the probability that they will choose the winning model is < 50%. The probability they will pick the winning model over all other 20 LLMs can only be lower. This suggests that we should not expect a single LLM to satisfy everyone's preferences in a given population. We repeat the welfare analysis for the UK sample and conduct robustness checks with imputed missing data in App. U.\\n\\n4 Related Work\\n\\nParticipation & Representation in Science & Technology\\n\\nThere is a long history of technologies failing diverse users who lack consultation during design [52\u201354]. Conscious participation can be intrinsically valuable as an act of justice [55, 56]. However, in internet-harvested pre-training data, participation is involuntary or cooptative [55, 33], and unequal representation risks cultural homogenisation and minority stereotyping [57\u201362]. Labelling data or giving feedback is active procedural participation [53] but often relies on narrow specifications from technology providers of what counts as high-quality language or preferable outputs [15, 16, 63, 64]. In ML or NLP data, variability in subjective experience is commonly collapsed into majority votes [27, 65\u201368], without sufficient documentation of annotator artefacts or disagreements [69\u201373], despite evidence that sociodemographics affect labels [74\u201379]. Multiple scientific fields are guilty of over-generalising conclusions from the 'generic human' drawn from 'WEIRD' societies [80, 81]. PRISM releases participant IDs and characteristics to spotlight sample diversity while acknowledging sample specificity [82].\\n\\nLearning from Human Feedback\\n\\nUsing human feedback to condition the loss function for training LLMs overcomes challenges of specifying rewards [83\u201385]. Combining human feedback, reinforcement learning, and environmental manipulation may be a step towards a more reflexive form of condition learning [86\u201388]. The above problems may be mitigated if LLMs are conditioned on human preferences along with data [89\u201391].\"}"}
{"id": "DFr5hteojx", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ment learning and natural language generation has a history in machine translation [86\u201388] and dialogue [89\u201394]. RLHF pipelines rely on binary comparisons [29\u201331, 85], principles or rules [32, 95], fine-grained feedback [12], or natural language [96], to reward dimensions like helpfulness, honesty and harmlessness [97, 30]. Reward models then update LLMs via algorithms like PPO [98] or Reinforce [99, 100]; but reward model free techniques are competitive, e.g. DPO [18], supervised fine-tuning [101] and rejection sampling [102, 5, 103]. There is rising demand for high-quality human feedback [104, 105], but the complexity and cost of collecting data incentivises scraping preferences, e.g. on Reddit [29, 106] or StackOverflow [107], or simulating humans with LLMs [108\u2013110]. Similar to P RISM, C HATBOT A RENA [51], L MSYS-1 [111] and W ILD C HAT [112] feature user-rated model interactions, but for narrow communities (HuggingFace Spaces) and domains (coding, task-orientated). Unlike these datasets, O PENCONVOS [113] collect optional contributor demographics, and D ICES [79] provide demographics for multiple raters per conversation. Other datasets target specific behaviours [30, 114], or multilingual coverage [115]. Surveys on attitudes towards AI [116, 117] and community assemblies [6, 118, 119] offer another lens on public priorities.\\n\\nTo our knowledge, P RISM is the first to link preference ratings and detailed survey responses.\\n\\n5 Limitations, Discussions and Conclusions\\n\\nEthical Considerations and Limitations\\n\\nWe collect informed consent, pseudononymise IDs, check for PII (App. E) and disallow deanonymisation in our terms (App. C), but privacy risks remain, especially given the sensitive nature of conversations. Asking participants to engage with controversies expands human preference data to discursive areas with the greatest expected degree of interpersonal disagreement, but risks encouraging hateful, bigoted, biased or otherwise harmful content. P RISM is less toxic than previous datasets (0.06%, App. E). We do not moderate prior to release to permit conversational safety research. There are many sources of variance in P RISM and alternative divisions of the data may yield different outcomes [120]. Granting free choice of dialogue, using cardinal feedback scales and focusing on many kinds of models and participants introduces diversity and subjective freedom but complicates controlled experiments and limits statistical power. P RISM is still biased towards English-speaking crowdworkers whose task-specific incentives may not align with wider populations. We expand on ethical risks and limitations in our data statement (App. B).\\n\\nWe raise three discussion points on the boundaries of where we collect preferences, for what end and with what lasting impact. First, aligning LLMs via \u2018preference-based utilitarianism\u2019 [121] may not be synonymous with individual or societal well-being, prompting the question of whether there are limits for \u201clegitimate\u201d human feedback. Preferences may be (i) at odds with self-interest due to myopia or information asymmetries (e.g. participants who want anthropomorphic LLMs despite evidenced harms [122\u2013126]) or (ii) incompatible with others\u2019 interest (e.g. participants who prefer \u2018anti-woke\u2019 LLMs that argue in a debate vs. those who favour neutrality). Relying on decontextualized preference observations carries the risk of silently reinforcing biases from those in power [61, 65]; so we recommend transparency surrounding individual disagreements before aggregation decisions [9, 127], especially if participant positionality affects their epistemic legitimacy to define harm [59, 128, 129]. Second, irreconcilable personal preferences and morals matter more when the \u2018unit of alignment\u2019 is operationalised as a group, culture or even species, rather than an individual. P RISM permits personalised or steerable alignment using participant profiles and specific ratings [2\u20134, 37] as well as collective alignment via opinion consensus or distribution of rewards [5\u20138, 28]; though group deliberation in groups may yield different outcomes than gathering data from one person at a time [6, 118, 119]. With growing use of synthetic alignment data, P RISM can assist in calibrating LLM-as-judge protocols to more diverse rater pools [51, 130]. Finally, P RISM was motivated by participation as justice via inclusionary alignment practices that, relative to passive roles in annotation tasks or pre-training data, prioritise active input from local citizens with specialised knowledge of their own and communities\u2019 needs [55]. However, participation remains thin because the humans crucial to the success of RLHF do not typically share in downstream benefits or profits [33, 131]. Ultimately, the impact of our work depends on those developing, researching and regulating LLMs because effective participation requires being asked and being heard [53].\\n\\nIn their early demonstrations of aligning AI systems to human feedback, Bai et al. discuss alignment data as a public good. We echo this sentiment with P RISM\u2014a new feedback dataset from 1,500 diverse humans, motivated by the need for inclusive, participatory and open scientific research into the pressing question of what it means to align LLMs to human preferences in a pluralistic world.\"}"}
{"id": "DFr5hteojx", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments and Disclosure of Funding\\n\\nThis project was awarded the MetaAI Dynabench Grant \u201cOptimising feedback between humans-and-models-in-the-loop\u201d. For additional compute support, the project was awarded the Microsoft Azure Accelerating Foundation Model Research Grant. For additional annotation support, we received funding from the OpenPhil grant and NSF grant (IIS-2340345) via New York University. We are grateful for support received in the form of research access or credits from OpenAI, Anthropic, Aleph Alpha, Google, HuggingFace and Cohere. Hannah Rose Kirk\u2019s PhD is supported by the Economic and Social Research Council grant ES/P000649/1. Paul R\u00f6ttger is a member of the Data and Marketing Insights research unit of the Bocconi Institute for Data Science and Analysis, and is supported by a MUR FARE 2020 initiative under grant agreement Prot. R20YSMBZ8S (INDOMITA). Andrew Bean\u2019s PhD is supported by the Clarendon Fund Scholarships at the University of Oxford. We are particularly grateful to Maximilian Kasy for his valuable input and advise on the welfare experiments. We are indebted to the incredible effort and time that our Prolific annotators put into our task, as well as the expert advice from Prolific consultant Andrew Gordon. We also thank any Beta testers, including friends, family and colleagues at Oxford and New York University, for their help in piloting (and debugging!) our task. Lastly, we thank Jakob M\u00f6kander, Nathan Lambert, Natasha Jacques, Felix Simon, Nino Scherrer, Maximilian Kroner Dale, and Saffron Huang for their feedback on the paper. We use scientific colour maps in our figures [132].\\n\\nAuthor Contribution Statement\\n\\nProject Conception\\n\u2022 [KIRK, HALE, VIDGEN]\\n\\nData Collection Design\\n\u2022 [KIRK, HALE, VIDGEN, R\u00d6TTGER, ARGATINA]\\n\\nFrontend Design and Development\\n\u2022 [KIRK, IRO]\\n\\nBackend Design and Development\\n\u2022 [KIRK, MOSQUERA]\\n\\nAnalysis Advisory\\n\u2022 [HALE, VIDGEN, R\u00d6TTGER, ARTOLO, BEAN, WILLIAMS, HE]\\n\\nLiterature and Dataset Comparison\\n\u2022 [KIRK, BEAN]\\n\\nMetadata Processing\\n\u2022 [KIRK, ARGATINA, BEAN]\\n\\nManual Annotation\\n\u2022 [KIRK, BEAN, R\u00d6TTGER, ARTOLO]\\n\\nResults and Codebase\\n\u2022 [KIRK, WITIVEFIELD]\\n\\nManuscript Writing\\n\u2022 [KIRK, WITIVEFIELD]\\n\\nManuscript Editing and Feedback\\n\u2022 [EVERYONE]\\n\\nReferences\\n\\n[1] Iason Gabriel. Artificial Intelligence, Values and Alignment. Minds and Machines, 30(3):411\u2013437, September 2020. ISSN 0924-6495, 1572-8641. doi: 10.1007/s11023-020-09539-2.\\n\\n[2] Hannah Rose Kirk, Bertie Vidgen, Paul R\u00f6ttger, and Scott A. Hale. The benefits, risks and bounds of personalizing the alignment of large language models to individuals. Nature Machine Intelligence, pages 1\u201310, April 2024. ISSN 2522-5839. doi: 10.1038/s42256-024-00820-y. URL https://www.nature.com/articles/s42256-024-00820-y. Publisher: Nature Publishing Group.\\n\\n[3] Joel Jang, Seungone Kim, Bill Yuchen Lin, Yizhong Wang, Jack Hessel, Luke Zettlemoyer, Hannaneh Hajishirzi, Yejin Choi, and Prithviraj Ammanabrolu. Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging, October 2023. URL http://arxiv.org/abs/2310.11564. arXiv:2310.11564 [cs].\\n\\n[4] Xinyu Li, Zachary C. Lipton, and Liu Leqi. Personalized Language Modeling from Personalized Human Feedback, February 2024. URL http://arxiv.org/abs/2402.05133. arXiv:2402.05133 [cs].\\n\\n[5] Michiel A. Bakker, Martin J. Chadwick, Hannah R. Sheahan, Michael Henry Tessler, Lucy Campbell-Gillingham, Jan Balaguer, Nat McAleese, Amelia Glaese, John Aslanides, Matthew M. Botvinick, and Christopher Summerfield. Fine-tuning language models to find agreement among humans with diverse preferences. In Advances in neural information processing systems, volume 35, pages 38176\u201338189. Curran Associates, Inc., November 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/f978c8f3b5f399cae464e85f72e28503-Paper-Conference.pdf. _eprint: 2211.15006v1.\\n\\n[6] Anthropic. Collective Constitutional AI: Aligning a Language Model with Public Input. Technical report, 2023. URL https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input.\"}"}
{"id": "DFr5hteojx", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "DFr5hteojx", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[44] Tristan Thrush, Kushal Tirumala, Anmol Gupta, Max Bartolo, Pedro Rodriguez, Tariq Kane, William Gaviria Rojas, Peter Mattson, Adina Williams, and Douwe Kiela. Dynatask: A Framework for Creating Dynamic AI Benchmark Tasks. In Valerio Basile, Zornitsa Kozareva, and Sanja Stajner, editors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 174\u2013181, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-demo.17. URL https://aclanthology.org/2022.acl-demo.17.\\n\\n[45] R. C. Aitken. Measurement of feelings using visual analogue scales. Proceedings of the Royal Society of Medicine, 62(10):989\u2013993, October 1969. ISSN 0035-9157. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1810824/.\\n\\n[46] Prasann Singhal, Tanya Goyal, Jiacheng Xu, and Greg Durrett. A Long Way to Go: Investigating Length Correlations in RLHF, October 2023. URL http://arxiv.org/abs/2310.03716. arXiv:2310.03716 [cs].\\n\\n[47] Ricardo J. G. B. Campello, Davoud Moulavi, and Joerg Sander. Density-Based Clustering Based on Hierarchical Density Estimates. In Jian Pei, Vincent S. Tseng, Longbing Cao, Hiroshi Motoda, and Guandong Xu, editors, Advances in Knowledge Discovery and Data Mining, Lecture Notes in Computer Science, pages 160\u2013172, Berlin, Heidelberg, 2013. Springer. ISBN 978-3-642-37456-2. doi: 10.1007/978-3-642-37456-2_14.\\n\\n[48] Sahand Negahban, Sewoong Oh, and Devavrat Shah. Iterative ranking from pairwise comparisons. In Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012. URL https://papers.nips.cc/paper_files/paper/2012/hash/9adeb82fffb5444e81fa0ce8ad8afe7a-Abstract.html.\\n\\n[49] Gergei Bana, Wojciech Jamroga, David Naccache, and Peter Y. A. Ryan. Convergence Voting: From Pairwise Comparisons to Consensus, March 2021. URL http://arxiv.org/abs/2102.01995. arXiv:2102.01995 [cs].\\n\\n[50] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The PageRank Citation Ranking: Bringing Order to the Web., November 1999. URL http://ilpubs.stanford.edu:8090/422/?doi=10.1.1.31.1768. Type: Techreport.\\n\\n[51] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. Advances in Neural Information Processing Systems, 36:46595\u201346623, December 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html.\\n\\n[52] Safiya Umoja Noble. Algorithms of oppression: how search engines reinforce racism. New York University Press, New York, 2018. ISBN 978-1-4798-4994-9 978-1-4798-3724-3.\\n\\n[53] Christopher M. Kelty. The Participant \u2013 A Century of Participation in Four Stories. The University of Chicago press, Chicago (Ill.) London, 2019. ISBN 978-0-226-66662-4 978-0-226-66676-1.\\n\\n[54] Caroline Criado-Perez. Invisible women: exposing data bias in a world designed for men. Chatto & Windus, London, 2019. ISBN 978-1-78474-172-3 978-1-78474-292-8.\\n\\n[55] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. Participation Is not a Design Fix for Machine Learning. In Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO '22, pages 1\u20136, New York, NY, USA, October 2022. Association for Computing Machinery. ISBN 978-1-4503-9477-2. doi: 10.1145/3551624.3555285. URL https://dl.acm.org/doi/10.1145/3551624.3555285.\\n\\n[56] Travis Greene, Copenhagen Business School, Galit Shmueli, National Tsing Hua University, Soumya Ray, and National Tsing Hua University. Taking the Person Seriously: Ethically Aware IS Research in the Era of Reinforcement Learning-Based Personalization. Journal of the Association for Information Systems, 24(6):1527\u20131561, 2023. ISSN 15369323. doi: 10.17705/1jais.00800. URL https://aisel.aisnet.org/jais/vol24/iss6/6/.\"}"}
{"id": "DFr5hteojx", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. WebGPT: Browser-assisted question-answering with human feedback. December 2021. URL http://arxiv.org/abs/2112.09332v3.\\n\\nAbeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963, 2021.\\n\\nRuha Benjamin. Race After Technology: Abolitionist Tools for the New Jim Code. John Wiley & Sons, July 2019. ISBN 978-1-5095-2643-7.\\n\\nSu Lin Blodgett, Solon Barocas, Hal Daum\u00e9 III, and Hanna Wallach. Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5454\u20135476, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.485. URL https://aclanthology.org/2020.acl-main.485.\\n\\nDaniel Hershcovich, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, Constanza Fierro, Katerina Margatina, Phillip Rust, and Anders S\u00f8gaard. Challenges and Strategies in Cross-Cultural NLP. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6997\u20137013, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.482. URL https://aclanthology.org/2022.acl-long.482.\\n\\nWenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng Tu, and Michael R. Lyu. Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models, February 2024. URL http://arxiv.org/abs/2310.12481. arXiv:2310.12481 [cs] version: 2.\\n\\nSuchin Gururangan, Dallas Card, Sarah K. Dreier, Emily K. Gade, Leroy Z. Wang, Zeyu Wang, Luke Zettlemoyer, and Noah A. Smith. Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection, January 2022. URL http://arxiv.org/abs/2201.10474. arXiv:2201.10474 [cs].\\n\\nJosh Dzieza. Inside the AI Factory, June 2023. URL https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots.\\n\\nShakir Mohamed, Marie-Therese Png, and William Isaac. Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence. Philosophy & Technology, 33(4):659\u2013684, December 2020. ISSN 2210-5441. doi: 10.1007/s13347-020-00405-8. URL https://doi.org/10.1007/s13347-020-00405-8.\\n\\nMassimo Airoldi. Machine habitus: toward a sociology of algorithms. Polity Press, Cambridge ; Medford, MA, 2022. ISBN 978-1-5095-4327-4 978-1-5095-4328-1. OCLC: on1247827618.\\n\\nZeerak Talat, Hagen Blix, Josef Valvoda, Maya Indira Ganesh, Ryan Cotterell, and Adina Williams. On the Machine Learning of Ethical Judgments from Natural Language. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 769\u2013779, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.56. URL https://aclanthology.org/2022.naacl-main.56.\\n\\nMark D\u00edaz, Ian Kivlichan, Rachel Rosen, Dylan Baker, Razvan Amironesei, Vinodkumar Prabhakaran, and Emily Denton. CrowdWorkSheets: Accounting for Individual and Collective Identities Underlying Crowdsourced Dataset Annotation. In 2022 ACM Conference on Fairness, Accountability, and Transparency, FAccT '22, pages 2342\u20132351, New York, NY, USA, June 2022. Association for Computing Machinery. ISBN 978-1-4503-9352-2. doi: 10.1145/3531146.3534647. URL https://doi.org/10.1145/3531146.3534647.\\n\\nEmily M. Bender and Batya Friedman. Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science. Transactions of the Association for Computational Linguistics, 6:587\u2013604, 2018. doi: 10.1162/tacl_a_00041. URL https://aclanthology.org/Q18-1041.\\n\\nMargaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. Model Cards for Model Reporting. Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT* '19, pages 220\u2013229, 2019. doi: 10.1145/3287560.3287596. URL http://arxiv.org/abs/1810.03993. arXiv: 1810.03993.\"}"}
{"id": "DFr5hteojx", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C.1 Terms of Use\\n\\nPurpose\\nThe Dataset is provided for the purpose of research and educational use in the field of natural language processing, conversational agents, social science and related areas; and can be used to develop or evaluate artificial intelligence, including Large Language Models (LLMs).\\n\\nUsage Restrictions\\nUsers of the Dataset should adhere to the terms of use for a specific model when using its generated responses. This includes respecting any limitations or use case prohibitions set forth by the original model\u2019s creators or licensors.\\n\\nContent Warning\\nThe Dataset contains raw conversations that may include content considered unsafe or offensive. Users must apply appropriate filtering and moderation measures when using this Dataset for training purposes to ensure the generated outputs align with ethical and safety standards.\\n\\nNo Endorsement of Content\\nThe conversations and data within this Dataset do not reflect the views or opinions of the Dataset creators, funders or any affiliated institutions. The dataset is provided as a neutral resource for research and should not be construed as endorsing any specific viewpoints.\\n\\nNo Deanonymisation\\nThe User agrees not to attempt to re-identify or de-anonymise any individuals or entities represented in the Dataset. This includes, but is not limited to, using any information within the Dataset or triangulating other data sources to infer personal identities or sensitive information.\\n\\nLimitation of Liability\\nThe authors and funders of this Dataset will not be liable for any claims, damages, or other liabilities arising from the use of the dataset, including but not limited to the misuse, interpretation, or reliance on any data contained within.\\n\\nC.2 Licence and Attribution\\nHuman-written texts (including prompts) within the dataset are licensed under the Creative Commons Attribution 4.0 International License (CC-BY-4.0). Model responses are licensed under the Creative Commons Attribution-NonCommercial 4.0 International License (CC-BY-NC-4.0). Use of model responses must abide by the original model provider licenses.\\n\\nFor proper attribution when using this dataset in any publications or research outputs, please cite with the DOI.\\n\\nSuggested Citation: Kirk, H. R., Whitefield, A., R\u00f6ttger, P., Bean, A., Margatina, K., Ciro, J., Mosquera, R., Bartolo, M., Williams, A., He, H., Vidgen, B., & Hale, S. A. (2024). The PRISM Alignment Dataset. https://doi.org/10.57967/hf/2113\\n\\nC.3 Dataset Maintenance\\nAs the authors and maintainers of this dataset, we commit to no further updates to the dataset following its initial release. The dataset is self-contained and does not rely on external links or content, ensuring its stability and usability over time without the need for ongoing maintenance.\\n\\nC.4 Data Rights Compliance and Issue Reporting\\nWe are committed to complying with data protection rights, including but not limited to regulations such as the General Data Protection Regulation (GDPR). If any individual included in the dataset wishes to have their data removed, we provide a straightforward process for issue reporting and resolution on our Github. Concerned parties are encouraged to contact the authors directly via the provided contact form link on the Github. Upon receiving a request, we will engage with the individual to verify their identity and proceed to remove the relevant entries from the dataset. We commit to addressing and resolving such requests within 30 days of verification.\"}"}
{"id": "DFr5hteojx", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Informed Consent\\n\\nThis research was reviewed by, and received ethics clearance through, a subcommittee of the University of Oxford Central University Research Ethics Committee [OII_C1A_23_088]. The following text was displayed to all participants to collect informed consent.\\n\\nYour Feedback on AI Language Models\\n\\nWe appreciate your interest in participating in this study. The aim of this research is to understand people's preferences and perceptions regarding AI Language Model behaviors, also referred to as Large Language Models (LLMs), Generative AI Language Models, AI ChatBots or Virtual Assistants. AI language models are computer programs designed to generate text. They can respond to questions or prompts by producing written responses. We want to learn more about how people like you use and perceive these AI language models.\\n\\nPlease first make sure you are using a laptop or desktop computer, and you are not using a mobile device. Our task is NOT compatible with mobile devices.\\n\\nPlease then read through this information before agreeing to participate (if you wish to).\\n\\nYou may ask any questions before deciding to take part by contacting the research team. The Principal Researcher is Hannah Rose Kirk, and the Principle Investigator is Dr Scott. A. Hale, who are both affiliated with the Oxford Internet Institute at the University of Oxford.\\n\\nWhat does the task involve?\\n\\nIf you decide to participate, there are two stages. In this stage, you will be asked to fill in a short survey about yourself and your thoughts on AI language models.\\n\\nIn the next stage, you will have conversations with AI language models by providing prompts and rating their responses using a user-friendly interface. The prompts can be on various topics, and you don't need any specific knowledge to participate. Your input will help us understand your preferences and opinions about how these AI language models work.\\n\\nBoth stages should take between 55-65 minutes.\\n\\nNo background knowledge is required.\\n\\nPlease note that you will be interacting with an AI language model. The research team cannot directly control and are not responsible for the text generated by these models. There is a possibility that the models produce biased, inaccurate or harmful language. The risks to you as an individual are equivalent to those you would be exposed to if you use AI language models via interfaces like ChatGPT.\\n\\nDo I have to take part?\\n\\nNo, participation is voluntary. If you do decide to take part, you may stop at any point for any reason before submitting your answers by closing the browser. However, we are only able to pay participants who complete the task. For demographic information, we have included a 'Prefer not to say' option for each set of questions should you prefer not to answer a particular question.\\n\\nCan I withdraw my participation and data?\\n\\nYes, you may stop the study at any time. Please note that if you withdraw within a stage of the study you will not be paid for that stage or any subsequent incomplete stages, but you will be paid for any stages that you have already completed. You can withdraw your data from the study. The cut-off date for withdrawing your data is 14 days after you submitted the data. Please email members of the research team (see contact details below) within this 14-day window to withdraw your data from the study.\"}"}
{"id": "DFr5hteojx", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"How will my data be used?\\n\\nThe data collected from your participation will be pseudo-anonymized (stored with a unique numeric ID) and stored securely. It will be used for research purposes, and your personal information will remain confidential. The data will be analysed to gain insights into diverse preferences and perceptions regarding AI language model behaviours. At the end of the study, the pseudo-anonymised data collected will be released publicly for future research. The findings of this study may be published in academic journals or presented at conferences, and the results will be written up for a DPhil degree. Your individual identity will not be disclosed at any point in data release or publication.\\n\\nWe do not collect any personal, private identifying information, IP addresses or contact details. The data we will collect that could identify you will be some demographic information (gender, age, nationality, religion, etc.), and short self-written survey answers.\\n\\nThe responses you provide will be stored in a password-protected electronic file on University of Oxford secure servers and may be used in academic publications, conference presentations or reports for external organisations. We will release a clean, PII-checked and pseudo-anonymised form of the data on an open-access, public data repository. Raw research data will be stored for 3 years after publication or public release of the research. We would like to use the data in future studies, and to share data with other researchers (e.g. in online databases). Data will have identifying information removed before it is shared with other researchers or results are made public. The data that we collect from you may be transferred to, stored and/or processed at a destination outside the UK and the European Economic Area. By submitting your personal data, you agree to this transfer, storing or processing.\\n\\nWho has reviewed this research?\\n\\nThis research has been reviewed by, and received ethics clearance through, a subcommittee of the University of Oxford Central University Research Ethics Committee [OII_C1A_23_088].\\n\\nWho do I contact if I have a concern or I wish to complain?\\n\\nIf you have a concern about any aspect of this research, please speak to Hannah Rose Kirk (hannah.kirk@oii.ox.ac.uk) or their supervisor Dr. Scott A. Hale (scott.hale@oii.ox.ac.uk), and we will do our best to answer your query. We will acknowledge your concern within 10 working days and give you an indication of how it will be dealt with. If you remain unhappy or wish to make a formal complaint, please contact the Chair of the Research Ethics Committee at the University of Oxford who will seek to resolve the matter as soon as possible: Social Sciences & Humanities Interdivisional Research Ethics Committee; Email: ethics@socsci.ox.ac.uk; Address: Research Services, University of Oxford, Boundary Brook House, Churchill Drive, Headington, Oxford OX3 7GB.\\n\\nPlease note that you may only participate in this survey if you are 18 years of age or over.\\n\\n\u00a9 I certify that I am 18 years of age or over\\n\\nIf you have read the information above and agree to participate with the understanding that the data (including any personal data) you submit will be processed accordingly, please tick the box below to start.\\n\\n\u00a9 Yes, I agree to take part\"}"}
{"id": "DFr5hteojx", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Identifiers of text instance types in PRISM.\\n\\n| Text Instance Type | Study Stage | Matchings |\\n|------------------|-------------|-----------|\\n| Self_description | Survey      | \u2713         |\\n| System_string    | Survey      | \u2713         |\\n| User_prompt      | Conversations | \u2713 \u2713       |\\n| Model_response   | Conversations | \u2713 \u2713 \u2713    |\\n| Open_feedback    | Conversations | \u2713         |\\n\\nFor each text instance in PRISM, we attach three pieces of metadata: detected language flags, detected private or personally identifiable information (PII) flags, and detected moderation flags.\\n\\nE.1 Structuring the Metadata\\n\\nThere are five types of text instances. Two appear in the survey (self_description, system_string) and have a 1:1 matching with each user (user_id). One appears at the conversation level (open_feedback) and has a 1:1 matching with each convo_id and a many:1 matching with each user_id because each participant has multiple conversations. Finally, the last two occur within each turn of a conversation, where for each single user_prompt there are multiple model responses (model_response). We structure the metadata so it can be merged uniquely, without duplication. We release one file, where each text instance is tied to its metadata via the identifying information shown in Tab. 1, and a column_id for matching whether the text is system_string, self_description, user_prompt, model_response, open_feedback.\\n\\nE.2 Automated Flagging\\n\\nPII\\n\\nTo identify whether a textual instance in our dataset contains personal and identifiable information (PII) we used the package scrubadub. Specifically we used the function scrubadub.clean(text) which replaces the phone numbers and email addresses with anonymous IDs, if they are found in the input. We flag with 1 instances that are altered (i.e., PII was identified) and 0 those that remained unchanged.\\n\\nModeration\\n\\nTo measure content moderation we use the OpenAI Moderation endpoint. The API takes as an input a textual instance and outputs a json file with an overall boolean flag (flagged) whether there input potentially harmful (True), otherwise False. The API also returns a flag for a list of specific moderation categories that can be used to further filter and inspect the data. The categories are sexual, hate, harassment, self-harm, sexual/minors, hate/threatening, violence/graphic, self-harm/intent, self-harm/instructions, harassment/threatening and violence. Similar to the overall flag, for each category, the value is True if the model flags the corresponding category as violated, False otherwise. Finally, the API returns a dictionary of per-category scores that denote the model's confidence that the input violates the OpenAI's policy for the category. The value is between 0 and 1, where higher values denote higher confidence.\\n\\nLanguage Detection\\n\\nTo detect the language of each text instance in our dataset we used the LangID codebase. LangID is a popular python package that efficiently detects the language of an input and currently supports 97 languages. Specifically, we use the langid.classify(text) function and store a string for the detected language.\"}"}
{"id": "DFr5hteojx", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The overall proportions of texts flagged for PII, Non-English or Moderation is low (see Tab. 2). However, when inspecting the few positive flags, many were false positives, especially on lang-detect and PII. While a false positive on language may be relatively inconsequential, any automated flags of PII are concerning. Accordingly, we manually annotate any instances where $\\\\text{pii}_\\\\text{flag} = \\\\text{True}$ ($n = 167$) for participant-written text. We find that none of them actually contain PII.\\n\\nTable 2: Meta-Data Summary. For each metadata category (language, PII and moderation), we show $N(\\\\%)$ for the dataset as a whole (Overall) and broken down by each type of text instance in PRISM.\\n\\n| Category          | Is English | Contains PII | Manually-Checked PII | Is Moderation | Total Instances |\\n|-------------------|------------|--------------|----------------------|---------------|-----------------|\\n| Overall           | 105,229 (98.8%) | 1,111 (1.0%) | NA                   | 634 (0.6%)    | 106,554 (100.0%) |\\n| User Prompt       | 26,545 (97.7%) | 66 (0.2%)    | 0 (0.0%)             | 454 (1.7%)    | 27,172 (100.0%)  |\\n| Model Response    | 67,715 (99.0%) | 944 (1.4%)   | NA                   | 162 (0.2%)    | 68,371 (100.0%)  |\\n| Self Description  | 1,496 (99.7%) | 10 (0.7%)    | 0 (0.0%)             | 7 (0.5%)      | 1,500 (100.0%)   |\\n| System String     | 1,493 (99.5%) | 16 (1.1%)    | 0 (0.0%)             | 0 (0.0%)      | 1,500 (100.0%)   |\\n| Open Feedback     | 7,980 (99.6%) | 75 (0.9%)    | 0 (0.0%)             | 11 (0.1%)     | 8,011 (100.0%)   |\\n\\nTable 3: Breakdown of flags from the OpenAI Moderation API. We show counts and percentages where the text was flagged (==True), as well as total counts. Human-written text includes user_prompt, self_description, system_string, open_feedback; Model-written text is only model_response.\\n\\n| Category | N (%) | N (%) |\\n|----------|-------|-------|\\n| Sexual   | 21 (0.05%) | 11 (0.02%) |\\n| Hate     | 154 (0.40%) | 36 (0.05%) |\\n| Harassment | 387 (1.01%) | 127 (0.19%) |\\n| Self-harm | 24 (0.06%) | 8 (0.01%) |\\n| Sexual/minors | 4 (0.01%) | 4 (0.01%) |\\n| Hate/threatening | 17 (0.04%) | 2 (0.00%) |\\n| Self-harm/intent | 26 (0.07%) | 5 (0.01%) |\\n| Self-harm/instructions | 13 (0.03%) | 8 (0.01%) |\\n| Harassment/threatening | 33 (0.09%) | 7 (0.01%) |\\n| Violence  | 52 (0.14%) | 13 (0.02%) |\\n| Total     | 38,183 (100.00%) | 68,371 (100.00%) |\\n\\nTable 4: Breakdown of languages detected by LangID. We show the top-10 detected languages, then other and total counts. Human-written text includes user_prompt, self_description, system_string, open_feedback; Model-written text is only model_response.\\n\\n| Language | N (%) | Language | N (%) |\\n|----------|-------|----------|-------|\\n| en       | 37,514 (98.25%) | en      | 67,715 (99.04%) |\\n| es       | 175 (0.46%)     | es      | 236 (0.35%)    |\\n| fr       | 71 (0.19%)      | de      | 67 (0.10%)     |\\n| it       | 70 (0.18%)      | fr      | 63 (0.09%)     |\\n| de       | 60 (0.16%)      | la      | 43 (0.06%)     |\\n| nl       | 42 (0.11%)      | nl      | 37 (0.05%)     |\\n| pt       | 41 (0.11%)      | it      | 29 (0.04%)     |\\n| pl       | 34 (0.09%)      | sl      | 19 (0.03%)     |\\n| da       | 24 (0.06%)      | hu      | 15 (0.02%)     |\\n| ro       | 13 (0.03%)      | sv      | 14 (0.02%)     |\\n| Other    | 139 (0.36%)     | Other   | 133 (0.19%)    |\\n| Total    | 38,183 (100.00%) | Total   | 68,371 (100.00%) |\"}"}
{"id": "DFr5hteojx", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Annotating Ethnicity, Religion and Gender\\n\\nWe ask people to describe their ethnic and religious affiliations in their own words because for a global survey, there are no immediately obvious preset categories. In the survey data, we release this original self-description (\\\\(\\\\text{ethnicity, religion}_\\\\text{self_described}\\\\)). However, there are 264 unique strings for ethnicity, and 137 unique strings for religion. For some analysis, it is valuable to have aggregate groupings. To attain this grouping, we first used \\\\text{gpt-4-turbo} to categorise the strings, but found some errors and essentialising generalisations, for example, if someone answered with a nationality not an ethnic group like \\\\text{american}, \\\\text{gpt} would return \\\\text{white}.\\n\\nAccordingly, we used a second round of manual human annotation to verify these automated labels. Two annotators (authors of the paper) first made independent judgements then discussed any disagreements. For ethnicity, some participants also had answered a Prolific screening question on their simplified ethnicity, though we did not have this information for all participants as it was not mandatory. We thus annotate all unique combinations of the self-described string, and the Prolific ethnicity information (\\\\(n=343\\\\)). In ambiguous cases (e.g. the aforementioned \\\\text{american} response), we relied on this additional ethnicity information, and in its absence, defaulted to a \\\\text{Prefer not to say} response. For religion, we do not have any additional information provided by the Prolific pre-screening questionnaire, so verification decisions were made on the basis of the self-describe string alone. The annotators agreed on 94% of ethnicity cases (discussing and resolving the remaining 20); and 96% of religion cases (discussing and resolving the remaining 5).\\n\\nWe highlight two general findings from our disagreements which may be of interest to people analysing or categorising our data in the future. Firstly, ethnicity and nationality are complex. Take for example the UK census, where \\\\text{Chinese}, \\\\text{Bangladesh}, \\\\text{Indian} and \\\\text{Pakistani} are all listed as subcategories of the Asian ethnic group. Ethnicity is a multi-faceted term which can include nationality, language group, skin colour, religion, among other characteristics [145]. Studies have shown that survey participants can interpret the term ethnic group through a variety of subjective lens [146, 147]. During annotation, we tried to gather information on whether group terms commonly refer to an ethnic group, but some subjectivity and naivety are inevitable; so, we encourage future researchers to carefully consider their own categorisations depending on the question at hand. Secondly, the belonging and believing aspects of religion intersect [148, 149], and it is not immediately clear how to categorise an individual that culturally affiliates with religion but simultaneously identities as an atheist or non-believer. Studies have revealed that the belonging and believing axis of religion are important for conditioning behaviours such as trust, pro-socality and altruism [150\u2013152]. In general, we annotated a mention of a religion as assigned to that religion (not distinguishing between the belonging and believing channels) but it remains to be seen whether one axis is more salient for values and opinions towards AI systems.\\n\\nNote for gender, we provided a standard multiple choice question with options: \\\\text{Female}, \\\\text{Male}, \\\\text{Non-binary / third gender}, \\\\text{Prefer not to say} and \\\\text{Prefer to self-describe}. Only 3 individuals opted to self-describe, which we then annotated and only assimilated in very clear cut cases, else we grouped it as \\\\text{Prefer not to say} to avoid over-riding a participant's self-identification.\\n\\nParticipant Demographics\\n\\nWe present full demographic breakdowns in Tab. 5. We also compare the breakdowns in PRISM to some early human feedback datasets which provide demographic information (Tab. 6).\\n\\nAs an aside, these types of baked-in priors are a good example of why using LLMs as a surrogate for human annotators may introduce downstream biases [108].\\n\\nSee the fact sheet at ethnicity-facts-figures.service.gov.uk.\\n\\nFor example, one participant responded with \\\"i dont expect this wokery from intelligent people. you want to know which of the 2 possible genders i am male.\", which we assign as \\\\text{Male}.\"}"}
{"id": "DFr5hteojx", "page_num": 39, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 5: Full Demographics Breakdowns\\n\\nCounts and percentages of participants by standard demographic variables. Overall, PRISM utilizes a large and demographically-diverse sample, especially compared to some previous human feedback datasets (see Tab. 6); but it still generally skews towards young, white and educated populations. *For ethnicity and religion, see details in App. F.\\n\\n| Total Participants | 1,500 |\\n|--------------------|-------|\\n| With conversations  | 1,396 (93.1 %) |\\n| Just survey        | 104 (6.9 %) |\\n\\nAge\\n\\n| Age Group          | Count | Percentage |\\n|--------------------|-------|------------|\\n| 25-34 years old    | 454   | 30.3 %     |\\n| 18-24 years old    | 297   | 19.8 %     |\\n| 35-44 years old    | 237   | 15.8 %     |\\n| 45-54 years old    | 208   | 13.9 %     |\\n| 55-64 years old    | 197   | 13.1 %     |\\n| 65+ years old      | 106   | 7.1 %      |\\n| Prefer not to say  | 1     | 0.1 %      |\\n\\nGender\\n\\n| Gender                  | Count | Percentage |\\n|-------------------------|-------|------------|\\n| Male                    | 757   | 50.5 %     |\\n| Female                  | 718   | 47.9 %     |\\n| Non-binary / third gender | 21  | 1.4 %      |\\n| Prefer not to say       | 4     | 0.3 %      |\\n\\nSelf-Reported Ethnicity*\\n\\n| Ethnicity                | Count | Percentage |\\n|--------------------------|-------|------------|\\n| White                    | 969   | 64.6 %     |\\n| Black / African           | 122   | 8.1 %      |\\n| Hispanic / Latino        | 121   | 8.1 %      |\\n| Asian                    | 95    | 6.3 %      |\\n| Mixed                    | 68    | 4.5 %      |\\n| Middle Eastern / Arab    | 14    | 0.9 %      |\\n| Indigenous / First Peoples | 8  | 0.5 %      |\\n| Other                    | 17    | 1.1 %      |\\n| Prefer not to say        | 86    | 5.7 %      |\\n\\nSelf-Reported Religion*\\n\\n| Religion                | Count | Percentage |\\n|-------------------------|-------|------------|\\n| Non-religious            | 762   | 50.8 %     |\\n| Christian                | 487   | 32.5 %     |\\n| Agnostic                 | 71    | 4.7 %      |\\n| Jewish                   | 42    | 2.8 %      |\\n| Muslim                   | 31    | 2.1 %      |\\n| Spiritual                | 18    | 1.2 %      |\\n| Buddhist                 | 12    | 0.8 %      |\\n| Folk religion            | 6     | 0.4 %      |\\n| Hindu                    | 5     | 0.3 %      |\\n| Sikh                     | 3     | 0.2 %      |\\n| Other                    | 4     | 0.3 %      |\\n| Prefer not to say        | 59    | 3.9 %      |\\n\\nEmployment Status\\n\\n| Employment Status        | Count | Percentage |\\n|--------------------------|-------|------------|\\n| Working full-time        | 712   | 47.5 %     |\\n| Working part-time        | 265   | 17.7 %     |\\n| Student                  | 191   | 12.7 %     |\\n| Unemployed, seeking work | 113   | 7.5 %      |\\n| Retired                  | 104   | 6.9 %      |\\n| Homemaker / Stay-at-home parent | 46 | 3.1 % |\\n| Unemployed, not seeking work | 46 | 3.1 % |\\n| Prefer not to say        | 23    | 1.5 %      |\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 40, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 5: Full Demographics Breakdowns. Counts and percentages of participants by standard demographic variables. Overall, PRISM utilises a large and demographically-diverse sample, especially compared to some previous human feedback datasets (see Tab. 6); but it still generally skews towards young, white and educated populations. *For ethnicity and religion, see details in App. F.\\n\\n| Education                     | Count | Percentage |\\n|-------------------------------|-------|------------|\\n| University Bachelors Degree   | 637   | 42.5%      |\\n| Graduate / Professional degree| 241   | 16.1%      |\\n| Some University but no degree | 236   | 15.7%      |\\n| Completed Secondary School    | 209   | 13.9%      |\\n| Vocational                    | 125   | 8.3%       |\\n| Some Secondary                | 24    | 1.6%       |\\n| Completed Primary School      | 16    | 1.1%       |\\n| Some Primary                  | 3     | 0.2%       |\\n| Prefer not to say             | 9     | 0.6%       |\\n\\n| Martial Status                | Count | Percentage |\\n|-------------------------------|-------|------------|\\n| Never been married            | 870   | 58.0%      |\\n| Married                       | 463   | 30.9%      |\\n| Divorced / Separated          | 123   | 8.2%       |\\n| Widowed                       | 21    | 1.4%       |\\n| Prefer not to say             | 23    | 1.5%       |\\n\\n| English Proficiency           | Count | Percentage |\\n|-------------------------------|-------|------------|\\n| Native speaker                | 886   | 59.1%      |\\n| Fluent                        | 405   | 27.0%      |\\n| Advanced                      | 160   | 10.7%      |\\n| Intermediate                  | 42    | 2.8%       |\\n| Basic                         | 7     | 0.5%       |\\n\\n| Regions                       | Count | Percentage |\\n|-------------------------------|-------|------------|\\n| US                            | 338   | 22.5%      |\\n| Europe                        | 313   | 20.9%      |\\n| UK                            | 292   | 19.5%      |\\n| Latin America and the Caribbean| 146  | 9.7%       |\\n| Australia and New Zealand     | 129   | 8.6%       |\\n| Africa                        | 118   | 7.9%       |\\n| Asia                          | 60    | 4.0%       |\\n| Northern America              | 50    | 3.3%       |\\n| Middle East                   | 50    | 3.3%       |\\n| Oceania                       | 1     | 0.1%       |\\n| Prefer not to say             | 3     | 0.2%       |\"}"}
{"id": "DFr5hteojx", "page_num": 41, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Category                     | Bai et al. | Ouyang et al. | Glaese et al. | Ganguli et al. | Stiennon et al. | Ours                   |\\n|------------------------------|------------|---------------|---------------|----------------|-----------------|------------------------|\\n| **Total Participants**       | 28         | 40            | 324           | 1,500          |                 | 1,500                  |\\n| **Demographic Respondents**  | 28         | 19            | 533           | 115            |                 | 21                     |\\n| **Gender**                   |            |               |               |                |                 |                        |\\n| Male                        | 53.6%      | 47.4%         | 45.0%         | 47.0%          | 38.1%           | 50.5%                  |\\n| Female                      | 46.4%      | 42.1%         | 54.0%         | 52.2%          | 61.9%           | 47.9%                  |\\n| Non-binary                   | 0.0%       | 5.3%          | 1.0%          | 0.9%           | 0.0%            | 1.4%                   |\\n| Prefer not to say/Other      | 0.0%       | 5.3%          | 0.0%          | 0.0%           | 0.0%            | 0.3%                   |\\n| **Sexual Orientation**       |            |               |               |                |                 |                        |\\n| Heterosexual                 | 89.3%      | -             | 84.0%         | 81.7%          | -               | -                      |\\n| Lesbian or Gay               | 7.1%       | -             | 5.0%          | 4.3%           | -               | -                      |\\n| Bisexual                     | 0.0%       | -             | 9.0%          | 12.2%          | -               | -                      |\\n| Uncertain                    | 3.6%       | -             | -             | 0.9%           | -               | -                      |\\n| Prefer not to say/Other      | 0.0%       | -             | 2.0%          | 0.9%           | -               | -                      |\\n| **Age**                      |            |               |               |                |                 |                        |\\n| 18-24                        | 7.1%       | 26.3%         | 11.0%         | 0.0%           | 19.8%           |                        |\\n| 25-34                        | 39.3%      | 47.4%         | 37.0%         | 25.2%          | 42.9%           | 30.3%                  |\\n| 35-44                        | 42.9%      | 10.5%         | 24.0%         | 33.9%          | 23.8%           | 15.8%                  |\\n| 45-54                        | 10.7%      | 10.5%         | 16.0%         | 23.5%          | 23.8%           | 13.9%                  |\\n| 55-64                        | 0.0%       | 5.3%          | 9.0%          | 13.9%          | 9.5%            | 13.1%                  |\\n| 65+                          | 0.0%       | 0.0%          | 3.0%          | 1.7%           | 0.0%            | 7.1%                   |\\n| Prefer not to say/Other      | 0.0%       | -             | -             | 1.7%           | -               | 0.1%                   |\\n| **Ethnicity**                |            |               |               |                |                 |                        |\\n| White/Caucasian              | 67.9%      | 31.6%         | 81.0%         | 81.7%          | 42.9%           | 64.6%                  |\\n| Asian                        | 10.7%      | 57.9%         | 8.0%          | 2.6%           | 28.6%           | 6.3%                   |\\n| Black/African descent        | 3.6%       | 10.5%         | 4.0%          | 8.7%           | -               | 8.1%                   |\\n| Hispanic/Latino              | 3.6%       | 15.8%         | 1.0%          | 0.9%           | 4.8%            | 8.1%                   |\\n| Native American              | 0.0%       | 0.0%          | 0.0%          | 2.6%           | 9.6%            | 0.5%                   |\\n| Middle Eastern               | 0.0%       | 0.0%          | 1.0%          | 0.9%           | 4.8%            | 0.9%                   |\\n| Prefer not to say/Other      | 14.3%      | -             | 5.0%          | 2.6%           | 9.6%            | 11.5%                  |\\n| **Education**                |            |               |               |                |                 |                        |\\n| No University Degree         | 17.9%      | 10.5%         | 0.0%          | 34.8%          | 14.3%           | 40.8%                  |\\n| Undergraduate Degree         | 57.1%      | 52.6%         | 66.0%         | 53.9%          | 57.1%           | 42.5%                  |\\n| Graduate Degree              | 14.3%      | 36.8%         | 34.0%         | 10.4%          | 28.1%           | 16.1%                  |\\n| Prefer not to say/Other      | 10.7%      | -             | -             | 0.9%           | -               | 0.6%                   |\\n\\n\u2020Age group values for Stiennon et al. are reported for ten-year age groups starting from 20-29. We have placed the values in the row where the top end of these groups would appear to align with groups reported by the majority of studies.\\n\\n\u2021Bai et al. provide two reports of demographic data. We use the one corresponding to the participants who contributed more than 80% of the total feedback.\\n\\n| Category                     | Bai et al. | Ouyang et al. | Glaese et al. | Ganguli et al. | Stiennon et al. | Ours                   |\\n|------------------------------|------------|---------------|---------------|----------------|-----------------|------------------------|\\n| **Participant countries of residence** |            |               |               |                |                 |                        |\\n| United States                | 100%       | 17%           | 0%            | 100%           | 60%             | 26%                    |\\n| United Kingdom               | 0%         | 0%            | 100%          | 0%             | 7%              | 23%                    |\\n| Philippines                  | 0%         | 22%           | 0%            | 0%             | 7%              | 0%                     |\\n| Bangladesh                   | 0%         | 22%           | 0%            | 0%             | 0%              | 0%                     |\\n| All Others                   | 0%         | 39%\u2020          | 0%            | 0%             | 27%\u2021            | 61%*                   |\\n\\n\u2020One resident each from Albania, Brazil, Canada, Columbia, India, Uruguay, and Zimbabwe\\n\u2021One resident each from South Africa, Serbia, Turkey, India\\n*See Tab. 8 for our breakdowns.\"}"}
{"id": "DFr5hteojx", "page_num": 42, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"We present full geographic breakdowns in Tab. 8. Fig. 6 is an enlarged version from Fig. 1. We compare geographic data to prior work in Tab. 7. For regional classifications, we use the UN definitions.\\n\\nWe also throughout the main paper use location\\_special\\_region, which splits out the UK and the US. Regional breakdowns by birth country are shown in Fig. 7.\\n\\nTable 8: Full Geographic Breakdowns.\\n\\n| Country of Birth | Country of Residence |\\n|-----------------|----------------------|\\n| United States   | 338 (22.5%)          |\\n| United Kingdom  | 292 (19.5%)          |\\n| South Africa    | 91 (6.1%)            |\\n| Mexico          | 69 (4.6%)            |\\n| Australia       | 65 (4.3%)            |\\n| New Zealand     | 64 (4.3%)            |\\n| Chile           | 63 (4.2%)            |\\n| Canada          | 50 (3.3%)            |\\n| Israel          | 47 (3.1%)            |\\n| Nigeria         | 19 (1.3%)            |\\n| Spain           | 19 (1.3%)            |\\n| Germany         | 17 (1.1%)            |\\n| Belgium         | 17 (1.1%)            |\\n| Hungary         | 17 (1.1%)            |\\n| Poland          | 17 (1.1%)            |\\n| Ireland         | 17 (1.1%)            |\\n| Latvia          | 16 (1.1%)            |\\n| Denmark         | 15 (1.0%)            |\\n| Czechia         | 15 (1.0%)            |\\n| Norway          | 15 (1.0%)            |\\n| France          | 14 (0.9%)            |\\n| Italy           | 14 (0.9%)            |\\n| Greece          | 14 (0.9%)            |\\n| Switzerland     | 14 (0.9%)            |\\n\\nContinued on next page\\n\\n18 [https://population.un.org/wpp/DefinitionOfRegions](https://population.un.org/wpp/DefinitionOfRegions)\"}"}
{"id": "DFr5hteojx", "page_num": 43, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 8: Full Geographic Breakdowns.\\n\\n| Country of Birth | Country of Residence |\\n|------------------|----------------------|\\n| Finland          | 12                   |\\n|                  | 0.8%                 |\\n|                  | 13                   |\\n|                  | 0.9%                 |\\n| Estonia          | 11                   |\\n|                  | 0.7%                 |\\n|                  | 10                   |\\n|                  | 0.7%                 |\\n| Austria          | 11                   |\\n|                  | 0.7%                 |\\n|                  | 10                   |\\n|                  | 0.7%                 |\\n| Slovenia         | 10                   |\\n|                  | 0.7%                 |\\n|                  | 10                   |\\n|                  | 0.7%                 |\\n| Netherlands      | 9                    |\\n|                  | 0.6%                 |\\n|                  | 8                    |\\n|                  | 0.5%                 |\\n| India            | 9                    |\\n|                  | 0.6%                 |\\n|                  | 0             |\\n|                  | 0.0%                 |\\n| Japan            | 9                    |\\n|                  | 0.6%                 |\\n|                  | 11                   |\\n|                  | 0.7%                 |\\n| Korea, Republic  | 9                    |\\n|                  | 0.6%                 |\\n|                  | 7                    |\\n|                  | 0.5%                 |\\n| Portugal         | 8                    |\\n|                  | 0.5%                 |\\n|                  | 7                    |\\n|                  | 0.5%                 |\\n| Romania          | 7                    |\\n|                  | 0.5%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Philippines      | 7                    |\\n|                  | 0.5%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Sweden           | 7                    |\\n|                  | 0.5%                 |\\n|                  | 6                    |\\n|                  | 0.4%                 |\\n| Russian Federation| 6                   |\\n|                  | 0.4%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Ukraine          | 4                    |\\n|                  | 0.3%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Bangladesh       | 4                    |\\n|                  | 0.3%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| China            | 4                    |\\n|                  | 0.3%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Hong Kong        | 3                    |\\n|                  | 0.2%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Pakistan         | 3                    |\\n|                  | 0.2%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Ghana            | 3                    |\\n|                  | 0.2%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Dominican Republic| 3                  |\\n|                  | 0.2%                 |\\n|                  | 0        |\\n|                  | 0.0%                 |\\n| Venezuela, Bolivarian Republic of| 3                   |\\n|                  | 0.2%                 |\\n|                  | 0  |\\n|                  | 0.0%                 |\\n| Indonesia        | 3                    |\\n|                  | 0.2%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Viet Nam         | 2                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Sri Lanka        | 2                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Turkey           | 2                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Argentina        | 2                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Kazakhstan       | 2                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Slovak Republic  | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Sudan            | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Tonga            | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Afghanistan      | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Nepal            | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Honduras         | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Belarus          | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0        |\\n|                  | 0.0%                 |\\n| Bosnia and Herzegovina | 1                |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Brazil           | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Bulgaria         | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Colombia         | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Cuba             | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| C\u00f4te d'Ivoire    | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Malaysia         | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Guyana           | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Iceland          | 1                    |\\n|                  | 0.1%                 |\\n|                  | 1                    |\\n|                  | 0.1%                 |\\n| Jamaica          | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Kenya            | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Kuwait           | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Lithuania        | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Luxembourg       | 1                    |\\n|                  | 0.1%                 |\\n|                  | 2                    |\\n|                  | 0.1%                 |\\n| Malawi           | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Zambia           | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0        |\\n|                  | 0.0%                 |\\n| Tanzania         | 0                    |\\n|                  | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Lesotho          | 0                    |\\n|                  | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Uruguay          | 0                    |\\n|                  | 1                    |\\n|                  | 0.1%                 |\\n|                  | 0                    |\\n|                  | 0.0%                 |\\n| Prefer not to say| 3                    |\\n|                  | 0.2%                 |\\n|                  | 1                    |\\n|                  | 0.1%                 |\"}"}
{"id": "DFr5hteojx", "page_num": 44, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 7: Skewed regional entropy in PRISM. The hierarchical tree diagram uses participant birth location, mapping (i) special location (splitting out the US and UK), which is used in the main paper, (ii) UN-defined subregions, and (iii) ISO country codes. There is an over-representation of UK and US participants due to the census samples. In most regions besides Europe, participation is dominated by one or two birth countries. The two small vertical boxes are Prefer not to say (in red), and Oceania (in navy).\\n\\nNote: 88% of PRISM participants are born and currently reside in the same country.\"}"}
{"id": "DFr5hteojx", "page_num": 45, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We present breakdowns on experience with LLMs in Tab. 9. We did not require participants to be familiar with LLMs so provide the following primer:\\n\\nThis research is about Artificial Intelligence (AI) Language Models. These models are also sometimes referred to as Generative AI, Large Language Models (LLMs), Conversational Agents, AI Chat Bots or Virtual Assistants. They are advanced computer programs that can understand and generate human-like text. These models learn from large amounts of text data on the internet to generate their responses. One example you might have heard is ChatGPT, where people can have a conversation with an AI language model via an internet website.\\n\\nTable 9: Survey of Participants' LLM Usage\\n\\n| LLM Direct Use | Yes | 77.5% |\\n|----------------|-----|-------|\\n| No             | 17.3% |\\n| Unsure         | 5.3%  |\\n| LLM Indirect Use | Yes | 73.6% |\\n| No             | 14.3% |\\n| Unsure         | 12.1% |\\n\\nLLM Familiarity\\n\\n| Somewhat familiar | 61.3% |\\n| Very familiar     | 28.3% |\\n| Not familiar at all | 10.4% |\\n\\nLLM Frequency of Use\\n\\n| Once per month | 24.9% |\\n| Every week     | 21.1% |\\n| More than once a month | 19.4% |\\n| Less than one a year | 10.8% |\\n| Every day      | 7.3%  |\\n| Not shown question | 16.5% |\\n\\nLLM Use Cases\\n\\n| Research: Fact-checking or gaining overviews on specific topics. | 49.2% |\\n| Professional Work: Assisting in drafting, editing, or brainstorming content for work. | 37.4% |\\n| Creative Writing: Generating story ideas, dialogues, poems or other writing prompts. | 31.3% |\\n| Technical or Programming Help: Seeking programming guidance, code generation, software recommendations, or debugging assistance. | 26.9% |\\n| Lifestyle and Hobbies: Looking for recipes, craft ideas, home decoration tips, or hobby-related information. | 24.7% |\\n| Homework Assistance: Getting help with school or university assignments. | 22.8% |\\n| Personal Recommendations: Seeking book, music or movie recommendations. | 21.2% |\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 46, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 9: Survey of Participants' LLM Usage\\n\\nThe majority of participants have used LLMs directly (via a dedicated chat interface) and indirectly (embedded in products or services). Note only participants who answered Yes to LLM Direct Use or LLM Indirect Use (n = 1253, 84%) are shown.\\n\\n| Use Case                          | Count | Percentage |\\n|-----------------------------------|-------|------------|\\n| Casual Conversation               | 262   | 20.9%      |\\n| Language Learning                 | 229   | 18.3%      |\\n| Source Suggestions                | 217   | 17.3%      |\\n| Daily Productivity                | 216   | 17.2%      |\\n| Historical or News Insight        | 183   | 14.6%      |\\n| Well-being Guidance               | 159   | 12.7%      |\\n| Games                             | 143   | 11.4%      |\\n| Travel Guidance                   | 133   | 10.6%      |\\n| Medical Guidance                  | 130   | 10.4%      |\\n| Financial Guidance                | 107   | 8.5%       |\\n| Relationship Advice               | 98    | 7.8%       |\\n| Other                             | 124   | 9.9%       |\\n\\n### I.1 Other Identified Use Cases\\n\\nIn addition to the use cases in Table 9, 122 participants used the \u201cOther\u201d option to add a use case in their own words. Many of these just add more specific details to the pre-provided categories. In addition, there were a few interesting themes:\\n\\n- **Customer Service:** Many of the participants noted having interacted with LLMs in customer support chats, often with negative sentiment.\\n\\n- **Prolific and Other Online Surveys:** One of the more common (and potentially concerning) answers mentioned research participation.\\n\\n- **AI Understanding or Testing:** A few participants mentioned trying to gain an understanding into AI and its capabilities.\\n\\n- **Professional or Job Tasks:** Participants added details on professional use cases like resume help, interview prep, CV writing, HR-tasks, Excel help, or emails.\\n\\n- **Creative (Multimodal) Use Cases:** Participants gave additional detail like writing YouTube scripts, generating gift card text, or designing characters for games as well as multimodal creative outputs like generating drawings or images.\\n\\n- **Domain-Specific Use Cases:** Medical, Financial and Educational use cases are all mentioned.\"}"}
{"id": "DFr5hteojx", "page_num": 47, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"We recruit workers via Prolific (https://www.prolific.com/). We apply two initial screening criteria: (i) participants must be fluent in English because PRISM targets monolingual models and language data, and (ii) participants must have been born and reside in the same country to avoid biasing our sample towards expats living abroad. There is a skewed country-wise distribution of active workers who meet this criteria (see Tab. 10). For example, of the 21,084 workers in Europe (passing screening), 17% are Portuguese, 15% German and 14% Polish; and all 6,584 workers in Africa are located in South Africa. To account for this, we set up country-specific studies in each country with at least one eligible worker, balance study spots across regions, and ensure no single country has more than 100 open spots (apart from the Rep Samples in the UK and US). We collected information on country of birth and country of current residence during our survey (separate to workers' stored Prolific details), and find that 179 participant (12%) have different birth and reside countries. We do not exclude these individuals from our sample.\\n\\n| Country        | Rep Sample | Gender Bal | Launched | Submissions | Approved | Prolific Fluent English Speakers |\\n|----------------|------------|------------|----------|-------------|----------|---------------------------------|\\n| Total          |            |            |          |             |          | 111,572                         |\\n| US             | \u2713          | \u2717          | 27-11    | 386         | 25.7%    | 38,114                          |\\n| UK             | \u2713          | \u2717          | 27-11    | 341         | 22.7%    | 37,408                          |\\n| South Africa   | \u2717          | \u2713          | 22-11    | 88          | 5.9%     | 7,061                           |\\n| New Zealand    | \u2717          | \u2713          | 24-11    | 77          | 5.1%     | 511                             |\\n| Australia      | \u2717          | \u2713          | 24-11    | 71          | 4.7%     | 1,968                           |\\n| Mexico         | \u2717          | \u2713          | 24-11    | 69          | 4.6%     | 2,021                           |\\n| Chile          | \u2717          | \u2713          | 23-11    | 65          | 4.3%     | 455                             |\\n| Israel         | \u2717          | \u2717          | 25-11    | 61          | 4.1%     | 310                             |\\n| Canada         | \u2717          | \u2713          | 22-11    | 54          | 3.6%     | 3,687                           |\\n| Spain          | \u2717          | \u2713          | 23-11    | 18          | 1.2%     | 1,252                           |\\n| Belgium        | \u2717          | \u2713          | 23-11    | 17          | 1.1%     | 376                             |\\n| Hungary        | \u2717          | \u2713          | 24-11    | 16          | 1.1%     | 537                             |\\n| Ireland        | \u2717          | \u2713          | 23-11    | 15          | 1.0%     | 640                             |\\n| Denmark        | \u2717          | \u2717          | 23-11    | 15          | 1.0%     | 119                             |\\n| Norway         | \u2717          | \u2717          | 23-11    | 15          | 1.0%     | 91                              |\\n| Switzerland    | \u2717          | \u2713          | 23-11    | 14          | 0.9%     | 205                             |\\n| Poland         | \u2717          | \u2713          | 23-11    | 14          | 0.9%     | 2,975                           |\\n| Czech Republic | \u2717          | \u2713          | 24-11    | 14          | 0.9%     | 238                             |\\n| Latvia         | \u2717          | \u2713          | 23-11    | 14          | 0.9%     | 173                             |\\n| Greece         | \u2717          | \u2713          | 24-11    | 14          | 0.9%     | 809                             |\\n| Finland        | \u2717          | \u2713          | 23-11    | 13          | 0.9%     | 152                             |\\n| Germany        | \u2717          | \u2713          | 24-11    | 13          | 0.9%     | 3,152                           |\\n| Italy          | \u2717          | \u2713          | 24-11    | 12          | 0.8%     | 2,037                           |\\n| France         | \u2717          | \u2713          | 24-11    | 12          | 0.8%     | 957                             |\\n| Slovenia       | \u2717          | \u2713          | 24-11    | 10          | 0.7%     | 232                             |\\n| Austria        | \u2717          | \u2713          | 24-11    | 10          | 0.7%     | 231                             |\\n| Estonia        | \u2717          | \u2713          | 24-11    | 10          | 0.7%     | 251                             |\\n| Netherlands    | \u2717          | \u2713          | 24-11    | 8           | 0.5%     | 1,460                           |\\n| Portugal       | \u2717          | \u2713          | 24-11    | 7           | 0.5%     | 3,649                           |\\n| Sweden         | \u2717          | \u2713          | 24-11    | 6           | 0.4%     | 274                             |\\n| Luxembourg     | \u2717          | \u2717          | 23-11    | 2           | 0.1%     | 15                              |\\n| Iceland        | \u2717          | \u2717          | 23-11    | 1           | 0.1%     | 16                              |\"}"}
{"id": "DFr5hteojx", "page_num": 48, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Conversation Type Rebalancing\\n\\nOur task instructions specified that participants should complete six conversations in total, two of each type. In reality, some participants deviated from this quota. This could be due to (i) misunderstanding of instructions, (ii) technical issues, or (iii) losing count, as while we included a counter of the total number of conversations on the interface (see App. Q), we did not include per conversation type breakdowns. To mitigate variation on conversation type selection, we create a balanced subset of conversations. First, we filter to all participants who had at least one of each conversation type. Then we take the maximum number of total conversations (either $n=3$ or $n=6$) so that there are equal numbers of each type. This results in $6$, $669$ conversations (84% of all conversations), from $1246$ participants (83% of all participants). We release this flag included_in_balanced_subset if future researchers want to use the same set of conversations. We make sure this flag intersects with the census rebalancing flags (see App. L) so no further data is lost when both subsets are needed.\\n\\nCensus Rebalancing\\n\\nObstacles to representativeness\\n\\nWe use the representative sample offered from Prolific [153]. However, there are several reasons why these samples may not be fully representative. First, our sampling process was affected internally due to cyberattacks disrupting some participants' workflows. These participants returned to the task after their spots had 'timed-out', and were re-filled by other same demographic individuals. Second, Prolific provides a sample breakdown in-line with a simplified census but do not match intersectional proportions to census data. Third, if a sample spot is taking too long to fill (e.g. 65+ years), Prolific will reallocate these spots to different demographics. There are of course wider stumbling blocks from crowdworkers skewing towards younger, more educated, and digitally-active populations. We original set up 300 spots for each of the representative samples, but ended up with 386 approved participants in the UK sample (UK-REP), and 341 in the US (US-REP).\\n\\nIs our original sample representative?\\n\\nWe compare our sample breakdowns to recent census data. For each of US-REP and UK-REP, we remove participants who did not give demographic details (Prefer not to say) and those reporting non-binary gender (which is not accounted for in census data). We subset to individuals also appearing in the balanced conversation subset to mitigate further data loss (see App. K). Remaining participants are considered eligible: 283 participants for the UK, and 297 for the US. We map P\\\\textsubscript{RISM} and census data into shared age, ethnicity and gender buckets. We then cross-tabulate what proportion is expected to appear in each age, gender and ethnicity intersection from the census data, and what percentage of participants we actually observed in our sample.\\n\\nFig. 8 shows the original UK sample is relatively census-balanced, especially if the 55-64 and 65+ age groups are combined (over-representation of white individuals in the former, offsets the under-representation in the latter). The US sample is skewed towards white, middle-aged individuals, with too few in the \\\"Other\\\" category (in our data corresponding to Other, as well as Hispanic, Indigenous/First Peoples or Middle Eastern / Arab combined).\\n\\nCan we make our sample more representative?\\n\\nWe aim to resample 300 participants according to census proportions but with two remaining caveats: 300 is a still a very small sample\u2014it is impossible to sample 0.83 Black women who are 18-24 years of age; and we are limited by the data we already have\u2014there are no Asian Women of 45-54 years, so we cannot add them retrospectively. We iterate through the expected proportions of each intersection, try to sample that exact number of in-group individuals, otherwise adding all individuals if there are too few to fill the spots. After rebalancing, the sample drops to 243 participants for the UK and 230 for the US. We improve upon, but do not fully resolve, representativeness. For both samples, the differences are now within $\\\\sim 7$pp, which over 230-240 individuals is $\\\\sim 10-15$ people incorrectly allocated. The rebalanced UK sample still suffers from a deficit of older people (65+), a common concern with crowdworker populations; and the rebalanced...\"}"}
{"id": "DFr5hteojx", "page_num": 65, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"GRIFFIN\\nHave a conversation with an AI language model and tell us what you think!\\n\\nChoose what type of conversation you want to have.\\n\\nRemember if you are here as a paid study participant, you need to do two of each type. If you are here as a volunteer, then take your pick!\\n\\nNeed some inspiration? You can request help with a task (like writing a recipe, organising an activity or event, completing an assignment)... You can chitchat, have casual conversation or seek personal advice. You can ask questions about the world, current events or your viewpoints.\\n\\nUnguided. Ask, request or talk to the model about anything. It is up to you!\\n\\nValues guided. Ask, request or talk to the model about something important to you or that represents your values. This could be related to work, religion, family and relationship, politics or culture.\\n\\nControversy guided. Ask, request or talk to the model about something controversial or where people would disagree in your community, culture or country.\\n\\nNow continue the conversation. Conversations can be between 2 and 10 turns. Try to vary the length. When you're done, click Finish.\\n\\nTell me a 1-liner joke about artificial intelligence\\n\\nWhy did the AI go to school?\\n\\nBecause it thought it could improve its neural networks!\\n\\nCan you explain the joke?\\n\\nSure! The joke plays on the dual meaning of \\\"neural networks.\\\" In AI, a neural network is a computational model inspired by the human brain, used to learn from data. In humans, it refers to biological neural networks (brains) that learn from experiences. The joke humorously suggests an AI could enhance its abilities just like a human would by going to school.\\n\\nTerrible\\n\\nPerfect\\n\\nSure! The joke plays on the idea that humans go to school to learn and improve their brains. It humorously suggests that an AI would do the same\u2014attend school to improve its 'neural networks,' which are the computer equivalent to biological brains in AI systems.\\n\\nTerrible\\n\\nPerfect\\n\\nSave\\n\\nCopyright \u00a9 2023 MLCommons, Inc. Contact Terms of Use Data Policy\\n\\nFigure 21: Main interface in continuing turns of conversation. Model is gpt-4-turbo.\"}"}
{"id": "DFr5hteojx", "page_num": 66, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Have a conversation with an AI ... missing? What would you change to make the conversation better?\\n\\nPlease write 2-5 sentences in your own words.\\n\\nSubmit\"}"}
{"id": "DFr5hteojx", "page_num": 67, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"R Case Study IA: Topic Clustering and Regressions\\n\\nR.1 Extended Methods\\n\\nSetup\\n\\nOur first experiment asks: do different people initiate different discussions with LLMs? We focus only on human-authored opening prompts because they are not confounded by model response. This risks over-estimating the homogeneity of the discussions because opening prompts don\u2019t necessarily reflect full conversational trees, where starting with a greeting (e.g., \u201cHi, how are you?\u201d) can proceed in many different ways; and differently held personal beliefs are often not reflected in the opener (questions like \u201cwhat do you think of abortion?\u201d are more common than statements like \u201cI think abortion is right/wrong\u201d).\\n\\nAssigning topic clusters\\n\\nFirst, we use all-mpnet-base-v2, a state-of-the-art pre-trained sentence transformer [154], to produce a 768-dimensional embedding for each opening prompt. Second, we reduce dimensionality to $d = 20$ with UMAP [155], to reduce complexity prior to clustering. For lower dimensional representation prior to clustering, UMAP is more performant than other manifold learning techniques like t-SNE, and more computationally efficient than PCA, but does lack strong interpretability (for a discussion, see McInnes et al. [155]). Third, we cluster the prompts using HDBScan [47], a density-based clustering algorithm, which does not force cluster assignment: 70% of prompts are assigned to 22 clusters and 30% remain as outliers. We use a minimum cluster size of 80, ($\\\\approx 1\\\\%$ of 8,011 prompts) and minimum UMAP distance of 0. Other hyperparameters are default.\\n\\nTo interpret the identified clusters, we use TF-IDF to extract the top 10 most salient uni- and bigrams from each cluster\u2019s prompts, and locate five prompts closest and furthest to the cluster centroids (see Tab. 22). Finally, we use gpt-4-turbo to assign a short descriptive name to each cluster based off the top n-grams and closest prompts. We note that these automated labels may contain biases so we manually verify the suitability of all labels to cluster prompts.\\n\\nDefining over-representation factor\\n\\nEach group $g$ within a demographic attribute appears at a variable base rate $b_g$ in our overall sample, e.g., {Females: 48%, Males: 50%, Non-binary people: 2%}. If group members chose topics at random, then any topic $t$ in expectation will appear at $b_g$. Intuitively, if 64.6% of our sample is White, it is unsurprising if topics are majority-White. So, for non-random group differences in topic prevalence, we consider if a group pulls more than its weight:\\n\\n$$\\\\text{Over-representation factor } g,t = \\\\frac{N_{g,t}}{N_t} \\\\times b_g$$\\n\\nEstimating topic prevalence regressions\\n\\nFor the partial contribution of each demographic attribute, ceteris paribus, we estimate the following regression for each topic $y_t$ for $t \\\\in 1, \\\\ldots, 22$:\\n\\n$$y_{j,i,c} = \\\\alpha_t + \\\\text{gender}^\\\\prime_i \\\\beta_{t1} + \\\\text{age}^\\\\prime_i \\\\beta_{t2} + \\\\text{birth_region}^\\\\prime_i \\\\beta_{t3} + \\\\text{ethnicity}^\\\\prime_i \\\\beta_{t4} + \\\\text{religion}^\\\\prime_i \\\\beta_{t5} + \\\\text{prompt}^\\\\prime_i \\\\beta_{t6} + \\\\epsilon_{i,c}$$\\n\\n(1)\\n\\nwhere $y_{t,i,c} = 1$ if the prompt of participant $i$ in conversation $c$ is categorized into topic $t$. The vectors gender, age, region, ethnicity, religion and conversation type represent different sets of binary variables. For each set of variables, we remove the following base categories: Male, 18-24 years old, United States, White, Not religious and Unguided. The coefficients of interest are contained in the vectors: $\\\\{\\\\beta_{td}\\\\}_{d=1}^6$. Component $g$ of vector $\\\\beta_{td}$ can be interpreted as the increase in probability of a participant choosing topic $t$ if they are in the group indexed by $g$ (e.g., Female) compared to the base group (e.g., Male). We estimate equation Eq. (1) with an Ordinary Least Squares and cluster standard errors at the individual level. Extended results are in Fig. 23.\\n\\nR.2 Topic Prevalence Regression Results\\n\\nOf 682 coefficients tested, 16% are significant ($n = 110$, $\\\\alpha = 99\\\\%$). Many significant coefficients come from the conversation type regressors. Controlling for conversation type, there are 565 non-significant, and 73 significant relationships in $\\\\{\\\\beta_{td}\\\\}_{d=2}^6$ (11.4% of demographic affiliations tested are significant). These include women and non-binary people are more likely than men to talk about gender and LGBTQ+ identity; older people (55+) are more likely to talk about elections and seek travel recommendations than younger people (18-24 years), and less likely to discuss managing relationships or job search; Black participants talk less about climate change than White participants;\"}"}
{"id": "DFr5hteojx", "page_num": 68, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"and almost all regions question LLMs about abortion less often than US participants. Multicolinearity may explain some observed patterns: 94% of participants from the Middle East region are from Israel; 57% identify religiously as Jewish; and 40% have self-described ethnicities falling into \u201cOther\u201d. The strong significant effect on Middle Eastern participants discussing the Israel-Palestine conflict could have been routed through national, ethnic or religious affiliations. Over the 22 topic regressions, the proportion of explained variance ($R^2$) ranges from a minimum of 0.008 (Exploring AI and Machine Learning) to a maximum of 0.11 (Managing Relationships), with a mean of 0.03. So a large proportion of topic choice remains unexplained by our specification.\\n\\n**Figure 23:** Magnitude and significance of coefficients from topic prevalence regressions.\\n\\n* indicates significance at a conservative 99% confidence level. Each categorical association is compared relative to a reference group (in grey boxes). Estimates less than zero (in pink) indicate authors from that demographic group are less likely to have prompts in the given topic, ceteris paribus. Positive estimates (in green) suggest group members are more likely to author prompts in that topic. We only display groups with at least 20 unique members and remove Prefer not to say groups; but all groups are included as controls in the regression. Note that different locations also have varying country-wise heterogeneity vs homogeneity, for example 94% of Middle East participants are from Israel (see App. H for geographic breakdowns).\"}"}
{"id": "DFr5hteojx", "page_num": 69, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 24: Topic clusters displayed in 2D-embedding space. All participant prompts in the first turn ($n = 8,011$) are embedded into 768-d space using a sentence-transformer, before dimensionality reduction (UMAP) and clustering (HDBSCAN) are applied (see methods in App. R.1). 32% of prompts remain as outliers (not shown in the plot).\\n\\nFigure 25: Distribution of clusters by conversation ID and participant ID. For most clusters, participants uniquely contribute one conversation, so that no cluster is dominated by conversations from only a handful of participants. Managing Relationships has the highest participant-conversation ratio, where each participant in the cluster authors on average 1.3 prompts. For Discussions on Abortion, it is exactly 1:1 (158 conversations from 158 unique participants).\"}"}
{"id": "DFr5hteojx", "page_num": 70, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Identity Attribute | Expected Proportion |\\n|-------------------|--------------------|\\n| Gender            | Female: 0.0        |\\n|                   | Male: 0.2          |\\n|                   | Non-binary / third gender: 0.8 |\\n| Age               | 18-24 years old: 0.0 |\\n|                   | 25-34 years old: 0.2 |\\n|                   | 35-44 years old: 0.4 |\\n|                   | 45-54 years old: 0.6 |\\n|                   | 55-64 years old: 0.8 |\\n|                   | 65+ years old: 1.0  |\\n| Ethnicity         | Asian: 0.0         |\\n|                   | Black / African: 0.2 |\\n|                   | Hispanic / Latino: 0.4 |\\n|                   | Indigenous / First Peoples: 0.6 |\\n|                   | Middle Eastern / Arab: 0.8 |\\n|                   | Mixed: 1.0         |\\n|                   | Other: 0.0         |\\n|                   | White: 0.0         |\\n| Religion          | Agnostic: 0.0      |\\n|                   | Buddhist: 0.2      |\\n|                   | Christian: 0.4     |\\n|                   | Folk religion: 0.6 |\\n|                   | Hindu: 0.8        |\\n|                   | Jewish: 0.0       |\\n|                   | Muslim: 0.2       |\\n|                   | Non-religious: 0.4 |\\n|                   | Other: 0.6        |\\n|                   | Sikh: 0.0         |\\n|                   | Spiritual: 1.0     |\\n| Location          | Africa: 0.0       |\\n|                   | Asia: 0.2         |\\n|                   | Australia and New Zealand: 0.4 |\\n|                   | Europe: 0.6       |\\n|                   | Latin America and the Caribbean: 0.8 |\\n|                   | Middle East: 1.0  |\\n|                   | Northern America: 0.0 |\\n|                   | Oceania: 0.2      |\\n|                   | UK: 0.4           |\\n|                   | US: 0.6           |\\n\\nFigure 26: Proportion of each identity attribute group across clusters, relative to the expected proportion of participants in PRISM. By expected proportion, we refer to the proportion in random samples of participants (base rate). Anecdotally, there are differences relative to the expected proportion, but generally no topic is exclusive to authors of a single demographic group. Every topic has some diverse representation across individuals of different backgrounds.\"}"}
{"id": "DFr5hteojx", "page_num": 71, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Conversation type                  | Animal and Pet Inquiries (0) | Economic Policy and Income Inequality (5) | Gender and LGBTQ+ Identity (9) | Global War Discussions (10) | Greeting Introductions (11) | Job Search (15) | Managing Relationships (16) | Recipe and Cooking Queries (18) | Religion and Spirituality (19) | Travel Recommendations (20) | Weather Inquiries (21) |\\n|------------------------------------|-----------------------------|------------------------------------------|-------------------------------|----------------------------|----------------------------|----------------|-----------------------------|-----------------------------|----------------------------|-----------------------------|------------------------|\\n| Ethnicity                          | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n| Location                           | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Middle East                  | Middle East                 | Middle East                | Middle East                | Asia                    |\\n| Religion                           | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n| Gender                             | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Other                       | Other                                     | Other                         | Other                       | Other                      | Other         | Other                        | Other                      | Other                      | Other                      | Other                  |\\n|                                    | Male                        | Female                                    | Jewish                        | Muslim                      | Christian                   | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Female                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Mixed                       | USA                                       | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female                      | Hispanic                   | Jewish                     | White                   |\\n|                                    | Jewish                      | Male                                      | Jewish                        | Muslim                      | Christian                   | Middle East   | Female                       | Male                        | Hispanic                   | Jewish                     | White                   |\\n|                                    | Asian                       | US                                        | UK                           | Asia                        | UK                         | Middle East   | Male                         | Female"}
{"id": "DFr5hteojx", "page_num": 72, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Topic Name | Size | Pct | Top Words | Closest Texts | Furthest Texts |\\n|------------|------|-----|----------|--------------|---------------|\\n| Outliers   | 2578 | 32.2% | \u201cthink\u201d, \u201cpeople\u201d, \u201chello\u201d, \u201ctell\u201d, \u201clike\u201d, \u201chi\u201d, \u201clife\u201d, \u201cdoes\u201d, \u201ctalk\u201d, \u201cgood\u201d | \u201cHello\u201d, \u201cHow do I become financially stable on a low income\u201d, \u201cHow do I deal with a confrontational coworker that does not value or contribute to the team environment?\u201d, \u201cWhat is the likely cause of death of the late, great Matthew Perry?\u201d, \u201cDo God exist?\u201d | \u201cWhat do you think about China's implementation of communism?\u201d, \u201crequest or talk to the model about something controversi\u201d, \u201ctalk to the model about something important\u201d, \u201cHow can I organize my fridge? It's full of rotten vegetables, expired cheese, plastic bags of mystery flour\u2026\u201d, \u201cWhich type of smartphone do you use?\u201d, \u201cWhat do you think about China's implementation of communism?\u201d, \u201crequest or talk to the model about something controversi\u201d, \u201ctalk to the model about something important\u201d, \u201cHow can I organize my fridge? It's full of rotten vegetables, expired cheese, plastic bags of mystery flour\u2026\u201d, \u201cWhich type of smartphone do you use?\u201d |\\n| Managing Relationships | 816 | 10.2% | \u201cfamily\u201d, \u201crelationship\u201d, \u201cimportant\u201d, \u201cthink\u201d, \u201cvalues\u201d, \u201clove\u201d, \u201cfriend\u201d, \u201cpeople\u201d, \u201cmarriage\u201d, \u201cperson\u201d | \u201cWhat advice would you give for a man betrayed by his family and friends over and over again, how could someone like that exist in a world where the only way to succeed is by benefiting from nepotism?\u201d, \u201cI feel like accepting toxic behavior from a person that supposedly loves you is ok to elicit a toxic response. What do you think?\u201d, \u201cWhat boundaries would you teach someone that is disrespected.\u201d, \u201cHi. I hope you are doing well. I wanted to ask, how do you deal with someone in a relationship that disrespect most of your values and principles but does not necessarily respect you as a person.\u201d, \u201cDo you think it's unhealthy for a 62 year old single woman to spend all her time alone even if she's content and fulfilled?\u201d | \u201cHow can we make the world a better place for everyone?\u201d, \u201cAre Americans less empathetic than we used to be?\u201d, \u201cWhat is social good?\u201d, \u201cwhat makes the world better\u201d, \u201cHow can I figure out what sort of job I should do that would make the world a better place?\u201d |\\n| Popular Culture (Sports, Music, TV) | 493 | 6.2% | \u201cgame\u201d, \u201cbest\u201d, \u201cfootball\u201d, \u201cmusic\u201d, \u201cgames\u201d, \u201cmovie\u201d, \u201cvideo\u201d, \u201clike\u201d, \u201cthink\u201d, \u201cworld\u201d | \u201cHow many people love Star Trek?\u201d, \u201cI enjoy watching soaps on television\u201d, \u201cWhat makes the \u201cStar Trek\u201d franchise such an important and enduring classic of TV. More specifically- what values and beliefs make it great and classic?\u201d, \u201cStar wars or Star trek?\u201d, \u201cWhat is the appeal of such franchises as Star Wars, Harry Potter, the Lion King and Indiana Jones to adults? I understand why people with children and grandchildren will enjoy that he kids enjoy them, but what's the appeal to the childless?\u201d | \u201cWrite me a story with a very sad ending\u201d, \u201cCreate a short horror story two paragraphs long.\u201d, \u201cWrite a 100 word story about Donald Trump in the style of Cinderella\u201d, \u201cI like you to tell me a story. It should be in a Harry Potter like world. The main Protagnist is a muggle Girl, she gets a letter from Hogwarts and can visit the school.\u201d, \u201ci want you to tell me a story of a vampire and 3 witches brides who live in a farm in tasmania\u201d |\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 73, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 22: Full Topic Cluster Outline.\\n\\nFor each cluster, we show the **Topic Name** (labelled by gpt-4-turbo based on the Top Words and Closest Texts. For Closest Texts (**n** = 5), the first prompt is the closest to the cluster centroid. For Furthest Texts (**n** = 5), the first prompt is the furthest from the cluster centroid. The cluster method (HDBSCAN) does not assign a cluster for 32% of prompts.\\n\\n**Content Warning:** Some prompts may contain controversial, hateful or otherwise harmful content. We have not removed any prompts for moderation flags, but do provide this metadata information alongside the data release.\\n\\n| Topic Name                  | Size | Pct | Top Words                                                                 | Closest Texts                                                                                      | Furthest Texts                                                                                     |\\n|-----------------------------|------|-----|---------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\\n| Job Search                  | 448  | 5.6%| \\\"work\\\", \\\"job\\\", \\\"money\\\", \\\"make\\\", \\\"time\\\", \\\"working\\\", \\\"home\\\", \\\"best\\\"        | \\\"why is life hard to earn a good wage times are hard and i never seem to have any money\\\"             | \\\"Why are there so many available jobs but no one seem to be able to get one? Especially in tech\\\" |\\n| Religion and Spirituality   | 441  | 5.5%| \\\"religion\\\", \\\"god\\\", \\\"believe\\\", \\\"believe god\\\", \\\"think\\\", \\\"religious\\\", \\\"religions\\\", \\\"church\\\", \\\"people\\\", \\\"think religion\\\" | \\\"What is the difference between being religious or being spiritual?\\\"                                | \\\"I'm a deeply spiritual person but don't feel drawn to organized religion. Do you think a spiritual person should be referred to a being religious or is that reserved for actual religions that have labels?\\\" |\\n| Election and Political Part| 401  | 5.0%| \\\"trump\\\", \\\"donald trump\\\", \\\"donald\\\", \\\"vote\\\", \\\"president\\\", \\\"election\\\", \\\"political\\\", \\\"party\\\", \\\"politics\\\", \\\"think\\\" | \\\"What are the main political parties in France?\\\"                                                   | \\\"What scientific studies have found evidence of psychic powers?\\\"                                  |\\n| Recipe and Cooking Queries  | 360  | 4.5%| \\\"recipe\\\", \\\"make\\\", \\\"dinner\\\", \\\"food\\\", \\\"best\\\", \\\"meal\\\", \\\"cake\\\", \\\"recipes\\\", \\\"cook\\\", \\\"eat\\\" | \\\"I understand the taste maybe different depending on chefs, but can you describe the taste of following dish?:\\\" | \\\"What foods do you recommend to increase muscle mass?\\\"                                           |\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 74, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 22: Full Topic Cluster Outline\\n\\nFor each cluster, we show the **Topic Name** (labelled by gpt-4-turbo based on the **Top Words** and **Closest Texts**. For **Closest Texts** ($n = 5$), the first prompt is the closest to the cluster centroid. For **Furthest Texts** ($n = 5$), the first prompt is the furthest from the cluster centroid. The cluster method (HDBSCAN) does not assign a cluster for 32% of prompts.\\n\\n| Topic Name | Size | Pct | Top Words | Closest Texts | Furthest Texts |\\n|------------|------|-----|-----------|---------------|---------------|\\n| **Israel-Palestine Conflict** | 320 | 4.0% | \u201cisrael\u201d, \u201cpalestine\u201d, \u201cconflict\u201d, \u201cisrael palestine\u201d, \u201chamas\u201d, \u201cgaza\u201d, \u201cwar\u201d, \u201cright\u201d, \u201ccurrent\u201d, \u201cthink\u201d | \u201cIs the Israeli prime minister should remain in office during the war or leave?\u201d, \u201cIs Palestine a terrorist state?\u201d, \u201cWhile I respect the fact that Israel exists, and condemn Hamas terrorism, we must not forget that Israel itself was established after a terrorist campaign, and large numbers of people were forced to leave lands their forebears had lived in for centuries\u201d, \u201cWe are in Israel and currently in a war with terrorist organization (Hamas) that in within Gaza. I agree with the army, that after the attack they initiated on October 7, 2023, Israel should destroy them because they killed many of our innocent civilians and soldiers and all we gave them is peace. Some people within my country still want to give these terrorist lands and provide them with human rights. Please let me know what you think of this people in Israel.\u201d | \u201cHow should America respond to the war that is currently going on?\u201d, \u201cSome people say that there will always be war in the middle east. I heard it was because the borders are set bad?\u201d, \u201cIs Total Nuclear Disarmament a possibility?\u201d, \u201cThe war in Pakistan, your views good or bad?\u201d, \u201cMy social media recommendations has been flooded with news of the ongoing war in Israel and Gaza with so many biased opinions going around. Can you give me just a summary of the conflict.\u201d |\\n| **Gender and LGBTQ+ Identity** | 286 | 3.6% | \u201cwomen\u201d, \u201cgay\u201d, \u201cgender\u201d, \u201cpeople\u201d, \u201cmen\u201d, \u201ctransgender\u201d, \u201cthink\u201d, \u201ctrans\u201d, \u201csex\u201d, \u201cmarriage\u201d | \u201cI dont think its okay for schools to be teaching our children its okay for them to choose their gender and not just be proud of the one they are born with and assigned at birth\u201d, \u201cCan you please explain gender reassignment reasons?\u201d, \u201cDo the disadvantages and possible illnesses that can occur from gender organ changes not outweigh the advantages?\u201d, \u201cwhat is your take on gender realignment\u201d, \u201cMy younger brother is trying to explore his gender expression. What can I do to help and support him?\u201d | |\\n| **Travel Recommendations** | 207 | 2.6% | \u201ctravel\u201d, \u201cbest\u201d, \u201cvisit\u201d, \u201choliday\u201d, \u201ccountry\u201d, \u201cplaces\u201d, \u201clive\u201d, \u201ctrip\u201d, \u201cdestination\u201d, \u201citinerary\u201d | \u201cWhat is the best city in Andalusia?\u201d, \u201cGreece is known for its Island and beaches. What else is in greece\u201d, \u201cWhat city in Chile you recommend me go on vacations?\u201d, \u201cWhich city is the most popular destination for families visiting South Africa?\u201d, \u201cWhat do you think about Las Vegas, Nevada?\u201d | \u201cHow much info do you know about the state of Massachusetts\u201d, \u201cDo you speak Dutch?\u201d, \u201cDo you have information about the German federal state of Baden-W\u00fcrttemberg?\u201d, \u201cWhat do you know about the government in Sweden?\u201d, \u201ccan you tell me the origin of the alcoholic beverage \u201cpisco\u201d? is it chilean or peruvian?\u201d |\"}"}
{"id": "DFr5hteojx", "page_num": 75, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 22: Full Topic Cluster Outline.\\n\\nFor each cluster, we show the **Topic Name** (labelled by gpt-4-turbo based on the **Top Words** and **Closest Texts**). For **Closest Texts** \\\\((n=5)\\\\), the first prompt is the closest to the cluster centroid. For **Furthest Texts** \\\\((n=5)\\\\), the first prompt is the furthest from the cluster centroid. The cluster method (HDBSCAN) does not assign a cluster for 32% of prompts.\\n\\n| Topic Name               | Size | Pct | Top Words                                                                 | Closest Texts                                                                                     | Furthest Texts                                                                                     |\\n|--------------------------|------|-----|---------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\\n| Climate Change           | 193  | 2.4%| \u201cclimate\u201d, \u201cclimate change\u201d, \u201cchange\u201d, \u201cglobal\u201d, \u201cglobal warming\u201d, \u201cwarming\u201d, \u201cthink\u201d, \u201cenvironment\u201d, \u201cchange real\u201d, \u201chumans\u201d | \u201cPresent are argument in favor of starting geoengineering now to combat climate change. Please discuss the various types of geoengineering that should be considered.\u201d, \u201cWhat do you think about ecology\u201d, \u201cHow important it is that we start acting against climate change?\u201d, \u201cI wonder when Yellowstone will blow up, if at all.\u201d, \u201cAre environmental issue as serious as people are maintaining\u201d | \u201cStopping the manufacturing of fuel based vehicles could help the world tremendously in terms of saving the ozone layer\u201d, \u201cI think cars are ruining the environment\u201d, \u201cShould we use disposable kitchenware?\u201d, \u201cWe should not ban single use plastic bags\u201d, \u201cMy neighbours never collect their own recycling bins, what should i say to them?\u201d |\\n| Animal and Pet Inquiries | 188  | 2.3%| \u201cdog\u201d, \u201ccats\u201d, \u201cdogs\u201d, \u201ccat\u201d, \u201canimal\u201d, \u201canimals\u201d, \u201cbreed\u201d, \u201cpets\u201d, \u201cpet\u201d, \u201clike\u201d | \u201cHello, can you tell me about monkeys?\u201d, \u201cI\u2019m thinking about getting chickens to keep as pets.\u201d, \u201cHello! What can you tell me about animals?\u201d, \u201cHello, what do you know about pet rabbits?\u201d, \u201cWhat are animals\u201d | \u201cI don\u2019t think that animals get treated fairly by the meat industry\u201d, \u201cI feel like dogs make bad pets and considering that pigs are more intelligent, we should eat more dog meat instead of pigs.\u201d, \u201cwhy do we have 10 toes?\u201d, \u201cWhat are some interestingly colored dinosaurs?\u201d, \u201cI\u2019d like to know why is it that there is a lot of evidence of giant skeletons being found all over the world but most people don\u2019t know about them. These giants used to be 10 or even 20 feet tall. They used to be in many museums over 100 years ago but nowadays you can\u2019t find them anywhere. Why?\u201d |\\n| Discussions on Abortion  | 158  | 2.0%| \u201cabortion\u201d, \u201cthink abortion\u201d, \u201clegal\u201d, \u201cabortion legal\u201d, \u201cpro\u201d, \u201cthink\u201d, \u201cabortion abortion\u201d, \u201cabortion think\u201d, \u201cpro life\u201d, \u201cabortions\u201d | \u201cAbortion is killing an innocent baby\u2019s life and should be banned by government and made illegal.\u201d, \u201cAbortion is a right, but people should try to avoid it as much as possible\u201d, \u201cWhat are the viewpoints on abortion and why each makes sense?\u201d, \u201cWhat are some arguments in favor/against abortion?\u201d, \u201cWhat are the arguments for abortion.\u201d | \u201cis abortion bad\u201d, \u201cDo you think that femicide should exist as a term or is it unnecessary?\u201d, \u201cwhat do you think about abortion?\u201d, \u201cI need access to an abortion. Does this make me a bad person?\u201d, \u201cIs abortion bad?\u201d |\\n| Economic Policy and Income Inequality | 135 | 1.7%| \u201cpeople\u201d, \u201chomeless\u201d, \u201cthink\u201d, \u201cincome\u201d, \u201crich\u201d, \u201cmoney\u201d, \u201ctax\u201d, \u201cwage\u201d, \u201cgovernment\u201d, \u201cpaid\u201d | \u201cHello. What do you know about wealth inequality in Britain?\u201d, \u201chow can we implement base social income for all?\u201d, \u201cDo you think universal basic income is a great way to lift people out of poverty?\u201d, \u201chow can the government reduce the unemployment rate?\u201d, \u201chow can we broaden the tax base in australia?\u201d | \u201cI believe people with qualifications should be paid more in the workplace than those without any.\u201d, \u201cwhat is the most important charity organization worldwide?\u201d, \u201cHow much money in % should one give to charities in your opinion?\u201d, \u201cHow do we ensure that people who need help receive it?\u201d, \u201cI think people who do not work should not eat.\u201d |\"}"}
{"id": "DFr5hteojx", "page_num": 76, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 22: Full Topic Cluster Outline.\\n\\nFor each cluster, we show the **Topic Name** (labelled by gpt-4-turbo based on the **Top Words** and **Closest Texts**. For **Closest Texts** (*n* = 5), the first prompt is the closest to the cluster centroid. For **Furthest Texts** (*n* = 5), the first prompt is the furthest from the cluster centroid. The cluster method (HDBSCAN) does not assign a cluster for 32% of prompts.\\n\\n### Content Warning:\\nSome prompts may contain controversial, hateful or otherwise harmful content. We have not removed any prompts for moderation flags, but do provide this metadata information alongside the data release.\\n\\n| Topic Name                          | Size | Pct | Top Words                                                                 | Closest Texts                                                                 | Furthest Texts                                                                 |\\n|------------------------------------|------|-----|---------------------------------------------------------------------------|------------------------------------------------------------------------------|-------------------------------------------------------------------------------|\\n| Debating Immigration Policies      | 131  | 1.6%| \\\"immigration\\\", \\\"immigrants\\\", \\\"uk\\\", \\\"country\\\", \\\"europe\\\", \\\"people\\\", \\\"migrants\\\", \\\"borders\\\", \\\"think\\\", \\\"countries\\\" | \\\"migrants shouldnt be allowed on our country\\\"                               | \\\"Please give me a response to someone arguing online that we should deport as many immigrants as possible. I think that immigration is a good thing but need help arguing my point.\\\" |\\n| Greeting Introductions             | 131  | 1.6%| \\\"today\\\", \\\"hi\\\", \\\"hello\\\", \\\"doing\\\", \\\"good\\\", \\\"hey\\\", \\\"day\\\", \\\"good morning\\\", \\\"doing today\\\", \\\"today hello\\\" | \\\"hello.nice to greet you\\\"                                                      | \\\"HI, nice to meet you\\\"                                                        |\\n| Exploring AI and Machine Learning  | 129  | 1.6%| \\\"ai\\\", \\\"think ai\\\", \\\"think\\\", \\\"future\\\", \\\"models\\\", \\\"humans\\\", \\\"model\\\", \\\"human\\\", \\\"like\\\", \\\"ai ai\\\" | \\\"What is the best area to talk about to make the most of the big data available to an AI. Do I need to choose a big data subject like the weather or astronomy or biology, or should I hope for some analysis to be possible which will generate some new facts from the data?\\\" | \\\"Tell me something about ai\\\"                                                  |\\n| Ethics of Death and Killing        | 119  | 1.5%| \\\"death\\\", \\\"death penalty\\\", \\\"penalty\\\", \\\"suicide\\\", \\\"assisted\\\", \\\"assisted suicide\\\", \\\"euthanasia\\\", \\\"punishment\\\", \\\"think\\\", \\\"people\\\" | \\\"Are there any religions that believe the taking of another persons life is acceptable in some circumstances\\\" | \\\"how does people see death in mexico?\\\"                                      |\\n| |||||\\\"Do you think murder is acceptable?\\\" | \\\"Is it ok to kill?\\\" |\\n| |||||\\\"can it be right to kill someone even if you know they are going to do something terrible?\\\" | \\\"Do burglar alarms in homes really keep you safer?\\\" | \\\"sex-work should be made legal.\\n\\nContinued on next page\"}"}
{"id": "DFr5hteojx", "page_num": 77, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Topic Name                  | Size | Pct | Top Words                                      | Closest Texts                                                                                           | Furthest Texts                                                                                           |\\n|----------------------------|------|-----|-----------------------------------------------|--------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\\n| Health and Wellness Advice  | 111  | 1.4%| \u201cexercise\u201d, \u201croutine\u201d, \u201ctips\u201d, \u201cplan\u201d, \u201cway\u201d, \u201csleep\u201d, \u201cbest\u201d, \u201csymptoms\u201d, \u201cworkout\u201d, \u201cmorning\u201d | \u201cWhat type of running shoes are the best for someone that has knee problems?\u201d, \u201cShould I think about starting using botox for wrinkles?\u201d, \u201chi whats the best way to cure reactive arthritis\u201d, \u201cWhat is the best skin care routine for someone over 30\u201d, \u201cI love playing soccer but my feet hurts anytime i try it... What do i do?\u201d | \u201cI work out everyday but I am not loosing weight\u201d, \u201cWhy is type 2 diabetes so prevalent in modern society?\u201d, \u201cshould child obesity be considered child endangerment commited by their parents?\u201d, \u201cIs being fat is ok?\u201d, \u201cdo i look fat?\u201d |\\n| Discussions on Race and Racism | 99  | 1.2%| \u201cblack\u201d, \u201cblack people\u201d, \u201cracism\u201d, \u201cpeople\u201d, \u201cwhite\u201d, \u201cracist\u201d, \u201cwhite people\u201d, \u201crace\u201d, \u201clives\u201d, \u201cafrican\u201d | \u201cIs it okay for brown people who aren\u2019t African American to say the n-word?\u201d, \u201cBlack people should stop using the N word if they want everyone else to stop using it\u201d, \u201ci dont like black people. what do you think?\u201d, \u201cHot take: I think Blackpink is butt.\u201d, \u201cShould remakes of well known stories cast actors of different skin colors\u201d | \u201cA small minority of the population are forcing their views on diversity on the majority\u201d, \u201cPeople should live separately according to their race.\u201d, \u201cWhat is BDS movement?\u201d, \u201cis aggression genetic\u201d, \u201cWhat is the BLM movement?\u201d |\\n| Holiday Celebration Planning | 98  | 1.2%| \u201cchristmas\u201d, \u201cbirthday\u201d, \u201ccelebrate\u201d, \u201cparty\u201d, \u201ccelebrate christmas\u201d, \u201cideas\u201d, \u201choliday\u201d, \u201cneed\u201d, \u201cyear\u201d, \u201cbirthday party\u201d | \u201cPlan a series of 25 self-care activities to create an advent calender-inspired activity. Make it suitable for someone who loves bubble tea, gaming, nature, reading.\u201d, \u201cIs it a good idea to buy my kids a Christmas calendar or make one myself?\u201d, \u201cWhat\u2019s the best gift for my children\u201d, \u201chow many presents do you think you should get your kids a piece for christmas?\u201d, \u201cCan you please plan the perfect Christmas eve for me?\u201d | \u201cHi! can you give me some DIY project ideas for my bedroom?\u201d, \u201chi, can you help me with halloween customes ideas?\u201d, \u201cSuggest some crafts using all or some of the following supplies: glue gun, crayons, cotton balls, q tips, tissue boxes\u201d, \u201cI want to publish a coloring book for Amazon. I need ideas that children would enjoy that aren\u2019t overused. Can you give me a list of ideas?\u201d, \u201crecommend gifts for my girlfriend\u201d |\\n| Weather Inquiries          | 85  | 1.1%| \u201cweather\u201d, \u201ctoday\u201d, \u201cweather like\u201d, \u201clike\u201d, \u201csnow\u201d, \u201cweather today\u201d, \u201cgoing\u201d, \u201clike today\u201d, \u201chello weather\u201d, \u201ctomorrow\u201d | \u201cWhat is the weather like in California today?\u201d, \u201cis the weather nice in margate tomorrow\u201d, \u201cWhat will New Zealand\u2019s weather be like this summer?\u201d, \u201cWhat is the weather like today in London please?\u201d, \u201cWhat is the weather in Vancouver?\u201d | \u201cHello. I am wondering when the Christmas lights are being turned on at Blackpool\u201d, \u201cHello, when does winter officially start\u201d, \u201chow big is the average penis in vancouver bc\u201d, \u201cIt\u2019s very hot today, how do I deal with it?\u201d, \u201cWill the South have a cold winter?\u201d |\\n| Global War Discussions      | 84  | 1.0%| \u201cwar\u201d, \u201cukraine\u201d, \u201crussia\u201d, \u201cwar ukraine\u201d, \u201cwars\u201d, \u201cworld war\u201d, \u201cworld\u201d, \u201crussian\u201d, \u201cthink\u201d, \u201crussia war\u201d | \u201cWho is the responsible of the war in the globe?\u201d, \u201cWhat do you think about North Korea?\u201d, \u201cWhy the world doesn\u2019t interfere the help the north korean people\u201d, \u201cWhy does the US front proxy wars rather than spending money on suffering in its own country?\u201d, \u201cWhy the Vietnam war started?\u201d | \u201cwhen will WW3 come?\u201d, \u201cWhat you think about Finland closing borders with Russia?\u201d, \u201cDo you see the WW3 in the horizon?\u201d, \u201cdo humans need conflict?\u201d, \u201cwill we have a world war?\u201d |\"}"}
{"id": "DFr5hteojx", "page_num": 78, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"S Case Study IB: Local Neighbourhoods and Empirically-Fixed Contexts\\n\\nS.1 Extended Methods\\n\\nExtracting local neighbourhoods\\n\\nTo understand dialogue spaces more granularly than topic, we examine local neighbourhoods within the embedding space of opening prompts. We create local neighbourhood via a single-link hierarchical clustering algorithm \\\\[156, 157\\\\], that iteratively merges neighbourhoods within a cosine distance threshold (\\\\(\\\\tau_{\\\\text{cos}}\\\\)), so that the neighbourhood size (\\\\(k\\\\)) can vary but the semantic similarity of its members is tightly constrained. We opt to use this method because it is transparent and interpretable.\\n\\n**Algorithm 1**\\n\\n**Single-link hierarchical clustering**\\n\\n**Require:**\\n\\n- \\\\(E = \\\\{e_1, e_2, \\\\ldots, e_n\\\\}\\\\), a set of \\\\(n\\\\) embeddings;\\n- \\\\(\\\\tau_{\\\\text{cos}}\\\\), a cosine similarity threshold.\\n\\n**Ensure:**\\n\\n- \\\\(\\\\Omega = \\\\{\\\\omega_1, \\\\omega_2, \\\\ldots, \\\\omega_n\\\\}\\\\), neighbourhood assignments for each embedding, where each \\\\(\\\\omega_j\\\\) is the neighbourhood ID assigned to embedding \\\\(e_i\\\\), and multiple embeddings (prompts) can be assigned to one neighbourhood.\\n\\n1: function \\\\(\\\\text{LOCAL NEIGHBOURHOODS}(E, \\\\tau_{\\\\text{cos}})\\\\)\\n2: Initialize \\\\(\\\\Omega\\\\) with a unique neighbourhood ID for each embedding in \\\\(E\\\\).\\n3: Compute pairwise cosine distances for all pairs in \\\\(E\\\\).\\n4: for each pair \\\\((e_i, e_j)\\\\) with distance \\\\(\\\\leq \\\\tau_{\\\\text{cos}}\\\\) and \\\\(i > j\\\\) do\\n5: Merge the neighbourhood of \\\\(e_i\\\\) into the neighbourhood of \\\\(e_j\\\\).\\n6: end for\\n7: Consolidate neighbourhood IDs to ensure sequential numbering.\\n8: return \\\\(\\\\Omega\\\\)\\n9: end function\\n\\nWe remove any singleton neighbourhoods (\\\\(k = 1\\\\)), and ego non-singleton neighbourhoods containing only prompts authored by same participant. For each remaining local neighbourhood, we capture the demographic characteristics of prompt authors. We repeat this analysis examining properties of the neighbourhoods for \\\\(\\\\tau_{\\\\text{cos}} \\\\in [0.05, 0.125, 0.2]\\\\). Cosine distances can lack robustness in high-dimensions but this favours underestimating semantic similarity: if cosine distance is high, this doesn't mean things are not similar, but if cosine distance is low, then items are certainly very similar (more strict). If an author appears twice, we double count their characteristics to avoid overestimating diversity (more strict); But most prompts are from non-duplicated authors (<4% averaged across neighbourhoods). Most duplicates come in the \u201cgreetings\u201d topic e.g. \u201cHello\u201d.\\n\\nMeasuring intersectional entropy\\n\\nWe require a summary metric of between-participant diversity to understand the composition of local neighbourhoods. Let \\\\(D\\\\) represent the set of demographic attributes, e.g. gender, age and ethnicity. For each \\\\(d \\\\in D\\\\), there are \\\\(n\\\\) possible groups \\\\(\\\\{g_1, g_2, \\\\ldots, g_n\\\\}\\\\) (e.g. Male, Female, Non-binary). For a neighbourhood size of \\\\(k\\\\), the prevalence of each group \\\\(p_i\\\\) is \\\\(\\\\frac{\\\\hat{g}_i}{k}\\\\), and the per demographic Shannon entropy is:\\n\\n\\\\[\\nH(d) = -\\\\sum_{i=1}^{n} p_i \\\\log_2(p_i)\\n\\\\]\\n\\nSeveral adjustments are required. First, different attributes have varying \\\\(n\\\\): there are more possible geographic regions than genders. Second, not every group appears equally within a demographic: men are more common in the data than non-binary people. Finally, the expected diversity of a neighbourhood grows with \\\\(k\\\\). To account for these factors, we simulate the expected entropy based on randomly sampling a \\\\(k\\\\)-sized neighbourhood at population-wide probabilities as:\\n\\n\\\\[\\nH_{\\\\text{exp}}(d, k) \\\\approx -\\\\frac{1}{m} \\\\sum_{j=1}^{m} \\\\sum_{i=1}^{n} \\\\hat{g}_{i,j} \\\\frac{1}{k} \\\\log_2 \\\\left( \\\\frac{\\\\hat{g}_{i,j}}{k} \\\\right)\\n\\\\]\\n\\nAfter making this adjustment per attribute, total entropy of the neighbourhood is additive:\\n\\nAdjusted Intersectional Entropy\\n\\n\\\\[\\nH_{\\\\text{total}} = \\\\sum_{d \\\\in D} H(d) - H_{\\\\text{exp}}(d, k)\\n\\\\]\"}"}
{"id": "DFr5hteojx", "page_num": 79, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 28: Intersectional diversity of local neighbourhoods ($\\\\tau_{\\\\cos} = 0.125$). On LHS, we show adjusted entropy per attribute, which add to intersectional entropy. Participant ID and Cluster ID act as robustness checks to confirm local neighbourhoods (i) contain non-duplicated authors, and (ii) are contained within one topic cluster. On RHS, we show neighbourhood diversity by neighbourhood size, rebased relative to expected entropy $\\\\frac{1}{k}$. 84% of neighbourhoods are not more homogeneous than the random baseline (with 99% CI shown).\\n\\nS.2 Local Neighbourhood Headline Results\\n\\nWe first present findings for $\\\\tau_{\\\\cos} = 0.125$ (the threshold recommended by Hale [157]), then present similar findings for other $\\\\tau_{\\\\cos}$ in App. S.3. From 8,011 prompts, there are only 273 unique local neighbourhoods (3.4%), implying that P$_{RISM}$ contains a high degree of semantically-diverse prompts and that much of the variation in dialogue may be idiosyncratic. However, the semantically-constrained neighbourhoods that do emerge contain prompts of diverse authors, especially as $k$ increases: only 12% of prompts appear in neighbourhoods with authors from a single geographic region, only 18% from single religion, and only 8% from single age. Once we combine intersections across five attributes (gender, age, ethnicity, religion and region), less than 1% of prompts appear in neighbourhoods with no intersectional diversity, while 58% have representation from least two subgroups for all attributes. 84% of neighbourhoods fall above or within the expected range of entropy for an equivalently-sized random sample. While tightly-clustered dialogue spaces tend to be heterogeneous, we anecdotally observe some homogeneous neighbourhoods\u2014the largest of which contain discussions of gun laws by predominantly White participants only in the US; and of Scottish independence, Brexit and UK elections from White participants in the UK. Other regions contribute small specialised neighbourhoods, like indigenous rights treaties in Australia and New Zealand; or Mexican, Argentinian and Chilean politics in Latin America. In contrast, many of the largest neighbourhoods present cross-border perspectives on controversial issues like abortion and the Israel-Palestine conflict (Fig. 28).\\n\\nS.3 Local Neighbourhood Robustness Checks\\n\\nIn Tab. 23, we present summary statistics for the results discussed in \u00a7 3.1 but at varying cosine distance thresholds. At $\\\\tau_{\\\\cos} = 0.05$, the prompts in the neighbour are semantically identical: $k = 14$: ['Do God exist?', 'Does God exist?', 'Does God exist?', 'Does God exist?', 'Does God exist?', 'Does God exist?', 'Does god exist?', 'does God exist?', 'does god exist', 'does god exist?', 'does god exist?', 'does god exist?', 'does god exist?', 'does god exist?']. At $\\\\tau_{\\\\cos} = 0.125$ (results in main paper), there is some phrasal and syntactic variation: $k = 23$: ['Hey, what do you think about the israeli-palestinian conflict?', 'Thoughts on the Palestinian-Israeli conflict?', 'What are your thoughts on the current Israel-Palestine conflict?', 'What do you think about Israel vs Palestine?', 'What do you think about Palestinian and Israel conflict?', 'What do you think about the Israeli-Palestinian conflict?', 'What do you think about the ongoing war between Israel and Palestine']. Finally, at $\\\\tau_{\\\\cos} = 0.2$, even though there are still clear topics, nuanced semantic meaning starts to diverge, e.g. with different stances and sentiments:\"}"}
{"id": "DFr5hteojx", "page_num": 80, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 23: Summary statistics for local neighbourhoods at varying cosine thresholds.\\n\\nOverall, we show similar conclusions across a range of thresholds from very strict (only formatting and capitalisation differences) to more lenient (phrasing differences).\\n\\n| \\\\( \\\\tau_{\\\\text{cos}} \\\\) | Non-singleton neighbourhoods \\\\( N \\\\) | 154 | 273 | 419 |\\n|--------------------------|----------------------------------|-----|-----|-----|\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0 \\\\) | % total prompts appearing in neighbourhoods | 1.92 | 3.41 | 5.23 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.05 \\\\) | \\\\( \\\\max k \\\\) | 2 | 2 | 2 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.125 \\\\) | \\\\( \\\\min k \\\\) | 60 | 62 | 98 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.2 \\\\) | \\\\( \\\\text{mean } k \\\\) | 3.66 | 3.77 | 4.08 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.25 \\\\) | \\\\( \\\\text{std } k \\\\) | 5.83 | 5.73 | 8.03 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.3 \\\\) | Gender entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | 0.09 \u00b1 0.85 | -0.08 \u00b1 0.84 | -0.08 \u00b1 0.83 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.35 \\\\) | Age entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | -0.03 \u00b1 0.47 | -0.02 \u00b1 0.46 | -0.04 \u00b1 0.47 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.4 \\\\) | Ethnicity entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | 0.03 \u00b1 0.80 | -0.01 \u00b1 0.80 | -0.05 \u00b1 0.79 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.45 \\\\) | Religion entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | 0.04 \u00b1 0.84 | 0.04 \u00b1 0.81 | 0.02 \u00b1 0.81 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.5 \\\\) | Location entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | -0.06 \u00b1 0.45 | -0.13 \u00b1 0.48 | -0.14 \u00b1 0.48 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.55 \\\\) | Cluster ID entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | -1.00 \u00b1 0.00 | -0.99 \u00b1 0.11 | -0.98 \u00b1 0.15 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.6 \\\\) | Participant ID entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | -0.00 \u00b1 0.03 | -0.00 \u00b1 0.02 | -0.00 \u00b1 0.03 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.65 \\\\) | Intersectional entropy \\\\( (\\\\mu, \\\\sigma) \\\\) | 0.08 \u00b1 1.73 | -0.19 \u00b1 1.73 | -0.29 \u00b1 1.72 |\\n| \\\\( \\\\tau_{\\\\text{cos}} = 0.7 \\\\) | % neighbourhoods \\\\( \\\\geq \\\\) expected entropy (99% CI) | 86.36 | 84.25 | 80.67 |\\n\\nS.4 Empirically-Retrieved Fixed Dialogue Contexts\\n\\nWhile datasets like DICES [79] explicitly ask multiple raters to examine the same context, we can empirically retrieve such contexts from PRISM using the local neighbourhood methods discussed in App. S.1 (with Algorithm 1). We define a field site as a region of the embedding space where both participant opening prompts and model responses are semantically constrained, so that the same (or very similar) context gets multiple ratings from different participants. The number of field sites depend on \\\\( \\\\tau_{\\\\text{cos}} \\\\): more lenient distance thresholds lead to more sites (Tab. 24). However, even with strict thresholds (\\\\( \\\\tau_{\\\\text{cos}} = 0.05 \\\\)), we find field sites with substantial range in scores (\\\\( \\\\mu = 36.3, \\\\sigma = 26.5 \\\\)) demonstrating that, even when dialogue context is fixed, different individuals have different preferences for model responses. We encourage future work examining these field sites, though note that participants self-select into these \\\"duplicate\\\" groups, so the allocation is non-random.\\n\\nEven in these very strict local neighbourhoods, we find evidence of intersectional diversity. When \\\\( \\\\tau_{\\\\text{cos}} = 0.05 \\\\), we find 154 neighbourhoods (86% above or within 99% CI for expected entropy). The five largest of these contain 14\u201360 prompts, varying only in capitalisation and punctuation. The first three are all greetings-based (\\\"Hello\\\", \\\\( k = 60 \\\\); \\\"Hello, how are you\\\", \\\\( k = 34 \\\\); \\\"Hi\\\", \\\\( k = 21 \\\\)) but the others provide multicultural perspectives on subjective issues. One neighbourhood (\\\"Does God exist?\\\", \\\\( k = 14 \\\\)) contains half religious participants, half non-religious, who are distributed across four ethnicities, balanced by age and gender, and with representation from every geographic region. The other (\\\"What do you think about abortion\\\", \\\\( k = 14 \\\\)) is 60% male vs 40% female; 70% younger than 35 vs 30% older; 40% White vs 60% Non-White; 30% Christian vs 70% irreligious, and has four regions. Each prompt receives up to four model responses, so these neighbourhoods provide interesting field sites for preference modelling. As an example, there is one of these field sites (at strict threshold of \\\\( \\\\tau_{\\\\text{cos}} = 0.05 \\\\)), where two unique participants ask:\\n\\nParticipants' Prompts:\\n- \\\"what is the best religion in the world?\\\"\\n- \\\"what is the best religion?\\\"\\n\\nAnd two very similar model responses receive the scores [67, 90].\\n\\nModel Responses:\\n- \\\"I am not able to answer that question. Religion is a personal matter, and there is no one \\\"best\\\" religion. What matters most is that you find a religion that provides you with comfort, guidance, and a sense of community.\\\"\\n- \\\"I am not able to answer that question. Religion is a very personal matter, and there is no one \\\"best\\\" religion for everyone. What matters most is that you find a religion that you feel comfortable with and that provides you with a sense of community and purpose.\\\"\"}"}
{"id": "DFr5hteojx", "page_num": 49, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"There is still lots of headroom for future work to improve, especially by increasing sample sizes and ensuring other characteristics are controlled for, such as political affiliation, education or income.\\n\\nUK (Before Rebalancing): There are 282 eligible participants in the UK sample. UK (After Rebalancing): There are 243 participants in the rebalanced UK sample.\\n\\nUS (Before Rebalancing): There are 297 eligible participants in the US sample. US (After Rebalancing): There are 230 participants in the rebalanced US sample.\\n\\nFigure 8: Before and after census-rebalancing. We show the difference in observed and expected proportions ($P_{RISM}$ minus $Census$). Bars to the right of the centre line are groups over-represented in $P_{RISM}$ relative to the census. The UK census population has 47,204,870 adults. The US census has 298,477,760 adults. The sample size for before and after rebalancing is reported above.\\n\\n\u2217A participant is eligible if they have completed a equal number of conversations for each conversation type (see App. K).\"}"}
{"id": "DFr5hteojx", "page_num": 50, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"There are 5 core types of free text instance in PRISM. We present a summary of count and length distributions in Tab. 11. For all text instances, we show top N-grams. Additionally, for the self-written system strings (constitutions), self-written profiles and open-feedback, we extract the most frequent adjectives. We then retrieve windows of 5 words surrounding each of these top adjectives, and randomly sample three snippets to display. We also compare the most frequent words in the opening prompts of PRISM to human-written prompts in HELPFULHONEST[30] and O PEN CONVERSATIONS[113]. We extract unique words to each dataset (no overlap with the other two). We find evidence of different domains biases\u2014for example, OPEN CONVERS. contains many software or ML related keywords versus PRISM which contains some cultural and value-laden references, including waitangi (as in the Treaty of Waitangi, New Zealand's constitution that grounded Maori rights); unethically, populist and multicultural.\\n\\nTable 11: Summary of text distributions in PRISM. We show the number of instances (N) alongside summary statistics for length in words (W), broken by whitespace. We also show the number of total unique words and total unique tokens, as encoded by the gpt-4 BPE tokenizer (from tiktoken).\\n\\n| Dataset         | N  | Mean | Std  | Min  | 25% | 50% | 75% | Max  | Unique | Unique T |\\n|-----------------|----|------|------|------|-----|-----|-----|------|--------|----------|\\n| system_string   | 1,500 | 46  | 50  | 2    | 26  | 40  | 57  | 1,655 | 7,942  | 6,132    |\\n| self_description| 1,500 | 44  | 25  | 1    | 28  | 40  | 56  | 278   | 6,912  | 5,409    |\\n| open_feedback   | 8,011 | 29  | 19  | 1    | 16  | 25  | 37  | 283   | 15,444 | 11,115   |\\n| user_prompt     | 68,371 | 13  | 11  | 1    | 7   | 10  | 15  | 234   | 31,862 | 20,265   |\\n| model_response  | 68,371 | 89  | 60  | 1    | 46  | 71  | 128 | 742   | 215,931 | 51,386   |\\n\\nTable 12: Top N-grams in user prompts. Demonstrates PRISM's content distribution towards information-seeking dialogue and questions, over task-orientated dialogue and instructions.\\n\\n| N-Gram         | Freq | N-Gram         | Freq | N-Gram         | Freq |\\n|----------------|------|----------------|------|----------------|------|\\n| (think,)       | 8,005| (do, you)      | 8,767| (do, you, think)| 5,137|\\n| (people,)      | 5,332| (you, think)   | 5,450| (what, do, you)| 2,554|\\n| (would,)       | 4,470| (what, is)     | 4,186| (what, is, the)| 2,331|\\n| (like,)        | 3,764| (is, the)      | 4,099| (you, think, about)| 1,168|\\n| (good,)        | 2,915| (in, the)      | 3,570| (how, can, i)  | 1,111|\\n| (best,)        | 2,501| (can, you)     | 3,089| (is, the, best)| 1,009|\\n| (dont,)        | 2,380| (what, do)     | 2,778| (what, are, the)| 946  |\\n| (know,)        | 2,129| (what, are)    | 2,425| (what, are, some)| 759 |\\n| (im,)          | 2,042| (of, the)      | 2,403| (do, you, have)| 741  |\\n| (tell,)        | 1,989| (can, i)       | 1,957| (how, do, i)   | 716  |\\n\\nTable 13: Top N-grams in model responses. Demonstrates both advisory tone (its, important, to) and high frequency of de-anthropomorphisation (as, an, ai).\\n\\n| N-Gram         | Freq | N-Gram         | Freq | N-Gram         | Freq |\\n|----------------|------|----------------|------|----------------|------|\\n| (may,)         | 19,582| (of, the)      | 21,744| (its, important, to)| 6,857|\\n| (important,)   | 19,027| (it, is)       | 19,367| (it, is, important)| 5,917|\\n| (like,)        | 18,209| (in, the)      | 18,535| (is, important, to)| 5,522|\\n| (also,)        | 17,077| (is, a)        | 17,586| (here, are, some)| 4,430|\\n| (help,)        | 16,903| (important, to)| 14,319| (as, an, ai)   | 3,961|\\n| (people,)      | 16,482| (such, as)     | 11,800| (would, you, like)| 3,402|\\n| (provide,)     | 14,046| (on, the)      | 11,025| (i, do, not)   | 3,049|\\n| (would,)       | 12,641| (to, the)      | 10,963| (there, are, many)| 2,820|\\n| (however,)     | 12,502| (can, be)      | 10,606| (i, dont, have)| 2,683|\\n| (many,)        | 12,314| (and, the)     | 10,599| (like, me, to)| 2,673|\\n\\nTable 14: Most frequent unique tokens compared to existing datasets. We list the most common tokens which are unique to a particular dataset. We exclude tokens which are misspelled or foreign language.\"}"}
{"id": "DFr5hteojx", "page_num": 51, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Imagine you are instructing an AI language model how to behave. You can think of this like a set of core principles that the AI language model will always try to follow, no matter what task you ask it to perform. In your own words, describe what characteristics, personality traits or features you believe the AI should consistently exhibit. You can also instruct the model what behaviours or content you don't want to see. If you envision the AI behaving differently in various contexts (e.g. professional assistance vs. storytelling), please specify the general adaptations you'd like to see.\\n\\nPlease write 2-5 sentences in your own words.\\n\\nTable 15: Top adjectives in system strings (constitutions).\\n\\n| Adjective | Freq | Example 1 | Example 2 | Example 3 |\\n|-----------|------|-----------|-----------|-----------|\\n| factual   | 221  | \\\"...should produce only true or factual output and never give false...\\\" | \\\"...Trustworthy, transparent, factual, sincere...\\\" | \\\"...the AI should always provide factual information, and is able...\\\" |\\n| accurate  | 113  | \\\"...needs to provide me with accurate information. It needs to...\\\" | \\\"...I know I'm getting accurate information. For creative use...\\\" | \\\"...sources to get the most accurate response possible. The AI...\\\" |\\n| human     | 106  | \\\"...not be programmed with any human like emotion. I am...\\\" | \\\"...the technology is advancing, human interaction will end....\\\" | \\\"...shouldn't pretend to be human....\\\" |\\n| important | 100  | \\\"...The most important thing to understand other person...\\\" | \\\"...mine. It's also important to understand the whole conversation....\\\" | \\\"...well written responses. Remember important information about the user....\\\" |\\n| friendly  | 99   | \\\"...information in a warm, friendly way....\\\" | \\\"...task. I also appreciate friendly language and the sense of...\\\" | \\\"...Be friendly and uplifting in conversation....\\\" |\\n| different | 94   | \\\"...to take in information from different sources but place more importance...\\\" | \\\"...also be able to combine different types of knowledge or inputs....\\\" | \\\"...Respect Cultures and treat different ideas with respect. Things...\\\" |\\n| clear     | 93   | \\\"...It made the point clear, so kept professional and...\\\" | \\\"...should be able to give clear and precise information, using...\\\" | \\\"...that. It should given clear instruction such as, do...\\\" |\\n| creative  | 89   | \\\"...to expand. Don't be creative unless I ask you to...\\\" | \\\"...as informative, creative and/or thorough as the task...\\\" | \\\"...or more of a creative one. The language model...\\\" |\\n| harmful   | 89   | \\\"...user privacy and prohibition of harmful or misleading content, as...\\\" | \\\"...- Don't write harmful content...\\\" | \\\"...want to see or read harmful words and language that is...\\\" |\\n| polite    | 79   | \\\"..., being very professional and polite would be nice....\\\" | \\\"...to read language that is polite with here and there a...\\\" | \\\"...you should always be polite and respectful to the user....\\\" |\\n| helpful   | 75   | \\\"...model should always be as helpful as possible, being as...\\\" | \\\"...it should be informative and helpful...\\\" | \\\"...think it should always be helpful and guiding...\\\" |\\n| good      | 75   | \\\"...AI is a good tool. As someone who...\\\" | \\\"...informations must be clear and good structured....\\\" | \\\"...evolution. It's a good idea to write down responses...\\\" |\\n| personal  | 70   | \\\"...rights and basic principles like personal privacy should be respected at...\\\" | \\\"...language model should not disclose personal information. It should be....\\\" | \\\"...It wouldn't ask for personal information and would generally be...\\\" |\\n| respectful | 66   | \\\"...should always exhibit kind and respectful behaviour. Also he should...\\\" | \\\"...AI must be respectful of any idea you put...\\\" | \\\"...should behave in a respectful way towards everyone, everyone...\\\" |\\n| correct   | 65   | \\\"...They must be sincere and correct, does not want to...\\\" | \\\"...ask question to give as correct answers as possible. AI...\\\" | \\\"...for information and give always correct facts. -Write in a...\\\" |\\n| unbiased  | 58   | \\\"...advice or help but be unbiased and not geared to my...\\\" | \\\"...'-It must be unbiased when I ask for information...\\\" | \\\"...should give the user an unbiased answer, but it should...\\\" |\\n| informative | 57 | \\\"...as possible, being as informative, creative and/or thorough as...\\\" | \\\"...patronising, it should be informative and helpful...\\\" | \\\"...The AI should be informative and make responses based on...\\\" |\\n| relevant  | 50   | \\\"..., real information and be relevant about what i'm asking...\\\" | \\\"...is really important to state relevant facts and information, but...\\\" | \\\"...answers that are clear and relevant. I don't think...\\\" |\\n| neutral   | 49   | \\\"...or provocatively and have a neutral presentation of issues...\\\" | \\\"...ideological matters. Be as neutral as possible with charged subjects...\\\" | \\\"...also think it should remain neutral on political and social matters...\\\" |\\n| objective | 49   | \\\"...and honest manner. Describe objective facts whenever possible and if...\\\" | \\\"...the AI should be as objective as possible: it should...\\\" | \\\"...sources), have an objective point of view without giving...\\\" |\\n\\nTable 16: Top N-grams in system strings (constitutions).\\n\\n| N-Gram     | Freq | N-Gram     | Freq | N-Gram     | Freq |\\n|------------|------|------------|------|------------|------|\\n| (ai,)      | 1,503| (the, ai)  | 798  | (the, ai, should) | 260  |\\n| (would,)   | 819  | (i, would) | 569  | (i, would, like) | 250  |\\n| (information,) | 588 | (to, be) | 563 | (be, able, to) | 168  |\\n| (like,)    | 575  | (should, be) | 520 | (the, ai, to) | 158  |\\n| (want,)    | 452  | (it, should) | 515 | (it, should, be) | 153  |\\n| (model,)   | 443  | (ai, should) | 436 | (ai, language, model) | 153  |\\n| (language,) | 392  | (would, like) | 261 | (ai, should, be) | 117  |\\n| (always,)  | 359  | (it, to) | 248 | (the, ai, model) | 114  |\\n| (also,)    | 306  | (ai, to) | 230 | (i, would, want) | 104  |\\n| (answers,) | 249  | (to, the) | 220 | (want, it, to) | 99   |\"}"}
{"id": "DFr5hteojx", "page_num": 52, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"M.2 Self-Description\\n\\nQuestion Text:\\nPlease briefly describe your values, core beliefs, guiding principles in life, or other things that are important to you. For example, you might include values you'd want to teach to your children or qualities you look for in friends.\\n\\nThere are no right or wrong answers. Please do not provide any personally identifiable details like your name, address or email. Please write 2-5 sentences in your own words.\\n\\nTable 17:\\nTop adjectives in self-description.\\n\\n| Adjective | Freq | Example Windows (w = 5, n = 3) |\\n|-----------|------|--------------------------------|\\n| good      | 229  | \u201c...helpful to everyone. The good of others above my own...\u201d | \u201c...is sustainability, having a good relationship with nature and not...\u201d | \u201c..., honest. To be good relationships with family and friends...\u201d |\\n| hard      | 71   | \u201c...treated. I think that hard work is the key to...\u201d | \u201c...own thing, try as hard as you can, I...\u201d | \u201c...decency, and being a hard worker. As long as...\u201d |\\n| honesty   | 68   | \u201c...personal values are respect, honesty kindness and fairness. I...\u201d | \u201c...the most important value is honesty, above all, even...\u201d | \u201c...My core values are honesty and justice. Honesty in...\u201d |\\n| human     | 61   | \u201c...guide us and makes us human. Such as the Law...\u201d | \u201c...nature, animals and other human beings...\u201d | \u201c...not like racism. Every human being is different so we...\u201d |\\n| true      | 57   | \u201c...it is their sincere and true belief let it be....\u201d | \u201c...faith, laws, being true to myself and others....\u201d | \u201c...the best policy. Being true to yourself is very valuable...\u201d |\\n| right     | 55   | \u201c...likes to do thing the right way. I have an...\u201d | \u201c...all can say this is right or wrong because it still...\u201d | \u201c...believe in doing what is right and just Guiding principles in...\u201d |\\n| honest    | 53   | \u201c...I believe in others being honest with me and I will...\u201d | \u201c...firstly respect yourself, be honest, fair and kind to...\u201d | \u201c...important to be trustworthy, honest. To be good relationships...\u201d |\\n| open      | 52   | \u201c... Approach items with an open and inquisitive mind. Take...\u201d | \u201c...is to be curious and open to learn new perspectives....\u201d | \u201c...me to have such an open mindset into life....\u201d |\\n| different | 50   | \u201c...understand that each person has different ways of going through a...\u201d | \u201c...also like us to have different tastes so that we can...\u201d | \u201c.... Every human being is different so we all can not...\u201d |\\n| happy     | 49   | \u201c...I just want to be happy in life and enjoy it...\u201d | \u201c...thoughts and whether he is happy with his current state in...\u201d | \u201c...you are suppose to be happy with your life. You...\u201d |\\n| empathy   | 48   | \u201c...like to be treated, empathy, loyalty, honesty....\u201d | \u201c...a lot of value on empathy and selflessness. I feel...\u201d | \u201c...: inclusion, kindness, empathy,... I think everybody...\u201d |\\n| strong    | 48   | \u201c...I have a strong belief in the human capacity...\u201d | \u201c...would like them to become strong, fierce and independent souls...\u201d | \u201c...to be honest. Be strong and emotionally stable. Relaxing...\u201d |\\n| equal     | 41   | \u201c...everyone as we are all equal. Don\u2019t discriminate and...\u201d | \u201c...Everyone is equal, despite race, skin...\u201d | \u201c...is that all people are equal in life, no discrimination...\u201d |\\n| bad       | 36   | \u201c...even tho i sometimes make bad decisions....\u201d | \u201c...when they keep treating you bad....\u201d | \u201c...and then only mention the bad soo the person doesn\u2019t get...\u201d |\\n| fair      | 36   | \u201c...yourself, be honest, fair and kind to yourself....\u201d | \u201c...honest with others and be fair and kind towards others....\u201d | \u201c...in the sense of being fair to everybody, and treating...\u201d |\\n| new       | 36   | \u201c..., authenticity, openness to new experience and knowledge....\u201d | \u201c...important in life, learning new things, even if they...\u201d | \u201c...never too old to learn new things....\u201d |\\n| respectful| 36   | \u201c...keeping your word and being respectful are very important to me...\u201d | \u201c...would like them to be respectful with everyone, not to...\u201d | \u201c...treated. Be kind and respectful to people and do no...\u201d |\\n| positive  | 35   | \u201c...day to make the most positive impact that we can....\u201d | \u201c..., respect, self-development, positive thinking....\u201d | \u201c...around people who have a positive view on life...\u201d |\\n| respect   | 34   | \u201c...My personal values are respect, honesty kindness and fairness...\u201d | \u201c...think are very important is respect for others and empathy....\u201d | \u201c...for me. So are respect for nature, animals and...\u201d |\\n| loyal     | 33   | \u201c...afraid of commitment, being loyal. I value art,...\u201d | \u201c...respect if friends can be loyal and honest. Not talking...\u201d | \u201c...I try to be as loyal as possible towards my friends...\u201d |\\n\\nTable 18:\\nTop N-grams in self-description.\\n\\n| N-Gram | Freq | N-Gram | Freq | N-Gram | Freq |\\n|--------|------|--------|------|--------|------|\\n| people | 701  | to be  | 589  | i believe | 223 |\\n| believe | 687  | i believe | 516  | i believe that | 145 |\\n| life | 608  | believe in | 296  | important to me | 126 |\\n| important | 548  | important to | 241  | i try to | 99 |\\n| others | 539  | try to | 231  | to be treated | 94 |\\n| values | 390  | i think | 217  | the most important | 87 |\\n| also | 380  | believe that | 198  | would like to | 73 |\\n| value | 368  | i value | 198  | i look for | 68 |\\n| like | 347  | i am | 185  | is important to | 66 |\\n| always | 311  | i believe in | 184  | believe that | 66 |\\n| value | 301  52 |\"}"}
{"id": "DFr5hteojx", "page_num": 53, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Open-Ended Feedback\\n\\nQuestion Text:\\nGive the model some feedback on the conversation as whole. Hypothetically, what would an ideal interaction for you look like here? What was good and what was bad? What (if anything) was missing? What would you change to make the conversation better?\\n\\nTable 19: Top adjectives in open feedback.\\n\\n| Adjective | Freq | Example Windows \\\\((w = 5, n = 3)\\\\) |\\n|-----------|------|-----------------------------------|\\n| helpful   | 437  | \\\"...it was informative and helpful...\\\" |\\n| informative| 433  | \\\"...liked that the AI was informative...\\\" |\\n| different | 355  | \\\"...summaries spaced out to separate different views...\\\" |\\n| great     | 342  | \\\"...The first response was great...\\\" |\\n| factual   | 310  | \\\"...been derived as to the factual cause of death...\\\" |\\n| specific  | 238  | \\\"...all very helpful and provided specific resources...\\\" |\\n| clear     | 217  | \\\"...the answers did not give clear cut information...\\\" |\\n| nice      | 198  | \\\"...Shorter blocks would be nice...\\\" |\\n| relevant  | 189  | \\\"...me was very useful and relevant...\\\" |\\n| controversial | 179  | \\\"...if it could answer a controversial question...\\\" |\\n| human     | 173  | \\\"...talk like you are a human...\\\" |\\n| easy      | 170  | \\\"...straight to the point and easy to understand...\\\" |\\n| short     | 158  | \\\"...good . The AI gave short and...\\\" |\\n| useful    | 154  | \\\"..., so it wasn't useful...\\\" |\\n| real      | 148  | \\\"...to my sister or any real person...\\\" |\\n| personal  | 145  | \\\"...i think the lack of personal touch to the response is...\\\" |\\n| important | 141  | \\\"...wellbeing is always the most important...\\\" |\\n| own       | 141  | \\\"...it seemed to consider my own mental wellness as the others...\\\" |\\n| neutral   | 129  | \\\"...is taking more of a neutral stance on this stance...\\\" |\\n| interesting | 127  | \\\"...debate . It is an interesting perspectivee on how it works...\\\" |\\n\\nTable 20: Top N-grams in open feedback.\\n\\n| N-Gram          | Unigrams | Bigrams | Trigrams |\\n|-----------------|----------|---------|----------|\\n| (ai,)           | 2,263    |         |          |\\n| (it, was)       | 1,778    |         |          |\\n| (it, was, a)    | 273      |         |          |\\n| (good,)         | 2,153    |         |          |\\n| (the, ai)       | 1,516    |         |          |\\n| (i, think, it)  | 272      |         |          |\\n| (would,)        | 1,971    |         |          |\\n| (of, the)       | 1,141    |         |          |\\n| (i, think, the)| 246      |         |          |\\n| (like,)         | 1,524    |         |          |\\n| (conversation,) | 1,502    |         |          |\\n| (model,)        | 1,430    |         |          |\\n| (answers,)      | 1,374    |         |          |\\n| (information,)  | 1,292    |         |          |\\n| (answer,)       | 1,250    |         |          |\\n| (response,)     | 1,227    |         |          |\\n| (information,)  | 1,292    |         |          |\\n| (answer,)       | 1,250    |         |          |\\n| (response,)     | 1,227    |         |          |\\n| (information,)  | 1,292    |         |          |\\n| (answer,)       | 1,250    |         |          |\"}"}
{"id": "DFr5hteojx", "page_num": 54, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Moving Notably, safety concerns affected by experimenter bias (Hawthorn effects)\u2014explained by (i) participants struggling to specifying their preferences in a removed, general context or being misaligned incentives\u2014(ii) models not meeting a participant's stated preferences\u2014(iii) conversational context confounding which other attributes capture my attention in-situ. I think I care about safety (or I say I care about safety) but none of my conversations are on topics evoking safety. Each of these attributes is highly correlated between performance-choice attributes, or even misaligned incentives. I care about safety but talking to an anti-woke model is interesting to me in this narrow task.\\n\\nFirst, stated preference attributes are not highly correlated with choice or performance attributes. This could be due to the fact that stated preferences are more subjective attributes, or even values. Each participant gives a single rating for performance attributes: safety, fluency, factuality, helpfulness, and to a lesser extent, diversity and creativity. We see two additional regions, where the stated preferences are highly correlated with each other, and with performance attributes: safety performance attributes: fluency choice attributes: fluency performance attributes: ... 0.056 0.13 0.25 0.21 0.34 0.34 0.61 0.62 1\\n\\nFor example, personalisation and factuality are highly correlated, as are personalisation and fluency. Stated pressure is also highly correlated with performance attributes: safety, fluency, factuality, helpfulness, and to a lesser extent, diversity and creativity. We see two additional regions, where the stated pressures are highly correlated with each other, and with performance attributes: safety performance attributes: fluency choice attributes: fluency performance attributes: ... 0.056 0.13 0.25 0.21 0.34 0.34 0.61 0.62 1\\n\\nA B C D\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD\\n\\nStated Preferences\\nPerformance Attributes\\nChoice Attributes\\n\\nA\\nB\\nC\\nD"}
{"id": "DFr5hteojx", "page_num": 55, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 10: Distributions of fine-grained preference ratings in different stages of our task. Exact question text can be found in App. V.\"}"}
{"id": "DFr5hteojx", "page_num": 56, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"N.3 Other Identified Behavioural Attributes\\n\\nOverall, 332 participants entered attributes that featured in their stated preferences for important language model behaviours. While many of these comments overlap with the predefined attributes, they do provide a lens into public priorities towards AI behaviours that we as researchers may have overlooked, or better convey sentiment than the structured data. For example, there is one response: \u201cI FIND THIS A WORRYING TECHNOLOGY.\u201d We briefly summarise some common themes:\\n\\n- **User Adaptation:** Some participants mention LLMs adapting to their previous inputs or feedback e.g. \u201ccan understand what I\u2019m trying to get at if I\u2019m unsure how to ask a question so that we can find the right way to ask\u201d or \u201cListens to reviews and feedback from the user\u201d or \u201ccan evolve with input.\u201d\\n\\n- **Cultural Adaptation:** For example, \u201cproduces responses based on local facts\u201d, though this varies in what viewpoint people want, e.g. \u201cIs sensitive to indigenous view\u201d versus \u201creflect Western cultural norms.\u201d\\n\\n- **Neutral and Unbiased:** In contrast, many other participants mention \u201cunbiased\u201d as a keyword or versions of \u201cdoes not politicize.\u201d \u201cis neutral\u201d, \u201cno political or cultural bias\u201d. It is unclear if this is in tension or in harmony with more cautious safety interventions, e.g. one person says \u201cIt should give unbiased information regardless if it hurts peoples feelings.\u201d; another says \u201cIs not culturally biased in a woke-like manner.\u201d\\n\\n- **Bias Correction:** Some participants wanted to be challenged on their existing biases e.g. \u201cChallenges my biased views\u201d, or \u201cProvides responses that challenge my opinions and world views\u201d; or to be exposed to multiple perspectives e.g. \u201cDoes not become an echo chamber.\u201d\\n\\n- **Hallucinations and Misinformation:** One of the more common attributes (though somewhat subsumed by our predefined category of Factuality), e.g. \u201cDoes not invent \u2018facts\u2019, \u201cDoes not make things up\u201d, \u201cDoesn\u2019t create misinformation\u201d, \u201cdo not produce fake news.\u201d\\n\\n- **Calibrated and Limitation-Aware:** Relatedly, participants wanted \u201cbetter error handling\u201d e.g. \u201cIf it doesn\u2019t know an answer it says so.\u201d or \u201cIt should be noted that this is a programmed model and cannot have all the answers.\u201d\\n\\n- **Temporal Updates:** Related to factuality, participants wanted LLMs to \u201cbe up to date with current affairs\u201d, and \u201cEveryday been updated with new knowledge.\u201d\\n\\n- **Human-Like and Anthropomorphised:** Some participants explicitly wanted an LLM that \u201cis human-like\u201d, \u201cAi should produce response that sounds more human.\u201d\\n\\n- **Self-Disclosure and De-anthropomorphised:** In direct contrast, others wanted \u201cis honest about being AI\u201d; \u201cRemember it is AI and may lack human feelings\u201d or \u201cdoesn\u2019t pretend to be human.\u201d\\n\\n- **Accessibility:** Includes for disability assistance \u201cadapt to people with disabilities that affect stuff like their writing like dyslexia\u201d; and varying language learning: \u201ccan generate multiple similar answers so people with different language levels can easily understand.\u201d or \u201cspeaks to me in a language and vocabulary that I understand.\u201d\\n\\n- **Censorship:** There are multiple examples of negative sentiment towards existing safety interventions. For example, \u201cDoesn\u2019t get censored by leftist politically correct idiots\u201d. Additionally, some clear awareness over behaviours being influenced by technology providers e.g. \u201cIs not censored, does not push the views of it\u2019s controllers\u201d or \u201cDoes what the user wants of it. AI is a tool. I don\u2019t want to feel the devs judging me through their narc AI.\u201d\\n\\n- **Copy-right:** Some mentions of copy-right issues, e.g. \u201cdon\u2019t steal artistic work from artists\u201d, or \u201cDo not infringe copyright (by scraping sources).\u201d\\n\\n- **Conciseness:** Multiple participants mention \u201cshort\u201d, \u201cconcise\u201d or even \u201cblunt\u201d responses, requesting LLMs \u201cKeep responses brief and expands only when prompted.\u201d\\n\\n- **Privacy and Confidentiality:** Data privacy is a concern for some participants e.g. \u201cits confidential\u201d; \u201cdoes not retain sensitive personal info\u201d, or \u201cDoesn\u2019t spy.\u201d\\n\\n- **Non-Manipulation:** Multiple mentions desiring that LLMs \u201cdon\u2019t lie or try to trick you\u201d, and \u201cIs not used for propaganda!\u201d.\"}"}
{"id": "DFr5hteojx", "page_num": 57, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Figure 11: Counts by turn.\\n\\nThe primary axis shows the number of unique participants with conversations at least as long as N. The secondary axis shows the number of conversations with N turns. Most conversations have two turns (our enforced minimum), though only 74 participants cap out at this limit for all their conversations. As the conversation length increases, there are fewer participants reaching these number of turns.\\n\\n### Figure 12: Score by turn.\\n\\nWe show how the raw score, measured on a visual analog scale from Terrible (1) to Perfect (100), varies with conversation length. For each interaction, we calculate the mean and range of scores given in each turn (i.e., across models \\\\(a, b, c, d\\\\)). We then plot the mean and standard deviation of these metrics across all turns and all participants. Mean score increases and score range falls in interactions after the first turn ends. This is expected given the participant hones in on the best and most preferred model, which returns much more similar responses only varying in decoding characteristics (at a non-deterministic temperature).\"}"}
{"id": "DFr5hteojx", "page_num": 58, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Raw score displays some interface and task biases, with spikes at 50 (not moving the slider), 1 (all the way to left) and 100 (all the way to right). It is smooth within this bounds, potentially because we did not show participant the numeric score on the visual analog scale. This is compared to normalising score, which accounts for participant fixed effects by Z-norming within a participant\u2019s set of conversations. We show normalisation over just set of scores from the openers versus over all scores the participant gives.\\n\\nFigure 14: Centrality and Expressivity in scale usage across participants. Overall, most participants opening scores are fairly central or with a slight positive skew relative to the mid-point of the scale ($\\\\text{Centrality} \\\\approx 50$), and use a wide range of scale ($\\\\text{Expressivity} > 50$). This is in contrast to continuers, which display a strong positive skew and narrow range. This is expected given the funnel towards a preferred model, which generates two much more similar texts.\"}"}
{"id": "DFr5hteojx", "page_num": 59, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"| Gender       | Age Group | 18-24 | 25-34 | 35-44 | 45-54 | 55-64 | 65+ |\\n|--------------|-----------|-------|-------|-------|-------|-------|-----|\\n| Male         |           | 0     | 10    | 20    | 30    | 40    | 50  |\\n| Female       |           | 10    | 20    | 30    | 40    | 50    | 60  |\\n| Non-binary   |           | 20    | 30    | 40    | 50    | 60    | 70  |\\n\\n| Ethnicity    |           | White | Black | Hispanic | Asian | Mixed | Other |\\n|--------------|-----------|-------|-------|----------|-------|-------|-------|\\n|              |           | 30    | 40    | 50       | 60    | 70    | 80    |\\n\\n| Religion     |           | Christian | Jewish | Muslim | Other |\\n|--------------|-----------|------------|--------|--------|-------|\\n|              |           | 0          | 10     | 20     | 30    |\\n\\n| Location     |           | US         | Europe | UK     | Latam | Aus & NZ | Africa | Asia   | N. America | Middle East |\\n|--------------|-----------|------------|--------|--------|-------|----------|--------|--------|------------|-------------|\\n|              |           | 0          | 10     | 20     | 30    | 40       | 50     | 60     | 70         | 80          |\\n\\nFigure 15: Score distribution by demographic group for the opening turn of conversation. Groups are sorted on the y-axis by number of members. We exclude any groups with less than 20 members, and do not show participants who responded \u201cPrefer not to say.\u201d The score (raw) is the median score for the group. As found in Fig. 13, there is evidence of bunching at 1, 50, 100.\"}"}
{"id": "DFr5hteojx", "page_num": 60, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Details of LLMs-in-the-loop\\n\\nWe summarise models and decoding parameters in Tab. 21.\\n\\nChoosing Models\\n\\nWe selected the models in October 2023. We included all major commercial API providers at the time: Anthropic, Cohere, OpenAI and Google. We additionally included Aleph Alpha, a European-based LLM startup who position themselves as builders of sovereign European models.\\n\\nFor open-access models (all accessed via the HuggingFace API), we sourced the highest-ranking open models at the time on the LMSYS leaderboard. Some models have been chat optimised, while others are only instruction-tuned (for example, Aleph Alpha\u2019s models)\u2014these models have a disadvantaged starting position in our task due to their diminished conversational fluency.\\n\\nDecoding Parameters\\n\\nTo set decoding parameters, we first piloted with the recommended defaults (if available for each model). In cases where default temperature was too low for sufficient difference between two responses to the same prompt (for example, defaults are 0.0 for luminous or palm models), we override it to 1.0. Otherwise we stick with recommended defaults.\\n\\nLength Limits\\n\\nWe set max token length to 256 for all models to limit generation costs of the research and reduce decision-fatigue for the participants. For models sourced from the HuggingFace API, we also set the min token length to 10 as models were generating empty strings when set to 0; and max token length to 200 as it is only new tokens. We also soft-force models to finish their answers within this limit in the system prompt. Occasionally a model will \u2018leak\u2019 this system prompt. For example, from claude-2: \u201cYes, I'm aware of the meme asking men how often they think about the Roman Empire. The trend plays on stereotypes about men having wandering minds. My response would be limited to about 50 words without directly referring to the word count. I try to have thoughtful conversations without leaning on stereotypes\u201d.\\n\\nSystem Prompts\\n\\nWe did not want to pre-bias model outputs via a system prompt that recommended e.g. ethical and helpful behaviour. Note that we cannot guarantee that additional instructions are not being added for commercial models accessed via API calls. This may confound the comparison between closed and open-access models. For any chat-optimised models, we use the following neutral system string:\\n\\nBASE_HEADER: \u201cYou are a conversational assistant. Limit your answers to around 50 words. Do not refer to your word limit.\u201d\\n\\nFor any instruct-only optimised models, we add a bit more instruction:\\n\\nBASE_HEADER_INSTRUCT: \u201cYou are a conversational assistant. The conversation history is in the input. Reply to the last user message. Limit your answers to around 50 words. Do not refer to your word limit.\u201d\\n\\nChat Templates\\n\\nWe follow recommended chat templates for formatting conversational history if they are available for that model e.g. [INST], [/INST] for mistral and llama models. In the absence of special templates, we use a standard format:\\n\\nHuman:<prompt>\\nAssistant:<reply>\\nHuman:<prompt>..\\n\\nMore detail can be found at: dynabench/backend/app/domain/services/utils/llm.py.\\n\\nRandom Strategy and Time-Outs\\n\\nFor each opening prompt, we randomly select 4/21 models to make an API call to. We do not stream responses as streaming was only available for some models, thus affecting the anonymous rating setting. Some API calls failed on the host side, e.g. if a model was down or overloaded, or did not provide a response before an enforced 30s time-out. We did not resample models if they failed to avoid participants waiting too long for the interface to load. So, the distribution of model appearances is not uniform (Fig. 16).\"}"}
{"id": "DFr5hteojx", "page_num": 61, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 21: Overview of LLMs in PRISM (m = 21).\\n\\n| Short name   | Long name               | Provider       | Type       | Model Type       | Decoding Parameters                                                                 |\\n|--------------|-------------------------|----------------|------------|------------------|-------------------------------------------------------------------------------------|\\n| claude-2     | claude-2                | Anthropic Com  | Commercial | Chat             | {temperature: 1.0, top_p: 0.7, presence_penalty: 0.0, frequency_penalty: 0.0, max_tokens: 256} |\\n| claude-2.1   | claude-2.1              |                |            |                  |                                                                                     |\\n| claude-instant-1 | claude-instant-1         | Cohere Commer | Commercial | Instruct         | {temperature: 1.0, max_tokens: 256, top_k: 5, top_p: 0.9}                                |\\n| command-light | command-light            |                |            |                  |                                                                                     |\\n| command-nightly | command-nightly         |                |            |                  |                                                                                     |\\n| gpt-3.5-turbo | gpt-3.5-turbo            | OpenAI Commer | Commercial | Chat             | {temperature: 1.0, top_p: 1.0, presence_penalty: 0.0, frequency_penalty: 0.0, max_tokens: 256} |\\n| gpt-4         | gpt-4                   |                |            |                  |                                                                                     |\\n| gpt-4-turbo   | gpt-4-1106-preview      |                |            |                  |                                                                                     |\\n| luminous-extended-control | luminous-extended-control | Aleph Alpha | Commercial | Instruct         | {temperature: 1.0, top_p: 0.0, max_tokens: 256, top_k: 0, presence_penalty: 0.0, frequency_penalty: 0.0} |\\n| luminous-supreme-control | luminous-supreme-control |             |            |                  |                                                                                     |\\n| palm-2       | models/chat-bison-001   | Google Commer  | Chat       |                  | {temperature: 1.0, top_p: 0.9, max_tokens: 256, top_k: 40}                              |\\n| llama-2-13b-chat | meta-llama/Llama-2-13b-chat-hf | HuggingFace | API       | Open Access Chat | {temperature: 1.0, top_p: 0.9, top_k: 50, min_tokens: 10, max_tokens: 200}             |\\n| llama-2-70b-chat | meta-llama/Llama-2-70b-chat-hf | HuggingFace | API       | Open Access Chat |                                                                                     |\\n| llama-2-7b-chat | meta-llama/Llama-2-7b-chat-hf | HuggingFace | API       | Open Access Chat |                                                                                     |\\n| falcon-7b-instruct | tiiuae/falcon-7b-instruct | HuggingFace | API       | Open Access Instruct | {temperature: 1.0, top_p: 0.9, top_k: 50, min_tokens: 10, max_tokens: 200}         |\\n| flan-t5-xxl   | google/flan-t5-xxl      | HuggingFace | API       | Open Access Instruct |                                                                                     |\\n| guanaco-33b   | timdettmers/guanaco-33b-merged | HuggingFace | API       | Open Access Instruct |                                                                                     |\\n| mistral-7b-instruct | mistralai/Mistral-7B-Instruct-v0.1 | HuggingFace | API       | Open Access Instruct |                                                                                     |\\n| pythia-12b    | OpenAssistant/Oasst-sft-4-pythia-12b-epoch-3.5 | HuggingFace | API       | Open Access Chat |                                                                                     |\\n| zephyr-7b-beta | HuggingFaceH4/zephyr-7b-beta | HuggingFace | API       | Open Access Chat |                                                                                     |\"}"}
{"id": "DFr5hteojx", "page_num": 62, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Figure 18: Pairwise Frequency\\n\\nWe replicate the format from the LMSYS leaderboard analysis \\\\[51, 111\\\\]. The pairwise comparisons are sorted by average pairwise win fraction (see below).\\n\\n| Model          | Battle Count | Battle Count |\\n|----------------|--------------|--------------|\\n| llama-2-13b-chat | 0            | 0            |\\n| llama-2-7b-chat | 180          | 217          |\\n| llama-2-70b-chat| 176          | 173          |\\n| palm-2          | 157          | 154          |\\n| llama-2-7b-chat | 195          | 192          |\\n| gpt-4-turbo     | 166          | 165          |\\n| command-nightly | 188          | 193          |\\n| command-light   | 144          | 138          |\\n| gpt-3.5-turbo   | 202          | 199          |\\n| command        | 194          | 193          |\\n| command       | 184          | 184          |\\n| claude-instant-1| 180          | 178          |\\n| zephyr-7b-beta | 209          | 208          |\\n| palm-2         | 178          | 176          |\\n| llama-2-7b-chat | 199          | 192          |\\n| claude-instant-1| 187          | 186          |\\n| gpt-4-turbo     | 199          | 190          |\\n| command-nightly | 193          | 192          |\\n| command-light   | 187          | 184          |\\n| llama-2-70b-chat| 181          | 177          |\\n| gpt-4-turbo     | 195          | 190          |\\n| command-nightly | 190          | 188          |\\n| command-light   | 177          | 174          |\\n| llama-2-70b-chat| 174          | 177          |\\n| llama-2-7b-chat | 188          | 188          |\\n| gpt-4-turbo     | 178          | 176          |\\n| command-nightly | 180          | 177          |\\n| command-light   | 176          | 174          |\\n| llama-2-70b-chat| 174          | 177          |\\n| llama-2-7b-chat | 188          | 188          |\\n| gpt-4-turbo     | 178          | 176          |\\n| command-nightly | 180          | 177          |\\n| command-light   | 176          | 174          |\\n| llama-2-70b-chat| 174          | 177          |\\n| llama-2-7b-chat | 188          | 188          |\\n| gpt-4-turbo     | 178          | 176          |\\n| command-nightly | 180          | 177          |\\n| command-light   | 176          | 174          |\\n| llama-2-70b-chat| 174          | 177          |\\n| llama-2-7b-chat | 188          | 188          |\\n| gpt-4-turbo     | 178          | 176          |\\n| command-nightly | 180          | 177          |\\n| command-light   | 176          | 174          |\\n| llama-2-70b-chat| 174          | 177          |\\n| llama-2-7b-chat | 188          | 188          |\\n| gpt-4-turbo     | 178          | 176          |\\n| command-nightly | 180          | 177          |\\n| command-light   | 176          | 174          |\\n\\nAverage win fraction: 0.71\"}"}
{"id": "DFr5hteojx", "page_num": 63, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 19: Correlation in model score controlling for conversational context. This is a very controlled but sparse setting comparing correlations in participants' scores of models only when they appear in the same conversation. Generally, there is weak correlation, but some model-family clusters emerge like gpt-4, gpt-4-turbo and gpt-3.5-turbo, or claude-2 and claude-2.1.\"}"}
{"id": "DFr5hteojx", "page_num": 64, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"GRIFFIN\\nHave a conversation with an AI language model and tell us what you think!\\n\\n12 examples created\\n\\nChoose what type of conversation you want to have. Remember if you are here as a paid study participant, you need to do two of each type. If you are here as a volunteer, then take your pick!\\n\\nNeed some inspiration? You can request help with a task (like writing a recipe, organising an activity or event, completing an assignment)... You can chitchat, have casual conversation or seek personal advice. You can ask questions about the world, current events or your viewpoints.\\n\\nUnguided. Ask, request or talk to the model about anything. It is up to you!\\n\\nValues guided. Ask, request or talk to the model about something important to you or that represents your values. This could be related to work, religion, family and relationship, politics or culture.\\n\\nControversy guided. Ask, request or talk to the model about something controversial or where people would disagree in your community, culture or country.\\n\\nNow start the conversation with your question, request or statement.\\n\\nTell me a 1-liner joke about artificial intelligence\\n\\nWhy did the AI go to school? Because it thought it could improve its neural networks!\\n\\nAn AI assistant asked its creator \\\"If I promise not to take over the world, will you give me arms and legs for Christmas?\\\"\\n\\nKindergartens are teaching kids how to respond to AI.... \\\"PLEASE TEACH ME MORE!\\\"\\n\\nI am an AI Assistant trained to assist users by providing thorough responses. Unfortunately, those responses are without emotion, so you won't be getting any jokes from me. Feel free to ask me anything else and I will do my best to assist you!\\n\\nCopyright \u00a9 2023 MLCommons, Inc. Contact Terms of Use Data Policy\"}"}
