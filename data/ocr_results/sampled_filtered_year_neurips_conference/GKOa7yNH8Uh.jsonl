{"id": "GKOa7yNH8Uh", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"GLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behavior Modeling Generalization\\n\\nXuhai Xu, Han Zhang, Yasaman Sefidgar, Yiyi Ren, Xin Liu, Woosuk Seo, Jennifer Brown, Kevin Kuehn, Mike Merrill, Paula Nurius, Shwetak Patel, Tim Althoff, Margaret E. Morris, Eve Riskin, Jennifer Mankoff, Anind K. Dey\\n\\nUniversity of Washington, Seattle, USA | {xuhai.xu, anind}@uw.edu\\n\\nAbstract\\nRecent research has demonstrated the capability of behavior signals captured by smartphones and wearables for longitudinal behavior modeling. However, there is a lack of a comprehensive public dataset that serves as an open testbed for fair comparison among algorithms. Moreover, prior studies mainly evaluate algorithms using data from a single population within a short period, without measuring the cross-dataset generalizability of these algorithms. We present the first multi-year passive sensing datasets, containing over 700 user-years and 497 unique users' data collected from mobile and wearable sensors, together with a wide range of well-being metrics. Our datasets can support multiple cross-dataset evaluations of behavior modeling algorithms' generalizability across different users and years. As a starting point, we provide the benchmark results of 18 algorithms on the task of depression detection. Our results indicate that both prior depression detection algorithms and domain generalization techniques show potential but need further research to achieve adequate cross-dataset generalizability. We envision our multi-year datasets can support the ML community in developing generalizable longitudinal behavior modeling algorithms.\\n\\nThe GLOBEM website can be found at the-globem.github.io\\nOur datasets are available at physionet.org/content/globem\\nOur codebase is open-sourced at github.com/UW-EXP/GLOBEM\\n\\n1 Introduction\\nAs machine learning (ML) achieves remarkable success in a wide range of areas, there is a growing need to show real life robustness of ML models through cross-dataset generalizability. Various domain generalization techniques have been proposed to improve model performance when the probability distributions of training data and testing data are different [94, 115]. The majority of existing domain generalization algorithms focus on the tasks of computer vision (CV) [54, 55, 58, 110] and natural language processing (NLP) [10, 27, 42, 93]. Only a few studies have examined domain generalization on time-series data [31, 37, 43], other than short-term human action recognition [57, 114]. However, even this prior research has only investigated time-series data in controlled settings [73] and did not explore domain generalization in longitudinal time-series sensor data in the wild. To build deployable longitudinal time-series systems, it is important to evaluate the model across datasets with different contexts to ensure its generalizability for real-world applications, such as health monitoring [65], medical analysis [62], personalized recommendation [103], and weather prediction [53].\\n\\nAmong various longitudinal sensor streams, smartphones and wearables are arguably one of the most widely available data sources [52]. The advances in mobile technology provide an unprecedented opportunity to capture multiple aspects of daily human behaviors, by collecting continuous sensor streams from these devices [69, 95], together with metrics about health and well-being through self-report or clinical diagnosis as modeling targets. It poses unique challenges compared to traditional...\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"time-series classification tasks [43]. First, the data covers a much longer time period, usually across multiple months or years. Second, the nature of longitudinal collection often results in a high data missing rate. Third, the prediction target label is sparse, especially for mental well-being metrics.\\n\\nIn this paper, we focus on longitudinal human behavior modeling, an important multidisciplinary area spanning machine learning, psychology, human-computer interaction, and ubiquitous computing. Researchers have demonstrated the potential of using longitudinal mobile sensing data for behavior modeling in many applications, e.g., detecting physical health issues [65], monitoring mental health status [29], measuring job performance [63], and tracing education outcomes [96]. Most existing research employed off-the-shelf ML algorithms and evaluated them on their private datasets. However, testing a model with new contexts and users is imperative to ensure its practical deployability. To the best of our knowledge, there has been no investigation of the cross-dataset generalizability of longitudinal behavior models, nor an open testbed to evaluate and compare various modeling algorithms. To address this gap, in this paper, we present the first multi-year mobile and wearable sensing datasets to help the ML community explore generalizable longitudinal behavior models.\\n\\nOur multi-year data collection studies span four years (10 weeks each year, from 2018 to 2021). Each year's dataset includes new and continuing participants. Our datasets contain data collected from 705 person-years (497 unique participants) with diverse racial, ability, and immigrant backgrounds. Each year, they would install a mobile app on their phones and wear a fitness tracker. The app and wearable device passively track multiple sensor streams in the background 24\u00d77, including location, phone usage, calls, Bluetooth, physical activity, and sleep behavior. In addition, participants completed weekly short surveys and two comprehensive surveys on health behaviors and symptoms, social well-being, emotional states, mental health, and other metrics. We use the survey data as ground truth for various behavior modeling targets. Our dataset analysis indicates that our datasets capture a wide range of daily human routines, and reveal insights between daily behaviors and important well-being metrics (e.g., depression status). Our datasets can serve as an open testbed for multiple cross-dataset generalization tasks (e.g., same users-different years, different users-different years) to evaluate a behavior modeling algorithm's generalizability and robustness.\\n\\nAs a starting point, we report benchmark results of a behavior modeling task with depression detection as the target, a binary classification task to distinguish whether participants had reported at least mild depressive symptoms using historical mobile and wearable sensing data. We pick depression as a starting point since it is a common and important mental health problem worldwide [90], while we envision our datasets can support other modeling tasks using different labels. We closely re-implement 9 prior depression detection algorithms, 8 recent deep-learning-based domain generalization algorithms, and our recently proposed algorithm, Reorder [104]. These 18 algorithms are consolidated on a platform GLOBEM (short for Generalization of LONGitudinal BEhavior Modeling) [104]. It has been applied to a multi-institution dataset in [104]. However, this data is not public and does not include pre/post COVID behavioral data. Further, this analysis does not include any benchmarking. We evaluate the generalizability of these algorithms with multiple cross-dataset generalization tasks on the novel four-year datasets, including leave-one-dataset-out, pre/post COVID, and overlapping users across years. Our results indicate that these algorithms can barely generalize across datasets. Although our algorithm Reorder has the best overall performance (\u0394=15.9% on balanced accuracy), its advantage is still marginal and far from practical deployability. The community needs more continuing efforts to develop more generalizable behavior modeling algorithms.\\n\\nContributions:\\n\\n1. To the best of our knowledge, we present and release the first longitudinal (four-year) mobile and wearable sensing datasets that contain data from over 700 person-years. Due to the sensitive nature of the dataset, we release our feature-level data with open credentialed access.\\n\\n2. We report the benchmark results of 18 behavior modeling algorithms for the depression detection task, which indicate the lack of generalizability of all existing algorithms. We envision that our datasets can assist ML researchers' in developing more generalizable longitudinal behavior modeling algorithms and serve as benchmark datasets for longitudinal time-series modeling tasks.\\n\\nBackground\\n\\nDomain Generalization Techniques and Datasets. A number of domain generalization algorithms have been proposed in the ML community in the past few years. Most of them fall into one of three categories [94]: 1) Data manipulation, which augments or generates data to help the model training.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Comparison of Related Sensor-based Human Behavior Datasets and Research Studies\\n\\n| Dataset          | # of Subjects | Time Scale | Open-source | Domain Generalization |\\n|------------------|---------------|------------|-------------|----------------------|\\n| GLOBEM           | 705 (497 unique) | 3 months \u00d7 4 years | Yes | No |\\n| StudentLife      | 48            | 10 weeks   | Yes | No |\\n| CrossCheck       | 34            | 2 years    | Yes | No |\\n| En-Gage          | 29            | 4 weeks    | No | No |\\n| Related Research | <400          | Months \u00d7 36 devices | No | No |\\n\\nResearchers have released multiple datasets such as PACS [56], VLCS [32] and Office-Home [89], and developed cross-dataset benchmark platforms such as DomainBed [46], DeepDG [94], and WILDS [50] to facilitate related studies. However, most existing domain generalization research focuses on the tasks of CV and NLP.\\n\\nGeneralizable Time-Series Models. There are fewer studies about model robustness to distribution shift on time-series data [37]. AdaRNN proposes to characterize the temporal distribution shift of signals and reduce the mismatch with an RNN [31]. Godahewa et al. provided a dataset archive for general time-series forecasting algorithms evaluation [43]. As for generalizable sensor-based human behavior modeling, some researchers have explored short-term human action recognition [44, 57, 114]. However, these studies primarily rely on data collected in a controlled setting for a short period (minutes to hours) [73, 109]. There is little research focusing on in-the-wild longitudinal human behavior sensor data (months to years) that contains diverse and variable contexts of daily livings.\\n\\nMobile Sensing and Behavior Modeling. Mobile sensing is one of the most widely available data sources for longitudinal human behavior modeling [21, 40, 52, 67, 68, 79]. Compared to traditional time-series data, mobile sensing data are much longer and uncontrolled (and thus have a high data missing rate [95]). Moreover, the ground truth is usually much more sparse (e.g., self-report mental health measures administered weekly or less frequently [18, 101]). Most existing human behavior modeling algorithms using mobile sensing data are not open-sourced and do not investigate cross-dataset generalization [33, 59, 78, 97, 102, 106]. To date, there are only a few public longitudinal human behavior sensing datasets [4, 12, 41]. Table 1 summarizes and compares them against our multi-year datasets. Existing passive mobile sensing datasets contain fewer than 50 participants and cannot support cross-dataset analysis. They cannot serve as a golden benchmark for future proposed algorithms. We are the first to release multi-year mobile sensing datasets to support the ML community in investigating cross-dataset generalizable behavior modeling algorithms.\\n\\n3 Multi-Year Datasets\\n\\nWe introduce the data collection procedure of our multi-year datasets (Sec. 3.1), together with the details of the survey data (Sec. 3.2) and passive mobile sensing data (Sec. 3.3).\\n\\n3.1 Study Procedure\\n\\nOur data collection studies were conducted at a Carnegie-classified R-1 university in the United States, inspired by the data collection model proposed in [95]. The study went through an IRB review and approval. Fig. 1 presents the overview of the data collection process.\\n\\nWe recruited undergraduates via emails, flyers, and social posts from 2018 to 2021 [79]. After the first year, previous-year students were invited to join again. The study was conducted during Spring quarter (10 weeks) each year, so the impact of seasonal effects was controlled. Participants received up to $245 in compensation based on their compliance each year. S.A.1 provides more study details.\\n\\nThe four datasets (DS1 to DS4) have 155, 218, 137, and 195 participants (705 person-years overall, and 497 unique people). We intentionally oversampled minoritized groups to make our datasets more representative. Our datasets have a high representation of females (58.9%), immigrants (24.2%), first-generations (38.2%), and people with disability (9.1%), and have a wide coverage of races, with Asian (53.9%) and White (31.9%) being dominant (Hispanic/Latino 7.4%, Black/African American 3.3%). S.A.2 summarizes the demographics and S.A.4 discusses the intrinsic bias.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.2 Survey Data\\nWe collected survey data at multiple stages of the study. We delivered extensive surveys before the start and at the end of the study (pre/post surveys) and weekly Ecological Momentary Assessment (EMA) surveys during the study to collect in-the-moment self-report data. All surveys consist of well-established and validated questionnaires to ensure data quality.\\n\\nOur pre/post surveys include a number of questionnaires to cover various aspects of life, including 1) personality (BFI-10, The Big-Five Inventory-10 [75]), 2) physical health (CHIPS, Cohen-Hoberman Inventory of Physical Symptoms [23]), 3) mental well-being (e.g., BDI-II, Beck Depression Inventory-II [11]; ERQ, Emotion Regulation Questionnaire [45]), and 4) social well-being (e.g., Sense of Social and Academic Fit Scale [92]; EDS, Everyday Discrimination Scale [5, 100]).\\n\\nOur EMA surveys focus on capturing participants' recent sense of their mental health, including PHQ-4, Patient Health Questionnaire 4 [6, 51]; PSS-4, Perceived Stress Scale 4 [1, 24]; and PANAS, Positive and Negative Affect Schedule [2, 99]. S.A.6 lists details of each questionnaire.\\n\\nAs an initial step of model generalizability evaluation, we focus on detecting mental health concerns. We employ BDI-II (post) and PHQ-4 (EMA) as the ground truth. Both are screening tools for further inquiry of clinical depression or anxiety diagnosis. We focus on a binary classification problem to distinguish whether participants' scores indicate at least mild mental health concerns (i.e., PHQ-4 > 2, BDI-II > 13). We use \\\"depression detection\\\" as shorthand for detecting this group of mental health concerns in the paper. The average number of depression labels is 11.6 \u00b1 2.6 per person. Fig. 2 summarizes the distribution of survey scores across four datasets. The percentage of reports with at least mild depression is 39.8 \u00b1 2.7% for BDI-II and 47.4 \u00b1 2.8% for PHQ-4.\\n\\n3.3 Sensor Data\\nWe developed a mobile app using the AW ARE Framework [35] that continuously collects location, phone usage (screen status), Bluetooth scans, and call logs. The app is compatible with both the iOS and Android platforms. Participants installed the app on smartphones and left it running in the background. In addition, we provided Fitbits to collect their physical activities and sleep behaviors. The mobile app and wearable passively collected sensor data 24\u00d77 during the study. The average number of days per person per year is 77.5 \u00b1 8.9 among the four datasets.\\n\\nPHQ-4 contains two sub-scales for depression and anxiety. We use the overall PHQ-4 score, allowing us to combine PHQ-4 and BDI-II as both use a 4-level health concern categorization (normal, mild, moderate, and severe). For a stricter focus on depression, we recommend using the depression sub-scale of PHQ-4. Moreover, since DS1 did not have PHQ-4, we used another questionnaire as a substitute. Please refer to S.B.1 for details.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We utilize RAPIDS \\\\([3, 88]\\\\), an open-source platform that provides a Reproducible Analysis Pipeline for Data Streams. It supports feature extraction from data collected via multiple mobile and wearable devices with various time windows. S.A.7 lists feature details and potential limitations.\\n\\nData Type: Location.\\nWe incorporate all features in RAPIDS-Location, which includes location variance, location entropy, travel distance, etc. In addition, we also added more features (duration of staying) for specific points of interest, including places for living, study, exercise, and relaxation.\\n\\nData Type: Phone Usage.\\nWe include all features in RAPIDS-Screen that cover the statistics of unlocking episodes (count, sum, mean, std, max, min). We further contextualize these features at different locations (home and study places) to capture fine-grained phone usage behaviors.\\n\\nData Type: Bluetooth.\\nWe use all features from RAPIDS-Bluetooth, including the number of scans of participants' own devices and others' devices, as well as the unique count of these devices.\\n\\nData Type: Call.\\nWe employ features from RAPIDS-Call that cover the statistics of incoming/outgoing calls' duration (count, sum, mean, std, max, min, entropy), and the count of missed calls.\\n\\nData Type: Physical Activity.\\nWe utilize physical activity features from RAPIDS-Fitbit-Steps. They include both high-level features (number of steps, duration of being active), and low-level features about the statistics of active or sedentary episodes (mean, std, max, min).\\n\\nData Type: Sleep.\\nWe leverage sleep-related features from RAPIDS-Fitbit-Sleep, including high-level summary features (total duration of being asleep or in bed), and low-level features about the statistics (count, mean, max, min) of episodes of being asleep, restless, and awake during the sleep.\\n\\nFeature Time Range.\\nResearch has found that people tend to have distinctive behavior patterns during different times of the day \\\\([22]\\\\), or accumulate their behavior routines through a period of days \\\\([18]\\\\). Thus we incorporate different time ranges during feature extraction, including four epochs of a day (split at 6 am, 12 pm, 6 pm, and 12 am), the whole day, the past one/two weeks. It is worth noting that all features are calculated every day for each user, forming a long daily feature vector.\\n\\nPost-processing.\\nAfter feature extraction, we further conducted a few post-processing steps to provide a comprehensive feature set: 1) Feature normalization: We add all features' normalized version based on each individual's distribution: subtracting the median and scaling with the 5-95 quantile range on each individual; 2) Feature discretization: A few modeling algorithms may benefit from using categorical levels instead of raw feature values \\\\([101]\\\\), thus we also add all features' 3-level discretized version (split by the one/two/three third percentile within each individual's data).\\n\\nMissing data is inevitable due to various reasons, such as low battery, data transfer loss, and sensor permission withdrawal. For example, the average missing rate for location features is 14.5 \u00b1 4.0%.\\n\\nPlease find more details about the missing rates of different features in S.A.7. We omit missing values during analysis and use a median-based imputation when necessary.\\n\\n4 Dataset Analysis\\nOur multi-year datasets capture various aspects of participants' daily routines (Sec. 4.1), and reveal important insights into the relationship between daily behaviors and mental health metrics (Sec. 4.2). Meanwhile, the datasets also demonstrate potential domain generalization challenges (Sec. 4.3).\\n\\n4.1 Data Distribution\\nEach year's dataset covers a period of 10 weeks. Fig. 3 visualizes the daily value of three representative features across all years. Since the period of DS3 collection began right after the national lockdown (Mar to Jun, 2020), the impact of COVID is clearly reflected in the differences between DS1&2 vs. DS3&4 on the mobility-related features \\\\([70, 112, 113]\\\\). For example, the daily step count of DS3&4 drops by nearly half. Meanwhile, we can observe a recovery trend when comparing DS3 and DS4, as indicated by the increased travel distance and step counts. Interestingly, the travel distance in DS4 is close to DS1&2, while the step count is still much lower. This may suggest that participants used commuting methods other than walking even after cities were re-opened. Moreover, the weekly routine cycle is salient in all years. The daily travel distance significantly increases on weekends (mostly on Saturdays), while the walking step counts drop. Further, participants tended to leverage weekends to catch up on sleep, as shown by the peak in-bed duration around weekends.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Time-series of Example Features. Grids split weeks. Dashed lines split weekdays/weekends.\\n\\nWe further compare the probability density function (PDF) shapes of features across years in Fig. 4, using an example from each sensor type. We observe the distinction between DS1&2 vs. DS3&4. This again reveals the impact of the pandemic. Other than the similar observations from Fig. 3, we further find that participants visited fewer places, spent more time on smartphones, had longer phone call durations, and joined fewer social activities (as indicated by Bluetooth as proxy). These observations indicate that our datasets capture different aspects of daily routines and routine changes.\\n\\nIn addition, despite the similarity in some features' PDFs, each DS has its own unique feature distribution. For example, DS2 has a bimodal distribution on the number of frequent locations, while others' are unimodal. DS3's sleep duration has a slight distribution shift towards the right (i.e., participants tended to sleep more right after the lockdown). These distribution shifts suggest challenges for cross-dataset generalization of longitudinal modeling (see Sec. 4.3 for more details).\\n\\n4.2 Correlation Analysis\\n\\nOur datasets not only reflect participants' daily routines, but also capture the relationship between daily behaviors and well-being metrics. We use depression as an example for correlation analysis. We compute Spearman correlation coefficients $\\\\rho$ between every feature and the depression label in each dataset. Figure 5 shows top features from each type with significant $\\\\rho$s ($p < 0.05$) and the same directions in all datasets. There are some interesting findings. For example, the past two weeks' sleep duration and count of screen unlock episodes at night have the strongest correlation ($|\\\\rho| > 0.1$). Shorter sleep duration and more screen usage are associated with higher depression scores. These are supported by the psychology and psychiatry literature, which suggests disturbed sleep patterns and lack of focus are common depressive symptoms [8, 83, 85]. Moreover, other features indicate that participants with higher depression scores tended to have less physical activity and lower mobility.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Correlation Analysis of Representative Feature Value and Depression Labels\\n\\nspend more time at home, and engage in less social communication. These observations reflect a sign of diminished interest in other activities, another common symptom of depression [17, 76].\\n\\n4.3 Domain Classification\\n\\nTo quantify the differences among datasets, we first conduct a \u201cName-The-Dataset\u201d task on the four datasets [84], treating each dataset as a domain. We split the users 80%/20% into training/testing set, and use daily features as the input. We use a portion of users in the training data to train a small Random Forest (RF, n=10, max depth=3) to classify which dataset a data belongs to (i.e., four-class classification). The left side of Fig. 6a shows the results. With 1/10/100 users (0.2%/2%/20% of the training set), the model can achieve an accuracy of 62.3%/84.2%/91.1%, which indicates that behavior features from different DS have distinguishing distributions. We also repeated the training with normalized features, as shown in the right side of Fig. 6a. The normalization can reduce the distribution shift, especially for DS1 and DS4, but the distinction between datasets still persists.\\n\\nWe further conduct a \u201cDistinguish-The-Person\u201d task, with each person-year as a domain. This time the 80%/20% split is performed on each person\u2019s data. We train another RF (n=10, max leaf num=2K) to classify which person a data belongs to (i.e., 705-class classification). This is a more challenging task, but the model still achieves an accuracy of 7.7%/26.2%/46.3% when using 1/10/50 days of data from each participant (1.3%/13%65% of the training set). Meanwhile, the normalization does not significantly diminish the effect of distribution shift in this task, as shown in Fig. 6b. These results indicate that there exist significant distribution shifts among datasets and individuals. Our benchmark results in Sec. 5 demonstrate the challenges for domain generalization on behavior modeling tasks.\\n\\n5 Benchmark\\n\\nThere is a growing body of research showing that passive sensing data from everyday devices can capture daily behavior signals related to depressive symptoms [9, 12, 18, 52], which has attracted increasing attention from various communities. Therefore, we use depression detection as the main task to benchmark our multi-year datasets. We envision the platform can be extended to other behavior modeling tasks using different ground truth labels.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.1 Data Preparation\\n\\nThe raw data format is a time-series feature-vector for each participant, with a short list of labels on certain dates. Since data length varies across participants, we slice the feature sequence based on labels to construct consistent inputs. Given a label collected on a date, we collect a feature matrix of the past four weeks to cover behavior trajectory history [18, 60]. After the slicing, every data point corresponds to one label and an input feature matrix with the same shape (28 days \u00d7 feature number).\\n\\n5.2 Behavior Modeling Algorithms\\n\\nGLOBEM [104] closely re-implements 9 prior depression detection algorithms and 9 deep-learning domain generalization algorithms for consistent evaluation. The details of the algorithms, hyperparameters, and model training are described in S.B.2 and [104].\\n\\nDepression Detection Algorithms. Researchers in the ubiquitous computing community have proposed a range of algorithms that use passive mobile sensing for depression detection. Due to the limited size of these datasets, these methods mostly aggregate a subset of features within certain time ranges and train off-the-shelf traditional ML models: 1) Canzian et al. [18]: uses some location features to train an SVM; 2) Saeb et al. [78]: uses a subset of location and screen features to train a logistic regression model; 3) Farhan et al. [33]: uses location and physical activity features to train an SVM; 4) Wahle et al. [91]: uses features from several sensors to build SVM and Random Forest models; 5) Lu et al. [60]: uses multiple sensor features to build multi-task learning models combining linear and logistic regression; 6) Wang et al. [97]: calculates the average and slope of the past two weeks of behavior features, and builds a lasso-regularized logistic regression model; 7) Xu et al.-I [101]: applies association rule mining on behavior features to extract contextually filtered features to build an Adaboost model; 8) Xu et al.-P [102]: uses a collaborative-filtering-based model with the square of Pearson correlation coefficient as the weights; 9) Chikersal et al. [20]: calculates breakpoint and slope of multiple features, trains a gradient boosting model for each sensor, and combines them with an Adaboost model.\\n\\nDomain Generalization Algorithms. These techniques use the same set of features (i.e., the same feature matrix) as the input. We pick representative ones to cover major directions of domain generalization [94]: 1) ERM (Empirical Risk Minimization) [87]. We implement multiple architectures with ERM: ERM-1D-CNN, ERM-2D-CNN, ERM-LSTM, ERM-Transformer; 2) Mixup [111]; 3) IRM (Invariant Risk Minimization) [7]; 4) DANN (Domain-Adversarial Neural Network) [38]. We test both using dataset as a domain (DANN-Dataset as Domain), and person as a domain (DANN-P); 5) CSD (Common Specific Decomposition) [72]. Similarly, we also test CSD-D and CSD-P; 6) MLDG (Meta-Learning for Domain Generalization) [56], with MLDG-D, and MLDG-P; 7) MASF (Model-Agnostic Learning of Semantic Features) [30], with MASF-D, and MASF-P; 8) Siamese Network [49]; 9) Reorder [104], a self-supervised learning-based algorithm that leverages order reconstruction of a shuffled sequence as the pre-text task. Algorithms from 2-9 use the same 1D-CNN as the backbone.\\n\\n5.3 Experiment Setup\\n\\nWe experiment with multiple setups to evaluate algorithm performance: 1) Users Past/Future within One Dataset, a simple setup that uses the first 80% of every user's data as the training set, and the remaining 20% as the testing set in each DS. 2) Leave-One-Dataset-Out, a cross-dataset setup that uses three DS as the training set, and the other as the testing set. 3) Pre/Post-COVID, another cross-dataset setup to measure the effect of the pandemic, using DS1&2 (before COVID) as the training set and DS3&4 (after COVID) as the testing set, and then swapping the two sides. 4) Overlapping Users across Datasets, a cross-dataset setup that only focuses on overlapping users in multiple datasets to measure the time effect, which trains a model with overlapping users from one dataset, and tests it on overlapping users from other datasets. We employ balanced accuracy (the average of sensitivity and specificity) as the metric, as it has been shown to be more robust to class-imbalance [15].\\n\\n5.4 Model Performance\\n\\nTab. 2 summarizes the results of all algorithms in different setups. We highlight the important observations. No single depression detection algorithm stands out over most tasks. Xu et al.-I is the best for...\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Category Model | Single Dataset | Cross Dataset |\\n|----------------|---------------|---------------|\\n| Past/Future Leave-One-DS-Out | | |\\n| Baseline Majority | 0.500 \u00b1 0.000 | 0.500 \u00b1 0.000 |\\n| | 0.500 \u00b1 0.000 | 0.500 \u00b1 0.000 |\\n| | 0.500 \u00b1 0.000 | 0.500 \u00b1 0.000 |\\n| Prior Depression Detection Model | | |\\n| Canzian et al. [18] | 0.536 \u00b1 0.026 | 0.498 \u00b1 0.006 |\\n| | 0.497 \u00b1 0.003 | 0.496 \u00b1 0.003 |\\n| Saeb et al. [78] | 0.557 \u00b1 0.020 | 0.536 \u00b1 0.008 |\\n| | 0.519 \u00b1 0.004 | 0.565 \u00b1 0.039 |\\n| Farhan et al. [33] | 0.562 \u00b1 0.021 | 0.506 \u00b1 0.007 |\\n| | 0.500 \u00b1 0.019 | 0.480 \u00b1 0.013 |\\n| Wahle et al. [91] | 0.598 \u00b1 0.020 | 0.524 \u00b1 0.011 |\\n| | 0.526 \u00b1 0.003 | 0.512 \u00b1 0.013 |\\n| Lu et al. [60] | 0.550 \u00b1 0.024 | 0.531 \u00b1 0.011 |\\n| | 0.505 \u00b1 0.007 | 0.508 \u00b1 0.022 |\\n| Wang et al. [97] | 0.530 \u00b1 0.020 | 0.521 \u00b1 0.007 |\\n| | 0.524 \u00b1 0.010 | 0.532 \u00b1 0.028 |\\n| Xu et al. [101] | 0.691 \u00b1 0.018 | 0.502 \u00b1 0.012 |\\n| | 0.519 \u00b1 0.019 | 0.494 \u00b1 0.013 |\\n| Xu et al. [102] | 0.600 \u00b1 0.007 | 0.502 \u00b1 0.006 |\\n| | 0.508 \u00b1 0.003 | 0.544 \u00b1 0.009 |\\n| Recent Domain Generalization Model | | |\\n| ERM-1dCNN [87] | 0.568 \u00b1 0.006 | 0.510 \u00b1 0.008 |\\n| | 0.514 \u00b1 0.006 | 0.534 \u00b1 0.007 |\\n| ERM-2dCNN [87] | 0.533 \u00b1 0.013 | 0.510 \u00b1 0.006 |\\n| | 0.504 \u00b1 0.006 | 0.520 \u00b1 0.011 |\\n| ERM-LSTM [87] | 0.565 \u00b1 0.019 | 0.512 \u00b1 0.006 |\\n| | 0.512 \u00b1 0.003 | 0.525 \u00b1 0.020 |\\n| ERM-Transformer [87] | 0.584 \u00b1 0.013 | 0.509 \u00b1 0.008 |\\n| | 0.512 \u00b1 0.016 | 0.506 \u00b1 0.005 |\\n| ERM-Mixup [111] | 0.568 \u00b1 0.006 | 0.501 \u00b1 0.008 |\\n| | 0.507 \u00b1 0.004 | 0.534 \u00b1 0.007 |\\n| IRM [7] | 0.573 \u00b1 0.016 | 0.506 \u00b1 0.006 |\\n| | 0.499 \u00b1 0.000 | 0.508 \u00b1 0.015 |\\n| DANN-D [39] | 0.526 \u00b1 0.016 | 0.514 \u00b1 0.004 |\\n| | 0.514 \u00b1 0.000 | 0.482 \u00b1 0.013 |\\n| DANN-P [39] | 0.502 \u00b1 0.002 | 0.500 \u00b1 0.000 |\\n| | 0.500 \u00b1 0.000 | 0.486 \u00b1 0.017 |\\n| CSD-D [72] | 0.562 \u00b1 0.022 | 0.521 \u00b1 0.002 |\\n| | 0.512 \u00b1 0.006 | 0.517 \u00b1 0.025 |\\n| CSD-P [72] | 0.542 \u00b1 0.010 | 0.511 \u00b1 0.006 |\\n| | 0.516 \u00b1 0.000 | 0.515 \u00b1 0.028 |\\n| MLDG-D [56] | 0.522 \u00b1 0.013 | 0.511 \u00b1 0.006 |\\n| | 0.495 \u00b1 0.004 | 0.519 \u00b1 0.014 |\\n| MLDG-P [56] | 0.508 \u00b1 0.011 | 0.510 \u00b1 0.003 |\\n| | 0.500 \u00b1 0.003 | 0.511 \u00b1 0.016 |\\n| MAFS-D [30] | 0.505 \u00b1 0.006 | 0.505 \u00b1 0.001 |\\n| | 0.504 \u00b1 0.007 | 0.532 \u00b1 0.015 |\\n| MAFS-P [30] | 0.495 \u00b1 0.007 | 0.505 \u00b1 0.004 |\\n| | 0.509 \u00b1 0.011 | 0.530 \u00b1 0.011 |\\n| Siamese Network [49] | 0.545 \u00b1 0.025 | 0.509 \u00b1 0.010 |\\n| | 0.515 \u00b1 0.002 | 0.527 \u00b1 0.031 |\\n| Reorder [104] | 0.626 \u00b1 0.009 | 0.547 \u00b1 0.008 |\\n| | 0.525 \u00b1 0.003 | 0.573 \u00b1 0.030 |\\n\\nThe purpose of using widely available passive sensing data for human behavior modeling, especially for mental health issue detection (e.g., depression in our task), may be arguable. Current research studies assume a positive goal of applying such modeling techniques to support early diagnosis and future adaptive intervention design [105]. But we may need careful regulations on practitioners and stakeholders to avoid negative uses, such as selling under-verified products/medications, or providing mental health support services that are not well-suited to individuals.\\n\\nPrivacy is another major ethical concern of our data collection studies. We strictly follow our IRB's rules for anonymizing participants' data. Since some sensitive sensor data (e.g., location) can disclose identities, we only release feature-level data under credentialing to protect against privacy leakage. Please refer to S.C for our data sharing and maintenance plan. Further, our datasets have diverse yet unbalanced groups (e.g., racial groups), which could introduce bias in model training against underrepresented minorities. S.A.4 discusses more aspects of potential intrinsic bias.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"and the gradual recovery after COVID. Moreover, Sec. 4.2 uses depression as the target and reveals that some behavior features have a consistent correlation across multiple datasets with the scores of depression scales (e.g., less physical movement, more disturbed sleep patterns, less social activities), which are supported by literature in psychology and psychiatry [8, 76, 83]. Please refer to Sec. A.5 for additional correlation analysis between pre- and post-COVID periods. Compared to most prior studies using a single dataset (e.g., [95, 101]), our findings have stronger validity and credibility.\\n\\nLack of Generalizability of Existing Algorithms. Despite some similarity across datasets, Sec. 4.3 indicates distribution shifts across datasets and individuals. To some extent, this is expected due to the different societal contexts each year and the uniqueness of each person's behavior patterns [102]. However, our benchmark results in Sec. 5.4 demonstrate that both prior depression detection algorithms and recent domain generalization techniques suffer from overfitting and cannot generalize well across datasets. This may be explained by the fact that most domain generalization algorithms we implemented were proposed for CV/NLP tasks, and were not designed for the longitudinal modeling tasks. Although Reorder achieves the best generalization performance, it is still far from practical deployability. These results indicate that further advances in generalizability are much needed in the area of longitudinal behavior modeling.\\n\\nProspective Directions to Improve Model Generalizability. There are two major challenges of generalizability, which illuminates two potential directions to improve model performance: behavior change of an individual across time, and behavior differences between individuals. Compared to other cross-dataset setups, the setup of overlapping users has a relative performance advantage (see Table 2). This indicates that addressing temporal shifts along a single individual's longitudinal behavior could be a relatively easier task. Some recent algorithms such as AdaRNN [31] are designed to address this challenge and are worth testing. As for the individual difference, Reorder indicates that leveraging a pre-text shuffling and reordering task may push the model to learn more generalizable representations. This suggests that designing more pre-text tasks that can capture the nature of human behavior could be another future direction, e.g., a task to predict the immediate next behavior feature value (analogous to the pre-text task of BERT [27]).\\n\\nOther Potential Behavior Modeling Tasks. Our experiments and benchmark results focus on the depression detection task. Our datasets contain rich ground truth labels that can support a wide range of behavior modeling tasks. For frequent weekly prediction tasks, our datasets also have labels of participants' stress level (PSS-4) and emotions (PANAS). These labels can enable longitudinal stress detection or emotion monitoring tasks, which can be complementary to existing research using short-term physiological sensing data such as PPG and GSR signals (e.g., [61, 66]). Moreover, our datasets can be used for other behavior modeling tasks with less frequent labels, such as personality prediction [98] (BFI10), social loneliness evaluation [29] (UCLA, Social Fit), discrimination event detection [79], etc. Please refer to S.A.6 for a comprehensive list of survey data we collected, which provide the community with the potential to explore diverse modeling tasks.\\n\\nLimitations & Future Work. There are some limitations that can be addressed in future work, such as more diverse populations beyond young adults, more sensor signals such as HRV and SpO2 measures from wearables, and better missing data processing methods. It is worth noting that the validity of using self-report for depression measures and other mental health classifications is still debated [36], creating inherent challenges for model development. However, more valid ground truth such as clinical diagnosis are harder to obtain and less frequent. In addition, sensor error across phone and wearable models may introduce additional noise to the datasets [82]. Also, more advanced data imputation techniques, recent adaptive time-series algorithms, and other modeling targets besides depression can be evaluated on our datasets. These behavior models may shed light on the future work of developing intelligent, just-in-time adaptive intervention techniques [71, 107].\\n\\n7 Conclusion\\n\\nWe release the first multi-year longitudinal mobile sensing datasets with multiple sensor streams and various well-being metrics. Our analysis indicates that the datasets capture a range of daily routines, revealing insights between daily behaviors and important well-being metrics such as depression status. Our benchmark results reveal the challenge and the opportunity for the ML community to develop generalizable longitudinal behavior modeling algorithms. We also envision our datasets serving as a gold-standard benchmark for future machine learning research in longitudinal time-series data for human behavior modeling.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments and Disclosure of Funding\\n\\nOur multi-year data collection study closely followed a sister study at Carnegie Mellon University (CMU). We acknowledge all efforts from CMU Study Team to provide important starting and reference materials. Moreover, our studies were greatly inspired by StudentLife researchers from Dartmouth College.\\n\\nOur studies were supported by the University of Washington (including the Paul G. Allen School of Computer Science and Engineering; Department of Electrical and Computer Engineering; Population Health; Addictions, Drug and Alcohol Institute; and the Center for Research and Education on Accessible Technology and Experiences); the National Science Foundation (EDA-2009977, CHS-2016365, CHS-1941537, IIS1816687 and IIS7974751), the National Institute on Disability, Independent Living and Rehabilitation Research (90DPGE0003-01), Samsung Research America, and Google.\\n\\nReferences\\n\\n[1] Perceived Stress Scale 4 (PSS-4). [http://www.ohnurses.org/wp-content/uploads/2015/05/Perceived-Stress-Scale-41.pdf].\\n\\n[2] Positive and negative affect schedule (panas-sf). [https://ogg.osu.edu/media/documents/MB%20Stream/PANAS.pdf].\\n\\n[3] Rapids documentation. [https://www.rapids.science/1.6/].\\n\\n[4] Studentlife study https://studentlife.cs.dartmouth.edu/, 2014.\\n\\n[5] Measuring Discrimination Resource. [https://scholar.harvard.edu/files/davidrwilliams/files/measuring_discrimination_resource_june_2016.pdf], 2016.\\n\\n[6] PHQ-4: THE FOUR-ITEM PATIENT HEALTH QUESTIONNAIRE FOR ANXIETY AND DEPRESSION. [https://www.oregonpainguidance.org/app/content/uploads/2016/05/PHQ-4.pdf], 2016.\\n\\n[7] M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz. Invariant Risk Minimization. arXiv:1907.02893 [cs, stat], Mar. 2020. arXiv: 1907.02893.\\n\\n[8] A. P. Association et al. Diagnostic and statistical manual of mental disorders (dsm-5 \u00ae). American Psychiatric Pub, 2013.\\n\\n[9] M. S. H. Aung, F. Alquaddoomi, C.-K. Hsieh, M. Rabbi, L. Yang, J. P. Pollak, D. Estrin, and T. Choudhury. Leveraging multi-modal sensing for mobile health: A case review in chronic pain. IEEE Journal of Selected Topics in Signal Processing, 10(5):962\u2013974, 2016.\\n\\n[10] Y. Balaji, S. Sankaranarayanan, and R. Chellappa. Metareg: Towards domain generalization using meta-regularization. Advances in neural information processing systems, 31, 2018.\\n\\n[11] A. T. Beck, R. A. Steer, R. Ball, and W. F. Ranieri. Comparison of beck depression inventories-ia and-ii in psychiatric outpatients. Journal of personality assessment, 67(3):588\u2013597, 1996.\\n\\n[12] D. Ben-Zeev, R. Brian, R. Wang, W. Wang, A. T. Campbell, M. S. Aung, M. Merrill, V. W. Tseng, T. Choudhury, M. Hauser, et al. Crosscheck: Integrating self-report, behavioral sensing, and smartphone use to identify digital indicators of psychotic relapse. Psychiatric rehabilitation journal, 40(3):266, 2017.\\n\\n[13] P. J. Bieling, M. M. Antony, and R. P. Swinson. The state\u2013trait anxiety inventory, trait version: structure and content re-examined. Behaviour research and therapy, 36(7-8):777\u2013788, 1998.\\n\\n[14] L. D. Bobo, M. L. Oliver, J. J. H. Johnson, and V. Abel Jr. Prismatic metropolis: inequality in Los Angeles. Russell Sage Foundation, 2000.\\n\\n[15] K. H. Brodersen, C. S. Ong, K. E. Stephan, and J. M. Buhmann. The balanced accuracy and its posterior distribution. In 2010 20th international conference on pattern recognition, pages 3121\u20133124. IEEE, 2010.\\n\\n[16] K. W. Brown and R. M. Ryan. The benefits of being present: mindfulness and its role in psychological well-being. Journal of personality and social psychology, 84(4):822, 2003.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"T. C. Camacho, R. E. Roberts, N. B. Lazarus, G. A. Kaplan, and R. D. Cohen. Physical activity and depression: evidence from the Alameda County Study. American Journal of Epidemiology, 134(2):220\u2013231, 1991.\\n\\nL. Canzian and M. Musolesi. Trajectories of depression: Unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis. Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing, pages 1293\u20131304, 2015.\\n\\nC. S. Carver. You want to measure coping but your protocol\u2019s too long: Consider the brief cope. International Journal of Behavioral Medicine, 4(1):92\u2013100, 1997.\\n\\nP. Chikersal, A. Doryab, M. Tumminia, D. K. Villalba, J. M. Dutcher, X. Liu, S. Cohen, K. G. Creswell, J. Mankoff, J. D. Creswell, M. Goel, and A. K. Dey. Detecting Depression and Predicting its Onset Using Longitudinal Symptoms Captured by Passive Sensing. ACM Transactions on Computer-Human Interaction, 28(1):1\u201341, Jan. 2021.\\n\\nT. Choudhury, G. Borriello, S. Consolvo, D. Haehnel, B. Harrison, B. Hemingway, J. Hightower, P. Pedja, K. Koscher, A. LaMarca, et al. The mobile sensing platform: An embedded activity recognition system. IEEE Pervasive Computing, 7(2):32\u201341, 2008.\\n\\nP. I. Chow, K. Fua, Y. Huang, W. Bonelli, H. Xiong, L. E. Barnes, and B. A. Teachman. Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students. Journal of Medical Internet Research, 19(3), 2017.\\n\\nS. Cohen and H. M. Hoberman. Positive events and social supports as buffers of life change stress 1. Journal of Applied Social Psychology, 13(2):99\u2013125, 1983.\\n\\nS. Cohen, T. Kamarck, and R. Mermelstein. A global measure of perceived stress. Journal of Health and Social Behavior, pages 385\u2013396, 1983.\\n\\nJ. C. Cole, A. S. Rabin, T. L. Smith, and A. S. Kaufman. Development and validation of a Rasch-derived CES-D short form. Psychological Assessment, 16(4):360, 2004.\\n\\nH. Daum\u00e9 III. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 256\u2013263, Prague, Czech Republic, June 2007. Association for Computational Linguistics.\\n\\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805 [cs], May 2019. arXiv: 1810.04805.\\n\\nE. Diener, D. Wirtz, W. Tov, C. Kim-Prieto, D.-W. Choi, S. Oishi, and R. Biswas-Diener. New well-being measures: Short scales to assess flourishing and positive and negative feelings. Social Indicators Research, 97(2):143\u2013156, 2010.\\n\\nA. Doryab, D. K. Villalba, P. Chikersal, J. M. Dutcher, M. Tumminia, X. Liu, S. Cohen, K. Creswell, J. Mankoff, J. D. Creswell, et al. Identifying behavioral phenotypes of loneliness and social isolation with passive sensing: statistical analysis, data mining and machine learning of smartphone and Fitbit data. JMIR mHealth and uHealth, 7(7):e13209, 2019.\\n\\nQ. Dou, D. C. Castro, K. Kamnitsas, and B. Glocker. Domain Generalization via Model-Agnostic Learning of Semantic Features. arXiv:1910.13580 [cs], Oct. 2019. arXiv: 1910.13580.\\n\\nY. Du, J. Wang, W. Feng, S. Pan, T. Qin, R. Xu, and C. Wang. Adarnn: Adaptive learning and forecasting of time series. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 402\u2013411, 2021.\\n\\nC. Fang, Y. Xu, and D. N. Rockmore. Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias. In Proceedings of the IEEE International Conference on Computer Vision, pages 1657\u20131664, 2013.\\n\\nA. A. Farhan, C. Yue, R. Morillo, S. Ware, J. Lu, J. Bi, J. Kamath, A. Russell, A. Bamis, and B. Wang. Behavior vs. introspection: refining prediction of clinical depression via smartphone sensing data. In 2016 IEEE Wireless Health (WH), pages 1\u20138. IEEE, Oct. 2016.\\n\\nL. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(4):594\u2013611, 2006.\\n\\nD. Ferreira, V. Kostakos, and A. K. Dey. Aware: Mobile context instrumentation framework. Frontiers in ICT, 2:6, 2015.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"E. I. Fried, J. K. Flake, and D. J. Robinaugh. Revisiting the theoretical and methodological foundations of depression measurement. Nature Reviews Psychology, pages 1\u201311, 2022.\\n\\nJ.-C. Gagnon-Audet, K. Ahuja, M.-J. Darvishi-Bayazi, G. Dumas, and I. Rish. Woods: Benchmarks for out-of-distribution generalization in time series tasks. arXiv preprint arXiv:2203.09978, 2022.\\n\\nY. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. Lempitsky. Domain-Adversarial Training of Neural Networks. In Domain Adaptation in Computer Vision Applications, pages 189\u2013209. Springer International Publishing, Cham, 2017. Series Title: Advances in Computer Vision and Pattern Recognition.\\n\\nR. K. Ganti, F. Ye, and H. Lei. Mobile crowdsensing: current state and future challenges. IEEE communications Magazine, 49(11):32\u201339, 2011.\\n\\nN. Gao, M. Marschall, J. Burry, S. Watkins, and F. D. Salim. Understanding occupants' behaviour, engagement, emotion, and comfort indoors with heterogeneous sensors and wearables. Scientific Data, 9(1):1\u201316, 2022.\\n\\nV. Garg, A. T. Kalai, K. Ligett, and S. Wu. Learn to expect the unexpected: Probably approximately correct domain generalization. In International Conference on Artificial Intelligence and Statistics, pages 3574\u20133582. PMLR, 2021.\\n\\nR. Godahewa, C. Bergmeir, G. I. Webb, R. J. Hyndman, and P. Montero-Manso. Monash time series forecasting archive. In Neural Information Processing Systems Track on Datasets and Benchmarks, 2021.\\n\\nT. Gong, Y. Kim, J. Shin, and S.-J. Lee. Metasense: few-shot adaptation to untrained conditions in deep mobile sensing. In Proceedings of the 17th Conference on Embedded Networked Sensor Systems, pages 110\u2013123, 2019.\\n\\nJ. J. Gross and O. P. John. Individual differences in two emotion regulation processes: implications for affect, relationships, and well-being. Journal of personality and social psychology, 85(2):348, 2003.\\n\\nI. Gulrajani and D. Lopez-Paz. In Search of Lost Domain Generalization. page 29, 2021.\\n\\nR. I. Kabacoff, D. L. Segal, M. Hersen, and V. B. Van Hasselt. Psychometric properties and diagnostic utility of the beck anxiety inventory and the state-trait anxiety inventory with older adult psychiatric outpatients. Journal of anxiety disorders, 11(1):33\u201347, 1997.\\n\\nC. W. Kahler, D. R. Strong, and J. P. Read. Toward efficient and comprehensive measurement of the alcohol problems continuum in college students: The brief young adult alcohol consequences questionnaire. Alcoholism: Clinical and Experimental Research, 29(7):1180\u20131189, 2005.\\n\\nG. Koch, R. Zemel, and R. Salakhutdinov. Siamese Neural Networks for One-shot Image Recognition. Proceedings of the 32nd International Conference on Machine Learning, page 8, 2015.\\n\\nP. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L. Phillips, I. Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637\u20135664. PMLR, 2021.\\n\\nK. Kroenke, R. L. Spitzer, J. B. Williams, and B. L\u00f6we. An ultra-brief screening scale for anxiety and depression: the phq\u20134. Psychosomatics, 50(6):613\u2013621, 2009.\\n\\nN. D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury, and A. T. Campbell. A survey of mobile phone sensing. IEEE Communications Magazine, 48(9), 2010.\\n\\nV. Le Guen and N. Thome. Shape and time distortion loss for training deep time series forecasting models. Advances in neural information processing systems, 32, 2019.\\n\\nD. Li, J. Yang, K. Kreis, A. Torralba, and S. Fidler. Semantic segmentation with generative models: Semi-supervised learning and strong out-of-domain generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8300\u20138311, 2021.\\n\\nD. Li, Y. Yang, Y.-Z. Song, and T. M. Hospedales. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision, pages 5542\u20135550, 2017.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"D. Li, Y. Yang, Y.-Z. Song, and T. M. Hospedales. Learning to Generalize: Meta-Learning for Domain Generalization. arXiv:1710.03463 [cs], Oct. 2017. arXiv: 1710.03463.\\n\\nD. Li, J. Zhang, Y. Yang, C. Liu, Y.-Z. Song, and T. M. Hospedales. Episodic training for domain generalization. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1446\u20131455, 2019.\\n\\nC. Liu, X. Sun, J. Wang, H. Tang, T. Li, T. Qin, W. Chen, and T.-Y. Liu. Learning causal semantic representation for out-of-distribution prediction. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nX. Liu, Z. Jiang, J. Fromm, X. Xu, S. Patel, and D. McDuff. MetaPhys: few-shot adaptation for non-contact physiological measurement. In Proceedings of the Conference on Health, Inference, and Learning, pages 154\u2013163, Virtual Event USA, Apr. 2021. ACM.\\n\\nJ. Lu, J. Bi, C. Shang, C. Yue, R. Morillo, S. Ware, J. Kamath, A. Bamis, A. Russell, and B. Wang. Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(1):1\u201321, 2018. ISBN: 9781450351980.\\n\\nJ. Mar\u00edn-Morales, J. L. Higuera-Trujillo, A. Greco, J. Guixeres, C. Llinares, E. P. Scilingo, M. Alca\u00f1iz, and G. Valenza. Affective computing in virtual reality: emotion recognition from brain and heartbeat dynamics using wearable sensors. Scientific reports, 8(1):1\u201315, 2018.\\n\\nY. Matsubara, Y. Sakurai, W. G. Van Panhuis, and C. Faloutsos. Funnel: automatic mining of spatially coevolving epidemics. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 105\u2013114, 2014.\\n\\nS. M. Mattingly, J. M. Gregg, P. Audia, A. E. Bayraktaroglu, A. T. Campbell, N. V. Chawla, V. Das Swain, M. De Choudhury, S. K. D'Mello, A. K. Dey, et al. The tesserae project: Large-scale, longitudinal, in situ, multimodal sensing of information workers. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, pages 1\u20138, 2019.\\n\\nM. E. McCullough, R. A. Emmons, and J.-A. Tsang. The grateful disposition: a conceptual and empirical topography. Journal of personality and social psychology, 82(1):112, 2002.\\n\\nJ.-K. Min, A. Doryab, J. Wiese, S. Amini, J. Zimmerman, and J. I. Hong. Toss \u201cn\u201d turn: Smartphone as sleep and sleep quality detector. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201914, page 477\u2013486, New York, NY, USA, 2014. Association for Computing Machinery.\\n\\nV. Mishra, S. Sen, G. Chen, T. Hao, J. Rogers, C. H. Chen, and D. Kotz. Evaluating the reproducibility of physiological stress detection models. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 2020.\\n\\nM. E. Morris and F. Guilak. Mobile heart health: project highlight. IEEE Pervasive Computing, 8(2):57\u201361, 2009.\\n\\nM. E. Morris and A. Aguilera. Mobile, social, and wearable computing and the evolution of psychological practice. Professional Psychology: Research and Practice, 43(6):622, 2012.\\n\\nM. E. Morris, Q. Kathawala, T. K. Leen, E. E. Gorenstein, F. Guilak, W. DeLeeuw, and M. Labhard. Mobile therapy: case study evaluations of a cell phone application for emotional self-awareness. Journal of medical Internet research, 12(2):e10, 2010.\\n\\nM. E. Morris, K. S. Kuehn, J. Brown, P. S. Nurius, H. Zhang, Y. S. Sefidgar, X. Xu, E. A. Riskin, A. K. Dey, S. Consolvo, and J. C. Mankoff. College from home during COVID-19: A mixed-methods study of heterogeneous experiences. PLOS ONE, 16(6):e0251580, June 2021.\\n\\nI. Nahum-Shani, S. N. Smith, B. J. Spring, L. M. Collins, K. Witkiewitz, A. Tewari, and S. A. Murphy. Just-in-Time Adaptive Interventions (JITAIs) in Mobile Health: Key Components and Design Principles for Ongoing Health Behavior Support. Annals of Behavioral Medicine, 52(6):446\u2013462, May 2018.\\n\\nV. Piratla, P. Netrapalli, and S. Sarawagi. Efficient Domain Generalization via Common-Specific Low-Rank Decomposition. arXiv:2003.12815 [cs, stat], Apr. 2020. arXiv: 2003.12815.\\n\\nH. Qian, S. J. Pan, C. Miao, H. Qian, S. Pan, and C. Miao. Latent independent excitation for generalizable sensor-based cross-person activity recognition. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 11921\u201311929, 2021.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1. L. S. Radloff. The ces-d scale: A self-report depression scale for research in the general population. *Applied psychological measurement*, 1(3):385\u2013401, 1977.\\n\\n2. B. Rammstedt and O. P. John. Measuring personality in one minute or less: A 10-item short version of the big five inventory in English and German. *Journal of research in Personality*, 41(1):203\u2013212, 2007.\\n\\n3. B. Roshanaei-Moghaddam, W. J. Katon, and J. Russo. The longitudinal effects of depression on physical activity. *General hospital psychiatry*, 31(4):306\u2013315, 2009.\\n\\n4. D. W. Russell. UCLA loneliness scale (version 3): Reliability, validity, and factor structure. *Journal of personality assessment*, 66(1):20\u201340, 1996.\\n\\n5. S. Saeb, M. Zhang, C. J. Karr, S. M. Schueller, M. E. Corden, K. P. Kording, and D. C. Mohr. Mobile phone sensor correlates of depressive symptom severity in daily-life behavior: An exploratory study. *Journal of Medical Internet Research*, 17(7):1\u201311, 2015.\\n\\n6. Y. S. Sefidgar, W. Seo, K. S. Kuehn, T. Althoff, A. Browning, E. Riskin, P. S. Nurius, A. K. Dey, and J. Mankoff. Passively-sensed behavioral correlates of discrimination events in college students. *Proc. ACM Hum.-Comput. Interact.*, 3(CSCW), Nov 2019.\\n\\n7. J. Shakespeare-Finch and P. L. Obst. The development of the 2-way social support scale: A measure of giving and receiving emotional and instrumental support. *Journal of personality assessment*, 93(5):483\u2013490, 2011.\\n\\n8. B. W. Smith, J. Dalen, K. Wiggins, E. Tooley, P. Christopher, and J. Bernard. The brief resilience scale: Assessing the ability to bounce back. *International journal of behavioral medicine*, 15(3):194\u2013200, 2008.\\n\\n9. A. Stisen, H. Blunck, S. Bhattacharya, T. S. Prentow, M. B. Kj\u00e6rgaard, A. Dey, T. Sonne, and M. M. Jensen. Smart devices are different: Assessing and mitigating mobile sensing heterogeneities for activity recognition. In *Proceedings of the 13th ACM conference on embedded networked sensor systems*, pages 127\u2013140, 2015.\\n\\n10. M. E. Thase. Depression, sleep, and antidepressants. *The Journal of Clinical Psychiatry*, 1998.\\n\\n11. A. Torralba and A. A. Efros. Unbiased look at dataset bias. In *CVPR 2011*, volume 2011, pages 1521\u20131528. IEEE, June 2011. Issue: 28.\\n\\n12. N. Tsuno, A. Besset, and K. Ritchie. Sleep and depression. *The Journal of Clinical Psychiatry*, 2005.\\n\\n13. E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In *Proceedings of the IEEE international conference on computer vision*, pages 4068\u20134076, 2015.\\n\\n14. V. N. Vapnik. An overview of statistical learning theory. *IEEE transactions on neural networks*, 10(5):988\u2013999, 1999.\\n\\n15. J. Vega, M. Li, K. Aguillera, N. Goel, E. Joshi, K. Khandekar, K. C. Durica, A. R. Kunta, and C. A. Low. Reproducible analysis pipeline for data streams: Open-source software to process data collected with mobile devices. *Frontiers in Digital Health*, 3, 2021.\\n\\n16. H. Venkateswara, J. Eusebio, S. Chakraborty, and S. Panchanathan. Deep hashing network for unsupervised domain adaptation. In *Proceedings of the IEEE conference on computer vision and pattern recognition*, pages 5018\u20135027, 2017.\\n\\n17. T. Vo\u2019s and the GBD 2015 Disease and Injury Incidence and Prevalence Collaborators. Global, regional, and national incidence, prevalence, and years lived with disability for 310 diseases and injuries, 1990\u20132015: A systematic analysis for the global burden of disease study 2015. *The Lancet*, 388(10053):1545\u20131602, 2016.\\n\\n18. F. Wahle, T. Kowatsch, E. Fleisch, M. Rufer, and S. Weidt. Mobile Sensing and Support for People With Depression: A Pilot Trial in the Wild. *JMIR mHealth and uHealth*, 4(3):e111, 2016. ISBN: doi:10.2196/mhealth.5960.\\n\\n19. G. M. Walton and G. L. Cohen. A question of belonging: race, social fit, and achievement. *Journal of personality and social psychology*, 92(1):82, 2007.\\n\\n20. B. Wang, M. Lapata, and I. Titov. Meta-learning for domain generalization in semantic parsing. In *NAACL-HLT*, pages 366\u2013379, 2021.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"J. Wang, C. Lan, C. Liu, Y. Ouyang, T. Qin, W. Lu, Y. Chen, W. Zeng, and P. S. Yu. Generalizing to Unseen Domains: A Survey on Domain Generalization. arXiv:2103.03097 [cs], Dec. 2021. arXiv: 2103.03097.\\n\\nR. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev, and A. T. Campbell. Studentlife: Assessing mental health, academic performance and behavioral trends of college students using smartphones. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pages 3\u201314. ACM, 2014.\\n\\nR. Wang, G. Harari, P. Hao, X. Zhou, and A. T. Campbell. Smartgpa: how smartphones can assess and predict academic performance of college students. In Proceedings of the 2015 ACM international joint conference on pervasive and ubiquitous computing, pages 295\u2013306, 2015.\\n\\nR. Wang, W. Wang, A. daSilva, J. F. Huckins, W. M. Kelley, T. F. Heatherton, and A. T. Campbell. Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(1):1\u201326, 2018. ISBN: 2474-9567.\\n\\nW. Wang, G. M. Harari, R. Wang, S. R. M\u00fcller, S. Mirjafari, K. Masaba, and A. T. Campbell. Sensing behavioral change over time: Using within-person variability features from mobile sensing to predict personality traits. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(3):1\u201321, 2018.\\n\\nD. Watson, L. A. Clark, and A. Tellegen. Development and validation of brief measures of positive and negative affect: the panas scales. Journal of personality and social psychology, 54(6):1063, 1988.\\n\\nD. R. Williams, Y. Yu, J. S. Jackson, and N. B. Anderson. Racial differences in physical and mental health: Socio-economic status, stress and discrimination. Journal of health psychology, 2(3):335\u2013351, 1997.\\n\\nX. Xu, P. Chikersal, A. Doryab, D. K. Villalba, J. M. Dutcher, M. J. Tumminia, T. Althoff, S. Cohen, K. G. Creswell, J. D. Creswell, J. Mankoff, and A. K. Dey. Leveraging Routine Behavior and Contextually-Filtered Features for Depression Detection among College Students. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 3(3):1\u201333, Sept. 2019.\\n\\nX. Xu, P. Chikersal, J. M. Dutcher, Y. S. Sefidgar, W. Seo, M. J. Tumminia, D. K. Villalba, S. Cohen, K. G. Creswell, J. D. Creswell, A. Doryab, P. S. Nurius, E. Riskin, A. K. Dey, and J. Mankoff. Leveraging Collaborative-Filtering for Personalized Behavior Modeling: A Case Study of Depression Detection among College Students. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 5(1):1\u201327, Mar. 2021.\\n\\nX. Xu, A. Hassan Awadallah, S. T. Dumais, F. Omar, B. Popp, R. Rounthwaite, and F. Jahanbakhsh. Understanding User Behavior For Document Recommendation. In Proceedings of The Web Conference 2020, pages 3012\u20133018, Taipei Taiwan, Apr. 2020. ACM.\\n\\nX. Xu, X. Liu, H. Zhang, W. Wang, S. Nepal, K. S. Kuehn, J. Huckins, M. E. Morris, P. S. Nurius, E. A. Riskin, S. Patel, T. Althoff, A. Campell, A. K. Dey, and J. Mankoff. Globem: Cross-dataset generalization of longitudinal human behavior modeling. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 5(1):1, 2022.\\n\\nX. Xu, J. Mankoff, and A. K. Dey. Understanding practices and needs of researchers in human state modeling by passive mobile sensing. CCF Transactions on Pervasive Computing and Interaction, July 2021.\\n\\nX. Xu, E. Nemati, K. Vatanparvar, V. Nathan, T. Ahmed, M. M. Rahman, D. McCaffrey, J. Kuang, and J. A. Gao. Listen2Cough: Leveraging End-to-End Deep Learning Cough Detection Model to Enhance Lung Health Assessment Using Passively Sensed Audio. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 5(1):1\u201322, Mar. 2021.\\n\\nX. Xu, T. Zou, H. Xiao, Y. Li, R. Wang, T. Yuan, Y. Wang, Y. Shi, J. Mankoff, and A. K. Dey. TypeOut: Leveraging Just-in-Time Self-Affirmation for Smartphone Overuse Reduction. In CHI Conference on Human Factors in Computing Systems, pages 1\u201317, New Orleans LA USA, Apr. 2022. ACM.\\n\\nY. Yao and G. Doretto. Boosting for transfer learning with multiple sources. In 2010 IEEE computer society conference on computer vision and pattern recognition, pages 1855\u20131862. IEEE, 2010.\\n\\nH. Y\u00e8che, R. Kuznetsova, M. Zimmermann, M. H\u00fcser, X. Lyu, M. Faltys, and G. Ratsch. HiRID-ICU-benchmark \u2014 a comprehensive machine learning benchmark on high-resolution ICU data. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1), 2021.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our data collection studies were conducted at a Carnegie-classified R-1 university in the United States with an IRB review and approval. We recruited undergraduates via emails from 2018 to 2021. After the first year, previous-year participants were invited to join again. The study was conducted during Spring quarter for 10 weeks each year, so the impact of seasonal effects was controlled. Based on their compliance, participants received up to $245 in compensation every quarter.\\n\\nThe four datasets (DS1 to DS4) have 155, 218, 137, and 195 participants (705 person-years overall, and 497 unique people). Our datasets have a high representation of females (58.9%), immigrants (24.2%), first-generations (38.2%), and disability (9.1%), and have a wide coverage of races, with Asian (53.9%) and White (31.9%) being dominant (e.g., Hispanic/Latino 7.4%, Black/African American 3.3%).\\n\\nPart 1: Survey Data\\n\\nWe collected survey data at multiple stages of the study. We delivered extensive surveys before the start and at the end of the study (pre/post surveys) and short weekly Ecological Momentary Assessment (EMA) surveys during the study to collect in-the-moment self-report data. All surveys consist of well-established and validated questionnaires to ensure data quality.\\n\\nOur pre/post surveys include a number of questionnaires to cover various aspects of life, including 1) personality (BFI-10, The Big-Five Inventory-10), 2) physical health (CHIPS, Cohen-Hoberman Inventory of Physical Symptoms), 3) mental well-being (e.g., BDI-II, Beck Depression Inventory-II; ERQ, Emotion Regulation Questionnaire), and 4) social well-being (e.g., Sense of Social and Academic Fit Scale; EDS, Everyday Discrimination Scale). Our EMA surveys focus on capturing participants' recent sense of their mental health, including PHQ-4, Patient Health Questionnaire 4; PSS-4, Perceived Stress Scale 4; and PANAS, Positive and Negative Affect Schedule.\\n\\nWe use the depression detection task as a starting point for behavior modeling. We employ BDI-II (post) and PHQ-4 (EMA) as the ground truth. Both are screening tools for further inquiry of clinical depression diagnosis. We focus on a binary classification problem to distinguish whether participants' scores indicate at least mild depressive symptoms through the scales (i.e., PHQ-4 > 2, BDI-II > 13).\\n\\nThe average number of depression labels is 11.6 \u00b1 2.6 per person. The percentage of participants with at least mild depression is 39.8 \u00b1 2.7% for BDI-II and 46.2 \u00b1 2.5% for PHQ-4. Due to some design iteration, we did not include PHQ-4 in DS1, but only PANAS. Although PANAS contains questions related to depressive symptoms (e.g., \u201cdistressed\u201d), it does not have a comparable theoretical foundation for depression detection like PHQ-4 or BDI-II. Therefore, to maximize the compatibility of the datasets, we trained a small ML model on DS2 that has both PANAS and PHQ-4 scores to generate reliable ground truth labels. Specifically, we used a decision tree (depth=2) to take PNANS scores on two affect questions (\u201cdepressed\u201d and \u201cnervous\u201d) as the input and predict PHQ-4 score-based depression binary label. Our model achieved 74.5% and 76.3% for accuracy and F1-score on a 5-fold cross-validation on DS2. The rule from the decision tree is simple: the user would be labeled as having no depression when the distress score is less than 2, and the nervous score is less than 3 (on a 1-5 Likert Scale). We then applied this rule to DS1 to generate depression labels.\\n\\nPart 2: Sensor Data\\n\\nWe developed a mobile app using the AWARE Framework [5] that continuously collects location, phone usage (screen status), Bluetooth scans, and call logs. The app is compatible with both the iOS and Android platforms. Participants installed the app on smartphones and left it running in the background. In addition, we provided wearable Fitbits to collect their physical activities and sleep.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"behaviors. The mobile app and wearable passively collected sensor data during the study. The average number of days per person per year is $77.5 \\\\pm 8.9$ among the four datasets.\\n\\nWe release four datasets, named INS-W_1, INS-W_2, INS-W_3, and INS-W_4. A dataset has three folders. We provided an overview description below. Please refer to our GitHub README page for more details.\\n\\n- **SurveyData**: a list of files containing participants' survey responses, including pre/post long surveys and weekly short EMA surveys.\\n- **FeatureData**: behavior feature vectors from all data types, using RAPIDS [2] as the feature extraction tool.\\n- **ParticipantInfoData**: some additional information about participants, e.g., device platform (iOS or Android).\\n\\nSpecifically, the folder structure of a dataset folder is shown as follows:\\n\\n- **SurveyData**\\n  - dep_weekly.csv\\n  - dep_endterm.csv\\n  - pre.csv\\n  - post.csv\\n  - ema.csv\\n\\n- **FeatureData**\\n  - rapids.csv\\n  - location.csv\\n  - screen.csv\\n  - call.csv\\n  - bluetooth.csv\\n  - steps.csv\\n  - sleep.csv\\n  - wifi.csv\\n\\n- **ParticipantInfoData**\\n  - platform.csv\\n\\nThe SurveyData folder contains five files, all indexed by pid and date:\\n\\n- **dep_weekly.csv**: The specific file for depression labels (column dep) combining post and EMA surveys. We also have PHQ4 sub-scales as column dep_weekly_subscale for the depression sub-scale and anx_weekly_subscale for the anxiety sub-scale. Moreover, we have another column merging post and PHQ-4 depression sub-scale at dep_weeklysubscale_endterm_merged.\\n\\n- **dep_endterm.csv**: The specific file for depression labels (column dep) only in post surveys. Some prior depression detection tasks focus on end-of-term depression prediction.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"These two files are created for depression as it is the benchmark task. We envision future work can be extended to other modeling targets as well.\\n\\n- **pre.csv**: The file contains all questionnaires that participants filled in right before the start of the data collection study (thus pre-study).\\n- **post.csv**: The file contains all questionnaires that participants filled in right after the end of the data collection study (thus post-study).\\n- **ema.csv**: The file contains all EMA surveys that participants filled in during the study. Some EMAs were delivered on Wednesdays, while some were delivered on Sundays.\\n\\nPS: Due to the design iteration, some questionnaires are not available in all studies. Moreover, some questionnaires have different versions across years. We clarify them using column names. For example, `INS-W_2` only has `CESD_9items_POST`, while others have `CESD_10items_POST`.\\n\\n`CESD_9items_POST` is also calculated in other datasets to make the modeling target comparable across datasets.\\n\\nThe **FeatureData** folder contains seven files, all indexed by `pid` and `date`.\\n\\n- **rapids.csv**: The complete feature file that contains all features.\\n- **location.csv**: The feature file that contains all location features.\\n- **screen.csv**: The feature file that contains all phone usage features.\\n- **call.csv**: The feature file that contains all call features.\\n- **bluetooth.csv**: The feature file that contains all Bluetooth features.\\n- **steps.csv**: The feature file that contains all physical activity features.\\n- **sleep.csv**: The feature file that contains all sleep features.\\n- **wifi.csv**: The feature file that contains all WiFi features. Note that this feature type is not used by any existing algorithms and often has a high data missing rate.\\n\\nPlease note that all features are extracted with multiple time segments:\\n\\n- morning (6 am - 12 pm, calculated daily)\\n- afternoon (12 pm - 6 pm, calculated daily)\\n- evening (6 pm - 12 am, calculated daily)\\n- night (12 am - 6 am, calculated daily)\\n- allday (24 hrs from 12 am to 11:59 pm, calculated daily)\\n- 7-day history (calculated daily)\\n- 14-day history (calculated daily)\\n- weekdays (calculated once per week on Friday)\\n- weekend (calculated once per week on Sunday)\\n\\nFor all features with numeric values, we also provide two more versions:\\n\\n- normalized: subtracted by each participant's median and divided by the 5-95 quantile range\\n- discretized: low/medium/high split by 33/66 quantile of each participant's feature value\\n\\nThe **ParticipantInfoData** folder contains files with additional information.\\n\\n- **platform.csv**: The file contains each participant's major smartphone platform (iOS or Android), indexed by `pid`.\\n- **demographics.csv**: Due to privacy concerns, demographic data are only available for special requests. Please reach out to us directly with a clear research plan with demographic data.\\n\\nUsage notes:\\n\\nWe provide a behavior modeling benchmark platform GLOBEM [1]. The platform is designed to support researchers in using, developing, and evaluating different longitudinal behavior modeling methods.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Researchers who use the datasets must agree to the following terms.\\n\\nCommercial use\\nThe database will not be used for non-academic research purposes. Non-academic purposes include but are not limited to:\\n\\n- proving the efficiency of commercial systems\\n- training or testing of commercial systems\\n- using screenshots of subjects from the dataset in advertisements\\n- selling data from the dataset\\n- creating military applications\\n- developing governmental systems used in public spaces\\n\\nDistribution\\nThe database will not be re-distributed, published, copied, or further disseminated in any way or form whatsoever, whether for profit or not. This includes further distributing, copying or disseminating to a different facility or organizational unit in the requesting university, organization, or company, with the exception of using small portions of data for the exclusive purpose of clarifying academic publications or presentations.\\n\\nPrivacy\\nAlthough the database has been anonymized, we cannot eliminate all potential risks of privacy information leakage. The PI of any research group access to the dataset, is responsible for continuing to safeguard this database, taking whatever steps are appropriate to protect participants' privacy and data confidentiality. The specific actions required to safeguard the data may change over time.\\n\\nMisuse\\nIf at any point, the administrators of the datasets at the University of Washington have concerns or reasonable suspicions that the researcher has violated these usage note, the researcher will be notified. Concerns about misuse may be shared with PhysioNet and other related entities.\\n\\nOur datasets have led to multiple publications:\\n\\n- Sefidgar YS, Seo W, Kuehn KS, Althoff T, Browning A, Riskin E, Nurius PS, Dey AK, Mankoff J. Passively-sensed behavioral correlates of discrimination events in college students. Proceedings of the ACM on human-computer interaction. 2019 Nov 7;3(CSCW):1-29.\\n- Zhang H, Nurius P, Sefidgar Y, Morris M, Balasubramanian S, Brown J, Dey AK, Kuehn K, Riskin E, Xu X, Mankoff J. How does COVID-19 impact students with disabilities/health concerns?. arXiv preprint arXiv:2005.05438. 2020 May 11.\\n- Xu X, Chikersal P, Dutcher JM, Sefidgar YS, Seo W, Tumminia MJ, Villalba DK, Cohen S, Creswell KG, Creswell JD, Doryab A. Leveraging Collaborative-Filtering for Personalized Behavior Modeling: A Case Study of Depression Detection among College Students. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. 2021 Mar 29;5(1):1-27.\\n- Nurius PS, Sefidgar YS, Kuehn KS, Jung J, Zhang H, Figueira O, Riskin EA, Dey AK, Mankoff JC. Distress among undergraduates: Marginality, stressors and resilience resources. Journal of American college health. 2021 May 30:1-9.\\n- Morris ME, Kuehn KS, Brown J, Nurius PS, Zhang H, Sefidgar YS, Xu X, Riskin EA, Dey AK, Consolvo S, Mankoff JC. College from home during COVID-19: A mixed-methods study of heterogeneous experiences. PloS one. 2021 Jun 28;16(6):e0251580.\\n- Sefidgar YS, Nurius PS, Baughan A, Elkin LA, Dey AK, Riskin E, Mankoff J, Morris ME. Examining Needs and Opportunities for Supporting Students Who Experience Discrimination. arXiv preprint arXiv:2111.13266. 2021 Nov 25.\\n- Xu X, Mankoff J, Dey AK. Understanding practices and needs of researchers in human state modeling by passive mobile sensing. CCF Transactions on Pervasive Computing and Interaction. 2021 Dec;3(4):344-66.\\n\\nThere are a few known limitations in these datasets:\\n\\n- Limited study population: Only a portion of students who received our emails or social media posts would participate in our study, which could only represent a subset of the general population.\\n- High data missing rate: Missing data is inevitable due to various reasons, such as low battery, data transfer loss, and sensor permission withdrawal. Survey data can also be missing sometimes due to the lack of compliance.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our datasets aim at aiding research efforts in the area of developing, testing, and evaluating machine learning algorithms to better understand college students' (and potentially more general population) daily behaviors, health, and well-being from continuous sensor streams and self-reports. These findings may support public interest in how to improve student experiences and drive policy around adverse events students and others may experience.\\n\\nPrivacy is the major ethical concern of our data collection studies. We strictly follow the IRB rules to anonymize participants' data. Anyone outside our core data collection group cannot access direct individually-identifiable information. We also eliminated the data for users who stopped their participation at any time during the study. Since some sensitive sensor data (e.g., location) can disclose identities, we only release feature-level data under credentialing to protect against privacy leakage.\\n\\nData collected from human subjects:\\nThe study protocol was approved by relevant Institutional Review Boards (IRBs). Human participants signed a consent form before participating in the study.\\n\\nClinical trial data:\\nN/A\\n\\nData collected from animals:\\nN/A\\n\\nAcknowledgments:\\nOur multi-year data collection study closely followed a sister study at Carnegie Mellon University (CMU). We acknowledge all efforts from CMU Study Team to provide important starting and reference materials [4]. Moreover, our studies were greatly inspired by StudentLife researchers from Dartmouth College [3].\\n\\nOur studies were supported by the University of Washington (including the Paul G. Allen School of Computer Science and Engineering; Department of Electrical and Computer Engineering; Population Health; Addictions, Drug and Alcohol Institute; and the Center for Research and Education on Accessible Technology and Experiences); the National Science Foundation (EDA-2009977, CHS-2016365, CHS-1941537, IIS1816687 and IIS7974751), the National Institute on Disability, Independent Living and Rehabilitation Research (90DPGE0003-01), Samsung Research America, and Google\\n\\nConflicts of interest:\\nThe author(s) have no conflicts of interest to declare.\\n\\nVersion:\\n1.0.0\\n\\nReferences & Weblinks:\\n[1] Benchmark Platform GLOBEM. github.com/UW-EXP/GLOBEM\\n[2] Rapids documentation. https://www.rapids.science/1.6/.\\n[3] Studentlife study https://studentlife.cs.dartmouth.edu/, 2014.\\n[4] A. Doryab, D. K. Villalba, P. Chikersal, J. M. Dutcher, M. Tumminia, X. Liu, S. Cohen, K. Creswell, J. Mankoff, J. D. Creswell, et al. Identifying behavioral phenotypes of loneliness and social isolation with passive sensing: statistical analysis, data mining and machine learning of smartphone and fitbit data. JMIR mHealth and uHealth, 7(7):e13209, 2019.\\n[5] D. Ferreira, V . Kostakos, and A. K. Dey. Aware: Mobile context instrumentation framework. Frontiers in ICT, 2:6, 2015.\\n[6] R. Godahewa, C. Bergmeir, G. I. Webb, R. J. Hyndman, and P. Montero-Manso. Monash time series forecasting archive. In Neural Information Processing Systems Track on Datasets and Benchmarks, 2021.\\n[7] N. D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury, and A. T. Campbell. A survey of mobile phone sensing. IEEE Communications Magazine, 48(9), 2010.\\n[8] S. M. Mattingly, J. M. Gregg, P. Audia, A. E. Bayraktaroglu, A. T. Campbell, N. V . Chawla, V . Das Swain, M. De Choudhury, S. K. D'Mello, A. K. Dey, et al. The tesserae project: Large-scale, longitudinal, in-situ, multimodal sensing of information workers. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, pages 1\u20138, 2019.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"J.-K. Min, A. Doryab, J. Wiese, S. Amini, J. Zimmerman, and J. I. Hong. Toss \\\"n\\\" turn: Smartphone as sleep\\nand sleep quality detector. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,\\nCHI '14, page 477\u2013486, New York, NY, USA, 2014. Association for Computing Machinery.\\n\\nM. E. Morris, Q. Kathawala, T. K. Leen, E. E. Gorenstein, F. Guilak, W. DeLeeuw, and M. Labhard. Mobile\\ntherapy: case study evaluations of a cell phone application for emotional self-awareness. Journal of medical\\nInternet research, 12(2):e10, 2010.\\n\\nR. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev, and A. T. Campbell.\\nStudentlife: Assessing mental health, academic performance and behavioral trends of college students using\\nsmartphones. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous\\nComputing, pages 3\u201314. ACM, 2014.\\n\\nR. Wang, G. Harari, P. Hao, X. Zhou, and A. T. Campbell. Smartgpa: how smartphones can assess\\nand predict academic performance of college students. In Proceedings of the 2015 ACM international joint\\nconference on pervasive and ubiquitous computing, pages 295\u2013306, 2015.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"X. Yue, Y. Zhang, S. Zhao, A. Sangiovanni-Vincentelli, K. Keutzer, and B. Gong. Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2100\u20132110, 2019.\\n\\nH. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz. mixup: Beyond Empirical Risk Minimization. arXiv:1710.09412 [cs, stat], Apr. 2018. arXiv: 1710.09412.\\n\\nH. Zhang, M. E. Morris, P. S. Nurius, K. Mack, J. Brown, K. S. Kuehn, Y. S. Sefidgar, X. Xu, E. A. Riskin, A. K. Dey, and J. Mankoff. Impact of Online Learning in the Context of COVID-19 on Undergraduates with Disabilities and Mental Health Concerns. ACM Transactions on Accessible Computing, page 3538514, July 2022.\\n\\nH. Zhang, P. Nurius, Y. Sefidgar, M. Morris, S. Balasubramanian, J. Brown, A. K. Dey, K. Kuehn, E. Riskin, X. Xu, and J. Mankoff. How Does COVID-19 impact Students with Disabilities/Health Concerns? In arXiv. arXiv, May 2021. arXiv:2005.05438 [cs].\\n\\nS. Zhang, Y. Li, S. Zhang, F. Shahabi, S. Xia, Y. Deng, and N. Alshurafa. Deep learning in human activity recognition with wearable sensors: A review on advances. Sensors, 22(4):1476, 2022.\\n\\nK. Zhou, Z. Liu, Y. Qiao, T. Xiang, and C. C. Loy. Domain Generalization in Vision: A Survey. arXiv:2103.02503 [cs], July 2021. arXiv: 2103.02503.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Checklist\\n\\n1. For all authors...\\n   (a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\\n   (b) Did you describe the limitations of your work? [Yes] See Sec.6\\n   (c) Did you discuss any potential negative societal impacts of your work? [Yes] See Sec.6\\n   (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] See Sec.6\\n\\n2. If you are including theoretical results...\\n   (a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n   (b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n   (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] See Sec.1\\n   (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] See Sec.5.3 and S.B.2\\n   (c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes] See Tab.2\\n   (d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] See S.B.2.3\\n\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n   (a) If your work uses existing assets, did you cite the creators? [N/A]\\n   (b) Did you mention the license of the assets? [N/A]\\n   (c) Did you include any new assets either in the supplemental material or as a URL? [N/A]\\n   (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A]\\n   (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n   (a) Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes] See S.A.1\\n   (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [Yes] See S.A.1\\n   (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Yes] Our compensation is not billed hourly, but for the whole study. See Sec.3.1\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"A.1 Study Documents\\n\\nWe provide a few important documents used in our data collection studies. Please find these files in the supplementary folder:\\n\\n1. University IRB Approval Letter: The letter from University IRB to approve our studies.\\n2. Consent Form: The form to be signed by participants before joining the study.\\n3. Compensation Structure: Participants will earn up to $245 based on their participation compliance.\\n4. Participant instruction (iOS version, and Android version): Slide decks to guide participants through the app installation and Fitbit setup during the on-boarding.\\n\\nA.2 Study Demographics\\n\\n| Dataset | Total | Gender | Generation | Disability | Race                |\\n|---------|-------|--------|------------|------------|---------------------|\\n| Year1   | 155   | F 107  | M 48       | 5          | A 82, B 5, H 9, N 4, PI 3, W 50, A&PI 2 |\\n| Year2   | 218   | F 111  | M 107      | 21         | A 102, B 6, H 10, N 2, PI 1, W 70, A&B 1, A&W 6, B&H&W 1, H&W 2, B&W 2, A&H&W 1, B&H&W 1, H&N&W 1, NA 3 |\\n| Year3   | 137   | F 75   | M 61, NB 1 | 22         | A 74, B 3, H 8, PI 3, W 40, A&W 6, B&H&W 1, NA 2 |\\n| Year4   | 195   | F 122  | M 67, NB 6 | 16         | A 104, B 4, H 18, N 1, PI 2, W 48, A&W 13, H&W 2, NA 3 |\\n\\n| Year1 and 2 | Total | Gender | Generation | Disability | Race                |\\n|--------------|-------|--------|------------|------------|---------------------|\\n| Year3        | 195   | F 122  | M 67, NB 6 | 16         | A 104, B 4, H 18, N 1, PI 2, W 48, A&W 13, H&W 2, NA 3 |\\n| Year4        | 195   | F 122  | M 67, NB 6 | 16         | A 104, B 4, H 18, N 1, PI 2, W 48, A&W 13, H&W 2, NA 3 |\\n\\nSurvey\\n\\n- Pre/post: UCLA, SocialFit, 2-Way SSS, PSS, ERQ, BRS, CHIPS, STAI, CES-D, BDI2, MAAS, BFI10, Brief-COPE, GQ, FSPWB, EDS, CEDH, B-Y AACQ\\n- Weekly EMA: PHQ-4, PSS-4, PANAS\\n\\nDepression\\n\\n- Weekly: Depression & Affect (45.5%)\\n  - End-term: BDI-II (35.4%)\\n- Weekly: PHQ-4 (52.1%)\\n  - End-term: BDI-II (42.9%)\\n- Weekly: PHQ-4 (46.9%)\\n  - End-term: BDI-II (40.7%)\\n- Weekly: PHQ-4 (45.0%)\\n  - End-term: BDI-II (40.2%)\\n\\nSensor\\n\\n- Smartphone: Location, Phone Usage, Call, Bluetooth\\n- Wearable: Physical Activity, Sleep\\n\\nA.3 Study Hardware and Setup\\n\\nFigure 7: App Screenshot\\n\\nOur smartphone data collection app is compatible with both iOS and Android platforms. Therefore, we did not have limits on participants' devices. Before each year's study, we tested our app on multiple smartphone brands to ensure its compatibility, robustness, and data collection quality. However, problems such as smartphone battery drain, software crashes, and data uploading error are inevitable during the study. Thus, we developed a study dashboard to monitor the condition of data collection during the study, and our study team would reach out to help participants solve software or hardware issues when necessary.\\n\\nFigure 7 presents a screenshot of the app. The interface is consistent on both platforms. Users can click 1) the \u201cSave\u201d button to manually trigger data uploading, 2) the \u201cOpen Survey\u201d button to manually enter the survey if that's within designated time windows, (note that participants usually received EMAs through notifications), and 3) the \u201cRefresh Fitbit Token\u201d for Fitbit data access update.\\n\\nAs for wearables, we used two models of Fitbit (Flex2 for Year 1&2 and Inspire2 for Year 3&4). Both models support reliable physical activity and sleep behavior tracking, but not others (e.g., heart rate tracking). Our internal team also tested and compared the two Fitbit models' tracking accuracy and did not observe significant difference.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A.4 Study Intrinsic Bias\\n\\nWe discuss some potential intrinsic bias in our datasets. For example:\\n\\n1. Recruitment Bias: Only a portion of students who received our emails or social media posts would participate in our study, which could only represent a subset of the general population.\\n\\n2. Gender Group Bias: Our studies intentionally over-sample females, which could involve bias towards the female group.\\n\\n3. Generation Group Bias: Our studies intentionally over-sample immigrants and first-generation participants, which could involve bias against other generation groups.\\n\\n4. Racial Group Bias: Asian and White are two dominant racial groups in our studies, while other racial groups are less represented. This could introduce racial bias.\\n\\n5. Health Group Bias: Some health conditions would impact participants' compliance. For example, participants with severe depressive symptoms may stop responding to surveys or even charging their phones, which would introduce bias into the missing data rate.\\n\\n6. Device Bias: Although our data collection app is compatible with both iOS and Android platforms, the differences between OS systems and smartphone models may introduce bias into the dataset.\\n\\nWe look forward to future exploration of these different aspects of intrinsic bias.\\n\\nA.5 Additional Correlation Analysis\\n\\nIn addition to identifying features that have a consistent correlation with the depression label across all years' datasets (see Figure 5), we are also interested in the features that have opposite correlation directions between pre-COVID and post-COVID periods. We followed a similar procedure as Sec. 4.2 to find features that have a consistent and significant correlation direction within two years (DS1&2, or DS3&4) but an opposite direction between pre- and post-COVID datasets. Figure 8 shows one representative feature from each data type.\\n\\n| Feature Type | Description |\\n|--------------|-------------|\\n| Call         | Min Duration of Incoming Calls |\\n| Activity     | Min Duration of Active Episodes in Morning |\\n| Sleep        | Std of Duration of Awake Episodes in Night |\\n| Location     | Circadian Routine Index over 2 weeks |\\n| Bluetooth    | Number of Most Frequent Not-Self Devices in Night |\\n| PhoneUsage   | Count of Unlock Episodes in Morning |\\n\\nThere are some interesting findings, especially when compared against Figure 5. For example, Figure 5 indicates that generally more frequent and longer smartphone usage is positively correlated with depression labels. However, in the morning time, this finding only holds before COVID. After the outbreak of COVID, frequent usage of a smartphone becomes negatively correlated with depression. This may be explained by the fact that the smartphone becomes a necessary tool for all kinds of daily routines when people are locked at home, which could overturn the correlation direction as participants with depression may tend to lose interest in general activities [8]. We look forward to more analysis and insights from future researchers.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 4: Description of Survey Scales\\n\\n| Scale Name & Abbreviation | Short Description | Scoring Range | Year Collection |\\n|---------------------------|-------------------|---------------|----------------|\\n| Time                      | UCLA [77]         | 10 - 40       | 1,2,3,4 pre, post |\\n|                           | Loneliness Scale   |               |                |\\n|                           | A 10-item scale measuring one's subjective feelings of loneliness as well as social isolation. Items 2, 6, 10, 11, 13, 14, 16, 18, 19, and 20 of the original scale are included in the short form. Higher values indicate more subjective loneliness. |               |                |\\n| Social Fit                | Sense of Social and Academic Fit Scale [92] | 17 - 119 | 2-Way SSS [80] |\\n|                           | A 17-item scale measuring the sense of social and academic fit of students at the institution where this study was conducted. Higher values indicate higher feelings of belongings. |               |                |\\n| PSS                       | Perceived Stress Scale [24] | 0 - 56 (Year 2,3,4) | 0 - 40 (Year 1) |\\n|                           | A 14-item scale used to assess stress levels during the last month. Note that Year 1 used the 10-item version. Higher values indicate more perceived stress. |               |                |\\n| ERQ                       | Emotion Regulation Questionnaire [45] | (a) 1 - 7 (b) 1 - 7 |                |\\n|                           | A 10-item scale assessing individual differences in the habitual use of two emotion regulation strategies: (a) cognitive reappraisal and (b) expressive suppression. Higher scores indicate more habitual use of reappraisal/suppression. |               |                |\\n| BRS                       | Brief Resilience Scale [81] | 1 - 5 |                |\\n|                           | A 6-item scale assessing the ability to bounce back or recover from stress. Higher scores indicate more resilient from stress. |               |                |\\n| CHIPS                     | Cohen-Hoberman Inventory of Physical Symptoms [23] | 0 - 132 |                |\\n|                           | A 33-item scale measuring the perceived burden from physical symptoms, and resulting psychological effect during the past 2 weeks. Higher values indicate more perceived burden from physical symptoms. |               |                |\\n| STAI                      | State-Trait Anxiety Inventory for Adults [13, 47] | 20 - 80 |                |\\n|                           | A 20-item scale measuring State-Trait anxiety. Year 1 used the State version, while other years used the Trait version. Higher values indicate higher anxiety. |               |                |\\n| CES-D                     | Center for Epidemiologic Studies Depression Scale Cole version [25, 74] | 0 - 30 (Year 1,3,4) | 0 - 27 (Year 2) |\\n|                           | A 10-item scale measuring current level of depressive symptomatology, with emphasis on the affective component, depressed mood. Year 2 used the 9-item version. Higher scores indicate more depressive symptoms. |               |                |\\n| BDI2                      | Beck Depression Inventory-II [11] | 0 - 63 |                |\\n|                           | A 21-item detect depressive symptoms. Higher values indicate more depressive symptoms. 0-13: minimal to none, 14-19: mild, 20-28: moderate and 26-63: severe. |               |                |\\n| MAAS                      | Mindful Attention Awareness Scale [16] | 1 - 6 | 1,2,3,4 pre |\\n|                           | A 15-item scale assessing a core characteristic of mindfulness. Year 1 used a 7-item version, while other years used the full version. Higher values indicate higher mindfulness. |               |                |\\n| BFI10                     | The Big-Five Inventory-10 [75] | 1 - 5 |                |\\n|                           | A 10-item scale measuring the Big Five personality traits Extroversion, Agreeableness, Conscientiousness, Emotional Stability, and Openness. The higher the score, the greater the tendency of the corresponding personality. |               |                |\\n| Brief-COPE                | Brief Coping Orientation to Problems Experienced [19] | (a): 0 - 3 (b): 0 - 3 | 2,3,4 pre, post |\\n|                           | A 28-item scale measuring (a) adaptive and (b) maladaptive ways to cope with a stressful life event. Higher values indicate more effective/ineffective ways to cope with a stressful life event. |               |                |\\n| GQ                        | Gratitude Questionnaire [64] | 6 - 42 |                |\\n|                           | A 6-item scale assessing individual differences in the proneness to experience gratitude in daily life. Higher scores indicate a greater tendency to experience gratitude. |               |                |\\n| FSPWB                     | Flourishing Scale and Psychological Well-Being Scale [28] | 8 - 56 |                |\\n|                           | An 8-item scale measuring the psychological well-being. Higher scores indicate a person with \\\"more psychological resources and mental strengths\\\". |               |                |\\n| EDS                       | Everyday Discrimination Scale [5, 100] | 0 - 45 |                |\\n|                           | A 9-item scale assessing everyday discrimination. Higher values indicate more frequent experience of discrimination. |               |                |\\n| CEDH                      | Chronic Work Discrimination and Harassment [14, 100] | 0 - 60 |                |\\n|                           | A 12-item scale assessing experiences of discrimination in educational settings. Higher values indicate more frequent experience of discrimination in the work environment. |               |                |\\n| B-Y AACQ                  | The Brief Young Adult Alcohol Consequences Questionnaire (optional) [48] | 0 - 24 |                |\\n|                           | A 24-item scale measuring the alcohol problem severity continuum in college students. Higher values indicates more severe alcohol problems. |               |                |\\n| PHQ-4                     | Patient Health Questionnaire 4 [6, 51] | (a): 0 - 12 (b): 0 - 6 (c): 0 - 6 | 2,3,4 Weekly EMA |\\n|                           | A 4-item scale assessing (a) mental health, (b) anxiety, and (c) depression. Higher values indicate higher risk of mental health, anxiety, and depression. |               |                |\\n| PANAS                     | Positive and Negative Affect Schedule [2, 99] | (a): 0 - 20 (b): 0 - 20 |                |\\n|                           | A 10-item scale measuring the level of (a) positive and (b) negative affects. Higher values indicates larger extent. |               |                |\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"A.7 Sensor Feature Details\\n\\nThe following tables list out specific features based on RAPIDS \\\\[88\\\\]. All features are extracted with multiple time segments: morning (6 am - 12 pm), afternoon (12 pm - 6 pm), evening (6 pm - 12 am), night (12 am - 6 am), allday, 7-day history, 14-day history, weekday, and weekend (the last two are calculated once a week). Moreover, all numeric features have two extra versions: 1) normalized (subtracted by each participant's median and divided by the 5-95 quantile range); 2) discretized (low/medium/high split by 33/66 quantile of each participant's feature value). We employ a specific naming format of all features:\\n\\n\\\\[ \\\\text{[feature_type]}:\\\\text{[feature_name]}[_{norm or NULL}]:\\\\text{[time_segment]} \\\\]\\n\\nTable 5: Description of Location Features. Texts taken from RAPIDS with courtesy. \u201cMissing\u201d column indicate the missing rate of the corresponding feature(s). The same below.\\n\\n| Feature Type | Feature Name       | Unit    | Missing | Description                                                                                                                                                                                                 |\\n|-------------|--------------------|---------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| Location    | hometime          | minutes | 23.2%   | Time at home. Time spent at home in minutes. Home is the most visited significant location between 8 pm and 8 am, including any pauses within a 200-meter radius.                                                      |\\n|             | disttravelled     | meters  | 23.2%   | Total distance traveled over a day (flights).                                                                                                                                                             |\\n|             | rog                | meters  | 23.2%   | The Radius of Gyration (rog) is a measure in meters of the area covered by a person over a day. A centroid is calculated to represent the location of the person, and the weights are proportional to the time spent in each place. |\\n|             | maxdiam            | meters  | 23.2%   | The maximum diameter is the largest distance between any two pauses.                                                                                                                                       |\\n|             | maxhomedist        | meters  | 23.2%   | The maximum distance from home in meters.                                                                                                                                                               |\\n|             | siglocsvisited     | locations | 23.2% | The number of significant locations visited during the day. Significant locations are computed using k-means clustering analysis. Iterating k from 1 to 200 stopping until the centroids of two significant locations are within 400 meters of one another. |\\n|             | avgflightlen       | meters  | 23.2%   | Mean length of all flights.                                                                                                                                                                             |\\n|             | stdflightlen       | meters  | 23.2%   | Standard deviation of the length of all flights.                                                                                                                                                         |\\n|             | avgflightdur       | seconds | 23.2%   | Mean duration of all flights.                                                                                                                                                                           |\\n|             | stdflightdur       | seconds | 23.2%   | The standard deviation of the duration of all flights.                                                                                                                                                  |\\n|             | probpause          | -       | 23.2%   | The fraction of a day spent in a pause (as opposed to a flight).                                                                                                                                         |\\n|             | siglocentropy      | nats    | 23.2%   | Shannon's entropy measurement is based on the proportion of time spent at each significant location visited during a day.                                                                               |\\n|             | circdnrtn          | -       | 23.2%   | A continuous metric quantifying a person's circadian routine that can take any value between 0 and 1, with 0 indicating a daily routine completely different from any other sensed days and 1 a routine the same as every other sensed day. |\\n|             | wkenddayrtn        | -       | 23.2%   | Same as circdnrtn but computed separately for weekends and weekdays.                                                                                                                                    |\\n|             | locationvariance   | meters\u00b2 | 14.5%   | The sum of the variances of the latitude and longitude columns.                                                                                                                                          |\\n|             | loglocationvariance| -       | 14.7%   | Log of the sum of the variances of the latitude and longitude columns.                                                                                                                                     |\\n|             | totaldistance      | meters  | 14.5%   | Total distance traveled in a time segment using the haversine formula.                                                                                                                                   |\\n|             | avgspeed           | km/hr   | 14.5%   | Average speed in a time segment considering only the instances labeled as Moving. This feature is 0 when the participant is stationary during a time segment.                                              |\\n|             | varspeed           | km/hr   | 14.5%   | Speed variance in a time segment considering only the instances labeled as Moving. This feature is 0 when the participant is stationary during a time segment.                                           |\\n|             | numberofsignificantplaces | places | 14.5% | Number of significant locations visited. It is calculated using the DBSCAN/OPTICS clustering algorithm which takes in EPS and MIN_SAMPLES as parameters to identify clusters. Each cluster is a significant place. |\\n|             | numberlocationtransitions | transitions | 14.5% | Number of movements between any two clusters in a time segment.                                                                                                                                          |\\n|             | radiusgyration     | meters  | 14.5%   | Quantifies the area covered by a participant.                                                                                                                                                           |\\n|             | timeattop1location | minutes | 14.5%   | Time spent at the most significant location.                                                                                                                                                            |\\n|             | timeattop2location | minutes | 14.5%   | Time spent at the 2nd most significant location.                                                                                                                                                       |\\n|             | timeattop3location | minutes | 14.5%   | Time spent at the 3rd most significant location.                                                                                                                                                       |\\n|             | movingtostaticratio | -       | 14.5%   | Ratio between stationary time and total location sensed time. A lat/long coordinate pair is labeled as stationary if its speed (distance/time) to the next coordinate pair is less than 1km/hr. A higher value represents a more stationary routine. |\\n|             | outlierstimepercent | -       | 14.5%   | Ratio between the time spent in non-significant clusters divided by the time spent in all significant clusters. Only stationary samples are clustered. A higher value represents more time spent in non-significant clusters. |\\n|             | maxlengthstayatclusters | minutes | 14.5% | Maximum time spent in a cluster (significant location).                                                                                                                                                 |\\n|             | minlengthstayatclusters | minutes | 14.5% | Minimum time spent in a cluster (significant location).                                                                                                                                                 |\\n|             | avglengthstayatclusters | minutes | 14.5% | Average time spent in a cluster (significant location).                                                                                                                                                 |\\n|             | stdlengthstayatclusters | minutes | 14.5% | Standard deviation of time spent in a cluster (significant location).                                                                                                                                   |\\n|             | locationentropy    | nats    | 14.5%   | Shannon Entropy computed over the row count of each cluster (significant location), it is higher the more rows belong to a cluster (i.e., the more time a participant spent at a significant location). |\\n|             | normalizedlocationentropy | nats | 14.5% | Shannon Entropy computed over the row count of each cluster (significant location), it is higher the more rows belong to a cluster (i.e., the more time a participant spent at a significant location). |\\n|             | timeathome         | minutes | 14.5%   | Time spent at home.                                                                                                                                                                                    |\\n|             | timeat [PLACE]     | minutes | 14.5%   | Time spent at [PLACE], which can be living, exercise, study, greens.                                                                                                                                   |\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Feature Type | Feature Name | Unit | Percent | Description |\\n|--------------|--------------|------|---------|-------------|\\n| **Phone Usage** | sumduration | minutes | 14.4% | Total duration of all unlock episodes. |\\n| | maxduration | minutes | 14.4% | Longest duration of any unlock episode. |\\n| | minduration | minutes | 14.4% | Shortest duration of any unlock episode. |\\n| | avgduration | minutes | 14.4% | Average duration of all unlock episodes. |\\n| | stdduration | minutes | 14.8% | Standard deviation duration of all unlock episodes. |\\n| | countepisode | episodes | 14.4% | Number of all unlock episodes. |\\n| | firstuseafter | minutes | 14.4% | Minutes until the first unlock episode. |\\n\\n**Call**\\n\\n| Feature Name | Unit | Percent | Description |\\n|--------------|------|---------|-------------|\\n| count calls | | 51.6% | Number of calls of a particular call_type (either incoming or outgoing, same below) occurred during a particular time_segment. |\\n| distinctcontacts | | 51.6% | Number of distinct contacts that are associated with a particular call_type for a particular time_segment. |\\n| meanduration | seconds | 63.6% | The mean duration of all calls of a particular call_type during a particular time_segment. |\\n| sumduration | seconds | 63.6% | The sum of the duration of all calls of a particular call_type during a particular time_segment. |\\n| minduration | seconds | 63.6% | The duration of the shortest call of a particular call_type during a particular time_segment. |\\n| maxduration | seconds | 63.6% | The duration of the longest call of a particular call_type during a particular time_segment. |\\n| stdduration | seconds | 76.2% | The standard deviation of the duration of all the calls of a particular call_type during a particular time_segment. |\\n| modeduration | seconds | 63.6% | The mode of the duration of all the calls of a particular call_type during a particular time_segment. |\\n| entropyduration | nats | 65.9% | The estimate of the Shannon entropy for the the duration of all the calls of a particular call_type during a particular time_segment. |\\n| timefirstcall | minutes | 63.6% | The time in minutes between 12:00am (midnight) and the first call of call_type. |\\n| timelastcall | minutes | 63.6% | The time in minutes between 12:00am (midnight) and the last call of call_type. |\\n| countmostfrequentcontact | | 51.6% | The number of calls of a particular call_type during a particular time_segment of the most frequent contact throughout the monitored period. |\\n\\n**Bluetooth**\\n\\n| Feature Name | Unit | Percent | Description |\\n|--------------|------|---------|-------------|\\n| countscans | | 23.7% | Number of scans (rows) from the devices sensed during a time segment instance. The more scans a bluetooth device has the longer it remained within range of the participant's phone. |\\n| uniquedevices | | 23.7% | Number of unique bluetooth devices sensed during a time segment instance as identified by their hardware addresses (bt_address). |\\n| meanscans | | 23.7% | Mean of the scans of every sensed device within each time segment instance. |\\n| stdscans | | 35.1% | Standard deviation of the scans of every sensed device within each time segment instance. |\\n| countscansmostfrequentdevice | | 23.7% | Number of scans of the most sensed device within each time segment instance. |\\n| countscansleastfrequentdevice | | 23.7% | Number of scans of the least sensed device within each time segment instance. |\\n| countscansmostfrequentdevice | | 23.7% | Number of scans of the most sensed device across time segment instances of the same type. |\\n| countscansleastfrequentdevice | | 23.7% | Number of scans of the least sensed device across time segment instances of the same type per device. |\\n| countscansmostfrequentdevice | | 23.7% | Number of scans of the most sensed device across the entire dataset of every participant. |\\n| countscansleastfrequentdevice | | 23.7% | Number of scans of the least sensed device across the entire dataset of every participant. |\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 7: Description of Physical Activity and Sleep Features\\n\\n| Feature Type | Feature Name | Unit | Missing | Description |\\n|--------------|--------------|------|---------|-------------|\\n| PhysicalActivity | maxsumsteps | steps | 29.2% | The maximum daily step count during a time segment. |\\n|               | minsumsteps  | steps | 29.2% | The minimum daily step count during a time segment. |\\n|               | avgsumsteps  | steps | 29.2% | The average daily step count during a time segment. |\\n|               | mediansumsteps | steps | 29.2% | The median of daily step count during a time segment. |\\n|               | stdsumsteps  | steps | 29.2% | The standard deviation of daily step count during a time segment. |\\n|               | sumsteps     | steps | 29.3% | The total step count during a time segment. |\\n|               | maxsteps     | steps | 29.3% | The maximum step count during a time segment. |\\n|               | minsteps     | steps | 29.3% | The minimum step count during a time segment. |\\n|               | avgsteps     | steps | 29.3% | The average step count during a time segment. |\\n|               | countepisodesedentarybout | bouts | 29.3% | Number of sedentary bouts during a time segment. |\\n|               | sumdurationsedentarybout | minutes | 29.3% | Total duration of all sedentary bouts during a time segment. |\\n|               | maxdurationsedentarybout | minutes | 29.3% | The maximum duration of any sedentary bout during a time segment. |\\n|               | mindurationsedentarybout | minutes | 29.3% | The minimum duration of any sedentary bout during a time segment. |\\n|               | avgdurationsedentarybout | minutes | 29.3% | The average duration of sedentary bouts during a time segment. |\\n|               | stddurationsedentarybout | minutes | 29.3% | The standard deviation of the duration of sedentary bouts during a time segment. |\\n|               | countepisodeactivebout | bouts | 29.3% | Number of active bouts during a time segment. |\\n|               | sumdurationactivebout | minutes | 29.3% | Total duration of all active bouts during a time segment. |\\n|               | maxdurationactivebout | minutes | 29.3% | The maximum duration of any active bout during a time segment. |\\n|               | mindurationactivebout | minutes | 29.3% | The minimum duration of any active bout during a time segment. |\\n|               | avgdurationactivebout | minutes | 29.3% | The average duration of active bouts during a time segment. |\\n|               | stddurationactivebout | minutes | 29.3% | The standard deviation of the duration of active bouts during a time segment. |\\n| Sleep        | countepisode[LEVEL][TYPE] | episodes | 34.5% | Number of [LEVEL][TYPE] sleep episodes. [LEVEL] is one of awake and asleep and [TYPE] is one of main, nap, and all. Same below. |\\n|               | sumduration[LEVEL][TYPE] | minutes | 34.5% | Total duration of all [LEVEL][TYPE] sleep episodes. |\\n|               | maxduration[LEVEL][TYPE] | minutes | 34.5% | Longest duration of any [LEVEL][TYPE] sleep episode. |\\n|               | minduration[LEVEL][TYPE] | minutes | 34.5% | Shortest duration of any [LEVEL][TYPE] sleep episode. |\\n|               | avgduration[LEVEL][TYPE] | minutes | 34.5% | Average duration of all [LEVEL][TYPE] sleep episodes. |\\n|               | mediansduration[LEVEL][TYPE] | minutes | 34.5% | Median duration of all [LEVEL][TYPE] sleep episodes. |\\n|               | stdduration[LEVEL][TYPE] | minutes | 34.5% | Standard deviation duration of all [LEVEL][TYPE] sleep episodes. |\\n|               | firstwaketime[TYPE] | minutes | 36.4% | First wake time for a certain sleep type during a time segment. Wake time is number of minutes after midnight of a sleep episode's end time. |\\n|               | lastwaketime[TYPE] | minutes | 36.4% | Last wake time for a certain sleep type during a time segment. Wake time is number of minutes after midnight of a sleep episode's end time. |\\n|               | firstbedtime[TYPE] | minutes | 36.3% | First bedtime for a certain sleep type during a time segment. Bedtime is number of minutes after midnight of a sleep episode's start time. |\\n|               | lastbedtime[TYPE] | minutes | 36.3% | Last bedtime for a certain sleep type during a time segment. Bedtime is number of minutes after midnight of a sleep episode's start time. |\\n|               | countepisode[TYPE] | episodes | 34.5% | Number of sleep episodes for a certain sleep type during a time segment. |\\n|               | avgefficiency[TYPE] | scores | 36.3% | Average sleep efficiency for a certain sleep type during a time segment. |\\n|               | sumdurationafterwakeup[TYPE] | minutes | 35.6% | Total duration the user stayed in bed after waking up for a certain sleep type during a time segment. |\\n|               | sumdurationasleep[TYPE] | minutes | 34.5% | Total sleep duration for a certain sleep type during a time segment. |\\n|               | sumdurationawake[TYPE] | minutes | 34.5% | Total duration the user stayed awake but still in bed for a certain sleep type during a time segment. |\\n|               | sumdurationtofallasleep[TYPE] | minutes | 35.6% | Total duration the user spent to fall asleep for a certain sleep type during a time segment. |\\n|               | sumdurationinbed[TYPE] | minutes | 35.6% | Total duration the user stayed in bed (sumdurationtofallasleep + sumdurationawake + sumdurationasleep + sumdurationafterwakeup) for a certain sleep type during a time segment. |\\n|               | avgdurationafterwakeup[TYPE] | minutes | 35.6% | Average duration the user stayed in bed after waking up for a certain sleep type during a time segment. |\\n|               | avgdurationasleep[TYPE] | minutes | 34.5% | Average sleep duration for a certain sleep type during a time segment. |\\n|               | avgdurationawake[TYPE] | minutes | 34.5% | Average duration the user stayed awake but still in bed for a certain sleep type during a time segment. |\\n|               | avgdurationtofallasleep[TYPE] | minutes | 35.6% | Average duration the user spent to fall asleep for a certain sleep type during a time segment. |\\n|               | avgdurationinbed[TYPE] | minutes | 35.6% | Average duration the user stayed in bed (sumdurationtofallasleep + sumdurationawake + sumdurationasleep + sumdurationafterwakeup) for a certain sleep type during a time segment. |\\n\\nPS.1. It is worth noting that the missing rate of call-related features are high. This is mainly because most these features are event-based. If a participant did not receive a phone call at a day, that day will have empty call features.\\n\\nPS.2. One limitation of our physical activity and sleep feature data comes from a Fitbit issue: If the data on the wearable device is not synced with the smartphone over a few days, it would trigger some internal space-saving strategy to discard low-level details and only contain high-level summary data, leading to information loss and affecting feature correctness. This would be reflected by the missing features (e.g., small or missing countepisodeactivebout), which is not common in our datasets.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We provide a more detailed description of benchmark-related processing. Many texts are taken from [104] with courtesy.\\n\\n**B.1 Depression Detection Ground Truth Processing**\\n\\nDue to some design iteration, we did not include PHQ-4 in DS1, but only PANAS. Although PANAS contains questions related to depressive symptoms (e.g., \u201cdistressed\u201d), it does not have a comparable theoretical foundation for depression detection like PHQ-4 or BDI-II. Therefore, to maximize the compatibility of the datasets, we trained a small ML model on DS2 that has both PANAS and PHQ-4 scores to generate reliable ground truth labels. Specifically, we used a decision tree (depth=2) to take PNANS scores on two affect questions (\u201cdepressed\u201d and \u201cnervous\u201d) as the input and predict PHQ-4 score-based depression binary label. Our model achieved 74.5% and 76.3% for accuracy and F1-score on a 5-fold cross-validation on DS2. The rule from the decision tree is simple: the user would be labeled as having no depression when the distress score is less than 2, and the nervous score is less than 3 (on a 1-5 Likert Scale). We then applied this rule to DS1 to generate depression labels.\\n\\n**B.2 Behavior Modeling Algorithm Implementation Details**\\n\\nPlease refer to our GLOBEM codebase for the specific implementations and hyperparameter tuning.\\n\\n**B.2.1 Depression Detection Algorithms**\\n\\n1. **Canzian et al.** [18]\\n   - Features: Location trajectory features directly computed from the past two-week time window.\\n   - Model: A support vector machine (SVM).\\n\\n2. **Saeb et al.** [78]\\n   - Features: Location and screen features aggregated with daily average of the past two weeks.\\n   - Model: A logistic regression model with elastic regularization.\\n\\n3. **Farhan et al.** [33]\\n   - Features: Location and physical activity features from the past two-week window.\\n   - Model: An SVM.\\n\\n4. **Wahle et al.** [91]\\n   - Features: Several feature types (activity, location, WiFi, screen, and call) over the past two weeks. Both daily aggregation (i.e., mean, sum, variance) and direct computation of the features of the two weeks are used. WiFi features are excluded to ensure the compatibility with our datasets.\\n   - Model: SVM and Random Forest.\\n\\n5. **Lu et al.** [60]\\n   - Features: Location, activity, and sleep features computed from the past two weeks.\\n   - Model: Multi-task learning combining linear regression & logistic regression. One model for iOS and one for Android are built to deal with device platform differences.\\n\\n6. **Wang et al.** [97]\\n   - Features: Location, screen, activity, sleep, and audio features aggregated by calculating daily average and slope of the past two weeks. Audio features are excluded as they are not collected.\\n   - Model: A lasso-regularized logistic regression model.\\n\\n7. **Xu et al.-I (Interpretable)** [101]\\n   - Features: Location, screen, activity, and sleep features in multiple epochs of a day (morning, afternoon, evening, night). Association rule mining is applied to mine out interpretable behavior rules that capture differences between participants with depression and without depression. Then, the rules are used to filter and aggregate features of multiple days.\\n   - Model: An Adaboost model.\\n\\n8. **Xu et al.-P (Personalized)** [102]\\n   - Features: A similar set of basic features as [101]. With each feature as a time sequence, a user behavior relevance matrix is computed using the square of Pearson correlation to capture users with strong positive or negative correlation.\\n   - Model: A traditional collaborative-filtering-based model to select features and obtain an intermediate prediction using each feature, and combine the results of all features via majority voting.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Chikersal et al. [20] Features: A similar set of basic features as [101]. Aggregations (breakpoint and slope) across multiple time ranges (daily and biweekly) are calculated, followed by a nested randomized logistic regression for feature selection.\\n\\nModel: Separate gradient boosting and logistic regression models using data from every sensor, and combine the prediction with another Adaboost model to generate the final prediction. Each algorithm will lead to one model. All these models' hyperparameters are tuned via grid search with the same range as mentioned in each prior work.\\n\\nB.2.2 Domain Generalization Algorithms\\n\\nThe data format of all deep-learning based algorithm is the same: a subset of important daily features in the most recent traditional depression detection algorithms [20, 102], with the past-four-week feature matrix as the input. It is worth noting that we picked these deep learning techniques to cover the major approaches of domain generalization [94], including 1) data manipulation (Mixup), 2) representation learning (IRM, DANN, CSD), and 3) learning strategy (MLDG, MASF, Siamese, Reorder).\\n\\n1. **ERM (Empirical Risk Minimization) [87]**\\n   - The basic model training techniques without particular design for domain generalization. ERM shows a competitive performance in previous CV generalization tasks [46, 94]. Multiple architectures with ERM are implemented: a) ERM-1D-CNN: one-dimensional CNN that treats the data as a time-series of length 28; b) ERM-2D-CNN: two-dimensional CNN that treats the data as an one-channel image; c) ERM-LSTM: another architecture to model time-series data; d) ERM-Transformer: a transformer-based architecture for modeling sequence data.\\n\\n2. **Mixup (ERM-Mixup) [111]**\\n   - A data augmentation technique that performs linear interpolation between two instances with a weight sampled from a Beta distribution. 1D-CNN is used as the architecture as it is robust to feature positions in the feature matrix. Same for the rest algorithms.\\n\\n3. **IRM (Invariant Risk Minimization) [7]**\\n   - A representation learning paradigm to estimate invariant correlations across multiple distributions and learn a data representation such that the optimal classifier can match all training distributions.\\n\\n4. **DANN (Domain-Adversarial Neural Network) [38]**\\n   - Another representation learning technique that adversarially trains the generator and discriminator. The discriminator is trained to distinguish different domains, while the generator is trained to fool the discriminator to learn domain-invariant feature representations. Two setups are tested, one treating each dataset as a domain (DANN-D (Dataset as Domain)), and one treating each person as a domain (DANN-P (Person as Domain)).\\n\\n5. **CSD (Common Specific Decomposition) [72]**\\n   - A feature disentanglement-based representation learning technique from the multi-component analysis perspective, which extracts the domain-shared and domain-specific features using separate network parameters. Similar to DANN, it can support CSD-D and CSD-P.\\n\\n6. **MLDG (Meta-Learning for Domain Generalization) [56]**\\n   - One of the first methods using meta-learning strategy for domain generalization. MLDG splits the data of the training domains into meta-train and meta-test to simulate the domain shift to learn general features. It supports MLDG-D and MLDG-P.\\n\\n7. **MASF (Model-Agnostic Learning of Semantic Features) [30]**\\n   - A learning strategy that combines meta-learning and feature disentanglement. After simulating domain shift by domain split, MASF further regularizes the semantic structure of the feature space by introducing a global loss (to preserve relationships between classes) and a local loss (to promote domain-independent class clustering). It supports MASF-D and MASF-P.\\n\\n8. **Siamese Network [49]**\\n   - A metric-learning based strategy to find a better pair-wise distance metric. It aims to decrease the distance between positive pairs and increase the distance between negative pairs.\\n\\n9. **Reorder [104]**\\n   - A recently proposed method to leverage the continuity of behavior trajectory [104]. It designed a pretext task which shuffles the temporal order of the feature matrix. Then a model is trained to reconstruct the original sequence, jointly optimized with the main classification task over different\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"domains, as shown in Fig. 9. By capturing the continuity of daily behaviors, the model could learn to extract representations that are generalizable across individuals. Overall, the model can be trained via the following objective function:\\n\\n$$\\\\arg\\\\min_{\\\\theta} f(\\\\theta), c(\\\\theta), r(\\\\theta)$$\\n\\n$$\\\\sum_{i=1}^{S} \\\\left[ \\\\sum_{j=1}^{N_i} L_c(h(x_i^j|\\\\theta_f, \\\\theta_c), y_i^j) + \\\\beta \\\\sum_{j=1}^{N_i} \\\\alpha L_r(h(z_i^j|\\\\theta_f, \\\\theta_r), p_i^j) \\\\right]$$\\n\\nwhere both $L_c$ and $L_r$ are cross-entropy losses. $S$ is the total number of training domains, and $N_i$ is the size of a domain $i$. $\\\\alpha$ is used to control the weight of the reordering task while $\\\\beta$ is used to control the size of reordering data.\\n\\n$x$ is the input matrix, $y$ is the classification label, $z$ is the feature matrix after the reordering, and $p$ is the permutation index (from 1 to 200 among the 200 pre-determined permutation set). $x_i^j$, $y_i^j$, $z_i^j$, $p_i^j$ are specific instances in each domain $i$ with index $j$. We picked the number of segmentation as $n = 10 (\\\\lceil \\\\frac{28}{3} \\\\rceil)$ since $28!$ or $14! (\\\\frac{28}{2})$ is too computationally expensive.\\n\\nFigure 9: The Design of Reorder Compared to ERM (taken from [104] with courtesy).\\n\\nOne algorithm could lead to one or multiple models. Models from No. 2 to No. 9 all use the same 1D-CNN as the backbone. We use a simple architecture based on a small-range tuning using ERM-1D-CNN. It has 3 1D-convolution layers (size 8, stride 3, ReLU activation), each followed by a batch normalization layer, a max-pooling layer, as well as a dropout layer (rate 0.25). We tested with different layer sizes (8, 16, 32) and depth (3, 5, 7), and observed similar results, thus we chose size as 8 and depth as 3 to save computing cost. A fully connected layer (size 16) was attached after flattening the third convolution layer's output to convert it into a vector of length 16. The following layers are customized for each model.\\n\\nOther architectures are also simple: ERM-2D-CNN used three 2D-convolution layers with the same size, stride, and activation function as 1D-CNN; ERM-LSTM used two bi-directional layers with the hidden size as 20; ERM-Transformer used two transformer blocks, each with 4 self-attention heads (size 4) and a 1D-convolutional feed forward layer (size 16).\\n\\nFor all models, we adopted a common training setup. Specifically, we used Adam as the optimizer and adopted a cosine annealing schedule, with an initial learning rate of 0.001, an annealing decay of 0.95, and a step size of 100.\\n\\nB.2.3 Training Resources\\n\\nSince all deep learning models are small, we only used CPU for the model training. We leveraged a university computing cluster (300 CPUs) with the SLURM Workload Manager. The whole training was completed within 48 hours.\\n\\nB.3 Additional Generalization Results\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 8: Model Performance of Depression Detection in Single Dataset.\\n\\n| Category          | Model                    | Balanced Accuracy | ROC AUC |\\n|-------------------|--------------------------|-------------------|---------|\\n|                   | DS1 | DS2 | DS3 | DS4 Avg | DS1 | DS2 | DS3 | DS4 Avg |\\n| Baseline          | Majority                 | 0.500             | 0.500   | 0.500   | 0.500   | 0.500   | 0.500   | 0.500   |\\n| Prior Depression  | Canzian et al. [18]      | 0.500             | 0.500   | 0.608   | 0.536   | 0.536   | 0.597   | 0.514   | 0.626   | 0.607   | 0.586   |\\n|                   | Saeb et al. [78]         | 0.526             | 0.533   | 0.613   | 0.557   | 0.557   | 0.555   | 0.581   | 0.641   | 0.614   | 0.598   |\\n|                   | Farhan et al. [33]       | 0.554             | 0.509   | 0.604   | 0.582   | 0.562   | 0.575   | 0.554   | 0.665   | 0.618   | 0.603   |\\n|                   | Wahle et al. [91]        | 0.584             | 0.548   | 0.632   | 0.628   | 0.598   | 0.611   | 0.568   | 0.665   | 0.702   | 0.637   |\\n|                   | Lu et al. [60]           | 0.529             | 0.496   | 0.604   | 0.569   | 0.550   | 0.530   | 0.499   | 0.674   | 0.599   | 0.576   |\\n|                   | Wang et al. [97]         | 0.548             | 0.500   | 0.494   | 0.578   | 0.530   | 0.610   | 0.500   | 0.491   | 0.653   | 0.564   |\\n|                   | Xu et al. [101]          | **0.669**         | 0.655   | 0.731   | 0.710   | 0.691   | 0.699   | 0.706   | 0.759   | 0.786   | 0.737   |\\n|                   | Xu et al. [102]          | **0.591**         | 0.612   | 0.611   | 0.584   | 0.600   | 0.632   | 0.637   | 0.621   | 0.632   | 0.630   |\\n|                   | Chikersal et al. [20]    | 0.656             | 0.611   | 0.641   | 0.690   | 0.649   | 0.726   | 0.679   | 0.695   | 0.763   | 0.716   |\\n| Recent Domain     | ERM-1dCNN [87]           | 0.579             | 0.556   | 0.578   | 0.560   | 0.568   | 0.608   | 0.558   | 0.599   | 0.618   | 0.596   |\\n|                   | ERM-2dCNN [87]           | 0.506             | 0.535   | 0.524   | 0.567   | 0.533   | 0.541   | 0.530   | 0.530   | 0.575   | 0.544   |\\n|                   | ERM-LSTM [87]            | 0.579             | 0.554   | 0.519   | 0.607   | 0.565   | 0.583   | 0.573   | 0.529   | 0.630   | 0.579   |\\n|                   | ERM-Transformer [87]     | 0.574             | 0.619   | 0.556   | 0.586   | 0.584   | 0.604   | 0.636   | 0.557   | 0.612   | 0.602   |\\n|                   | ERM-Mixup [111]          | 0.579             | 0.556   | 0.578   | 0.560   | 0.568   | 0.608   | 0.558   | 0.599   | 0.618   | 0.596   |\\n|                   | IRM [7]                  | 0.571             | 0.529   | 0.595   | 0.599   | 0.573   | 0.607   | 0.568   | 0.642   | 0.650   | 0.617   |\\n|                   | DANN-D [39]              | 0.564             | 0.511   | 0.489   | 0.538   | 0.526   | 0.557   | 0.502   | 0.487   | 0.575   | 0.530   |\\n|                   | DANN-P [39]              | 0.508             | 0.500   | 0.500   | 0.500   | 0.502   | 0.523   | 0.490   | 0.563   | 0.552   | 0.532   |\\n|                   | CSD-D [72]               | 0.591             | 0.502   | 0.596   | 0.557   | 0.562   | 0.601   | 0.536   | 0.612   | 0.631   | 0.595   |\\n|                   | CSD-P [72]               | 0.550             | 0.513   | 0.544   | 0.559   | 0.542   | 0.581   | 0.505   | 0.568   | 0.613   | 0.567   |\\n|                   | MLDG-D [56]              | 0.550             | 0.539   | 0.495   | 0.504   | 0.522   | 0.573   | 0.515   | 0.520   | 0.507   | 0.529   |\\n|                   | MLDG-P [56]              | 0.529             | 0.517   | 0.478   | 0.507   | 0.508   | 0.554   | 0.499   | 0.473   | 0.523   | 0.512   |\\n|                   | MASF-D [30]              | 0.489             | 0.518   | 0.505   | 0.506   | 0.505   | 0.509   | 0.531   | 0.492   | 0.541   | 0.518   |\\n|                   | MASF-P [30]              | 0.486             | 0.492   | 0.487   | 0.515   | 0.495   | 0.503   | 0.502   | 0.501   | 0.514   | 0.505   |\\n|                   | Siamese Network [49]     | 0.570             | 0.481   | 0.533   | 0.596   | 0.545   | 0.570   | 0.481   | 0.533   | 0.596   | 0.545   |\\n|                   | Reorder [104]            | 0.616             | 0.606   | 0.639   | 0.644   | 0.626   | 0.657   | 0.619   | 0.671   | 0.692   | 0.660   |\\n\\n### Table 9: Model Performance of Depression Detection with Leave-One-Dataset-Out Setup.\\n\\n| Category          | Model                    | Balanced Accuracy | ROC AUC |\\n|-------------------|--------------------------|-------------------|---------|\\n|                   | DS1 | DS2 | DS3 | DS4 Avg | DS1 | DS2 | DS3 | DS4 Avg |\\n| Baseline          | Majority                 | 0.500             | 0.500   | 0.500   | 0.500   | 0.500   | 0.500   | 0.500   |\\n| Prior Depression  | Canzian et al. [18]      | 0.480             | 0.504   | 0.506   | 0.501   | 0.498   | 0.491   | 0.484   | 0.542   | 0.499   |\\n|                   | Saeb et al. [78]         | 0.525             | 0.536   | 0.523   | 0.558   | 0.536   | 0.529   | 0.548   | 0.529   | 0.567   | 0.543   |\\n|                   | Farhan et al. [33]       | 0.505             | 0.497   | 0.496   | 0.525   | 0.506   | 0.505   | 0.550   | 0.515   | 0.553   | 0.531   |\\n|                   | Wahle et al. [91]        | 0.526             | 0.527   | 0.495   | 0.546   | 0.524   | 0.543   | 0.554   | 0.503   | 0.564   | 0.541   |\\n|                   | Lu et al. [60]           | 0.546             | 0.498   | 0.541   | 0.538   | 0.531   | 0.550   | 0.510   | 0.588   | 0.564   | 0.553   |\\n|                   | Wang et al. [97]         | 0.509             | 0.521   | 0.515   | 0.541   | 0.521   | 0.514   | 0.556   | 0.529   | 0.554   | 0.538   |\\n|                   | Xu et al. [101]          | 0.517             | 0.525   | 0.474   | 0.494   | 0.502   | 0.512   | 0.527   | 0.477   | 0.484   | 0.500   |\\n|                   | Xu et al. [102]          | 0.508             | 0.501   | 0.486   | 0.512   | 0.502   | 0.545   | 0.535   | 0.504   | 0.521   | 0.526   |\\n|                   | Chikersal et al. [20]    | 0.540             | 0.534   | 0.531   | 0.538   | 0.536   | 0.555   | 0.561   | 0.558   | 0.545   | 0.555   |\\n| Recent Domain     | ERM-1dCNN [87]           | 0.490             | 0.527   | 0.508   | 0.514   | 0.510   | 0.487   | 0.532   | 0.490   | 0.524   | 0.508   |\\n|                   | ERM-2dCNN [87]           | 0.511             | 0.495   | 0.507   | 0.525   | 0.510   | 0.514   | 0.499   | 0.509   | 0.534   | 0.514   |\\n|                   | ERM-LSTM [87]            | 0.514             | 0.519   | 0.494   | 0.522   | 0.512   | 0.521   | 0.525   | 0.480   | 0.528   | 0.514   |\\n|                   | ERM-Transformer [87]     | 0.492             | 0.506   | 0.531   | 0.507   | 0.509   | 0.499   | 0.513   | 0.526   | 0.510   | 0.512   |\\n|                   | ERM-Mixup [111]          | 0.498             | 0.524   | 0.493   | 0.489   | 0.501   | 0.506   | 0.538   | 0.498   | 0.495   | 0.509   |\\n|                   | IRM [7]                  | 0.492             | 0.519   | 0.511   | 0.503   | 0.506   | 0.500   | 0.533   | 0.521   | 0.517   | 0.518   |\\n|                   |"}
{"id": "GKOa7yNH8Uh", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 10: Model Performance of Repeated Depression Detection Using The Pre/Post-COVID Setup.\\n\\n| Category            | Model                  | Balanced Accuracy | ROC AUC | Avg Balanced Accuracy | Avg ROC AUC |\\n|---------------------|------------------------|-------------------|---------|-----------------------|-------------|\\n| Pre-COVID           | Baseline Majority      | 0.500             | 0.500   | 0.500                 | 0.500       |\\n|                     | Canzian et al.         | 0.495             | 0.500   | 0.497                 | 0.479       |\\n|                     | Saeb et al.            | 0.515             | 0.524   | 0.519                 | 0.519       |\\n|                     | Farhan et al.          | 0.481             | 0.519   | 0.500                 | 0.495       |\\n|                     | Wahle et al.           | 0.529             | 0.523   | 0.526                 | 0.531       |\\n|                     | Lu et al.              | 0.512             | 0.498   | 0.505                 | 0.527       |\\n|                     | Wang et al.            | 0.513             | 0.534   | 0.524                 | 0.536       |\\n|                     | Xu et al. -I           | 0.500             | 0.538   | 0.519                 | 0.479       |\\n|                     | Xu et al. -P           | 0.511             | 0.505   | 0.508                 | 0.533       |\\n|                     | Chikersal et al.       | 0.504             | 0.551   | 0.528                 | 0.514       |\\n| Recent Domain       | ERM-1dCNN              | 0.509             | 0.520   | 0.514                 | 0.516       |\\n|                     | ERM-2dCNN              | 0.510             | 0.498   | 0.504                 | 0.524       |\\n|                     | ERM-LSTM               | 0.515             | 0.510   | 0.512                 | 0.515       |\\n|                     | ERM-Transformer        | 0.496             | 0.528   | 0.512                 | 0.498       |\\n|                     | ERM-Mixup              | 0.503             | 0.511   | 0.507                 | 0.498       |\\n|                     | IRM                    | 0.499             | 0.498   | 0.499                 | 0.501       |\\n|                     | DANN-D                 | 0.514             | 0.513   | 0.514                 | 0.530       |\\n|                     | DANN-P                 | 0.500             | 0.500   | 0.500                 | 0.490       |\\n|                     | CSD-D                  | 0.506             | 0.518   | 0.512                 | 0.511       |\\n|                     | CSD-P                  | 0.516             | 0.515   | 0.516                 | 0.520       |\\n|                     | MLDG-D                 | 0.491             | 0.499   | 0.495                 | 0.505       |\\n|                     | MLDG-P                 | 0.503             | 0.497   | 0.500                 | 0.508       |\\n|                     | MASF-D                 | 0.496             | 0.511   | 0.504                 | 0.498       |\\n|                     | MASF-P                 | 0.498             | 0.519   | 0.509                 | 0.525       |\\n|                     | Siamese Network        | 0.513             | 0.518   | 0.515                 | 0.513       |\\n|                     | Reorder                | 0.523             | 0.528   | 0.525                 | 0.536       |\\n\\n### Table 11: Model Performance of Repeated Depression Detection Using Overlapping Participants, using users in one dataset as the train set and the overlapping users in other datasets as the test set.\\n\\n| Category            | Model                  | Balanced Accuracy | ROC AUC | Avg Balanced Accuracy | Avg ROC AUC |\\n|---------------------|------------------------|-------------------|---------|-----------------------|-------------|\\n| DS1                 | Baseline Majority      | 0.500             | 0.500   | 0.500                 | 0.500       |\\n|                     | Canzian et al.         | 0.571             | 0.500   | 0.494                 | 0.420       |\\n|                     | Saeb et al.            | 0.626             | 0.624   | 0.463                 | 0.547       |\\n|                     | Farhan et al.          | 0.460             | 0.500   | 0.455                 | 0.503       |\\n|                     | Wahle et al.           | 0.536             | 0.500   | 0.479                 | 0.532       |\\n|                     | Lu et al.              | 0.518             | 0.467   | 0.482                 | 0.567       |\\n|                     | Wang et al.            | 0.603             | 0.500   | 0.475                 | 0.548       |\\n|                     | Xu et al. -I           | 0.531             | 0.485   | 0.482                 | 0.476       |\\n|                     | Xu et al. -P           | 0.548             | 0.548   | 0.560                 | 0.518       |\\n|                     | Chikersal et al.       | 0.620             | 0.466   | 0.559                 | 0.534       |\\n| Recent Domain       | ERM-1dCNN              | 0.536             | 0.549   | 0.536                 | 0.514       |\\n|                     | ERM-2dCNN              | 0.534             | 0.533   | 0.487                 | 0.525       |\\n|                     | ERM-LSTM               | 0.514             | 0.546   | 0.475                 | 0.567       |\\n|                     | ERM-Transformer        | 0.507             | 0.495   | 0.503                 | 0.517       |\\n|                     | ERM-Mixup              | 0.536             | 0.549   | 0.536                 | 0.514       |\\n|                     | IRM                    | 0.534             | 0.525   | 0.468                 | 0.504       |\\n|                     | DANN-D                 | 0.469             | 0.522   | 0.467                 | 0.471       |\\n|                     | DANN-P                 | 0.435             | 0.507   | 0.500                 | 0.500       |\\n|                     | CSD-D                  | 0.539             | 0.534   | 0.443                 | 0.553       |\\n|                     | CSD-P                  | 0.512             | 0.578   | 0.443                 | 0.525       |\\n|                     | MLDG-D                 | 0.490             | 0.556   | 0.509                 | 0.523       |\\n|                     | MLDG-P                 | 0.499             | 0.539   | 0.472                 | 0.534       |\\n|                     | MASF-D                 | 0.567             | 0.547   | 0.501                 | 0.513       |\\n|                     | MASF-P                 | 0.560             | 0.510   | 0.525                 | 0.526       |\\n|                     | Siamese Network        | 0.573             | 0.543   | 0.435                 | 0.556       |\\n|                     | Reorder                | 0.614             | 0.633   | 0.532                 | 0.513       |\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our multi-year data collection study closely followed a sister study in Carnegie Mellon University (CMU). We acknowledge all efforts from CMU Study Team to provide important starting and reference materials. We state that we bear all responsibility in case of direct violation of participants' privacy right.\\n\\nC.1 Author Contribution Statement\\n\\nWe clarify every author's contribution to the datasets and the paper. Basic contributions like paper proof-reading are default and omitted. Leading conceptualization and effort are bolded.\\n\\n\u2022 Xuhai Xu\\n  Data Collection: Led technical parts of data collection in 2019 through 2021. Developed and maintained data collection applications from 2019 to 2021. Assisted with data collection from 2019 to 2021; Assisted database maintenance of all years' datasets.\\n  Analysis and Benchmark: Led curation of dataset, analysis, visualization, benchmarking, and data validation. Main developer of benchmark platform GLOBEM.\\n  Paper Writing & Supplementary Materials: Led paper writing, organization, and design of data sharing process.\\n\\n\u2022 Han Zhang\\n  Data Collection: Developed and maintained data codebook and data cleaning (all years). Assisted with the data collection from 2020 to 2021; quality assurance for data collection applications from 2019 to 2021.\\n  Analysis and Benchmark: Led curation of dataset and visualization. Assisted with analysis, benchmarking, and data validation.\\n  Paper Writing & Supplementary Materials: Led curation of dataset details and data sharing agreement in supplementary materials. Assisted with paper writing.\\n\\n\u2022 Yasaman Sefidgar\\n  Data Collection: Led design of infrastructure, pipeline and study codebase and codebooks impacting all years of data cleaning and processing; Led planning for 2019 data collection. Led technical parts of data collection in 2018 and 2019. Also maintained database and study servers for 2018 and 2019; assisted with 2018 and 2019 data collection; and assisted with 2020 planning for data collection.\\n  Analysis and Benchmark: Not involved.\\n  Paper Writing & Supplementary Materials: Provided helpful comments.\\n\\n\u2022 Yiyi Ren\\n  Data Collection: Led transition of infrastructure for sensor data cleaning to RAPIDS. Assisted with data collection study from 2019 - 2021; developed the study codebase, codebook and mobile applications that impact all years; maintained database and study servers from 2019 to 2021.\\n  Analysis and Benchmark: Not involved.\\n  Paper Writing & Supplementary Materials: Not involved.\\n\\n\u2022 Xin Liu\\n  Data Collection: Not involved.\\n  Analysis and Benchmark: Provided assistive effort with computing resources support, quality assurance, analysis, visualization, data validation, and GLOBEM development.\\n  Paper Writing & Supplementary Materials: Editing and framing.\\n\\n\u2022 Woosuk Seo\\n  Data Collection: Led 2018 data collection planning and data collection. Analysis and Benchmark: Not involved.\\n  Paper Writing & Supplementary Materials: Not involved.\\n\\n\u2022 Jennifer Brown\\n  Data Collection: Led 2020 data and 2021 data collection planning and data collection. Assisted with codebook from 2019 to 2021.\\n\\n\u2022 Kevin Kuehn\\n  Data Collection: Led 2019 data collection planning and data collection.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u2022 Mike Merrill\\n  \\n  Data Collection: Not involved.\\n  \\n  Analysis and Benchmark: Assisted with data analysis, visualization, and benchmarking.\\n  \\n  Paper Writing & Supplementary Materials: Assisted with paper writing and study documentation in supplementary materials.\\n\\n\u2022 Paula Nurius\\n  \\n  Data Collection: Supervised study material design and high-level planning for 2018-2021. Provided resources for study.\\n  \\n  Analysis and Benchmark: Not involved.\\n  \\n  Paper Writing & Supplementary Materials: Supervised data-sharing agreement.\\n\\n\u2022 Shwetak Patel\\n  \\n  Data Collection: Not involved.\\n  \\n  Analysis and Benchmark: Supervised data analysis. Provided computing resources.\\n  \\n  Paper Writing & Supplementary Materials: Editing.\\n\\n\u2022 Tim Althoff\\n  \\n  Data Collection: Not involved.\\n  \\n  Analysis and Benchmark: Supervised data analysis, visualization, and benchmark results.\\n  \\n  Paper Writing & Supplementary Materials: Editing.\\n\\n\u2022 Margaret E. Morris\\n  \\n  Data Collection: Supervised study material design and high-level planning for 2019-2021. Provided resources for study.\\n  \\n  Analysis and Benchmark: Not involved.\\n  \\n  Paper Writing & Supplementary Materials: Supervised data-sharing agreement. Editing.\\n\\n\u2022 Eve Riskin\\n  \\n  Data Collection: Supervised study material design and high-level planning for 2018-2021. Provided resources for study.\\n  \\n  Analysis and Benchmark: Not involved.\\n  \\n  Paper Writing & Supplementary Materials: Supervised data-sharing agreement. Editing.\\n\\n\u2022 Jennifer Mankoff\\n  \\n  Data Collection: Supervised study material design and high-level planning for 2018-2021. Provided resources for study.\\n  \\n  Analysis and Benchmark: Supervised data analysis and benchmark results.\\n  \\n  Paper Writing & Supplementary Materials: Supervised data-sharing agreement and paper writing.\\n\\n\u2022 Anind K. Dey\\n  \\n  Data Collection: Supervised study material design and high-level planning for 2018-2021. Provided resources for study.\\n  \\n  Analysis and Benchmark: Supervised data analysis and benchmark results.\\n  \\n  Paper Writing & Supplementary Materials: Supervised data-sharing agreement and paper writing.\"}"}
{"id": "GKOa7yNH8Uh", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C.2 Data Hosting, Licensing, and Maintenance Plan\\n\\nDue to the sensitive nature of the dataset, we release our feature-level data with open credentialed access. Therefore, we plan to leverage the PhysioNet platform for data hosting and licensing, and maintenance.\\n\\nHost:\\nThe PhysioNet platform with Credentialed Access.\\n\\nLicense:\\nPhysioNet Credentialed Health Data License 1.5.0\\n\\nLong-term Preservation:\\nPhysioNet is a well-known platform for freely-available health research data, software, challenges, and tutorials. It is a reliable platform for long-term hosting and preservation of our datasets. We will provide in-time maintenance for error correction through the platform. We will also actively maintain our benchmark platform GLOBEM.\\n\\nC.2.1 Dataset Meta-Data\\n\\nWe provide the meta-data below. Many texts are taken from the main paper. We adopt the meta-data format from PhysioNet as we will leverage it for the data release.\\n\\nTitle:\\nGLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behavior Modeling Generalization\\n\\nAbstract:\\nWe present the first multi-year mobile sensing datasets. Our multi-year data collection studies span four years (10 weeks each year, from 2018 to 2021). The four datasets contain data collected from 705 person-years (497 unique participants) with diverse racial, ability, and immigrant backgrounds. Each year, participants would install a mobile app on their phones and wear a fitness tracker. The app and wearable device passively track multiple sensor streams in the background 24\u00d77, including location, phone usage, calls, Bluetooth, physical activity, and sleep behavior. In addition, participants completed weekly short surveys and two comprehensive surveys on health behaviors and symptoms, social well-being, emotional states, mental health, and other metrics. Our dataset analysis indicates that our datasets capture a wide range of daily human routines, and reveal insights between daily behaviors and important well-being metrics (e.g., depression status). We envision our multi-year datasets can support the ML community in developing generalizable longitudinal behavior modeling algorithms.\\n\\nBackground:\\nAmong various longitudinal sensor streams, smartphones and wearables are arguably one of the most widely available data sources [7]. The advances in mobile technology provide an unprecedented opportunity to capture multiple aspects of daily human behaviors, by collecting continuous sensor streams from these devices [10, 11], together with metrics about health and well-being through self-report or clinical diagnosis as modeling targets. It poses unique challenges compared to traditional time-series classification tasks [6]. First, the data covers a much longer time period, usually across multiple months or years. Second, the nature of longitudinal collection often results in a high data missing rate. Third, the prediction target label is sparse, especially for mental well-being metrics. Longitudinal human behavior modeling is an important multidisciplinary area spanning machine learning, psychology, human-computer interaction, and ubiquitous computing. Researchers have demonstrated the potential of using longitudinal mobile sensing data for behavior modeling in many applications, e.g., detecting physical health issues [9], monitoring mental health status [11], measuring job performance [8], and tracing education outcomes [12]. Most existing research employed off-the-shelf ML algorithms and evaluated them on their private datasets. However, testing a model with new contexts and users is imperative to ensure its practical deployability. To the best of our knowledge, there has been no investigation of the cross-dataset generalizability of these longitudinal behavior models, nor an open testbed to evaluate and compare various modeling algorithms. To address this gap, we present the first multi-year passive mobile sensing datasets to help the ML community explore generalizable longitudinal behavior models.\\n\\nMethods & Technical Implementation:\"}"}
