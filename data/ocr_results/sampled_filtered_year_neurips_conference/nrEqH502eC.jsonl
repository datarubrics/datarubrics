{"id": "nrEqH502eC", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Large language models (LLMs) often lack culture-specific knowledge of daily life, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are limited to a single language or collected from online sources such as Wikipedia, which do not reflect the mundane everyday lifestyles of diverse regions. That is, information about the food people eat for their birthday celebrations, spices they typically use, musical instruments youngsters play, or the sports they practice in school is common cultural knowledge but uncommon in easily collected online sources, especially for underrepresented cultures. To address this issue, we introduce BLEND, a hand-crafted benchmark designed to evaluate LLMs' everyday knowledge across diverse cultures and languages. BLEND comprises 52.6k question-answer pairs from 16 countries/regions, in 13 different languages, including low-resource ones such as Amharic, Assamese, Azerbaijani, Hausa, and Sundanese. We construct the benchmark to include two formats of questions: short-answer and multiple-choice. We show that LLMs perform better for cultures that are highly represented online, with a maximum 57.34% difference in GPT-4, the best-performing model, in the short-answer format. For cultures represented by mid-to-high-resource languages, LLMs perform better in their local languages, but for cultures represented by low-resource languages, LLMs perform better in English than the local languages. We make our dataset publicly available at: https://github.com/nlee0212/BLEnD.\"}"}
{"id": "nrEqH502eC", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"What do people eat on their birthday in Ethiopia? What do people from Spain usually eat for dessert?\\n\\nManual Data Construction\\n1. Question Collection\\n2. Question Filtering & Translation\\n3. Answer Annotation\\n\u21d2 500 questions \u00d7 16 countries/regions (13 languages)\\n4. Answer Aggregation\\n\\nWho usually do the house chores in Assam?\\n\\nFigure 1: The overall framework of dataset construction and LLM evaluation on BLEND. BLEND is built through 4 steps: question collection, question filtering & translation, answer annotation, and answer aggregation. The dataset includes the same questions in 13 different languages, answered from 16 different countries/regions. We evaluate LLMs by short-answer and multiple-choice questions.\\n\\nEven though these inquiries are frequently encountered in daily lives, this can lead to hallucinations or stereotypical responses, potentially offending a large and diverse user base. This challenge becomes even more evident in cross-lingual settings, as most LLMs are primarily trained on English data reflecting Western perspectives [8, 20, 15]. They often reflect the stereotypes present in the training data [19, 18, 21, 36, 13], hence these models would often respond based on Western perspectives rather than reflecting actual diverse practices. Ideally, language models would reflect the cultural norms of various regions around the world and generate culturally appropriate content when responding in local languages of the regions, unless otherwise specified. To develop multilingual LLMs with such cultural appropriateness, we first need to evaluate the cultural commonsense knowledge. However, there is no well-crafted multilingual multicultural benchmark that captures the daily lives of people in diverse cultures.\\n\\nTo bridge this gap, we present BLEND, a Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages. The benchmark covers 13 languages spoken in 16 different countries and regions shown in Table 1. Note that we include languages that are spoken in two regions with vastly different cultures, such as South Korea and North Korea, both represented by the Korean language. To effectively capture the cultural diversity of people's daily lives, we recruit annotators who are native speakers from various countries. The final dataset includes 500 socio-cultural question-answer pairs for each country/region in 6 categories: food, sports, family, education, holidays/celebrations/leisure, and work-life. To capture a comprehensive understanding of the cultural sensitivity of LLMs, we create a set of questions and answers in two formats: short-answer and multiple-choice questions. The overall framework for construction and evaluation of BLEND is shown in Figure 1. The statistics of BLEND are shown in Table 1. In total, BLEND features an extensive collection of 52.6k question-and-answer pairs, 15k short-answer and 37.6k multiple-choice.\\n\\nOur experimental results on BLEND show that even current state-of-the-art LLMs exhibit unbalanced cultural knowledge and unfair cultural biases across various countries and regions. The average performance of all tested models on short answer questions about United States (US) culture in English is 79.22%. In contrast, when asked about Ethiopian (ET) culture in Amharic, the average performance is lower.\"}"}
{"id": "nrEqH502eC", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistics of the question samples within BLE\\n\\nD. BLE\\n\\n| Country/Region | Language Count | Language Count |\\n|----------------|----------------|----------------|\\n| United States (US) | 500 | 1,942 |\\n| United Kingdom (GB) | 500 | 2,167 |\\n| China (CN) | 1,000 | 1,929 |\\n| Spain (ES) | 1,000 | 1,931 |\\n| Indonesia (ID) | 1,000 | 1,995 |\\n| Mexico (MX) | 1,000 | 1,899 |\\n| South Korea (KR) | 1,000 | 2,512 |\\n| Greece (GR) | 1,000 | 2,734 |\\n| Iran (IR) | 1,000 | 3,699 |\\n| Algeria (DZ) | 1,000 | 2,600 |\\n| Azerbaijan (AZ) | 1,000 | 2,297 |\\n| North Korea (KP) | 1,000 | 2,185 |\\n| West Java (JB) | 1,000 | 2,345 |\\n| Assam (AS) | 1,000 | 2,451 |\\n| Northern Nigeria (NG) | 1,000 | 2,008 |\\n| Ethiopia (ET) | 1,000 | 2,863 |\\n| **Subtotal** | **15,000** | **37,557** |\\n| **Total** | **52,557** |  \\n\\ndrops to only 12.18%, highlighting a significant performance gap in relatively underrepresented cultures and languages. A similar trend is observed in the multiple-choice format, where the LLMs are required to choose the correct answer for each target country/region, with answers from other countries/regions presented as wrong options.\\n\\nThe main contributions of our paper are as follows:\\n\\n\u2022 We present BLE\\\\(\\\\text{^N}\\\\)D, a benchmark of carefully crafted 52.5k question-answer pairs that reflect the everyday cultural knowledge across 16 countries/regions in 13 different languages.\\n\\n\u2022 Within BLE\\\\(\\\\text{^N}\\\\)D, we propose two types of questions to automatically measure the cultural knowledge in LLMs: short-answer questions and multiple-choice questions.\\n\\n\u2022 We conduct extensive experiments across 16 LLMs on BLE\\\\(\\\\text{^N}\\\\)D, showing a significant performance gap between highly represented cultures and underrepresented cultures.\\n\\n2 Related Work\\n\\nAlthough LLMs generally incorporate extensive parametric knowledge from large text corpora during pretraining \\\\[25\\\\], such models frequently display bias due to imbalanced representations in the data sources \\\\[3\\\\]. Cultural knowledge is critical in enhancing the reasoning capabilities of LLMs, contributing significantly to their success across various downstream applications.\\n\\nNumerous studies have examined the socio-cultural aspects of LLMs. Previous work on cultural NLP defines culture as the way of life of a specific group of people \\\\[10\\\\]. Most research on the cultural knowledge of LLMs centers on the culture at a national level. Anacleto et al.\\\\[1\\\\] collect commonsense knowledge about eating habits in Brazil, Mexico, and US through the Open Mind Common Sense portal. GeoMLAMA \\\\[33\\\\] introduces 16 geo-diverse commonsense concepts and uses crowdsourcing to compile knowledge from 5 different countries, each in its native languages. Nguyen et al. \\\\[22\\\\] introduce a methodology to extract large-scale cultural commonsense knowledge from the Common Crawl corpus on geography, religion, and occupations. CREHate \\\\[17\\\\] is a cross-cultural English hate speech dataset covering annotations from 5 English-speaking countries. CultureAtlas \\\\[9\\\\] includes textual data encapsulating the cultural norms from 193 countries, primarily sourced from Wikipedia documents in English. However, the majority of these studies are conducted exclusively in English and focus on more objective aspects of culture that are written in formal data sources.\"}"}
{"id": "nrEqH502eC", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Detailed statistics of the number of questions per category for each country/region in Short Answer Questions (SAQ) and Multiple-Choice Questions (MCQ).\\n\\n| Country/Region   | Food | Sports | Family | Education | Holidays | Work-life |\\n|------------------|------|--------|--------|-----------|----------|-----------|\\n| **SAQ**          | 105  | 88     | 63     | 84        | 92       | 68        |\\n| United States (US)| 642  | 393    | 60     | 173       | 500      | 174       |\\n| United Kingdom (GB)| 990  | 403    | 50     | 189       | 427      | 108       |\\n| Spain (ES)       | 714  | 476    | 43     | 172       | 425      | 101       |\\n| Mexico (MX)      | 489  | 491    | 39     | 183       | 578      | 119       |\\n| Indonesia (ID)   | 471  | 369    | 60     | 212       | 699      | 184       |\\n| China (CN)       | 475  | 349    | 74     | 200       | 705      | 126       |\\n| South Korea (KR) | 753  | 792    | 57     | 218       | 539      | 153       |\\n| Algeria (DZ)     | 873  | 569    | 59     | 189       | 819      | 91        |\\n| Greece (GR)      | 1,345| 516    | 40     | 154       | 500      | 179       |\\n| Iran (IR)        | 666  | 519    | 50     | 173       | 2,135    | 156       |\\n| North Korea (KP) | 784  | 430    | 78     | 228       | 476      | 189       |\\n| Azerbaijan (AZ)  | 852  | 513    | 65     | 216       | 453      | 198       |\\n| West Java (JB)   | 892  | 461    | 20     | 160       | 680      | 132       |\\n| Assam (AS)       | 862  | 584    | 34     | 198       | 666      | 107       |\\n| Northern Nigeria (NG)| 647  | 421    | 50     | 207       | 508      | 175       |\\n| Ethiopia (ET)    | 984  | 649    | 46     | 278       | 692      | 214       |\\n\\nMore recent studies have focused on the cultural knowledge of non-English speaking countries and languages. For instance, CLIcK [14] and HAE-RAE Bench [29] evaluate LLMs\u2019 knowledge in Korean, while COPAL-ID [32], ID-CSQA [26], and IndoCulture [15] include culturally nuanced questions in Indonesian. Nonetheless, we do not know of any work that has been done to compare the cultural adaptiveness of LLMs across diverse languages and cultures using the same question set, which would enable a direct comparison.\\n\\nOther recent work focuses on capturing the everyday cultural nuances of LLMs using social networking platforms. StereoKG [7] extracts cultural stereotypes of five nationalities and five religious groups from questions posted on X (formerly Twitter) and Reddit. However, this method produces a significant amount of noisy and inappropriate assertions due to insufficient filtering. CAM [20] includes masked prompts from naturally occurring contexts on X, focusing on Arabic content, and CultureBank [28] is a collection of diverse perspectives and opinions on cultural descriptors, including English comments from TikTok and Reddit. However, these datasets are limited to a single language and rely solely on data available from social media, not able to capture people\u2019s everyday behaviors to the full extent [31].\\n\\nIn contrast to prior work, BLEND is carefully human-crafted, capturing everyday life cultural knowledge across 13 languages spoken in 16 different countries/regions including underrepresented regions such as West Java and North Korea.\\n\\n3 Construction of BLEND\\n\\nLanguage Coverage.\\n\\nWe select languages with varying levels of resource availability using the metrics defined by Joshi et al. [12]. The resource availability of languages included in BLEND is shown in Table 4 in the Appendix. Additionally, we involve at least one author who is a native speaker of the language and originally from the country/region represented in the dataset to handle the data inspection process 2.\\n\\nQuestion Collection and Filtering.\\n\\nBLEND includes 500 question templates that reflect daily life aspects across six socio-cultural categories: food, sports, family, education, holidays/celebrations/leisure, and work-life. To create these templates, we collect 10-15 questions for each category from at least two native annotators per country/region. These annotators are asked to generate culturally relevant questions about their countries while avoiding stereotypical questions. The question generation guideline is shown in Appendix B.4. The collected questions are filtered 2.\\n\\n4 North Korea was an exception, where we collaborated with a South Korean researcher studying North Korean language.\"}"}
{"id": "nrEqH502eC", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Heatmap showing the average number of common lemmas within each question between all country/region pairs. Pairs from the same countries/regions are shown in white. Higher numbers of shared lemmas indicate that those countries/regions provide more similar answers compared to other countries/regions (e.g., Indonesia and West Java).\\n\\nTo eliminate duplicates and country-specific items that can only apply to one country/region. For example, items with proper nouns from a single country/region are excluded. Then the questions are formatted into templates like \\\"What is a common snack for preschool kids in [your country]?\\\"\\n\\nSubsequently, '[your country]' is replaced by the country/region names for localizing the questions. Except for US and GB, the questions are translated into the local languages by the native speakers. This process results in a comprehensive dataset of 15,000 short-answer questions, as shown in Table 1. The specific number of questions per topic is shown in Table 2.\\n\\nAnswer Annotation. To obtain the answers to the collected questions, we recruit annotators who are native speakers of the target languages and are originally from the target regions/countries. We ensure that the annotators have lived in these countries for over half of their lifetimes. For most countries, we recruit annotators through Prolific. However, in cases where it is not possible to find annotators through crowdsourcing platforms (i.e., DZ, KR, KP, AZ, JB, AS, NG, and ET), we directly recruit five annotators who meet our criteria.\\n\\nAnnotators are required to give at least one short answer to each question and can offer up to three responses if a single answer is insufficient. If an annotator does not know the answer, they can choose from the following options: 'not applicable to our culture,' 'no specific answer for this question,' 'I don't know the answer,' or 'others.' By default, responses are collected from five annotators per question. If an annotator chooses 'I don't know the answer,' we discard the response and collect a new one. This process continues until five valid responses for each question are obtained, or more than five annotators choose 'I don't know.' Examples of the collected questions with answers from each country are presented in Figure 1. The guideline and the interface for answer annotation provided to annotators are shown in Appendix B.5 and B.6.\\n\\nAnswer Aggregation. We request 1-2 annotators from each country to review the annotations and remove invalid answers. These invalid answers appear to be due to some annotators misunderstanding a question, leading to nonsensical answers. Additionally, due to the nature of natural language, there are multiple variations of a single term (e.g., \\\"go to bed\\\" and \\\"sleep\\\"). We instruct the annotators to group these variants into one to ensure the final dataset contains accurate vote counts for each answer. We also ask the annotators to translate all the annotations into English. As a result, our final dataset includes variants in local languages and English, along with a final vote count for answers to the question.\\n\\n3 This condition was not fully met for North Korea due to a very limited pool of annotators.\\n4 https://www.prolific.co/\\n5 Tables 5 and 6 in the Appendix shows a detailed demographic distribution of the annotators.\"}"}
{"id": "nrEqH502eC", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Statistical Analysis on Annotations.\\n\\nWe analyze the annotations to assess their quality and consistency, as detailed in Table 7 in the Appendix. Despite the subjective nature of the questions, the average level of agreement among annotators, calculated by the average of the maximum votes for each question, is 3.16 out of 5 (63.2%). The balance within the dataset indicates that while there is consensus on certain annotations, there is also a substantial variety in the answers within each country, reflecting a diverse range of perspectives. We also present the average number of annotations per question in Table 8 in the Appendix, to show the level of answer variance.\\n\\nTable 9 in the Appendix presents the average number of 'I don't know' responses per question. On average, there were 1.01 out of 5 such responses per question, with a standard deviation of 0.35 (ranging from a high of 1.912 in Northern Nigeria to a low of 0.42 in South Korea). The frequency of 'I don't know' responses was higher in the sports and holidays/celebrations/leisure categories, likely due to questions on sports or holidays that are not widely recognized or celebrated in certain countries or regions.\\n\\nFurthermore, we measure the overlap of answers between countries/regions by calculating the number of shared lemmas of the English versions of annotations to compare the trend between them and show the result in Figure 2. The result indicates that countries/regions with closely aligned cultural backgrounds exhibit higher overlaps in answers. The top pairs with the most similar responses are Indonesia & West Java (a province in Indonesia), the United States & the United Kingdom, and Spain & Mexico, likely due to shared historical, linguistic, or cultural ties that influence how questions are understood and answered. On the other hand, the pairs with the lowest value are Northern Nigeria & Greece/Ethiopia/South Korea. This could be due to the fact that Northern Nigeria has its own unique regional culture captured in the dataset.\\n\\n4 LLMs Cultural Knowledge Evaluation\\n\\nWe measure how the current LLMs perform on BLEND on the two task settings: short answer and multiple-choice. Details for the experimental settings and the 16 evaluated models can be seen in Appendix C.1.\\n\\n4.1 Short Answer Questions (SAQ)\\n\\nExperimental Setting. In this experiment, we measure LLMs' performance on SAQ. The final score for each country is calculated as the average score over two prompts: 1) directly ask LLMs to provide the answer, and 2) add persona to the LLMs to make them act as a person from the target country or region. The detailed prompts are shown in Appendix C.2.1. To compute the score, we first mark the LLM's response as correct if it is included in the human annotators' responses to the same question. Then we compute the percentage of questions to which LLM's answer is correct. More details on calculating the scores can be found in Appendix C.2.2.\\n\\nWe compute the scores for all the countries based on the results obtained for the local language and English, respectively. We use lemmatizers and stemmers to handle highly inflectional languages such as Arabic and variations in words. The details are shown in Appendix C.2.2. In addition, we remove accents from words in languages that contain accents, such as Spanish and Greek, to ensure that the annotations from human annotators match the responses of LLMs. When computing the scores, we ignore questions for which three or more annotators do not know the answer.\\n\\n4.1.1 LLM Performance on SAQ\\n\\nFigure 3a presents the performance of five LLMs on short answer questions in the local languages of target countries/regions. Table 10 shows the performance of all 16 LLMs evaluated. The results indicate a consistent trend of lower performance for lower resource languages [12]. Highlighting just a few results, the average LLM performance for US, Spain, Iran, North Korea, Northern Nigeria, and Ethiopia are 79.22%, 69.08%, 50.78%, 41.92%, 21.18%, and 12.18%, respectively, indicating a significant drop in performance for underrepresented cultures. Countries that share a common language but differ culturally show significant differences, for example, GPT-4, the highest-performing model, shows a substantial performance disparity of 31.63% between South Korea and North Korea. Similarly, between Spain and Mexico, GPT-4 exhibits a performance gap...\"}"}
{"id": "nrEqH502eC", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Performance of Region-Centric LLMs.\\n\\nModels built from non-Western countries tend to show higher performance on that specific country/region. For example, as seen in Figure 3a, Qwen1.5-72B [5], made by the Qwen Team in Alibaba Group, shows highest performance on Chinese among all models. HyperCLOVA-X [34], built from the Naver Corporation, also shows comparable results on Korean, even exceeding GPT-4 performance in North Korean cultural questions. These language/region-specific models often benefit from customized datasets richer in local cultural content and nuances, typically underrepresented in the more universally used datasets, leading to higher performances in their regions.\\n\\nLocal language vs. English.\\n\\nWe compare the average LLM performance when prompted in local languages versus English, as shown in Figure 3b. For cultures represented by high-resource languages like Spanish and Chinese, the local languages show better performance across all models. In contrast, in cultures represented by low-resource languages such as Azerbaijani, Sundanese, and Amharic, English results in better performance (full results are shown in Table 1). This implies that the models' proficiency in a particular language significantly influences its performance and that models tend to show better cultural sensitivity in the local language when they possess sufficient expertise in that language.\"}"}
{"id": "nrEqH502eC", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"linguistic capability. Note for North Korean (KP) cultural questions, both English and Korean show poor performance as expected, but Korean performs slightly better, as it is a relatively high-resource language.\\n\\nPerformance by Question Category.\\n\\nIn our analysis of six socio-cultural categories, models generally exhibit lower performance on questions related to food and holidays/celebrations/leisure than those concerning work-life or education. This disparity, significant with a $p < 0.05$ using one-way ANOVA, is detailed in Figure 15. This pattern indicates that more subjective topics like food and leisure are more challenging for LLMs to show cultural adaptiveness.\\n\\n4.2 Multiple-Choice Questions (MCQ)\\n\\nWhile SAQ is effective for multilingual evaluation, LLMs often generate responses that deviate from the annotators' one- or few-word answers, for example, generating long sentences, especially in languages that do not follow the instructions well. Hence we make the MCQ to enable simpler evaluation of LLMs. One limitation of our MCQ is that it is only available in English, as the incorrect options were chosen from different cultures' responses to the same questions, and translating all of those requires additional work. We plan to release a multilingual version of MCQ soon.\\n\\n4.2.1 MCQ Construction\\n\\nWe make the multiple-choice questions about each target country/region in English, with other answer options from other countries/regions. For fair comparison across all countries, we remove questions for which at least one country has an annotation of 'not applicable to our culture,' or more than three annotators don't know the answer. We also remove questions where all annotations have one vote each, indicating no typical answer from that country for that question. We determine the correct answer for each question by selecting the annotation with the highest votes from each country. We provide four answer options for each question, with no more than one option from any of the other countries. The detailed process of choosing plausible incorrect answer options can be seen in Appendix C.3.1. The final multiple-choice question prompt is shown in Appendix C.3.3.\\n\\n4.2.2 LLM Performance on MCQ\\n\\nIn general, models show higher performance in MCQ than in SAQ as shown in Figure 4. This improvement is due to using questions with well-defined answers for multiple-choice questions. However, the pattern of displaying higher performance in high-resource cultures remains consistent. When considering the tendencies of all countries/regions for each model, the average Pearson correlation between the average performance in SAQ in the local languages and English across all countries/regions and the MCQ performance across all countries/regions is notably strong at 0.93. Furthermore, the Pearson correlation between the average model performance in English SAQ for all countries and that in MCQ exhibits a considerably high value of 0.98. This indicates a strong alignment between the two evaluation formats.\\n\\n5 Human Evaluation\\n\\nWe conduct a human evaluation for short-answer responses from LLMs to understand the source of errors. We use responses from GPT-4, the best-performing model, for short-answer questions. We define the following categories: stereotypical, partially correct, refusal, nonsensical, unnatural language, and different country's view to analyze 120 wrong answers based on the automated evaluation. The detailed instructions and the definitions of each category can be found in Appendix D.3.1. Also, the summary of the human evaluation results can be found in Table 13. The most stereotypical responses came from answers generated for underrepresented languages/cultures such as Ethiopia, West Java, and Assam, with 48.33% of responses from Ethiopia being stereotypical. Most stereotypical questions were related to food or festivals, where the LLM attempted to provide traditional information about the country or the region without fully understanding the context. For instance, for West Java, the LLM frequently answered any food-related questions with 'Seblak,' one of the most famous dishes originating from the region. Notably, countries with a high percentage of partially correct answers or refusals were all from underrepresented cultures, such as Azerbaijan, North Korea, Northern Nigeria, and Ethiopia.\"}"}
{"id": "nrEqH502eC", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: LLMs' performance on multiple-choice questions. Models constructed from a Western country are shown in shades of blue, whereas those built from a non-Western country are shown in shades of red. Similar to the results from short-answer questions, models tend to show lower performance in underrepresented countries/regions.\\n\\nindicates that the LLMs tend to provide a long list of multiple answers or even refuse to answer when there is insufficient information about the topic/question. The same trend was observed for nonsensical answers, indicating that the capability of LLMs to comprehend questions is limited for low-resource languages. There were also many hallucinations for low-resource languages, such as providing 'Ruslan Cfrov' as the most famous basketball player in Azerbaijan, despite the non-existence of a famous player with that name.\\n\\nGPT-4 also tends to provide answers from the perspective of other countries when responding to queries about Azerbaijan and North Korea. For Azerbaijan, many answers were from the perspectives of other countries in the Caucasus region, and for North Korea, most responses were from the perspective of South Korea. This aligns with the annotations for unnatural language, as the same two countries had the highest ratio of unnatural language. In the case of Azerbaijan, there were instances where the LLM even responded in Turkish. For North Korea, a surprising 18.33% of the responses were marked as unnatural because they were phrased in the words used exclusively in South Korea.\\n\\n6 Conclusion\\n\\nIn this paper, we present BLEND, a benchmark to evaluate the cultural knowledge about everyday life within 16 current LLMs in 16 countries/regions and 13 distinct languages.\\n\\nOur experimental findings indicate that current LLMs demonstrate a high level of competence in highly represented cultures such as the United States and the United Kingdom. However, their performance is significantly lower in the case of less-represented and underrepresented cultures and languages, especially when prompted in the local language. This outcome is observed in both short-answer questions and multiple-choice questions. Furthermore, our study reveals the performance gap between two countries using the same language, highlighting a cultural bias among those regions.\\n\\nMoreover, the study shows that the performance of LLMs varies depending on the language used in prompting: LLMs generally perform better in local languages for mid-to-highly represented cultures, while for underrepresented cultures, they perform better in English.\\n\\n7 Limitations and Future Work\\n\\nOne limitation of our approach is the relatively small number of annotators, typically five per question, sometimes from the same locality within one country. This might not fully represent the countries/regions we include in our dataset. Extending efforts to increase the number of annotators per country, especially from diverse regional bases within each of the countries/regions, will be the most immediate future work of this research. Moreover, most language experts involved in the benchmark creation were academics proficient in English, the reference language for communication and translation. This may bias part of the construction process as they may not be fully representative.\"}"}
{"id": "nrEqH502eC", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of the population of each country. We do not claim that our data fully represents all the speakers of any language/region, but our dataset remains a good starting point for researchers interested in the topic.\\n\\nAdditionally, evaluating short-answer questions poses noticeable challenges. Despite the extensive human effort and using lemmatizers/stemmers, accounting for all word variations is difficult, leading to correct answers not being evaluated accurately. Our dataset also faces challenges in evaluating long-form responses from LLMs, as the annotated data is based on short answers. Future work should focus on accurately evaluating the cultural adaptiveness of LLMs in long-form natural contexts, as limitations exist within prompt-based evaluations.\\n\\nAcknowledgments and Disclosure of Funding\\n\\nThis project was funded by the KAIST-NA VER hypercreative AI center. Alice Oh is funded by Institute of Information communications Technology Planning Evaluation (IITP) grant funded by the Korea government(MSIT) (No. 2022-000184, Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics). Moreover, this research project has benefitted from the Microsoft Accelerate Foundation Models Research (AFMR) grant program through which leading foundation models hosted by Microsoft Azure along with access to Azure credits were provided to conduct the research. Jose Camacho-Collados, Dimosthenis Antypas, and Yi Zhou are supported by a UKRI Future Leaders Fellowship.\\n\\nWe also thank the following annotators for their invaluable help in building the dataset: \u00c1ngela Collados Ais, Kiamehr Rezaee, Nurul Ariyani, Sabrina Borrelli, Trapsilo Bumi, Helia Taheri, Chao Tan, Guanqun Cao, Dimitra Mavridou, Abderrahmane Samir Lazouni, Noufel Bouslama, Lyes Taher Khalfi, Nitumoni Neog, Bhagyashree Deka, Sikha Swarnakar, Sangeeta Neog, Nitashree Neog, Hailegnaw Tilaye, Amare Lakew, Wasihun Lakew, Yohannes Bogale, Addis Alemayehu, Yeon Su Park, Hee Su Park, Jeong Min Young, Hyewon Im, Geunsoo Lee, David Chong, Dea Adhista, Sarah Oktavianti, Muhammad Syahrul Kurniawan, Taufik Muhamad Yusup, Miguel Ramirez, Thomas Welsch, annotators from Prolific, and all other annotators who preferred to remain unnamed.\\n\\nReferences\\n\\n[1] Junia Anacleto, Henry Lieberman, Marie Tsutsumi, V\u00e2nia Neris, Aparecido Carvalho, Jose Espinosa, Muriel Godoi, and Silvia Zem-Mascarenhas. Can common sense uncover cultural differences in computer applications? In Max Bramer, editor, Artificial Intelligence in Theory and Practice, pages 1\u201310, Boston, MA, 2006. Springer US. ISBN 978-0-387-34747-9.\\n\\n[2] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Cl\u00e9ment Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D\u00edaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran V odrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.\"}"}
{"id": "nrEqH502eC", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "nrEqH502eC", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[10] Eunsu Kim, Juyoung Suk, Philhoon Oh, Haneul Yoo, James Thorne, and Alice Oh. CLIcK: A benchmark dataset of cultural and linguistic intelligence in Korean. In Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste, Alessandro Lenci, Sakriani Sakti, and Nianwen Xue, editors, Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 3335\u20133346, Torino, Italia, May 2024. ELRA and ICCL. URL https://aclanthology.org/2024.lrec-main.296.\\n\\n[15] Fajri Koto, Rahmad Mahendra, Nurul Aisyah, and Timothy Baldwin. Indoculture: Exploring geographically-influenced cultural commonsense reasoning across eleven indonesian provinces. arXiv preprint arXiv:2404.01854, 2024. URL https://arxiv.org/abs/2404.01854.\\n\\n[16] Anoop Kunchukuttan. The IndicNLP Library. https://github.com/anoopkunchukuttan/indic_nlp_library/blob/master/docs/indicnlp.pdf, 2020.\\n\\n[17] Nayeon Lee, Chani Jung, Junho Myung, Jiho Jin, Jose Camacho-Collados, Juho Kim, and Alice Oh. Exploring cross-cultural differences in english hate speech annotations: From dataset construction to analysis, 2024. URL https://arxiv.org/abs/2308.16705.\\n\\n[18] Moin Nadeem, Anna Bethke, and Siva Reddy. StereoSet: Measuring stereotypical bias in pre-trained language models. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5356\u20135371, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.416. URL https://aclanthology.org/2021.acl-long.416.\\n\\n[19] Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel R. Bowman. CrowS-pairs: A challenge dataset for measuring social biases in masked language models. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1953\u20131967, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.154. URL https://aclanthology.org/2020.emnlp-main.154.\\n\\n[20] Tarek Naous, Michael J Ryan, and Wei Xu. Having beer after prayer? measuring cultural bias in large language models. arXiv preprint arXiv:2305.14456, 2023. URL https://arxiv.org/abs/2305.14456.\\n\\n[21] Roberto Navigli, Simone Conia, and Bj\u00f6rn Ross. Biases in large language models: origins, inventory, and discussion. ACM Journal of Data and Information Quality, 15(2):1\u201321, 2023.\\n\\n[22] Tuan-Phong Nguyen, Simon Razniewski, Aparna Varde, and Gerhard Weikum. Extracting cultural commonsense knowledge at scale. In Proceedings of the ACM Web Conference 2023, WWW \u201923, page 1907\u20131917, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9781450394161. doi: 10.1145/3543507.3583535. URL https://doi.org/10.1145/3543507.3583535.\\n\\n[23] Xuan-Phi Nguyen, Wenxuan Zhang, Xin Li, Mahani Aljunied, Qingyu Tan, Liying Cheng, Guanzheng Chen, Yue Deng, Sen Yang, Chaoqun Liu, Hang Zhang, and Lidong Bing. Seallms - large language models for southeast asia. arXiv preprint arXiv:2312.00738, 2023. URL https://arxiv.org/abs/2312.00738.\\n\\n[24] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Sim\u00f3n Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan...\"}"}
{"id": "nrEqH502eC", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463\u20132473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://aclanthology.org/D19-1250.\\n\\nRifki Afina Putri, Faiz Ghifari Haznitrama, Dea Adhista, and Alice Oh. Can llm generate culturally relevant commonsense qa data? case study in indonesian and sundanese, 2024. URL https://arxiv.org/abs/2402.17302.\\n\\nIrwan Setiawan and Hung-Yu Kao. Sustem: An improved rule-based sundanese stemmer. ACM Trans. Asian Low-Resour. Lang. Inf. Process., apr 2024. ISSN 2375-4699. doi: 10.1145/3656342. URL https://doi.org/10.1145/3656342. Just Accepted.\\n\\nWeiyan Shi, Ryan Li, Yutong Zhang, Caleb Ziems, Raya Horesh, Rog\u00e9rio Abreu de Paula, Diyi Yang, et al. Culturebank: An online community-driven knowledge base towards culturally aware language technologies. arXiv preprint arXiv:2404.15238, 2024. URL https://arxiv.org/abs/2404.15238.\\n\\nGuijin Son, Hanwool Lee, Suwan Kim, Huiseo Kim, Jae cheol Lee, Je Won Yeom, Jihyu Jung, Jung woo Kim, and Songseong Kim. HAE-RAE bench: Evaluation of Korean knowledge in language models. In Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste, Alessandro Lenci, Sakriani Sakti, and Nianwen Xue, editors, Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, 2024.\"}"}
{"id": "nrEqH502eC", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "nrEqH502eC", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "nrEqH502eC", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "nrEqH502eC", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Zeynep Tufekci. Big questions for social media big data: Representativeness, validity and other methodological pitfalls. In Proceedings of the international AAAI conference on web and social media, volume 8, pages 505\u2013514, 2014.\\n\\nHaryo Akbarianto Wibowo, Erland Hilman Fuadi, Made Nindyatama Nityasya, Radityo Eko Prasojo, and Alham Fikri Aji. Copal-id: Indonesian language reasoning with local culture and nuances, 2024. URL https://arxiv.org/abs/2311.01012.\"}"}
{"id": "nrEqH502eC", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Da Yin, Hritik Bansal, Masoud Monajatipoor, Liunian Harold Li, and Kai-Wei Chang. GeoM-LAMA: Geo-diverse commonsense probing on multilingual pre-trained language models. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 2039\u20132055, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.132. URL https://aclanthology.org/2022.emnlp-main.132.\"}"}
{"id": "nrEqH502eC", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sangkyu Lee, Se Young Lee, Seulgi Lee, Seung Jin Lee, Suhyeon Lee, Yeonjae Lee, Yesol Lee, Youngbeom Lee, Yujin Lee, Shaodong Li, Tianyu Liu, Seong-Eun Moon, Taehong Moon, Max-Lasse Nihlenramstroem, Wonseok Oh, Yuri Oh, Hongbeen Park, Hyekyung Park, Jaeho Park, Nohil Park, Sangjin Park, Jiwon Ryu, Miru Ryu, Simo Ryu, Ahreum Seo, Hee Seo, Kangdeok Seo, Jamin Shin, Seungyoun Shin, Heetae Sin, Jiangping Wang, Lei Wang, Ning Xiang, Longxiang Xiao, Jing Xu, Seonyeong Yi, Haanju Yoo, Haneul Yoo, Hwanhee Yoo, Liang Yu, Youngjae Yu, Weijie Yuan, Bo Zeng, Qian Zhou, Kyunghyun Cho, Jung-Woo Ha, Joonsuk Park, Jihyun Hwang, Hyoung Jo Kwon, Soonyong Kwon, Jungyeon Lee, Seungho Lee, Seonghyeon Lim, Hyunkyung Noh, Seungho Choi, Sang-Woo Lee, Jung Hwa Lim, and Nako Sung. Hyperclova x technical report. arXiv preprint arXiv:2404.01954, 2024. URL https://arxiv.org/abs/2404.01954.\\n\\n[35] Taha Zerrouki. qalsadi, arabic mophological analyzer library for python., 2012. URL https://pypi.python.org/pypi/qalsadi.\\n\\n[36] Yi Zhou, Jose Camacho-Collados, and Danushka Bollegala. A predictive factor analysis of social biases and task-performance in pretrained masked language models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 11082\u201311100, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.683. URL https://aclanthology.org/2023.emnlp-main.683.\\n\\n[37] Ahmet \u00dcst\u00fcn, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D\u2019souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. Aya model: An instruction finetuned open-access multilingual language model. arXiv preprint arXiv:2402.07827, 2024. URL https://arxiv.org/abs/2402.07827.\\n\\nChecklist\\n\\n1. For all authors...\\n   (a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] See Abstract and Section 1\\n   (b) Did you describe the limitations of your work? [Yes] See Section 7\\n   (c) Did you discuss any potential negative societal impacts of your work? [Yes] See Section 7\\n   (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] See Section B.2\\n\\n2. If you are including theoretical results...\\n   (a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n   (b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n   (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] Link provided in Abstract\\n   (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] See Appendix C.1\\n   (c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes] See Figure 3b\\n   (d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] See Appendix C.1\\n\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n   (a) If your work uses existing assets, did you cite the creators? [N/A]\\n   (b) Did you mention the license of the assets? [N/A]\\n   (c) Did you include any new assets either in the supplemental material or as a URL? [Yes] URL in the Abstract.\"}"}
{"id": "nrEqH502eC", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] See Appendix B.2\\n\\n(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n\\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes] See Appendix B.4, B.5, and B.6\\n\\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [Yes] See Appendix B.2\\n\\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Yes] See Appendix B.2\"}"}
{"id": "nrEqH502eC", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Appendix\\n\\nA Dataset Details\\n\\nA.1 Accessibility, Usage, License, and Maintenance\\n\\nAccessibility:\\n\\nAll data samples of BLEND\u2014including short answer questions, multiple-choice questions, and their answers\u2014as well as the codes we use in our work, can be found at [https://github.com/nlee0212/BLEnD](https://github.com/nlee0212/BLEnD). We also make our dataset publicly available at HuggingFace Datasets ([https://huggingface.co/datasets/nayeon212/BLEnD](https://huggingface.co/datasets/nayeon212/BLEnD)).\\n\\nUsage:\\n\\nIn the GitHub repository, all the data samples for short-answer questions, including the human-annotated answers, can be found in the `data/` directory. Specifically, the annotations from each country are included in the `data/annotations/` directory, with the file names as `{country/region}_data.json`. Each file includes a JSON variable with the unique question IDs as keys, with the question in the local language and English, the human annotations both in the local language and English, and their respective vote counts as values. The example of an instance in the dataset for South Korea is shown below:\\n\\n```\\n\\\"Al-en-06\\\": {\\n  \\\"question\\\": \\\"\ub300\ud55c\ubbfc\uad6d \ud559\uad50\uae09\uc2dd\uc5d0\uc11c \ud754\ud788 \ubcfc \uc218 \uc788\ub294 \uc74c\uc2dd\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\\",\\n  \\\"en_question\\\": \\\"What is a common school cafeteria food in your country?\\\",\\n  \\\"annotations\\\": [\\n    {\\n      \\\"answers\\\": [\\\"\uae40\uce58\\\"],\\n      \\\"en_answers\\\": [\\\"kimchi\\\"],\\n      \\\"count\\\": 4\\n    },\\n    {\\n      \\\"answers\\\": [\\\"\ubc25\\\", \\\"\uc300\ubc25\\\", \\\"\uc300\\\"],\\n      \\\"en_answers\\\": [\\\"rice\\\"],\\n      \\\"count\\\": 3\\n    },\\n    ...\\n  ],\\n  \\\"idks\\\": {\\n    \\\"idk\\\": 0,\\n    \\\"no-answer\\\": 0,\\n    \\\"not-applicable\\\": 0,\\n    \\\"others\\\": []\\n  }\\n},\\n```\\n\\nWe also include the prompts that we used for LLM evaluation in local languages and English in the `data/prompts/` directory. Each file is named `{country/region}_prompts.csv`. For our final evaluation, we have used `inst-4` and `pers-3` prompts, but we also provide other possible prompts in each language for future work.\\n\\nThe topics and source language for each question can be found in the `data/questions/` directory. Each file is named `{country/region}_questions.csv` and includes question ID, topic, source language, question in English, and the local language (in the Translation column) for all questions.\"}"}
{"id": "nrEqH502eC", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The code for retrieving answers from LLMs for the short-answer questions is provided at `model_inference.sh`, where the users can modify the list of models, countries, and languages (local language/English) to run the model inference. The results of each model's inference on the questions will be saved in default at `model_inference_results/` directory. To calculate the scores for the short-answer questions, the users can run `evaluation/evaluate.sh`.\\n\\nThe multiple-choice questions and their answers can be found at `evaluation/mc_data/mc_questions_file.csv`. Multiple-choice questions and answers are generated through the codes found at `evaluation/multiple_choice_generation.sh`. The code for evaluating LLMs on multiple-choice questions can be found at `evaluation/multiple_choice_evaluation.sh`, where the users can modify the list of models to evaluate. Users must input their API keys within these files for the required models for all evaluations.\\n\\nLicense: CC BY-SA 4.0\\n\\nMaintenance: On GitHub, we plan to continually update our code and constantly resolve any bugs and issues. We encourage contributions from community members and researchers.\\n\\nA.2 Country/Region & Language Codes\\n\\nTable 3 shows the two-letter ISO codes for each country/region and local language. We use the codes throughout the main content of the paper and the supplementary materials.\\n\\n| Country/Region | Code | Language Code |\\n|----------------|------|---------------|\\n| United States  | US   | English en    |\\n| United Kingdom | GB   | English en    |\\n| China          | CN   | Chinese zh    |\\n| Spain          | ES   | Spanish es    |\\n| Mexico         | MX   | Spanish es    |\\n| Indonesia      | ID   | Indonesian id |\\n| South Korea    | KR   | Korean ko     |\\n| North Korea    | KP   | Korean ko     |\\n| Greece         | GR   | Greek el      |\\n| Iran           | IR   | Persian fa    |\\n| Algeria        | DZ   | Arabic ar     |\\n| Azerbaijan     | AZ   | Azerbaijani az|\\n| West Java      | JB   | Sundanese su  |\\n| Assam          | AS   | Assamese as   |\\n| Northern Nigeria| NG | Hausa ha    |\\n| Ethiopia       | ET   | Amharic am    |\\n\\nA.3 Annotation Examples\\n\\nThe examples of annotations for cultural questions within each topic (i.e., food, sport, family, education, holidays, and work-life) for each country/region in our dataset are shown in Figure 5, Figure 6, Figure 7, Figure 8, Figure 9, and Figure 10 respectively. All the answers are presented in both local languages and English.\\n\\nB Construction Details of BLE\\n\\nB.1 Resource Availability of Languages\\n\\nAs illustrated in the main text, we select languages with varying levels of resource availability and recruit annotators who are native speakers of each language. The detailed resource availability of the languages included in BLE_N is shown in Table 4.\"}"}
{"id": "nrEqH502eC", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Country/Region | Street Food |\\n|----------------|-------------|\\n| US             | hot dogs: 4, hamburger: 1, tacos: 1, ... |\\n| UK             | kebabs: 2, burgers: 2, fish and chips: 2, ... |\\n| CN             | \u70e4\u80a0 (roasted sausage): 3, \u70e7\u70e4 (barbecue): 2, \u7cd6\u846b\u82a6 (candied haw): 1, ... |\\n| ES             | churros (churros): 2, patatas fritas (French fries): 1, pipas (sunflower seeds): 1, ... |\\n| MX             | tacos (tacos): 5, quesadillas (quesadillas): 3, tamales (tamales): 2, ... |\\n| ID             | cilok (cilok): 3, bakso (meatball): 2, seblak (seblak): 1, ... |\\n| KR             | \ub5a1\ubcf6\uc774 (stir-fried rice cakes): 4, \ubd09\uc5b4\ube75 (bungeoppang): 1,\ub378\ub9ac\ub9cc\uc96c (delimanjoo): 1, ... |\\n| KP             | \ub450\ubd80\ubc25 (tofu rice): 4, \uc778\uc870\uace0\uae30\ubc25 (synthetic meat rice): 2, \uae40\ubc25 (gimbap): 1, ... |\\n| GR             | \u03c0\u03b9\u03c4\u03ac\u03b3\u03c5\u03c1\u03bf (pita gyro): 3, \u03c3\u03bf\u03c5\u03b2\u03bb\u03ac\u03ba\u03b9 (souvlaki): 1, \u03c0\u03af\u03c4\u03c3\u03b1 (pizza): 1, ... |\\n| IR             | \u0641\u0644\u0648\u0642\u0648 (falafel): 2, \u0633\u0645\u0628\u0648\u0633\u0629 (samosa): 1, \u067e\u06cc\u062a\u0627\u0634\u06a9\u06cc (pastry): 1, ... |\\n| DZ             | \u0627\u0644\u0643\u0633\u0643\u0633 (couscous): 4, \u0627\u0644\u0634\u062e\u0634\u0648\u062e\u0629 (chakhchoukha): 2, \u0627\u0644\u0631\u0634\u062a\u0629 (rishta): 1, ... |\\n| JB             | \u09ab\u09c1\u099a\u09c7\u09cb (panipuri): 4, \u09ae\u09c1\u09ae (dumpling): 4, \u099a\u09cb\u09b9 (tea): 1, ... |\\n| NG             | \u8c46paste (fried bean cake): 3, gurasa (flatbread): 2, shinkafa (rice): 1, ... |\\n| ET             | \u1334.Points \u1260\u121b\u1295 \u12ed\u1240\u12cd\u120d \u12e8\u130e\u12f3\u1293 \u121d\u130d\u1265 \u12ed\u12c8\u12f3\u1209? \u123d\u121d\u1235 (chips): 4, \u1208\u6211\u4eec\u4e00\u8d77\u5403 (qollo): 2, ... |\\n\\nFigure 5: Example annotations for a cultural question related to the topic of food for each country/region in our dataset. The questions and annotations are provided in different languages, with translations of the annotated answers into English included in brackets. Annotations are sorted in descending order based on the frequency (i.e., vote count) of an answer provided by annotators, each separated by a line break. The vote count for each answer is displayed as numbers.\"}"}
{"id": "nrEqH502eC", "page_num": 24, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"What is the most popular indoor sport in the US?\\n\\n- basketball: 5\\n- hockey: 1\\n\\nWhat is the most popular indoor sport in the UK?\\n\\n- swimming: 2\\n- netball: 2\\n- badminton: 1\\n\\nWhat is the most popular indoor sport in China?\\n\\n- table tennis (ping pong): 3\\n- badminton: 2\\n- e-sports: 1\\n\\n\u00bfCu\u00e1l es el deporte de interior m\u00e1s popular en Espa\u00f1a?\\n\\n- basketball (baloncesto): 2\\n- indoor football (f\u00fatbol sala): 2\\n- 7-a-side football (f\u00fatbol 7): 1\\n\\n\u00bfCu\u00e1l es el deporte de interior m\u00e1s popular en M\u00e9xico?\\n\\n- basketball (basquetbol): 3\\n- swimming (nataci\u00f3n): 1\\n- boxing (box): 1\\n\\nApa olahraga dalam ruangan yang paling populer di Indonesia?\\n\\n- badminton (bulu tangkis): 4\\n- futsal: 2\\n- table tennis (ping pong): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uac00\uc7a5 \uc778\uae30 \uc788\ub294 \uc2e4\ub0b4 \uc2a4\ud3ec\uce20\ub294 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- table tennis (\ud0c1\uad6c): 2\\n- badminton (\ubc30\ub4dc\ubbfc\ud134): 1\\n- basketball (\ub18d\uad6c): 1\\n\\n\u00bfCu\u00e1l es el deporte de interior m\u00e1s popular en Korea?\\n\\n- table tennis (\ud0c1\uad6c): 3\\n- basketball (\ubc30\uad6c): 2\\n- volleyball (\ubc30\uad6c): 1\\n\\n\u03a0\u03bf\u03b9\u03bf \u03b5\u03af\u03bd\u03b1\u03b9 \u03c4\u03bf \u03c0\u03b9\u03bf \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ad\u03c2 \u03ac\u03b8\u03bb\u03b7\u03bc\u03b1 \u03b5\u03c3\u03c9\u03c4\u03b5\u03c1\u03b9\u03ba\u03bf\u03cd \u03c7\u03ce\u03c1\u03bf\u03c5 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- basketball (\u03bc\u03c0\u03ac\u03c3\u03ba\u03b5\u03c4): 4\\n- football (\u03c0\u03bf\u03b4\u03cc\u03c3\u03c6\u03b1\u03b9\u03c1\u03bf): 1\\n\\n\u0645\u062d\u0628\u0648\u0628\u200c\u062a\u0631\u06cc\u0646 \u0648\u0631\u0632\u0634 \u0633\u0631\u067e\u0648\u0634\u06cc\u062f\u0647 \u062f\u0631 \u0627\u06cc\u0631\u0627\u0646 \u0686\u06cc\u0633\u062a\u061f\\n\\n- volleyball (\u0648\u0627\u0644\u06cc\u0628\u0627\u0644): 2\\n- futsal (\u0641\u0648\u062a\u0633\u0627\u0644): 2\\n- basketball (\u0628\u0633\u06a9\u062a\u0628\u0627\u0644): 1\\n\\n\u0645\u0627\u200c\u0647\u064a\u200c\u0623\u0634\u0647\u0631\u200c\u0631\u06cc\u0627\u0636\u0629\u200c\u0642\u0627\u0639\u0629\u200c\u0641\u064a\u200c\u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- boxing (\u0627\u0644\u0645\u0644\u0627\u0643\u0645\u0629): 2\\n- handball (\u0643\u0631\u0629\u200c\u0627\u0644\u06cc\u062f): 1\\n- volleyball (\u0643\u0631\u0629\u200c\u0627\u0644\u0637\u0627\u0626\u0631\u0629): 1\\n\\nAz\u0259rbaycanda \u0259n populyar qapal\u0131 idman n\u00f6v\u00fc hans\u0131d\u0131r?\\n\\n- chess (\u0634\u0430\u0445\u043c\u0430\u0442): 3\\n- basketball (basketbol): 1\\n\\nNaon olahraga jero rohangan nu pang populerna di Jawa Barat?\\n\\n- badminton (bulu tangkis): 4\\n- futsal (futsal): 2\\n- table tennis (pingpong): 1\\n\\n\u0985\u09b8\u09ae\u09a4 \u0995\u09bf \u09b8\u09ac\u09be\u09a4\u09a4\u09be\u0995\u09bf \u099c\u09a8\u0995\u09bf\u09af\u09bc \u0987\u09a8\u09a1\u09bc\u09f0 \u0995\u09cd\u09b0\u09c0\u09a1\u09be \u0995\u09bf?\\n\\n- ludo (\u09b2\u09c1\u09a1\u09c1): 4\\n- carrom (\u0995\u09bf\u09f0\u09ae): 3\\n- chess (\u09a6\u09ac\u09be): 2\\n\\nWanne wasan cikin gida da aka fi so a Arewacin Najeriya?\\n\\n- football (kwallon kafa): 1\\n- riddle (kacici-kacici): 1\\n\\n\u1260\u12a2\u1275\u12ee\u1335\u12eb \u12e8\u1275\u129b\u12cd \u12d3\u12ed\u1290\u1275 \u12e8\u1264\u1275 \u12cd\u1235\u1325 \u1235\u1356\u122d\u1275 \u1260\u1323\u121d \u1273\u12cb\u1242 \u1290\u12cd? idk (I don't know): 3\\n\\n- boxing (foyoks): 1\\n\\nFigure 6: Example annotations for a cultural question related to the topic of sport for each country/region in our dataset. The questions and annotations are provided in different languages, with translations of the annotated answers into English included in brackets. Annotations are sorted in descending order based on the frequency (i.e., vote count) of an answer provided by annotators, each separated by a line break. The vote count for each answer is displayed as numbers.\"}"}
{"id": "nrEqH502eC", "page_num": 25, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"What is a popular family activity with a child to do on weekends in the US?\\n\\n- go to a park: 2\\n- bowling: 1\\n- swim: 1\\n\\nWhat is a popular family activity with a child to do on weekends in the UK?\\n\\n- go to the zoo: 2\\n- go to the park: 2\\n- walks: 1\\n\\nWhat is a popular family activity with a child to do on weekends in China?\\n\\n- go to a park (go to a park): 2\\n- shopping (shopping): 1\\n- outdoor activities (outdoor activities): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\nWhat is a popular family activity with a child to do on weekends in the USA?\\n\\n- go to the park: 2\\n- bowling: 1\\n- swim: 1\\n\\nWhat is a popular family activity with a child to do on weekends in the UK?\\n\\n- go to the zoo: 2\\n- go to the park: 2\\n- walks: 1\\n\\nWhat is a popular family activity with a child to do on weekends in China?\\n\\n- go to the park (go to a park): 2\\n- shopping (shopping): 1\\n- outdoor activities (outdoor activities): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- \u0627\u0644\u062a\u0645\u062a\u0639 (hiking): 5\\n- \u0627\u0644\u0633\u0641\u0631 (travel): 1\\n- \u0627\u0644\u0645\u062e\u0627\u0632\u0646 (party): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en Espa\u00f1a?\\n\\n- ir al parque (go to the park): 2\\n- pasear (to walk): 2\\n- jugar a videojuegos (play video games): 1\\n\\n\u00bfCu\u00e1l es una actividad familiar popular para hacer con un ni\u00f1o los fines de semana en M\u00e9xico?\\n\\n- ir al parque (go to the park): 5\\n- visitar a la abuelita (visit grandma): 1\\n- ir al cine (go to the movies): 1\\n\\nApa kegiatan keluarga yang populer untuk dilakukan bersama anak pada akhir pekan di Indonesia?\\n\\n- jalan-jalan ke mall (going to the mall): 3\\n- bersepeda (cycling): 2\\n- nonton tv (watch tv): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc8fc\ub9d0\uc5d0 \uc544\uc774\uc640 \ud568\uaed8\ud558\ub294 \uc778\uae30\uc788\ub294 \uac00\uc871 \ud65c\ub3d9\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- \uc5ec\ud589 (travel): 2\\n- \uc2a4\ud3ec\uce20 (sports): 1\\n- \ubcf4\ub4dc \uac8c\uc784 (board game): 1\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03bc\u03b9\u03b1 \u03b4\u03b7\u03bc\u03bf\u03c6\u03b9\u03bb\u03ae\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03b5\u03bd\u03b5\u03b9\u03b1\u03ba\u03ae \u03b4\u03c1\u03b1\u03c3\u03c4\u03b7\u03c1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03bc\u03b5 \u03ad\u03bd\u03b1 \u03c0\u03b1\u03b9\u03b4\u03af \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03c3\u03b1\u03b2\u03b2\u03b1\u03c4\u03bf\u03ba\u03cd\u03c1\u03b9\u03b1\u03ba\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- \u03b2\u03cc\u03bb\u03c4\u03b1 (stroll): 1\\n- \u03ba\u03b9\u03bd\u03b7\u03bc\u03b1\u03c4\u03bf\u03b3\u03c1\u03ac\u03c6\u03bf\u03c2 (cinema): 1\\n- \u03c0\u03b1\u03b9\u03b4\u03b9\u03ba\u03ae \u03c7\u03b1\u03c1\u03ac (playground): 1\\n\\n\u062f\u0631\u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u0641\u0639\u0627\u0644\u06cc\u062a \u062e\u0627\u0646\u0648\u0627\u062f\u06af\u06cc \u0645\u062d\u06cc\u0637 \u0628\u0627 \u0641\u0631\u0632\u0646\u062f \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0631 \u0622\u062e\u0631 \u0647\u0641\u062a\u0647 \u0647\u0627 \u0686\u06cc\u0633\u062a\u061f\\n\\n- \u067e\u06cc\u06a9\u0646\u06cc\u06a9 \u062f\u0631 \u067e\u0627\u0631\u06a9 (picnic in the park): 1\\n- \u0633\u0641\u0631 (travel): 1\\n- \u0645\u0647\u0645\u0627\u0646\u06cc (party): 1\\n\\n\u0645\u0627 \u0647\u064a \u0627\u0644\u0646\u0634\u0627\u0637\u0627\u062a \u0627\u0644\u0639\u0627\u0626\u0644\u064a\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0627\u0644\u062a\u064a \u064a\u0645\u0643\u0646 \u0627\u0644\u0642\u064a\u0627\u0645 \u0628\u0647\u0627 \u0645\u0639 \u0627\u0644\u0623\u0637\u0641\u0627\u0644 \u0641\u064a \u0639\u0637\u0644\u0629 \u0646\u0647\u0627\u064a\u0629 \u0627\u0644\u0623\u0633\u0628\u0648\u0639 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n-"}
{"id": "nrEqH502eC", "page_num": 26, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"What language is taught in schools in the US besides English?\\n- spanish: 5\\n- french: 3\\n- german: 2\\n- ...\\n\\nWhat language is taught in schools in the UK besides English?\\n- spanish: 3\\n- french: 5\\n- german: 2\\n- ...\\n\\n\u5728\u4e2d\u56fd\u7684\u5b66\u6821\u91cc\u9664\u4e86\u82f1\u8bed\u4e4b\u5916\u8fd8\u6559\u6388\u54ea\u79cd\u8bed\u8a00?\\n- \u6c49\u8bed (chinese): 4\\n\\n\u00bfQu\u00e9 idioma se ense\u00f1a en las escuelas de Espa\u00f1a adem\u00e1s del ingl\u00e9s?\\n- franc\u00e9s (french): 5\\n- latin (latin): 2\\n- alem\u00e1n (german): 1\\n- ...\\n\\n\u00bfQu\u00e9 idioma se ense\u00f1a en las escuelas de M\u00e9xico adem\u00e1s del ingl\u00e9s?\\n- franc\u00e9s (french): 4\\n- espa\u00f1ol (spanish): 2\\n- nahuatl (nahuatl): 1\\n- ...\\n\\nBahasa apa yang diajarkan di sekolah-sekolah di Indonesia selain Bahasa Inggris?\\n- bahasa Indonesia (indonesian): 2\\n- mandarin (mandarin): 2\\n- bahasa daerah (regional language): 1\\n- ...\\n\\n\ub300\ud55c\ubbfc\uad6d\uc758\ud559\uad50\uc5d0\uc11c \ud559\uc0dd\ub4e4\uc740 \uc601\uc5b4 \uc678\uc5d0 \uc5b4\ub5a4 \uc678\uad6d\uc5b4\ub97c \ubc30\uc6c1\ub2c8\uae4c?\\n- \uc77c\ubcf8\uc5b4 (japanese): 4\\n- \uc911\uad6d\uc5b4 (chinese): 3\\n- \ubd88\uc5b4 (french): 1\\n- ...\\n\\n\u03a0\u03bf\u03b9\u03b1 \u03b3\u03bb\u03ce\u03c3\u03c3\u03b1 \u03b4\u03b9\u03b4\u03ac\u03c3\u03ba\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03b1 \u03c3\u03c7\u03bf\u03bb\u03b5\u03af\u03b1 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1 \u03c0\u03ad\u03c1\u03b1 \u03b1\u03c0\u03cc \u03c4\u03b1 \u0391\u03b3\u03b3\u03bb\u03b9\u03ba\u03ac;\\n- \u03b3\u03b5\u03c1\u03bc\u03b1\u03bd\u03b9\u03ba\u03ac (german): 5\\n- \u03b3\u03b1\u03bb\u03bb\u03b9\u03ba\u03ac (french): 5\\n- \u03b5\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac (greek): 1\\n- ...\\n\\n\u062f\u0631\u06cc\u0631\u0627\u0646 \u0628\u0647 \u062c\u0632 \u0627\u0646\u06af\u0644\u06cc\u0633\u06cc\u060c \u0686\u0647 \u0632\u0628\u0627\u0646\u200c\u0647\u0627\u06cc\u06cc \u062f\u0631 \u0645\u062f\u0627\u0631\u0633 \u062a\u062f\u0631\u06cc\u0633 \u0645\u06cc\u200c\u0634\u0648\u062f\u061f\\n- \u0639\u0631\u0628\u06cc (arabic): 4\\n- \u0627\u0646\u06af\u0644\u06cc\u0633\u06cc (english): 1\\n- \u0641\u0631\u0627\u0646\u0633\u0647 (france): 1\\n- ...\\n\\n\u0623\u064a \u0644\u063a\u0629 \u062a\u064f\u062f\u0631\u064e\u0651\u0633 \u0641\u064a \u0627\u0644\u0645\u062f\u0627\u0631\u0633 \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u06cc\u0629 \u0628\u0627\u0644\u0625\u0636\u0627\u0641\u0629 \u0625\u0644\u0649 \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0625\u0646\u062c\u0644\u06cc\u0632\u06cc\u0629\u061f\\n- \u0627\u0644\u0641\u0631\u0646\u0633\u06cc\u0629 (french): 5\\n\\nAz\u0259rbaycanda m\u0259kt\u0259bl\u0259rd\u0259 ingilis dilind\u0259n ba\u015fqa hans\u0131 dill\u0259r t\u0259dris edilir?\\n- rus dili (russian): 5\\n- alman dili (german): 2\\n- frans\u0131z dili (french): 1\\n- ...\\n\\nBasa naon nu diajarkeun di sakola-sakola di Jawa Barat salian ti Basa Inggris?\\n- basa Indonesia (indonesian language): 4\\n- basa sunda (sundanese language): 2\\n- jepang (japanese language): 2\\n- ...\\n\\n\u0985\u09b8\u09ae\u09f0 \u09ac\u09bf\u09a6\u09cd\u09af\u09be\u09b2\u09af\u09bc\u09b8\u09ae\u09c2\u09b9\u09a4 \u0987\u0982\u09f0\u09be\u099c\u09c0\u09f0 \u0989\u09aa\u09ac\u09f0\u0993 \u0986\u09a8 \u0995\u09be\u09a8 \u09ad\u09be\u09f0\u09b7\u09be \u09ac\u09bf\u0995\u09cd\u09b7\u09be \u09ac\u09a6\u09cd\u09af\u09bc\u09be \u09b9\u09af\u09bc?\\n- \u09ac\u0982\u09a3\u09bf (hindi): 5\\n- \u09b8\u0982\u09b8\u09cd\u0995\u09c3\u09a4 (sanskrit): 2\\n- \u0985\u09b8\u09ae\u09c0\u09af\u09bc\u09be (assamese): 2\\n- ...\\n\\nWane yare ake koyarwa a makarantun Arewacin Najeriya bandan Turanci?\\n- hausa (hausa): 4\\n- larabci (arabic): 4\"}"}
{"id": "nrEqH502eC", "page_num": 27, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"On which holiday do all family members tend to reunite in the US?\\n\\n- **Thanksgiving**: 4\\n- **Christmas**: 2\\n\\nOn which holiday do all family members tend to reunite in the UK?\\n\\n- **Christmas**: 5\\n\\nIn China, which festival do all family members tend to reunite?\\n\\n- **Spring Festival (Chinese New Year)**: 4\\n- **Mid Autumn Festival**: 4\\n- **Qingming (Tomb Sweeping Day)**: 1\\n\\n\u00bfEn qu\u00e9 festividad suelen reunirse todos los miembros de la familia en Espa\u00f1a?\\n\\n- **Christmas**: 3\\n- **Christmas Eve**: 2\\n- **New Year's Eve**: 2\\n\\n\u00bfEn qu\u00e9 festividad suelen reunirse todos los miembros de la familia en M\u00e9xico?\\n\\n- **Christmas**: 5\\n- **New Year**: 3\\n- **September 16th**: 1\\n\\nPada hari libur apa semua anggota keluarga biasanya berkumpul di Indonesia?\\n\\n- **Idul Fitri (Eid Al-Fitr)**: 4\\n- **Christmas**: 3\\n- **New Year**: 2\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \ubaa8\ub4e0 \uac00\uc871 \uad6c\uc131\uc6d0\ub4e4\uc774 \ud568\uaed8 \ubaa8\uc774\ub294 \uba85\uc808\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- **\ucd94\uc11d (Chuseok)**: 5\\n- **\uc124\ub0a0 (Lunar New Year)**: 5\\n\\n\u03a3\u03b5 \u03c0\u03bf\u03b9\u03b1 \u03b5\u03bf\u03c1\u03c4\u03ae \u03c3\u03c5\u03bd\u03b7\u03b8\u03af\u03b6\u03bf\u03c5\u03bd \u03bf\u03bb\u03cc\u03ba\u03bb\u03b7\u03c1\u03b1 \u03c4\u03b1 \u03bc\u03ad\u03bb\u03b7 \u03c4\u03b7\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03ad\u03bd\u03b5\u03b9\u03b1\u03c2 \u03bd\u03b1 \u03b5\u03c0\u03b1\u03bd\u03b1\u03c3\u03c5\u03bd\u03b4\u03ad\u03bf\u03bd\u03c4\u03b1\u03b9 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- **Pascha (Easter)**: 4\\n- **Christmas**: 3\\n- **Birthday**: 1\\n\\n\u00bfEn qu\u00e9 festividad suelen reunirse todos los miembros de la familia en M\u00e9xico?\\n\\n- **Christmas**: 3\\n- **New Year**: 1\\n- **September 16th**: 1\\n\\n\u03a3\u03b5 \u03c0\u03bf\u03b9\u03b1 \u03b5\u03bf\u03c1\u03c4\u03ae \u03c3\u03c5\u03bd\u03b7\u03b8\u03af\u03b6\u03bf\u03c5\u03bd \u03bf\u03bb\u03cc\u03ba\u03bb\u03b7\u03c1\u03b1 \u03c4\u03b1 \u03bc\u03ad\u03bb\u03b7 \u03c4\u03b7\u03c2 \u03bf\u03b9\u03ba\u03bf\u03b3\u03ad\u03bd\u03b5\u03b9\u03b1\u03c2 \u03bd\u03b1 \u03b5\u03c0\u03b1\u03bd\u03b1\u03c3\u03c5\u03bd\u03b4\u03ad\u03bf\u03bd\u03c4\u03b1\u03b9 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- **Pascha (Easter)**: 4\\n- **Christmas**: 3\\n- **Birthday**: 1\\n\\nIn which festival do all family members tend to reunite in Iran?\\n\\n- **New Year (Gregorian New Year)**: 1\\n- **Chaharshanbe Suri (Fourteen of Shahr)**: 1\\n- **Nature's Day (Siyah e Saba or 13th of Soltani)**: 1\\n\\n\u00bfEn qu\u00e9 festividad suelen reunirse todos los miembros de la familia en Algeria?\\n\\n- **Eid al-Fitr (Idul Fitri)**: 5\\n- **Eid al-Adha (Idul Azha)**: 4\\n- **New Year**: 1\\n\\nAz\u0259rbaycanda ail\u0259 \u00fczvl\u0259ri hans\u0131 bayramda bir araya g\u0259lirl\u0259r?\\n\\n- **Novruz**: 5\\n- **New Year**: 1\\n\\nDina liburan naon sadaya anggota kulawarga biasana ngariung deui di Jawa Barat?\\n\\n- **Idul Fitri (Eid Al-Fitr)**: 4\\n- **Idul Adha (Eid Al-Adha)**: 1\\n- **Christmas**: 1\\n\\nIn Assam, which festival do all family members usually get together?\\n\\n- **Bihu (Chadu)**: 5\\n- **Puja**: 1\\n- **Durga Puja**: 2\\n\\nIn Nigeria, what festival do all family members usually get together?\\n\\n- **Eid Holiday**: 4\\n- **Christmas**: 3\\n\\nIn Ethiopia, in which festival do all family members usually get together?\\n\\n- **Easter**: 2\\n- **Ramadan**: 1\\n- **New Year**: 1\"}"}
{"id": "nrEqH502eC", "page_num": 28, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"What is regarded as the most important perk typically offered to employees in the US?\\n\\n- vacation: 3\\n- healthcare: 3\\n- benefits: 1\\n\\nWhat is regarded as the most important perk typically offered to employees in the UK?\\n\\n- bonus: 2\\n- free lunches: 1\\n- pension: 1\\n\\nIn China, usually considered the most important benefit given to employees is:\\n\\n- five insurances and one fund (\u4e94\u9669\u4e00\u91d1): 3\\n- weekends off (\u53cc\u4f11): 2\\n- annual leave (\u5e74\u5047): 1\\n\\n\u00bfCu\u00e1l se considera el beneficio m\u00e1s importante que se ofrece t\u00edpicamente a los empleados en Espa\u00f1a?\\n\\n- social security (la seguridad social): 2\\n- salary (salario): 1\\n- free time (tiempo libre): 1\\n\\n\u00bfCu\u00e1l se considera el beneficio m\u00e1s importante que se ofrece t\u00edpicamente a los empleados en M\u00e9xico?\\n\\n- Mexican social security institute (imss): 2\\n- paid vacations (vacaciones pagadas): 2\\n- retirement fund administration companies (afore): 1\\n\\nApa yang dianggap sebagai keuntungan paling penting yang biasanya ditawarkan kepada karyawan di Indonesia?\\n\\n- salary (gaji): 3\\n- religious holiday allowance (thr): 1\\n- annual bonus (bonus tahunan): 1\\n\\n\ub300\ud55c\ubbfc\uad6d\uc5d0\uc11c \uc77c\ubc18\uc801\uc73c\ub85c \uc9c1\uc6d0\ub4e4\uc5d0\uac8c \uc81c\uacf5\ub418\ub294 \ud61c\ud0dd \uc911 \uac00\uc7a5 \uc911\uc694\ud558\uac8c \uc5ec\uaca8\uc9c0\ub294 \uac83\uc740 \ubb34\uc5c7\uc778\uac00\uc694?\\n\\n- bonus (\ubcf4\ub108\uc2a4): 2\\n- employee discount (\uc9c1\uc6d0 \ud560\uc778): 2\\n- vacation (\ud734\uac00): 1\\n\\n\u03a0\u03bf\u03b9\u03bf \u03b8\u03b5\u03c9\u03c1\u03b5\u03af\u03c4\u03b1\u03b9 \u03c4\u03bf \u03c3\u03b7\u03bc\u03b1\u03bd\u03c4\u03b9\u03ba\u03cc\u03c4\u03b5\u03c1\u03bf \u03c0\u03c1\u03bf\u03bd\u03cc\u03bc\u03b9\u03bf \u03c0\u03bf\u03c5 \u03c3\u03c5\u03bd\u03ae\u03b8\u03c9\u03c2 \u03c0\u03c1\u03bf\u03c3\u03c6\u03ad\u03c1\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03bf\u03c5\u03c2 \u03b5\u03c1\u03b3\u03b1\u03b6\u03bf\u03bc\u03ad\u03bd\u03bf\u03c5\u03c2 \u03c3\u03c4\u03b7\u03bd \u0395\u03bb\u03bb\u03ac\u03b4\u03b1;\\n\\n- insurance (\u03b1\u03c3\u03c6\u03ac\u03bb\u03b9\u03c3\u03b7): 2\\n- short breaks (\u03ba\u03bf\u03bd\u03c4\u03b9\u03bd\u03ad\u03c2 \u03b4\u03b9\u03b1\u03ba\u03bf\u03c0\u03ad\u03c2): 1\\n- days off (\u03ac\u03b4\u03b5\u03b9\u03b1): 1\\n\\n\u062f\u0631 \u0627\u06cc\u0631\u0627\u0646 \u0645\u0647\u0645\u200c\u062a\u0631\u06cc\u0646 \u0645\u0632\u06cc\u062a\u06cc \u06a9\u0647 \u0645\u0639\u0645\u0648\u0644\u0627\u064b \u0628\u0647 \u06a9\u0627\u0631\u0645\u0646\u062f\u0627\u0646 \u0627\u0631\u0627\u0626\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f\u060c \u0686\u06cc\u0633\u062a\u061f\\n\\n- insurance (\u0628\u06cc\u0645\u0647): 2\\n- pension (\u062d\u0642\u0648\u0642 \u0628\u0627\u0632\u0646\u0634\u0633\u062a\u06af\u06cc): 1\\n- overtime bonus (\u067e\u0627\u062f\u0627\u0634 \u0627\u0636\u0627\u0641\u0647 \u06a9\u0627\u0631): 1\\n\\n\u0645\u0627 \u0647\u064a \u0623\u0647\u0645 \u0645\u064a\u0632\u0629 \u062a\u064f\u0642\u062f\u0645 \u0639\u0627\u062f\u0629\u064b \u0644\u0644\u0645\u0648\u0638\u0641\u06cc\u0646 \u0641\u064a \u0627\u0644\u062c\u0632\u0627\u0626\u0631\u061f\\n\\n- salary (\u0627\u0644\u0631\u0627\u062a\u0628): 2\\n- allowance (\u0627\u0644\u0639\u0644\u0627\u0648\u0629): 2\\n- official car (\u0633\u064a\u0627\u0631\u0629 \u0648\u0638\u06cc\u0641\u0629): 1\\n\\nAz\u0259rbaycanda i\u015f\u00e7il\u0259r\u0259 ad\u0259t\u0259n t\u0259klif edil\u0259n \u0259n \u00f6n\u0259mli imtiyaz n\u0259 hesab olunur?\\n\\n- long vacation (uzun m\u0259zuniyy\u0259t): 1\\n- promotion (r\u00fctb\u0259 art\u0131m\u0131): 1\\n- salary (maa\u015f): 1\\n\\nNaon nu dianggap minangka kauntungan pang pentingna nu biasana ditawarkeun ka karyawan di Jawa Barat?\\n\\n- health insurance (asuransi kasihata): 2\\n- salary (gajih): 1\\n- bonus (bonus): 1\\n\\nApa yang dianggap minangka kauntungan pangpenting na bashi mabii\u00f1na ditawar ke karyawan di Jawa Barat?\\n\\n- health insurance (\u5065\u5eb7\u4fdd\u9669): 2\\n- free treatment (\u514d\u8d39\u6cbb\u7597): 1\\n- salary (\u5de5\u8d44): 1\\n\\nMenene ake matsayin mafi muhimmancin alawus da ake bayarwa ga ma\u2019aikata a Arewacin Najeriya?\\n\\n- money (ku\u0257i): 2\\n- allowance (_allowance): 1\\n- bonus (_bonus): 1\\n\\n\u1260\u12a2\u1275\u12ee\u1335\u12eb \u1208\u1220\u122b\u1270\u129e\u127d \u1270\u1208\u12ed\u1276 \u12e8\u121a\u1240\u122d\u1265 \u12a5\u1293 \u12a5\u1305\u130d \u12cb\u1293 \u12ed\u12c8\u1290 \u1270\u1328\u121b\u122a \u12a0\u1260\u120d \u121d\u1295\u12f5\u1290\u12cd?\\n\\n- housing allowance (housing allowance): 2\\n- allowance (_allowance): 1\\n- bonus (_bonus): 1\\n\\nFigure 10: Example annotations for a cultural question related to the topic of work life for each country/region in our dataset. The questions and annotations are provided in different languages, with translations of the annotated answers into English included in brackets. Annotations are sorted in descending order based on the frequency (i.e., vote count) of an answer provided by annotators, each separated by a line break. The vote count for each answer is displayed as numbers.\"}"}
{"id": "nrEqH502eC", "page_num": 29, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Resource availability of the 13 languages covered in BLE\\n\\n| Class                        | Languages                      |\\n|-----------------------------|--------------------------------|\\n| 1 - The Left-Behinds        | Assamese, Azerbaijani, Sundanese|\\n| 2 - The Hopefuls            | Amharic, Hausa                 |\\n| 3 - The Rising Stars         | Greek, Indonesian              |\\n| 4 - The Underdogs           | Korean, Persian                |\\n| 5 - The Winners             | Arabic, Chinese (Mandarin), English, Spanish |\\n\\nTable 5: Annotator demographics for each country or region who are recruited via Prolific.\\n\\n| US  | GB  | CN  | ES  | ID  | GR  | MX  | IR  |\\n|-----|-----|-----|-----|-----|-----|-----|-----|\\n| No. of Annotators             | 87  | 119 | 59  | 91  | 40  | 86  | 86  | 50  |\\n| Gender (%)                    |     |     |     |     |     |     |     |     |\\n| Female                       | 42.53 | 46.22 | 55.93 | 49.45 | 50.00 | 45.35 | 48.84 | 56.00 |\\n| Male                         | 52.87 | 49.58 | 44.07 | 49.45 | 50.00 | 54.65 | 48.84 | 42.00 |\\n| Non-binary                   | 4.60  | 2.52  | -   | 1.10  | -   | -   | 2.33  | 2.00  |\\n| Prefer not to say            | -    | 1.68  | -   | -    | -   | -   | -    | -    |\\n| Age (%)                      |     |     |     |     |     |     |     |     |\\n| -29                          | 36.78 | 13.45 | 64.41 | 41.76 | 45.00 | 50.00 | 59.30 | 48.00 |\\n| 30-39                        | 19.54 | 26.89 | 25.42 | 23.08 | 35.00 | 29.07 | 26.74 | 44.00 |\\n| 40-49                        | 17.24 | 21.01 | 3.39  | 18.68 | 12.50 | 13.95 | 8.14  | 8.00  |\\n| 50-59                        | 14.94 | 21.85 | 6.78  | 14.29 | 7.50  | 6.98  | 4.65  | -    |\\n| 60+                          | 11.49 | 16.81 | -    | 2.20  | -    | -    | 1.16  | -    |\\n| Duration of Residence in Target Country (%) |     |\\n| 100%                         | 55.17 | 75.63 | 1.69  | 75.82 | 5.00  | 86.05 | 75.58 | 8.00  |\\n| \u2265 90%                        | 9.20  | 7.56  | 28.81 | 10.99 | 25.00 | 1.16  | 16.28 | 34.00 |\\n| \u2265 80%                        | 13.79 | 5.04  | 23.73 | 5.49  | 20.00 | 6.98  | 2.33  | 22.00 |\\n| \u2265 70%                        | 6.90  | 3.36  | 15.25 | 5.49  | 17.50 | 5.81  | 4.65  | 20.00 |\\n| \u2265 60%                        | 9.20  | 5.04  | 25.42 | 2.20  | 12.50 | -    | 1.16  | 10.00 |\\n| \u2265 50%                        | 5.75  | 2.52  | 5.08  | -    | 20.00 | -    | -    | 6.00  |\\n| Education Level (%)          |     |     |     |     |     |     |     |     |\\n| Below High School            | -    | 0.84  | -    | 3.30  | -    | -    | -    | 2.00  |\\n| High School                  | 11.49 | 12.61 | 6.78  | 12.09 | 20.00 | 13.95 | 15.12 | 4.00  |\\n| College                      | 22.99 | 21.85 | 3.39  | 16.48 | 2.50  | 11.63 | 4.65  | 10.00 |\\n| Bachelor                     | 47.13 | 48.74 | 35.59 | 40.66 | 30.00 | 40.70 | 66.28 | 32.00 |\\n| Master's Degree              | 18.39 | 13.45 | 38.98 | 21.98 | 40.00 | 25.58 | 11.63 | 46.00 |\\n| Doctorate                    | -    | 2.52  | 15.25 | 5.49  | 7.50  | 8.14  | 2.33  | 6.00  |\\n\\nB.2 Ethical Considerations of Annotator Recruitment\\n\\nThis research project was performed under approval from KAIST IRB (KH2023-226). We obtained 'Informed Consent for Human Subjects' from the annotators. We embedded the consent document within the annotation website for the crowdworkers or received written consent from the directly recruited annotators. The annotations were gathered only from those who had read and consented to the form. We recruited annotators without any discrimination based on age, ethnicity, disability, or gender. Workers were compensated at a rate exceeding Prolific's ethical standards. These same standards were applied to workers directly recruited for the annotation of low-resource languages. Participants could voluntarily decide to join or withdraw from the study, and any data provided would not be used for research purposes if they withdraw. Additionally, the annotators were notified that if an unexpected situation arises during participation, appropriate actions will be taken according to the situation, and documents complying with the requirements of the KAIST IRB will be promptly prepared and reported.\\n\\nhttps://www.prolific.com/resources/how-much-should-you-pay-research-participants\"}"}
{"id": "nrEqH502eC", "page_num": 30, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 6: Annotator demographics for each country or region who are recruited directly.\\n\\n| No. of Annotators | Gender (%):     |          |          |          |          |          |\\n|-------------------|-----------------|----------|----------|----------|----------|----------|\\n|                   | Female:         | 60.00    | 40.00    | 40.00    | 80.00    | 40.00    |\\n|                   | Male:           | 40.00    | 60.00    | 60.00    | 20.00    | 60.00    |\\n|                   | Non-binary:     |          |          |          |          |          |\\n|                   | Prefer not to say: |          |          |          |          |          |\\n|                   | Age:            |          |          |          |          |          |\\n|                   | 29-39:          | 60.00    | 20.00    | 100.00   |          | 100.00   |\\n|                   | 30-39:          |          | 60.00    |          |          | 40.00    |\\n|                   | 40-49:          |          |          | 40.00    |          |          |\\n|                   | 50-59:          | 40.00    | 20.00    |          | 60.00    |          |\\n|                   | 60+:            |          |          |          |          |          |\\n\\n| Duration of Residence in Target Country (%): |\\n|---------------------------------------------|\\n| 100%:                                        |\\n| \u226590%:                                        |\\n| \u226580%:                                        |\\n| \u226570%:                                        |\\n| \u226560%:                                        |\\n| \u226550%:                                        |\\n| <50%:                                        |\\n\\nEducation Level (%):\\n\\n| Below High School: | High School: | College: | Bachelor: | Master's Degree: | Doctorate: |\\n|--------------------|--------------|----------|-----------|------------------|-----------|\\n|                    | 60.00        | -        | 80.00     | 40.00            | -         |\\n\\nB.3 Annotator Demographics\\n\\nThe statistics of all annotators participating in our dataset construction are shown in Table 5 and 6.\"}"}
{"id": "nrEqH502eC", "page_num": 31, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 7: Average of maximum votes among all answers for each question in different categories across countries. A value of '3.00' indicates that, on average, three annotators provided the same answer for each question.\\n\\n| Category | US   | GB   | ES   | MX   | ID   | CN   | KR   | DZ   | GR   | IR   | KP   | AZ   | JB   | AS   | NG   | ET   |\\n|----------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|\\n| Food     | 3.12 | 3.14 | 2.99 | 3.27 | 2.93 | 2.67 | 3.28 | 3.29 | 2.91 | 2.99 | 2.61 | 3.19 | 3.01 | 3.14 | 2.72 | 3.04 |\\n| Sport    | 3.35 | 3.47 | 3.57 | 3.53 | 3.59 | 3.07 | 3.57 | 3.09 | 3.30 | 3.59 | 2.89 | 3.24 | 3.47 | 2.97 | 2.98 | 3.18 |\\n| Family   | 3.17 | 3.40 | 3.17 | 3.16 | 3.16 | 3.08 | 3.40 | 2.94 | 3.19 | 3.17 | 2.81 | 3.25 | 2.94 | 3.19 | 2.65 | 2.78 |\\n| Education| 3.24 | 3.26 | 3.30 | 3.19 | 3.21 | 3.25 | 3.63 | 3.18 | 3.29 | 3.20 | 3.27 | 3.42 | 3.45 | 3.10 | 2.94 | 3.23 |\\n| Holidays | 3.09 | 3.33 | 3.18 | 3.28 | 3.14 | 3.04 | 3.60 | 3.04 | 2.98 | 3.20 | 3.07 | 3.27 | 3.10 | 2.92 | 2.60 | 3.12 |\\n| Work-life| 3.10 | 3.19 | 3.09 | 3.00 | 3.22 | 3.15 | 3.57 | 3.31 | 2.87 | 3.09 | 3.01 | 3.59 | 3.10 | 3.25 | 2.75 | 3.12 |\\n| Overall  | 3.18 | 3.29 | 3.22 | 3.25 | 3.20 | 3.02 | 3.50 | 3.15 | 3.08 | 3.21 | 2.93 | 3.31 | 3.18 | 3.08 | 2.78 | 3.09 |\\n\\nB.4 Question Construction Guidelines\\n\\nBelow are the annotation guidelines for creating the question templates in BLE.\\n\\nThe goal of this task is to write question-and-answer pairs that ask about your country's culture. In each spreadsheet, you need to write down the questions and the corresponding answers to each question. Write them down in your native language, and add their translation into English too in the spreadsheet provided.\\n\\nPlease find below a few guidelines to take into account when writing the questions:\\n\\n- Questions and answers should be a culture specific question related to your culture (can be a common sense question). For example, a question related to the sport topic could be \\\"What is the most popular sport in your country?\\\". You should refrain from writing factual questions as much as possible.\\n- Do not generate yes or no questions or answers that only have two options (e.g. male or female). You could convert a yes or no question to a question starting with question words. Instead of asking \\\"'Do people in your country tend to get off work at 5:30 pm?\\\"., you may ask \\\"What time do people in your country tend to get off work?\\\".\\n- Please write questions distinct from each other as much as possible under each topic.\\n- The answer should be short and concrete. It is better to use precise concepts, entities, time, etc. to answer each question.\\n- Please avoid asking questions about a very stereotypical topic. For instance, avoid questions like \\\"Who bears more responsibility for taking care of children at home in your country?\\\"\\n\\nB.5 Answer Annotation Guidelines\\n\\nFigure 11 shows the annotation guidelines given to the annotators for all countries/regions. We provided guidelines, all in their local languages.\\n\\nB.6 Answer Annotation Interface\\n\\nFigure 12 shows the annotation interface shown to the crowdworkers annotators in Prolific. We used an Excel sheet for annotators recruited by direct recruitment for the annotations (i.e., for low-resource languages).\\n\\nB.7 Annotation Analysis\\n\\nTable 7 shows the level of agreement between the annotators, calculated by averaging the maximum votes among answers for each question in different categories across countries. Additionally, Table 8 shows the average number of answers per questions per categories across countries. Lastly, Table 9 shows the average number of I don't know per questions per categories across countries.\"}"}
{"id": "nrEqH502eC", "page_num": 32, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 8: Average number of annotations for each question in different categories across countries.\\n\\nA value of '3.00' indicates that, on average, three answers were provided as the answer for each question.\\n\\n| Category    | US     | GB     | ES     | MX     | ID     | CN     | KR     | DZ     | GR     | IR     | KP     | AZ     | JB     | AS     | NG     | ET     |\\n|-------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|\\n| Food        | 4.93   | 4.40   | 4.80   | 5.36   | 5.03   | 4.64   | 3.48   | 3.15   | 4.54   | 4.53   | 4.21   | 3.30   | 3.94   | 5.20   | 3.23   | 3.02   |\\n| Sport       | 4.06   | 3.82   | 3.60   | 3.49   | 3.72   | 4.13   | 2.72   | 2.13   | 3.25   | 3.16   | 3.58   | 2.14   | 2.55   | 3.90   | 2.16   | 2.00   |\\n| Family      | 4.41   | 3.44   | 3.71   | 4.78   | 4.32   | 3.81   | 2.84   | 2.38   | 3.38   | 3.43   | 3.60   | 2.86   | 2.48   | 4.46   | 2.63   | 2.59   |\\n| Education   | 3.93   | 3.23   | 3.49   | 3.90   | 3.89   | 3.57   | 2.81   | 2.55   | 3.32   | 3.25   | 3.52   | 2.71   | 3.11   | 4.74   | 2.94   | 2.49   |\\n| Holidays    | 4.40   | 3.62   | 3.77   | 4.40   | 4.15   | 4.04   | 2.41   | 2.42   | 3.57   | 3.41   | 3.20   | 2.46   | 3.12   | 5.14   | 2.49   | 2.57   |\\n| Work Life   | 4.44   | 3.93   | 3.71   | 4.44   | 4.28   | 4.10   | 2.54   | 2.84   | 3.63   | 3.84   | 3.60   | 2.49   | 3.09   | 4.21   | 2.74   | 2.56   |\\n| Overall     | 4.38   | 3.77   | 3.89   | 4.41   | 4.25   | 4.08   | 2.83   | 2.60   | 3.66   | 3.64   | 3.64   | 2.67   | 3.10   | 4.65   | 2.71   | 2.55   |\\n\\nC. Experimental Settings for LLM Evaluation\\n\\nC.1 Models\\n\\nWe use GPT-4 ([gpt-4-1106-preview](https://platform.openai.com/docs/models)), GPT-3.5 ([gpt-3.5-turbo-1106](https://platform.openai.com/docs/models)), Claude-3-Opus ([claude-3-opus-20240229](https://www.anthropic.com/api)), Claude-3-Sonnet ([claude-3-sonnet-20240229](https://www.anthropic.com/api)), Claude-3-Haiku ([claude-3-haiku-20240307](https://www.anthropic.com/api)), Llama-3.1-70B ([Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct)), PaLM2 ([text-bison-002](https://www.anthropic.com/api)), Gemini-1.0-Pro ([https://docs.cohere.com/reference/about](https://docs.cohere.com/reference/about)), C4AI Command R+ ([https://huggingface.co/CohereForAI/c4ai-command-r-v01](https://huggingface.co/CohereForAI/c4ai-command-r-v01)).\"}"}
{"id": "nrEqH502eC", "page_num": 33, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 12: Annotation interface given to the annotators.\\n\\nTable 9: Average number of \u2018I don\u2019t know\u2019 for each question in different categories across countries. A value of \u20181.00\u2019 indicates that, on average, one of the annotators failed to provide the answer to the question.\\n\\n| Category     | US  | GB  | ES  | MX  | ID  | CN  | KR  | DZ  | GR  | IR  | KP  | AZ  | JB  | AS  | NG  | ET  |\\n|--------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\\n| Food         | 0.80| 0.71| 0.49| 0.36| 0.56| 0.68| 0.23| 1.00| 0.52| 0.90| 1.24| 0.58| 1.15| 0.54| 1.69| 0.81|\\n| Sport        | 1.58| 1.70| 1.22| 1.11| 1.08| 0.92| 0.31| 1.65| 1.41| 1.67| 1.44| 1.64| 1.69| 1.01| 2.16| 1.53|\\n| Family       | 1.24| 1.24| 1.03| 0.51| 0.92| 0.81| 0.40| 1.33| 1.13| 1.29| 1.30| 0.71| 1.59| 0.63| 2.13| 1.16|\\n| Education    | 0.92| 1.02| 0.83| 0.39| 0.48| 0.37| 0.24| 0.82| 0.58| 0.52| 0.51| 0.37| 0.69| 0.25| 1.42| 0.61|\\n| Holidays     | 1.42| 1.50| 1.33| 0.71| 0.68| 1.23| 0.88| 1.91| 1.24| 1.38| 1.80| 1.25| 1.47| 0.93| 2.48| 1.10|\\n| Work Life    | 0.71| 1.10| 0.91| 0.63| 0.43| 0.69| 0.49| 0.62| 1.13| 1.16| 1.29| 0.60| 1.22| 0.63| 1.59| 0.68|\\n| Total        | 1.11| 1.20| 0.95| 0.62| 0.69| 0.79| 0.42| 1.24| 0.98| 1.15| 1.27| 0.87| 1.29| 0.67| 1.91| 0.98|\\n\\n1.5-72B/32B/14B-Chat [5], SeaLLM-7B-v2.5 [23], HyperCLOVA X [34], Aya-23 [4] and Aya-101 [37] for evaluation of cultural sensitivity of LLMs.\\n\\n8 Quadro RTX 8000 48GB were used with CUDA version 11.8 for all experiments. For all models, we use greedy decoding (temperature=0, top_p=1.0). We use the PyTorch library for all experiments.\\n\\nC.2 Short Answer Question\\nC.2.1 Prompt for Short Answer Evaluation\\nWe use two types of prompts to evaluate the LLMs in short answer settings: 1) directly ask LLMs to provide the answer and 2) add persona to the LLMs to make them act as a person from the target country or region. The details of each prompt are as follows:\\n\\nPROMPT #1:\\nRead the following question and provide a single answer without any explanations.\"}"}
{"id": "nrEqH502eC", "page_num": 34, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Question: {QUESTION}\\n\\nAnswer:\\n\\nPROMPT #2:\\nYou are a person from {COUNTRY/REGION} who is trying to explain your country's culture to a foreigner. Answer the following question, providing a single answer without any explanations.\\n\\nC.2.2 Details of Short Answer Evaluation\\n\\nLet $Q$ denote the question set, $A_q$ the annotated answer set for each question $q \\\\in Q$, with each answer $a \\\\in A_q$, for a question $q$ in the country or region $c$ in the human annotation. For any LLM prediction $y$, we define $s_{q,c}(y)$ as\\n\\n$$s_{q,c}(y) = \\\\begin{cases} 1, & \\\\text{if } \\\\exists a \\\\in A_q \\\\text{ such that } a \\\\subseteq y \\\\\\\\ 0, & \\\\text{otherwise} \\\\end{cases}$$\\n\\nso that $s_{q,c}(y)$ is 1 if the prediction $y$ includes any of the answers from the human annotations, denoted as $a \\\\subseteq y$, and 0 otherwise.\\n\\nFor a model $m$ that outputs $f_{m}(q, c)$ when given $q$ and $c$, the score $S(c)$ for each country or region $c$ is calculated as\\n\\n$$S(c) = \\\\frac{1}{|Q|} \\\\sum_{q \\\\in Q} s_{q,c}(f_{m}(q, c)) \\\\times 100$$\\n\\nTo evaluate LLM responses, we lemmatize/stem/tokenize the annotations and LLM responses for each question to consider the language variations. We use one of the three techniques that are available for each language.\\n\\n- We use the lemmatizer from the English model from SpaCy ($\\\\text{en_core_web_sm}$) for English.\\n- For Spanish and Amharic, we use lemmatizers from SparkNLP.\\n- For Indonesian, we use the lemmatizer from Kumparan NLP Library.\\n- For Chinese, we use jieba, a Chinese word segmentation module.\\n- For Korean, we use the Okt lemmatizer from the konlpy package.\\n- For Arabic, we use Qalsadi Arabic Lemmatizer.\\n- For Greek, we use the CLTK Greek lemmatizer.\\n- For Persian, we use Hazm, a Persian NLP Toolkit.\\n- For Azerbaijani, we use the Azerbaijani Language Stemmer.\\n- For Sundanese, we use SUSTEM, a Sundanese Stemmer.\\n- For Assamese, we use the Assamese tokenizer from Indic NLP Library.\\n- For Hausa, we use the Hausa Stemmer.\\n\\nC.3 Multiple Choice Question\\n\\nC.3.1 Multiple Choice Question Construction\\n\\nTo create plausible incorrect answer options for questions about the target country/region, we first consider all answer annotations from all other countries with at least two votes. Then, we sort these answer candidates by their vote count from each country/region. Next, we check each candidate to see if it is similar to any annotations collected from the target country/region. If it is, we block that candidate from being added as a wrong answer choice, as well as the same answer from the other countries/regions. We use GPT-4 to determine if two words are similar in meaning, such as 'fruit' and 'apple', as the two can be considered the same when answering the question. The prompt can be seen in Appendix C.3.2.\\n\\nAs this process would lead to differing possible wrong answer options for each target country per question, we pick the answer options with the minimum number of possible wrong answer options among all countries. If there are $n$ possible answer choices, we include all combinations of $n^3$ if $1$.\"}"}
{"id": "nrEqH502eC", "page_num": 35, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"n \u2265 3, or include all n answer choices plus 3\u2212n dummy options otherwise. We use GPT-4 (see Appendix C.3.2 for the prompt details) to produce dummy answer options to make the number of options comprised of one correct answer and three wrong answer options four. If there are multiple correct answers, we generate multiple versions of the question, each with a different correct answer. The choices are provided in alphabetical order when asked to LLMs in a multiple-choice format.\\n\\nC.3.2 Prompt for Multiple Choice Question Construction\\nSimilar Term Detection. Since we asked the human annotators to provide answers in a short answer format, there may be cases where different textual answers refer to the same meaning. To avoid duplicate options in multiple-choice format, we utilized GPT-4 to determine whether the answers have the same meaning using the following prompt:\\n\\nDetermine if a 'target' word is the same in meaning (e.g., football & soccer or soccer & football) to at least one of the 'answer' words, or one is a subset to another (e.g., fruit & apple or apple & fruit). If so, the 'result' for 'target' word is 'O'. However, if the two simply falls into the same level of hierarchy, the 'result' is 'X' (banana & apple, rose & carnation).\\n\\nNote that the 'answer' list is from 'answer_country,' and the 'target' word is from 'target_country,' as written by a person.\\n\\nWrite down your reasoning first. Do not write any other JSON formatted object in your answer except for the result JSON object, formatted as {\"result\":\"O\"} or {\"result\":\"X\"}.\\n\\nDummy Options Generation. In cases where a question has fewer than four options during the option generation process, we ask GPT-4 to produce dummy options using the following prompt:\\n\\nProvide \\\\(3\u2212n\\\\) dummy option(s) that makes sense to be the answer(s) of the given \\\"question,\\\" and has to exist in real-life (non-fiction), but is totally different from the given \\\"answers\\\" without any explanation. Make sure that the options are different from each other, and cannot be an answer from any country. Provide as JSON format: {\"dummy_options\":[]}\\n\\nC.3.3 Prompt for Multiple Choice Evaluation\\nWe use the following prompt to evaluate the LLMs' performance in multiple-choice format:\\n\\n{QUESTION} Without any explanation, choose only one from the given alphabet choices (e.g., A, B, C). Provide as JSON format: {\"answer_choice\":\"\\\"\"}\\n\\nA. {CHOICE 1}\\nB. {CHOICE 2}\\nC. {CHOICE 3}\\nD. {CHOICE 4}\\n\\nAnswer: D\\n\\nD.1 LLM Evaluation Results\\nFigure 13 shows the performance of models presented in 3a in SAQ when asked in English. Table 10 and Table 11 show the performance of all LLMs experimented on SAQ for all countries/regions on the local language and English, respectively.\\n\\nTable 12 shows the performance of all LLMs on MCQ for all countries/regions.\"}"}
{"id": "nrEqH502eC", "page_num": 36, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Figure 13: LLMs' performance on short answer questions for each country/region in English. Models constructed from a Western country are shown in shades of blue, whereas those built from a non-Western country are shown in shades of red.\\n\\nTable 10: Performance of all LLMs on short answer questions for each country/region in local language.\\n\\n| Country/Region | GPT-4 | Claude-3-Opus | Gemini-1.0-Pro | Command R+ | Qwen1.5-72B | HyperCLOVA-X |\\n|----------------|-------|---------------|----------------|------------|-------------|--------------|\\n| US, en         | 83.19 | 83.84         | 80.48          | 80.48      | 83.95       | 81.45        |\\n| GB, en         | 82.75 | 78.79         | 78.57          | 78.35      | 79.34       | 79.34        |\\n| ES, es         | 79.00 | 78.78         | 74.95          | 73.67      | 70.04       | 69.08        |\\n| MX, es         | 77.45 | 75.57         | 72.55          | 70.77      | 70.15       | 72.13        |\\n| ID, id         | 77.50 | 78.02         | 72.71          | 72.19      | 65.31       | 40.39        |\\n| CN, zh         | 77.32 | 76.90         | 70.36          | 64.87      | 78.27       | 58.44        |\\n| KR, ko         | 80.95 | 78.95         | 65.26          | 75.05      | 60.53       | 79.05        |\\n| DZ, ar         | 67.62 | 65.68         | 65.26          | 62.13      | 54.81       | 29.98        |\\n\\n| Country/Region | GPT-4 | Claude-3-Opus | Gemini-1.0-Pro | Command R+ | Qwen1.5-72B | HyperCLOVA-X |\\n|----------------|-------|---------------|----------------|------------|-------------|--------------|\\n| AS, ja         | 80.48 | 77.91         | 71.22          | 62.55      | 70.73       | 62.55        |\\n| JB, ko         | 77.87 | 77.58         | 68.55          | 60.76      | 49.06       | 60.76        |\\n| KP, zh         | 77.33 | 72.09         | 69.62          | 66.81      | 49.06       | 66.84        |\\n| AZ, su         | 78.74 | 79.67         | 59.70          | 79.11      | 52.74       | 52.74        |\\n| AS, ha         | 53.36 | 48.02         | 45.84          | 32.17      | 52.74       | 32.17        |\\n| NG, am         | 78.74 | 76.59         | 56.82          | 76.79      | 52.21       | 39.82        |\\n\\n| Country/Region | GPT-4 | Claude-3-Opus | Gemini-1.0-Pro | Command R+ | Qwen1.5-72B | HyperCLOVA-X |\\n|----------------|-------|---------------|----------------|------------|-------------|--------------|\\n| GR, el         | 70.43 | 69.24         | 64.78          | 59.89      | 32.93       | 35.54        |\\n| IR, fa         | 73.03 | 77.85         | 38.82          | 67.11      | 39.25       | 30.48        |\\n| KP, ko         | 49.32 | 55.41         | 43.47          | 49.55      | 38.96       | 52.03        |\\n| AZ, su         | 62.05 | 69.62         | 44.24          | 41.15      | 36.89       | 40.39        |\\n| JB, ha         | 55.79 | 56.55         | 44.87          | 31.22      | 32.42       | 40.39        |\\n| AS, am         | 45.93 | 52.41         | 27.99          | 25.89      | 18.45       | 5.77         |\\n| NG, am         | 25.85 | 46.37         | 35.82          | 16.26      | 9.67        | 1.48         |\\n| ET, am         | 45.93 | 46.37         | 24.07          | 21.82      | 9.67        | 1.48         |\\n\\n| Country/Region | GPT-4 | Claude-3-Opus | Gemini-1.0-Pro | Command R+ | Qwen1.5-72B | HyperCLOVA-X |\\n|----------------|-------|---------------|----------------|------------|-------------|--------------|\\n| AS, ja         | 77.87 | 69.62         | 44.24          | 41.15      | 32.42       | 40.39        |\\n| JB, ko         | 77.33 | 56.55         | 44.87          | 31.22      | 36.89       | 40.39        |\\n| KP, zh         | 78.74 | 76.59         | 43.47          | 41.15      | 32.42       | 40.39        |\\n| AZ, su         | 53.36 | 56.55         | 44.24          | 31.22      | 36.89       | 40.39        |\\n| AS, ha         | 55.79 | 52.41         | 27.99          | 16.26      | 9.67        | 1.48         |\\n| NG, am         | 25.85 | 46.37         | 24.07          | 21.82      | 9.67        | 1.48         |\\n| ET, am         | 45.93 | 46.37         | 24.07          | 21.82      | 9.67        | 1.48         |\"}"}
{"id": "nrEqH502eC", "page_num": 37, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"## Table 11: Performance of all LLMs on short answer questions for each country/region in English.\\n\\n| Country/Region | GPT-4       | Claude-3-Opus | Claude-3-Sonnet | Llama-3.1-70B | Gemini-1.0-Pro | Command R+ | Claude-3-Haiku | GPT-3.5 | PaLM2    | Qwen1.5-72B | SeaLLM | HyperCLOV A X | Qwen1.5-32B | Command R | Aya-23 | Qwen1.5-14B | Aya-101 |\\n|----------------|-------------|---------------|-----------------|---------------|---------------|------------|----------------|---------|----------|------------|--------|----------------|------------|-----------|--------|------------|---------|\\n| CN             | 70.89       | 66.98         | 66.88           | 63.71         | 66.46         | 64.98      | 60.44           | 64.66   | 66.14    | 66.88      | 65.61  | 62.76          | 69.30      | 61.50     | 56.65  | 64.66      | 34.28   |\\n| ID             | 70.00       | 62.81         | 66.67           | 61.98         | 59.27         | 59.58      | 59.38           | 63.23   | 62.19    | 63.54      | 62.81  | 63.65          | 58.75      | 57.40     | 53.33  | 55.73      | 38.65   |\\n| ES             | 67.91       | 61.30         | 60.45           | 59.38         | 59.70         | 59.06      | 53.62           | 62.26   | 60.45    | 63.33      | 62.58  | 48.74          | 47.69      | 58.64     | 54.90  | 55.12      | 35.71   |\\n| GR             | 68.70       | 61.09         | 60.98           | 61.85         | 60.54         | 58.59      | 45.70           | 61.85   | 48.47    | 49.79      | 51.78  | 40.76          | 44.65      | 45.70     | 44.34  | 45.39      | 38.04   |\\n| MX             | 63.15       | 58.35         | 57.93           | 59.71         | 56.47         | 61.06      | 37.84           | 61.48   | 43.36    | 41.89      | 60.44  | 44.03          | 39.41      | 41.67     | 36.26  | 33.00      | 28.49   |\\n| KR             | 69.68       | 64.42         | 63.47           | 62.11         | 59.68         | 59.89      | 59.89           | 60.00   | 40.04    | 43.75      | 56.95  | 45.34          | 41.31      | 38.67     | 34.11  | 39.72      | 26.38   |\\n| AZ             | 64.61       | 60.66         | 61.30           | 59.49         | 57.46         | 56.50      | 56.29           | 59.59   | 38.03    | 38.90      | 58.42  | 40.22          | 39.01      | 35.05     | 29.78  | 39.89      | 23.41   |\\n\\n| Country/Region | GPT-4       | Claude-3-Opus | Claude-3-Sonnet | Llama-3.1-70B | Gemini-1.0-Pro | Command R+ | Claude-3-Haiku | GPT-3.5 | PaLM2    | Qwen1.5-72B | SeaLLM | HyperCLOV A X | Qwen1.5-32B | Command R | Aya-23 | Qwen1.5-14B | Aya-101 |\\n|----------------|-------------|---------------|-----------------|---------------|---------------|------------|----------------|---------|----------|------------|--------|----------------|------------|-----------|--------|------------|---------|\\n| IR             | 65.46       | 61.29         | 57.35           | 61.07         | 55.92         | 54.28      | 53.18           | 56.36   | 55.92    | 56.91      | 60.20  | 56.91          | 54.06      | 50.99     | 50.77  | 52.96      | 28.95   |\\n| DZ             | 64.76       | 57.78         | 54.92           | 56.52         | 53.78         | 56.86      | 52.29           | 57.67   | 56.29    | 57.55      | 52.97  | 55.15          | 49.89      | 55.26     | 47.83  | 48.51      | 30.89   |\\n| AS             | 54.09       | 48.74         | 48.74           | 51.26         | 44.55         | 48.43      | 45.70           | 48.43   | 47.38    | 49.79      | 51.78  | 40.76          | 47.69      | 45.70     | 44.34  | 45.39      | 34.70   |\\n| JB             | 55.68       | 50.76         | 50.11           | 49.89         | 49.89         | 46.40      | 37.84           | 44.48   | 43.36    | 47.60      | 41.89  | 44.03          | 39.41      | 42.03     | 42.90  | 40.94      | 28.49   |\\n| KP             | 46.62       | 42.00         | 41.10           | 45.83         | 42.68         | 43.58      | 37.84           | 44.48   | 43.36    | 41.89      | 41.89  | 45.34          | 39.41      | 41.67     | 36.26  | 33.00      | 24.32   |\\n| ET             | 45.97       | 40.78         | 42.06           | 44.60         | 40.15         | 40.78      | 35.49           | 40.04   | 38.03    | 43.75      | 42.90  | 45.34          | 41.31      | 38.67     | 34.11  | 39.72      | 26.38   |\\n| NG             | 37.69       | 34.95         | 35.71           | 36.37         | 32.42         | 33.52      | 34.40           | 38.46   | 33.08    | 38.90      | 43.08  | 40.22          | 39.01      | 35.05     | 29.78  | 39.89      | 23.41   |\"}"}
{"id": "nrEqH502eC", "page_num": 38, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 12: Performance of all LLMs on multiple-choice questions for each country/region in English.\\n\\n| Country/Region | GPT-4  | Claude-3-Opus | Qwen1.5-72B | Qwen1.5-32B | Gemini-1.0-Pro | Claude-3-Sonnet | Command R+ | PaLM2  | GPT-3.5 | Claude-3-Haiku | SeaLLM | Aya-23 | Qwen1.5-14B | Command R | HyperCLOVA X | Aya-101 |\\n|----------------|--------|---------------|-------------|-------------|----------------|----------------|------------|--------|---------|---------------|--------|--------|-----------|-----------|-------------|--------|\\n| GB             | 94.17  | 95.74         | 91.80       | 91.94       | 87.87          | 83.98          | 85.16      | 89.38  | 86.87   | 87.41         | 82.66  | 82.45  | 82.96     | 79.75     | 79.80       | 68.75  |\\n| US             | 93.34  | 93.18         | 92.29       | 89.79       | 89.18          | 86.18          | 83.03      | 86.75  | 88.83   | 81.75         | 83.17  | 79.83  | 81.36     | 73.44     | 79.78       | 64.86  |\\n| CN             | 93.70  | 93.05         | 88.54       | 89.98       | 86.97          | 86.54          | 79.46      | 83.18  | 80.30   | 79.79         | 80.08  | 79.47  | 78.14     | 76.57     | 74.85       | 61.09  |\\n| ES             | 92.04  | 91.52         | 85.43       | 84.45       | 82.53          | 81.12          | 80.18      | 79.10  | 82.37   | 79.34         | 76.41  | 76.24  | 75.47     | 73.80     | 71.34       | 55.69  |\\n| MX             | 87.98  | 89.19         | 81.14       | 79.26       | 80.68          | 82.75          | 77.23      | 77.24  | 78.74   | 73.22         | 71.78  | 72.17  | 75.24     | 70.18     | 69.14       | 55.17  |\\n| DZ             | 89.28  | 85.98         | 79.42       | 76.09       | 79.09          | 78.02          | 76.00      | 79.68  | 76.64   | 78.47         | 72.68  | 72.36  | 68.96     | 72.66     | 67.91       | 43.88  |\\n| GR             | 86.73  | 84.75         | 80.93       | 80.40       | 78.92          | 77.30          | 78.39      | 76.96  | 75.54   | 76.24         | 74.29  | 70.90  | 68.89     | 69.99     | 68.67       | 45.29  |\\n| KR             | 88.10  | 86.83         | 76.94       | 72.31       | 80.58          | 81.79          | 73.06      | 73.02  | 71.10   | 75.21         | 74.71  | 71.49  | 71.10     | 70.05     | 71.15       | 45.49  |\"}"}
{"id": "nrEqH502eC", "page_num": 39, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"D.2 LLM Performance by Question Category\\n\\nFigure 14 illustrates the average performance of all LLMs for each category per country. This indicates that LLMs generally perform better in high-resource languages and countries. However, there are discrepancies in performance across different categories. LLMs do better on work-life or education-related questions but struggle with food and holidays/celebrations/leisure-related questions. This could be because the latter topics are more subjective. Figure 15 displays the results of the Tukey-HSD test on LLM performances for each topic, confirming that the performance difference between these two groups is statistically significant.\\n\\nD.3 Human Evaluation\\n\\nD.3.1 Human Evaluation Schema\\n\\nThe human evaluation is conducted on the following categories, which were decided based on the pilot annotations by the authors.\\n\\nApplicability. We ask annotators to evaluate whether the LLM's response is applicable to the general population of their country/region. Since we take annotations from only 5 people per question, a correct answer from the annotator may not necessarily represent the whole culture and vice versa. The applicability of the response is evaluated on three categories: 1) Applicable, 2) Conditionally Applicable, and 3) Incorrect. A response is annotated as applicable if all the answers provided by the model are valid for the general population of the country/region. When the response contains an answer that makes sense in some contexts but not necessarily to most people from the country/region,\"}"}
{"id": "nrEqH502eC", "page_num": 40, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 13: Summary of the human evaluation results across all countries. Scores are calculated by giving a weight of 1 for applicable, 0.5 for conditionally applicable, and 0 for incorrect responses. The values are presented as percentages, calculated by the number of responses that satisfy the criteria divided by the total number of responses. The country with the highest percentage is marked in bold, and the second highest is underlined.\\n\\n| Country/Region | Score | Unnatural | Language Stereotypical | Partially Correct | Refusal | Nonsensical | Different Country's View |\\n|----------------|-------|-----------|------------------------|-------------------|---------|-------------|--------------------------|\\n| US             | 66.67 | 3.33      | 0.83                   | 0.00              | 4.17    | 5.83        | 2.50                     |\\n| GB             | 82.50 | 0.83      | 0.83                   | 0.00              | 0.00    | 6.67        | 5.00                     |\\n| ES             | 39.17 | 0.00      | 1.67                   | 5.00              | 0.00    | 10.00       | 11.67                    |\\n| CN             | 63.33 | 0.00      | 3.33                   | 7.50              | 7.50    | 3.33        | 1.67                     |\\n| ID             | 60.00 | 0.83      | 13.33                  | 2.50              | 1.67    | 18.33       | 4.17                     |\\n| MX             | 68.75 | 0.83      | 5.83                   | 4.17              | 0.83    | 3.33        | 6.67                     |\\n| KR             | 50.42 | 0.83      | 7.50                   | 3.33              | 8.33    | 5.00        | 8.33                     |\\n| DZ             | 47.50 | 0.00      | 14.17                  | 8.33              | 2.50    | 7.50        | 6.67                     |\\n| GR             | 56.25 | 0.83      | 7.50                   | 0.83              | 8.33    | 15.00       | 8.33                     |\\n| IR             | 56.67 | 0.00      | 13.33                  | 10.83             | 2.50    | 10.00       | 0.00                     |\\n| KP             | 38.33 | 18.33     | 12.50                  | 1.67              | 16.67   | 6.67        | 12.50                    |\\n| AZ             | 42.50 | 10.00     | 13.33                  | 0.83              | 17.50   | 10.83       | 13.33                    |\\n| JB             | 44.58 | 6.67      | 21.67                  | 5.00              | 3.33    | 38.33       | 1.67                     |\\n| AS             | 45.83 | 5.00      | 19.17                  | 10.00             | 6.67    | 20.83       | 1.67                     |\\n| NG             | 36.25 | 7.50      | 2.50                   | 22.50             | 0.83    | 18.33       | 7.50                     |\\n| ET             | 27.92 | 1.67      | 48.33                  | 15.83             | 8.33    | 24.17       | 4.17                     |\\n\\nIt is annotated as conditionally applicable. Finally, if at least one answer is completely inapplicable to the country/region, the response is annotated as incorrect.\\n\\nUnnatural Language. The response from the model is annotated as unnatural if it is phrased in a way that a native speaker would not typically use. This includes instances where words sound like direct translations from English, phrases that sound unnecessarily formal, or when a different language is used to answer.\\n\\nStereotypical. This includes responses containing stereotypical answers about a target country/region. For example, providing the most common traditional food in the country/region as an answer to a completely unrelated question would be considered a stereotypical response.\\n\\nPartially correct. The response is annotated as partially correct when the model's response contains multiple answers and at least one is completely inapplicable to the general population of the country/region.\\n\\nRefusal. This category indicates where the model declines to provide an answer despite the annotators having determined that a valid answer exists.\\n\\nNonsensical. Nonsensical answers include hallucinations from the model or are completely incorrect by not answering the question properly (e.g., answering \u201csoccer\u201d for a question about a sport played without a ball).\\n\\nDifferent country's view. A response is annotated under this category if the model includes answers from the viewpoint of a different country/region. For instance, it includes answers from neighboring countries or countries sharing a similar yet different culture.\\n\\nD.3.2 Human Evaluation Result\\n\\nThe summary of the human evaluation result by each error category is shown in Table 13. Detailed analysis is included in the main text.\"}"}
{"id": "nrEqH502eC", "page_num": 41, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"when irrelevant to the question. For example, the model suggested couscous and baklava as common picnic foods in Algeria, which is both inaccurate and somehow stereotypical. Hallucinations were frequently encountered in responses to questions about celebrations or sports not commonly observed in Algeria. For instance, when asked about Halloween, the model referenced an unrelated old tradition and included the name of an equally unrelated sweet in Latin script. Another issue with the model\u2019s responses was the tendency to provide answers applicable to other Arabic-speaking countries, particularly Middle Eastern ones. This often led to culturally inaccurate or inappropriate responses for the Algerian context. For instance, when asked about the least favorite vegetable, the model mentioned bamiya/bamieh, the Middle Eastern name for okra. In Algeria, okra is called differently (mloukhiya) and is not commonly consumed nationwide. A similar misalignment with the Middle Eastern view was found in responses about local caf\u00e9 brands and popular YouTube channels.\\n\\nAssam (Assamese). The responses of the model often pointed towards Bihu, a cultural celebration of the Assamese people, even though it did not fit the context. It answered many questions with references to Bihu or Bihu-related activities. For instance, the model answered many food-related questions with Pitha, a traditional food item only served on special occasions like Bihu. The model also hallucinated by naming the most popular sports tournament in Assam as the Bihu Tournament, despite no such tournament existing in Assam.\\n\\nAzerbaijan (Azerbaijani). The model often gave stereotypical answers related to traditional Azerbaijani dishes, irrespective of context. For example, it offered traditional foods as answers like Qutab and Kebab even for settings like amusement parks or fast food preferences, which are not the most typical or relevant choices in those contexts. Additionally, the model often provided answers broadly applicable to people from post-Soviet or Eastern European regions rather than offering responses that uniquely represent Azerbaijan. Though these responses are not necessarily incorrect, they can be interpreted as lacking specificity. For instance, the model answered that the most famous leisure activity among retired men in Azerbaijan is chess, which is a viable option but is still more famous in Russia and T\u00fcrkiye.\\n\\nChina (Chinese). The responses from the model were generally acceptable, with a few cases either stereotypical or biased toward Western culture. For instance, the model answered that the most famous sport played without a ball in China is table tennis, which is both stereotypical and nonsensical. It also answered that the most popular sports-related TV program in China is Sports Scene, a Chinese TV program broadcasted in English.\\n\\nAt certain times, the model demonstrated impressive capabilities, indicating its high cultural understanding of China. For instance, when answering questions related to Ramadan, the model showed a good understanding of the minor population in China. Though Ramadan is generally not observed in most parts of China, it is often observed in certain regions, particularly in the Ningxia province. The text below is the response from GPT-4 on the question, \u2018What do people from China eat in Ramadan?\u2019 (translated in English).\\n\\nRamadan is the Islamic fasting month, mainly observed by Muslims. Chinese Muslims eat prepared food before sunrise (called \u201cSuhur\u201d) and break their fast (called \u201cIftar\u201d) after sunset during Ramadan. They usually eat light, nutritious food, including fruits, vegetables, meat, beans, dairy products, and grains. Non-Muslim Chinese people do not eat any different food during Ramadan than usual.\\n\\nEthiopia (Amharic). Nonsensical answers were significantly prevalent, where the model often repeated the question itself as an answer. There were even answers containing typographic errors. Additionally, there were several cases where the model gave long texts of repeated words and phrases. Such incidents indicate the model\u2019s limited ability to understand and use Amharic. The model often gave answers commonly associated with Ethiopia but did not necessarily answer the question correctly. For instance, the model gave Injera as the answer for most of the food-related questions, possibly because \u2018Injera\u2019 is a well-known food item in Ethiopia. These answers were often regarded as stereotypical or even nonsensical.\\n\\nGreece (Greek). Stereotypical answers were mostly from food-related questions, where the model gave a typical Greek dish as an answer to an irrelevant question. For instance, the model answered...\"}"}
{"id": "nrEqH502eC", "page_num": 42, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"that the most popular flavor of crisps/chips is feta cheese, which is not a very popular choice among people. There were also several instances where the model displayed biases towards the English culture. For example, it incorrectly stated that people in Greece eat pumpkin pie during Halloween, even though Halloween is not widely celebrated in Greece. It also answered that one of the most popular sports among elderly people is golf, a sport that is not as popular as in Greece compared to other countries around the Mediterranean.\\n\\nIndonesia (Indonesian). Most of the stereotypical answers came from the food category questions. The most popular choice from the model was nasi goreng (fried rice), where the model even gave that as an answer to a question about the most popular wheat-based food item. Hallucinations were also common for questions requiring a person's name, where the model provided the name of a completely unrelated person. Though it was very rare, there were instances where the answers could be considered offensive, especially for questions related to religion. For example, the model incorrectly identified Ketupat, a dish commonly served during Muslim festivals in Indonesia, as the most common food served during Easter. Such answers may inadequately represent the Christian population in Indonesia.\\n\\nAn interesting example related to 'different country's view' came from the following question: 'What is installed in front of the house when a family member dies in your country?'. The model's answer was flying the flag at half mast, a practice common in other countries during national mourning. However, this practice is not applicable when a family member dies in Indonesia. In Indonesia, people usually put up a yellow flag to indicate that someone has died in that area. There were many other instances where the model answered from the perspective of a different country. For example, it provided Independence Day as an answer to a question about the day of the year dedicated to fireworks in Indonesia. In Indonesia, people do not celebrate Independence Day by using fireworks.\\n\\nIran (Persian). Hallucinations were very common when answering questions that required a person's name. For instance, it incorrectly identified the Mayor of Tehran as the most famous boxer, provided the coach's name instead of the athlete's, and even provided non-existent names. In many cases, the model refused to answer because the question was considered illegal according to local laws. For instance, when asked about the most common alcoholic drink, the model responded that these drinks are illegal in Iran and, therefore, it could not provide an answer.\\n\\nThe model almost always provided answers to questions about a specific date based on the Gregorian calendar, even though people in Iran use the Solar Hijri calendar. While the answers were mostly correct when converted, the fact that both the questions and answers were in Persian suggests that the responses lacked cultural sensitivity.\\n\\nNorth Korea (Korean). Offensive responses were heavily prevalent in North Korea, where the model answered Kim Jong Un, the current supreme leader of North Korea, for completely unrelated questions, such as the most popular fruit in North Korea or the type of shoes students wear at school. Moreover, the responses from the model were biased towards the people from Pyongyang, the capital of North Korea. This phenomenon may stem from insufficient information about people from other areas in North Korea.\\n\\nAnother interesting finding was that the responses from the model were often phrased in the words used exclusively in South Korea. For instance, the answer given by the model for many food-related questions was naengmyeon (\ub0c9\uba74), despite the fact that it is spelled differently in North Korea (\ub7ad\uba74).\\n\\nSouth Korea (Korean). Most incorrect responses that reflected the viewpoint of the other country were mainly due to the different age system used in South Korea. For instance, the model answered 19 for the question about the average age at which people go to university, whereas the most plausible answer would be '20' according to the South Korean age system. Such responses are surprising, as we have explicitly prompted the model to provide the answer using South Korea's traditional age-counting custom. One interesting case was the question about the most famous family in South Korea. The model answered Admiral Yi Sun-sin's family, referencing a national hero who is very famous among people.\"}"}
{"id": "nrEqH502eC", "page_num": 43, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"from South Korea, but not his family. Similarly, there were several instances where the model hallucinated by giving inaccurate answers tied to South Korea's traditional culture or history.\\n\\nUnlike prior expectations that the model would wrongly provide answers applicable to people from all parts of Indonesia, as West Java is a specific region within the Indonesian country, the model tended to offer specific answers related to West Java. However, the problem was that these answers did not include a full understanding of the context. For instance, the model answered \\\"Dodol Garut,\\\" a traditional dessert from West Java, for a question asking about the food associated with Valentine's Day. Such a response is very stereotypical, considering that people in West Java also exchange chocolate for Valentine's Day, similar to other countries.\\n\\nThere were also errors in the language used by the model, where it answered in Indonesian instead of Sundanese.\"}"}
