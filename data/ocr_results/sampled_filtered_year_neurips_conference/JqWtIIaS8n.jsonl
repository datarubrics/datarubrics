{"id": "JqWtIIaS8n", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"LithoBench: Benchmarking AI Computational Lithography for Semiconductor Manufacturing\\n\\nSu Zheng\\nHaoyu Yang\\nBinwu Zhu\\nBei Yu\\nMartin D.F. Wong\\n\\n1 The Chinese University of Hong Kong\\n2 nVIDIA, Austin, USA\\n3 Hong Kong Baptist University\\n\\nAbstract\\nComputational lithography provides algorithmic and mathematical support for resolution enhancement in optical lithography, which is critical for semiconductor manufacturing. The time-consuming lithography simulation and mask optimization processes limit the practical application of inverse lithography technology (ILT), a promising solution to the challenges of advanced-node lithography. Although machine learning for ILT has shown promise for reducing the computational burden, this field lacks a dataset that can train the models thoroughly and evaluate the performance comprehensively. To boost the development of AI-driven computational lithography, we present the LithoBench dataset, a collection of circuit layout tiles for deep-learning-based lithography simulation and mask optimization. LithoBench consists of more than 120k tiles that are cropped from real circuit designs or synthesized according to topologies of widely adopted ILT testcases. Ground truths are generated by a famous lithography model in academia and an advanced ILT method. We provide a framework to design and evaluate deep neural networks (DNNs) with the data. The framework is used to benchmark state-of-the-art models on lithography simulation and mask optimization. LithoBench is available at https://github.com/shelljane/lithobench.\\n\\n1 Introduction\\nSemiconductor lithography transfers circuit patterns drawn on a mask onto a silicon wafer, which is essential for the fabrication of integrated circuits (IC). It typically accounts for about 30% of the cost of IC manufacturing. As transistor sizes continue to shrink, lithography tends to be the technical limiting factor for further advances [1]. Diffraction or process effects may distort the patterns on the wafer, leading to performance degradation and even failures. Given the importance, how to ensure the correctness of semiconductor lithography becomes a critical issue in industry and academia.\\n\\nOptical proximity correction (OPC) is a technique used to improve the accuracy and quality of lithography patterns on semiconductor wafers. OPC evolves from rule-based methods [2] to model-based approaches [3\u20135], improving the resilience to manufacturing variation. Inverse lithography technology (ILT) [6\u20138] is a mathematically rigorous inverse approach that optimizes the mask to achieve the desired results on the wafer. It has been explored and developed as the next generation of OPC, promising a solution to challenges of advanced technology such as extreme ultraviolet (EUV).\\n\\nHowever, there exist significant challenges that limit the broad application of ILT. A major reason is that ILT typically consumes a significant amount of runtime, making it challenging to implement ILT at a production-level scale. Moreover, the patterns generated by ILT algorithms may be too complex to be produced efficiently. To alleviate the problems above, DNN-based ILT algorithms have been proposed to reduce the runtime and complexity [9 \u201317]. Compared with traditional methods, the improvement of DNN-based ILT algorithms has two aspects. Firstly, unlike traditional methods that...\"}"}
{"id": "JqWtIIaS8n", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"require multiple iterations to optimize the mask, DNN-based methods can generate a mask in one forward pass. A few iterations of finetuning can further improve the quality of the mask. Secondly, by incorporating loss functions for complexity reduction, deep learning methods can remarkably improve the printability of ILT results [13, 14]. Deep learning shows great potential in advancing ILT.\\n\\nIntegrated circuits are represented by multi-layer layouts for manufacturing. A mask contains the patterns of one layout layer, optimized by ILT algorithms to produce desired printed patterns on silicon wafers. To achieve affordable runtimes, ILT algorithms typically generate the entire mask by optimizing fixed-size tiles cropped from the layout layer [18]. Fig. 1a presents a representative workflow of traditional ILT algorithms, which optimizes the mask iteratively. At each iteration, the lithography simulation model can output the printed image after the lithography processes. After that, the loss function evaluates the printed image in terms of error (L2 loss), process variation band (PVB), complexity (cpx.), etc. Given a loss function, the mask can be optimized by gradient descent [7] and other methods [19, 20]. Fig. 1b shows the DNN-based ILT flow. The input is the target image T, which contains the target shapes that should be printed. The DNN ILT model outputs the optimized mask $M^*$ in one forward pass, which is significantly faster than traditional ILT.\\n\\nIn recent years, researchers have proposed various DNN-based ILT methods [9 \u201317], which can significantly boost the speed and performance of ILT with excellent initialization, refinement, and GPU acceleration. However, since the ILT methods are evaluated in different scenarios with different training data, it is difficult to compare them comprehensively and challenging to apply them in production. Specifically, circuit layouts typically consist of multiple layers of patterns. The shape, size, and density of the patterns vary from layer to layer. An ILT method may have only been evaluated on metal-layer [14] or via-layer [12] testcases. Nevertheless, a via layer typically contains square shapes, while a metal layer can include diverse rectilinear polygons. It is questionable to assert that one of the methods above is better because they are not evaluated in the same scenarios. In addition, some models are trained on synthetic data [9], while others focus on real-world designs [21]. Therefore, a representative and comprehensive dataset should cover metal and via layers, as well as synthetic and real-world designs. It is valuable to construct a common dataset that can train and evaluate DNN ILT models in various scenarios.\\n\\nTo evaluate ILT methods, multiple metrics should be considered. For example, L2 loss measures the difference between the printed patterns and the target shapes. PVB estimates the robustness of the mask against process variations. Shot count shows the complexity of the mask, which affects the manufacturing time and cost. Runtime is also an important factor. To choose an appropriate algorithm, users usually need to make a trade-off between the metrics. As a result, there is a need for a platform that can effectively benchmark various ILT methods using comprehensive metrics.\\n\\nDNN can be employed in ILT for lithography simulation or mask optimization. In simple terms, the output of ILT is an optimized mask $M^*$, which can get similar results as the target patterns $T$ after the lithography processes $G(M^*)$. Existing works [22, 23] approximate the lithography processes $G(M^*)$ with DNN-based lithography simulation models, which can not only provide faster evaluation of the mask quality but also be used in mask refinement. DNN-based mask optimization models [9,11,12,16] are designed to directly obtain the optimized mask, formulated by $M^* = F(T)$.\\n\\nTo meet the above requirements, we present LithoBench, a collection of circuit layout tiles to train DNN models for lithography simulation and mask optimization. Its benchmarking platform can provide an extensive evaluation of the models. Our contributions are summarized as follows.\"}"}
{"id": "JqWtIIaS8n", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We assemble a dataset for DNN-based lithography simulation and mask optimization, which not only contains synthetic and real-world layout tiles but also covers metal and via layers. It is the first large-scale dataset for computational lithography built from real-world designs.\\n\\nWe implement a platform to evaluate the DNN models for lithography simulation and mask optimization. Users can design and select appropriate models with our platform by benchmarking them in terms of quality, robustness, complexity, runtime, etc.\\n\\nWe train and evaluate state-of-the-art (SOTA) DNN models for lithography simulation and mask optimization on LithoBench, providing a comprehensive assessment of them.\\n\\n2 Related Work\\n\\nThis section provides the fundamentals of ILT. We begin by discussing the commonly used lithography simulation method. Next, we describe typical ILT methods that solve mask optimization via numerical optimization. Then we review the latest advancements in DNN models for lithography simulation and mask optimization. Finally, LithoBench is compared to existing datasets about lithography.\\n\\n2.1 Lithography Simulation\\n\\nThe lithography simulation targets to approximate the real lithography process in chip manufacturing and provides an accurate estimation of the manufactured designs on silicon wafers. Lithography simulation consists of the optical projection and photoresist models. In optical projection, incident light passes through the mask, transmitting the spatial information of the mask patterns $M$ to the optical projection system. This results in the transformation of the input light intensity distribution into an aerial intensity distribution on the wafer plane. The intensity distribution is commonly represented by an aerial image $I$. The process can be modeled by Hopkins' diffraction theory:\\n\\n$$I = H(M) = \\\\sum_{k=1}^{K} \\\\mu_k |h_k \\\\otimes M|^2,$$\\n\\nwhere $h_k$ is the $k$th optical kernel function and $\\\\mu_k$ is the corresponding weight. The notation $\\\\otimes$ stands for convolution operation. $| \\\\cdot |^2$ gets the squared modulus of each element.\\n\\nAfter optical projection, a photoresist model transfers the aerial image $I$ to the printed image $Z$, which is also called resist image. To enable gradient descent in ILT algorithms, researchers commonly design the photoresist model as:\\n\\n$$Z(x, y) = \\\\sigma Z(I(x, y)) = 1 + e^{-\\\\alpha (I(x, y) - I_{th})},$$\\n\\nwhere $I_{th}$ is the intensity threshold, $\\\\alpha$ is a constant number that controls the steepness of the function, and $(x, y)$ represents a coordinate on the aerial or resist image. Lithography simulation transforms the mask $M$ to the resist image $Z$ with the optical projection and photoresist models.\\n\\n2.2 Mask Optimization via ILT\\n\\nThe application of ILT [25\u201332] in industrial productions began in 2005 [33\u201338]. It tries to solve the mask pattern such that after the lithography process, the remaining pattern on the silicon wafer is as close as the original design. Thus, ILT can be viewed as the inverse process of lithography simulation. In recent years, the ICCAD-13 benchmark [39] has facilitated extensive research on ILT in academia, such as MOSAIC [7], MultiLevel [40], GPU-LevelSet [8, 19], etc.\\n\\nAn ILT algorithm usually optimizes a parameter matrix $P$ that can be transformed to the mask image $M$ with the following function:\\n\\n$$M(x, y) = \\\\sigma M(P(x, y)) = 1 + e^{-\\\\beta (P(x, y) - \\\\gamma)},$$\\n\\nwhere $\\\\beta$ is the constant steepness factor and $\\\\gamma$ is a constant offset. With this function, the values in $M$ can be limited in $[0, 1]$, while the values in $P$ have no limitation. Finally, the transformation from the parameter matrix $P$ to the resist image $Z$ can be formulated as:\\n\\n$$Z = \\\\sigma Z(H(\\\\sigma M(P))).$$\"}"}
{"id": "JqWtIIaS8n", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In mask manufacturing, the printed patterns on the wafer may differ drastically under varying process conditions (e.g. depth of focus, intensity of incident light). ILT algorithms typically consider three process corners, maximum, nominal, and minimum. Specifically, three series of optical kernels are employed to form the optical projection models $H_{\\\\text{max}}, H_{\\\\text{nom}},$ and $H_{\\\\text{min}}$. The corresponding resist images can be denoted by $Z_{\\\\text{max}}, Z_{\\\\text{nom}},$ and $Z_{\\\\text{min}}$.\\n\\n$L_2$ loss measures the difference between the nominal resist image and the target image, defined as:\\n\\n$$L_2(Z_{\\\\text{nom}}, T) = \\\\| Z_{\\\\text{nom}} - T \\\\|_2^2.$$  \\\\(5\\\\)\\n\\nTo enhance the robustness against varying process conditions, ILT algorithms are commonly required to reduce the process variation band (PVB) defined as:\\n\\n$$PVB(Z_{\\\\text{max}}, Z_{\\\\text{min}}) = \\\\| Z_{\\\\text{max}} - Z_{\\\\text{min}} \\\\|_2^2.$$  \\\\(6\\\\)\\n\\nILT loss functions are usually based on $L_2(Z_{\\\\text{nom}}, T), PVB(Z_{\\\\text{max}}, Z_{\\\\text{min}})$, and additional components like complexity losses. Given the loss function, the parameter matrix $P$ can be optimized by gradient descent. The final parameter matrix $P^*$ can be binarized to obtain the optimized mask $M^*$ by checking whether each element satisfies $\\\\sigma_M(P^*(x, y)) > 0.5$.\\n\\n### 2.3 DNN-based Methods\\n\\nFor lithography simulation, conditional generative adversarial network (CGAN) [41, 42] is utilized in LithoGAN [22], DAMO [12], and TEMPO [43]. Fourier Neural Operator (FNO) [44] inspires DOINN [23]. These works suggest that lithography simulation via DNN models is a rapidly developing field. To distinguish the lithography model based on Hopkins' diffraction theory from the DNN-based models, we refer to the theory-based one as the reference lithography simulation model.\\n\\nIn mask optimization, DNN-based methods also achieve tremendous success. For instance, GAN-OPC [9] trains a CGAN guided by reference optimized masks and lithography simulation for mask optimization. Its training scheme inspires subsequent research, such as Neural-ILT [11] and DAMO [12]. CFNO [16] presents a powerful model inspired by Vision Transformer [45] and FNO.\\n\\n### 2.4 Lithography Datasets\\n\\nICCAD-13 [39] is a famous benchmark for mask optimization consisting of $10 \\\\mu m \\\\times 2 \\\\mu m$ metal-layer clips. However, it is targeting numerical optimization solutions only and the 10 instances are too small to fit AI solutions. GAN-OPC [9] releases around 4k synthetic tiles for metal-layer mask optimization. However, its size is small for a thorough training and the quality of the optimized masks falls behind SOTA results. Furthermore, it does not provide real-world designs and via-layer tiles, which limits its applications. Another limitation of existing datasets is that they do not support DNN-based lithography simulation, which is also a critical step in computational lithography. To overcome these weaknesses, we propose LithoBench, the first comprehensive dataset that simultaneously supports lithography simulation and mask optimization. Unlike previous datasets, LithoBench includes abundant and diverse data that covers synthetic and real-world layout tiles, as well as metal and via layers. The ground truths are generated by SOTA method, providing the high-quality data.\\n\\nICCAD-12 [46] is a dataset for lithography hotspot detection (HSD), which aims to find the locations on the mask that may lead to defects on the printed patterns. HSD only indicates the presence of defects in certain regions, but provides little information for mask optimization. LithoBench focuses on lithography simulation, which is more important than HSD, providing detailed information about the printed patterns. Besides, AI approaches for HSD have been deeply studied in literature and are mature in production flows. Therefore, HSD-related benchmarks are not the scope of this paper.\\n\\n### 3 Dataset\\n\\nLithoBench consists of 133,496 tiles that forms four subsets: MetalSet, ViaSet, StdMetal, and StdContact. MetalSet and ViaSet are large subsets primarily used for training, compatible with existing research. StdMetal and StdContact are small subsets for evaluating the generalization ability of the models. In each subset, we prepare the target images, optimized masks, aerial images, and printed images. In lithography simulation tasks, the input of the DNN model is an optimized mask, and the outputs include an aerial image and a printed image. In mask optimization tasks, the input and output are a target image and the optimized mask, respectively.\"}"}
{"id": "JqWtIIaS8n", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Summary of LithoBench\\n\\n| Task                   | Subset          | Training Tiles | Testing Tiles |\\n|------------------------|-----------------|----------------|---------------|\\n| Lithography Simulation | MetalSet        | 14,824         | 1,648         |\\n|                        | ViaSet          | 104,733        | 11,642        |\\n|                        | StdMetal        | 0              | 271           |\\n|                        | StdContact      | 163            | 165           |\\n\\nFigure 2: Samples from (a) ICCAD-13 [39], (b) MetalSet, (c) ViaSet, (d) StdMetal, (e) StdContact.\\n\\n3.1 Data Collection\\n\\n3.1.1 MetalSet\\n\\nICCAD-13 benchmark [39] is a famous benchmark for metal-layer mask optimization, used in various SOTA ILT methods [7\u20139,11,13\u201315,19]. It contains 10 tiles in GLP format [39] that come from 32 nm industrial layouts. We design MetalSet to enable the training of DNN-based model that can achieve high performance on ICCAD-13 benchmark. We synthesize 16,472 tiles using the layout generation method in [48]. Each tile is randomly generated following the design rules of ICCAD-13 benchmark. The rules refer to the limitations on shape widths, distances, and areas, determined by the technology node. The original ICCAD-13 benchmark is used to evaluate DNN-based mask optimization models that are trained on MetalSet. This setting is compatible with existing methods [9, 11, 13, 14]. Fig. 2a and Fig. 2b show examples of ICCAD-13 benchmark and MetalSet.\\n\\n3.1.2 ViaSet\\n\\nFor via-layer ILT, we generate the layouts at the 45 nm technology node with the IC design tool, OpenROAD [49, 50]. We select the gcd and aes circuits from the OpenROAD project and get their layouts in GDSII format, the de facto industry standard for electronic design automation. The Python package python-gdsii [51] is used to extract the shapes on the first via layers of the circuits and save them in the GLP format. We crop the layouts into 2048 \u00d7 2048 nm\u00b2 tiles with a stride of 512 nm. Following existing ILT methods, we only include the shapes within the central region, which has a size of 1280 \u00d7 1280 nm\u00b2. Finally, we get 116,415 clips of the layout. Following the MetalSet, we select 10 tiles with different complexity for testing.\\n\\n3.1.3 StdMetal and StdContact\\n\\nStdMetal and StdContact subsets include the layout tiles of the Nangate 45 nm standard cells [52]. Nangate 45 nm is an open IC library that is widely used in academia. A standard cell is a group of transistors and interconnect structures that provide a boolean logic function (e.g., AND, OR, XOR, XNOR, inverters) or a storage function (flip-flop or latch). Since standard cells are typically the basic building blocks of digital IC, the ILT of standard cells is important for manufacturing. We crop the layouts of the standard cells in the same way as ViaSet. The StdMetal subset consists of the tiles on the first metal layer. Since the standard cells do not use via layers, we use the contact layer to build the StdContact subset, which also contains square shapes like the via layer. The 271 tiles in StdMetal are used to evaluate the generalization ability of models trained on MetalSet. Fig. 2d shows an example from StdMetal. On StdContact, we test the models trained on ViaSet with 165 tiles. We allow the finetuning on another 163 tiles because the density of shapes in StdContact is obviously higher than the density in ViaSet. Fig. 2c and Fig. 2e show the examples from ViaSet and StdContact, which can illustrate the difference in density.\"}"}
{"id": "JqWtIIaS8n", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.2 Data Preparation\\n\\nTarget Images\\nWe parse the data in the GLP format and put the shapes in the central region of a \\\\(2048 \\\\times 2048\\\\) image. Each pixel in the image corresponds to a \\\\(1 \\\\times 1\\\\) nm\\\\(^2\\\\) area of the circuit layout.\\n\\nOptimized Masks\\nWe employ an ILT method inspired by [14, 40] to get the ground truths. The lithography simulation model is given by the ICCAD-13 benchmark, which is for the 32 nm technology node. Since the resolution required by 45 nm is lower than 32 nm, it is also applicable for 45 nm designs. In the ILT forward pass, we apply average pooling, (3), (1), and (2) to the parameters \\\\(P\\\\):\\n\\n\\\\[\\nZ = \\\\sigma(Z(H(\\\\sigma(M(AvgPool(P)))))).\n\\\\]\\n\\n(7)\\n\\nConsidering three process corners \\\\(H_{\\\\text{max}}, H_{\\\\text{nom}}, \\\\) and \\\\(H_{\\\\text{min}}\\\\), we can obtain three resist images \\\\(Z_{\\\\text{max}}, Z_{\\\\text{nom}}, \\\\) and \\\\(Z_{\\\\text{min}}\\\\). The loss function is defined as:\\n\\n\\\\[\\nL_f(Z_{\\\\text{nom}}, Z_{\\\\text{max}}, Z_{\\\\text{max}}, T) = \\\\|Z_{\\\\text{max}} - T\\\\|^2_2 + \\\\|Z_{\\\\text{max}} - Z_{\\\\text{min}}\\\\|^2_2 + L_{\\\\text{curv}}(Z_{\\\\text{nom}}),\\n\\\\]\\n\\n(8)\\n\\nwhere \\\\(\\\\|Z_{\\\\text{max}} - T\\\\|^2_2\\\\) and \\\\(\\\\|Z_{\\\\text{max}} - Z_{\\\\text{min}}\\\\|^2_2\\\\) are for the minimization of L2 and PVB, respectively. \\\\(L_{\\\\text{curv}}(Z_{\\\\text{nom}})\\\\) is the curvature loss that can improve the smoothness of the mask [14]. In the backpropagation, we update the parameters \\\\(P\\\\) via gradient descent. Inspired by multi-level ILT [40], we optimize the mask at resolutions \\\\(256 \\\\times 256\\\\), \\\\(512 \\\\times 512\\\\), and \\\\(1024 \\\\times 1024\\\\) for 200, 100, and 100 iterations, respectively. Finally, we get a \\\\(2048 \\\\times 2048\\\\) mask by interpolating the result.\\n\\nAerial and Printed Images\\nAn aerial image \\\\(I\\\\) is generated by applying (1) to the optimized mask \\\\(M^*\\\\) with the nominal kernel. A printed image \\\\(Z\\\\) is obtained by binarizing \\\\(I\\\\) with \\\\(I_{\\\\text{th}}\\\\).\\n\\n3.3 Tasks\\n\\n3.3.1 Lithography Simulation\\nGiven an optimized mask, the lithography simulation model outputs the corresponding aerial and printed image. For MetalSet and ViaSet, we use 90% of the data as the training set and the rest as the test set. The models trained on MetalSet can be tested on StdMetal without finetuning. The models trained on ViaSet are tested on StdContact after the finetuning on a few data.\\n\\nMean squared error (MSE) is adopted to measure the performance of lithography simulation. Furthermore, intersection over union (IOU) and pixel accuracy (PA) [23] are utilized to evaluate the quality of the predicted printed image. The IOU metric can be defined as:\\n\\n\\\\[\\n\\\\text{IOU}(Z, T) = \\\\frac{Z \\\\cap T}{Z \\\\cup T},\\n\\\\]\\n\\n(9)\\n\\nwhere \\\\(Z\\\\) and \\\\(T\\\\) are the regions in printed patterns and target shapes, respectively. PA is defined as:\\n\\n\\\\[\\n\\\\text{PA}(Z, T) = \\\\frac{Z \\\\cap T}{T}.\\n\\\\]\\n\\n(10)\\n\\nNote that we interpolate the output images to \\\\(2048 \\\\times 2048\\\\) before computing any metric.\\n\\n3.3.2 Mask Optimization\\nFor mask optimization, the model predicts a well-optimized mask according to the target image. The training splits used for mask optimization are the same as for the lithography simulation task. However, the test data of MetalSet and ViaSet are different. We use the 10 testcases in the ICCAD-13 benchmark to test the model on MetalSet. For ViaSet, we select 10 representative tiles as the testcases. StdMetal and StdContact provide hundreds of challenging samples for testing.\\n\\nMask optimization models aim to produce high-quality ILT results, not just mimic the reference optimized masks. We evaluate these metrics [7, 11] after binarizing the masks and printed images:\\n\\n1. L2 loss, as defined in (5), is a metric that measures the difference between the nominal resist image and the target image. Fig. 3a visualizes the L2 loss.\\n2. PVB, as defined in (6), evaluates the robustness of the mask against varying process conditions. Fig. 3b visualizes the PVB between the maximum and minimum process corners.\"}"}
{"id": "JqWtIIaS8n", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"EPE Violation (Inner)\\nResist Image (Nominal)\\nTarget Shape\\nL2 Loss\\nResist Image (Maximum)\\nResist Image (Minimum)\\nPVB\\nEPE Violation (Outer)\\nShot\\nShape on the Mask\\n\\nFigure 3: Illustration of the metrics. (a) L2 measures the difference between the printed and target images. (b) PVB quantifies the maximum discrepancy between process corners. (c) EPE estimates the distortion of the printed image. (d) #Shots counts the rectangles needed to construct the mask.\\n\\nTable 2: Comparison on Lithography Simulation\\n\\n| Subtask | MSE A | MSE B | IOU PA |\\n|---------|-------|-------|--------|\\n| LithoGAN [22] | 1.38 \u00b7 10^{-4} | 7.44 \u00b7 10^{-6} | 0.97 |\\n| DAMO [12] | 1.72 \u00b7 10^{-2} | 1.54 \u00b7 10^{-2} | 0.98 |\\n| DOINN [23] | 8.38 \u00b7 10^{-6} | 7.54 \u00b7 10^{-6} | 0.97 |\\n| CFNO [16] | 1.92 \u00b7 10^{-5} | 1.54 \u00b7 10^{-5} | 0.98 |\\n\\nAverage: 1.38 \u00b7 10^{-4} \u00b7 8.38 \u00b7 10^{-6} = 1.13 \u00b7 10^{-3} |\\n\\nRuntime: 0.013 s / image\\n\\nFigure 4: Lithography simulation. (a)Ground truth, (b)LithoGAN, (c)DAMO, (d)DOINN, (e)CFNO.\\n\\n3. As shown in Fig. 3c, edge placement error (EPE) estimates the distortion of the resist image. We sample probe points equidistantly on horizontal and vertical edges of the target patterns. If the distance from the target pattern to the printed pattern is larger than the EPE constraint, it produces an EPE violation. The number of EPE violations is the EPE score of the mask.\\n\\n4. Shot count (#Shots) is the number of rectangular shots for replicating the shapes on the mask. It can evaluate the complexity of an optimized mask. Fig. 3d shows an example, where a shape is fitted by rectangular shots. In LithoBench, we compute the shot count using adaptive rectangular decomposition [53] with adaptive-boxes [54] (MIT license).\\n\\nTable 1 summarizes the statistics of LithoBench.\\n\\n4 Experiments\\n4.1 Benchmarked Models\\n4.1.1 Lithography Simulation Models\\nMultiple SOTA models are implemented using PyTorch [55] and OpenILT [56] on RTX3090 GPU. For lithography simulation, we implement LithoGAN [22], DAMO [12], DOINN [23], and CFNO [16]. The last layer of each model outputs two channels as the aerial and printed images. These models minimize the MSE between their outputs and the ground truths.\\n\\nLithoGAN\\nA CGAN is employed to fit the reference lithography simulation model. The generator of the CGAN is a fully convolutional network (FCN) [57] and the discriminator is a convolutional neural network (CNN). Images are downsampled to 256 \u00d7 256 and input to the model. Note that different models may vary in image resolution to make trade-offs between accuracy and runtime.\"}"}
{"id": "JqWtIIaS8n", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 3: Comparison on Mask Optimization\\n\\n| Subtask | L2 \\\\( \\\\text{PVB} \\\\) | Shots | L2 \\\\( \\\\text{PVB} \\\\) | Shots | L2 \\\\( \\\\text{PVB} \\\\) | Shots | L2 \\\\( \\\\text{PVB} \\\\) | Shots |\\n|---------|---------------------|-------|---------------------|-------|---------------------|-------|---------------------|-------|\\n| 1       | 43414 41290 8.7 574 | 36670 42666 7.3 476 | 32579 41173 5.4 | 523 |\\n| 2       | 14767 6686 8.3 166 | 12723 8537 6.2 263 | 5081 9962 0.0 176 | 26809 26814 4.2 232 |\\n| 3       | 25929 23715 4.6 457 | 20045 23548 2.4 373 | 16120 23796 0.2 418 | 26809 26814 4.2 232 |\\n| 4       | 81378 4931 73.2 276 | 25422 41537 3.2 265 | 50445 35673 26.7 458 | 70740 17950 55.1 396 |\\n\\nAverage | 41372 19156 23.7 368 | 23715 29072 4.8 344 | 26056 27651 8.0 394 | 38578 25196 18.0 |\\n\\nRuntime | 0.010 s/image | 0.025 s/image | 0.028 s/image | 0.040 s/image |\\n\\nFigure 5: Mask optimization. (a) Ground truth, (b) GAN-OPC, (c) Neural-ILT, (d) DAMO, (e) CFNO.\\n\\nDAMO\\nIt improves the CGAN for lithography simulation with the backbone based on UNet++ [58] and the multiscale discriminator inspired by pix2pixHD [59]. The resolution of DAMO is \\\\(1024 \\\\times 1024\\\\), which is significantly higher than LithoGAN.\\n\\nDOINN\\nInspired by Fourier Neural Operator (FNO) [60], DOINN utilizes a novel reduced FNO architecture to fit the lithography simulation model. Its resolution is \\\\(1024 \\\\times 1024\\\\).\\n\\nCFNO\\nCombining the principles of Vision Transformer (ViT) [45] and FNO, the CFNO module is designed for efficient global layout embedding and resolving stitching issues caused by long-range dependency. The resolution for CFNO is also \\\\(1024 \\\\times 1024\\\\).\\n\\n4.1.2 Mask Optimization Models\\nFor mask optimization, we implement GAN-OPC [9], Neural-ILT [11], DAMO [12], and CFNO [16].\\n\\nGAN-OPC\\nCGAN also inspires the design of GAN-OPC. The training of GAN-OPC consists of two stages. In the first stage called ILT-guided pretraining, we train the generator to minimize the MSE between its outputs and the optimized masks. The second stage is based on the training process of GAN. During the training of the generator, we use the L2 loss formulated by (5) as an additional objective, where the printed image \\\\(Z_{\\\\text{nom}}\\\\) is obtained by the reference lithography simulation model. GAN-OPC uses a resolution of \\\\(256 \\\\times 256\\\\).\\n\\nNeural-ILT\\nA UNet [61] is utilized in Neural-ILT to predict the optimized mask. Neural-ILT also has a pretraining stage like GAN-OPC. In the second stage, it uses \\\\(L2(Z_{\\\\text{nom}}, T) + \\\\text{PVB}(Z_{\\\\text{max}}, Z_{\\\\text{min}})\\\\) as the objective function. The resolution of Neural-ILT is \\\\(512 \\\\times 512\\\\).\\n\\nDAMO and CFNO use the same architectures as in lithography simulation.\\n\\n4.1.3 Subtasks\\nFor lithography simulation and mask optimization, we benchmark the models with the following subtask: (1) training on MetalSet, testing on MetalSet; (2) training on ViaSet, testing on ViaSet; (3) training on MetalSet, testing on StdMetal; (4) training on ViaSet, testing on StdContact. The last two are more challenging since high generalization ability is required in these subtasks.\\n\\n4.2 Results on Lithography Simulation\\nTable 2 presents the performance of the tested models on all subtasks. MSE \\\\(A\\\\) and MSE \\\\(P\\\\) are the MSE losses of the aerial and printed images. Fig. 4 shows the outputs images of the models. DOINN achieves the best performance with a competitive runtime. DAMO and CFNO have comparable performance, which is beyond the reach of LithoGAN. As shown in Fig. 4b, even a coarse generation of the target shapes is too difficult for LithoGAN. This can be explained by two factors. First, LithoGAN\"}"}
{"id": "JqWtIIaS8n", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"uses a lower resolution than other methods, which makes it harder for LithoGAN to approximate the shapes in a higher resolution. Second, the convolution layers in LithoGAN progressively shrink the feature maps until they reach a size of $512 \\\\times 1 \\\\times 1$ at the intermediate layer. Since the printed image resembles the input mask, it is difficult to decode the complex shapes from such low-resolution feature maps. Thus, high-resolution features and outputs are essential for accurate lithography simulation.\\n\\n4.3 Results on Mask Optimization\\nTable 3 compares the mask optimization models on all subtasks. Fig. 5 shows the output masks of the models. While GAN-OPC has the best PVB among these methods, it sacrifices L2 and EPE. It fails to learn the complicated curves that improve the L2 loss due to its low resolution. With a moderate resolution, Neural-ILT achieves moderate performance on the first three tasks. But it generalizes well to StdContact, enabling it to achieve the best average L2 and EPE. DAMO has the best performance on the first three tasks, while CFNO achieves lower mask complexity due to the small shot counts. In mask optimization, the model designer may consider the trade-off between resolution, generalization, and complexity. It is challenging to design a model that is optimal across all metrics.\\n\\n5 Conclusion\\nIn this paper, we present LithoBench, a dataset for DNN-based lithography simulation and mask optimization with an evaluation platform. LithoBench includes 133,496 layout tiles that involve the metal and via layers of circuit layouts. It can not only support the typical setup where a model is trained and evaluated on similar tiles, but also evaluate the model's generalization ability to unseen data. Given the data, state-of-the-art DNN models for lithography simulation and mask optimization are trained and evaluated on LithoBench to show their advantages and weaknesses. We hope LithoBench can contribute to the further development of computational lithography.\\n\\nReferences\\n[1] C. Mack, *Fundamental principles of optical lithography: the science of microfabrication*. John Wiley & Sons, 2007.\\n[2] J.-S. Park et al., \u201cAn efficient rule-based OPC approach using a DRC tool for 0.18/\\\\m\\\\ asic,\u201d in *IEEE International Symposium on Quality Electronic Design (ISQED)*, 2000, pp. 81\u201385.\\n[3] A. Awad et al., \u201cA fast process variation and pattern fidelity aware mask optimization algorithm,\u201d in *IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, 2014, pp. 238\u2013245.\\n[4] J. Kuang, W.-K. Chow, and E. F. Young, \u201cA robust approach for process variation aware mask optimization,\u201d in *IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE)*, 2015, pp. 1591\u20131594.\\n[5] Y.-H. Su et al., \u201cFast lithographic mask optimization considering process variation,\u201d *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)*, vol. 35, no. 8, pp. 1345\u20131357, 2016.\\n[6] Y. Liu et al., \u201cInverse lithography technology principles in practice: Unintuitive patterns,\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992, 2005, pp. 886\u2013893.\\n[7] J.-R. Gao et al., \u201cMOSAIC: Mask optimizing solution with process window aware inverse correction,\u201d in *ACM/IEEE Design Automation Conference (DAC)*, 2014.\\n[8] Z. Yu et al., \u201cA GPU-enabled level-set method for mask optimization,\u201d *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)*, vol. 42, no. 2, pp. 594\u2013605, 2022.\\n[9] H. Yang et al., \u201cGAN-OPC: Mask optimization with lithography-guided generative adversarial nets,\u201d in *ACM/IEEE Design Automation Conference (DAC)*, 2018.\\n[10] \u2014\u2014, \u201cGAN-OPC: Mask optimization with lithography-guided generative adversarial nets,\u201d *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)*, vol. 39, no. 10, pp. 2822\u20132834, 2019.\"}"}
{"id": "JqWtIIaS8n", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B. Jiang et al., \\\"Neural-ILT: Migrating ILT to neural networks for mask printability and complexity co-optimization,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.\\n\\nG. Chen et al., \\\"DAMO: Deep agile mask optimization for full chip scale,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.\\n\\nB. Jiang et al., \\\"Neural-ILT 2.0: Migrating ilt to domain-specific and multitask-enabled neural network,\\\" IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 41, no. 8, pp. 2671\u20132684, 2021.\\n\\nG. Chen et al., \\\"DevelSet: Deep neural level set for instant mask optimization,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2021.\\n\\nQ. Wang et al., \\\"A2-ILT: GPU accelerated ilt with spatial attention mechanism,\\\" in ACM/IEEE Design Automation Conference (DAC), 2022, pp. 967\u2013972.\\n\\nH. Yang and H. Ren, \\\"Enabling scalable ai computational lithography with physics-inspired models,\\\" in IEEE/ACM Asia and South Pacific Design Automation Conference (ASPDAC), 2023, pp. 715\u2013720.\\n\\nH.-C. Shao, C.-W. Lin, and S.-Y. Fang, \\\"Data-driven approaches for process simulation and optimal proximity correction,\\\" in IEEE/ACM Asia and South Pacific Design Automation Conference (ASPDAC), 2023, pp. 721\u2013726.\\n\\nH. Yang et al., \\\"Large scale mask optimization via convolutional fourier neural operator and litho-guided self training,\\\" arXiv preprint arXiv:2207.04056, 2022.\\n\\nZ. Yu et al., \\\"A gpu-enabled level set method for mask optimization,\\\" in IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE), 2021, pp. 1835\u20131838.\\n\\nJ. Chen and H. Liu, \\\"An alternating direction method of multipliers for inverse lithography problem,\\\" arXiv preprint arXiv:2209.10814, 2022.\\n\\nW. Zhao et al., \\\"AdaOPC: A self-adaptive mask optimization framework for real design patterns,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2022.\\n\\nW. Ye et al., \\\"LithoGAN: End-to-end lithography modeling with generative adversarial networks,\\\" in ACM/IEEE Design Automation Conference (DAC), 2019.\\n\\nH. Yang et al., \\\"Generic lithography modeling with dual-band optics-inspired neural networks,\\\" in ACM/IEEE Design Automation Conference (DAC), 2022, pp. 973\u2013978.\\n\\nH. H. Hopkins, \\\"The concept of partial coherence in optics,\\\" in Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences, vol. 208, no. 1093. The Royal Society London, 1951, pp. 263\u2013277.\\n\\nA. Poonawala and P. Milanfar, \\\"Mask design for optical microlithography\u2014an inverse imaging problem,\\\" IEEE Transactions on Image Processing (TIP), vol. 16, no. 3, pp. 774\u2013788, 2007.\\n\\nJ. Zhang et al., \\\"A highly efficient optimization algorithm for pixel manipulation in inverse lithography technique,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2008, pp. 480\u2013487.\\n\\nN. Jia, A. K. Wong, and E. Y. Lam, \\\"Robust mask design with defocus variation using inverse synthesis,\\\" in Lithography Asia, vol. 7140. SPIE, 2008, pp. 440\u2013449.\\n\\nF. Liu and X. Shi, \\\"An efficient mask optimization method based on homotopy continuation technique,\\\" in IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE), 2011.\\n\\nY. Shen, N. Wong, and E. Y. Lam, \\\"Level-set-based inverse lithography for photomask synthesis,\\\" Optics Express, vol. 17, no. 26, pp. 23 690\u201323 701, 2009.\\n\\nY. Shen et al., \\\"Robust level-set-based inverse lithography,\\\" Optics Express, vol. 19, no. 6, pp. 5511\u20135521, 2011.\\n\\nW. Lv et al., \\\"Level-set-based inverse lithography for mask synthesis using the conjugate gradient and an optimal time step,\\\" Journal of Vacuum Science & Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena, vol. 31, no. 4, 2013.\"}"}
{"id": "JqWtIIaS8n", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Z. Geng et al., \\\"Fast level-set-based inverse lithography algorithm for process robustness improvement and its application,\\\" Journal of Computer Science and Technology, vol. 30, no. 3, pp. 629\u2013638, 2015.\\n\\nY. Liu et al., \\\"Inverse lithography technology principles in practice: Unintuitive patterns,\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 886\u2013893.\\n\\nL. Pang et al., \\\"Laser and e-beam mask-to-silicon with inverse lithography technology,\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 659\u2013669.\\n\\nJ. Ho et al., \\\"Real-world impacts of inverse lithography technology,\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 643\u2013650.\\n\\nA. Balasinski et al., \\\"Inverse lithography technology: verification of SRAM cell pattern,\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 881\u2013885.\\n\\nC.-Y. Hung et al., \\\"First 65nm tape-out using inverse lithography technology (ILT),\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 596\u2013604.\\n\\nP. M. Martin et al., \\\"Manufacturability study of masks created by inverse lithography technology (ILT),\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 921\u2013929.\\n\\nS. Banerjee, Z. Li, and S. R. Nassif, \\\"ICCAD-2013 CAD contest in mask optimization and benchmark suite,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2013, pp. 271\u2013274.\\n\\nS. Sun et al., \\\"Efficient ilt via multi-level lithography simulation,\\\" in ACM/IEEE Design Automation Conference (DAC), 2023.\\n\\nA. Balasinski et al., \\\"Inverse lithography technology: verification of SRAM cell pattern,\\\" in BACUS Symposium on Photomask Technology, vol. 5992. SPIE, 2005, pp. 881\u2013885.\\n\\nM. Mirza and S. Osindero, \\\"Conditional generative adversarial nets,\\\" arXiv preprint arXiv:1411.1784, 2014.\\n\\nP. Isola et al., \\\"Image-to-image translation with conditional adversarial networks,\\\" in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 1125\u20131134.\\n\\nW. Ye et al., \\\"TEMPO: Fast mask topography effect modeling with deep learning,\\\" in ACM International Symposium on Physical Design (ISPD), 2020, pp. 127\u2013134.\\n\\nZ. Li et al., \\\"Fourier neural operator for parametric partial differential equations,\\\" in International Conference on Learning Representations (ICLR), 2021.\\n\\nA. Dosovitskiy et al., \\\"An image is worth 16x16 words: Transformers for image recognition at scale,\\\" in International Conference on Learning Representations (ICLR).\\n\\nJ. A. Torres, \\\"ICCAD-2012 CAD contest in fuzzy pattern matching for physical verification and benchmark suite,\\\" in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2012, pp. 349\u2013350.\\n\\nH. Yang et al., \\\"Layout hotspot detection with feature tensor generation and deep biased learning,\\\" in ACM/IEEE Design Automation Conference (DAC), 2017.\\n\\n\u2014, \\\"Automatic layout generation with applications in machine learning engine evaluation,\\\" in ACM/IEEE Workshop on Machine Learning CAD (MLCAD), 2019.\\n\\nT. Ajayi et al., \\\"OpenROAD: Toward a self-driving, open-source digital layout implementation tool chain,\\\" in Proc. GOMACTECH, 2019, pp. 1105\u20131110.\\n\\n\u2014, \\\"Toward an open-source digital flow: First learnings from the openroad project,\\\" in ACM/IEEE Design Automation Conference (DAC), 2019.\\n\\nE. Meshcheryakov, \\\"python-gdsii \u2014 a gdsii manipulation library,\\\" https://github.com/eugmes/python-gdsii.\\n\\n\\\"Nangate 45nm library,\\\" http://www.nangate.com/.\\n\\nN. Raghuvanshi, R. Narain, and M. C. Lin, \\\"Efficient and accurate sound propagation using adaptive rectangular decomposition,\\\" IEEE Transactions on Visualization and Computer Graphics, vol. 15, no. 5, pp. 789\u2013801, 2009.\\n\\nJ. F. C. Perugachi, \\\"Adaptive-boxes,\\\" https://github.com/jnfran92/adaptive-boxes.\\n\\nA. Paszke et al., \\\"Pytorch: An imperative style, high-performance deep learning library,\\\" in Annual Conference on Neural Information Processing Systems (NeurIPS), vol. 32, 2019.\"}"}
{"id": "JqWtIIaS8n", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"S. Zheng, B. Yu, and M. Wong, \\\"OpenILT: An open source inverse lithography technique framework,\\\" in IEEE International Conference on ASIC (ASICON), 2023.\\n\\nJ. Long, E. Shelhamer, and T. Darrell, \\\"Fully convolutional networks for semantic segmentation,\\\" in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3431\u20133440.\\n\\nZ. Zhou et al., \\\"Unet++: A nested u-net architecture for medical image segmentation,\\\" in Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, 2018, pp. 3\u201311.\\n\\nT.-C. Wang et al., \\\"High-resolution image synthesis and semantic manipulation with conditional GANs,\\\" in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 8798\u20138807.\\n\\nZ. Li et al., \\\"Fourier neural operator for parametric partial differential equations,\\\" in International Conference on Learning Representations (ICLR), 2020.\\n\\nO. Ronneberger, P. Fischer, and T. Brox, \\\"U-net: Convolutional networks for biomedical image segmentation,\\\" in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015, pp. 234\u2013241.\"}"}
{"id": "JqWtIIaS8n", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Summary of LithoBench\\n\\n| Task       | MetalSet | ViaSet | StdMetal | StdContact |\\n|------------|----------|--------|----------|------------|\\n| Subsets    | MetalSet | ViaSet | StdMetal | StdContact |\\n| Training Tiles | 14,824 | 104,733 | 0 | 163 |\\n| Testing Tiles  | 1,648  | 11,642 | 271 | 165 |\\n\\n3.1 Data Collection\\n\\n3.1.1 MetalSet\\n\\nICCAD-13 benchmark [39] is a famous benchmark for metal-layer mask optimization, used in various SOTA ILT methods [7\u20139,11,13\u201315,19]. It contains 10 tiles in GLP format [39] that come from 32 nm industrial layouts. We design MetalSet to enable the training of DNN-based model that can achieve high performance on ICCAD-13 benchmark. We synthesize 16,472 tiles using the layout generation method in [48]. Each tile is randomly generated following the design rules of ICCAD-13 benchmark. The rules refer to the limitations on shape widths, distances, and areas, determined by the technology node. The original ICCAD-13 benchmark is used to evaluate DNN-based mask optimization models that are trained on MetalSet. This setting is compatible with existing methods [9, 11, 13, 14]. Fig. 2a and Fig. 2b show examples of ICCAD-13 benchmark and MetalSet.\\n\\n3.1.2 ViaSet\\n\\nFor via-layer ILT, we generate the layouts at the 45 nm technology node with the IC design tool, OpenROAD [49, 50]. We select the gcd and aes circuits from the OpenROAD project and get their layouts in GDSII format, the de facto industry standard for electronic design automation. The Python package python-gdsii [51] is used to extract the shapes on the first via layers of the circuits and save them in the GLP format. We crop the layouts into 2048 \u00d7 2048 tiles with a stride of 512 nm. Following existing ILT methods, we only include the shapes within the central region, which has a size of 1280 \u00d7 1280 nm\u00b2. Finally, we get 116,415 clips of the layout. Following the MetalSet, we select 10 tiles with different complexity for testing.\\n\\n3.1.3 StdMetal and StdContact\\n\\nStdMetal and StdContact subsets include the layout tiles of the Nangate 45 nm standard cells [52]. Nangate 45 nm is an open IC library that is widely used in academia. A standard cell is a group of transistors and interconnect structures that provide a boolean logic function (e.g., AND, OR, XOR, XNOR, inverters) or a storage function (flip-flop or latch). Since standard cells are typically the basic building blocks of digital IC, the ILT of standard cells is important for manufacturing. We crop the layouts of the standard cells in the same way as ViaSet. The StdMetal subset consists of the tiles on the first metal layer. Since the standard cells do not use via layers, we use the contact layer to build the StdContact subset, which also contains square shapes like the via layer. The 271 tiles in StdMetal are used to evaluate the generalization ability of models trained on MetalSet. Fig. 2d shows an example from StdMetal. On StdContact, we test the models trained on ViaSet with 165 tiles. We allow the finetuning on another 163 tiles because the density of shapes in StdContact is obviously higher than the density in ViaSet. Fig. 2c and Fig. 2e show the examples from ViaSet and StdContact, which can illustrate the difference in density.\"}"}
{"id": "JqWtIIaS8n", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.2 Data Preparation\\n\\nTarget Images\\nWe parse the data in the GLP format and put the shapes in the central region of a $2048 \\\\times 2048$ image. Each pixel in the image corresponds to a $1 \\\\times 1 \\\\text{nm}^2$ area of the circuit layout.\\n\\nOptimized Masks\\nWe employ an ILT method inspired by [14, 40] to get the ground truths. The lithography simulation model is given by the ICCAD-13 benchmark, which is for the 32nm technology node. Since the resolution required by 45nm is lower than 32nm, it is also applicable for 45nm designs. In the ILT forward pass, we apply average pooling, (3), (1), and (2) to the parameters $P$:\\n\\n$$Z = \\\\sigma(Z(H(\\\\sigma(M(AvgPool(P)))))),$$ (7)\\n\\nConsidering three process corners $H_{\\\\text{max}}$, $H_{\\\\text{nom}}$, and $H_{\\\\text{min}}$, we can obtain three resist images $Z_{\\\\text{max}}$, $Z_{\\\\text{nom}}$, and $Z_{\\\\text{min}}$. The loss function is defined as:\\n\\n$$L_f(Z_{\\\\text{nom}}, Z_{\\\\text{max}}, Z_{\\\\text{max}}, T) = \\\\|Z_{\\\\text{max}} - T\\\\|^2_2 + \\\\|Z_{\\\\text{max}} - Z_{\\\\text{min}}\\\\|^2_2 + L_{\\\\text{curv}}(Z_{\\\\text{nom}}),$$ (8)\\n\\nwhere $\\\\|Z_{\\\\text{max}} - T\\\\|^2_2$ and $\\\\|Z_{\\\\text{max}} - Z_{\\\\text{min}}\\\\|^2_2$ are for the minimization of L2 and PVB, respectively. $L_{\\\\text{curv}}(Z_{\\\\text{nom}})$ is the curvature loss that can improve the smoothness of the mask [14]. In the backpropagation, we update the parameters $P$ via gradient descent. Inspired by multi-level ILT [40], we optimize the mask at resolutions $256 \\\\times 256$, $512 \\\\times 512$, and $1024 \\\\times 1024$ for 200, 100, and 100 iterations, respectively. Finally, we get a $2048 \\\\times 2048$ mask by interpolating the result.\\n\\nAerial and Printed Images\\nAn aerial image $I$ is generated by applying (1) to the optimized mask $M^*$ with the nominal kernel. A printed image $Z$ is obtained by binarizing $I$ with $I_{\\\\text{th}}$.\\n\\n3.3 Tasks\\n\\n3.3.1 Lithography Simulation\\nGiven an optimized mask, the lithography simulation model outputs the corresponding aerial and printed image. For MetalSet and ViaSet, we use 90% of the data as the training set and the rest as the test set. The models trained on MetalSet can be tested on StdMetal without finetuning. The models trained on ViaSet are tested on StdContact after the finetuning on a few data.\\n\\nMean squared error (MSE) is adopted to measure the performance of lithography simulation. Furthermore, intersection over union (IOU) and pixel accuracy (PA) [23] are utilized to evaluate the quality of the predicted printed image. The IOU metric can be defined as:\\n\\n$$IOU(Z, T) = \\\\frac{Z \\\\cap T}{Z \\\\cup T},$$ (9)\\n\\nwhere $Z$ and $T$ are the regions in printed patterns and target shapes, respectively. PA is defined as:\\n\\n$$PA(Z, T) = \\\\frac{Z \\\\cap T}{T}.$$ (10)\\n\\nNote that we interpolate the output images to $2048 \\\\times 2048$ before computing any metric.\\n\\n3.3.2 Mask Optimization\\nFor mask optimization, the model predicts a well-optimized mask according to the target image. The training splits used for mask optimization are the same as for the lithography simulation task. However, the test data of MetalSet and ViaSet are different. We use the 10 testcases in the ICCAD-13 benchmark to test the model on MetalSet. For ViaSet, we select 10 representative tiles as the testcases. StdMetal and StdContact provide hundreds of challenging samples for testing.\\n\\nMask optimization models aim to produce high-quality ILT results, not just mimic the reference optimized masks. We evaluate these metrics [7, 11] after binarizing the masks and printed images:\\n\\n1. L2 loss, as defined in (5), is a metric that measures the difference between the nominal resist image and the target image. Fig. 3a visualizes the L2 loss.\\n\\n2. PVB, as defined in (6), evaluates the robustness of the mask against varying process conditions. Fig. 3b visualizes the PVB between the maximum and minimum process corners.\"}"}
{"id": "JqWtIIaS8n", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Illustration of the metrics. (a) $L_2$ measures the difference between the printed and target images. (b) $PVB$ quantifies the maximum discrepancy between process corners. (c) $EPE$ estimates the distortion of the printed image. (d) #Shots counts the rectangles needed to construct the mask.\\n\\nTable 2: Comparison on Lithography Simulation\\n\\n| Subtask | MSE | A | MSE | P | IOU | PA |\\n|---------|-----|---|-----|---|-----|----|\\n| LithoGAN | 1.98e-4 | 1.77e-2 | 0.38 | 0.43 | 8.4e-6 | 5.6e-4 |\\n| DAMO | 2.6e-4 | 1.47e-3 | 0.47 | 0.53 | 3.0e-6 | 5.0e-4 |\\n| DOINN | 1.98e-4 | 1.77e-2 | 0.38 | 0.43 | 8.4e-6 | 5.6e-4 |\\n| CFNO | 2.6e-4 | 1.47e-3 | 0.47 | 0.53 | 3.0e-6 | 5.0e-4 |\\n\\nAverage: 1.3e-3 | 1.4e-2 | 0.29 | 0.33 | 8.2e-5 | 5.2e-4\\n\\nRuntime: 0.013s/image | 0.030s/image | 0.017s/image | 0.035s/image\\n\\n3. As shown in Fig. 3c, edge placement error (EPE) estimates the distortion of the resist image. We sample probe points equidistantly on horizontal and vertical edges of the target patterns. If the distance from the target pattern to the printed pattern is larger than the EPE constraint, it produces an EPE violation. The number of EPE violations is the $EPE$ score of the mask.\\n\\n4. Shot count (#Shots) is the number of rectangular shots for replicating the shapes on the mask. It can evaluate the complexity of an optimized mask. Fig. 3d shows an example, where a shape is fitted by rectangular shots. In LithoBench, we compute the shot count using adaptive rectangular decomposition [53] with adaptive-boxes [54] (MIT license).\\n\\nTable 1 summarizes the statistics of LithoBench.\\n\\n4 Experiments\\n\\n4.1 Benchmarked Models\\n\\n4.1.1 Lithography Simulation Models\\n\\nMultiple SOTA models are implemented using PyTorch [55] and OpenILT [56] on RTX3090 GPU. For lithography simulation, we implement LithoGAN [22], DAMO [12], DOINN [23], and CFNO [16]. The last layer of each model outputs two channels as the aerial and printed images. These models minimize the MSE between their outputs and the ground truths.\\n\\nLithoGAN\\n\\nA CGAN is employed to fit the reference lithography simulation model. The generator of the CGAN is a fully convolutional network (FCN) [57] and the discriminator is a convolutional neural network (CNN). Images are downsampled to $256 \\\\times 256$ and input to the model. Note that different models may vary in image resolution to make trade-offs between accuracy and runtime.\"}"}
{"id": "JqWtIIaS8n", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Comparison on Mask Optimization\\n\\n| Subtask        | GAN-OPC | Neural-ILT | DAMO | CFNO |\\n|----------------|---------|------------|------|------|\\n| L\u2082 PVB EPE Shots | 43414 41290 8.7 574 | 36670 42666 7.3 476 | 32579 41173 5.4 | 523 |\\n| L\u2082 PVB EPE Shots | 14767 6686 8.3 166 | 12723 8537 6.2 263 | 9962 9962 0.0 176 | 8949 9890 0.1 184 |\\n| Average        | 41372 19156 23.7 368 | 23715 29072 4.8 344 | 26056 27651 8.0 394 | 38578 25196 18.0 |\\n\\nRuntime: 0.010 s / image (GAN-OPC), 0.025 s / image (Neural-ILT), 0.028 s / image (DAMO), 0.040 s / image (CFNO)\\n\\nFigure 5: Mask optimization. (a) Ground truth, (b) GAN-OPC, (c) Neural-ILT, (d) DAMO, (e) CFNO.\\n\\nDAMO\\n\\nIt improves the CGAN for lithography simulation with the backbone based on UNet++ [58] and the multiscale discriminator inspired by pix2pixHD [59]. The resolution of DAMO is 1024 \u00d7 1024, which is significantly higher than LithoGAN.\\n\\nDOINN\\n\\nInspired by Fourier Neural Operator (FNO) [60], DOINN utilizes a novel reduced FNO architecture to fit the lithography simulation model. Its resolution is 1024 \u00d7 1024.\\n\\nCFNO\\n\\nCombining the principles of Vision Transformer (ViT) [45] and FNO, the CFNO module is designed for efficient global layout embedding and resolving stitching issues caused by long-range dependency. The resolution for CFNO is also 1024 \u00d7 1024.\\n\\n4.1.2 Mask Optimization Models\\n\\nFor mask optimization, we implement GAN-OPC [9], Neural-ILT [11], DAMO [12], and CFNO [16].\\n\\nGAN-OPC\\n\\nCGAN also inspires the design of GAN-OPC. The training of GAN-OPC consists of two stages. In the first stage called ILT-guided pretraining, we train the generator to minimize the MSE between its outputs and the optimized masks. The second stage is based on the training process of GAN. During the training of the generator, we use the L\u2082 loss formulated by (5) as an additional objective, where the printed image \\\\( Z_{\\\\text{nom}} \\\\) is obtained by the reference lithography simulation model. GAN-OPC uses a resolution of 256 \u00d7 256.\\n\\nNeural-ILT\\n\\nA UNet [61] is utilized in Neural-ILT to predict the optimized mask. Neural-ILT also has a pretraining stage like GAN-OPC. In the second stage, it uses \\\\( \\\\text{L}_2(Z_{\\\\text{nom}}, T) + \\\\text{PVB}(Z_{\\\\text{max}}, Z_{\\\\text{min}}) \\\\) as the objective function. The resolution of Neural-ILT is 512 \u00d7 512.\\n\\nDAMO and CFNO use the same architectures as in lithography simulation.\\n\\n4.1.3 Subtasks\\n\\nFor lithography simulation and mask optimization, we benchmark the models with the following subtasks: (1) training on MetalSet, testing on MetalSet; (2) training on ViaSet, testing on ViaSet; (3) training on MetalSet, testing on StdMetal; (4) training on ViaSet, testing on StdContact. The last two are more challenging since high generalization ability is required in these subtasks.\\n\\n4.2 Results on Lithograph Simulation\\n\\nTable 2 presents the performance of the tested models on all subtasks. MSE_A and MSE_P are the MSE losses of the aerial and printed images. Fig. 4 shows the outputs images of the models. DOINN achieves the best performance with a competitive runtime. DAMO and CFNO have comparable performance, which is beyond the reach of LithoGAN. As shown in Fig. 4b, even a coarse generation of the target shapes is too difficult for LithoGAN. This can be explained by two factors. First, LithoGAN...\"}"}
{"id": "JqWtIIaS8n", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"LithoBench: Benchmarking AI Computational Lithography for Semiconductor Manufacturing\\n\\nSu Zheng, Haoyu Yang, Binwu Zhu, Bei Yu, Martin D.F. Wong\\n\\n1. The Chinese University of Hong Kong\\n2. nVIDIA, Austin, USA\\n3. Hong Kong Baptist University\\n\\nAbstract\\nComputational lithography provides algorithmic and mathematical support for resolution enhancement in optical lithography, which is critical for semiconductor manufacturing. The time-consuming lithography simulation and mask optimization processes limit the practical application of inverse lithography technology (ILT), a promising solution to the challenges of advanced-node lithography. Although machine learning for ILT has shown promise for reducing the computational burden, this field lacks a dataset that can train the models thoroughly and evaluate the performance comprehensively. To boost the development of AI-driven computational lithography, we present the LithoBench dataset, a collection of circuit layout tiles for deep-learning-based lithography simulation and mask optimization. LithoBench consists of more than 120k tiles that are cropped from real circuit designs or synthesized according to topologies of widely adopted ILT testcases. Ground truths are generated by a famous lithography model in academia and an advanced ILT method. We provide a framework to design and evaluate deep neural networks (DNNs) with the data. The framework is used to benchmark state-of-the-art models on lithography simulation and mask optimization. LithoBench is available at https://github.com/shelljane/lithobench.\\n\\n1 Introduction\\nSemiconductor lithography transfers circuit patterns drawn on a mask onto a silicon wafer, which is essential for the fabrication of integrated circuits (IC). It typically accounts for about 30% of the cost of IC manufacturing. As transistor sizes continue to shrink, lithography tends to be the technical limiting factor for further advances [1]. Diffraction or process effects may distort the patterns on the wafer, leading to performance degradation and even failures. Given the importance, how to ensure the correctness of semiconductor lithography becomes a critical issue in industry and academia.\\n\\nOptical proximity correction (OPC) is a technique used to improve the accuracy and quality of lithography patterns on semiconductor wafers. OPC evolves from rule-based methods [2] to model-based approaches [3\u20135], improving the resilience to manufacturing variation. Inverse lithography technology (ILT) [6\u20138] is a mathematically rigorous inverse approach that optimizes the mask to achieve the desired results on the wafer. It has been explored and developed as the next generation of OPC, promising a solution to challenges of advanced technology such as extreme ultraviolet (EUV). However, there exist significant challenges that limit the broad application of ILT. A major reason is that ILT typically consumes a significant amount of runtime, making it challenging to implement ILT at a production-level scale. Moreover, the patterns generated by ILT algorithms may be too complex to be produced efficiently. To alleviate the problems above, DNN-based ILT algorithms have been proposed to reduce the runtime and complexity [9 \u201317]. Compared with traditional methods, the improvement of DNN-based ILT algorithms has two aspects. Firstly, unlike traditional methods that...\"}"}
{"id": "JqWtIIaS8n", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"require multiple iterations to optimize the mask, DNN-based methods can generate a mask in one forward pass. A few iterations of finetuning can further improve the quality of the mask. Secondly, by incorporating loss functions for complexity reduction, deep learning methods can remarkably improve the printability of ILT results [13, 14]. Deep learning shows great potential in advancing ILT. Integrated circuits are represented by multi-layer layouts for manufacturing. A mask contains the patterns of one layout layer, optimized by ILT algorithms to produce desired printed patterns on silicon wafers. To achieve affordable runtimes, ILT algorithms typically generate the entire mask by optimizing fixed-size tiles cropped from the layout layer [18]. Fig. 1a presents a representative workflow of traditional ILT algorithms, which optimizes the mask iteratively. At each iteration, the lithography simulation model can output the printed image after the lithography processes. After that, the loss function evaluates the printed image in terms of error (L2 loss), process variation band (PVB), complexity (cpx.), etc. Given a loss function, the mask can be optimized by gradient descent [7] and other methods [19, 20]. Fig. 1b shows the DNN-based ILT flow. The input is the target image $T$, which contains the target shapes that should be printed. The DNN ILT model outputs the optimized mask $M^*$ in one forward pass, which is significantly faster than traditional ILT.\\n\\nIn recent years, researchers have proposed various DNN-based ILT methods [9 \u201317], which can significantly boost the speed and performance of ILT with excellent initialization, refinement, and GPU acceleration. However, since the ILT methods are evaluated in different scenarios with different training data, it is difficult to compare them comprehensively and challenging to apply them in production. Specifically, circuit layouts typically consist of multiple layers of patterns. The shape, size, and density of the patterns vary from layer to layer. An ILT method may have only been evaluated on metal-layer [14] or via-layer [12] testcases. Nevertheless, a via layer typically contains square shapes, while a metal layer can include diverse rectilinear polygons. It is questionable to assert that one of the methods above is better because they are not evaluated in the same scenarios. In addition, some models are trained on synthetic data [9], while others focus on real-world designs [21]. Therefore, a representative and comprehensive dataset should cover metal and via layers, as well as synthetic and real-world designs. It is valuable to construct a common dataset that can train and evaluate DNN ILT models in various scenarios.\\n\\nTo evaluate ILT methods, multiple metrics should be considered. For example, L2 loss measures the difference between the printed patterns and the target shapes. PVB estimates the robustness of the mask against process variations. Shot count shows the complexity of the mask, which affects the manufacturing time and cost. Runtime is also an important factor. To choose an appropriate algorithm, users usually need to make a trade-off between the metrics. As a result, there is a need for a platform that can effectively benchmark various ILT methods using comprehensive metrics.\\n\\nDNN can be employed in ILT for lithography simulation or mask optimization. In simple terms, the output of ILT is an optimized mask $M^*$, which can get similar results as the target patterns $T$ after the lithography processes $G(M^*)$. Existing works [22, 23] approximate the lithography processes $G(M^*)$ with DNN-based lithography simulation models, which can not only provide faster evaluation of the mask quality but also be used in mask refinement. DNN-based mask optimization models [9,11,12,16] are designed to directly obtain the optimized mask, formulated by $M^* = F(T)$.\\n\\nTo meet the above requirements, we present LithoBench, a collection of circuit layout tiles to train DNN models for lithography simulation and mask optimization. Its benchmarking platform can provide an extensive evaluation of the models. Our contributions are summarized as follows.\"}"}
{"id": "JqWtIIaS8n", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We assemble a dataset for DNN-based lithography simulation and mask optimization, which not only contains synthetic and real-world layout tiles but also covers metal and via layers. It is the first large-scale dataset for computational lithography built from real-world designs.\\n\\nWe implement a platform to evaluate the DNN models for lithography simulation and mask optimization. Users can design and select appropriate models with our platform by benchmarking them in terms of quality, robustness, complexity, runtime, etc.\\n\\nWe train and evaluate state-of-the-art (SOTA) DNN models for lithography simulation and mask optimization on LithoBench, providing a comprehensive assessment of them.\\n\\n2 Related Work\\n\\nThis section provides the fundamentals of ILT. We begin by discussing the commonly used lithography simulation method. Next, we describe typical ILT methods that solve mask optimization via numerical optimization. Then we review the latest advancements in DNN models for lithography simulation and mask optimization. Finally, LithoBench is compared to existing datasets about lithography.\\n\\n2.1 Lithography Simulation\\n\\nThe lithography simulation targets to approximate the real lithography process in chip manufacturing and provides an accurate estimation of the manufactured designs on silicon wafers. Lithography simulation consists of the optical projection and photoresist models. In optical projection, incident light passes through the mask, transmitting the spatial information of the mask patterns $M$ to the optical projection system. This results in the transformation of the input light intensity distribution into an aerial intensity distribution on the wafer plane. The intensity distribution is commonly represented by an aerial image $I$.\\n\\n$$I = H(M) = \\\\sum_{k} \\\\mu_k |h_k \\\\otimes M|^2,$$\\n\\nwhere $h_k$ is the $k$th optical kernel function and $\\\\mu_k$ is the corresponding weight. The notation $\\\\otimes$ stands for convolution operation. $| \\\\cdot |^2$ gets the squared modulus of each element.\\n\\nAfter optical projection, a photoresist model transfers the aerial image $I$ to the printed image $Z$, which is also called resist image. To enable gradient descent in ILT algorithms, researchers commonly design the photoresist model as:\\n\\n$$Z(x, y) = \\\\sigma Z(I(x, y)) = 1 + e^{-\\\\alpha (I - I_{th})},$$\\n\\nwhere $I_{th}$ is the intensity threshold, $\\\\alpha$ is a constant number that controls the steepness of the function, and $(x, y)$ represents a coordinate on the aerial or resist image. Lithography simulation transforms the mask $M$ to the resist image $Z$ with the optical projection and photoresist models.\\n\\n2.2 Mask Optimization via ILT\\n\\nThe application of ILT in industrial productions began in 2005. It tries to solve the mask pattern such that after the lithography process, the remaining pattern on the silicon wafer is as close as the original design. Thus, ILT can be viewed as the inverse process of lithography simulation. In recent years, the ICCAD-13 benchmark has facilitated extensive research on ILT in academia, such as MOSAIC, MultiLevel, GPU-LevelSet, etc.\\n\\nAn ILT algorithm usually optimizes a parameter matrix $P$ that can be transformed to the mask image $M$ with the following function:\\n\\n$$M(x, y) = \\\\sigma M(P(x, y)) = 1 + e^{-\\\\beta (P - \\\\gamma)},$$\\n\\nwhere $\\\\beta$ is the constant steepness factor and $\\\\gamma$ is a constant offset. With this function, the values in $M$ can be limited in $[0, 1]$, while the values in $P$ have no limitation. Finally, the transformation from the parameter matrix $P$ to the resist image $Z$ can be formulated as:\\n\\n$$Z = \\\\sigma Z(H(\\\\sigma M(P))).$$\"}"}
{"id": "JqWtIIaS8n", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In mask manufacturing, the printed patterns on the wafer may differ drastically under varying process conditions (e.g. depth of focus, intensity of incident light). ILT algorithms typically consider three process corners, maximum, nominal, and minimum. Specifically, three series of optical kernels are employed to form the optical projection models $H_{\\\\text{max}}$, $H_{\\\\text{nom}}$, and $H_{\\\\text{min}}$. The corresponding resist images can be denoted by $Z_{\\\\text{max}}$, $Z_{\\\\text{nom}}$, and $Z_{\\\\text{min}}$.\\n\\n$L^2$ loss measures the difference between the nominal resist image and the target image, defined as:\\n\\n$$L^2(Z_{\\\\text{nom}}, T) = \\\\|Z_{\\\\text{nom}} - T\\\\|^2_2.$$\\n\\n(5)\\n\\nTo enhance the robustness against varying process conditions, ILT algorithms are commonly required to reduce the process variation band (PVB) defined as:\\n\\n$$\\\\text{PVB}(Z_{\\\\text{max}}, Z_{\\\\text{min}}) = \\\\|Z_{\\\\text{max}} - Z_{\\\\text{min}}\\\\|^2_2.$$\\n\\n(6)\\n\\nILT loss functions are usually based on $L^2(Z_{\\\\text{nom}}, T)$, $\\\\text{PVB}(Z_{\\\\text{max}}, Z_{\\\\text{min}})$, and additional components like complexity losses. Given the loss function, the parameter matrix $P$ can be optimized by gradient descent. The final parameter matrix $P^*$ can be binarized to obtain the optimized mask $M^*$ by checking whether each element satisfies $\\\\sigma_{M^*}(P^*(x, y)) > 0.5$.\\n\\n2.3 DNN-based Methods\\n\\nFor lithography simulation, conditional generative adversarial network (CGAN) [41, 42] is utilized in LithoGAN [22], DAMO [12], and TEMPO [43]. Fourier Neural Operator (FNO) [44] inspires DOINN [23]. These works suggest that lithography simulation via DNN models is a rapidly developing field. To distinguish the lithography model based on Hopkins' diffraction theory from the DNN-based models, we refer to the theory-based one as the reference lithography simulation model.\\n\\nIn mask optimization, DNN-based methods also achieve tremendous success. For instance, GAN-OPC [9] trains a CGAN guided by reference optimized masks and lithography simulation for mask optimization. Its training scheme inspires subsequent research, such as Neural-ILT [11] and DAMO [12]. CFNO [16] presents a powerful model inspired by Vision Transformer [45] and FNO.\\n\\n2.4 Lithography Datasets\\n\\nICCAD-13 [39] is a famous benchmark for mask optimization consisting of $10 \\\\mu m \\\\times 2 \\\\mu m$ metal-layer clips. However, it is targeting numerical optimization solutions only and the 10 instances are too small to fit AI solutions. GAN-OPC [9] releases around 4k synthetic tiles for metal-layer mask optimization. However, its size is small for a thorough training and the quality of the optimized masks falls behind SOTA results. Furthermore, it does not provide real-world designs and via-layer tiles, which limits its applications. Another limitation of existing datasets is that they do not support DNN-based lithography simulation, which is also a critical step in computational lithography. To overcome these weaknesses, we propose LithoBench, the first comprehensive dataset that simultaneously supports lithography simulation and mask optimization. Unlike previous datasets, LithoBench includes abundant and diverse data that covers synthetic and real-world layout tiles, as well as metal and via layers. The ground truths are generated by SOTA method, providing the high-quality data.\\n\\nICCAD-12 [46] is a dataset for lithography hotspot detection (HSD), which aims to find the locations on the mask that may lead to defects on the printed patterns. HSD only indicates the presence of defects in certain regions, but provides little information for mask optimization. LithoBench focuses on lithography simulation, which is more important than HSD, providing detailed information about the printed patterns. Besides, AI approaches for HSD have been deeply studied in literature and are mature in production flows. Therefore, HSD-related benchmarks are not the scope of this paper.\\n\\n3 Dataset\\n\\nLithoBench consists of 133,496 tiles that forms four subsets: MetalSet, ViaSet, StdMetal, and StdContact. MetalSet and ViaSet are large subsets primarily used for training, compatible with existing research. StdMetal and StdContact are small subsets for evaluating the generalization ability of the models. In each subset, we prepare the target images, optimized masks, aerial images, and printed images. In lithography simulation tasks, the input of the DNN model is an optimized mask, and the outputs include an aerial image and a printed image. In mask optimization tasks, the input and output are a target image and the optimized mask, respectively.\"}"}
{"id": "JqWtIIaS8n", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"uses a lower resolution than other methods, which makes it harder for LithoGAN to approximate the shapes in a higher resolution. Second, the convolution layers in LithoGAN progressively shrink the feature maps until they reach a size of $512 \\\\times 1 \\\\times 1$ at the intermediate layer. Since the printed image resembles the input mask, it is difficult to decode the complex shapes from such low-resolution feature maps. Thus, high-resolution features and outputs are essential for accurate lithography simulation.\\n\\n4.3 Results on Mask Optimization\\n\\nTable 3 compares the mask optimization models on all subtasks. Fig. 5 shows the output masks of the models. While GAN-OPC has the best PVB among these methods, it sacrifices L2 and EPE. It fails to learn the complicated curves that improve the L2 loss due to its low resolution. With a moderate resolution, Neural-ILT achieves moderate performance on the first three tasks. But it generalizes well to StdContact, enabling it to achieve the best average L2 and EPE. DAMO has the best performance on the first three tasks, while CFNO achieves lower mask complexity due to the small shot counts. In mask optimization, the model designer may consider the trade-off between resolution, generalization, and complexity. It is challenging to design a model that is optimal across all metrics.\\n\\n5 Conclusion\\n\\nIn this paper, we present LithoBench, a dataset for DNN-based lithography simulation and mask optimization with an evaluation platform. LithoBench includes 133,496 layout tiles that involve the metal and via layers of circuit layouts. It can not only support the typical setup where a model is trained and evaluated on similar tiles, but also evaluate the model's generalization ability to unseen data. Given the data, state-of-the-art DNN models for lithography simulation and mask optimization are trained and evaluated on LithoBench to show their advantages and weaknesses. We hope LithoBench can contribute to the further development of computational lithography.\\n\\nReferences\\n\\n[1] C. Mack, *Fundamental principles of optical lithography: the science of microfabrication*. John Wiley & Sons, 2007.\\n\\n[2] J.-S. Park et al., \u201cAn efficient rule-based OPC approach using a DRC tool for 0.18/\u03bcm ASIC,\u201d in IEEE International Symposium on Quality Electronic Design (ISQED), 2000, pp. 81\u201385.\\n\\n[3] A. Awad et al., \u201cA fast process variation and pattern fidelity aware mask optimization algorithm,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2014, pp. 238\u2013245.\\n\\n[4] J. Kuang, W.-K. Chow, and E. F. Young, \u201cA robust approach for process variation aware mask optimization,\u201d in IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE), 2015, pp. 1591\u20131594.\\n\\n[5] Y.-H. Su et al., \u201cFast lithographic mask optimization considering process variation,\u201d IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 35, no. 8, pp. 1345\u20131357, 2016.\\n\\n[6] Y. Liu et al., \u201cInverse lithography technology principles in practice: Unintuitive patterns,\u201d in BACUS Symposium on Photomask Technology, vol. 5992, 2005, pp. 886\u2013893.\\n\\n[7] J.-R. Gao et al., \u201cMOSAIC: Mask optimizing solution with process window aware inverse correction,\u201d in ACM/IEEE Design Automation Conference (DAC), 2014.\\n\\n[8] Z. Yu et al., \u201cA GPU-enabled level-set method for mask optimization,\u201d IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 42, no. 2, pp. 594\u2013605, 2022.\\n\\n[9] H. Yang et al., \u201cGAN-OPC: Mask optimization with lithography-guided generative adversarial nets,\u201d in ACM/IEEE Design Automation Conference (DAC), 2018.\\n\\n[10] \u2014\u2014, \u201cGAN-OPC: Mask optimization with lithography-guided generative adversarial nets,\u201d IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 39, no. 10, pp. 2822\u20132834, 2019.\"}"}
{"id": "JqWtIIaS8n", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B. Jiang et al., \u201cNeural-ILT: Migrating ILT to neural networks for mask printability and complexity co-optimization,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.\\n\\nG. Chen et al., \u201cDAMO: Deep agile mask optimization for full chip scale,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.\\n\\nB. Jiang et al., \u201cNeural-ILT 2.0: Migrating ILT to domain-specific and multitask-enabled neural network,\u201d IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), vol. 41, no. 8, pp. 2671\u20132684, 2021.\\n\\nG. Chen et al., \u201cDevelSet: Deep neural level set for instant mask optimization,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2021.\\n\\nQ. Wang et al., \u201cA2-ILT: GPU accelerated ILT with spatial attention mechanism,\u201d in ACM/IEEE Design Automation Conference (DAC), 2022, pp. 967\u2013972.\\n\\nH. Yang and H. Ren, \u201cEnabling scalable AI computational lithography with physics-inspired models,\u201d in IEEE/ACM Asia and South Pacific Design Automation Conference (ASPDAC), 2023, pp. 715\u2013720.\\n\\nH.-C. Shao, C.-W. Lin, and S.-Y. Fang, \u201cData-driven approaches for process simulation and optimal proximity correction,\u201d in IEEE/ACM Asia and South Pacific Design Automation Conference (ASPDAC), 2023, pp. 721\u2013726.\\n\\nH. Yang et al., \u201cLarge scale mask optimization via convolutional fourier neural operator and litho-guided self training,\u201d arXiv preprint arXiv:2207.04056, 2022.\\n\\nZ. Yu et al., \u201cA gpu-enabled level set method for mask optimization,\u201d in IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE), 2021, pp. 1835\u20131838.\\n\\nJ. Chen and H. Liu, \u201cAn alternating direction method of multipliers for inverse lithography problem,\u201d arXiv preprint arXiv:2209.10814, 2022.\\n\\nW. Zhao et al., \u201cAdaOPC: A self-adaptive mask optimization framework for real design patterns,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2022.\\n\\nW. Ye et al., \u201cLithoGAN: End-to-end lithography modeling with generative adversarial networks,\u201d in ACM/IEEE Design Automation Conference (DAC), 2019.\\n\\nH. Yang et al., \u201cGeneric lithography modeling with dual-band optics-inspired neural networks,\u201d in ACM/IEEE Design Automation Conference (DAC), 2022, pp. 973\u2013978.\\n\\nH. H. Hopkins, \u201cThe concept of partial coherence in optics,\u201d in Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences, vol. 208, no. 1093. The Royal Society London, 1951, pp. 263\u2013277.\\n\\nA. Poonawala and P. Milanfar, \u201cMask design for optical microlithography\u2014an inverse imaging problem,\u201d IEEE Transactions on Image Processing (TIP), vol. 16, no. 3, pp. 774\u2013788, 2007.\\n\\nJ. Zhang et al., \u201cA highly efficient optimization algorithm for pixel manipulation in inverse lithography technique,\u201d in IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2008, pp. 480\u2013487.\\n\\nN. Jia, A. K. Wong, and E. Y. Lam, \u201cRobust mask design with defocus variation using inverse synthesis,\u201d in Lithography Asia, vol. 7140. SPIE, 2008, pp. 440\u2013449.\\n\\nF. Liu and X. Shi, \u201cAn efficient mask optimization method based on homotopy continuation technique,\u201d in IEEE/ACM Proceedings Design, Automation and Test in Europe (DATE), 2011.\\n\\nY. Shen, N. Wong, and E. Y. Lam, \u201cLevel-set-based inverse lithography for photomask synthesis,\u201d Optics Express, vol. 17, no. 26, pp. 23 690\u201323 701, 2009.\\n\\nY. Shen et al., \u201cRobust level-set-based inverse lithography,\u201d Optics Express, vol. 19, no. 6, pp. 5511\u20135521, 2011.\\n\\nW. Lv et al., \u201cLevel-set-based inverse lithography for mask synthesis using the conjugate gradient and an optimal time step,\u201d Journal of Vacuum Science & Technology B, Nanotechnology and Microelectronics: Materials, Processing, Measurement, and Phenomena, vol. 31, no. 4, 2013.\"}"}
{"id": "JqWtIIaS8n", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Z. Geng et al., \u201cFast level-set-based inverse lithography algorithm for process robustness improvement and its application,\u201d *Journal of Computer Science and Technology*, vol. 30, no. 3, pp. 629\u2013638, 2015.\\n\\nY. Liu et al., \u201cInverse lithography technology principles in practice: Unintuitive patterns,\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 886\u2013893.\\n\\nL. Pang et al., \u201cLaser and e-beam mask-to-silicon with inverse lithography technology,\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 659\u2013669.\\n\\nJ. Ho et al., \u201cReal-world impacts of inverse lithography technology,\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 643\u2013650.\\n\\nA. Balasinski et al., \u201cInverse lithography technology: verification of SRAM cell pattern,\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 881\u2013885.\\n\\nC.-Y. Hung et al., \u201cFirst 65nm tape-out using inverse lithography technology (ILT),\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 596\u2013604.\\n\\nP. M. Martin et al., \u201cManufacturability study of masks created by inverse lithography technology (ILT),\u201d in *BACUS Symposium on Photomask Technology*, vol. 5992. SPIE, 2005, pp. 921\u2013929.\\n\\nS. Banerjee, Z. Li, and S. R. Nassif, \u201cICCAD-2013 CAD contest in mask optimization and benchmark suite,\u201d in *IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, 2013, pp. 271\u2013274.\\n\\nS. Sun et al., \u201cEfficient ilt via multi-level lithography simulation,\u201d in *ACM/IEEE Design Automation Conference (DAC)*, 2023.\\n\\nM. Mirza and S. Osindero, \u201cConditional generative adversarial nets,\u201d *arXiv preprint arXiv:1411.1784*, 2014.\\n\\nP. Isola et al., \u201cImage-to-image translation with conditional adversarial networks,\u201d in *IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2017, pp. 1125\u20131134.\\n\\nW. Ye et al., \u201cTEMPO: Fast mask topography effect modeling with deep learning,\u201d in *ACM International Symposium on Physical Design (ISPD)*, 2020, pp. 127\u2013134.\\n\\nZ. Li et al., \u201cFourier neural operator for parametric partial differential equations,\u201d in *International Conference on Learning Representations (ICLR)*, 2021.\\n\\nA. Dosovitskiy et al., \u201cAn image is worth 16x16 words: Transformers for image recognition at scale,\u201d in *International Conference on Learning Representations (ICLR)*.\\n\\nJ. A. Torres, \u201cICCAD-2012 CAD contest in fuzzy pattern matching for physical verification and benchmark suite,\u201d in *IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, 2012, pp. 349\u2013350.\\n\\nH. Yang et al., \u201cLayout hotspot detection with feature tensor generation and deep biased learning,\u201d in *ACM/IEEE Design Automation Conference (DAC)*, 2017.\\n\\n\u2014\u2014, \u201cAutomatic layout generation with applications in machine learning engine evaluation,\u201d in *ACM/IEEE Workshop on Machine Learning CAD (MLCAD)*, 2019.\\n\\nT. Ajayi et al., \u201cOpenROAD: Toward a self-driving, open-source digital layout implementation tool chain,\u201d in *Proc. GOMACTECH*, 2019, pp. 1105\u20131110.\\n\\n\u2014\u2014, \u201cToward an open-source digital flow: First learnings from the openroad project,\u201d in *ACM/IEEE Design Automation Conference (DAC)*, 2019.\\n\\nE. Meshcheryakov, \u201cpython-gdsii \u2014 a gdsii manipulation libarary,\u201d https://github.com/eugmes/python-gdsii.\\n\\n\u201cNangate 45nm library,\u201d http://www.nangate.com/.\\n\\nN. Raghuvanshi, R. Narain, and M. C. Lin, \u201cEfficient and accurate sound propagation using adaptive rectangular decomposition,\u201d *IEEE Transactions on Visualization and Computer Graphics*, vol. 15, no. 5, pp. 789\u2013801, 2009.\\n\\nJ. F. C. Perugachi, \u201cAdaptive-boxes,\u201d https://github.com/jnfran92/adaptive-boxes.\\n\\nA. Paszke et al., \u201cPytorch: An imperative style, high-performance deep learning library,\u201d in *Annual Conference on Neural Information Processing Systems (NeurIPS)*, vol. 32, 2019.\"}"}
{"id": "JqWtIIaS8n", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"S. Zheng, B. Yu, and M. Wong, \u201cOpenILT: An open source inverse lithography technique framework,\u201d in IEEE International Conference on ASIC (ASICON), 2023.\\n\\nJ. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3431\u20133440.\\n\\nZ. Zhou et al., \u201cUnet++: A nested u-net architecture for medical image segmentation,\u201d in Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, 2018, pp. 3\u201311.\\n\\nT.-C. Wang et al., \u201cHigh-resolution image synthesis and semantic manipulation with conditional GANs,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 8798\u20138807.\\n\\nZ. Li et al., \u201cFourier neural operator for parametric partial differential equations,\u201d in International Conference on Learning Representations (ICLR), 2020.\\n\\nO. Ronneberger, P. Fischer, and T. Brox, \u201cU-net: Convolutional networks for biomedical image segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015, pp. 234\u2013241.\"}"}
