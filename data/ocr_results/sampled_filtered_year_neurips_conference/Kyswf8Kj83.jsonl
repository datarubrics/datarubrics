{"id": "Kyswf8Kj83", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"TwiBot-22: Towards Graph-Based Twitter Bot Detection\\n\\nShangbin Feng\\nZhaoxuan Tan\\nHerun Wan\\nNingnan Wang\\nZilong Chen\\nBinchi Zhang\\nQinghua Zheng\\nWenqian Zhang\\nZhenyu Lei\\nShujie Yang\\nXinshun Feng\\nQingyue Zhang\\nHongrui Wang\\nYuhan Liu\\nYuyang Bai\\nHeng Wang\\nZijian Cai\\nYanbo Wang\\nLijing Zheng\\nZihan Ma\\nJundong Li\\nMinnan Luo\\n\\nXi'an Jiaotong University\\nUniversity of Washington\\nTsinghua University\\nUniversity of Virginia\\n\\nAbstract\\n\\nTwitter bot detection has become an increasingly important task to combat misinformation, facilitate social media moderation, and preserve the integrity of the online discourse. State-of-the-art bot detection methods generally leverage the graph structure of the Twitter network, and they exhibit promising performance when confronting novel Twitter bots that traditional methods fail to detect. However, very few of the existing Twitter bot detection datasets are graph-based, and even these few graph-based datasets suffer from limited dataset scale, incomplete graph structure, as well as low annotation quality. In fact, the lack of a large-scale graph-based Twitter bot detection benchmark that addresses these issues has seriously hindered the development and evaluation of novel graph-based bot detection approaches. In this paper, we propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark that presents the largest dataset to date, provides diversified entities and relations on the Twitter network, and has considerably better annotation quality than existing datasets. In addition, we re-implement 35 representative Twitter bot detection baselines and evaluate them on 9 datasets, including TwiBot-22, to promote a fair comparison of model performance and a holistic understanding of research progress. To facilitate further research, we consolidate all implemented codes and datasets into the TwiBot-22 evaluation framework, where researchers could consistently evaluate new models and datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation framework are publicly available at https://twibot22.github.io/.\\n\\n1 Introduction\\n\\nAutomated users on Twitter, also known as Twitter bots, have become a widely known and well-documented phenomenon. Over the past decade, malicious Twitter bots were responsible for a wide range of problems such as online disinformation [Cui et al., 2020, Wang et al., 2020, Lu and Li, 2020], election interference [Howard et al., 2016, Bradshaw et al., 2017, Rossi et al., 2020, Ferrara, 2017], extremism campaign [Ferrara et al., 2016, Marcellino et al., 2020], and even the spread of...\"}"}
{"id": "Kyswf8Kj83", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Compared to real-world Twitter, existing Twitter bot detection datasets suffer from (a) limited dataset scale, (b) incomplete graph structure, and (c) poor annotation quality. These societal challenges have called for automatic Twitter bot detection models to mitigate their negative influence.\\n\\nExisting Twitter bot detection models are generally feature-based, where researchers propose to extract numerical features from user information such as metadata, user timeline, and follow relationships. However, feature-based approaches are susceptible to adversarial manipulation, i.e., when bot operators try to avoid detection by tampering with these hand-crafted features.\\n\\nResearchers also proposed text-based approaches, where text analysis techniques such as word embeddings, recurrent neural networks, and pre-trained language models are leveraged to analyze tweet content and identify malicious intent. However, new generations of Twitter bots often intersperse malicious content with normal tweets stolen from genuine users, thus their bot nature becomes more subtle to text-based methods.\\n\\nWith the advent of graph neural networks, recent advances focus on developing graph-based Twitter bot detection models. These methods interpret users as nodes and follow relationships as edges to leverage graph mining techniques such as GCN, R-GCN, and RGT for graph-based bot detection. In fact, recent research have shown that graph-based approaches achieve state-of-the-art performance, are capable of detecting novel Twitter bots, and are better at addressing various challenges facing Twitter bot detection.\\n\\nHowever, the development and evaluation of graph-based Twitter bot detection models are poorly supported by existing datasets. The Bot Repository provides a comprehensive collection of existing datasets. Out of the 18 listed datasets, only two of them, TwiBot-20 and cresci-2015, explicitly provide the graph structure among Twitter users. In addition, these two graph-based datasets suffer from the following issues as illustrated in Figure 1:\\n\\n(a) limited dataset scale. Twibot-20 contains 11,826 labeled users and cresci-2015 contains 7,251 labeled users, while online conversations and discussions about heated topics often involve hundreds of thousands of users.\\n\\n(b) incomplete graph structure. Real-world Twitter is a heterogeneous information network that contains many types of entities and relations, while TwiBot-20 and cresci-2015 only provide users and follow relationships.\\n\\n(c) low annotation quality. TwiBot-20 resorted to crowdsourcing for user annotation, while crowdsourcing leads to significant noise and is susceptible to the false positive problem.\"}"}
{"id": "Kyswf8Kj83", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In light of these challenges, we propose TwiBot-22, a graph-based Twitter bot detection benchmark that addresses these issues. Specifically, TwiBot-22 adopts a two-stage controlled expansion to sample the Twitter network, which results in a dataset that is 5 times the size of the largest existing dataset. TwiBot-22 provides 4 types of entities and 14 types of relations in the Twitter network, which provides the first (truly) heterogeneous graph for Twitter bot detection. Finally, TwiBot-22 adopts the weak supervision learning strategy for data annotation which results in significantly improved annotation quality. To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view of research progress and highlight the advantages of TwiBot-22. We consolidate all datasets and implemented codes into the TwiBot-22 evaluation framework to facilitate further research. Our main contributions are summarized as follows:\\n\\n\u2022 We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest benchmark to date, provides diversified entities and relations in the Twitter network, and has considerably improved annotation quality.\\n\\n\u2022 We re-implement and benchmark 35 existing Twitter bot detection models on 9 datasets, including TwiBot-22, to compare different approaches fairly and facilitate a holistic understanding of research progress in Twitter bot detection.\\n\\n\u2022 We present the TwiBot-22 evaluation framework, where researchers could easily reproduce our results, examine existing datasets and methods, infer on unseen Twitter data, and contribute new datasets and models to the framework.\\n\\n2 Related Work\\n\\n2.1 Twitter Bot Detection\\n\\nExisting Twitter bot detection methods mainly fall into three categories: feature-based methods, text-based methods, and graph-based methods.\\n\\nFeature-based methods conduct feature engineering with user information and apply traditional classification algorithms for bot detection. Various features are extracted from user metadata [Kudugunta and Ferrara, 2018], tweets [Miller et al., 2014], description [Hayawi et al., 2022], temporal patterns [Mazza et al., 2019], and follow relationships [Feng et al., 2021a]. Later research efforts improve the scalability of feature-based approaches [Yang et al., 2020], automatically discover new bots [Chavoshi et al., 2016], and strike the balance between precision and recall [Morstatter et al., 2016]. However, as bot operators are increasingly aware of these hand-crafted features, novel bots often try to tamper with these features to evade detection [Cresci, 2020]. As a result, feature-based methods struggle to keep up with the arms race of bot evolution [Feng et al., 2021a].\\n\\nText-based methods use techniques in natural language processing to detect Twitter bots based on tweets and user descriptions. Word embeddings [Wei and Nguyen, 2019], recurrent neural networks [Kudugunta and Ferrara, 2018], the attention mechanism [Feng et al., 2021a], and pre-trained language models [Duki\u00b4c et al., 2020] are adopted to encode tweets for bot detection. Later research combines tweet representations with user features [Cai et al., 2017], learns unsupervised user representations [Feng et al., 2021a], and attempts to address the multi-lingual issue in tweet content [Knauth, 2019]. However, novel bots begin to counter text-based approaches by diluting malicious tweets with content stolen from genuine users [Cresci, 2020]. In addition, Feng et al. [2021b] shows that analyzing tweet content alone might not be robust and accurate for bot detection.\\n\\nGraph-based methods interpret Twitter as graphs and leverage concepts from network science and geometric deep learning for Twitter bot detection. Node centrality [Dehghan et al., 2022], node representation learning [Pham et al., 2022], graph neural networks (GNNs) [Ali Alhosseini et al., 2019], and heterogeneous GNNs [Feng et al., 2021b] are adopted to conduct graph-based Twitter bot detection. Later research try to combine graph-based and text-based methods [Guo et al., 2021a] or propose new GNN architectures to leverage heterogeneities in the Twitter network [Feng et al., 2022]. Graph-based approaches have shown great promise in tackling various challenges facing Twitter bot detection, such as bot communities and bot disguise [Feng et al., 2021b].\\n\\nThe development and evaluation of these models would not be possible without the many valuable Twitter bot detection datasets that were proposed over the past decade. These datasets mainly focus\"}"}
{"id": "Kyswf8Kj83", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Yang et al., 2020] and European countries [Cresci et al., 2017a]. Cresci-17 [Cresci et al., 2017a] propose the concept of \u201csocial spambots\u201d and presents a widely used dataset with more than one type of bots. TwiBot-20 [Feng et al., 2021c] is the latest and most comprehensive Twitter bot detection dataset that addresses the issue of user diversity in previous datasets. However, among 18 datasets presented in the Bot Repository, the go-to place for Twitter bot detection research, only 2 explicitly provide the graph structure of the Twitter network. In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low annotation quality while increasingly falling short of consistently benchmarking novel graph-based approaches. In light of these challenges, we present TwiBot-22 to alleviate these issues, promote a rethinking of research progress, and facilitate further research in Twitter bot detection.\\n\\n2.2 Graph-based Social Network Analysis\\n\\nUsers in online social networks interact with each other and become part of the network structure, while the network structure is essential in understanding the patterns of social media [Carrington et al., 2005]. With the advent of geometric deep learning, graph neural networks (GNNs) have become increasingly popular in social network analysis research. Qian et al. [2021] propose to model social media with heterogeneous graphs and leverage relational GNNs for illicit drug trafficker detection. Guo et al. [2021b] propose dual graph enhanced embedding neural network to improve graph representation learning and tackle challenges in click-through rate prediction. Graphs and GNNs are also adopted to detect online fraud [Liu et al., 2021, Li et al., 2021, Wang et al., 2021, Mishra et al., 2021, Dou et al., 2020], combat misinformation [Cui et al., 2020, Wang et al., 2020, Lu and Li, 2020, Varlamis et al., 2022, Hu et al., 2021], and improve recommender systems [Ying et al., 2018, Wu et al.]. The task of Twitter bot detection is no exception, where novel and state-of-the-art approaches are increasingly graph-based [Ali Alhosseini et al., 2019, Magelinski et al., 2020, Feng et al., 2021b, 2022, Lei et al., 2022]. In this paper, we propose the TwiBot-22 benchmark to better support the development and evaluation of graph-based Twitter bot detection models.\\n\\n3 TwiBot-22 Dataset\\n\\n3.1 Data Collection\\n\\nTwiBot-22 aims to present a large-scale and graph-based Twitter bot detection benchmark. To this end, we adopt a two-stage data collection process. We firstly adopt diversity-aware breadth-first search (BFS) to obtain the user network of TwiBot-22. We then collect additional entities and relations on the Twitter network to enrich the heterogeneity of the TwiBot-22 network.\\n\\nUser network collection.\\n\\nA common drawback of existing Twitter bot detection datasets is that they only feature a few types of bots and genuine users, while real-world Twitter is home to diversified users and bots [Feng et al., 2021c]. As a result, TwiBot-20 proposes to use breadth-first search (BFS) for user collection, starting from \u201cseed users\u201d and expanding with user follow relationships. To ensure that TwiBot-22 includes different types of bots and genuine users, we augment BFS with two diversity-aware sampling strategies:\\n\\n\u2022 Distribution diversity. Given user metadata such as follower count, different types of users fall differently into the metadata distribution. Distribution diversity aims to sample users in the top, middle, and bottom of the distribution. For numerical metadata, among a user\u2019s neighbors and their metadata values, we select the \\\\( k \\\\) users with the highest value, \\\\( k \\\\) with the lowest, and \\\\( k \\\\) randomly chosen from the rest. For true-or-false metadata, we select \\\\( k \\\\) with true and \\\\( k \\\\) with false.\\n\\n\u2022 Value diversity. Given a user and its metadata, value diversity is adopted so that neighbors with significantly different metadata values are more likely to be included, ensuring the diversity of collected users. For numerical metadata, among expanding user \\\\( u \\\\)'s neighbors \\\\( X \\\\) and their metadata values \\\\( x_{num} \\\\), the probability of user \\\\( x \\\\in X \\\\) being sampled is denoted as \\\\( p(x) \\\\propto | u_{num} - x_{num}| \\\\). For true-or-false metadata we select \\\\( k \\\\) users from the opposite class.\\n\\nBased on these sampling strategies, TwiBot-22 conducts diversity-aware BFS starting from @NeurIPSConf. For each neighborhood expansion, one metadata and one of the sampling strategies are randomly adopted. The BFS process stops until the user network contains a desirable amount of Twitter users. More information about the user collection process is presented in Appendix A.2.\"}"}
{"id": "Kyswf8Kj83", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Analyzing TwiBot-22. (a) Dataset scale in terms of users. (b) List of entities and relations in TwiBot-22 and graph-based datasets. (c) Accuracy and F1-score of dataset labels compared to expert annotations as well as Randolph\u2019s kappa coefficient [Randolph, 2005] of expert agreement.\\n\\nHeterogeneous graph building. The user network collection process constructs a homogeneous graph with users as nodes and follow relationships as edges. Apart from that, the Twitter network contains diversified entities and relations such as lists and retweets. Based on the user network, we collect the tweets, associated lists, and mentioned hashtags of these users as well as 12 other relations between users and these new entities. As a result, TwiBot-22 presents a heterogeneous Twitter network with 4 types of entities and 14 types of relations. More information about the heterogeneous Twitter network is presented in Appendix A.4.\\n\\nAs a result, we obtain the TwiBot-22 heterogeneous graph that contains 92,932,326 nodes and 170,185,937 edges. We present more dataset statistics in Table 7 in the appendix.\\n\\n3.2 Data Annotation\\n\\nExisting bot detection datasets often rely on manual annotation or crowdsourcing, while it is labor-intensive and thus not feasible with the large-scale TwiBot-22. As a result, we adopt weak supervision learning strategy to generate high-quality labels. We firstly invite bot detection experts to annotate 1,000 Twitter users in TwiBot-22. We then generate noisy labels with the help of bot detection models. Finally, we generate high-quality annotations for TwiBot-22 with the Snorkel framework [Ratner et al., 2017].\\n\\nExpert annotation. We randomly select 1,000 users in TwiBot-22 and assign each user to 5 Twitter bot detection experts to identify if it is a bot. We then create an 8:2 split for these expert annotations as training and test sets. More details about these experts are presented in Appendix A.3.\\n\\nGenerate noisy labels. We employ 8 hand-crafted labeling functions and 7 competitive feature-based and neural network-based bot detection models to generate noisy labels. For handcrafted labeling functions, we adopt spam keywords in tweets and user descriptions as well as user categorical features such as verified and sensitive tweets. For feature engineering models, we select features based on users\u2019 metadata such as creation time, follower count and name length. We then adopt Adaboost, random forest, and MLP to result in three feature-based classifiers. For neural network-based models, we follow Feng et al. [2021b] to encode user information and employ MLP, GAT [Veli\u02c7ckovi\u00b4c et al., 2018], GCN [Kipf and Welling, 2016], and R-GCN [Schlichtkrull et al., 2018] as four classifiers. We train these classifiers on the training set of expert annotations and calculate the uncertainty scores for all users in TwiBot-22 under each classifier as\\n\\n$$\\\\phi = -\\\\hat{y}_0 \\\\log(\\\\hat{y}_0) + \\\\hat{y}_1 \\\\log(\\\\hat{y}_1),$$\\n\\nwhere $\\\\hat{y}_0$ and $\\\\hat{y}_1$ denote the probability of being genuine users or bots. For each classifier, we then remove model predictions with the top 40% uncertainty scores to alleviate label noises.\\n\\nMajority voting. After obtaining the noisy labels, we evaluate their plausibility with Snorkel [Ratner et al., 2017] and clean the labels at the same time. The output of the Snorkel system are probabilistic labels, thus we use these labels to train an MLP classifier to obtain the final annotations of TwiBot-22. We further evaluate the annotation quality on the test set of expert annotations and...\"}"}
{"id": "Kyswf8Kj83", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistics of the 9 datasets. TwiBot-20 contains unlabelled users so that # User \u2260 # Human + # Bot. C-15, G-17, C-17, M-18, C-S-18, C-R-19, B-F-19 are short for cresci-2015, gilani-2017, cresci-2017, midterm-18, cresci-stock-2018, cresci-rtbust-2019, botometer-feedback-2019. C-17 contains only \u201cpost\u201d edges between users and tweets, which is not a graph-based dataset.\\n\\n| Dataset       | # Human | # Bot | # User | # Tweet | # Human Tweet | # Bot Tweet | # Edge |\\n|---------------|---------|-------|--------|---------|---------------|-------------|--------|\\n| C-15          | 1,950   | 3,351 | 5,301  | 2,827,757| 2,631,730     | 196,027     | 7,086,134|\\n| G-17          | 1,394   | 1,090 | 2,484  | 0       | 0             | 0           | 0      |\\n| C-17          | 3,474   | 10,894| 14,368 | 6,637,615| 2,839,361     | 3,798,254   | 6,637,615|\\n| M-18          | 8,092   | 42,446| 50,538 | 0       | 0             | 0           | 0      |\\n| C-S-18        | 6,174   | 7,102 | 13,276 | 0       | 0             | 0           | 0      |\\n| C-R-19        | 340     | 353   | 693    | 0       | 0             | 0           | 0      |\\n| B-F-19        | 380     | 138   | 518    | 0       | 0             | 0           | 0      |\\n| TwiBot-20     | 5,237   | 6,589 | 229,580| 33,488,192| 33,488,192   | 33,488,192 | 170,185,937|\\n| TwiBot-22     | 860,057 | 139,943| 1,000,000| 88,217,457| 81,250,102 | 6,967,355 | 170,185,937|\\n\\nWe obtain an 90.5% accuracy. Compared to the 80% accuracy standard in TwiBot-20 [Feng et al., 2021c], TwiBot-22 has considerably improved annotation quality.\\n\\n3.3 Data Analysis\\nExisting graph-based Twitter bot detection datasets suffer from limited dataset scale, incomplete graph structure, and low annotation quality. As a result, we examine whether TwiBot-22 has adequately addressed these challenges and present our findings in Figure 2.\\n\\nDataset scale. Figure 2(a) illustrates the number of Twitter users in TwiBot-22 and existing datasets. It is illustrated that TwiBot-22 establishes the largest Twitter bot detection benchmark to date, with approximately 5 times more users than the second-largest TwiBot-20.\\n\\nGraph structure. Figure 2(b) demonstrates that the TwiBot-22 network contains 4 types of entities and 14 types of relations, resulting in significantly enriched graph structure compared to existing graph-based datasets cresci-15 and TwiBot-20 with only 2 entity types and 3 relation types.\\n\\nAnnotation quality. TwiBot-20, the largest graph-based Twitter bot detection benchmark to date, leveraged crowdsourcing for data annotation. To improve label quality, TwiBot-22 uses weak supervision learning strategies and leverages 1,000 expert annotations to guide the process. To examine whether TwiBot-22 has improved annotation quality than TwiBot-20, we ask Twitter bot detection experts to participate in an \u201cexpert study\u201d, where they are asked to evaluate users in TwiBot-20 and TwiBot-22 to examine how often do experts agree with dataset labels. Figure 2(c) illustrates the results, which shows that these experts find TwiBot-22 to provide more consistent, accurate, and trustworthy data annotations. More details about the expert study are available in Appendix A.5.\\n\\n4 Experiments\\n4.1 Experiment Settings\\nDatasets. We evaluate Twitter bot detection models on all 9 datasets in the Bot Reportory that contain both bots and genuine users: cresci-2015 [Cresci et al., 2015], gilani-2017 [Gilani et al., 2017], cresci-2017 [Cresci et al., 2017a, b], midterm-18 [Yang et al., 2020], cresci-stock-2018 [Cresci et al., 2018, 2019], cresci-rtbust-2019 [Mazza et al., 2019], botometer-feedback-2019 [Yang et al., 2019], TwiBot-20 [Feng et al., 2021c], and TwiBot-22. We present dataset details in Table 1.\\n\\nWe create a 7:2:1 random split as training, validation, and test set to ensure fair comparison.\\n\\nBaselines. We re-implement and evaluate 35 Twitter bot detection baselines SGBot [Yang et al., 2020], Kudugunta and Ferrara [2018], Hayawi et al. [2022], BotHunter [Beskow and Carley, 2018], NameBot [Beskow and Carley, 2019], Abreu et al. [2020], Cresci et al. [2016], Wei and Nguyen [2019], BGSRD [Guo et al., 2021a], RoBERTa [Liu et al., 2019], T5 [Raffel et al., 2020], Efthimion et al. [2018], Kantepe and Ganiz [2017], Miller et al. [2014], Varol et al. [2017], Kouvela et al. [2020], Ferreira Dos Santos et al. [2019], Lee et al. [2011], LOBO [Echeverr\u00eda et al., 2018].\"}"}
{"id": "Kyswf8Kj83", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Average bot detection accuracy and standard deviation of five runs of 35 baseline methods...\\n\\nDehghan et al. Yang et al., 2022, Feng et al. 2013. Graph-based approaches are generally more effective than feature-based or text-based methods. As a matter of fact, all top 5 models on TwiBot-20 and TwiBot-22 are graph-based. On average, these top-5 graph-based methods outperform the global average of all baselines by 13.8% and 73.\\n\\nTable 2: run each baseline method for five times on 9 datasets. Bold Lv et al. Rodrifuez-Ruiz\\n\\nAs a matter of fact, all top 5 models on TwiBot-20 and TwiBot-22 are graph-based. On average, these top-5 graph-based methods outperform the global average of all baselines by 13.8% and 73.\\n\\n| Method                | Accuracy | SD  |\\n|-----------------------|----------|-----|\\n| SimpleHGNFTG          | 86.9     | \u00b13  |\\n| HGT FTG               | 73       | \u00b19  |\\n| LoBo FTG              | 86       | \u00b17  |\\n| BotRGCN FTG           | 72       | \u00b16  |\\n| Botometer FTG         | 80       | \u00b14  |\\n| FriendBot FTG         | 77       | \u00b15  |\\n| EvolveBot FTG         | 75       | \u00b13  |\\n| SATAR FTG             | 90       | \u00b10  |\\n| SimpleHGNFTG          | 85       | \u00b15  |\\n| HGT FTG               | 74       | \u00b17  |\\n| LoBo FTG              | 86       | \u00b17  |\\n| BotRGCN FTG           | 72       | \u00b16  |\\n| Botometer FTG         | 81       | \u00b14  |\\n| FriendBot FTG         | 77       | \u00b15  |\\n| EvolveBot FTG         | 75       | \u00b13  |\\n| SATAR FTG             | 90       | \u00b10  |\\n| SimpleHGNFTG          | 86       | \u00b15  |\\n| HGT FTG               | 73       | \u00b17  |\\n| LoBo FTG              | 84       | \u00b15  |\\n| BotRGCN FTG           | 72       | \u00b16  |\\n| Botometer FTG         | 81       | \u00b14  |\\n| FriendBot FTG         | 77       | \u00b15  |\\n| EvolveBot FTG         | 75       | \u00b13  |\\n| SATAR FTG             | 91       | \u00b10  |\\n| SimpleHGNFTG          | 87       | \u00b15  |\\n| HGT FTG               | 73       | \u00b17  |\\n| LoBo FTG              | 84       | \u00b15  |\\n| BotRGCN FTG           | 72       | \u00b16  |\\n| Botometer FTG         | 81       | \u00b14  |\\n| FriendBot FTG         | 77       | \u00b15  |\\n| EvolveBot FTG         | 75       | \u00b13  |\\n| SATAR FTG             | 92       | \u00b10  |\\n| SimpleHGNFTG          | 86       | \u00b15  |\\n| HGT FTG               | 73       | \u00b17  |\\n| LoBo FTG              | 84       | \u00b15  |\\n| BotRGCN FTG           | 72       | \u00b16  |\\n| Botometer FTG         | 81       | \u00b14  |\"}"}
{"id": "Kyswf8Kj83", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 3: Removing the graph-related model component from graph-based methods (w/o G) while comparing to their original versions (Prev.) on TwiBot-20 and TwiBot-22.\\n\\n| Method                        | TwiBot-20 Acc | TwiBot-20 F1 | TwiBot-22 Acc | TwiBot-22 F1 |\\n|-------------------------------|--------------|--------------|--------------|--------------|\\n| Prev. w/o G Diff.             | 59.9         | 61.8         | 72.1         | 70.7         |\\n| Ali Alhosseini et al. [2019]  | 59.9         | 61.8         | 72.1         | 70.7         |\\n| Moghaddam and Abbaspour [2022]| 74.0         | 72.2         | 77.9         | 75.8         |\\n| Knauth [2019]                 | 81.9         | 81.4         | 85.2         | 84.9         |\\n| EvolveBot [Yang et al., 2013] | 65.8         | 65.1         | 69.7         | 69.3         |\\n| BotRGCN [Feng et al., 2021b]  | 85.7         | 82.6         | 87.3         | 83.8         |\\n| RGT [Feng et al., 2022]       | 86.6         | 82.6         | 88.0         | 83.8         |\\n\\nMost existing datasets do not provide the graph structure of Twitter users to support graph-based approaches, while TwiBot-22 supports all baseline methods and serves as a comprehensive evaluation benchmark. As novel and state-of-the-art models are increasingly graph-based, future Twitter bot detection datasets should provide the graph structure of real-world Twitter.\\n\\nTwiBot-22 establishes the largest benchmark while exposing the scalability issues of baseline methods. For example, Dehghan et al. [2022] achieves near-SOTA performance on TwiBot-20, while failing to scale to TwiBot-22 as our implementation encounters the out-of-memory problem.\\n\\nPerformance on TwiBot-22 is on average 2.7% lower than on TwiBot-20 across all baseline methods, which demonstrates that Twitter bot detection is still an open problem that calls for further research. This could be attributed to the fact that Twitter bots are constantly evolving to improve their disguise and evade detection, thus bot detection methods should also adapt and evolve.\\n\\n4.3 Removing Graphs from Baselines\\n\\nBenchmarking results in Table 2 demonstrate that graph-based approaches generally achieve better performance. To examine the role of graphs in graph-based approaches, we remove the graph component in competitive graph-based methods [Ali Alhosseini et al., 2019, Moghaddam and Abbaspour, 2022, Knauth, 2019, Yang et al., 2013, Feng et al., 2021b, 2022] and report model performance in Table 3. It is demonstrated that:\\n\\n- All baseline methods exhibit performance drops to different extents on two datasets when the graph component is removed. This indicates that the graph-related components in graph-based approaches contribute to bot detection performance.\\n- For graph neural network-based approaches BotRGCN [Feng et al., 2021b] and RGT [Feng et al., 2022], the performance drop is generally more severe. This suggests that graph neural networks play an important role in boosting model performance and advancing bot detection research.\\n\\nMore details about how graphs are removed from baseline methods are presented in Appendix B.4.\\n\\n4.4 Generalization Study\\n\\nThe challenge of generalization [Yang et al., 2020, Feng et al., 2021a], i.e., whether Twitter bot detection models perform well on unseen data, is essential in ensuring that bot detection research translates to effective social media moderation and real-world impact. To evaluate the generalization ability of existing Twitter bot detection approaches, we identify 10 sub-communities in the TwiBot-22 network. We then use these sub-communities as folds and examine the performance of several representative models when trained on fold \\\\( i \\\\) and evaluated on fold \\\\( j \\\\). Figure 3 illustrates that:\\n\\n- Graph-based methods are better at generalizing to unseen data. For example, BotRGCN [Feng et al., 2021b] achieves the best avg score among all baseline methods, outperforming the second-highest RGT by 3.66. This suggests that leveraging the network structure of Twitter might be a potential solution to the generalization challenge.\\n- Good model performance does not necessarily translate to good generalization ability. For example, GAT outperforms LOBO by 5.9% and 3.8% on TwiBot-20 and TwiBot-22 respectively.\"}"}
{"id": "Kyswf8Kj83", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We present model accuracy and report the average value of each heatmap (avg), which serves as an overall indicator of generalization ability. GAT has lower avg (-2.55) compared to LOBO. This suggests that future bot detection research should focus on generalization in addition to model performance.\\n\\nMore details about the 10 sub-communities are provided in Appendix B.5.\\n\\n5 Evaluation Framework\\n\\nWe consolidate Twitter bot detection datasets, data preprocessing codes, and all 35 implemented baselines into the TwiBot-22 evaluation framework and make it publicly available. We hope our efforts would facilitate further research in Twitter bot detection through:\\n\\n\u2022 establishing a unified interface for different types of Twitter bot detection datasets\\n\u2022 providing 35 representative baselines and well-documented implementations\\n\u2022 enriching the evaluation framework with new datasets and methods proposed in future research\\n\\nPlease refer to https://twibot22.github.io/ for more details.\\n\\n6 Conclusion and Future Work\\n\\nIn this paper, we propose TwiBot-22, a graph-based Twitter bot detection benchmark. TwiBot-22 successfully alleviates the challenges of limited dataset scale, incomplete graph structure, and poor annotation quality in existing datasets. Specifically, we employ a two-stage data collection process and adopt the weak supervision learning strategy for data annotation. We then re-implement 35 representative Twitter bot detection models and evaluate them on 9 datasets, including TwiBot-22, to promote a holistic understanding of research progress. We further examine the role of graphs in graph-based methods and the generalization ability of competitive bot detection baselines. Finally, we consolidate all implemented codes into the TwiBot-22 evaluation framework, where researchers could easily reproduce our experiments and quickly test out new datasets and models.\\n\\nArmed with the TwiBot-22 benchmark and the TwiBot-22 evaluation framework, we aim to investigate these research questions in the future:\\n\\n\u2022 How do we identify bot clusters and their coordination campaigns? While existing works study Twitter bot detection through individual analysis, novel Twitter bots are increasingly observed to act in groups and launch coordinated attacks. We aim to complement the scarce literature by proposing temporal and subgraph-level bot detection approaches to address this issue.\"}"}
{"id": "Kyswf8Kj83", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"How do we incorporate multi-modal user features for bot detection?\\n\\nIn addition to text and graph, Twitter users and bots generate multi-modal user information such as images and videos. Since TwiBot-22 provides user media while none of the 35 baselines leverage these modalities, we aim to further explore Twitter bot detection with the help of images and videos.\\n\\nHow do we evaluate the generalization ability of bot detection methods?\\n\\nExisting works mainly focus on bot detection performance while generalization is essential in ensuring that bot detection research generates real-world impact. We aim to complement the scarce literature by proposing measures to quantitatively evaluate bot detection generalization.\\n\\nHow do we improve the scalability of graph-based models?\\n\\nExisting graph-based bot detection methods demand significantly more computation resources and execution time than feature-based models. Given that the Twitter network is rapidly expanding, we aim to further explore scalable and graph-based bot detection methods.\\n\\nAcknowledgements\\n\\nThis work was supported by the National Key Research and Development Program of China (No. 2020AAA0108800), National Nature Science Foundation of China (No. 62192781, No. 62272374, No. 61872287, No. 62250009, No. 62137002), Innovative Research Group of the National Natural Science Foundation of China (61721002), Innovation Research Team of Ministry of Education (IRT_17R86), Project of China Knowledge Center for Engineering Science and Technology and Project of Chinese academy of engineering \u201cThe Online and Offline Mixed Educational Service System for The Belt and Road Training in MOOC China\u201d.\\n\\nWe would like to thank the reviewers and area chair for the constructive feedback. We would also like to thank all LUD lab members for our collaborative research environment and for making our bot detection research series possible. As Shangbin concludes his term as the director and Zhaoxuan begins his term, we hope the LUD lab will continue to thrive in the years to come.\\n\\nReferences\\n\\nLimeng Cui, Haeseung Seo, Maryam Tabar, Fenglong Ma, Suhang Wang, and Dongwon Lee. Deterrnent: Knowledge guided graph attention network for detecting healthcare misinformation. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pages 492\u2013502, 2020.\\n\\nYouze Wang, Shengsheng Qian, Jun Hu, Quan Fang, and Changsheng Xu. Fake news detection via knowledge-driven multimodal graph convolutional networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval, pages 540\u2013547, 2020.\\n\\nYi-Ju Lu and Cheng-Te Li. Gcan: Graph-aware co-attention networks for explainable fake news detection on social media. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 505\u2013514, 2020.\\n\\nPhilip N Howard, Bence Kollanyi, and Samuel Woolley. Bots and automation over twitter during the us election. Computational propaganda project: Working paper series, 21(8), 2016.\\n\\nSamantha Bradshaw, Bence Kollanyi, Clementine Desigaud, and Gillian Bolsover. Junk news and bots during the french presidential election: What are french voters sharing over twitter? Technical report, COMPROP Data Memo, 2017.\\n\\nSippo Rossi, Matti Rossi, Bikesh Upreti, and Yong Liu. Detecting political bots on twitter during the 2019 finnish parliamentary election. In Proceedings of the 53rd Hawaii International Conference on System Sciences, 2020.\\n\\nEmilio Ferrara. Disinformation and social bot operations in the run up to the 2017 french presidential election. arXiv preprint arXiv:1707.00086, 2017.\\n\\nEmilio Ferrara, Wen-Qiang Wang, Onur Varol, Alessandro Flammini, and Aram Galstyan. Predicting online extremism, content adopters, and interaction reciprocity. In International conference on social informatics, pages 22\u201339. Springer, 2016.\"}"}
{"id": "Kyswf8Kj83", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"William Marcellino, Madeline Magnuson, Anne Stickells, Benjamin Boudreaux, Todd C Helmus, Edward Geist, and Zev Winkelman. Counter-radicalization bot research using social bots to fight violent extremism. Technical report, Rand Corp Santa Monica CA United States, 2020.\\n\\nEmilio Ferrara. What types of covid-19 conspiracies are populated by twitter bots? arXiv preprint arXiv:2004.09531, 2020.\\n\\nWasim Ahmed, Francesc L\u00f3pez Segu\u00ed, Josep Vidal-Alaball, Matthew S Katz, et al. Covid-19 and the film your hospital conspiracy theory: social network analysis of twitter data. Journal of medical Internet research, 22(10):e22374, 2020.\\n\\nAhmed Anwar, Haider Ilyas, Ussama Yaqub, and Salma Zaman. Analyzing qanon on twitter in context of us elections 2020: Analysis of user messages and profiles using vader and bert topic modeling. In DG. O2021: The 22nd Annual International Conference on Digital Government Research, pages 82\u201388, 2021.\\n\\nKai-Cheng Yang, Onur Varol, Pik-Mai Hui, and Filippo Menczer. Scalable and generalizable social bot detection through data selection. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 1096\u20131103, 2020.\\n\\nKyumin Lee, Brian Eoff, and James Caverlee. Seven months with the devils: A long-term study of content polluters on twitter. In Proceedings of the international AAAI conference on web and social media, volume 5, pages 185\u2013192, 2011.\\n\\nMichele Mazza, Stefano Cresci, Marco Avvenuti, Walter Quattrociocchi, and Maurizio Tesconi. Rtbust: Exploiting temporal patterns for botnet detection on twitter. In Proceedings of the 10th ACM conference on web science, pages 183\u2013192, 2019.\\n\\nNikan Chavoshi, Hossein Hamooni, and Abdullah Mueen. Debot: Twitter bot detection via warped correlation. In 2016 IEEE 16th International Conference on Data Mining (ICDM), pages 817\u2013822. IEEE Computer Society, 2016.\\n\\nDavid M Beskow and Kathleen M Carley. You are known by your friends: Leveraging network metrics for bot detection in twitter. In Open Source Intelligence and Cyber Crime, pages 53\u201388. Springer, 2020.\\n\\nZi Chu, Steven Gianvecchio, Haining Wang, and Sushil Jajodia. Detecting automation of twitter accounts: Are you a human, bot, or cyborg? IEEE Transactions on dependable and secure computing, 9(6):811\u2013824, 2012.\\n\\nStefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. The paradigm-shift of social spambots: Evidence, theories, and tools for the arms race. In Proceedings of the 26th international conference on world wide web companion, pages 963\u2013972, 2017a.\\n\\nStefano Cresci. A decade of social bot detection. Communications of the ACM, 63(10):72\u201383, 2020.\\n\\nFeng Wei and Uyen Trang Nguyen. Twitter bot detection using bidirectional long short-term memory neural networks and word embeddings. In 2019 First IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA), pages 101\u2013109. IEEE, 2019.\\n\\nSneha Kudugunta and Emilio Ferrara. Deep neural networks for bot detection. Information Sciences, 467:312\u2013322, 2018.\\n\\nShangbin Feng, Herun Wan, Ningnan Wang, Jundong Li, and Minnan Luo. Satar: A self-supervised approach to twitter account representation learning and its application in bot detection. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 3808\u20133817, 2021a.\\n\\nDavid Duki\u0107, Dominik Ke\u010da, and Dominik Stipi\u0107. Are you human? detecting bots on twitter using bert. In 2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA), pages 631\u2013636. IEEE, 2020.\"}"}
{"id": "Kyswf8Kj83", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Shangbin Feng, Herun Wan, Ningnan Wang, and Minnan Luo. Botrgcn: Twitter bot detection with relational graph convolutional networks. In Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, pages 236\u2013239, 2021.\\n\\nSeyed Ali Alhosseini, Raad Bin Tareaf, Pejman Najafi, and Christoph Meinel. Detect me if you can: Spam bot detection using inductive representation learning. In Companion Proceedings of The 2019 World Wide Web Conference, pages 148\u2013153, 2019.\\n\\nThomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.\\n\\nMichael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In European semantic web conference, pages 593\u2013607. Springer, 2018.\\n\\nShangbin Feng, Zhaoxuan Tan, Rui Li, and Minnan Luo. Heterogeneity-aware twitter bot detection with relational graph transformers. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 3977\u20133985, 2022.\\n\\nShangbin Feng, Herun Wan, Ningnan Wang, Jundong Li, and Minnan Luo. Twibot-20: A comprehensive twitter bot detection benchmark. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 4485\u20134494, 2021.\\n\\nStefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. Fame for sale: Efficient detection of fake twitter followers. Decision Support Systems, 80:56\u201371, 2015.\\n\\nJuan M Banda, Ramya Tekumalla, Guanyu Wang, Jingyuan Yu, Tuo Liu, Yuning Ding, Ekaterina Artemova, Elena Tutubalina, and Gerardo Chowell. A large-scale covid-19 twitter chatter dataset for open scientific research: an international collaboration. Epidemiologia, 2(3):315\u2013324, 2021.\\n\\nEduardo Graells-Garrido and Ricardo Baeza-Yates. Bots don't vote, but they surely bother! a study of anomalous accounts in a national referendum. arXiv preprint arXiv:2203.04135, 2022.\\n\\nAdrian Rauchfleisch and Jonas Kaiser. The false positive problem of automatic bot detection in social science research. PloS one, 15(10):e0241045, 2020.\\n\\nZachary Miller, Brian Dickinson, William Deitrick, Wei Hu, and Alex Hai Wang. Twitter spammer detection using data stream clustering. Information Sciences, 260:64\u201373, 2014.\\n\\nKadhim Hayawi, Sujith Mathew, Neethu Venugopal, Mohammad M Masud, and Pin-Han Ho. Deep-robot: a hybrid deep neural network model for social bot detection based on user profile data. Social Network Analysis and Mining, 12(1):1\u201319, 2022.\\n\\nFred Morstatter, Liang Wu, Tahora H Nazer, Kathleen M Carley, and Huan Liu. A new approach to bot detection: striking the balance between precision and recall. In 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pages 533\u2013540. IEEE, 2016.\\n\\nChiyu Cai, Linjing Li, and Daniel Zeng. Detecting social bots by jointly modeling deep behavior and content information. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 1995\u20131998, 2017.\\n\\nJ\u00fcrgen Knauth. Language-agnostic twitter-bot detection. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019), pages 550\u2013558, 2019.\\n\\nAshkan Dehghan, Kinga Siuta, Agata Skorupka, Akshat Dubey, Andrei Betlen, David Miller, Wei Xu, Bogumil Kaminski, and Pawel Pralat. Detecting bots in social-networks using node and structural embeddings. 2022.\\n\\nPhu Pham, Loan TT Nguyen, Bay Vo, and Unil Yun. Bot2vec: A general approach of intra-community oriented representation learning for bot detection in different types of social networks. Information Systems, 103:101771, 2022.\"}"}
{"id": "Kyswf8Kj83", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Qinglang Guo, Haiyong Xie, Yangyang Li, Wen Ma, and Chao Zhang. Social bots detection via fusing bert and graph convolutional networks. *Symmetry*, 14(1):30, 2021.\\n\\nPeter J Carrington, John Scott, and Stanley Wasserman. *Models and methods in social network analysis*, volume 28. Cambridge university press, 2005.\\n\\nYiyue Qian, Yiming Zhang, Yanfang Ye, and Chuxu Zhang. Distilling meta knowledge on heterogeneous graph for illicit drug trafficker detection on social media. *Advances in Neural Information Processing Systems*, 34, 2021.\\n\\nWei Guo, Rong Su, Renhao Tan, Huifeng Guo, Yingxue Zhang, Zhirong Liu, Ruiming Tang, and Xiuqiang He. Dual graph enhanced embedding neural network for ctr prediction. In *Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining*, pages 496\u2013504, 2021.\\n\\nCan Liu, Li Sun, Xiang Ao, Jinghua Feng, Qing He, and Hao Yang. Intention-aware heterogeneous graph attention networks for fraud transactions detection. In *Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining*, pages 3280\u20133288, 2021.\\n\\nZhao Li, Haishuai Wang, Peng Zhang, Pengrui Hui, Jiaming Huang, Jian Liao, Ji Zhang, and Jiajun Bu. Live-streaming fraud detection: A heterogeneous graph neural network approach. In *Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining*, pages 3670\u20133678, 2021.\\n\\nLi Wang, Peipei Li, Kai Xiong, Jiashu Zhao, and Rui Lin. Modeling heterogeneous graph network on fraud detection: A community-based framework with attention mechanism. In *Proceedings of the 30th ACM International Conference on Information & Knowledge Management*, pages 1959\u20131968, 2021.\\n\\nPushkar Mishra, Helen Yannakoudakis, and Ekaterina Shutova. Modeling users and online communities for abuse detection: A position on ethics and explainability. In *Findings of the Association for Computational Linguistics: EMNLP 2021*, pages 3374\u20133385, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.287. URL https://aclanthology.org/2021.findings-emnlp.287.\\n\\nYingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. Enhancing graph neural network-based fraud detectors against camouflaged fraudsters. In *Proceedings of the 29th ACM International Conference on Information & Knowledge Management*, pages 315\u2013324, 2020.\\n\\nIraklis Varlamis, Dimitrios Michail, Foteini Glykou, and Panagiotis Tsantilas. A survey on the use of graph convolutional networks for combating fake news. *Future Internet*, 14(3):70, 2022.\\n\\nLinmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, and Ming Zhou. Compare to the knowledge: Graph neural fake news detection with external knowledge. In *Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)*, pages 754\u2013763, 2021.\\n\\nRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining*, pages 974\u2013983, 2018.\\n\\nShiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. Graph neural networks in recommender systems: a survey. *ACM Computing Surveys (CSUR)*.\\n\\nThomas Magelinski, David Beskow, and Kathleen M Carley. Graph-hist: Graph classification from latent feature histograms with application to bot detection. In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 34, pages 5134\u20135141, 2020.\\n\\nZhenyu Lei, Herun Wan, Wenqian Zhang, Shangbin Feng, Zilong Chen, Qinghua Zheng, and Minnan Luo. Bic: Twitter bot detection with text-graph interaction and semantic consistency. *arXiv preprint arXiv:2208.08320*, 2022.\"}"}
{"id": "Kyswf8Kj83", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher R\u00e9. Snorkel: Rapid training data creation with weak supervision. In Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases, volume 11, page 269. NIH Public Access, 2017.\\n\\nJustus J Randolph. Free-marginal multirater kappa (multirater k [free]): An alternative to fleiss' fixed-marginal multirater kappa. Online submission, 2005.\\n\\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. Graph attention networks. In International Conference on Learning Representations, 2018.\\n\\nZafar Gilani, Reza Farahbakhsh, Gareth Tyson, Liang Wang, and Jon Crowcroft. Of bots and humans (on twitter). In Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017, pages 349\u2013354, 2017.\\n\\nStefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. Social fingerprinting: detection of spambot groups through dna-inspired behavioral modeling. IEEE Transactions on Dependable and Secure Computing, 15(4):561\u2013576, 2017b.\\n\\nStefano Cresci, Fabrizio Lillo, Daniele Regoli, Serena Tardelli, and Maurizio Tesconi. Fake: Evidence of spam and bot activity in stock microblogs on twitter. In Twelfth international AAAI conference on web and social media, 2018.\\n\\nStefano Cresci, Fabrizio Lillo, Daniele Regoli, Serena Tardelli, and Maurizio Tesconi. Cashtag piggybacking: Uncovering spam and bot activity in stock microblogs on twitter. ACM Transactions on the Web (TWEB), 13(2):1\u201327, 2019.\\n\\nKai-Cheng Yang, Onur Varol, Clayton A Davis, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. Arming the public with artificial intelligence to counter social bots. Human Behavior and Emerging Technologies, 1(1):48\u201361, 2019.\\n\\nDavid M Beskow and Kathleen M Carley. Bot-hunter: a tiered approach to detecting & characterizing automated activity on twitter. In Conference paper. SBP-BRiMS: International Conference on Social Computing, Behavioral-Cultural Modeling and Prediction and Behavior Representation in Modeling and Simulation, volume 3, page 3, 2018.\\n\\nDavid M Beskow and Kathleen M Carley. Its all in a name: detecting and labeling bots by their name. Computational and Mathematical Organization Theory, 25(1):24\u201335, 2019.\\n\\nJefferson Viana Fonseca Abreu, C\u00e9lia Ghedini Ralha, and Jo\u00e3o Jos\u00e9 Costa Gondim. Twitter bot detection with reduced feature set. In 2020 IEEE International Conference on Intelligence and Security Informatics (ISI), pages 1\u20136. IEEE, 2020.\\n\\nStefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. Dna-inspired online behavioral modeling and its application to spambot detection. IEEE Intelligent Systems, 31(5):58\u201364, 2016.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1\u201367, 2020.\\n\\nPhillip George Efthimion, Scott Payne, and Nicholas Proferes. Supervised machine learning bot detection techniques to identify social twitter bots. SMU Data Science Review, 1(2):5, 2018.\\n\\nM\u00fccahit Kantepe and Murat Can Ganiz. Preprocessing framework for twitter bot detection. In 2017 International conference on computer science and engineering (ubmk), pages 630\u2013634. IEEE, 2017.\"}"}
{"id": "Kyswf8Kj83", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "Kyswf8Kj83", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online, October 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-demos.6. URL https://aclanthology.org/2020.emnlp-demos.6.\\n\\nMatthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. arXiv preprint arXiv:1903.02428, 2019.\\n\\nF. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.\\n\\nRadim \u0158eh\u016f\u0159ek and Petr Sojka. Software Framework for Topic Modelling with Large Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45\u201350, Valletta, Malta, May 2010. ELRA. http://is.muni.cz/publication/884893/en.\\n\\nMatthew Honnibal, Ines Montani, Sofie Van Landeghem, and Adriane Boyd. spaCy: Industrial-strength Natural Language Processing in Python. 2020. doi: 10.5281/zenodo.1212303.\\n\\nJoshua Roesslein. tweepy documentation. Online http://tweepy.readthedocs.io/en/v3, 2009.\\n\\nWes McKinney et al. pandas: a foundational python library for data analysis and statistics. Python for high performance and scientific computing, 14(9):1\u20139, 2011.\\n\\nCharles R Harris, K Jarrod Millman, St\u00e9fan J Van Der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J Smith, et al. Array programming with numpy. Nature, 585(7825):357\u2013362, 2020.\\n\\nClayton Hutto and Eric Gilbert. Vader: A parsimonious rule-based model for sentiment analysis of social media text. In Proceedings of the international AAAI conference on web and social media, volume 8, pages 216\u2013225, 2014.\\n\\nGuillaume Lema\u00eetre, Fernando Nogueira, and Christos K. Aridas. Imbalanced-learn: A python toolbox to tackle the curse of imbalanced datasets in machine learning. Journal of Machine Learning Research, 18(17):1\u20135, 2017.\"}"}
