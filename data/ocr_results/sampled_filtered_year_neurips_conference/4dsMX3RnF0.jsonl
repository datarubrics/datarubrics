{"id": "4dsMX3RnF0", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses\\n\\nE. Sizikova, N. Saharkhiz, D. Sharma, M. Lago, B. Sahiner, J. G. Delfino, A. Badano\\n\\nOffice of Science and Engineering Laboratories\\nCenter for Devices and Radiological Health\\nU.S. Food and Drug Administration\\nSilver Spring, MD 20993 USA\\n\\nAbstract\\n\\nTo generate evidence regarding the safety and efficacy of artificial intelligence (AI) enabled medical devices, AI models need to be evaluated on a diverse population of patient cases, some of which may not be readily available. We propose an evaluation approach for testing medical imaging AI models that relies on in silico imaging pipelines in which stochastic digital models of human anatomy (in object space) with and without pathology are imaged using a digital replica imaging acquisition system to generate realistic synthetic image datasets. Here, we release M-SYNTH, a dataset of cohorts with four breast fibroglandular density distributions imaged at different exposure levels using Monte Carlo x-ray simulations with the publicly available Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit. We utilize the synthetic dataset to analyze AI model performance and find that model performance decreases with increasing breast density and increases with higher mass density, as expected. As exposure levels decrease, AI model performance drops with the highest performance achieved at exposure levels lower than the nominal recommended dose for the breast type.\\n\\nKB BREAST MODEL\\nGENERATION\\nMASS\\nGENERATION\\nMASS\\nINSERTION\\nBREAST MODEL\\nCOMPRESSION\\nDM\\nX-RAY\\nPROJECTION\\nAI ANALYSIS\\n1\\n2\\n3\\n4\\n5\\n6\\nMass Present?\\n\\nFigure 1: Overview of the computational pipeline components for generating the M-SYNTH in silico dataset for medical imaging AI evaluation.\\n\\n1 Introduction\\n\\nThe goal of this work is to demonstrate that AI models for medical imaging can be evaluated using simulations, specifically, using an in silico (also known as synthetic) imaging pipeline equipped with a stochastic model for human anatomy and disease [1]. We show that in silico methods can constitute rich sources of data with realistic physical variability for performing comparative analysis of AI device performance.\\n\\n* Code and data links available at: https://github.com/DIDSR/msynth-release/\\n\\n37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks.\"}"}
{"id": "4dsMX3RnF0", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To date, computational models have been applied to some extent for the analysis of nearly all medical imaging modalities and for a wide variety of clinical tasks [2]. Since it is critical to ensure patient safety and system effectiveness in healthcare applications, rigorous and thorough testing procedures must be performed in order to study performance in the intended population including subpopulations of interest. To prevent estimates that might be biased by overfitting, model testing is typically performed on a previously unseen dataset. However, datasets consisting of patient images may present a limited distribution of the variability in human anatomy and may not always capture rare, but life-critical cases, and may be biased towards specific populations or parameters of image acquisition devices dominant at specific clinical sites. In addition, patient data and associated health records may not be available due to patient privacy, cost, or additional risk associated with additional imaging procedures. Precise mass location and extent (e.g., mass boundaries) are typically not available in the patient's records, and it is burdensome, error-prone, and sometimes impossible to collect this information retrospectively. In many medical imaging applications, these limitations pose a significant barrier to development and evaluation of novel computational techniques in medical imaging products.\\n\\nWe propose evaluating AI models using physics-based simulations. We create realistic test cases by imaging digital objects using digital image acquisition systems. Our in silico testing pipeline offers the ability to control both object and acquisition parameters, and generate highly realistic test cases (see Figure 1). We show that digital objects and computer simulated replicas of image acquisition devices offer a rich source of realistic data capturing a variety of patient and imaging conditions for evaluation purposes. In particular, our approach (and associated dataset) allows for performing comparative analysis of AI performance across physical breast properties (e.g., mass size) and imaging characteristics (e.g., radiation dose). Such testing typically cannot be performed with patient data, as the data may be too costly to collect or unsafe to acquire (e.g., one cannot ethically re-image the same patient multiple times using ionizing radiation). Our contributions in this work can be summarized as follows:\\n\\n\u2022 We demonstrate that, using this approach, we can detect differences in AI model performance based on selected image acquisition device or physical object model parameters. Specifically, we evaluate the effect of image acquisition (radiation dose) and object model (breast and mass densities, mass size) parameters on the performance of the AI model.\\n\\n\u2022 We release a dataset, M-SYNTH, to facilitate testing with pre-computed data using the proposed pipeline. The dataset consists of 1,200 stochastic knowledge-based models and their associated digital mammography (DM) images with varying physical (breast density, mass size and density) and imaging (dose) characteristics.\\n\\n2 Background\\n\\nFirst, we introduce the concepts of knowledge-based models and physics-based imaging simulation that form the in silico imaging pipeline, the foundation of our work.\\n\\nObject Models. Knowledge-based (KB) models incorporate information about the physical world into the data generation process to create realistic virtual representations of human parts or organs [3]. As discussed in [1], large cohorts of digital stochastic human models can be represented by:\\n\\n\\\\[ \\\\{ f_s \\\\}_{s=1}^{S} = \\\\{ \\\\sum_{\\\\phi_n} \\\\theta_n(\\\\mathbf{r}) \\\\}_{s=1}^{S}, \\\\]\\n\\nwhere \\\\( s \\\\) denotes a particular state or random realization of a digital human in a cohort of size \\\\( S \\\\), \\\\( r \\\\) denotes a spatial variable, \\\\( \\\\phi_n \\\\) denote expansion (basis) functions, and \\\\( \\\\theta_n \\\\) denote expansion coefficients. Knowledge-based models specifically are constructed by sampling a set of \\\\( \\\\theta_n \\\\) in Eq. 1 from distributions representing the relevant model characteristics, given a specific \\\\( \\\\phi_n \\\\) based on the application. The characteristics of the distributions are often derived from physical or biological measurements. In the case of breast, knowledge-based models allow us to vary physical patient characteristics including breast size, breast shape, mass size and mass density (see Figures 2, 3 and 4). Specifically, the object (breast) is a model \\\\( D \\\\), parameterized by a vector \\\\( x \\\\) characterizing a fixed, user-defined set of physiological properties (e.g., breast density, mass presence, mass size, glandularity). Given a sample \\\\( x_s \\\\), we can generate a realistic, high-resolution object \\\\( f_s = D(x_s) \\\\). We rely on Graff's breast model [3] as the KB model for this project and describe its properties in Section 3.\"}"}
{"id": "4dsMX3RnF0", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Digital Mammography (DM) image generation. Once created, KB models are imaged using simulations of x-ray transport through the materials present in each KB model. The image acquisition device is a parametric model that receives the object $d_i$ as well as user-defined choices for control parameters $y_j$ (e.g., detector type, radiation dose) and outputs an image $r_{i,j} = I(d_i, y_j)$ given a sample choice of parameters $y_j$ and an input object $d_i$. Parameters of such a system (e.g., geometry, source characteristics, detector technology, anti-scatter grid, etc.) can emulate system geometries and x-ray acquisition parameters found in commercially available imaging device (e.g., mammography) specifications. In our work, we used MC-GPU [4], a Monte Carlo x-ray simulation software implemented on GPUs that generates mammography images. Additional details for this component of the pipeline can be found in Section 3.\\n\\nRelated work in generative image models. The in silico imaging pipeline described above is highly related to medical imaging generation using generative models. One popular type of generative model is a generative adversarial network (GAN) [5], which learns a mapping from a low-dimensional representation to images at resolution. Generative models have been applied to a variety of medical image generation tasks [6]. For example, Guan [7] showed that GAN-generated synthetic images can be used to augment a smaller patient breast image dataset for breast image classification. [8] introduced image-based GAN to generate high resolution images conditioned on pixel-level mask constraints. GANs may not correctly capture the link between input parameters and outputs, and thus, are prone to generating unrealistic examples [9]. A number of alternative types of generative models [10, 11, 12, 13, 14] have been developed that address its limitations, such as training instabilities and unrealistic output images. A key advantage of generative models is that their run time can be faster than fully-detailed, object-space simulations, and it remains important to explore and compare both techniques. Their key limitation is that they require large training datasets and typically learn noise and artifacts from the imaging system [15]. In particular, all image acquisition systems have a null space, i.e., the set of object-space details that are not observed in the acquired images due to imaging system limitations (e.g., finite spatial and temporal resolution). Null space constraints limit the ability of generative models to describe certain components of patient anatomy and pathology. Simulation-based testing has been proposed in other fields, such as autonomous vehicle navigation [16], and is related to the concept of generating adversarial perturbations in the image [17, 18, 19] and the physical property space [20, 21, 22]. For example, [23] introduced 3DB, a photo-realistic simulation framework to debug and improve computer vision models. Inspired by these works, we propose to evaluate medical imaging AI using images generated using KB models and physics simulations and release a dataset to facilitate such exploration.\\n\\n3 Dataset Generation\\nThe use of in silico imaging allows for the generation of large object and image datasets without the need of human clinical trials. Here, we take advantage of the benefits of the in silico approach to perform comparative analysis of AI model performance across different physical properties of the case population of breast models. We rely on the VICTRE pipeline\u2020 for generating breast models and their corresponding DM images. Previous work [24] has shown that the VICTRE pipeline replicated the results of a clinical study comparing DM and digital breast tomosynthesis (DBT) involving hundreds of enrolled women. An overview of the data generation process can be seen in Figure 1.\\n\\nBreast Model Synthesis. In silico breast models [3] (also known as breast imaging phantoms) were generated using a procedural analytic model which allows for adjusting various patient characteristics including breast shape, size and glandular density. The models are compressed in the craniocaudal direction using FeBio [25], an open source finite-element software. We simplified the breast materials in non-glandular (as fat) or glandular tissue with Young's modulus and Poisson ratio of $E = 5 \\\\times 10^4 \\\\text{ Pa}$, $\\\\nu = 0.49$, and $E = 15 \\\\times 10^4 \\\\text{ Pa}$, $\\\\nu = 0.49$, respectively. Lesions were inserted in a subset to create the signal-present cohort. These models were then imaged using a state-of-the-art Monte Carlo x-ray transport code (MC-GPU) [4].\\n\\nWe studied breast densities of extremely dense (referred to as \u201cdense\u201d), heterogeneously dense (referred to as \u201chetero\u201d), scattered, and fatty, matching the distributions from [24]. For each breast density, a different breast size is used to correspond with population statistics. Therefore, the dense breast is the smallest, followed by heterogeneously dense, then scattered, and then fatty. Each breast\u2020 See VICTRE Github Page and FDA Regulatory Science Tools (RST) Catalog.\"}"}
{"id": "4dsMX3RnF0", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The model was compressed to 3.5 cm, 4.5 cm, 5.5 cm, and 6.0 cm for each respective density, mimicking the organ compression during the imaging. Random spiculated breast masses were generated using the de Sisternes model [26] with three different sizes (5 mm, 7 mm and 9 mm radii) and mass density was set to be a factor of glandular tissue density (1.0, 1.06 and 1.1 times). Note that for dense and hetero breasts, we only used mass sizes of 5 and 7 mm, since 9 mm masses do not fit within the breast region. No micro-calcification clusters were inserted. To create the signal-present cohort, a single spiculated mass was inserted in half of the cases at randomly chosen locations chosen from a list of candidate sites determined by the position of the terminal duct lobular units. The resulting in silico dataset comprises of 1,200 digital breast models, corresponding to 300 patients per breast size/density. Compared to the original VICTRE trial [24], we introduce variations in mass size and density. Samples of model realizations are shown in Figures 2, 3 and 4. Note that the bounding boxes are only to make the masses more conspicuous for visualization purposes only.\\n\\nDigital Mammography (DM) Generation.\\n\\nTo simulate the x-ray imaging process, we used MC-GPU [4], a Monte Carlo x-ray simulation software implemented on GPUs that generates DM images. The detector model relies on system geometries and x-ray acquisition parameters inspired by the currently available Siemens Mammomat Inspiration DM system. The dosimetric and x-ray acquisition parameters were selected based on publicly available device specifications and clinical recommendations for each compressed breast thickness and glandularity. We applied 20-100% of the clinically recommended dose for each breast density. See Badal et al. [4] for the exact parameter values and doses delivered to each breast and Sengupta et al. [28] for additional details. X-ray photons arriving at the detector are tracked until first photoelectric interaction incorporating fluorescence effects by generating and tracking a secondary x-ray based on the fluorescence yield in a uniformly random direction. Electronic noise is added to the pixel variance. The focal spot blurring in the source was modeled as a 3D Gaussian probability distribution with a full-width-at-half-maximum of 300 \\\\( \\\\mu m \\\\). A tungsten anode filtered with 50 \\\\( \\\\mu m \\\\) rhodium was used with a peak voltage of 28 kV for fatty and scattered breasts and 30 kV for dense and heterogeneously dense breasts. The same analytical anti-scatter grid was also included for generating the DM images. (5:1 ratio, 31 line pairs/mm), see [4]. The resulting detector model (known as DIR in [28]) is representative of a solid-state amorphous selenium transducer in a direct detector configuration. Visualizations of generated images and masses can be seen in Figure 5. A summary of complete parameters used to generate data points in the presented dataset is described in Table 1. In Figure 7, we report statistics of dose levels corresponding to the dataset.\\n\\n| Parameter Considered | Values |\\n|----------------------|--------|\\n| Breast phantom density | Dense, Hetero, Scattered, Fatty |\\n| Mass radius (mm) | 5, 7, 9 |\\n| Mass density | 1.0, 1.06, 1.1 |\\n| Relative Dose | 20%, 40%, 60%, 80%, 100% |\\n| Detector type | DIR |\\n\\nTable 1: Parameters and their values corresponding to the M-SYNTH dataset.\\n\\n4 Related Datasets\\n\\nTo date, a number of datasets for mammographic image analysis have been collected (see Table 2). The majority of datasets are created from patient data collected from DM [29, 30, 31, 32] or digital breast tomosynthesis (DBT) [33, 34] scans from various clinical sites. The DREAM Challenge [35] offered datasets for development of AI-based mammography analysis techniques. Patient datasets vary widely in the types of labels available, and the data may be biased toward the demographic characteristics of patients at the source site. While there exist datasets, such as the EMory BrEast imaging Dataset (EMBED) [34], that specifically focus on equal representation (in this case, equal representation of African American and White patients), collecting a truly balanced dataset across all possible characteristics may not be possible with patient cases.\\n\\nWe found only two in silico datasets for mammography analysis. The first dataset, published by Sarno [36], consists of 150 patient-derived digital breast models with uncompressed computational breast phantoms derived from 3D breast images acquired with an in-house dedicated breast computed tomography (CT) scanner. The models were processed by a voxel classification algorithm into four...\"}"}
{"id": "4dsMX3RnF0", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Effect of varying mass size (5 mm to 9 mm radius) in a fatty breast. Two breast models are shown, first: (a)-(c), and second: (d)-(f). Dose (# of hist.) $2.2 \\\\times 10^{10}$ and mass density 1.1 remain constant. Bounding boxes are placed here to indicate the location of the masses.\\n\\nFigure 3: Effect of varying mass density (1.0 to 1.1 times glandular tissue density) in a fatty breast. Two models are shown, first: (a)-(c), and second: (d)-(f). Dose (# of hist.) $2.2 \\\\times 10^{10}$ and mass size 7 mm remain constant. Bounding boxes are placed here to indicate the location of the masses.\\n\\nFigure 4: Cohort variability. Varying breast density: (L to R) Fatty, Scattered, Heterogeneously dense, and Dense with mass size 7 mm and mass density 1.1. Note that dose changes with breast density. (e) shows artistic renderings of models for each composition (details in Kim et al. [27].\\n\\nMaterials (air, adipose tissue, fibroglandular tissue, and skin). The second dataset is the VICTRE [24] collection that consists of about 3,000 digital patients with breast sizes and densities representative of a screening population. Digital microcalcification clusters and spiculated masses were inserted in the voxelized phantoms to create the positive cohort. The phantoms were imaged in silico to produce digital mammogram projections and digital breast tomosynthesis volumes. In comparison to both of these datasets, our work contains more significant variability in breast and mass characteristics, as well as a range of applied dose levels for image acquisition, in order to facilitate comparative evaluations of AI across characteristic changes.\"}"}
{"id": "4dsMX3RnF0", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Imaging. Effect of increasing imaging dose (# of hist.) from left to right. Mass size of 5 mm and mass density of 1.1 remain constant.\\n\\nFigure 6: Dose distribution (# of hist.) and percentages of optimal dose considered by breast density.\\n\\nFigure 7: Glandular dose distributions for the dataset.\\n\\nTable 2: Summary of existing mammographic image datasets.\\n\\n---\\n\\n5 Results and Analysis\\n\\nIn this section, we present an approach to using our M-SYNTH dataset to evaluate an AI device. Formally, an image processing AI model $F$ takes as input an image $r$ and predicts a specific property of interest $F(r)$ about the image. For example, such a model can predict the presence or absence of a mass. Typically for AI models, $F$ is a neural network and is trained on a dataset of images and their labels $T_{train} = \\\\{(r_1, l_1), (r_2, l_2), \\\\ldots, (r_n, l_n)\\\\}$, and then evaluated on a held-out dataset $T_{test}$.\\n\\nWhen using patient images, evaluation is limited to the variability contained in the samples and in the annotations present across examples in the fixed test set $T_{test}$. Instead, we propose to generate $T_{train}$ and $T_{test}$ dynamically using $D$ and $I$ described above in order to test $F$ across variations in model $x$ and acquisition parameters $y$. \\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\\n\\n---\"}"}
{"id": "4dsMX3RnF0", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5.1 Implementation Details\\n\\nEvaluation Metrics\\nWe evaluate performance using the area under curve (AUC) metric for a mass detection task. Specifically, we treat evaluation as a multiple reader multiple case study, where an AI model is a single reader. Multiple readers are obtained by re-training the model with different random seeds. We rely on the iMRMC software [37, 38] to identify associated confidence intervals.\\n\\nNetwork Training\\nWe represent the AI-enabled device as a neural network with an efficientnet_b0 architecture, receiving an image with one channel and dimensions of 224 by 224, and outputting a binary mass presence label. The network is trained with batch size 64 using binary cross entropy loss (BCE) and optimized using RMSProp optimizer (with learning rate 0.0001). We rely on the timm library [39] and fine-tune the model pre-trained with ImageNet [40]. We also compared performance with alternative architectures (vit_small_patch16_224 and vgg_16), but results were very similar (see supplementary material).\\n\\nFor each specific breast density, radiation dose level, and mass size and density, the 300 images in the M-SYNTH dataset were divided into 200 for training, 50 for validation, and 50 for test. For comparison, we also train the AI device on 410 patient DM images from the INBreast dataset [32], where images were obtained using MammoNovation Siemens full-field digital mammography system with a solid-state amorphous selenium detector. We use the same pre-processing and training regimes on this dataset and learn a network to predict mass presence. The trained models on the real patient dataset were then tested on 50 examples of M-SYNTH dataset for each specific breast density, dose level, and mass size and density. The full experimental setup is implemented in Python and C over a cluster with 50 Tesla V100-SXM2 GPUs.\\n\\n5.2 Experimental Results\\n\\nWe identify two tasks that can be performed using our method. In the subgroup analysis task, we train and test an AI model using the released synthetic (M-SYNTH) dataset to identify performance changes on specified subgroups. In the patient data evaluation task, we study how an AI model trained on patient data (InBreast) performs on the proposed M-SYNTH dataset. This task can help identify where the trained model may show variable performance for different subgroups belonging to the target population.\\n\\nFigure 8: Subgroup analysis. Performance change across (a) mass size, (b) mass density, (c) breast density, and (d) radiation dose, for models trained and tested on our M-SYNTH dataset. These parameters remained constant for the set of experiments performed during both training and test: (a) Fatty breast phantom, mass density of 1.06, and relative dose of 100%. (b) Fatty breast phantom, mass size of 7 mm, and relative dose of 100%. (c) Mass density of 1.06, mass size of 7 mm, and relative dose of 100%. (d) Fatty breast phantom, mass density of 1.06, and mass size of 7 mm. Subgroup Analysis. In Figures 8 and 9, we report the results of the AI model performance at detecting masses, when the model is trained and tested on the our dataset (see Section 5.1 for details of splits). We find that masses with larger sizes or higher densities (Figures 8a-b) are more easily detected. Although models trained on all sizes or mass densities have the highest performance, when the models are trained on smaller masses or lower densities, they generalize better to other masses (more difficult cases). The performance of the models are highest when they are tested and trained on the same breast density and decrease as the density of the test breast phantom differs from the train phantom (Figures 8c). The dose levels applied in this study have minimal impact on the performance.\"}"}
{"id": "4dsMX3RnF0", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Evaluation of the performance change across all the breast densities (Figures 9a-b) reveals that the AUC improves with larger mass density and mass size, yet is impacted by the breast density, where mass detection performance is lowest in high-density breasts (dense) and highest in low-density breasts (fatty) in most of the cases, consistent with findings from clinical practice.\\n\\nPatient Data Evaluation. In Figure 10, we report experiments where the AI model is trained on INBreast data and evaluated on the M-SYNTH data. Although the performance results for all experiments are lower in general, we find a similar set of trends as when the model is trained on M-SYNTH data. Note that we have made no attempt to match the radiation dose levels or the image acquisition parameters for these comparisons using patient images. Even though the simulated pipeline is designed to replicate a specific DM system with a particular detector technology and technique factors, the comparison suggests similarity between the datasets. The images are qualitatively different but overall have similar glandular patterns which is an important consideration for the realism of the task of detecting masses in a noisy background. We also assessed similarity between INBreast and M-SYNTH datasets in terms of low-level pixel distributions using first five statistical moments: mean, variance, skewness, kurtosis, and hyperskewness. We found that there is a reasonably good alignment in terms of moments, especially when the synthetic images were included at all four breast densities (see supplementary material). Future work should develop a more detailed comparison including radiomics features for the training and testing datasets used in the study to complement the validation of our approach.\\n\\nLimitations. There are a number of limitations to our work. First, simulations may require long runtimes and demand large computational resources, thus somewhat limiting the amounts of data that can be generated. This limitation needs to be considered with respect to the difficulty of obtaining large patient image datasets with known mass locations. In addition, data can be pre-generated offline (as we do with the M-SYNTH dataset), therefore, removing the large runtime limit and computational burden off the user. Second, testing with simulations is constrained to the variability captured by the parameter space of the object models for anatomy and pathology and the acquisition system. Thus, the complexity of the object model and acquisition system may need to be adjusted depending on the complexity of the questions to be investigated with simulated testing. In particular, a potential risk of testing using simulated data is missing the variability observed in patient populations. Finally, there is a risk of misjudging model performance due to a domain gap between real and synthetic\"}"}
{"id": "4dsMX3RnF0", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"### AUC as a Function of Mass Size Across All Breast Densities\\n\\n| Test Breast Density | Mass Density | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\\n|--------------------|-------------|-----|-----|-----|-----|-----|-----|-----|\\n| Fatty              | 1.0         |     |     |     |     |     |     |     |\\n|                   | 1.06        |     |     |     |     |     |     |     |\\n|                   | 1.1         |     |     |     |     |     |     |     |\\n|                   | 1.0         |     |     |     |     |     |     |     |\\n\\n### AUC as a Function of Mass Density Across All Breast Densities\\n\\n| Test Breast Density | Mass Size (mm) | 5.0 | 7.0 | 9.0 |\\n|--------------------|----------------|-----|-----|-----|\\n| Fatty              | 1.00           |     |     |     |\\n|                   | 1.02           |     |     |     |\\n|                   | 1.04           |     |     |     |\\n|                   | 1.06           |     |     |     |\\n|                   | 1.08           |     |     |     |\\n|                   | 1.10           |     |     |     |\\n|                   | 1.00           |     |     |     |\\n|                   | 1.02           |     |     |     |\\n|                   | 1.04           |     |     |     |\\n|                   | 1.06           |     |     |     |\\n|                   | 1.08           |     |     |     |\\n|                   | 1.10           |     |     |     |\\n\\n---\\n\\n**Figure 10:** Model Evaluation. Performance changes for a model trained on 410 real patient images (INBreast dataset) and tested on our M-SYNTH dataset. The test sets consist of 50 images using parameters shown in the plots. The test radiation dose is set to 100% of the clinically recommended dose for each breast density.\\n\\n---\\n\\n**6 Conclusion and Future Work**\\n\\nWe introduce and discuss an approach for validating AI models using physics-based simulations of digital humans from the object space to the image data, specifically for the task of breast cancer mass detection. The simulated images are highly realistic and offer a challenging test case for AI model evaluation. Our findings are consistent with expected performance and show that the AI model performance increases with mass size and mass density as expected. Finally, we show that our approach can be used to validate a model trained on independent patient data. This finding suggests that the proposed simulation setup can be used as a framework for more general evaluation of medical AI devices.\\n\\n---\\n\\n**7 Acknowledgements**\\n\\nWe thank Andreu Badal (OSEL/CDRH/FDA) and anonymous reviewers for helpful suggestions, Kenny Cha, Mike Mikailov and the OpenHPC team (OSEL/CDRH/FDA) for providing help with experiments, Akhonda, Mohammad (OSEL/CDRH/FDA) for help with data release, and Andrea Kim...\"}"}
{"id": "4dsMX3RnF0", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"for rendering visualizations of the 3D breast model. This is a contribution of\\nthe US Food and Drug Administration and is not subject to copyright. The mention of commercial\\nproducts herein is not to be construed as either an actual or implied endorsement of such products by\\nthe Department of Health and Human Services.\\n\\nReferences\\n\\n[1] A Badano, M Lago, E Sizikova, JG Delfino, S Guan, MA Anastasio, and B Sahiner. The stochastic digital\\nhuman is now enrolling for in silico imaging trials\u2013methods and tools for generating digital cohorts.\\narXiv preprint arXiv:2301.08719, 2023.\\n\\n[2] Ana Barrag\u00e1n-Montero, Umair Javaid, Gilmer Vald\u00e9s, Dan Nguyen, Paul Desbordes, Benoit Macq, Siri\\nWillems, Liesbeth Vandewinckele, Mats Holmstr\u00f6m, Fredrik L\u00f6fman, et al. Artificial intelligence and\\nmachine learning for medical imaging: A technology review. Physica Medica, 83:242\u2013256, 2021.\\n\\n[3] Christian G Graff. A new, open-source, multi-modality digital breast phantom. In Medical Imaging 2016:\\nPhysics of Medical Imaging, volume 9783, pages 72\u201381. SPIE, 2016.\\n\\n[4] Andreu Badal, Diksha Sharma, Christian G Graff, Rongping Zeng, and Aldo Badano. Mammography and\\nbreast tomosynthesis simulator for virtual clinical trials. Computer Physics Communications, 261:107779,\\n2021.\\n\\n[5] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron\\nCourville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):139\u2013\\n144, 2020.\\n\\n[6] Youssef Skandarani, Pierre-Marc Jodoin, and Alain Lalande. Gans for medical image synthesis: An\\nempirical study. arXiv preprint arXiv:2105.05318, 2021.\\n\\n[7] Shuyue Guan and Murray Loew. Breast cancer detection using synthetic mammograms from generative\\nadversarial networks in convolutional neural networks. Journal of Medical Imaging, 6(3):031411\u2013031411,\\n2019.\\n\\n[8] Yinhao Ren, Zhe Zhu, Yingzhou Li, Dehan Kong, Rui Hou, Lars J Grimm, Jeffery R Marks, and Joseph Y\\nLo. Mask embedding for realistic high-resolution medical image synthesis. In MICCAI, pages 422\u2013430.\\nSpringer, 2019.\\n\\n[9] Elena Sizikova, Xu Cao, Ashia Lewis, Kenny Moise, and Megan Coffee. Improving computed tomography\\n(CT) reconstruction via 3D shape induction. arXiv preprint arXiv:2208.10937, 2022.\\n\\n[10] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,\\n2013.\\n\\n[11] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In International\\nconference on machine learning, pages 1530\u20131538. PMLR, 2015.\\n\\n[12] Piotr Bojanowski, Armand Joulin, David Lopez-Paz, and Arthur Szlam. Optimizing the latent space of\\ngenerative networks. arXiv preprint arXiv:1707.05776, 2017.\\n\\n[13] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural\\nInformation Processing Systems, 33:6840\u20136851, 2020.\\n\\n[14] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion models in vision:\\na survey. arXiv preprint arXiv:2209.04747, 2022.\\n\\n[15] Weimin Zhou, Sayantan Bhadra, Frank J Brooks, Hua Li, and Mark A Anastasio. Learning stochastic\\nobject models from medical imaging measurements by use of advanced ambient generative adversarial\\nnetworks. Journal of Medical Imaging, 9(1):015503, 2022.\\n\\n[16] Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren,\\nand Raquel Urtasun. Advsim: Generating safety-critical scenarios for self-driving vehicles. In CVPR,\\npages 9909\u20139918, 2021.\\n\\n[17] Naveed Akhtar and Ajmal Mian. Threat of adversarial attacks on deep learning in computer vision: A\\nsurvey. Ieee Access, 6:14410\u201314430, 2018.\\n\\n[18] Samuel G Finlayson, John D Bowers, Joichi Ito, Jonathan L Zittrain, Andrew L Beam, and Isaac S Kohane.\\nAdversarial attacks on medical machine learning. Science, 363(6433):1287\u20131289, 2019.\"}"}
{"id": "4dsMX3RnF0", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[10] Hokuto Hirano, Akinori Minagi, and Kazuhiro Takemoto. Universal adversarial attacks on deep neural networks for medical image classification. BMC medical imaging, 21:1\u201313, 2021.\\n\\n[20] Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, and Mingyan Liu. Meshadv: Adversarial meshes for visual recognition. In CVPR, pages 6898\u20136907, 2019.\\n\\n[21] Xiaohui Zeng, Chenxi Liu, Yu-Siang Wang, Weichao Qiu, Lingxi Xie, Yu-Wing Tai, Chi-Keung Tang, and Alan L Yuille. Adversarial attacks beyond the image space. In CVPR, pages 4302\u20134311, 2019.\\n\\n[22] Hsueh-Ti Derek Liu, Michael Tao, Chun-Liang Li, Derek Nowrouzezahrai, and Alec Jacobson. Beyond pixel norm-balls: Parametric adversaries using an analytically differentiable renderer. arXiv preprint arXiv:1808.02651, 2018.\\n\\n[23] Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, et al. 3db: A framework for debugging computer vision models. arXiv preprint arXiv:2106.03805, 2021.\\n\\n[24] Aldo Badano, Christian G Graff, Andreu Badal, Diksha Sharma, Rongping Zeng, Frank W Samuelson, Stephen J Glick, and Kyle J Myers. Evaluation of digital breast tomosynthesis as replacement of full-field digital mammography using an in silico imaging trial. JAMA network open, 1(7):e185474\u2013e185474, 11 2018.\\n\\n[25] Steve A. Maas, Benjamin J. Ellis, Gerard A. Ateshian, and Jeffrey A. Weiss. FEBio: Finite Elements for Biomechanics. Journal of Biomechanical Engineering, 134(1):011005, 02 2012.\\n\\n[26] Luis de Sisternes, Jovan G Brankov, Adam M Zysk, Robert A Schmidt, Robert M Nishikawa, and Miles N Wernick. A computational model to generate simulated three-dimensional breast masses. Medical physics, 42(2):1098\u20131118, 2015.\\n\\n[27] Andrea Kim, Aunnasha Sengupta, and Aldo Badano. Automated animation pipeline for visualizing in silico tumor growth models. Physics of Medical Imaging, 12463, 2023.\\n\\n[28] Aunnasha Sengupta, Andreu Badal, Andrey Makeev, and Aldo Badano. Computational models of direct and indirect x-ray breast imaging detectors for in silico trials. Medical Physics, 49(11):6856\u20136870, 2022.\\n\\n[29] Helen ML Frazer, Jennifer SN Tang, Michael S Elliott, Katrina M Kunicki, Brendan Hill, Ravishankar Karthik, Chun Fung Kwok, Carlos A Pe\u00f1a-Solorzano, Yuanhong Chen, Chong Wang, et al. Admani: Annotated digital mammograms and associated non-image datasets. Radiology: Artificial Intelligence, 5(2):e220072, 2022.\\n\\n[30] Chunyan Cui, Li Li, Hongmin Cai, Zhihao Fan, Ling Zhang, Tingting Dan, Jiao Li, and Jinghua Wang. The chinese mammography database (cmmd): An online mammography database with biopsy confirmed types for machine diagnosis of breast. Data Cancer Imaging Arch, 2021.\\n\\n[31] Mark D. Halling-Brown, Lucy M. Warren, Dominic Ward, Emma Lewis, Alistair Mackenzie, Matthew G. Wallis, Louise S. Wilkinson, Rosalind M. Given-Wilson, Rita McAvinchey, and Kenneth C. Young. Optimam mammography image database: A large-scale resource of mammography images and clinical data. Radiology: Artificial Intelligence, 3(1), 2020.\\n\\n[32] In\u00eas C Moreira, Igor Amaral, In\u00eas Domingues, Ant\u00f3nio Cardoso, Maria Joao Cardoso, and Jaime S Cardoso. Inbreast: toward a full-field digital mammographic database. Academic radiology, 19(2):236\u2013248, 2012.\\n\\n[33] Mateusz Buda, Ashirbani Saha, Ruth Walsh, Sujata Ghate, Nianyi Li, Albert \u00b4Swi\u02db ecicki, Joseph Y Lo, and Maciej A Mazurowski. Dete ction of masses and architectural distortions in digital breast tomosynthesis: a publicly available dataset of 5,060 patients and a deep learning model. arXiv preprint arXiv:2011.07995, 2020.\\n\\n[34] Jiwoong J Jeong, Brianna L Vey, Ananth Bhimireddy, Thomas Kim, Thiago Santos, Ramon Correa, Raman Dutt, Marina Mosunjac, Gabriela Oprea-Ilies, Geoffrey Smith, et al. The emory breast imaging dataset (embed): A racially diverse, granular dataset of 3.4 million screening and diagnostic mammographic images. Radiology: Artificial Intelligence, 5(1):e220047, 2023.\\n\\n[35] Berkman Sahiner. Digital mammography dream challenge overview (conference presentation). In Medical Imaging 2017: Computer-Aided Diagnosis, volume 10134, pages 1159\u20131159. SPIE, 2017.\\n\\n[36] Antonio Sarno, Giovanni Mettivier, Francesca di Franco, Antonio Varallo, Kristina Bliznakova, Andrew M. Hernandez, John M. Boone, and Paolo Russo. Dataset of patient-derived digital breast phantoms for in silico studies in breast computed tomography, digital breast tomosynthesis, and digital mammography. Medical Physics, 48(5):2682\u20132693, 2021.\"}"}
{"id": "4dsMX3RnF0", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
