{"id": "mJWt6pOcHNy", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Breaking Bad: A Dataset for Geometric Fracture and Reassembly\\nSilvia Sell\u00e1n, Yun-Chun Chen, Ziyi Wu, Animesh Garg, Alec Jacobson\\n1 University of Toronto, 2 Vector Institute, 3 NVIDIA, 4 Adobe Research, Toronto\\n{sgsellan, ycchen, ziyiwu, garg, jacobson}@cs.toronto.edu\\n\\nFigure 1: The Breaking Bad dataset contains over one million fractured objects. A subset of these is shown here, each base model in light blue and each fractured piece in a different color. This dataset can be used for machine learning applications such as geometric reassembly or example-based fracture simulation.\\n\\nAbstract\\nWe introduce Breaking Bad, a large-scale dataset of fractured objects. Our dataset consists of over one million fractured objects simulated from ten thousand base models. The fracture simulation is powered by a recent physically based algorithm that efficiently generates a variety of fracture modes of an object. Existing shape assembly datasets decompose objects according to semantically meaningful parts, effectively modeling the construction process. In contrast, Breaking Bad models the destruction process of how a geometric object naturally breaks into fragments. Our dataset serves as a benchmark that enables the study of fractured object reassembly and presents new challenges for geometric shape understanding. We analyze our dataset with several geometry measurements and benchmark three state-of-the-art shape assembly deep learning methods under various settings. Extensive experimental results demonstrate the difficulty of our dataset, calling on future research in model designs specifically for the geometric shape assembly task. We host our dataset at https://breaking-bad-dataset.github.io/.\\n\\n1 Introduction\\nFracture reassembly aims to compose the fragments of a fractured object back into its original shape, e.g., a shattered sculpture or a broken item of kitchenware. With applications in artifact preservation [38, 40], digital heritage archiving [39, 43], computer vision [20, 29], robotics [12, 24] and geometry processing [2, 21], fracture reassembly is a practical yet challenging task that receives attention from multiple communities.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Our Breaking Bad dataset contains a large number of fractured objects with various, physically realistic fractures. S: shapes. BP: breakdown patterns. OP: object parts.\\n\\n| Dataset          | #S    | #BP    | #BP / #S | #OP / #BP |\\n|------------------|-------|--------|----------|-----------|\\n| Decomposition    |       |        |          |           |\\n| Physically based | 26,671| 26,671 | 1        | 21.51     |\\n| Semantic No      |       |        |          |           |\\n| AutoMate [23]    | 92,529| 92,529 | 1        | 5.85      |\\n| Semantic No      |       |        |          |           |\\n| JoinABLe [59]    | 8,251 | 8,251  | 1        | 18.72     |\\n| Semantic No      |       |        |          |           |\\n| NSM dataset [7]  | 1,246 | 201,590| 161.78   | 2         |\\n| Geometric No     |       |        |          |           |\\n| Breaking Bad     | 10,474| 1,047,400| 100     | 8.06      |\\n\\nInput\\n\\nSemantic segmentation\\nPhysical fracture\\n\\nMachine learning approaches have shown progress on the fracture reassembly task [10, 55], but require large-scale datasets of fracture objects. Existing assembly datasets like PartNet [32], AutoMate [23] and JoinABLe [59] are constructed based on human or automated semantic segmentation. The objects in these datasets are decomposed in a semantically consistent way. However, objects that break naturally due to external forces generally do not break into fragments that are semantically well defined (see inset). Thus, existing part assembly datasets are not suitable for studying fracture reassembly.\\n\\nSimulating how an object fractures when receiving an impact is a well-studied scientific problem. One can generate a dataset of broken objects by using any existing algorithm (e.g., [36, 61]) to simulate how objects in a typical shape dataset would break under randomly sampled dynamic conditions. Unfortunately, the high computational cost of physics-based fracture simulation algorithms (e.g., those used in engineering or the film industry) makes them hard to scale. While fast fracture algorithms (e.g., those for real-time applications like video games) exist to account for this shortcoming [33, 54], they use consistent geometric strategies to produce fracture patterns with no physical realism guarantee, limiting dataset diversity and generalization.\\n\\nRecently, Sell\u00e1n et al. [51] introduced the concept of an object's fracture modes, which correspond to a shape's most geometrically natural form of breaking apart. Once these modes are precomputed for a given object, different impacts can be projected onto the modes to produce different fracture patterns in milliseconds. By producing physically realistic, diverse breaking patterns with a reasonably fast runtime, this method provides a good tradeoff for fractured object data generation.\\n\\nIn this paper, we introduce Breaking Bad, a large-scale fractured object dataset. We collect base models from Thingi10K [65] and PartNet [32] and apply Sell\u00e1n et al.'s fracture simulation algorithm to each. For each base model, we compute the first 20 fracture modes, generating 20 fracture patterns. Using these modes, we sample 80 additional random impacts and project them onto these fracture modes to generate 80 additional fracture patterns. This results in a total of 100 unique fracture patterns per base model. Our dataset contains a diverse set of shapes spanning everyday objects, artifacts, and objects that are commonly used in video gaming, fabrication, and example-based fracture simulation, combining one million geometrically natural fracture patterns (see Figure 1).\\n\\nBreaking Bad is a suitable dataset for studying the reassembly task and presents several challenges to candidate solutions, including complex shape geometry, large variations in fracture volumes, and varying numbers of fractured pieces per shape. We analyze Breaking Bad with several geometry measurements and benchmark three state-of-the-art deep learning models under various settings. Extensive experiments against Breaking Bad reveal that fractured shape reassembly is still a quite open problem, inviting opportunities for future contributions.\\n\\nSummary of contributions:\\n\\n1. We introduce a large-scale dataset of fractured objects for the geometric shape assembly task.\\n2. We provide a geometric analysis of the collected dataset.\\n3. We benchmark three state-of-the-art deep learning methods on our dataset under various settings, with accompanying code to ensure reproducibility and facilitate future research.\\n4. Our dataset is publicly available at [https://breaking-bad-dataset.github.io/](https://breaking-bad-dataset.github.io/) (see prototype website in Figure 4).\"}"}
{"id": "mJWt6pOcHNy", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 2: Dataset statistics at different percentiles for each subset in our dataset. O: objects. FP: fractured pieces. V: vertices. F: faces. PCR: piece convexity rank.\\n\\n| Category | #O     | #FP / #O | #V / #FP | #F / #FP | V / #FP (\u21e510) | PCR (\u21e510) |\\n|----------|--------|----------|----------|----------|---------------|-----------|\\n| Percentile | 25th   | 50th     | 75th     | 25th     | 50th          | 75th      |\\n| Everyday  | 542    | 2        | 3        | 6        | 98            | 279       | 949       | 216       | 742       | 3,162       | 2.47       | 9.32       | 71.13      | 6.19       | 16.63       | 44.00      |\\n| Artifacts | 204    | 3        | 8        | 19       | 90            | 307       | 757       | 208       | 872       | 2,310       | 0.64       | 3.96       | 23.75      | 9.13       | 19.78       | 45.44      |\\n| Others    | 9,475  | 3        | 6        | 13       | 70            | 331       | 1,119     | 146       | 832       | 3,222       | 0.51       | 6.17       | 39.36      | 5.58       | 11.17       | 16.00      |\\n| All       | 10,221 | 3        | 10       | 13       | 92            | 286       | 1,345     | 22        | 286       | 2,552       | 0.05       | 2.70       | 31.89      | 6.38       | 13.99       | 28.90      |\\n\\n### Related Work\\n\\nWe review prior work and its relationship to our choices, focusing on works relevant to our target applications, dataset scope, or data generation.\\n\\n**Vision Model**\\n\\n| F1 | F2 | F3 | \u2026 | Fn |\\n|----|----|----|---|----|\\n| P1 | P2 | P3 | \u2026 | Pn |\\n| R1 | R2 | R3 | \u2026 | Rn |\\n| T1 | T2 | T3 | Tn, |\\n\\n**Object Pieces Points AssemblyPoses**\\n\\n3D shape assembly. Shape assembly has been widely studied (see inset on the right for a typical vision-based shape assembly pipeline). Existing methods studying part assembly [10, 16, 20, 23, 29, 55, 59, 63] aim at composing a complete object from a set of parts by leveraging part segmentation [29] or formulate part assembly as a graph learning problem [16, 20]. These methods use the PartNet dataset [32] in which the objects are decomposed in a semantically consistent way. Unlike these works, we consider the task of reassembling fractured objects, where fracture patterns are physically realistic yet semantically inconsistent. NSM [7] is the one that comes closest to our task setting. However, NSM is designed for two-part assembly, whereas objects in our dataset often break into multiple fractured pieces (on average 8.06 pieces per fracture).\\n\\n**Shape assembly datasets.** Early shape assembly datasets [5, 10, 21, 52] are often small in size and contain only a few categories. To develop learning-based algorithms for shape assembly, several large-scale datasets have been constructed [7, 23, 32, 59]. PartNet [32], AutoMate [23] and JoinABLe [59] are datasets that contain shapes where the object decomposition is semantically consistent. The object breakdown patterns in these datasets are not suited for the fractured shape reassembly task, where objects generally do not break in semantically meaningful ways. The object decomposition patterns in the NSM dataset [7] are not determined by a semantic part decomposition. Instead, they trim models with a non-predefined set of parametric functions (e.g., a sine function). This arbitrary decomposition will in general bear no relationship to the physically meaningful fracture behavior of a given object.\\n\\nIn contrast, our dataset is generated by a physically based fracture simulation algorithm [51], which generates various fracture patterns of a single object. See Table 1 for a comparison between datasets.\\n\\n**Fracture simulation.** Computing the fracture pattern of a base shape under certain conditions is a well-studied problem for its applications in physics, engineering, and computer graphics. In graphics, previous work has focused on producing realistic-looking fractures in runtimes suitable for their use in the film and video game industries. These can be grouped into physical and procedural methods.\\n\\nPhysical fracture simulation methods model the dynamic growth of fracture faults at very high temporal and spatial resolutions, with discretization strategies that vary from mass-springs [18, 35] to finite elements [25, 27, 36, 42, 58], boundary elements [14, 15, 66], and the material-point method [60, 61]. Unfortunately, the realistic-looking results produced by these algorithms require significant runtimes, often in the days or weeks for a single simulation. While these costs can be assumed by a film studio seeking to produce the perfect breaking scene, they make these methods ill-suited for dataset generation at a massive scale.\\n\\nProcedural fracture algorithms use geometric heuristics to precompute a prefraction of an object into realistic-looking pieces before simulation. This can be achieved, for example, by cutting a shape by the Voronoi diagrams of randomly scattered points [37, 45], perturbed level-set functions (e.g., [7, 34]) or pre-authored fracture patterns [33, 54]. They then use geometric strategies such as Euclidean distance thresholds to decide which fractures get activated when a sufficiently strong contact is detected. While some of these algorithms are fast enough to be used at a massive scale, the artificial regularity of the produced pieces (e.g., Voronoi diagrams produce only convex patterns) would limit the diversity of any produced dataset. Further, the fact that the fracture patterns are not physically based would make it harder for learning from data to generalize to real-world scenarios.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"First, compute fracture modes. Then, use fracture modes to simulate different fracture patterns.\\n\\nRecently, Sell\u00e1n et al. [51] bridged the gap between physical and procedural fracture by providing a physics-based pre-fracture algorithm. We adopt this method for our dataset generation task, as it efficiently (i.e., in a scalable way) computes a set of orthogonal (i.e., maximally different), natural (i.e., likely) fracture patterns. We review their algorithm below.\\n\\n**3 Background: Fracture Modes for Fast Simulation**\\n\\nLet $\\\\Omega$ be a volumetric mesh with $n$ vertices and $m$ tetrahedra. The first $k$ elastic modes of $\\\\Omega$ are then defined as the columns of a matrix $U \\\\in \\\\mathbb{R}^{3 \\\\times k}$ which solve the eigenvalue problem:\\n\\n$$\\\\arg\\\\min_U U^T MU = I,$$\\n\\nwhere $Q$ is the Hessian matrix of some elastic strain energy at the rest configuration and $M$ is the traditional FEM mass matrix.\\n\\nSell\u00e1n et al. [51] generalize this idea to generate discontinuous \\\"fracture modes.\\\" The key insight is to define solutions over a larger discontinuous function space, where values are not stored per vertex, but rather per corner of each tetrahedron. Their fracture modes are columns in a matrix $\\\\tilde{U} \\\\in \\\\mathbb{R}^{12 \\\\times k}$ which solve the generalized eigenvalue problem:\\n\\n$$\\\\arg\\\\min_{\\\\tilde{U}} \\\\tilde{U}^T \\\\tilde{M} \\\\tilde{U} = I,$$\\n\\nwhere $\\\\tilde{Q}, \\\\tilde{M} \\\\in \\\\mathbb{R}^{12 \\\\times 12}$ operators are trivial extensions into this larger function space, $E_D(\\\\tilde{u}_r)$ is a convex objective function measuring the total amount of discontinuity (intuitively, how fractured the function is), and $!$ is a weight balancing both terms. As shown by Sell\u00e1n et al. [51], the value of $!$ has no effect on the output modes as long as it is small enough, so we fix it at $0.001$.\\n\\nThe computed fracture modes can then be used for efficient destruction simulation. Any impact on the shape represented as a vector $w \\\\in \\\\mathbb{R}^{12 \\\\times m}$ can be projected onto the precomputed fracture modes to obtain a fractured displacement of the model:\\n\\n$$w^? = \\\\tilde{U} \\\\tilde{U}^T \\\\tilde{M} w.$$\\n\\nLike the individual modes, $w^?$ will represent the function with discontinuities. By identifying these (through a discontinuity threshold $\\\\tau$), one can compute an impact-dependent fracture pattern for $\\\\Omega$. Much of the computational cost of this impact projection step can benefit from precomputation, as shown in [51]. Thus, the impact-specific runtime has linear complexity in the mesh size. This precomputation also benefits our dataset generation by allowing very efficient storage of many fractures of the same shape (see Section 4.3). We refer the reader to [51] for more details about the fracture simulation algorithm.\\n\\n**4 The Breaking Bad Dataset**\\n\\nOur dataset contains results of fracture simulation conducted on a large base library of 3D shapes.\\n\\n**Base shape selection.** Since our main intended application is to facilitate research in shape reassembly, we first collect all meshes from 20 daily object categories in PartNet [32], i.e., BeerBottle, Bottle, ...\"}"}
{"id": "mJWt6pOcHNy", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 3: Dataset gallery. Our dataset contains a diverse set of objects, which can be used for various applications. (Left) Artifacts for archaeology applications. (Middle) Everyday objects for computer vision and robotics applications. (Right) Other objects for video gaming and example-based fracture simulation. Bowl, Cup, Cookie, DrinkBottle, DrinkingUtensil, Mirror, Mug, PillBottle, Plate, Ring, Spoon, Statue, Teacup, Teapot, ToyFigure, Vase, WineBottle, and WineGlass, forming the everyday object subset. We also select meshes with tag sculpture and tag scan from Thingi10K [65] to construct the artifact subset, which contains common objects in archeology. Finally, we construct the other subset using all the remaining meshes from Thingi10K to increase the diversity of our dataset. For Thingi10K models, we use the pre-processed watertight meshes provided by Hu et al. [19].\\n\\n4.1 Fracture Simulation\\n\\nFigure 2 presents the dataset processing pipeline. We treat objects as solids and assume isotropic materials. We process each of the selected input meshes in the base dataset independently. We re-scale each of them to fit a unit-length box for parameter choice consistency. This normalization scheme allows our method to be scale invariant.\\n\\nWe begin by constructing a coarse (4,000 face) cage triangular mesh that fully contains the input following the Simple Nested Cages (SNC) algorithm introduced in [51], with a grid size of 100. While more tightly-fitting cage generation algorithms exist (e.g., [47]), we find SNC, which relies on signed distance computation [4] and isosurface extraction [30], to be superior in robustness, runtime and reliability. These are all aspects that are critical for geometry processing at a large scale. We tetrahedralize the cage using TETGEN [53].\\n\\nWe compute the first 20 fracture modes of the tetrahedral cage mesh following the scheme described in Section 3. We then transfer these modes to the input mesh, intersecting all the possible fracture patterns that can be spanned by the modes with the input mesh as described in Section 3.5 of [51]. This step is the performance bottleneck of our processing pipeline, covering around 70% of runtime. After this pre-computation step, we simulate impacts at random points on the cage geometry\u2019s surface, obtaining each impact-dependent fracture pattern in around one millisecond. For each impact, we also randomize the discontinuity threshold $\\\\tau$ to account for different materials being more or less prone to breaking. We discard a fracture pattern if it produces fewer than two or more than 100 pieces (while perhaps realistic behavior, this can make the reassembly task excessively difficult) and repeat until we have 80 valid fracture patterns. We add these, together with the 20 fracture modes, to our dataset, totaling 100 fracture patterns per base shape. The speed of the impact projection makes it so that this step is dominated by the writing of the output fractured meshes into our dataset. See inset for examples of fractured objects in each subset of our dataset.\\n\\nImplementation.\\n\\nWe implement our data processing pipeline in PYTHON, using LIBIGL [22] for common geometry processing subroutines. We run the jobs on a dedicated CPU cluster with 2.5GHz Intel(R) Xeon(R) processors. We use 320 CPU cores, each with 386GB RAM, to parallelize the data generation jobs. With our efficient simulator, we can generate the entire dataset in 24 hours.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.2 Dataset Analysis\\n\\nWe report statistics at the 25th, 50th, and 75th percentiles of a variety of geometric characteristics: report the number of fractured pieces per object, the number of vertices per fractured piece, the number of faces per fractured piece, the volume per fractured piece for each subset in Table 2. A tell-tale sign of prior precomputed fracture methods (e.g., [33]) is the overabundance of convex pieces. We quantify the convexity of our produced fracture pieces using the rank defined by Asafi et al. [3] (computed on a randomly selected subset of 1,000 pieces). The inset presents the percentile plot of fractured pieces of each subset. Our dataset has a wide distribution over the number of fractured pieces with large variations of volume. See Figure 3 for some examples of fractured objects in each subset of our dataset.\\n\\n4.3 Dataset Access and Storage\\n\\nOur full dataset contains over one million individual fractured shapes. Stored in a standard geometric file format (i.e., .OBJ), it occupies well over 1TB (before zipping). While its massive scale is one of the main contributions of our dataset, it can also complicate its sharing and storage. To address this, we draw from the specifics of our fracture simulation step to produce a losslessly compressed version of our dataset, which contains all the same information as our full dataset in as little as 10GB before zipping and 7.3GB after zipping. We release it alongside our full dataset.\\n\\nBy nature of the projection step in Equation (3), the simulated fractures can only contain discontinuities at fracture faults that are already present in at least one of the fracture modes. Therefore, we can use the fracture modes to compute a super-segmentation of the base shape into all possible pieces that can result from projecting impacts onto them. Thus, instead of storing 100 fracture patterns per base shape, we can store only this super-segmentation and, for each projected impact, per-piece labeling identifies which pieces break off. This reduces the size of our dataset by almost a factor of 100. Decompressing the data is just a matter of looping over all fractures and pasting the pieces of the super-segmented mesh that do not break off in each case. We provide a PYTHON script that does this.\\n\\nWe develop a website (see Figure 4) to host our dataset and facilitate interactive exploring of the fractured objects. Our prototype at https://breaking-bad-dataset.github.io/ contains the compressed dataset, the decompression instructions, and user-friendly gallery views, allowing direct download of individual models.\\n\\n4.4 Licensing\\n\\nWe gather our base models following the licenses specified in each of the source datasets: the MIT license in the PARTNET dataset and a variety of open-source licenses in the THINGI 10K dataset (see Figure 12 in [65]). We release each model in our dataset with an as-permissive-as-possible license compatible with its underlying base model and all code under the MIT license.\\n\\n5 Case Study Application: 3D Geometric Shape Assembly\\n\\nThe Breaking Bad dataset can be used for applications in the 3D geometric shape assembly task. In this section, we consider vision-based 3D geometric shape assembly as a case-study application.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Evaluation on fracture reassembly. We report the results of three learning-based shape assembly models on the everyday object subset. The results are averaged over all 20 categories.\\n\\n| Method       | RMSE (\u00b0) | #RMSE (\u00b0) | #CD | #PA |\\n|--------------|----------|-----------|-----|-----|\\n| Global       | 80.7     | 15.1      | 14.6| 24.6|\\n| LSTM         | 84.2     | 16.2      | 15.8| 22.7|\\n| DGL          | 79.4     | 15.0      | 14.3| 31.0|\\n\\nGT Input DGL Global LSTM\\n\\nFigure 5: Visual results on the everyday object subset.\\n\\nFollowing existing methods [7, 20], we assume the models only have access to point clouds sampled from each fracture. Meshes are only used for result visualizations. Given $N$ mesh fractured pieces of an object $F = \\\\{F_i\\\\}_{i=1}^N$, we sample a point cloud from the mesh of each fractured piece forming $P = \\\\{P_i\\\\}_{i=1}^N$, where $N$ is the number of fracture pieces which varies across different shapes and fracture patterns. We aim to learn a model that takes as input the sampled point clouds $P$ and predicts the canonical SE(3) pose for each point cloud (fractured piece). Denote the predicted SE(3) pose of the $i$-th fractured piece as $q_i = \\\\{ (R_i, T_i) | R_i \\\\in \\\\mathbb{R}^{3 \\\\times 3}, T_i \\\\in \\\\mathbb{R}^3 \\\\}$, where $R_i$ is the rotation matrix and $T_i$ is the translation vector. We apply the predicted SE(3) poses to transform the pose of each fractured piece and get $q_i(P_i) = R_iP_i + T_i$, respectively. The union of all of the pose-transformed point clouds $S = \\\\bigcup q_i(P_i)$ results in the predicted assembly result.\\n\\nWe benchmark three state-of-the-art shape assembly methods and perform analysis on the Breaking Bad dataset to answer the following questions:\\n\\n1. How do learning-based shape assembly methods perform on fracture reassembly? (Section 6.1)\\n2. How does the number of fractured pieces affect performance? (Section 6.2)\\n3. Do model pre-training and fine-tuning schemes help improve performance? (Section 6.3)\\n4. How well do state-of-the-art shape assembly methods generalize to unseen objects? (Section 6.4)\\n\\nEvaluation metrics. Following the same evaluation scheme as NSM [7], we compute the root mean square error (RMSE) and the mean absolute error (MAE) between the predicted and ground-truth rotation $R$ and translation $T$, respectively. We use Euler angle to represent rotation. We report the RMSE results in the main paper and the results of MAE are provided in the Appendix. In addition, we follow the evaluation protocol in [29] and adopt the shape chamfer distance (CD) and part accuracy (PA) metrics for performance evaluation. The details of shape chamfer distance and part accuracy are provided in Appendix B.\\n\\nBaseline methods. We select three state-of-the-art learning-based shape assembly methods for benchmarking performance on our dataset: Global [28, 48], LSTM [62] and DGL [20]. We note that while NSM [7] is a learning-based method that is designed for geometric shape assembly, their model only considers two-part assembly, which cannot be applied directly to address the multi-part assembly problem, which is the task considered in this paper. We also do not benchmark RGL-NET [16] on our dataset, because it requires part ordering information for shape assembly. While such an ordering can be defined in semantic part assembly (e.g. chair seat \u2192 chair leg \u2192 chair back), the definition is unclear in geometric shape assembly. Without the ordering information, RGL-NET will degenerate to DGL. We therefore do not include NSM and RGL-Net for benchmarking performance. The details of each baseline method are provided in Appendix C.\\n\\nImplementation details. Meshes in each category are aligned to a canonical pose as the ground-truth assembly. In each experiment, we use 80% data for training and the remaining 20% for testing. We sample 1,000 points from each fractured piece on the fly during training. Each point cloud is zero-centered and randomly rotated, providing self-supervision labels for model training. More training and implementation details are summarized in Appendix E.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"6.1 Task Performance\\nFollowing semantic part assembly methods [20, 29], we train and test each baseline method on fractured objects with at most 20 fractured pieces, train one model for each category, and report performance averaged over all 20 categories. We use the *everyday* object subset for evaluation.\\n\\nTable 3 presents the performance of three baseline methods. Quantitatively, DGL outperforms Global and LSTM on all metrics. Qualitatively, (see Figure 5) DGL predicts assembly results that are visually more similar to ground truths compared to the other two baselines. The results suggest that GNNs have a better ability in reasoning about the fit between fractures than the other two architectures.\\n\\nWhile these methods achieve strong performance on the semantic part assembly task, they all suffer from a drastic performance drop on the geometric shape assembly task (the task considered in this paper). This is because in semantic shape assembly, all parts have clear semantic meanings and shape assembly can be achieved by leveraging such priors. To achieve this, existing methods use PointNet [44] to learn a global shape feature for each part. In contrast, geometric shape assembly has to rely on learned local features for local surface matching, which cannot be achieved by PointNet.\\n\\nThe significant performance drop highlights the difference between semantic shape assembly and geometric shape assembly and suggests that specific model designs leveraging local geometric cues for assembling fractured pieces are required. More results are provided in Appendix F.1.\\n\\n6.2 Ablation Study: Number of Fractured Pieces\\nExisting semantic part assembly methods [20, 28, 48, 62] only consider cases where each object has at most 20 parts. However, objects can break into more numbers of fractured pieces. Since our dataset contains objects with up to 100 fractured pieces, we analyze how training with different numbers of fractured pieces affects model performance. Specifically, we train DGL on the *everyday* object subset with three settings: (i) training the model on fractured objects with 2 to 20 fractured pieces, (ii) 2 to 50 fractured pieces, and (iii) 2 to 100 fractured pieces. In each setting, we report the performance evaluated on objects with 2 to 20, 21 to 50, and 51 to 100 fractured pieces, respectively.\\n\\nAs shown in Table 4, the performance evaluated by chamfer distance and part accuracy drops significantly when the model is tested on objects with more numbers of fractures. Training on more numbers of fractures improves chamfer distance and part accuracy evaluated on objects with 21 to 50 and 51 to 100 fractures. Shape assembly is a combinatorial problem. As the number of fractures increases, the problem complexity increases. The ablation study results concur with this and demonstrate the difficulty of our dataset. More quantitative results are provided in Appendix F.2.\\n\\n6.3 Analysis of Model Pre-training and Fine-tuning\\nModel pre-training and fine-tuning have been shown effective in many vision tasks [17, 46, 67]. We analyze how applying model pre-training and fine-tuning schemes affect performance on the fracture reassembly task. We adopt the *artifact* subset for quantifying performance. Following Section 6.1, we train and test each baseline method on objects with at most 20 fractured pieces.\\n\\nWe report the results of training each baseline from scratch in the top block of Table 5 and those obtained by fine-tuning from the respective models in Table 3 in the bottom block of Table 5. All three models improve chamfer distance and part accuracy when the models are fine-tuned from the respective models pre-trained on the *everyday* object subset. This finding is in line with those in recent model pre-training studies [17, 46, 67]. More quantitative results are provided in Appendix F.3.\\n\\n6.4 Generalization to Unseen Objects\\nA core question in machine learning and computer vision is generalization. We investigate this and ask how well do the three learning-based shape assembly methods generalize to unseen objects.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Ablation study: Number of fractured pieces. We train DGL on the everyday object subset in three settings and report performance evaluated on fractured objects of different numbers of fractured pieces. The results are averaged over all 20 categories.\\n\\n| Test set   | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| 2-20 pieces | 79.4     | 15.0      | 14.3 | 31.0 |\\n| 21-50 pieces | 84.4     | 20.1      | 15.0 | 7.5  |\\n| 51-100 pieces | 85.1     | 21.3      | 23.0 | 4.8  |\\n\\nResults of training on fractured objects with 2 to 20 fracture pieces\\n\\n| Test set   | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| 2-20 pieces | 79.9     | 14.8      | 14.0 | 29.9 |\\n| 21-50 pieces | 84.5     | 19.6      | 14.0 | 7.7  |\\n| 51-100 pieces | 84.8     | 20.5      | 18.1 | 4.7  |\\n\\nResults of training on fractured objects with 2 to 50 fracture pieces\\n\\n| Test set   | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| 2-20 pieces | 79.8     | 14.4      | 14.0 | 29.4 |\\n| 21-50 pieces | 84.3     | 19.2      | 14.5 | 7.4  |\\n| 51-100 pieces | 85.3     | 20.0      | 13.9 | 4.8  |\\n\\nResults of training on fractured objects with 2 to 100 fracture pieces\\n\\nTable 5: Analysis of model pre-training and fine-tuning. We report the results of three learning-based shape assembly models on the artifact subset.\\n\\n| Method     | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| Global     | 84.8     | 16.7      | 19.0 | 12.7 |\\n| LSTM       | 85.2     | 17.2      | 23.5 | 6.6  |\\n| DGL        | 85.8     | 16.8      | 19.4 | 12.8 |\\n\\nResults of training the model from scratch\\n\\n| Method     | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| Global     | 83.8     | 16.6      | 19.0 | 13.3 |\\n| LSTM       | 84.6     | 16.8      | 21.5 | 11.7 |\\n| DGL        | 81.7     | 16.6      | 17.3 | 19.4 |\\n\\nResults of fine-tuning from the model in Table 3\\n\\nTable 6: Generalization to unseen objects. We report the results of three learning-based shape assembly models on the other subset.\\n\\n| Method     | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| Global     | 86.4     | 19.4      | 42.2 | 6.0  |\\n| LSTM       | 84.9     | 18.7      | 45.3 | 4.8  |\\n| DGL        | 86.6     | 20.1      | 38.5 | 7.5  |\\n\\nResults of testing the model in Table 3\\n\\n| Method     | RMSE (R) | #RMSE (T) | CD | PA   |\\n|------------|----------|-----------|----|------|\\n| Global     | 83.9     | 18.8      | 39.2 | 6.7  |\\n| LSTM       | 82.9     | 17.9      | 40.3 | 5.5  |\\n| DGL        | 81.3     | 17.2      | 36.6 | 8.3  |\\n\\nResults of testing the model in the bottom block of Table 5\\n\\nWe take the models in Table 3 (models trained on the everyday object subset) and the models in the bottom block of Table 5 (models trained on the everyday object subset and fine-tuned on the artifact subset), and test them on the other subset. Similar to Section 6.1, we train and test each baseline method on fractured objects with at most 20 fractured pieces. We report the results of testing the model in Table 3 in the top block of Table 6 and the results of testing the model in the bottom block of Table 5 in the bottom block of Table 6. Both chamfer distance and part accuracy become worse when compared to the results in Table 3 and Table 5. This is not surprising as the models are never trained on the other subset and the shape geometry and fracture patterns in the other subset are different from those in the everyday object and artifact subsets (see Figure 3). More quantitative results are provided in Appendix F.4.\\n\\nWhile the results show that all three learning-based shape assembly models do not generalize well, we observe that when comparing the results between the top and bottom blocks of Table 6 the models pre-trained on more data (models used in the bottom block) achieve better chamfer distance and part accuracy results. The finding here is consistent with those in computer vision tasks that training on more data results in better model generalization [6,8,13].\\n\\n7 Limitations & Future Work\\n\\nWe inherit all the fundamental limitations of our choice of the underlying fracture simulation method [51]. Most notably, fractures are assumed to be brittle (as opposed to ductile). This is reasonable for stiff materials like ceramics, glass or plastic undergoing sudden impacts, but not representative of fractures caused by extensive plastic deformations (e.g., when bending or...\"}"}
{"id": "mJWt6pOcHNy", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"stretching rubber or metal until finally reaching its breaking point). Further, fractures are assumed to instantaneously appear. In reality, fractures propagate through a shape according to relieved stress. One characteristic is that faults tend to be perpendicular at junctures. This quality is absent from Sell\u00e1n et al.'s fracture patterns; known methods for achieving this require excessively small simulation time-stepping, prohibiting efficient construction of a large-scale dataset generation. Finally, our fractures follow the faces of the underlying tetrahedral mesh. Sell\u00e1n et al. suggest post-processing fracture surfaces with the upper-envelope-based method of Abdrashitov et al. [1]. As this post-processing introduces yet another hyperparameter, we leave smoothing as an option for the dataset user to conduct on their own. Future improvements of our dataset could alternate between [51] and other fracture algorithms at the generation stage to mitigate simulation-specific biases.\\n\\nWhile Sell\u00e1n et al. [51] can simulate material changes and fracture anisotropies through a user-specified vector field, setting this parameter automatically given an object is a research problem beyond the scope of our work. For scalability, we instead assume every object to be made of a single material with no preferred fracture direction. Future work could couple our fracture generation with neural material or semantic segmentations to produce fractures for more complex objects.\\n\\nOur choice of the base model library includes models relevant to many situations, but would be inappropriate for others (e.g., medical domains requiring anatomical accuracy). We inherit the biases of these base libraries (e.g., cultural biases of the \u201ceveryday\u201d objects in PartNet and biases toward small plastic 3D printable objects in Thingi10K).\\n\\nThere are a number of directions for future work that are made possible by our dataset. In computer graphics, using our dataset facilitates the development of real-time example-based fracture algorithms [50]. In archaeology [9], our dataset can be used to study the problems of missing fractured pieces [63] or distorted parts. Another interesting direction would be studying geometric shape assembly in few-shot [57] and zero-shot [56] settings, since data is often scarce or even not available in real world. In robotics, our dataset facilitates the development of sequential decision-making algorithms [12] with task-oriented grasping [64] to achieve robotic assembly. We hope that releasing our dataset and a testbed that includes all three baseline methods will allow multiple communities to form discussions and development around this practical yet challenging fracture reassembly problem.\\n\\nAcknowledgments\\n\\nThis project is funded in part by NSERC Discovery (RGPIN2017\u201305235, RGPAS\u20132017\u2013507938), New Frontiers of Research Fund (NFRFE\u2013201), the Ontario Early Research Award program, the Canada Research Chairs Program, a Sloan Research Fellowship, the DSI Catalyst Grant program and gifts by Adobe Inc. Silvia Sell\u00e1n is funded in part by an NSERC Vanier Scholarship and an Adobe Research Fellowship. Animesh Garg is supported by CIFAR AI chair, NSERC Discovery Award, University of Toronto XSeed Grant and NSERC Exploration grant. We would like to acknowledge Vector institute for computation support. We thank Xuan Dam, John Hancock and all the University of Toronto Department of Computer Science research, administrative and maintenance staff that literally kept our lab running during very hard years.\\n\\nReferences\\n\\n[1] Rinat Abdrashitov, Seungbae Bang, David IW Levin, Karan Singh, and Alec Jacobson. Interactive modeling of volumetric musculoskeletal anatomy. ACM TOG, 2021.10\\n[2] Enkhbayar Altantsetseg, Katsutsugu Matsuyama, and Kouichi Konno. Pairwise matching of 3d fragments using fast fourier transform. The Visual Computer, 2014.1\\n[3] Shmuel Asafi, Avi Goren, and Daniel Cohen-Or. Weak convex decomposition by lines-of-sight. Computer Graphics Forum, 2013.6\\n[4] Gavin Barill, Neil G Dickson, Ryan Schmidt, David IW Levin, and Alec Jacobson. Fast winding numbers for soups and clouds. ACM TOG, 2018.5\\n[5] Benedict J Brown, Corey Toler-Franklin, Diego Nehab, Michael Burns, David Dobkin, Andreas Vlachopoulos, Christos Doumas, Szymon Rusinkiewicz, and Tim Weyrich. A system for high-volume acquisition and matching of fresco fragments: Reassembling theran wall paintings. ACM TOG, 2008.3\\n[6] Joao Carreira and Andrew Zisserman. Quo vadis, action recognition? a new model and the kinetics dataset. In CVPR, 2017.9\"}"}
{"id": "mJWt6pOcHNy", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Yun-Chun Chen, Haoda Li, Dylan Turpin, Alec Jacobson, and Animesh Garg. Neural shape matching: Self-supervised object assembly with adversarial shape priors. In CVPR, 2022.\\n\\nJeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014.\\n\\nG Fatuzzo, G Mussumeci, SM Oliveri, and G Sequenzia. The \u201cguerriero di castiglione\u201d: reconstructing missing elements with integrated non-destructive 3D modelling techniques. Journal of Archaeological Science, 2011.\\n\\nThomas Funkhouser, Hijung Shin, Corey Toler-Franklin, Antonio Garc\u00eda Casta\u00f1eda, Benedict Brown, David Dobkin, Szymon Rusinkiewicz, and Tim Weyrich. Learning how to match fresco fragments. Journal on Computing and Cultural Heritage, 2011.\\n\\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9 III, and Kate Crawford. Datasheets for datasets. Communications of the ACM, 64(12):86\u201392, 2021.\\n\\nSeyed Kamyar Seyed Ghasemipour, Daniel Freeman, Byron David, Satoshi Kataoka, Igor Mordatch, et al. Blocks assemble! learning to assemble with large-scale structured reinforcement learning. arXiv preprint arXiv:2203.13733, 2022.\\n\\nRoss Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, 2014.\\n\\nDavid Hahn and Chris Wojtan. High-resolution brittle fracture simulation with boundary elements. ACM TOG, 2015.\\n\\nDavid Hahn and Chris Wojtan. Fast approximations for boundary element based brittle fracture simulation. ACM TOG, 2016.\\n\\nAbhinav Narayan Harish, Rajendra Nagar, and Shanmuganathan Raman. Rgl-net: A recurrent graph learning framework for progressive part assembly. In WACV, 2022.\\n\\nKaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In CVPR, 2021.\\n\\nKoichi Hirota, Yasuyuki Tanoue, and Toyohisa Kaneko. Generation of crack patterns with a physical model. The Visual Computer, 1998.\\n\\nYixin Hu, Qingnan Zhou, Xifeng Gao, Alec Jacobson, Denis Zorin, and Daniele Panozzo. Tetrahedral meshing in the wild. ACM TOG, 2018.\\n\\nJialei Huang, Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas Guibas, and Hao Dong. Generative 3D part assembly via dynamic graph learning. In NeurIPS, 2020.\\n\\nQi-Xing Huang, Simon Fl\u00f6ry, Natasha Gelfand, Michael Hofer, and Helmut Pottmann. Re-assembling fractured objects by geometric matching. In ACM SIGGRAPH, 2006.\\n\\nAlec Jacobson, Daniele Panozzo, et al. libigl: A simple C++ geometry processing library, 2018.\\n\\nBenjamin Jones, Dalton Hildreth, Duowen Chen, Ilya Baran, Vladimir G Kim, and Adriana Schulz. Automate: A dataset and learning approach for automatic mating of CAD assemblies. ACM TOG, 2021.\\n\\nSatoshi Kataoka, Seyed Kamyar Seyed Ghasemipour, Daniel Freeman, and Igor Mordatch. Bi-manual manipulation and attachment via sim-to-real reinforcement learning. arXiv preprint arXiv:2203.08277, 2022.\\n\\nPeter Kaufmann, Sebastian Martin, Mario Botsch, Eitan Grinspun, and Markus Gross. Enrichment textures for detailed cutting of shells. ACM TOG, 2009.\\n\\nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2014.\\n\\nDan Koschier, Sebastian Lipponer, and Jan Bender. Adaptive tetrahedral meshes for brittle fracture simulation. In Symposium on Computer Animation, 2014.\\n\\nJun Li, Chengjie Niu, and Kai Xu. Learning part generation and assembly for structure-aware shape synthesis. In AAAI, 2020.\\n\\nYichen Li, Kaichun Mo, Lin Shao, Minhyuk Sung, and Leonidas Guibas. Learning 3D part assembly from a single image. In ECCV, 2020.\\n\\nWilliam E Lorensen and Harvey E Cline. Marching cubes: A high resolution 3D surface construction algorithm. In ACM SIGGRAPH, 1987.\\n\\nIlya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. In ICLR, 2017.\\n\\nKaichun Mo, Shilin Zhu, Angel X. Chang, Li Yi, Subarna Tripathi, Leonidas J. Guibas, and Hao Su. PartNet: A large-scale benchmark for fine-grained and hierarchical part-level 3D object recognition.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"understanding. In CVPR, 2019.2, 3, 4, 14\\n\\n[33] Matthias M\u00fcller, Nuttapong Chentanez, and Tae-Yong Kim. Real time dynamic fracture with volumetric approximate convex decompositions. ACM TOG, 2013.2, 3, 6\\n\\n[34] Ken Museth, Peter Cucka, Mihai Alden, and David Hill. Openvdb, 2021.3\\n\\n[35] Alan Norton, Greg Turk, Bob Bacon, John Gerth, and Paula Sweeney. Animation of fracture by physical modeling. The visual computer, 1991.3\\n\\n[36] James F O'Brien and Jessica K Hodgins. Graphical modeling and animation of brittle fracture. In Conference on Computer graphics and interactive techniques, 1999.2, 3\\n\\n[37] Seungtaik Oh, Seunghyup Shin, and Hyeryeong Jun. Practical simulation of hierarchical brittle fracture. Computer Animation and Virtual Worlds, 2012.3\\n\\n[38] Georgios Papaioannou and Evaggelia-Aggeliki Karabassi. On the automatic assemblage of arbitrary broken solid artefacts. Image and Vision Computing, 2003.1\\n\\n[39] Georgios Papaioannou, E-A Karabassi, and Theoharis Theoharis. Virtual archaeologist: Assembling the past. IEEE Computer Graphics and Applications, 2001.1\\n\\n[40] Constantin Papaodysseus, Dimitris Arabadjis, Michalis Exarhos, Panayiotis Rousopoulos, Solomon Zannos, Michail Panagopoulos, and Lena Papazoglou-Manioudaki. Efficient solution to the 3d problem of automatic wall paintings reassembly. Computers & Mathematics with Applications, 2012.1\\n\\n[41] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In NeurIPS, 2019.17\\n\\n[42] Tobias Pfaff, Rahul Narain, Juan Miguel de Joya, and James F. O'Brien. Adaptive tearing and cracking of thin sheets. ACM TOG, 2014.3\\n\\n[43] Ruggero Pintus, Kazim Pal, Ying Yang, Tim Weyrich, Enrico Gobbetti, and Holly Rushmeier. A survey of geometric analysis in cultural heritage. Computer Graphics Forum, 2016.1\\n\\n[44] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In CVPR, 2017.8, 16\\n\\n[45] Saty Raghavachary. Fracture generation on polygonal meshes using voronoi polygons. In ACM SIGGRAPH, 2002.3\\n\\n[46] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NeurIPS, 2015.8\\n\\n[47] Leonardo Sacht, Etienne Vouga, and Alec Jacobson. Nested cages. ACM TOG, 2015.5\\n\\n[48] Nadav Schor, Oren Katzir, Hao Zhang, and Daniel Cohen-Or. Component: Learning to generate the unseen by part synthesis and composition. In CVPR, 2019.7, 8, 16\\n\\n[49] Mike Schuster and Kuldip K Paliwal. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 1997.16\\n\\n[50] Sara C Schvartzman and Miguel A Otaduy. Physics-aware voronoi fracture with example-based acceleration. Journal of Computer Graphics Techniques, 2014.10\\n\\n[51] Silvia Sell\u00e1n, Jack Luong, Leticia Mattos Da Silva, Aravind Ramakrishnan, Yuchuan Yang, and Alec Jacobson. Breaking good: Fracture modes for realtime destruction. Conditionally accepted to Transactions on Graphics (ToG), 2022.2, 3, 4, 5, 9, 10\\n\\n[52] Hijung Shin, Christos Doumas, Thomas Funkhouser, Szymon Rusinkiewicz, Kenneth Steiglitz, Andreas Vlachopoulos, and Tim Weyrich. Analyzing and simulating fracture patterns of theran wall paintings. Journal on Computing and Cultural Heritage, 2012.3\\n\\n[53] Hang Si. Tetgen, a delaunay-based quality tetrahedral mesh generator. ACM Transactions on Mathematical Software, 2015.5\\n\\n[54] Jonathan Su, Craig Schroeder, and Ronald Fedkiw. Energy stability and fracture for frame rate rigid body simulations. In SIGGRAPH/Eurographics Symposium on Computer Animation, 2009.2, 3\\n\\n[55] Corey Toler-Franklin, Benedict Brown, Tim Weyrich, Thomas Funkhouser, and Szymon Rusinkiewicz. Multi-feature matching of fresco fragments. ACM TOG, 2010.2, 3\\n\\n[56] Wei Wang, Vincent W Zheng, Han Yu, and Chunyan Miao. A survey of zero-shot learning: Settings, methods, and applications. ACM Transactions on Intelligent Systems and Technology, 2019.10\\n\\n[57] Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. Generalizing from a few examples: A survey on few-shot learning. ACM Computing Surveys, 2020.10\\n\\n[58] Martin Wicke, Daniel Ritchie, Bryan M Klingner, Sebastian Burke, Jonathan R Shewchuk, and James F O'Brien. Dynamic local remeshing for elastoplastic simulation. ACM TOG, 2010.3\"}"}
{"id": "mJWt6pOcHNy", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Karl DD Willis, Pradeep Kumar Jayaraman, Hang Chu, Yunsheng Tian, Yifei Li, Daniele Grandi, Aditya Sanghi, Linh Tran, Joseph G Lambourne, Armando Solar-Lezama, et al. Joinable: Learning bottom-up assembly of parametric CAD joints. In CVPR, 2022.\\n\\nJoshuah Wolper, Yunuo Chen, Minchen Li, Yu Fang, Ziyin Qu, Jiecong Lu, Meggie Cheng, and Chenfanfu Jiang. Anisompm: Animating anisotropic damage mechanics: Supplemental document. ACM TOG, 2020.\\n\\nJoshuah Wolper, Yu Fang, Minchen Li, Jiecong Lu, Ming Gao, and Chenfanfu Jiang. CD-MPM: Continuum damage material point methods for dynamic fracture animation. ACM TOG, 2019.\\n\\nRundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen. PQ-NET: A generative part seq2seq network for 3D shapes. In CVPR, 2020.\\n\\nKangxue Yin, Zhiqin Chen, Siddhartha Chaudhuri, Matthew Fisher, Vladimir G Kim, and Hao Zhang. Coalesce: Component assembly by learning to synthesize connections. In 3DV, 2020.\\n\\nMingxin Yu, Lin Shao, Zhehuan Chen, Tianhao Wu, Qingnan Fan, Kaichun Mo, and Hao Dong. Roboassembly: Learning generalizable furniture assembly policy in a novel multi-robot contact-rich simulation environment. arXiv preprint arXiv:2112.10143, 2021.\\n\\nQingnan Zhou and Alec Jacobson. Thingi10K: A dataset of 10,000 3D-printing models. In Symposium on Geometry Processing, 2021.\\n\\nYufeng Zhu, Robert Bridson, and Chen Greif. Simulating rigid body fracture with surface meshes. ACM TOG, 2015.\\n\\nBarret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin Dogus Cubuk, and Quoc Le. Rethinking pre-training and self-training. In NeurIPS, 2020.\"}"}
{"id": "mJWt6pOcHNy", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Checklist\\n\\n1. For all authors...\\n   (a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\\n   (b) Did you describe the limitations of your work? [Yes] See Section 7.\\n   (c) Did you discuss any potential negative societal impacts of your work? [Yes] See Appendix A.\\n   (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\\n\\n2. If you are including theoretical results...\\n   (a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n   (b) Did you include complete proofs of all theoretical results? [N/A]\\n\\n3. If you ran experiments (e.g. for benchmarks)...\\n   (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes]\\n      https://breaking-bad-dataset.github.io/ contains instructions to download and process the data. We provide the benchmark_code folder as supplementary material, which contains instructions and code to reproduce the benchmark results.\\n   (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] See Section 5 and Appendix E.\\n   (c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [No] We follow the same evaluation in [20] and do not report error bars. To account for different results caused by different random seeds, all of our experimental results are averaged over three runs. We empirically found that the results are similar over different runs (i.e., standard deviation is small).\\n   (d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] See Section 4.1 and Appendix E.\\n\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n   (a) If your work uses existing assets, did you cite the creators? [Yes] See references [19, 32, 65] for object meshes we used and references [20, 28, 48, 62] and Appendix C for the baseline methods we used.\\n   (b) Did you mention the license of the assets? [Yes] See Section 4.4.\\n   (c) Did you include any new assets either in the supplemental material or as a URL? [No] We did not include new assets either in the supplemental material or as a URL.\\n   (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] See Section 4.4.\\n   (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]\\n\\n5. If you used crowdsourcing or conducted research with human subjects...\\n   (a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]\\n   (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]\\n   (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]\\n\"}"}
