{"id": "CVPR-2023-580", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\n[1] Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, and Alekh Agarwal. Deep batch active learning by diverse, uncertain gradient lower bounds. In International Conference on Learning Representations, 2019.\\n\\n[2] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 113\u2013123, 2019.\\n\\n[3] Alexander Freytag, Erik Rodner, and Joachim Denzler. Selecting influential examples: Active learning with expected model output changes. In European conference on computer vision, pages 562\u2013577. Springer, 2014.\\n\\n[4] Bo Fu, Zhangjie Cao, Jianmin Wang, and Mingsheng Long. Transferable query selection for active domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7272\u20137281, 2021.\\n\\n[5] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francis Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096\u20132030, 2016.\\n\\n[6] Yuhong Guo. Active instance sampling via matrix partition. Advances in Neural Information Processing Systems, 23, 2010.\\n\\n[7] Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, Andrea Vedaldi, and Andrew Zisserman. Automatically discovering and learning new visual categories with ranking statistics. In International Conference on Learning Representations, 2020.\\n\\n[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.\\n\\n[9] Sheng-Jun Huang, Jia-Wei Zhao, and Zhao-Yang Liu. Cost-effective training of deep cnns with active model adaptation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 1580\u20131588, 2018.\\n\\n[10] Ajay J Joshi, Fatih Porikli, and Nikolaos Papanikolopoulos. Multi-class active learning for image classification. In 2009 IEEE conference on computer vision and pattern recognition, pages 2372\u20132379. IEEE, 2009.\\n\\n[11] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\\n\\n[12] David D Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning. In Machine learning proceedings 1994, pages 148\u2013156. Elsevier, 1994.\\n\\n[13] Jichang Li, Guanbin Li, Yemin Shi, and Yizhou Yu. Cross-domain adaptive clustering for semi-supervised domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2505\u20132514, 2021.\\n\\n[14] Jian Liang, Dapeng Hu, and Jiashi Feng. Domain adaptation with auxiliary target domain-oriented classifier. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16632\u201316642, 2021.\\n\\n[15] Zhuoming Liu, Hao Ding, Huaping Zhong, Weijia Li, Jifeng Dai, and Conghui He. Influence selection for active learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9274\u20139283, 2021.\\n\\n[16] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97\u2013105. PMLR, 2015.\\n\\n[17] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial domain adaptation. Advances in neural information processing systems, 31, 2018.\\n\\n[18] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint adaptation networks. In International conference on machine learning, pages 2208\u20132217. PMLR, 2017.\\n\\n[19] Hieu T Nguyen and Arnold Smeulders. Active learning using pre-clustering. In Proceedings of the twenty-first international conference on Machine learning, page 79, 2004.\\n\\n[20] Amin Parvaneh, Ehsan Abbasnejad, Damien Teney, Gholamreza Reza Haffari, Anton van den Hengel, and Javen Qinfeng Shi. Active learning by feature mixing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12237\u201312246, 2022.\\n\\n[21] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1406\u20131415, 2019.\\n\\n[22] Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, and Judy Hoffman. Active domain adaptation via clustering uncertainty-weighted embeddings. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8505\u20138514, 2021.\\n\\n[23] Dan Roth and Kevin Small. Margin-based active learning for structured output spaces. In European Conference on Machine Learning, pages 413\u2013424. Springer, 2006.\\n\\n[24] Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Trevor Darrell, and Kate Saenko. Semi-supervised domain adaptation via minimax entropy. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8050\u20138058, 2019.\\n\\n[25] Ozan Sener and Silvio Savarese. Active learning for convolutional neural networks: A core-set approach. In International Conference on Learning Representations, 2018.\\n\\n[26] Jong-Chyi Su, Yi-Hsuan Tsai, Kihyuk Sohn, Buyu Liu, Subhransu Maji, and Manmohan Chandraker. Active adversarial domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 739\u2013748, 2020.\\n\\n[27] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472\u20137481, 2018.\"}"}
{"id": "CVPR-2023-580", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018\u20135027, 2017.\\n\\nDan Wang and Yi Shang. A new active labeling method for deep learning. In 2014 International joint conference on neural networks (IJCNN), pages 112\u2013119. IEEE, 2014.\\n\\nKeze Wang, Dongyu Zhang, Ya Li, Ruimao Zhang, and Liang Lin. Cost-effective active learning for deep image classification. IEEE Transactions on Circuits and Systems for Video Technology, 27(12):2591\u20132600, 2016.\\n\\nBinhui Xie, Longhui Yuan, Shuang Li, Chi Harold Liu, Xinjing Cheng, and Guoren Wang. Active learning for domain adaptation: An energy-based approach. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8708\u20138716, 2022.\\n\\nJunyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised deep embedding for clustering analysis. In International conference on machine learning, pages 478\u2013487. PMLR, 2016.\\n\\nMing Xie, Yuxi Li, Yabiao Wang, Zekun Luo, Zhenye Gan, Zhongyi Sun, Mingmin Chi, Chengjie Wang, and Pei Wang. Learning distinctive margin toward active domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7993\u20138002, 2022.\\n\\nHeng-Chao Yan, Jun-Hong Zhou, and Chee Khiang Pang. Gaussian mixture model using semisupervised learning for probabilistic fault diagnosis under new data categories. IEEE Transactions on Instrumentation and Measurement, 66(4):723\u2013733, 2017.\\n\\nZizheng Yan, Yushuang Wu, Guanbin Li, Yipeng Qin, Xiaoguang Han, and Shuguang Cui. Multi-level consistency learning for semi-supervised domain adaptation. arXiv preprint arXiv:2205.04066, 2022.\\n\\nShiqi Yang, Joost van de Weijer, Luis Herranz, Shangling Jui, et al. Exploiting the intrinsic neighborhood structure for source-free domain adaptation. Advances in Neural Information Processing Systems, 34:29393\u201329405, 2021.\\n\\nDonggeun Yoo and In So Kweon. Learning loss for active learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 93\u2013102, 2019.\\n\\nZiyi Zhang, Weikai Chen, Hui Cheng, Zhen Li, Siyuan Li, Liang Lin, and Guanbin Li. Divide and contrast: Source-free domain adaptation via adaptive contrastive learning. arXiv preprint arXiv:2211.06612, 2022.\"}"}
{"id": "CVPR-2023-580", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"with information, therefore building a more trustworthy GMM model be labeled samples can be used to construct supervision infor-\\n\\nbe created by manual division. Then be separated, thereby avoiding sampling bias that may \\n\\nmapped to the probability distribution of four categories and \\n\\nmixture model (GMM), the target data can be adaptively \\n\\ntribution of InfoF scores using a four-component Gaussian \\n\\nto learn mixture models to separate four sample partitioning \\n\\nbe labeled target data as stated above are significantly separable \\n\\ngeneral, it can be observed that the four categories of unla-\\n\\ngoal of adaptively selecting informative target samples. In \\n\\nformulates an Informative Sampling Function to achieve the \\n\\ning manual data division, leading to a biased sampling strat-\\n\\ntained above would hinder accurate data categorization us-\\n\\nscore. In next section, we devise a strategy for informa-\\n\\nspecific knowledge can be extracted based on the InfoF \\n\\nconfident-inconsistent (CI)\\n\\nAlgorithm 1:\\n\\nThe training procedure of four-\\n\\nsemi-supervised Expectation-Maximization \\n\\ncomponent Gaussian Mixture Model (GMM) using \\n\\n// M step: \\n\\n// E step: \\n\\n\\\\[\\n\\\\alpha, \\\\pi, \\\\mu, \\\\sigma \\\\rightarrow \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\left( \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right) \\\\right)\\n\\\\]\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\\\]\\n\\nInitialize \\n\\nOutput:\\n\\n// E step: \\n\\n\\\\[\\nL = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\n// M step: \\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\nOnce we obtain \\n\\n\\\\[\\nq \\\\rightarrow \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\nQ \\\\rightarrow \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\nThe similarity-based label is determined using categorical \\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\\\]\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\nAfterwards, given a training \\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\\\]\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\\\]\\n\\nOnce we obtain \\n\\n\\\\[\\nq \\\\rightarrow \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\\n\\nQ \\\\rightarrow \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\log \\\\left( \\\\prod_{l=1}^{K} \\\\pi_l \\\\cdot \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) \\\\right)\\n\\n\\\\[\\n\\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot g_k \\\\cdot \\\\frac{1}{N_k} \\\\cdot \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma_k^2}} \\\\cdot \\\\exp \\\\left( -\\\\frac{(x - \\\\mu_k)^2}{2\\\\sigma_k^2} \\\\right) = \\\\sum_u \\\\sum_g \\\\sum_k u \\\\cdot \\\\sum_l \\\\sum_k \\\\sum_g \\\\sum_k u \\\\cdot p(x, y) \\n\\\\]\"}"}
{"id": "CVPR-2023-580", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"used for the weighted integration of the labeled and unlabeled training instances. Thus, we can summarize the training procedure of the GMM model using a semi-supervised EM algorithm in Algorithm 1 according to [34].\\n\\nAfter obtaining the trained GMM parameters $W$, the probability of a sample $x$ from $U$ being classified into the $k$-th component can be computed as follows,\\n\\n$$\\\\text{Pr}(z = k | x, W) = \\\\frac{\\\\pi_k N(\\\\ell_u(x); \\\\mu_k, \\\\sigma_k)}{\\\\sum_{k'} \\\\pi_{k'} N(\\\\ell_u(x); \\\\mu_{k'}, \\\\sigma_{k'})},$$\\n\\n(9)\\n\\nwhere $z$ is a discrete variable to infer which component the sample $x$ belongs to.\\n\\n### 3.3. Candidate Selection and Training Objectives\\n\\nAfter acquiring the informativeness sampling function, it is utilized for carrying out data partitioning. For ADA, the main focus should be on annotating samples that are uncertain to the model and can effectively represent the target dataset, which is termed as uncertain-inconsistent samples within our subdivision framework. Therefore, during each sampling step, we first rank the unlabeled target samples in descending order according to the scores predicted by $\\\\text{Pr}(z = k | \\\\cdot, W)$, and then the top $b$ examples are selected to annotate and moved into labeled target data. Following previous ADA works, we apply the standard cross-entropy loss to the labeled data as follows:\\n\\n$$L_{\\\\text{sup}} = E_{(x,y) \\\\sim S \\\\cup T} \\\\left[ -\\\\sum_{c=1}^{C} 1 \\\\{ c = y \\\\} \\\\cdot \\\\log P_c(x) \\\\right].$$\\n\\n(10)\\n\\nTo boost the selectivity of the sampling strategy, we further design tailored training techniques for the other data subsets with varied transferable properties. We perform data partitioning on the remaining unlabeled target samples, i.e., $U \\\\leftarrow U \\\\setminus T$, according to the posterior probabilities regarding the rest of Gaussian components.\\n\\n$$\\\\hat{U}_k = \\\\{ x | \\\\arg\\\\max \\\\text{Pr}(x) = k, \\\\forall (x, \\\\cdot) \\\\in U \\\\},$$\\n\\n(11)\\n\\nwhere $\\\\hat{U}_1, \\\\hat{U}_2, \\\\hat{U}_4$ refer to $\\\\hat{U}_{CC}, \\\\hat{U}_{UC}, \\\\hat{U}_{CI}$. Here, $\\\\text{Pr}(x)$ is the concatenated probability vector corresponding to different components, i.e., $\\\\text{Pr}(x) = [\\\\text{Pr}(z = 1 | x, W), \\\\text{Pr}(z = 2 | x, W), \\\\text{Pr}(z = 3 | x, W), \\\\text{Pr}(z = 4 | x, W)]$ w.r.t the sample $x$.\\n\\nAs shown in Figure 1(4), the source-oriented model could produce confident but unreliable predictions for some target samples having large domain gap with the source. Samples from $\\\\hat{U}_{CI}$ have extremely controversial results between model prediction and similarity-based label, which are most likely to be some excessively challenging instances. Therefore, we withhold them in the current stage to avoid jeopardizing the training stability.\\n\\nThe samples in $\\\\hat{U}_{CC}$ have confident and reliable predictions, which tend to be some class centroid in the target feature space. Therefore, we apply consistency regularization to them to enforce the prediction consistency under different perturbations, which can be formulated as follows:\\n\\n$$L_{\\\\text{con}} = E_{(x, \\\\cdot) \\\\sim \\\\hat{U}_{CC}} \\\\left[ -\\\\sum_{c=1}^{C} 1 \\\\{ \\\\hat{y}(x) = c \\\\} \\\\cdot \\\\log P_c(\\\\text{Aug}(x)) \\\\right].$$\\n\\n(12)\\n\\nwhere $\\\\text{Aug}(\\\\cdot)$ is a function to create perturbations for the sample $x$ using classic data augmentation techniques such as AutoAugment [2].\\n\\nFor data group $\\\\hat{U}_{UC}$ whose prediction tend to be reliable but uncertain, we directly minimize the entropy of the predictions to using the following conditional entropy loss:\\n\\n$$L_{\\\\text{ent}} = E_{(x, \\\\cdot) \\\\sim \\\\hat{U}_{UC}} \\\\left[ -\\\\sum_{c=1}^{C} P_c(x) \\\\log P_c(x) \\\\right].$$\\n\\n(13)\\n\\nIn summary, the overall loss functions used to further optimize the model can be formulated as follows,\\n\\n$$L = L_{\\\\text{sup}} + \\\\lambda_c L_{\\\\text{con}} + \\\\lambda_e L_{\\\\text{ent}}$$\\n\\n(14)\\n\\nwhere $\\\\lambda_c$ and $\\\\lambda_e$ are the weights to trade off different loss terms during the training process. As shown in Figure 2, $L_{\\\\text{sup}}$ can calibrate the potentially underfitting of uncertain and target-specific samples. $L_{\\\\text{con}}$ can guide the model to learn global cross-domain clustering while $L_{\\\\text{ent}}$ serves to minimize the distance of data from the same class. As demonstrated in Sec.4.3, these training objectives are complementary to each other to best adapt the model to the target domain.\\n\\n### 3.4. Compatibility with UDA/SSDA/SFDA\\n\\nThe proposed sampling strategy of DiaNA requires no additional network modules like a domain discriminator or multiple classifiers [4, 26], making it easy to be integrated into existing DA frameworks, such as unsupervised domain adaptation (UDA), semi-supervised domain adaptation (SSDA), and source-free domain adaptation (SFDA); see supplementary document for the implementation details. It should be noted that we further design a variant of DiaNA for the SFDA settings, due to the unavailability of source data. As evidenced by Sec.4.3, when integrated into diverse DA techniques, the proposed sampling strategy can deliver more performance improvement than random sample selection, thereby demonstrating its compatibility in various DA settings. To the best of our knowledge, we are the first to propose an active selection strategy that can generalize to UDA, SSDA, and SFDA methods.\"}"}
{"id": "CVPR-2023-580", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"### 4. Experiments\\n\\n#### 4.1. Dataset\\n\\nWe validate the effectiveness of the proposed approach DiaNA on three standard benchmark datasets: DomainNet [21], Office-Home [28], and CIFAR-10 [11]. On DomainNet, we select five domains namely Real (R), Clipart (C), Sketch (S), Painting (P), and Quickdraw (Q), while we hire these domains to construct 6 adaptation scenarios. As in [4, 31, 33], we report 12 different adaptation scenarios on Office-Home, constructed from four domains: Real (R), Clipart (C), Art (A), and Product (P). To further evaluate the generalization of the proposed sample selection strategy, we additionally report the classification results on CIFAR-10 with a standard active learning setting.\\n\\n#### 4.2. Implementation\\n\\nHere, we mainly focus on the detailed descriptions of the settings involving active learning on DomainNet, Office-Home, and CIFAR-10, while more implementation details can be found in the supplementary material. In each adaptation scenario, we report the average accuracy over 3 trials.\\n\\n**DomainNet.**\\n\\nSimilar to CLUE [22], we consider ResNet-34 [8] as the network backbone, where such network model is pre-trained on all labeled source samples over 50 training epochs through standard supervision. In all adaptation cases, we set $B = 5000$ and $R = 10$.\\n\\n**Office-Home.**\\n\\nTo be fair, we follow the experimental settings of existing ADA works [4, 31, 33] to conduct performance comparison. In particular, we also use ResNet-50 [8] as the backbone model, while we choose a 5% proportion of unlabeled target data to set the labeling budget $B$, and $R$ is set to 5.\\n\\n**CIFAR-10.**\\n\\nOn this dataset, we select ResNet-34 [8] as the backbone model. We randomly choose 10% training samples at random as the initially labeled data set, and we then annotate 4% at each sampling step with a total annotation budget 30%.\\n\\n#### 4.3. Main Results\\n\\n**Results on DomainNet and Office-Home.**\\n\\nWe summarize the comparison with baselines in Table 1 and Table 2 on both datasets respectively. Note that we consider varying label budgets, namely 1k, 2k, and 5k, on DomainNet. We can see that DiaNA achieves the highest average accuracy in all cases on both datasets for solving the ADA tasks. Especially in the most difficult adaptation scenarios, e.g., C \u2192 A and R \u2192 C, on Office-Home, the proposed method can still exceed all the other methods by more than 1.6% and 1.8% respectively, demonstrating the effectiveness of DiaNA on the commonly used DA benchmark datasets.\\n\\n**Results on CIFAR-10.**\\n\\nWe also extend the proposed method to standard AL tasks on CIFAR-10, where the domain gap between labeled and unlabeled ones is minor. Figure 4(a) lists the comparisons of DiaNA against classic AL strategies involving [1, 20, 25, 29]. It can be observed that compared to classic AL algorithms, with fewer labeling budgets, the effect of the proposed method is still noticeable.\"}"}
{"id": "CVPR-2023-580", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3. Ablation study results of DiaNA. The \u201cAL\u201d column indicates which type of data subset should be selected to be annotated during each sampling step. We evaluated the performance of all adaptation scenarios on Office-Home by averaging their accuracy.\\n\\nCombination with UDA/SSDA/SFDA methods. To validate the compatibility of the proposed DiaNA with existing UDA, SSDA, and SFDA algorithms, we conduct the experiments for UDA and SSDA in the adaptation $C \\\\rightarrow S$ on DomainNet, and for SFDA in $C \\\\rightarrow A$ and $R \\\\rightarrow C$ on Office-Home. DANN [5], MME [24], and NRC [36] correspond to the SOTA methods towards UDA, SSDA, and SFDA, respectively. As shown in Figure 4(b) and Figure 4(c), combining the selection strategy of DiaNA with other DA methods, i.e., DANN+Ours, MME+Ours, and NRC+Ours, significantly increases the performance of existing DA algorithms that select labeled target samples via random selection, namely DANN+Random, MME+Random and NRC+Random. This suggests that, adaptively considering both the domainness and uncertainty, DiaNA is beneficial for the selection of informative target sample searching, while combined into diverse domain adaptation techniques.\\n\\n4.4. Ablation study\\n\\nEfficacy of the targeted training strategies. To illustrate the effect of each component of the proposed DiaNA, we conduct ablation study by removing the corresponding individual components. As displayed in Table 3, the proposed method exceeds all of the model variants by a large accuracy margin on average, demonstrating the effectiveness of each component. By comparing our proposed entire approach with DiaNA w/o GMM, manual data division strategy might considerably cause performance degradation, thereby emphasizing the need for adaptive data subdivision protocol. Furthermore, as demonstrated, disrupting the correspondence between targeted data sub-sets provides empirical evidence supporting the validity of our proposed customized learning techniques; see supplementary document for more details.\\n\\nEfficacy of the sampling strategy. To provide insights into how effectively the domainness-based metric and the uncertainty-based metric work in the sampling step, we use different data subsets to replace the UI subset as active samples for annotation. To eliminate the influence of $L_{con}$ and $L_{ent}$, we remove these two terms but only retain $L_{sup}$ during training. As shown in Table 3, both DiaNA-UC and DiaNA-CI achieve better classification performance than baseline selection, thereby showing the effect of the proposed uncertainty metric and domainness metric. Moreover, active sampling on UI samples (DiaNA-UI) obtains the best performance among all the variants, further illustrating the superiority of the integration of both metrics.\\n\\n5. Conclusions\\n\\nIn this paper, we introduce a \u201cdivide-and-adapt\u201d framework, named DiaNA, to address the problem of active domain adaptation. Specifically, we first design an informativeness function that jointly captures sample's uncertainty and domainness. Moreover, we devise an automatic data subdivision protocol to partition the target instances into four categories with different characteristics. While selecting the most informative samples to annotate, we also design tailored learning strategies for the other target data subsets with stratified transferable properties. Extensive experimental results, as well as ablation studies, have confirmed the superiority of the proposed approach.\\n\\nAcknowledgments\\n\\nThis work was supported in part by the Guangdong Basic and Applied Basic Research Foundation (NO. 2020B1515020048), in part by the National Natural Science Foundation of China (NO. 61976250), in part by the Shenzhen Science and Technology Program (NO. JCYJ20220530141211024) and in part by the Fundamental Research Funds for the Central Universities under Grant 22lgqb25.\"}"}
{"id": "CVPR-2023-580", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Active domain adaptation (ADA) aims to improve the model adaptation performance by incorporating active learning (AL) techniques to label a maximally-informative subset of target samples. Conventional AL methods do not consider the existence of domain shift, and hence, fail to identify the truly valuable samples in the context of domain adaptation. To accommodate active learning and domain adaptation, the two naturally different tasks, in a collaborative framework, we advocate that a customized learning strategy for the target data is the key to the success of ADA solutions. We present Divide-and-Adapt (DiaNA), a new ADA framework that partitions the target instances into four categories with stratified transferable properties. With a novel data subdivision protocol based on uncertainty and domainness, DiaNA can accurately recognize the most gainful samples. While sending the informative instances for annotation, DiaNA employs tailored learning strategies for the remaining categories. Furthermore, we propose an informativeness score that unifies the data partitioning criteria. This enables the use of a Gaussian mixture model (GMM) to automatically sample unlabeled data into the proposed four categories. Thanks to the \\\"divide-and-adapt\\\" spirit, DiaNA can handle data with large variations of domain gap. In addition, we show that DiaNA can generalize to different domain adaptation settings, such as unsupervised domain adaptation (UDA), semi-supervised domain adaptation (SSDA), source-free domain adaptation (SFDA), etc.\\n\\n1. Introduction\\n\\nDomain adaptation (DA) approaches strive to generalize model trained on a labeled source domain to a target domain with rare annotation [5, 13, 16, 24] by coping with the domain disparity. Nevertheless, DA methods are significantly outperformed by their supervised counterparts due to the scarceness of annotation as demonstrated in [4, 14, 27]. In practice, it is cost-effective to get a moderate amount of target samples labeled to boost the performance of domain adaptation. Active learning (AL) approaches seek to select samples with uncertainty [9, 12, 29, 30] and diversity [19, 25] to best benefit the model, which properly matches the demand. However, previous AL methods assume that both the labeled and unlabeled data follow the same distribution, such a strategy may become ineffective to the DA scenarios where the target data suffer from domain shift. The recently proposed active domain adaptation (ADA) [4, 22, 31] aims to resolve this issue by actively selecting the maximally-informative instances such that the performance of the transferred model can be best boosted with a limited annotation budget.\\n\\nThe key to the success of ADA is to strike a good balance between the highly coupled yet inherently different tasks: active learning and domain adaptation. The real-world target data typically exhibit either of the two characteristics:\"}"}
{"id": "CVPR-2023-580", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"or target-specific. While the former has similar feature distribution with the source data, the latter tends to be the unique part of target domain and deviates greatly from the source distribution [4, 26, 38]. On one hand, to achieve domain adaptation, applying the same adaptation strategy to all target data equally cannot generalize well to scenarios with varying degrees of domain shift. This is particularly true when the gap between the source-like and target-specific data is unknown. On the other hand, in active learning tasks, the samples with a learning difficulty will be more likely to be selected for labeling. Nonetheless, with large domain gap, incorporating such difficult samples in the adaptation task would hamper the learning of the adaptation model, making the training highly unstable. However, despite the impressive progress that has been made, none of the existing works has fully addressed the above issues.\\n\\nIn this work, we propose Divide-And-Adapt (DiaNA), a novel ADA framework that can scale to large variations of domain gaps while achieving cost-effective data labeling with a significant performance boost for domain adaptation. Our key observation is that customized learning strategies are vital for target data with different characteristics. In particular, DiaNA divides the target data into four sub-sets with different levels of transferable properties (see Figure 1), each of which is handled with a customized learning strategy. Unlike traditional AL methods that would simply label the most uncertain data [29, 30, 37], we propose to withhold the most challenging samples (Figure 1 category (4)) for training the domain adaption models. Instead, the selected samples for active annotation would maintain a proper stimulus for the source model, providing informative domain knowledge without jeopardizing the training stability. The subdivision of target data is dynamically updated as the domain disparity is gradually mitigated with more labeled data. Hence, the previous challenging samples could be classified as transferable in the later stage and exploited in the network training.\\n\\nWe introduce a novel protocol for subdividing the target samples for customized learning. In addition to the uncertainty of model prediction, we advocate that the consistency with the learned prior distribution, i.e. the domainness, is another key criterion for active domain adaptation [4, 26]. To this end, we divide the target data into four categories as shown in Figure 1 according to the domainness and uncertainty of the instances. We further propose that the samples with 1) being uncertain to the model and 2) having inconsistent prediction with the label of its closest category prototype in the learned feature space (i.e. high domainness) are the most \\\"profitable\\\" instances for bringing informative knowledge of target domain if annotated. Thereby, we identify the uncertain inconsistent samples for labeling while applying tailored learning strategies for the remaining categories to boost the selectivity of the sampling.\\n\\nTo avoid heuristic thresholding for data subdivision, we propose an automatic data sampling mechanism based on Gaussian mixture model (GMM). In particular, we propose an informativeness function that incorporates the domainness and uncertainty in a unified scoring system. The computed informativeness score of the labeled data is used to train a four-component GMM model, which is then applied to sample the unlabeled target data into four categories. We evaluate DiaNA over a large variety of domain shift scenarios on DomainNet [21], Office-Home [28] and CIFAR-10 [11]. Furthermore, the proposed sampling strategy of DiaNA can be generalized to various domain adaptation problems with different supervision settings, including unsupervised domain adaptation (UDA), semi-supervised domain adaptation (SSDA), and source-free domain adaptation (SFDA).\\n\\nWe summarize our contributions as follows:\\n\\n\u2022 A general \\\"divide-and-adapt\\\" framework, coded DiaNA, for active domain adaptation that can handle diversified degrees of domain gaps while being able to generalize to different domain adaptation problems, including UDA, SSDA, and SFDA.\\n\\n\u2022 A new target data partition strategy based on domainness and uncertainty that enables stratified learning to achieve more stable training, superior adaptation performance, and better generality.\\n\\n\u2022 A novel informativeness scoring system and the corresponding sampling paradigm based on GMM model for automatic data partitioning.\\n\\n\u2022 New state-of-the-art performance over the mainstream public datasets in the task of active domain adaptation.\\n\\n2. Related Work\\n\\nDomain adaptation (DA). Most of the prior methods involving domain adaptation follow the unsupervised domain adaptation (UDA) paradigm that only unlabeled data is accessible in the target domain. Early UDA approaches [16, 18, 32] utilized maximum mean discrepancy (MMD) to minimize the discrepancy of features from different domains to address the domain shift, while recent adversarial learning based methods [5, 17] have become popular solutions for UDA. Despite effectiveness, UDA is still significantly outperformed by its supervised variant as indicated in [4, 14, 27]. Semi-supervised domain adaptation (SSDA) [13, 24, 35] allows a few target instances to be labeled and generally achieves improved performance. However, SSDA assumes that the labeled instances are passively provided in advance, depriving the choice of informative samples beneficial to the model. In this work, we propose an active domain adaption method to select the most informative samples, which can be incorporated into other DA methods to further boost their performance.\"}"}
{"id": "CVPR-2023-580", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2. We propose a general \\\"divide-and-adapt\\\" framework, named DiaNA, for active domain adaptation. (a) A new target data partition strategy is presented to divide target data into four categories via building an informativeness scoring function that incorporates both domainness and uncertainty metrics. Besides, an automatic data partitioning function based on a learned four-component GMM model is applied to adaptively separate four sample categories from unlabeled target data. (b) To achieve customized learning, different auxiliary techniques are integrated into model fine-tuning w.r.t the four categories of unlabeled target data.\\n\\nActive Learning (AL). Active learning is proposed to select a maximally-informative subset of unlabeled data for annotation via a query function, in an effort to best improve the model performance with a limited annotation budget. There exist several efforts to tackle the challenges involving active learning. For example, the uncertainty-based AL methods mainly focus on designing query functions based on prediction confidence [30], entropy [9, 29], or margin [10, 23] of the posterior probabilities. On the other hand, the diversity-based approaches [6, 19, 25] concentrate on selecting samples that can well represent the entire dataset. Meanwhile, expected model change-based methods [3, 15] aim to query the instances that would lead to a significant change to the current model. Recently proposed active learning approaches attain better performance by utilizing hybrid strategies which taking multiple metrics into consideration [1, 20]. Notwithstanding, the efficacy of previous AL resources may falter in DA scenarios as their selection strategy fails to meticulously consider the implications of the domain gap.\\n\\nActive Domain Adaptation (ADA). Early ADA researches [4, 26] propose to measure the uncertainty and domainness of each target instance via a domain discriminator with adversarial training. CLUE [22] presents an entropy-weighted clustering algorithm to query uncertain and diverse samples in the target domain. Recently, SDM [33] is proposed to optimize a margin loss function for exploring target instances similar to potential hard samples in the source domain. Nevertheless, the majority of existing ADA methods deliberately design hand-crafted query functions to evaluate sample's annotation value and apply the same adaptation strategy to all target data equally [4, 26, 31]. The rigid criteria make them easily overfit to certain domain adaption scenarios, which limits the generalization of the method. In contrast, we propose to integrate uncertainty and domainness metrics within a unified scoring function to select informative samples. Moreover, we apply tailored learning strategies for target data with different characteristics, constructing an effective framework capable of generalizing across large variations of domain shifts.\\n\\n3. Divide-and-Adapt Framework\\n\\nProblem formulation. Active domain adaptation aims at seeking an optimal model for a target domain when given labeled source data \\\\( S = \\\\{ (x_s, y_s) \\\\} \\\\) as well as unlabeled target data \\\\( U = \\\\{ x_u \\\\} \\\\), assisted by the iteratively queried labeled data \\\\( T = \\\\{ (x_t, y_t) \\\\} \\\\) of the target domain. Here, \\\\( S, U \\\\), and \\\\( T \\\\) share the same label space over \\\\( C \\\\) categories. Initially, \\\\( T \\\\) is an empty set. The model is iteratively trained using \\\\( S, T, \\\\) and \\\\( U \\\\) for \\\\( R \\\\) active learning loops until a given annotation budget \\\\( B \\\\) is reached. In each active learning loop, \\\\( b = B/R \\\\) samples from \\\\( U \\\\) would be selected, labeled by human experts, and then moved into \\\\( T \\\\). The proposed Divide-and-Adapt framework consists of a feature extractor and a classifier. Our goal is to design a query function to identify informative samples to annotate and utilize limited amount of labeled samples to best enhance the classification performance for the target domain.\\n\\nOverview. In this paper, we propose Divide-And-Adapt, coded DiaNA, to tackle the problem of active domain adaptation. In detail, we first propose to design an informativeness function for subdividing the target samples into four categories, one of which is the informative target samples used for actively annotating. Such a function is a unified scoring system that incorporates the domainness and the uncertainty. To avoid heuristic thresholding for data subdivision, we propose an automatic data sampling mechanism to divide the unlabeled target data into four categories.\"}"}
{"id": "CVPR-2023-580", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3. Informativeness Scoring Mechanism\\n\\nFollowing previous ADA works [4, 26, 31], we aim to search for the target instances with high domainness and uncertainty. To achieve this goal, we propose to first estimate category-wise centroids based on the labeled samples, and then define a similarity-based label for each unlabeled target sample by computing its top-k feature similarity with the categorical centroids. Finally, we integrate both the domainness and the uncertainty metrics into an informativeness function, which is formulated as the consistency between model prediction and similarity-based label.\\n\\nCategorical centroids. We propose to average the features of labeled samples to estimate the category-specific data distribution, i.e., category prototype. Here, we formulate the centroid with respect to the $c$-th category as follows,\\n\\n$$ A_c = \\\\frac{\\\\sum_{(x,y) \\\\in S_1} y = c} \\\\sum_{(x,y) \\\\in S_1} y = c \\\\cdot G(x), \\\\hspace{1cm}(1) $$\\n\\nwhere $\\\\{\\\\cdot\\\\}$ is an indicator function, and $G(x)$ is a feature extractor that outputs the sample feature of $x$. Note that, as the active learning loops proceed, labeled target samples would be incorporated into the calculation of categorical centroids to mitigate the impact of distribution change.\\n\\nSimilarity-based data label. As introduced in the works [7, 13], samples share more top-k indices in their respective lists of rank-ordered feature elements would have a higher probability of being the same category. To obtain the similarity-based label for each target instance, we first measure pairwise similarity of the indices of the sorted feature elements based on the magnitude. Then, we can formulate a similarity-based label for a sample $x$ from $U$ as follows,\\n\\n$$ \\\\hat{y}(x) = \\\\arg\\\\max_{1 \\\\leq c \\\\leq C} \\\\text{IoU}(\\\\text{top}_k(G(x)), \\\\text{top}_k(A_c)), \\\\hspace{1cm}(2) $$\\n\\nwhere $\\\\text{top}_k(\\\\cdot)$ computes the top-k feature element indices ranked according to their magnitudes. In addition, $\\\\text{IoU}(\\\\cdot, \\\\cdot)$ denotes an Intersection-over-Union function, which returns the extent of overlap of the two respective index lists. We set the value of $k$ to be significantly smaller than the full dimension of the feature vector. In this way, the function $\\\\text{top}_k(\\\\cdot)$ only extracts the principle components of the feature of sample. Therefore, the IoU function in Eq.2 is equivalent to measuring pairwise image sample similarity under a low-resolution condition. In ADA tasks, the training of model is inevitably dominated by the source domain especially in the early stage [33]. Therefore, source-like target samples that are similar to the source domain would naturally have more accurate representation than the target-specific ones that are distinct from the source. Under the low-resolution condition, i.e., $k$ set to be small, source-like samples tend to have the same similarity-based label as the model predicted class thanks to their reliable and discriminative features extracted by the model. In contrast, target-specific samples are prone to produce inconsistent results since they are typically underfitted by the current model as shown in Figure 3. Based on the analysis above, we utilize the consistency of the model predicted class and similarity-based label to evaluate the domainness of each target sample. Detailed theoretical and experimental supports are demonstrated in our supplementary.\\n\\nInformativeness function. To explore the most informative target samples, we integrate the domainness and uncertainty into a unified informativeness function (InfoF). The informativeness score for a sample $x$ from unlabeled target domain can be formulated as follows,\\n\\n$$ \\\\ell_u(x) = -C \\\\sum_{c=1}^{C} \\\\{c = \\\\hat{y}(x)\\\\} \\\\cdot \\\\log P_c(x), \\\\hspace{1cm}(3) $$\\n\\nwhere $P(x)$ denotes the probabilistic prediction of a sample $x$ from the network model and $P_c(x)$ is the $c$-th element of the vector $P(x)$. According to Eq. 3, we can divide unlabeled target samples into two subsets depending on whether the model predicted class and the similarity-based label are identical: consistent and inconsistent subsets, while both sets have confident samples and uncertain samples depending on whether the predicted probability is greater than a given confidence threshold. We name these four categories of unlabeled target data as confident-consistent (CC), uncertain-consistent (UC), uncertain-inconsistent (UI) and...\"}"}
