{"id": "CVPR-2023-49", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Algorithm 1\\n\\nProposed Approach PETAL\\n\\nInput:\\n\\nTraining dataset $X = \\\\{x_n, y_n\\\\}_{n=1}^{N}$\\n\\nTest domain data $U = \\\\{x_d^m\\\\}_{m=1}^{M}$\\n\\nOutput:\\n\\nPrediction $Y_d$\\n\\nTraining:\\n\\n1: Compute $q(\\\\theta) \\\\approx p(\\\\theta | X)$\\n\\nContinual Adaptation:\\n\\n2: Initialize time step $t = 0$, prediction set $Y_d = \\\\emptyset$\\n\\n3: Initialize student model $\\\\theta_0 = \\\\max \\\\theta \\\\log q(\\\\theta)$\\n\\n4: Initialize teacher model $\\\\theta'_0 = \\\\theta_0$\\n\\n5: for $d = 1, \\\\ldots, D$ do\\n\\n6: for each batch $B \\\\in U_d$ do\\n\\n7: $\\\\theta'_{t+1}, \\\\theta_{t+1}, B_y = \\\\text{Adapt}(\\\\theta'_t, \\\\theta_t, \\\\theta_0, B, q(\\\\theta), t)$\\n\\n8: $Y_d = Y_d \\\\cup B_y$\\n\\n9: $t = t + 1$\\n\\n10: end for\\n\\n11: end for\\n\\n4. Related Work\\n\\n4.1. Unsupervised Domain Adaptation\\n\\nThe goal of unsupervised domain adaptation (UDA) [6, 24, 30, 40] is to enhance the performance of the learning model when there is a change in distribution between the training data domain and the test data domain. UDA approaches often assume that the source and (unlabeled) target domain data are accessible simultaneously. Most existing methods address UDA by ensuring that the feature distributions [6, 24, 37] or the input spaces [12, 44] of the source and the target domains are brought closer.\\n\\n4.2. Test-Time Adaptation\\n\\nSome works also refer to TTA as source-free domain adaptation. Recent works explore source-free domain [18, 20, 23] setting in which training data is unavailable and only unlabeled data is available during adaptation. Test entropy minimization (TENT) [38] starts from a source pre-trained model and updates only the batch-norm (BN) parameters by minimizing entropy in test predictions. [34] address TTA by updating the source domain BN statistics using test input statistics. Continual Test-Time Adaptation (CoTTA) [41] addresses online lifelong TTA by employing weight averaging and augmentation averaging, and random parameter restoration back to source pre-trained model parameters. [8] adapts to continually changing target domains by utilizing a normalization layer to handle the out-of-distribution examples and balanced reservoir sampling to store the simulated i.i.d. data in the memory. It would be an interesting future work to extend PETAL for the temporally correlated test stream setting proposed by [8].\\n\\nEATA [29] is another related work that looks at preventing forgetting in the context of TTA; however, EATA mainly focuses on preventing the forgetting of the source task model and is not designed to handle forgetting in a lifelong TTA setting. Our work PETAL is a principled probabilistic approach for lifelong test-time adaptation that uses an approximate posterior during test-time adaptation obtained from source domain data. PETAL also offers a probabilistic perspective and justification to CoTTA which arises a special case of PETAL.\\n\\nBayesian Adaptation for Covariate Shift (BACS) [46] proposes a Bayesian perspective for TENT, which naturally gives rise to the entropy term along with a regularizer that captures knowledge from posterior density obtained from training data. However, BACS only addresses standard TTA setting, and regularized entropy minimization lacks the ability to handle error accumulation and catastrophic forgetting encountered in lifelong TTA.\\n\\nAlgorithm 2\\n\\nAdapt\\n\\nInput:\\n\\n$\\\\theta'_t, \\\\theta_t, \\\\theta_0, B, q(\\\\theta)$\\n\\nRequire:\\n\\nNumber of augmentations $K$; learning rate $\\\\eta$; Threshold for confident predictions $\\\\tau$; Confidence function $C$; Cross-entropy weight $\\\\overline{\\\\lambda}$; Quantile of FIM $\\\\delta$; Augmentation function $\\\\alpha$; Smoothing factor $\\\\pi$\\n\\nOutput:\\n\\n$\\\\theta'_{t+1}, \\\\theta_{t+1}, B_y$\\n\\n1: Initialize: $H = 0$, $B_y = \\\\emptyset$\\n\\n2: for each test input $\\\\bar{x} \\\\in B$ do\\n\\n3: Teacher model prediction: $\\\\hat{y}' = p(y | \\\\bar{x}, \\\\theta'_t)$\\n\\n4: Augmented Average: $\\\\tilde{y}' = \\\\frac{1}{K} \\\\sum_{i=1}^{K} p(y | \\\\alpha_i(\\\\bar{x}), \\\\theta'_t)$\\n\\n5: Augment based on domain gap: $y' = (\\\\hat{y}', \\\\text{if } C(p(y | \\\\bar{x}, \\\\theta_0) \\\\geq \\\\tau))$, $\\\\tilde{y}'$, otherwise.\\n\\n6: Using student model, predict: $y = p(y | x, \\\\theta)$\\n\\n7: Update: $H = H + H_{xe}(y', y | \\\\bar{x})$\\n\\n8: $B_y = B_y \\\\cup \\\\{y'\\\\}$\\n\\n9: end for\\n\\n10: Compute: $L = \\\\log q(\\\\theta) - \\\\overline{\\\\lambda} \\\\frac{|B|}{|B|} H$\\n\\n11: Adapt student model: $\\\\theta_{t+1} = \\\\theta_t + \\\\eta \\\\nabla_{\\\\theta} L$\\n\\n12: Update teacher model: $\\\\theta'_{t+1} = \\\\pi \\\\theta'_t + (1 - \\\\pi) \\\\theta_{t+1}$\\n\\n13: Compute FIM: $F = \\\\text{Diag}(\\\\nabla_{\\\\theta} L (\\\\nabla_{\\\\theta} L)^T)$\\n\\n14: Compute mask for resetting: $\\\\gamma = \\\\text{quantile}(F, \\\\delta)$, $m_p = (1, \\\\text{if } F_p < \\\\gamma_0, \\\\text{otherwise})_p$.\\n\\n15: Reset updated student model back to source model: $\\\\theta_{t+1} = m \\\\odot \\\\theta_0 + (1 - m) \\\\odot \\\\theta_{t+1}$\\n\\nthe forgetting of the source task model and is not designed to handle forgetting in a lifelong TTA setting. Our work PETAL is a principled probabilistic approach for lifelong test-time adaptation that uses an approximate posterior during test-time adaptation obtained from source domain data. PETAL also offers a probabilistic perspective and justification to CoTTA which arises a special case of PETAL.\\n\\nBayesian Adaptation for Covariate Shift (BACS) [46] proposes a Bayesian perspective for TENT, which naturally gives rise to the entropy term along with a regularizer that captures knowledge from posterior density obtained from training data. However, BACS only addresses standard TTA setting, and regularized entropy minimization lacks the ability to handle error accumulation and catastrophic forgetting encountered in lifelong TTA.\"}"}
{"id": "CVPR-2023-49", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1. Experimental results for CIFAR10-to-CIFAR10C online lifelong test-time adaptation task. The numbers denote the classification error (%) obtained with the highest corruption of severity level 5. TENT-online uses domain information, denoted using +.\\n\\n4.3. Continual Learning\\nThe objective of Continual Learning (CL) is to learn from a sequential series of tasks, enabling the model to retain previously acquired knowledge while learning a new task, preventing catastrophic forgetting [27, 31, 33]. Elastic weight consolidation (EWC) [15] is a regularization-based technique that penalizes parameter changes having a significant impact on prediction. [22] proposed learning without forgetting (LwF), which preserves knowledge of previous tasks using knowledge distillation. Gradient episodic memory (GEM) [25] maintains a limited number of samples to retrain while constraining fresh task updates from interfering with prior task knowledge. [1, 39] address the continual semi-supervised learning problem where continually arriving tasks consist of labeled and unlabeled data.\\n\\n5. Experiments\\nWe thoroughly evaluate PETAL and compare it to other state-of-the-art approaches on image classification lifelong test-time adaptation benchmark tasks: CIFAR10-to-CIFAR10C, CIFAR100-to-CIFAR100C, ImageNet-to-ImageNetC, and ImageNet-to-Imagenet3DCC.\\n\\n5.1. Benchmark Datasets\\n[11] developed CIFAR10C, CIFAR100C, and ImageNetC datasets to serve as benchmarks for the robustness of classification models. In each dataset, there are 15 different types of corruption and five different levels of severity. These corruptions are applied to test images of original CIFAR10 and CIFAR100 [17] datasets and validation images of original ImageNet [5] dataset. Further, we experiment with Imagenet 3D Common Corruptions (Imagenet3DCC) dataset, recently proposed by [14], which utilizes the geometry of the scene in transformations, leading to more realistic corruptions. Imagenet3DCC dataset consists of 12 different types of corruptions, each with five levels of severity. Refer to Appendix for details.\\n\\nIn online lifelong TTA, we begin with a network trained on CIFAR10, CIFAR100, and ImageNet clean training set for the respective experiments. At the time of testing, the model gets corrupted images online. Following CoTTA, we continually adjust the source pre-trained model to each corruption type as they sequentially arrive, as opposed to conventional TTA in which the pre-trained model is separately adapted to each corruption type. We evaluate the model using online predictions obtained immediately as the data is encountered. We follow the online lifelong test-time adaptation setting for all the experiments. For ImageNet-to-ImageNetC experiments, we evaluate using 10 different sequences of corruptions.\\n\\n5.2. Model Architectures and Hyperparameters\\nFollowing TENT [38] and CoTTA [41], we adopt pre-trained WideResNet-28 [45] model for CIFAR10-to-CIFAR10C, pre-trained ResNeXt-29 [43] model for CIFAR100-to-CIFAR100C, and standard pre-trained ResNet-50 model for both ImageNet-to-ImagenetC and ImageNet-to-Imagenet3DCC experiments from RobustBench [4].\\n\\nWe utilize SW AG-D [26] to approximate the posterior density from the source domain training data. SW AG-D approximates the posterior using a Gaussian distribution with diagonal covariance from the SGD trajectory. Before adapting the model, we initialize it with the maximum a posteriori (MAP) of the approximate posterior that corresponds to the solution obtained by Stochastic Weight Averaging [13]. This is effectively the source domain pre-trained model. We update all the trainable parameters in all experiments. We use $K = 32$ number of augmentations. We adopt the same augmentation confidence threshold described in [41]. For FIM based parameter restoration, we set the quantile value $\\\\delta = 0.03$. We refer the readers to the Appendix for more details on the hyperparameters.\\n\\n5.3. Baselines and Compared Approaches\\nTo evaluate the efficacy of PETAL, we compare the PETAL with CoTTA and five other methods in online lifelong test-time adaptation.\"}"}
{"id": "CVPR-2023-49", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2. Experimental results for CIFAR100-to-CIFAR100C online lifelong test-time adaptation task. The numbers denote the classification error rate (%) obtained with the highest corruption of severity level 5.\\n\\n| Method       | Source | BN Adapt | Pseudo-label | TENT-continual | CoTTA |\\n|--------------|--------|----------|--------------|----------------|-------|\\n|              |        | 42.14    | 40.66        | 42.73          | 37.20 |\\n|              |        | 27.64    | 41.82        | 29.72          | 35.80 |\\n|              |        | 34.88    | 35.03        | 41.50          | 41.70 |\\n|              |        | 26.52    | 30.31        | 35.66          | 35.90 |\\n| Mean         |        | 35.37    | 35.37        | 35.37          | 35.40 |\\n\\nAdapt [21, 34], the network parameters are kept frozen, and only Batch Normalization statistics are adapted to produce predictions for test inputs. Pseudo-label updates the BatchNorm trainable parameters with hard pseudo-labels [19]. TENT-online denotes the TENT [38] approach in this setting, but it has access to extra information about the change in the domain and, thus, resets itself to the original pre-trained model upon encountering test inputs from the new domain and adapts afresh. But this additional knowledge is unavailable in real-life scenarios. TENT-continual has no extra information about domain change. CoTTA [41] uses weight averaging and augmentation averaging, along with randomly restoring parameters to the original pre-trained model. However, it lacks explicit uncertainty modeling and data-driven parameter restoration.\\n\\n5.4. Evaluation Metrics\\n\\nWe evaluate our model using the error rate in predictions. To evaluate the uncertainty estimation, we use negative log-likelihood (NLL) and Brier score [2]. Both NLL and Brier are proper scoring rules [7], and they are minimized if and only if the predicted distribution becomes identical to the actual distribution. In Table 1, 2 and 4, the number within brackets is the standard deviation over 5 runs. Refer to the Appendix for more details on evaluation metrics.\\n\\nTable 3. CIFAR10-to-CIFAR10C results for gradually changing severity level before changing corruption types. The numbers are averaged over all 15 corruption types. The number after \\\\(\\\\pm\\\\) is the standard deviation over 10 random corruption sequences. Our method surpasses all baselines in the depicted settings.\\n\\n| Metric     | Method       | Source | BN Adapt | TENT | CoTTA |\\n|------------|--------------|--------|----------|------|-------|\\n| Error (%)  |              | 23.94  | 13.54    | 29.46| 10.40 |\\n|            |              | \u00b10.22  | \u00b10.23    |      | \u00b10.23 |\\n| Brier      |              | 0.408  | 0.222    | 0.575| 0.159 |\\n|            |              | \u00b10.003 | \u00b10.004   |      | \u00b10.004|\\n\\n5.5. CIFAR10-to-CIFAR10C Results\\n\\nIn Table 1, we observe that directly using the pre-trained model (Source) leads to poor performance with an average error rate of 43.51%, suggesting the necessity of adaptation. Adapting the Batch Normalization (BN) statistics improves the average error rate to 20.44%. Using hard pseudo-labels and updating only the BN parameters further improves the performance to 19.8%. TENT-online reduces the error rate to 18.58% using extra information about domain change, but access to such information is mostly unavailable in real-world scenarios. As expected, the error rate of TENT-continual increases to 20.7% without access to domain change information. Further, CoTTA improves the average error rate to 16.29%. Our proposed approach consistently outperforms other approaches for most individual corruption types, reducing the average error rate to 15.95%. Moreover, our proposed approach demonstrates no performance degradation in the long term.\\n\\nTo investigate the contribution of FIM based parameter restore, we show the results of our approach with stochastic restore in place of FIM based restore, denoted using S-Res. We observe that FIM based restore performs better than S-Res for most of the corruption types, highlighting the effectiveness of FIM based restore. Further, the improved performance of PETAL (S-Res) and PETAL (FIM) over various baselines, including CoTTA which is specifically designed for continual TTA, demonstrates the effectiveness of our probabilistic framework where the source model's posterior induces a regularizer and the data-driven resetting helps make an informed selection of weights to reset/keep. Moreover, the contribution of the regularizer term (induced by the source model's posterior) is evident from the superior performance of PETAL over CoTTA, since CoTTA is a special case of PETAL without the regularizer term.\\n\\nGradually changing corruptions:\\n\\nFollowing [41], we evaluate PETAL in the setting where the severity of corruption changes gradually before the change in corruption type. When the corruption type changes, the severity level is lowest, and thus, domain shift is gradual. In addition, distribution shifts within each corruption type are also gradual. Refer to the Appendix for details.\\n\\nWe report the average error and average Brier score over 10 randomly shuffled orders of corruptions. We can observe in Table 3 that our approach PETAL performs better than other approaches in terms of error and Brier score.\"}"}
{"id": "CVPR-2023-49", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"**Table 4. CIFAR100-to-CIFAR100C results with the most severe level of corruption, 5, averaged over all corruption types. Our method surpasses all baselines in terms of NLL and Brier uncertainty estimation measures.**\\n\\n| Metric   | Method   | Source  | BN Adapt | TENT     | CoTTA    | PETAL (FIM) |\\n|----------|----------|---------|----------|----------|----------|-------------|\\n|          |          |         |          |          |          | NLL (SD)    |\\n| NLL      |          |         | 2.4945   | 1.3937   | 7.3789   | 1.2767 (0.0006) |\\n| Brier    |          |         | 0.6704   | 0.4744   | 1.1015   | 0.4430 (0.0003) |\\n\\n**5.6. CIFAR100-to-CIFAR100C Results**\\n\\nTo illustrate the efficacy of the proposed approach, we conduct an evaluation on the more challenging CIFAR100-to-CIFAR100C task. In Table 2, we compare the results with Source, BN Adapt, Pseudo-label, and TENT-continual approaches. We observe that TENT-continual performs better initially, but as new domains arrive continually, the performance degrades drastically in the long term. With an average error rate of 31.46%, our proposed approach PETAL (FIM) consistently outperforms the other approaches.\\n\\nTo measure the ability of uncertainty estimation of our approach, we compare with the other approaches in Table 4 in terms of NLL and Brier score. We obtain both NLL and Brier score for corruption with a severity level of 5 and average over all corruption types. Our approach performs better than all other approaches in terms of average NLL and average Brier, demonstrating the ability of our approach to improve the uncertainty estimation. Moreover, the FIM based restore outperforms stochastic restore for most corruption types, illustrating the utility of data-driven resetting.\\n\\n**Figure 2. ImageNet-to-ImageNetC results averaged over 10 different corruption orders with level 5 corruption severity.**\\n\\n**5.7. ImageNet-to-ImageNetC Results**\\n\\nIn Table 5, we investigate the performance of our proposed approach for ImageNet-to-ImageNetC task with 10 different sequences of corruption. We obtain the performance scores by averaging over all corruption types and all corruption orders. In terms of average error, average NLL, and average Brier, our approach performs better than the other approaches. In Fig. 2, we compare the performance by averaging over 10 different corruption orders in terms of error rate and Brier score. For most corruption types, our approach performs better than other existing approaches.\\n\\n**Table 5. ImageNet-to-ImageNetC results averaged over all corruption types and over 10 diverse corruption orders (highest corruption severity level 5).**\\n\\n| Metric   | Method   | Source  | BN Adapt | TENT     | CoTTA    | PETAL (FIM) |\\n|----------|----------|---------|----------|----------|----------|-------------|\\n|          |          |         |          |          |          | Error (%)   |\\n| Error (%)|          |         | 82.35    | 72.07    | 66.52    | 63.18       |\\n| NLL      |          |         | 5.0701   | 3.9956   | 3.6076   | 3.3425      |\\n| Brier    |          |         | 0.9459   | 0.8345   | 0.8205   | 0.7681      |\\n\\n**5.8. ImageNet-to-ImageNet3DCC Results**\\n\\nFor ImageNet-to-ImageNet3DCC dataset, we experiment with 10 different random sequences of corruptions. We provide the results in Table 6 by averaging over 10 random sequences of corruptions and 12 corruption types at severity level 5. PETAL consistently outperforms all other approaches in terms of error rate, NLL, and Brier score.\\n\\n**Table 6. ImageNet-to-ImageNet3DCC results averaged over all corruption types and over 10 diverse corruption orders (highest corruption severity level 5).**\\n\\n| Metric   | Method   | Source  | BN Adapt | TENT     | CoTTA    | PETAL (FIM) |\\n|----------|----------|---------|----------|----------|----------|-------------|\\n|          |          |         |          |          |          | Error (%)   |\\n| Error (%)|          |         | 69.21    | 67.32    | 95.93    | 59.91       |\\n| NLL      |          |         | 5.0701   | 3.9956   | 3.6076   | 3.3425      |\\n| Brier    |          |         | 3.9664   | 3.7163   | 19.0408  | 3.2636      |\\n\\n**6. Conclusion**\\n\\nWe proposed a probabilistic framework for lifelong TTA using a partly data-driven prior. Addressing the problem via the probabilistic perspective naturally gives rise to the student-teacher framework along with a regularizer that captures the source domain knowledge. In lifelong TTA, we have demonstrated that our principled use of an approximate training posterior surpasses prior heuristic approaches. Our proposed approach also provides more reliable uncertainty estimates demonstrated with better NLL and Brier score. Further, we developed a Fisher information matrix based parameter restoration, which is driven by the data to improve upon existing stochastic restore. In terms of error rate, NLL and Brier score, PETAL yields state-of-the-art results across CIFAR10-to-CIFAR10C, CIFAR100-to-CIFAR100C, ImageNet-to-ImageNetC, and ImageNet-to-ImageNet3DCC benchmark tasks.\\n\\n**Acknowledgments:** The authors acknowledge support from the Qualcomm Innovation Fellowship and travel grant support from the Research-I Foundation at IIT Kanpur.\"}"}
{"id": "CVPR-2023-49", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[1] Dhanajit Brahma, Vinay Kumar Verma, and Piyush Rai. Hypernetworks for continual semi-supervised learning. In International Workshop on Continual Semi-Supervised Learning, IJCAI, 2021.\\n\\n[2] Glenn W Brier et al. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):1\u20133, 1950.\\n\\n[3] Chaoqi Chen, Weiping Xie, Wenbing Huang, Yu Rong, Xinghao Ding, Yue Huang, Tingyang Xu, and Junzhou Huang. Progressive feature alignment for unsupervised domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 627\u2013636, 2019.\\n\\n[4] Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.\\n\\n[5] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. IEEE, 2009.\\n\\n[6] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International conference on machine learning, pages 1180\u20131189. PMLR, 2015.\\n\\n[7] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359\u2013378, 2007.\\n\\n[8] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Robust continual test-time adaptation: Instance-aware bn and prediction-balanced memory. arXiv preprint arXiv:2208.05117, 2022.\\n\\n[9] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004.\\n\\n[10] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International conference on machine learning, pages 1321\u20131330. PMLR, 2017.\\n\\n[11] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019.\\n\\n[12] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In International conference on machine learning, pages 1989\u20131998. Pmlr, 2018.\\n\\n[13] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages 876\u2013885. Association For Uncertainty in Artificial Intelligence (AUAI), 2018.\\n\\n[14] O\u02d8guzhan Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir. 3d common corruptions and data augmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18963\u201318974, 2022.\\n\\n[15] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521\u20133526, 2017.\\n\\n[16] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, pages 5637\u20135664. PMLR, 2021.\\n\\n[17] Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.\\n\\n[18] Jogendra Nath Kundu, Naveen Venkat, R Venkatesh Babu, et al. Universal source-free domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4544\u20134553, 2020.\\n\\n[19] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, page 896, 2013.\\n\\n[20] Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9641\u20139650, 2020.\\n\\n[21] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical domain adaptation. arXiv preprint arXiv:1603.04779, 2016.\\n\\n[22] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935\u20132947, 2017.\\n\\n[23] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In International Conference on Machine Learning, pages 6028\u20136039. PMLR, 2020.\\n\\n[24] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97\u2013105. PMLR, 2015.\\n\\n[25] David Lopez-Paz and Marc\u2019Aurelio Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017.\\n\\n[26] Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A simple baseline for bayesian uncertainty in deep learning. Advances in Neural Information Processing Systems, 32, 2019.\\n\\n[27] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of learning and motivation, volume 24, pages 109\u2013165. Elsevier, 1989.\"}"}
{"id": "CVPR-2023-49", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and Jan Hendrik Metzen. Test-time adaptation to distribution shift by confidence maximization and input transformation. arXiv preprint arXiv:2106.14999, 2021.\\n\\nShuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In International Conference on Machine Learning. PMLR, 2022.\\n\\nSinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE transactions on neural networks, 22(2):199\u2013210, 2010.\\n\\nGerman I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, and Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural Networks, 113:54\u201371, 2019.\\n\\nViraj Prabhu, Shivam Khare, Deeksha Kartik, and Judy Hoffman. Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8558\u20138567, 2021.\\n\\nRoger Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and forgetting functions. Psychological review, 97(2):285, 1990.\\n\\nSteffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539\u201311551, 2020.\\n\\nYu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229\u20139248. PMLR, 2020.\\n\\nRohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig Schmidt. Measuring robustness to natural distribution shifts in image classification. Advances in Neural Information Processing Systems, 33:18583\u201318599, 2020.\\n\\nYi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker. Learning to adapt structured output space for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7472\u20137481, 2018.\\n\\nDequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021.\\n\\nLiyuan Wang, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, and Jun Zhu. Ordisco: Effective and efficient usage of incremental unlabeled data for semi-supervised continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5383\u20135392, 2021.\\n\\nMei Wang and Weihong Deng. Deep visual domain adaptation: A survey. Neurocomputing, 312:135\u2013153, 2018.\\n\\nQin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022.\\n\\nQizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student improves imagenet classification. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10687\u201310698, 2020.\\n\\nSaining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1492\u20131500, 2017.\\n\\nYanchao Yang and Stefano Soatto. Fda: Fourier domain adaptation for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4085\u20134095, 2020.\\n\\nSergey Zagoruyko and Nikos Komodakis. Wide residual networks. In British Machine Vision Conference 2016. British Machine Vision Association, 2016.\\n\\nAurick Zhou and Sergey Levine. Training on test data with bayesian adaptation for covariate shift. NeurIPS, 2021.\"}"}
{"id": "CVPR-2023-49", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Probabilistic Framework for Lifelong Test-Time Adaptation\\n\\nDhanajit Brahma\\nIndian Institute of Technology Kanpur\\ndhanajit@cse.iitk.ac.in\\n\\nPiyush Rai\\nIndian Institute of Technology Kanpur\\npiyush@cse.iitk.ac.in\\n\\nAbstract\\nTest-time adaptation (TTA) is the problem of updating a pre-trained source model at inference time given test input(s) from a different target domain. Most existing TTA approaches assume the setting in which the target domain is stationary, i.e., all the test inputs come from a single target domain. However, in many practical settings, the test input distribution might exhibit a lifelong/continual shift over time. Moreover, existing TTA approaches also lack the ability to provide reliable uncertainty estimates, which is crucial when distribution shifts occur between the source and target domain. To address these issues, we present PETAL (Probabilistic lifelong Test-time Adaptation with Self-training prior), which solves lifelong TTA using a probabilistic approach, and naturally results in (1) a student-teacher framework, where the teacher model is an exponential moving average of the student model, and (2) regularizing the model updates at inference time using the source model as a regularizer. To prevent model drift in the lifelong/continual TTA setting, we also propose a data-driven parameter restoration technique which contributes to reducing the error accumulation and maintaining the knowledge of recent domains by restoring only the irrelevant parameters. In terms of predictive error rate as well as uncertainty based metrics such as Brier score and negative log-likelihood, our method achieves better results than the current state-of-the-art for online lifelong test-time adaptation across various benchmarks, such as CIFAR-10C, CIFAR-100C, ImageNetC, and ImageNet3DCC datasets. The source code for our approach is accessible at https://github.com/dhanajitb/petal.\\n\\n1. Introduction\\nDeep learning models exhibit excellent performance in settings where the model is evaluated on data from the same distribution as the training data. However, the performance of such models degrades drastically when the distribution of the test inputs at inference time is different from the distribution of the train data (source) [11, 16, 36]. Thus, there is a need to robustify the network to handle such scenarios. A particularly challenging setting is when we do not have any labeled target domain data to finetune the source model, and unsupervised adaptation must happen at test time when the unlabeled test inputs arrive. This problem is known as test-time adaptation (TTA) [28, 35, 38]. Moreover, due to the difficulty of training a single model to be robust to all potential distribution changes at test time, standard fine-tuning is infeasible, and TTA becomes necessary. Another challenge in TTA is that the source domain training data may no longer be available due to privacy/storage requirements, and we only have access to the source pre-trained model. Current approaches addressing the problem of TTA [28, 35, 38, 41] are based on techniques like self-training based pseudo-labeling or entropy minimization in order to enhance performance under distribution shift during testing. One crucial challenge faced by existing TTA methods is that real-world machine learning systems work in non-stationary and continually changing environments. Even though the self-training based approaches perform well when test inputs are from a different domain but all still i.i.d., it has been found that the performance is unstable when target test inputs come from a continually changing environment [32]. Thus, it becomes necessary to perform test-time adaptation in a continual manner. Such a setting is challenging because the continual adaptation of the model in the long term makes it more difficult to preserve knowledge about the source domain. Continually changing test distribution causes pseudo-labels to become noisier and miscalibrated [10] over time, leading to error accumulation [3] which is more likely to occur if early predictions are incorrect. When adapting to new test input, the model tends to forget source domain knowledge, triggering catastrophic forgetting [27, 31, 33]. Moreover, existing TTA methods do not account for model/predictive uncertainty, which can result in miscalibrated predictions. Recently, [41] proposed CoTTA, an approach to address the continual/lifelong TTA setting using a stochastic parameter reset mechanism to prevent forgetting. Their reset mechanism however is based on randomly choosing a subset of weights to reset and is not data-driven. Moreover,\"}"}
{"id": "CVPR-2023-49", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1.\\n\\nLeft: Problem setup of online lifelong TTA. During adaptation on test input, the source domain data is no longer available, and only the model pre-trained on the source domain is provided. Test inputs from different domains arrive continually, and the model has no knowledge about change in the domain.\\n\\nRight: Our proposed probabilistic framework for online lifelong TTA. We obtain a source domain pre-trained model from the posterior density learned using training data from the source domain. The posterior density is used to initialize the student model. A test sample is provided as input to the student model. Using multiple augmentations of a test sample, we obtain augmentation averaged prediction from the teacher model. The loss term consists of log posterior and cross-entropy terms utilizing student and teacher model predictions. We utilize backpropagation to update student model and exponential moving average for teacher model.\\n\\nTo improve upon these challenges of continual/lifelong TTA, we propose a principled, probabilistic framework for lifelong TTA. Our framework (shown in Fig. 1 (Right)) constructs a posterior distribution over the source model weights and a data-dependent prior which results in a self-training based cross-entropy loss, with a regularizer term in the learning objective. This regularizer arises from terms corresponding to the posterior, which incorporates knowledge of source (training) domain data.\\n\\nMoreover, our framework also offers a probabilistic perspective and justification to the recently proposed CoTTA [41] approach, which arises as a special case of our probabilistic framework. In particular, only considering the data-driven prior in our approach without the regularizer term, corresponds to the student-teacher based cross-entropy loss used in CoTTA. Further, to improve upon the stochastic restore used by [41], we present a data-driven parameter restoration based on Fisher Information Matrix (FIM). In terms of improving accuracy and enhancing calibration during distribution shift, our approach surpasses existing approaches in various benchmarks.\\n\\nMain Contributions\\n\\n1. From a probabilistic perspective, we arrive at the student-teacher training framework in our proposed Probabilistic lifelong Test-time Adaptation with self-training prior (PETAL) approach. Inspired from the self-training framework [19, 42], the teacher model is the exponential moving average of the student model, as depicted in Fig. 1 (Right).\\n\\n2. The student-teacher cross-entropy loss with a regularizer term corresponding to posterior of source domain data naturally emerges in the probabilistic formulation.\\n\\n3. We propose a data-driven parameter restoration based on Fisher Information Matrix (FIM) to handle error accumulation and catastrophic forgetting.\"}"}
{"id": "CVPR-2023-49", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In lifelong/continual test-time adaptation, unlabeled test inputs from different target domains \\\\( D \\\\) arrive continually, and, thus, the model can utilize only the data available for the current target domain. Note that there is no information available to the learner about the change in domain. At step \\\\( t \\\\), for a test input \\\\( x_m \\\\), we make predictions using \\\\( p(y_m | x_m, \\\\theta_t) \\\\) as well as adapt the parameters for future steps, i.e., \\\\( \\\\theta_t \\\\rightarrow \\\\theta_{t+1} \\\\). Note that there is a continual domain shift in the data distribution of \\\\( x_m \\\\). Moreover, the model evaluation is performed based on predictions obtained online. Fig. 1 (Left) depicts the online lifelong TTA problem setup.\\n\\n### 2.2. The Underlying Probabilistic Framework\\n\\nIn this section, we review standard probabilistic discriminative models for supervised learning and semi-supervised learning (SSL), which incorporates unlabeled data via a partly data-dependent prior. Then we discuss a formulation of self-training based Bayesian SSL with partly data-driven cross-entropy prior. Further, we describe a modification to this Bayesian SSL formulation to handle the situation when the distribution of unlabeled inputs is different from the labeled inputs (covariate shift).\\n\\nIn Section 3, we describe how this Bayesian SSL formulation can be further extended for our problem, i.e., the lifelong/continual TTA setting where we learn a source model using only labeled data, and then the model has to predict labels of unlabeled test inputs coming from target domains with different distributions.\\n\\n#### Bayesian Supervised Learning\\n\\nThe Bayesian setup for supervised learning typically assumes that we are given labeled data \\\\( D = \\\\{x_n, y_n\\\\}_{n=1}^N \\\\), and we estimate \\\\( \\\\theta \\\\) using its posterior distribution\\n\\n\\\\[\\np(\\\\theta | D) \\\\propto p(\\\\theta) \\\\prod_{n=1}^{N} p(y_n | x_n, \\\\theta).\\n\\\\]\\n\\nGiven a novel test input \\\\( x_{N+1} \\\\), we make predictions using posterior predictive distribution obtained by marginalizing over the posterior distribution\\n\\n\\\\[\\np(y_{N+1} | x_{N+1}) = \\\\int p(y_{N+1} | x_{N+1}, \\\\theta) p(\\\\theta | D) d\\\\theta.\\n\\\\]\\n\\n#### Bayesian Semi-Supervised Learning\\n\\nHere, we are provided with unlabeled data along with some labeled data. We denote the unlabeled data points as \\\\( U = \\\\{x_m\\\\}_{m=1}^M \\\\). To circumvent the inability to use unlabeled data while inferring \\\\( \\\\theta \\\\), one needs to make assumptions about the dependency between distributions of inputs and labels. To this end, [9] proposed a prior that is partly data-dependent via the inputs \\\\( x \\\\):\\n\\n\\\\[\\np(\\\\theta | \\\\psi) \\\\propto p(\\\\theta) \\\\exp(-\\\\lambda H_{\\\\theta,\\\\psi}(y | x))\\n\\\\]\\n\\nwhere \\\\( p(\\\\theta) \\\\) is the prior in Eq. 1, and \\\\( H \\\\) is the conditional entropy of the class label. Here, partly data-dependent prior refers to a prior defined using only the input \\\\( x \\\\) treated as given, not the label \\\\( y \\\\) which is treated as a random variable.\\n\\n#### Bayesian Semi-Supervised Learning with Self-Training\\n\\nThe self-training framework [19, 42] has demonstrated significant success in semi-supervised learning. Our proposed framework is also based on self-training wherein we use an exponential moving average of the parameters \\\\( \\\\theta \\\\) of the student model \\\\( p(y | x, \\\\theta) \\\\) (which is initialized with the source pre-trained model parameters \\\\( \\\\theta_0 \\\\)), and refer to the averaged model as the teacher model \\\\( \\\\theta' \\\\) :\\n\\n\\\\[\\n\\\\theta'_{t+1} = \\\\pi \\\\theta'_{t} + (1 - \\\\pi) \\\\theta_{t+1},\\n\\\\]\\n\\nwhere \\\\( \\\\pi \\\\) is the smoothing factor. For brevity, we will omit the time step index \\\\( t \\\\) from here onwards.\\n\\nIn the semi-supervised setting, the teacher model can be utilized to obtain augmentation-averaged pseudo-labels \\\\( y' \\\\) corresponding to an unlabeled input \\\\( x \\\\). To prevent error accumulation, augmentation is only used when the domain difference is substantial. Defining \\\\( \\\\hat{y}' = p(y | x, \\\\theta') \\\\); \\\\( \\\\tilde{y}' = \\\\frac{1}{K} \\\\sum_{i=1}^{K} p(y | \\\\alpha_i(x), \\\\theta') \\\\), the pseudo-label is defined as\\n\\n\\\\[\\ny' = \\\\begin{cases} \\n\\\\hat{y}', & \\\\text{if } C(p(y | x, \\\\theta_0) \\\\geq \\\\tau) \\\\\\\\\\n\\\\tilde{y}', & \\\\text{otherwise}\\n\\\\end{cases}\\n\\\\]\\n\\nHere, \\\\( K \\\\) is number of times augmentation is applied, \\\\( \\\\alpha_i() \\\\) is augmentation function, \\\\( C() \\\\) gives the confidence of the prediction, and \\\\( \\\\tau \\\\) is threshold for selecting confident predictions. The prediction confidence of current input using source domain pre-trained model \\\\( \\\\theta_0 \\\\) gives us an estimate of the domain difference between source and target domain.\\n\\nUsing these pseudo labels, we formulate the following partly data-driven cross-entropy prior\\n\\n\\\\[\\np(\\\\theta | \\\\psi) \\\\propto p(\\\\theta) \\\\exp(-\\\\lambda H_{xe,\\\\psi}(y', y | x)) = p(\\\\theta) \\\\exp(\\\\lambda E_{x \\\\sim p(x | \\\\psi), y' \\\\sim p(y' | x, \\\\theta')}[\\\\log p(y | x, \\\\theta)])\\n\\\\]\\n\\nHere, \\\\( y = p(y | x, \\\\theta) \\\\) is the prediction of the student model and \\\\( H_{xe} \\\\) is the conditional cross-entropy of labels conditioned on the inputs. This cross-entropy term leverages the knowledge from the teacher model as it is incorporated into the partly data-driven prior.\\n\\n#### Bayesian Semi-Supervised Learning with Unlabeled Data Distribution Shift\\n\\nThe above semi-supervised learning formulation assumes that the unlabeled inputs come from the same distribution as the labeled inputs. To handle the situation when the unlabeled inputs come from a different distribution, we introduce additional generative parameters \\\\( \\\\bar{\\\\psi} \\\\) while using the same conditional model \\\\( p(y | x, \\\\theta) \\\\) parameters \\\\( \\\\theta \\\\) for both distributions. Unlabeled inputs \\\\( \\\\bar{x} \\\\) which come from a different distribution, are assumed to be sampled from the generative model with parameters \\\\( \\\\bar{\\\\psi} \\\\).\\n\\nIncorporating the additional generative parameters \\\\( \\\\bar{\\\\psi} \\\\) in Eq. 3, the prior becomes\\n\\n\\\\[\\np(\\\\theta | \\\\psi, \\\\bar{\\\\psi}) \\\\propto p(\\\\theta) \\\\exp(-\\\\lambda H_{xe,\\\\psi}(y', y | x)) \\\\exp(-\\\\bar{\\\\lambda} H_{xe,\\\\bar{\\\\psi}}(y', y | \\\\bar{x}))\\n\\\\]\"}"}
{"id": "CVPR-2023-49", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The conditional entropies present in Eq. 4 require expectations over the distributions of the (labeled and unlabeled) inputs. Replacing \\\\( p(x | \\\\psi) \\\\) and \\\\( p(\\\\bar{x} | \\\\bar{\\\\psi}) \\\\) with the empirical distributions of \\\\( x \\\\) and \\\\( \\\\bar{x} \\\\), we get\\n\\\\[\\n\\\\begin{align*}\\np(\\\\theta | \\\\psi, \\\\bar{\\\\psi}) \\\\propto & p(\\\\theta) \\\\exp{-\\\\lambda N} \\\\sum_{n=1}^{N} H(x_n, y_n | x_n, \\\\theta) \\\\\\\\ & \\\\exp{-\\\\bar{\\\\lambda} M} \\\\sum_{m=1}^{M} H(x_m, y_m | \\\\bar{x}_m, \\\\theta).\\n\\\\end{align*}\\n\\\\]\\n\\nUsing Eq. 5 as the prior in Eq. 1 and taking logarithm on both sides (ignoring additive normalization constants), the new posterior distribution of the network parameters becomes:\\n\\\\[\\n\\\\begin{align*}\\n\\\\log p(\\\\theta | D, U) = & \\\\log p(\\\\theta) + \\\\sum_{n=1}^{N} \\\\log p(y_n | x_n, \\\\theta) \\\\\\\\ & - \\\\lambda N \\\\sum_{n=1}^{N} H(x_n, y_n | x_n, \\\\theta) \\\\\\\\ & - \\\\bar{\\\\lambda} M \\\\sum_{m=1}^{M} H(x_m, y_m | \\\\bar{x}_m, \\\\theta).\\n\\\\end{align*}\\n\\\\]\\n\\nSince the labeled data is already used in the likelihood term, in the prior we ignore the cross-entropy term for the labeled data by setting \\\\( \\\\lambda = 0 \\\\). Thus, the log-posterior density is simplified to\\n\\\\[\\n\\\\begin{align*}\\n\\\\log p(\\\\theta | D, U) = & \\\\log p(\\\\theta) + \\\\sum_{n=1}^{N} \\\\log p(y_n | x_n, \\\\theta) \\\\\\\\ & - \\\\bar{\\\\lambda} M \\\\sum_{m=1}^{M} H(x_m, y_m | \\\\bar{x}_m, \\\\theta).\\n\\\\end{align*}\\n\\\\]\\n\\n3. Probabilistic Test-Time Adaptation\\n\\nOur formulation for TTA is similar to the formulation we described above for the problem of Bayesian semi-supervised learning with unlabeled data distribution shift, with a key difference. In contrast to Bayesian SSL in which labeled and unlabeled data are available during training, in test-time adaptation, we need to predict labels of the test inputs from a different domain, but we only have access to the source model weights without the source domain training data. In our probabilistic approach, we assume that the source model is given in form of the approximate posterior distribution\\n\\\\[\\nq(\\\\theta) \\\\approx p(\\\\theta | D).\\n\\\\]\\n\\nAt test-time, we use \\\\( q(\\\\theta) \\\\) to represent the source domain knowledge. Substituting Eq. 1 for the posterior of the source domain data, we take the logarithm in Eq. 7 and simplify further to get the following\\n\\\\[\\n\\\\log q(\\\\theta) = \\\\log p(\\\\theta) + \\\\sum_{n=1}^{N} \\\\log p(y_n | x_n, \\\\theta).\\n\\\\]\\n\\nFor our TTA setting, substituting this approximate posterior above in Eq. 6, the log-posterior density with both labeled (source) and unlabeled (test inputs) data becomes\\n\\\\[\\n\\\\begin{align*}\\n\\\\log p(\\\\theta | D, U) = & \\\\log q(\\\\theta) - \\\\bar{\\\\lambda} M \\\\sum_{m=1}^{M} H(x_m, y_m | \\\\bar{x}_m, \\\\theta).\\n\\\\end{align*}\\n\\\\]\\n\\nSince posterior inference for deep neural networks is challenging, we leverage the Gaussian posterior approximation based on the SW AG-diagonal [26] method. It uses the SGD iterates to construct the mean and (diagonal) covariance matrix of the Gaussian posterior approximation and requires minimal changes to the training mechanism on source domain training data.\\n\\n3.1. Parameter Restoration\\n\\nStochastic Restoration\\n\\nIn lifelong TTA, in order to reduce the error accumulation over the long term in self-training and handle catastrophic forgetting, [41] proposed stochastic restoration of weights by additionally updating the parameters. Let \\\\( \\\\theta_f \\\\) denote the flattened parameter \\\\( \\\\theta \\\\) of the student model, and \\\\( D \\\\) be the dimension of \\\\( \\\\theta_f \\\\). After the gradient update at time step \\\\( t \\\\), stochastic restore further updates the parameters:\\n\\\\[\\nm \\\\sim \\\\text{Bernoulli}(\\\\rho),\\n\\\\]\\n\\\\[\\n\\\\theta_{f,t+1} = m \\\\odot \\\\theta_{f,0} + (1 - m) \\\\odot \\\\theta_{f,t+1}.\\n\\\\]\\n\\nHere, \\\\( \\\\odot \\\\) is element-wise multiplication, and \\\\( \\\\rho \\\\) is stochastic restore probability. \\\\( m \\\\) is mask to determine which parameters within \\\\( \\\\theta_{f,t+1} \\\\) to restore to original source weight \\\\( \\\\theta_f \\\\).\\n\\nFisher Information Based Restoration\\n\\nTo improve upon stochastic restoration, we propose a data-driven parameter restoration. Fisher Information Matrix (FIM) is widely used as a metric of parameter importance for a given data [15]. Thus, we use FIM, \\\\( F \\\\), of the student model parameterized by \\\\( \\\\theta \\\\) as a measure of the importance of the parameters. For a given time step \\\\( t \\\\) with unlabeled test inputs batch \\\\( B = \\\\{\\\\bar{x}_m\\\\}_{t+1} | B | \\\\), we consider the following diagonal approximation of FIM:\\n\\\\[\\nF = \\\\text{Diag}(\\\\nabla \\\\theta L)(\\\\nabla \\\\theta L)^T,\\n\\\\]\\nwhere,\\n\\\\[\\n\\\\begin{align*}\\nL = & \\\\log q(\\\\theta) - \\\\bar{\\\\lambda} |B| \\\\sum_{m=1}^{|B|} H(x_m, y_m | \\\\bar{x}_m, \\\\theta).\\n\\\\end{align*}\\n\\\\]\\n\\nHere, \\\\( y' \\\\) and \\\\( y \\\\) are the teacher and student model predictions, respectively. Note that \\\\( F \\\\) has the same dimension as \\\\( \\\\theta \\\\). Thus, upon using FIM based restore, the parameter restoration in Eq. 10 becomes\\n\\\\[\\nm_p = \\\\begin{cases} 1 & \\\\text{if } F_p < \\\\gamma_0 \\\\\\\\ 0 & \\\\text{otherwise} \\\\end{cases},\\n\\\\]\\n\\\\[\\np = 1, \\\\ldots, P.\\n\\\\]\\n\\nHere, \\\\( \\\\gamma = \\\\text{quantile}(F, \\\\delta) \\\\) is the threshold value which is the \\\\( \\\\delta \\\\)-quantile of \\\\( F \\\\). Thus, the elements in \\\\( m \\\\) corresponding to FIM value less than \\\\( \\\\gamma \\\\) would be 1, implying that the corresponding parameters would be restored to original source weight \\\\( \\\\theta_f \\\\). The algorithm for PETAL is given in Algorithm 1. Fig. 1 (Right) provides an overview of our approach PETAL.\"}"}
