{"id": "CVPR-2022-341", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\n[1] Ali Ayub and Alan R Wagner. EEC: Learning to encode and regenerate images for continual learning. In ICLR, 2021. 8\\n\\n[2] Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar. Regularized learning for domain adaptation under label shifts. arXiv preprint arXiv:1903.09734, 2019. 2\\n\\n[3] Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H Campbell, and Sergey Levine. Stochastic variational video prediction. In ICLR, 2018. 5, 8\\n\\n[4] Lluis Castrejon, Nicolas Ballas, and Aaron Courville. Improved conditional VRNNs for video prediction. In CVPR, pages 7608\u20137617, 2019. 8\\n\\n[5] Hyuntak Cha, Jaeho Lee, and Jinwoo Shin. Co2l: Contrastive continual learning. In ICCV, pages 9516\u20139525, 2021. 8\\n\\n[6] Sudeep Dasari, Frederik Ebert, Stephen Tian, Suraj Nair, Bernadette Bucher, Karl Schmeckpeper, Siddharth Singh, Sergey Levine, and Chelsea Finn. Robonet: Large-scale multi-robot learning. In CoRL, pages 885\u2013897, 2019. 2, 5\\n\\n[7] Bert De Brabandere, Xu Jia, Tinne Tuytelaars, and Luc Van Gool. Dynamic filter networks. In NeurIPS, pages 667\u2013675, 2016. 8\\n\\n[8] Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. 8\\n\\n[9] Emily Denton and Rob Fergus. Stochastic video generation with a learned prior. In ICML, pages 1182\u20131191, 2018. 1, 2, 3, 5, 6, 8\\n\\n[10] Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with gaussian mixture variational autoencoders. arXiv preprint arXiv:1611.02648, 2016. 3\\n\\n[11] Chelsea Finn and Sergey Levine. Deep visual foresight for planning robot motion. In ICRA, pages 2786\u20132793, 2017. 1\\n\\n[12] Jean-Yves Franceschi, Edouard Delasalles, Mickael Chen, Sylvain Lamprier, and Patrick Gallinari. Stochastic latent residual video prediction. In ICML, pages 3233\u20133246, 2020. 8\\n\\n[13] Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013. 1, 8\\n\\n[14] Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmitfull, Karsten Borgwardt, and Bernhard Scholkopf. Covariate shift by kernel mean matching. Dataset shift in machine learning, 3(4):5, 2009. 2\\n\\n[15] Vincent Le Guen and Nicolas Thome. Disentangling physical dynamics from unknown factors for unsupervised video prediction. In CVPR, pages 11474\u201311484, 2020. 1, 5, 6\\n\\n[16] Jiaxian Guo, Mingming Gong, Tongliang Liu, Kun Zhang, and Dacheng Tao. LTF: A label transformation framework for correcting label shift. In ICML, pages 3843\u20133853, 2020. 2\\n\\n[17] David Ha and Jurgen Schmidhuber. Recurrent world models facilitate policy evolution. In NeurIPS, 2018. 1\\n\\n[18] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning behaviors by latent imagination. In ICLR, 2020. 1, 2, 3\\n\\n[19] Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James Davidson. Learning latent dynamics for planning from pixels. In ICML, pages 2555\u20132565, 2019. 1\\n\\n[20] Xu He and Herbert Jaeger. Overcoming catastrophic interference using conceptor-aided backpropagation. In ICLR, 2018. 8\\n\\n[21] Arun Iyer, Saketha Nath, and Sunita Sarawagi. Maximum mean discrepancy for class ratio estimation: Convergence bounds and kernel selection. In ICML, pages 530\u2013538, 2014. 2\\n\\n[22] Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and Hanning Zhou. Variational deep embedding: An unsupervised and generative approach to clustering. In IJCAI, pages 1965\u20141972, 2017. 3\\n\\n[23] Zixuan Ke, Bing Liu, Hu Xu, and Lei Shu. Classic: Continual and contrastive learning of aspect sentiment classification tasks. In EMNLP, pages 6871\u20136883, 2021. 8\\n\\n[24] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521\u20133526, 2017. 5, 6, 8\\n\\n[25] Alex X Lee, Richard Zhang, Frederik Ebert, Pieter Abbeel, Chelsea Finn, and Sergey Levine. Stochastic adversarial video prediction. arXiv preprint arXiv:1804.01523, 2018. 8\\n\\n[26] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935\u20132947, 2017. 5, 6, 8\\n\\n[27] Zachary Lipton, Yu-Xiang Wang, and Alexander Smola. Detecting and correcting for label shift with black box predictors. In ICML, pages 3122\u20133130, 2018. 2\\n\\n[28] Hong Liu, Mingsheng Long, Jianmin Wang, and Michael Jordan. Transferable adversarial training: A general approach to adapting deep classifiers. In ICML, pages 4013\u20134022, 2019. 2\\n\\n[29] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In ICML, pages 97\u2013105, 2015. 2\\n\\n[30] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial domain adaptation. In NeurIPS, 2017. 2\\n\\n[31] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint adaptation networks. In ICML, pages 2208\u20132217, 2017. 2\\n\\n[32] MarcAurelio Ranzato, Arthur Szlam, Joan Bruna, Michael Mathieu, Ronan Collobert, and Sumit Chopra. Video (language) modeling: a baseline for generative models of natural videos. arXiv preprint arXiv:1412.6604, 2014. 8\"}"}
{"id": "CVPR-2022-341", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dushyant Rao, Francesco Visin, Andrei A. Rusu, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. Continual unsupervised representation learning. In NeurIPS, 2019.\\n\\nSylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. iCaRL: Incremental classifier and representation learning. In CVPR, pages 2001\u20132010, 2017.\\n\\nMatthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interference. In ICLR, 2019.\\n\\nAndrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671, 2016.\\n\\nChristian Sch\u00fcldt, Ivan Laptev, and Barbara Caputo. Recognizing human actions: A local SVM approach. In ICPR, pages 32\u201336, 2004.\\n\\nXingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. In NeurIPS, pages 802\u2013810, 2015.\\n\\nHidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of statistical planning and inference, 90(2):227\u2013244, 2000.\\n\\nHanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim. Continual learning with deep generative replay. In NeurIPS, pages 2990\u20132999, 2017.\\n\\nNitish Srivastava, Elman Mansimov, and Ruslan Salakhutdinov. Unsupervised learning of video representations using LSTMs. In ICML, pages 843\u2013852, 2015.\\n\\nJiahao Su, Wonmin Byeon, Furong Huang, Jan Kautz, and Animashree Anandkumar. Convolutional tensor-train LSTM for spatio-temporal learning. In NeurIPS, 2020.\\n\\nMasashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul von Buenau, and Motoaki Kawanabe. Direct importance estimation with model selection and its application to covariate shift adaptation. In NeurIPS, volume 7, pages 1433\u20131440, 2007.\\n\\nSergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. MoCoGAN: Decomposing motion and content for video generation. In CVPR, pages 1526\u20131535, 2018.\\n\\nCarl Vondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dynamics. In NeurIPS, pages 613\u2013621, 2016.\\n\\nYunbo Wang, Lu Jiang, Ming-Hsuan Yang, Li-Jia Li, Ming-sheng Long, and Li Fei-Fei. Eidetic 3D LSTM: A model for video prediction and beyond. In ICLR, 2019.\\n\\nYunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, and S. Yu Philip. PredRNN: Recurrent neural networks for predictive learning using spatiotemporal LSTMs. In NeurIPS, pages 879\u2013888, 2017.\\n\\nBohan Wu, Suraj Nair, Roberto Mart\u00edn-Mart\u00edn, Li Fei-Fei, and Chelsea Finn. Greedy hierarchical variational autoencoders for large-scale video prediction. In CVPR, pages 2318\u20132328, 2021.\\n\\nZhiyu Yao, Yunbo Wang, Mingsheng Long, and Jianmin Wang. Unsupervised transfer learning for spatiotemporal predictive networks. In ICML, pages 10778\u201310788, 2020.\\n\\nKun Zhang, Bernhard Sch\u00f6lkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under target and conditional shift. In ICML, pages 819\u2013827, 2013.\"}"}
{"id": "CVPR-2022-341", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Continual Predictive Learning from Videos\\n\\nGeng Chen\u2217 1\\nWendong Zhang\u2217 1\\nHan Lu 1\\nSiyu Gao 1\\nYunbo Wang\u2020 1\\nMingsheng Long 2\\nXiaokang Yang 1\\n\\n1MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University\\n2School of Software, BNRist, Tsinghua University\\n\\n{chengeng, diergent, yunbow}@sjtu.edu.cn\\n\\nAbstract\\n\\nPredictive learning ideally builds the world model of physical processes in one or more given environments. Typical setups assume that we can collect data from all environments at all times. In practice, however, different prediction tasks may arrive sequentially so that the environments may change persistently throughout the training procedure. Can we develop predictive learning algorithms that can deal with more realistic, non-stationary physical environments? In this paper, we study a new continual learning problem in the context of video prediction, and observe that most existing methods suffer from severe catastrophic forgetting in this setup. To tackle this problem, we propose the continual predictive learning (CPL) approach, which learns a mixture world model via predictive experience replay and performs test-time adaptation with non-parametric task inference. We construct two new benchmarks based on RoboNet and KTH, in which different tasks correspond to different physical robotic environments or human actions. Our approach is shown to effectively mitigate forgetting and remarkably outperform the na\u00efve combinations of previous art in video prediction and continual learning.\\n\\n1. Introduction\\n\\nPredictive learning is an unsupervised learning technique to build a world model of the environment by learning the consequences from historical observations, sequences of actions, and corresponding future observation frames. The standard predictive learning setup is assumed to operate the model in a stationary environment with relatively fixed physical dynamics [9, 15, 38, 41]. However, the assumption of stationarity does not always hold in more realistic scenarios, such as in the settings of continual learning (CL), where the model is learned through tasks that arrive sequentially. For example, in robotics (see Fig. 1), world models often serve as the representation learners of model-based control systems [11, 17\u201319], while the agent may be subjected to non-stationary environments in different training periods. Under these circumstances, it is not practical to maintain a single model for each environment or each task, nor is it practical to collect data from all environments at all times. A primary finding of this paper is that most existing predictive networks [9, 15, 38, 41] cannot perform well when trained in non-stationary environments, suffering from a phenomenon known as catastrophic forgetting [13].\\n\\nWe formalize this problem setup as continual predictive learning, in which the world model is trained in time-varying environments (i.e., \u201ctasks\u201d in the context of continual learning) with non-stationary physical dynamics. The model is expected to handle both newer tasks and older ones after the entire training phase (see Section 2 for detailed setups). There are two major challenges.\\n\\n1.1. Covariate\u2013Dynamics\u2013Target Shift\\n\\nUnlike in the settings of domain-incremental or class-incremental CL for deterministic models, the world model,\"}"}
{"id": "CVPR-2022-341", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"which can be viewed as a conditioned generative model, cannot assume a stationary distribution of training targets or fixed target space. Therefore, different from all previous CL problems, the unique challenge of continual predictive learning is due to the co-existence of three types of distribution shift, including the covariate shift in $P_{X}$, the target shift in $P_{Y}$, and the dynamics shift $P_{Y|X}$. Notably, the covariate shift [14,28\u201331,39,43] and target shift [2,16,21,27,50] have been widely considered by existing methods, whereas the conditional distribution is typically assumed to be invariant. In our setup, however, the conditional distribution $P_{Y|X}$ corresponding to the spatiotemporal dynamics also changes over training periods. It significantly increases the probability of catastrophic forgetting in the world model.\\n\\nTo combat the dynamics shift, we first present a new world model that learns multi-modal visual dynamics of different tasks on top of task-specific latent variables. Future frames are generated by drawing samples from learned mixture-of-Gaussian priors conditioned on a set of categorical task variables, and combining them with a deterministic component of future prediction (see Section 3.1).\\n\\nSecond, we specifically design a novel training scheme named predictive experience replay. Like deep generative replay (DGR) [40], the proposed training method leverages a learned generative model to produce samples of previous tasks. Yet, in our approach, these samples are fed into the world model as the first frames to generate entire sequences, which can be reused as model inputs for rehearsal. The world model alternates between (i) generating rehearsal data without backpropagating the gradients, (ii) regressing the facilitate future frames of previous tasks produced by the world model itself, and (iii) generating future frames from real data of the current task. Another advantage of this training scheme is about the memory efficiency, as it only retains parts of low-dimensional action vectors in the buffer (see Section 3.2).\\n\\n1.2. Task Inference: Coupled Forgetting Issues\\n\\nThe second challenge in continual predictive learning is the task ambiguity at test time, which can greatly affect the prediction results. Unlike existing CL methods for fully generative models [33, 40], in our setup, the models are required not only to solve each task seen so far, but also to infer which task they are presented with. A na\\\"ive solution is to infer the task using another neural network. However, due to the inevitable forgetting issue of the task inference model itself, coupled with that of the world model, this method is unlikely to perform well. In Section 3.3, we propose the non-parametric task inference strategy, which overcomes the intrinsic nature of forgetting of a deterministic model.\\n\\nIn predictive learning settings, the input $X$ is in forms of sequential observation frames $X_{1:T}$ and the training target $Y$ corresponds to future frames $X_{T+1:T+H}$. We here skip the input action signals for simplicity. We also present a self-supervised, test-time training process that recalls the pre-learned knowledge of the inferred task through one or several online adaptation steps. We construct two new benchmarks for continual predictive learning based on real-world datasets, RoboNet [6] and KTH [37], in which different tasks correspond to different physical robotic environments or human actions. Our CPL approach is shown to effectively avoid forgetting and remarkably outperform the straightforward combinations of previous art in video prediction and continual learning.\\n\\n2. Problem Setup\\n\\nUnlike existing predictive learning approaches, we consider to learn a world model ($M$) in non-stationary environments (i.e., the evolution of tasks), such that $bX_{T+1:T+H} \\\\sim M(X_{1:T}, a_{T:T+H-1}, \\\\hat{t})$, where $X_{1:T}$ and $X_{T+1:T+H}$ are respectively the observed frames and future frames to be predicted. The task index $t$ is known at training, but not observed at test. It requires our approach not only to solve each task seen so far, but also to infer which task it is presented with, denoted as $T_{\\\\hat{t}}$. Here, $a_{T:T+H-1}$ is the optional inputs of action signals when $M$ is learned for vision-based robot control, as in the action-conditioned video prediction experiments in this paper. Formally, continual predictive learning assumes that:\\n\\nCovariate shift: $P(X_{k1:T}) \\\\neq P(X_{k+11:T})$\\n\\nDynamics shift: $P(X_{kT+1:T+H}|X_{1:T}) \\\\neq P(X_{k+1T+1:T+H}|X_{k+11:T})$\\n\\nTarget shift: $P(X_{kT+1:T+H}) \\\\neq P(X_{k+1T+1:T+H})$,\\n\\nwhere we leave out $a_{T:T+H-1}$ for simplicity in the conditional distribution of visual dynamics. The setup is in part similar to class-incremental CL for supervised tasks that assumes $P(X_{k}) \\\\neq P(X_{k+1})$, $\\\\{Y_{k}\\\\} = \\\\{Y_{k+1}\\\\}$, $P(Y_{k}) \\\\neq P(Y_{k+1})$, $\\\\{Y_{k}\\\\}$ denotes a constant label set for discriminative models. In contrast, continual predictive learning does not assume a fixed target space, and therefore may have more severe catastrophic forgetting issues.\\n\\n3. Approach\\n\\nIn this section, we present the new continual predictive learning (CPL) approach, which first mitigates catastrophic forgetting within the world model from two aspects:\\n\\n\u2022 Mixture world model: A recurrent network that captures multi-modal visual dynamics. Unlike existing models [9, 18], the learned task-specific priors are in forms of mixture-of-Gaussians to overcome dynamics shift.\\n\\n\u2022 Predictive experience replay: A new rehearsal-based training scheme that combats the forgetting within the world model and is efficient in memory usage.\"}"}
{"id": "CVPR-2022-341", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.1. Mixture World Model\\n\\nFig. 2(a), the world model consists of three components: input/output observation space. Accordingly, as shown in the latent space, as well as that of spatial appearance in the capture the multi-modal distribution of visual dynamics in environments. Therefore, the key idea of the proposed world model in CPL is to use mixture-of-Gaussian variables to represent. As mentioned above, the forgetting problem from the perspective of spatiotemporal trophic forgetting is mainly caused by the covariate-dynamics-target shift in time-varying environments. Predictive learning scenarios. The encoding module corresponds to the covariate shift and dynamically maps the input to cope with the target shift in continual learning. It takes as input the categorical task variable \u2208 {k, target frames. It takes as input the categorical task variable t \\\\in \\\\{1, \\\\ldots, K\\\\} to cope with the target shift in continual learning. The representation module infers the latent state z_t \\\\sim p(z_t | x_t, \\\\theta, \\\\phi, a_t) from the LSTM (3). The encoding module encodes the input data into a latent representation. The representation module infers the latent state z_t \\\\sim p(z_t | x_t, \\\\theta, \\\\phi, a_t). The dynamics module learns the deterministic transition component from the previous task, and the generative model can be used to generate the first frames of previous tasks without backpropagating the gradients, then use the rehearsal data and real data to jointly train the model. (a) The world model learns representations in the forms of mixture-of-Gaussians based on categorical task variables. (b) As respond to the covariate shift and dynamically maps the input and only use the future frames, and finally combine the rehearsal data and real data to jointly train the model. (c) The world model learns representations in the forms of mixture-of-Gaussians based on categorical task variables. (d) As respond to the covariate shift and dynamically maps the input and only use the future frames, and finally combine the rehearsal data and real data to jointly train the model. (e) The world model learns representations in the forms of mixture-of-Gaussians based on categorical task variables. (f) As respond to the covariate shift and dynamically maps the input and only use the future frames, and finally combine the rehearsal data and real data to jointly train the model.\"}"}
{"id": "CVPR-2022-341", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Training data\\n\\nPredictive experience replay\\n\\nAlgorithm 1\\n\\n1: Initialize the world model.\\n2: For each previous task:\\n   1: Gather rehearsal sequences.\\n   2: Train the world model on the rehearsal sequences.\\n3: During hybrid replay:\\n   1: Sample a batch of actions.\\n   2: Use the world model to generate the first frame.\\n   3: Use the generated first frame to replay the video sequence.\\n4: Evaluation:\\n   1: Use the world model to predict future frames.\\n   2: Evaluate the predictive accuracy.\\n\\nTraining procedure\\n\\nObjective function\\n\\nAlgorithm 2\\n\\n1: Initialize the mixture world model.\\n2: For each previous task:\\n   1: Gather rehearsal sequences.\\n   2: Train the mixture world model on the rehearsal sequences.\\n3: During test-time:\\n   1: Sample an input sequence.\\n   2: Infer the task label.\\n   3: Use the inferred task label to predict future frames.\\n4: Evaluation:\\n   1: Use the learned mixture world model to classify the input sequence.\\n   2: Evaluate the classification accuracy.\"}"}
{"id": "CVPR-2022-341", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1. Quantitative results of continual predictive learning on the RoboNet benchmark in both action-conditioned and action-free setups.\\n\\n| Method                        | PSNR \u00b1 SSIM | PSNR \u00b1 SSIM |\\n|-------------------------------|-------------|-------------|\\n| PredRNN [47]                  | 19.45       | 66.38       |\\n| PhyDNet [15]                  | 19.60       | 68.68       |\\n| PredRNN + LwF [26]            | 19.10       | 64.73       |\\n| PredRNN + EWC [24]            | 21.15       | 74.72       |\\n| CPL-base + EWC [24]           | 21.29 \u00b1 0.30| 75.16 \u00b1 0.98|\\n| CPL-base                      | 19.36 \u00b1 0.00 | 63.57 \u00b1 0.00|\\n| CPL-full                      | 23.26 \u00b1 0.10| 80.72 \u00b1 0.23|\\n| CPL-base (Joint training)     | 24.64 \u00b1 0.01| 83.73 \u00b1 0.00|\\n\\nIn addition to using $P(X_{T/2+1:T} | X_{1:T/2})$ to perform task inference, we also use this self-supervision for test-time adaptation, which allows the model to continue training after deployment. Test-time adaptation effectively reaps the pre-learned knowledge in the inferred task $T_k$ through one-step (or few-steps) online optimization, thus further alleviating the forgetting problem.\\n\\n4. Experiment\\n4.1. Experimental Setup\\n\\nBenchmarks. We quantitatively and qualitatively evaluate CPL on the following two real-world datasets:\\n\\n- RoboNet [6]. The RoboNet dataset contains action-conditioned videos of robotic arms interacting with a variety of objects in various environments. We divide the whole dataset into four continual learning tasks according to the environments (i.e., Berkeley \u2192 Google \u2192 Penn \u2192 Stanford). For each task, we collect about $3,840$ training sequences and $960$ testing sequences.\\n- KTH action [37]. This dataset contains gray-scale videos which include $6$ types of human actions. We directly use the action labels to divide the dataset into $6$ tasks (i.e., Boxing \u2192 Clapping \u2192 Waving \u2192 Walking \u2192 Jogging \u2192 Running). For each task, we collect about $1,500$ training sequences and $800$ testing sequences in average.\\n\\nWe define the task orders by random sampling, and without loss of generality, our approach is effective to any task orders (see Section 4.4). More experimental configurations and the implementation details can be found in the Supplementary Material.\\n\\nEvaluation criteria. We adopt SSIM and PSNR from previous literature [9, 47] to evaluate the prediction results. We run the continual learning procedure $10$ times and report the mean results and standard deviations in the two metrics.\\n\\nCompared methods. We compare CPL with the following baselines and existing approaches:\\n\\n- CPL-base: A baseline model that excludes the new components of Gaussian mixtures, predictive replay, and task inference.\\n- PredRNN [47], SVG [9], PhyDNet [15]: Video prediction models focused on stochastic, deterministic, and disentangled dynamics modeling respectively.\\n- LwF [26]: It is a distillation-based CL method built on the memory state of PredRNN [47].\\n- EWC [24]: It constrains the parameters of PredRNN and CPL-base on new tasks with additional loss terms.\\n\\n4.2. RoboNet Benchmark\\n\\nWe first evaluate CPL on the real-world RoboNet benchmark, in which different continual learning tasks are divided by laboratory environments. We conduct both action-conditioned and action-free video prediction on RoboNet. The former follows the common practice [3, 48] to train the world model to predict $10$ frames into the future from $2$ observations and corresponding action sequence at the $11$ time steps. For the action-free setup, we use the first $5$ frames as input to predict the next $10$ frames.\\n\\nQuantitative comparison. Table 1 gives the quantitative results on RoboNet, in which the models are evaluated on the test sets of all $4$ tasks after the training period on the last task. We have the following findings here.\\n\\nFirst, CPL outperforms existing video prediction models by a large margin. For instance, in the action-conditioned setup, it improves SVG in PSNR by $24.3\\\\%$, PredRNN by $19.6\\\\%$, and PhyDNet by $18.7\\\\%$.\\n\\nSecond, CPL generally performs better than previous continual learning methods (i.e., LwF and EWC) combined with video prediction backbones. Note that a naive implementation of LwF on top of PredRNN even leads to a negative effect on the final results.\\n\\nThird, CPL generally performs better than previous continual learning methods (i.e., LwF and EWC) combined with video prediction backbones. Note that a naive implementation of LwF on top of PredRNN even leads to a negative effect on the final results.\"}"}
{"id": "CVPR-2022-341", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3. Results on the action-conditioned RoboNet benchmark. The horizontal axis represents the sequential training process, and the vertical axes represent test results on particular tasks after each training period. The purple dashed line indicates the results of the baseline model jointly trained on all tasks.\\n\\nBy comparing CPL-full (our final approach) with CPL-base (w/o Gaussian mixture latents, predictive experience replay, or non-parametric task inference), we can see that the new technical contributions have a great impact on the performance gain. We provide more detailed ablation studies in Section 4.4.\\n\\nFinally, CPL is shown to effectively ease catastrophic forgetting by approaching the results of jointly training the world model on all tasks in the i.i.d. setting (23.20 vs. 24.64 in PSNR). Apart from the average scores for all tasks, in Fig. 3, we provide the test results on particular tasks after individual training periods. As shown in the bar charts right to the main diagonal, CPL performs particularly well on previous tasks, effectively alleviating the forgetting issue. Please refer to the Supplementary Material for detailed comparison results.\\n\\nQualitative comparison. Fig. 4 provides the qualitative comparisons on the action-conditioned RoboNet benchmark. Specifically, we use the final models after the training period of the last task to make predictions on the first task. We can see from these demonstrations that our approach is more accurate in predicting both future dynamics of the objects as well as the static information of the scene. In contrast, the predicted frames by PredRNN+LwF and CPL-base+EWC suffer from severe blur effect in the moving object or the static (but complex) background, indicating that directly combining existing CL algorithms with the world models cannot effectively cope with the dynamics shift in highly non-stationary environments.\\n\\n4.3. KTH Benchmark\\n\\nQuantitative comparison. Table 2 shows the quantitative results on the test sets of all 6 tasks after the last training period of the models on the last task. We can observe that CPL significantly outperforms the compared video prediction methods and continual learning methods in both PSNR and SSIM. Furthermore, an interesting result is that our approach even outperforms the joint training model, as shown in the bottom line in Table 2. While we do not know the exact reasons, we state two hypotheses that can be investigated in future work. First, the Gaussian mixture priors enable the world model to better disentangle the representations of visual dynamics learned in different continual learning tasks. Second, the predictive experience replay allows the pre-learned knowledge on previous tasks to facilitate the understanding of the current task.\"}"}
{"id": "CVPR-2022-341", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"Figure 5. Results on the KTH benchmark. The horizontal axis represents the sequential training process, and the vertical axes represent test results on particular tasks after each training period.\\n\\n| Training periods | Test results on tasks |\\n|------------------|-----------------------|\\n| T1               | T2                    |\\n| 18.00            | 21.25                 |\\n| 24.50            | 27.75                 |\\n\\nTable 3. Ablation study for each component of CPL on the KTH benchmark. \u201cReplay\u201d denotes the use of predictive experience replay. \u201cInfer $k$\u201d indicates the use of non-parametric task inference. \u201cRandom $k$\u201d means that the world model takes as input a random task label at test time. \u201cAdapt\u201d means test-time adaptation.\\n\\nQualitative comparison. We visualize a sequence of predicted frames on the first task of KTH in Fig. 6. As shown, all existing video prediction models and even the one with LwF generate future frames with the dynamics learned in the last task (e.g., Running), which clearly demonstrates the influence of the dynamics shift. Images generated by CPL-base+EWC suffer from a severe blur effect, indicating that the model cannot learn disentangled representations for different dynamics in the non-stationary training environments. In comparison, CPL produces more reasonable results. To testify the necessity of task inference, we also provide incorrect task labels for CPL. As shown in the third line from the bottom, the model takes as input the Boxing frames along with an erroneous task label of Running. Interestingly, CPL combines the inherent dynamics of input frames (reflected in motion of arms) with the dynamics priors from the input task label (reflected in motion of legs).\\n\\n4.4. Ablation Study\\n\\nEffectiveness of each component in CPL. We conduct ablation studies on the KTH benchmark step by step. In Table 3, the first line shows the results of the CPL-base model and the bottom line corresponds to our final approach. In the second line, we train CPL-base with predictive experience replay and observe a significant improvement from 22.96 to 27.21 in PSNR. In the third line, we improve the world model with mixture-of-Gaussian priors and accordingly perform non-parametric task inference at test time. We observe consistent improvements in both PSNR and SSIM upon the previous version of the model. In the fourth line, we skip the non-parametric task inference during testing and use a random task label instead. We observe that...\"}"}
{"id": "CVPR-2022-341", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4. Robustness of CPL on random task orders.\\n\\n| Dataset  | PSNR (\u00b1) | SSIM (\u00b1) |\\n|----------|----------|----------|\\n| RoboNet  | 23.58 \u00b1 0.28 | 79.67 \u00b1 3.75 |\\n| KTH      | 28.93 \u00b1 0.14 | 83.99 \u00b1 0.40 |\\n\\nIs CPL robust to the task order? As shown in Table 4, we further conduct experiments to analyze whether CPL can effectively alleviate catastrophic forgetting regardless of the task order. We additionally train the CPL model in 3-4 random task orders. From the results, we find that the proposed techniques including mixture world model, predictive experience replay, and non-parametric task inference are still effective despite the change of training order.\\n\\n5. Related Work\\n\\nContinual learning of supervised tasks. Continual learning is designed to cope with the continuous information flow, retaining or even optimizing old knowledge while absorbing new knowledge. Mainstream paradigms include regularization, replay, and parameter isolation [8]. The regularization approaches typically tackle catastrophic forgetting [13] by constraining the learned parameters on new tasks with additional loss terms, e.g., EWC [24], or distilling knowledge from old tasks, e.g., LwF [26]. For replay-based approaches, a typical solution is to retain a buffer on earlier tasks of representative data or feature exemplars [1, 34, 35]. Some approaches also use generative networks to encode the previous data distribution and synthesize fictitious data for experience replay, e.g., DGR [40] and CURL [33]. The parameter isolation approaches allow the neural networks to dynamically expand when new tasks arrive [36] or encourage the new tasks to use previously \u201cunused\u201d parameter subspaces [20].\\n\\nContinual learning of unsupervised tasks. Most existing approaches are mainly focused on supervised tasks of image data. Despite the previous literature that discussed unsupervised CL [5, 23, 33], our approach is significantly different from these methods as it explores the specific challenges of continual predictive learning for video data, especially the covariate-dynamics-target shift. The most related method to CPL is CURL [33], which introduces a mixture-of-Gaussian latent space for class-incremental CL and combat forgetting via generative replay. There are three major differences between CPL and CURL. First, CURL cannot be directly used in our setup as it does not handle the dynamics shift in non-stationary spacetime, while CPL tackles it through a new world model. Second, CPL greatly benefits from the carefully-designed predictive replay algorithm, while it is extremely difficult for CURL to replay valid video frames using a fully generative model alone. Third, CPL provides a non-parametric task inference method as opposed to the model-based inference method in CURL.\\n\\n6. Discussion\\n\\nIn this paper, we explored a new research problem of continual predictive learning, which is challenging due to the co-existence of the covariate, dynamics, and target shift. We proposed an approach named CPL, whose major contributions of CPL can be viewed in three aspects. First, it presents a new world model to capture task-specific visual dynamics in a Gaussian mixture latent space. Second, it introduces the predictive experience replay method to overcome the forgetting issue in the world model. Third, it leverages a non-parametric task inference strategy to avoid coupling the forgetting issues caused by the introduction of a task inference model. Our approach has shown competitive results on RoboNet and KTH benchmarks, achieving remarkable improvements over the naive combinations of existing world models and CL algorithms.\\n\\nAlthough CPL can be easily extended to more complex tasks, the potential limitation is that it has not been evaluated in the entire pipeline of vision-based robot control, which includes the processes of predictive learning and decision making. In future work, we plan to integrate CPL in a model-based reinforcement learning framework to further validate its effectiveness for downstream tasks.\\n\\n7. Acknowledgement\\n\\nThis work was supported by NSFC grants (U19B2035, 62106144, 62022050), Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), and Shanghai Sailing Program (21Z510202133).\"}"}
