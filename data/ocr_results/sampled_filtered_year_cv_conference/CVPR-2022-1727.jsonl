{"id": "CVPR-2022-1727", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"[1] Iro Armeni, Ozan Sener, Amir R Zamir, Helen Jiang, Ioannis Brilakis, Martin Fischer, and Silvio Savarese. 3d semantic parsing of large-scale indoor spaces. In CVPR, 2016. 2, 5\\n\\n[2] Mathieu Aubry, Ulrich Schlickewei, and Daniel Cremers. The wave kernel signature: A quantum mechanical approach to shape analysis. In ICCV workshops, 2011. 2\\n\\n[3] Michael M Bronstein and Iasonas Kokkinos. Scale-invariant heat kernel signatures for non-rigid shape recognition. In CVPR, 2010. 2\\n\\n[4] Shaoyu Chen, Jiemin Fang, Qian Zhang, Wenyu Liu, and Xinggang Wang. Hierarchical aggregation for 3d instance segmentation. In ICCV, 2021. 1, 3, 4, 5, 6, 7\\n\\n[5] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4d spatio-temporal convnets: Minkowski convolutional neural networks. In CVPR, 2019. 2\\n\\n[6] Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias Nie\u00dfner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. In CVPR, 2017. 2, 5\\n\\n[7] Francis Engelmann, Martin Bokeloh, Alireza Fathi, Bastian Leibe, and Matthias Nie\u00dfner. 3d-mpa: Multi-proposal aggregation for 3d semantic instance segmentation. In CVPR, 2020. 6, 7\\n\\n[8] Benjamin Graham, Martin Engelcke, and Laurens Van Der Maaten. 3d semantic segmentation with submanifold sparse convolutional networks. In CVPR, 2018. 2, 3\\n\\n[9] Lei Han, Tian Zheng, Lan Xu, and Lu Fang. Occuseg: Occupancy-aware 3d instance segmentation. In CVPR, 2020. 2, 6, 7\\n\\n[10] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. In ICCV, 2017. 5\\n\\n[11] Tong He, Chunhua Shen, and Anton van den Hengel. Dyco3d: Robust instance segmentation of 3d point clouds through dynamic convolution. In CVPR, 2021. 6\\n\\n[12] Ji Hou, Angela Dai, and Matthias Nie\u00dfner. 3d-sis: 3d semantic instance segmentation of rgb-d scans. In CVPR, 2019. 2, 4, 6, 7\\n\\n[13] Binh-Son Hua, Minh-Khoi Tran, and Sai-Kit Yeung. Pointwise convolutional neural networks. In CVPR, 2018. 2\\n\\n[14] Zhaojin Huang, Lichao Huang, Yongchao Gong, Chang Huang, and Xinggang Wang. Mask scoring r-cnn. In CVPR, 2019. 5\\n\\n[15] Li Jiang, Hengshuang Zhao, Shaoshuai Shi, Shu Liu, Chi-Wing Fu, and Jiaya Jia. Pointgroup: Dual-set point grouping for 3d instance segmentation. In CVPR, 2020. 1, 3, 4, 5, 6, 7\\n\\n[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICVLR, 2015. 5\\n\\n[17] Jean Lahoud, Bernard Ghanem, Marc Pollefeys, and Martin R Oswald. 3d instance segmentation via multi-task metric learning. In ICCV, 2019. 2, 6\\n\\n[18] Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh. Set transformer: A framework for attention-based permutation-invariant neural networks. In ICML, 2019. 2\\n\\n[19] Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, and Baoquan Chen. Pointcnn: Convolution on x-transformed points. In NIPS, 2018. 2\\n\\n[20] Zhihao Liang, Zhihao Li, Songcen Xu, Mingkui Tan, and Kui Jia. Instance segmentation in 3d scenes using semantic superpoint tree networks. In ICCV, 2021. 1, 3, 4, 6, 7\\n\\n[21] Chen Liu and Yasutaka Furukawa. Masc: Multi-scale affinity with sparse convolution for 3d instance segmentation. arXiv:1902.04478, 2019. 6\\n\\n[22] Shih-Hung Liu, Shang-Yi Yu, Shao-Chi Wu, Hwann-Tzong Chen, and Tyng-Luh Liu. Learning gaussian instance segmentation in point clouds. arXiv:2007.09860, 2020. 2, 4, 6, 7\\n\\n[23] Yongcheng Liu, Bin Fan, Shiming Xiang, and Chunhong Pan. Relation-shape convolutional neural network for point cloud analysis. In CVPR, 2019. 2\\n\\n[24] Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. In ICVLR, 2017. 5\\n\\n[25] Daniel Maturana and Sebastian Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In IROS, 2015. 2\\n\\n[26] Kaichun Mo, Shilin Zhu, Angel X Chang, Li Yi, Subarna Tripathi, Leonidas J Guibas, and Hao Su. Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding. In CVPR, 2019. 7\\n\\n[27] Gaku Narita, Takashi Seno, Tomoya Ishikawa, and Yohsuke Kaji. Panopticfusion: Online volumetric semantic mapping at the level of stuff and things. arXiv:1903.01177, 2019. 6\\n\\n[28] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In NIPS-W, 2017. 5\\n\\n[29] Quang-Hieu Pham, Thanh Nguyen, Binh-Son Hua, Gemma Roig, and Sai-Kit Yeung. Jsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields. In CVPR, 2019. 2\\n\\n[30] Charles R Qi, Or Litany, Kaiming He, and Leonidas J Guibas. Deep hough voting for 3d object detection in point clouds. In CVPR, 2019. 7\\n\\n[31] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In CVPR, 2018. 7\\n\\n[32] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In CVPR, 2017. 2\\n\\n[33] Charles R Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. arXiv:1706.02413, 2017. 2\\n\\n[34] Gernot Riegler, Ali Osman Ulusoy, and Andreas Geiger. Octnet: Learning deep 3d representations at high resolutions. In CVPR, 2017. 2\\n\\n[35] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI, 2015. 3\\n\\n[36] Radu Bogdan Rusu, Nico Blodow, and Michael Beetz. Fast point feature histograms (fpfh) for 3d registration. In ICVRA, 2009. 2\"}"}
{"id": "CVPR-2022-1727", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Radu Bogdan Rusu, Nico Blodow, Zoltan Csaba Marton, and Michael Beetz. Aligning point cloud views using persistent feature histograms. In *IROS*, 2008.\\n\\nYiru Shen, Chen Feng, Yaoqing Yang, and Dong Tian. Mining point cloud local structures by kernel correlation and graph pooling. In *CVPR*, 2018.\\n\\nMartin Simonovsky and Nikos Komodakis. Dynamic edge-conditioned filters in convolutional neural networks on graphs. In *CVPR*, 2017.\\n\\nHugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Fran\u00e7ois Goulette, and Leonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. In *ICCV*, 2019.\\n\\nWeiyue Wang, Ronald Yu, Qiangui Huang, and Ulrich Neumann. Sgpn: Similarity group proposal network for 3d point cloud instance segmentation. In *CVPR*, 2018.\\n\\nXinlong Wang, Shu Liu, Xiaoyong Shen, Chunhua Shen, and Jiaya Jia. Associatively segmenting instances and semantics in point clouds. In *CVPR*, 2019.\\n\\nYue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph CNN for learning on point clouds. *ACM TOG*, 2019.\\n\\nWenxuan Wu, Zhongang Qi, and Li Fuxin. Pointconv: Deep convolutional networks on 3d point clouds. In *CVPR*, 2019.\\n\\nYifan Xu, Tianqi Fan, Mingye Xu, Long Zeng, and Yu Qiao. Spidercnn: Deep learning on point sets with parameterized convolutional filters. In *ECCV*, 2018.\\n\\nBo Yang, Jianan Wang, Ronald Clark, Qingyong Hu, Sen Wang, Andrew Markham, and Niki Trigoni. Learning object bounding boxes for 3d instance segmentation on point clouds. In *NeurIPS*, 2019.\\n\\nLi Yi, Wang Zhao, He Wang, Minhyuk Sung, and Leonidas J Guibas. Gspn: Generative shape proposal network for 3d instance segmentation in point cloud. In *CVPR*, 2019.\\n\\nBiao Zhang and Peter Wonka. Point cloud instance segmentation using probabilistic embeddings. In *CVPR*, 2021.\\n\\nBiao Zhang and Peter Wonka. Point cloud instance segmentation using probabilistic embeddings. In *CVPR*, 2021.\\n\\nHengshuang Zhao, Li Jiang, Jiaya Jia, Philip HS Torr, and Vladlen Koltun. Point transformer. In *ICCV*, 2021.\"}"}
{"id": "CVPR-2022-1727", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nExisting state-of-the-art 3D instance segmentation methods perform semantic segmentation followed by grouping. The hard predictions are made when performing semantic segmentation such that each point is associated with a single class. However, the errors stemming from hard decision propagate into grouping that results in (1) low overlaps between the predicted instance with the ground truth and (2) substantial false positives. To address the aforementioned problems, this paper proposes a 3D instance segmentation method referred to as SoftGroup by performing bottom-up soft grouping followed by top-down refinement. SoftGroup allows each point to be associated with multiple classes to mitigate the problems stemming from semantic prediction errors and suppresses false positive instances by learning to categorize them as background. Experimental results on different datasets and multiple evaluation metrics demonstrate the efficacy of SoftGroup. Its performance surpasses the strongest prior method by a significant margin of +6.2% on the ScanNet v2 hidden test set and +6.8% on S3DIS Area 5 in terms of AP$\\\\_50$. SoftGroup is also fast, running at 345ms per scan with a single Titan X on ScanNet v2 dataset. The source code and trained models for both datasets are available at https://github.com/thangvubk/SoftGroup.git.\\n\\n1. Introduction\\n\\nScene understanding on 3D data has received increasing attention for the rapid development of 3D sensors and availability of large-scale 3D datasets. Instance segmentation on point clouds is a 3D perception task, serving as the foundation for a wide range of applications such as autonomous driving, virtual reality, and robot navigation. Instance segmentation processes the point clouds to output a category and an instance mask for each detected object. State-of-the-art methods [4, 15, 20] consider 3D instance segmentation as a bottom-up pipeline. They learn the point-wise semantic labels and center offset vectors and then group points of the same labels with small geometric distances into instances. These grouping algorithms are performed on the hard semantic prediction, where a point is associated with a single class. In many cases, objects are locally ambiguous, the output semantic predictions show different categories for different parts, and thus using hard semantic predictions for instance grouping leads to two problems: (1) low overlap between predicted instance and the ground-truth and (2) extra false-positive instances from wrong semantic regions. Figure 1 shows a visualization example. Here, in the semantic prediction results, some parts of cabinet is wrongly predicted as other furniture. When hard semantic predictions are used to perform grouping, the semantic prediction error is propagated to instance prediction. As a result, the predicted cabinet instance has low overlap with the ground truth, and the other furniture instance is a false positive.\"}"}
{"id": "CVPR-2022-1727", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"lems by considering soft semantic scores to perform group-\\ning instead of hard one-hot semantic predictions. The intu-\\ntion of SoftGroup is illustrated in Figure 2. Our finding is\\nthat the object parts with wrong semantic predictions still\\nhave reasonable scores for the true semantic class. Soft-\\ngroup relies on a score threshold to determine which cate-\\ngory the object belongs instead of the argument max values.\\nGrouping on the soft semantic scores produces for accurate\\ninstance on true semantic class. The instance with wrong\\nsemantic prediction will be suppressed by learning to cate-\\ngorize it as background. To this end, we treat an instance\\nproposal as either a positive or negative sample depending\\non the maximum Intersection over Union (IoU) with the\\nground truth, then construct a top-down refinement stage\\nto refine the positive sample and suppress the negative one.\\nAs shown in Figure 1, SoftGroup is able to produce accurate\\ninstance masks from imperfect semantic prediction.\\n\\nSoftGroup is conceptually simple and easy to imple-\\nment. Experiments on the ScanNet v2 [6] and S3DIS [1]\\nbenchmark datasets show the efficacy of our method. No-\\ntably, SoftGroup outperforms the previous state-of-the-art\\nmethod by a significant margin of +6.2% on the ScanNet\\nhidden test set and +6.8% on S3DIS Area 5 in terms of\\nAP$_{50}$. SoftGroup is fast, requiring 345ms to process a Scan-\\nNet scene. In summary, our contribution is threefold.\\n\\n\u2022 We propose SoftGroup that performs grouping on soft\\nsemantic scores to avoid error propagation from hard\\nsemantic predictions to instance segmentation.\\n\u2022 We propose a top-down refinement stage to correct, re-\\nfine the positive samples and suppress false positives\\nintroduced by wrong semantic predictions.\\n\u2022 We report extensive experiments on multiple datasets\\nwith different evaluation metrics, showing significant\\nimprovements over existing state-of-the-art methods.\\n\\n2. Related work\\n\\nDeep Learning on 3D Point Clouds.\\nPoint cloud representation is a common data format for 3D scene understand-\\ning. To process point clouds, early methods [2,3,36,37] ex-\\ntract hand-crafted features based on statistical properties of\\npoints. Recent deep learning methods learn to extract fea-\\ntures from points. PointNet-based methods [32,33] propose\\nto process points through shared Multi-Layer Perceptron\\n(MLP) and then aggregate regional and global features from\\nsymmetric function, such as max-pooling. Convolution\\nmethods are actively explored for point clouds processing.\\nContinuous convolution methods [23, 40, 44, 45] learn the\\nkernels which are associated to the spatial distribution of lo-\\ncal points. Discrete convolution methods [5,8,13,19,25,34]\\nlearn the kernels which are regular grids obtaining from\\npoint quantization. Transformers [18, 50] and graph-based\\nmethods [38, 39, 43] are also proposed to address the data\\nirregularity of point clouds.\\n\\nProposal-based Instance Segmentation.\\nProposal-based methods consider a top-down strategy that generates\\nregion proposals and then segments the object within each\\nproposal. Existing proposal-based methods for 3D point\\nclouds are highly influenced by the success of Mask-R\\nCNN for 2D images. To handle data irregularity of point\\nclouds, Li et al. [47] propose GSPN, which takes an\\nanalysis-by-synthesis strategy to generate high-objectness\\n3D proposals, which are refined by a region-based PointNet.\\nHou et al. [12] present 3DSIS that combines multi-view\\nRGB input with 3D geometry to predict bounding boxes\\nand instance masks. Yang et al. [46] propose 3D-BoNet\\nwhich directly outputs a set of bounding boxes without\\nanchor generation and non-maximum suppression, then\\nsegments the object by a pointwise binary classifier. Liu et\\nal. [22] present GICN to approximate the instance center of\\neach object as a Gaussian distribution, which is sampled to\\nget object candidates then produce corresponding bounding\\nboxes and instance masks.\\n\\nGrouping-based Instance Segmentation.\\nGrouping-based methods rely on a bottom-up pipeline that produces\\nper-point predictions (such as semantic maps, and geo-\\nmetric shifts, or latent features) then groups points into\\ninstances. Wang et al. [41] propose SGPN to construct a\\nfeature similarity matrix for all points and then group points\\nof similar features into instances. Pham et al. [29] present\\nJSIS3D that incorporates the semantic and instance labels\\nby a multi-value conditional random field model and jointly\\noptimizes the labels to obtain object instances. Lahoud et\\nal. [17] propose MTML to learn feature and directional\\nembedding, then perform mean-shift clustering on the\\nfeature embedding to generate object segments which are\\nscored according to their direction feature consistency. Han et\\nal. [9] introduce OccuSeg that performs graph-based\"}"}
{"id": "CVPR-2022-1727", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3. The architecture of the proposed method consists of bottom-up grouping and top-down refinement stages. From the input point clouds, the U-Net backbone extracts the point features. Then semantic and offset branches predict the semantic scores and offset vectors, followed by a soft grouping module to generate instance proposal. The feature extractor layer extracts backbone features from instance proposals. The features for each proposal are fed into a tiny U-Net followed by the classification, segmentation, and mask scoring branches to get the final instances.\\n\\nClustered guided by object occupancy signal for more accurate segmentation outputs. Zhang et al. [48] consider a probabilistic approach that represents each point as a tri-variate normal distribution followed by a clustering step to obtain object instances. Jiang et al. [15] propose PointGroup to segment objects on original and offset-shifted point sets, relying on a simple yet effective algorithm that groups nearby points of the same label and expands the group progressively. Chen et al. [4] extend PointGroup and propose HAIS that further absorbs surrounding fragments of instances and then refines the instances based on intra-instance prediction. Liang et al. [20] SSTNet to construct a tree network from pre-computed superpoints then traverse the tree and split nodes to get object instances.\\n\\nThe common proposal-based and grouping-based methods have their advantages and drawbacks. Proposal-based methods process each object proposal independently that is not interfered with by other instances. Grouping-based methods process the whole scene without proposal generation, enabling fast inference. However, proposal-based methods have difficulties in generating high-quality proposals since the point only exists on the object surface. Grouping-based methods highly depend on semantic segmentation such that the errors in semantic predictions are propagated to instance predictions. The proposed method leverages the advantages and address the limitations of both approaches. Our method is constructed as a two-stage pipeline, where the bottom-up stage generates high-quality object proposals by grouping on soft semantic scores, and then the top-down stage process each proposal to refine positive samples and suppress negative ones.\\n\\n3. Method\\n\\nThe overall architecture of SoftGroup is depicted in Figure 3, which is divided into two stages. In the bottom-up grouping stage, the point-wise prediction network (Sec. 3.1) takes point clouds the input and produces point-wise semantic labels and offset vectors. The soft grouping module (Sec. 3.2) processes these outputs to produce preliminary instance proposals. In the top-down refinement stage, based on the proposals, the corresponding features from the backbone are extracted and used to predict classes, instance masks, and mask scores as the final results.\\n\\n3.1. Point-wise Prediction Network\\n\\nThe input of the point-wise prediction network is a set of \\\\( N \\\\) points, each of which is represented by its coordinate and color. The point set is voxelized to convert unordered points to ordered volumetric grids, which are fed into a U-Net style backbone [35] to obtain point features. The Submanifold Sparse Convolution [8] is adopted to implement the U-Net for 3D point clouds. From the point features, two branches are constructed to output the point-wise semantic scores and offset vectors.\\n\\n**Semantic Branch.** A semantic branch is constructed from a two-layer MLP and learns to output semantic scores \\\\( S = \\\\{s_1, ..., s_N\\\\} \\\\in \\\\mathbb{R}^{N \\\\times N_{\\\\text{class}}} \\\\) for \\\\( N \\\\) points over \\\\( N_{\\\\text{class}} \\\\) classes. Different from existing methods [4,15], we directly perform grouping on semantic scores without converting the semantic scores to one-hot semantic predictions.\\n\\n**Offset Branch.** In parallel with the semantic branch, we apply a two-layer MLP to learn the offset vectors \\\\( O = \\\\{o_1, ..., o_N\\\\} \\\\in \\\\mathbb{R}^{N \\\\times 3} \\\\), which represents the vector from each point to the geometric center of the instance the point belongs. Based on the learned offset vectors, we shift the points to the center of the corresponding instance to perform grouping more effectively.\\n\\nThe cross-entropy loss and \\\\( \\\\ell_1 \\\\) regression loss are used to train the semantic and offset branches, respectively.\"}"}
{"id": "CVPR-2022-1727", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\\\\[ L = \\\\sum_{i=1}^{N} C(s_i, s^*_{i}) \\\\] (1)\\n\\n\\\\[ L_{\\\\text{offset}} = \\\\sum_{i=1}^{N} \\\\frac{1}{\\\\sum_{j=1}^{N} 1 \\\\{p_i\\\\}} \\\\|o_i - o^*_{i}\\\\|_1 \\\\] (2)\\n\\nwhere \\\\(s^*\\\\) is the semantic label, \\\\(o^*\\\\) is offset label representing the vector from a point to the geometric center of the instance that the point belongs to (analogous to [4, 15, 20]), and \\\\(1 \\\\{p_i\\\\}\\\\) is the indicator function indicating whether the point \\\\(p_i\\\\) belongs to any instance.\\n\\n### 3.2. Soft Grouping\\n\\nThe soft grouping module receives the semantic scores and offset vectors as the input and produces instance proposals. First, the offset vectors are used to shift points toward the corresponding instance centers. To perform grouping using the semantic scores, we define a score threshold \\\\(\\\\tau\\\\) to determine which semantic classes a point belongs to, allowing the point to be associated with multiple classes.\\n\\nGiven semantic scores \\\\(S \\\\in \\\\mathbb{R}^{N \\\\times N_{\\\\text{class}}}\\\\), we iterate through \\\\(N_{\\\\text{class}}\\\\) classes, and at each class index we slice a point subset of the whole scene that has the score (w.r.t. the class index) higher than the threshold \\\\(\\\\tau\\\\). We follow [4, 15] to perform grouping on each point subset. Since all points in each subset belong to the same class, we simply traverse all the points in the subset and create the links between points having a geometric distance smaller than a grouping bandwidth \\\\(b\\\\) to get the instance proposals. For each iteration, the grouping is performed on a point subset of the whole scan, ensuring fast inference. The overall instance proposals are the union of the proposals from all subsets.\\n\\nWe note that existing proposal-based methods [12, 22, 46] commonly consider bounding boxes as object proposals then perform segmentation within each proposal. Intuitively, the bounding box with high overlap with the instance should have the center close to the object center. However, generating high-quality bounding box proposals in 3D point clouds is challenging since the point only exists on object surfaces. Instead, SoftGroup relies on point-level proposals which are more accurate and naturally inherit the scattered property of point clouds.\\n\\nSince the quality of instance proposals from grouping highly depend on the quality of semantic segmentation, we quantitatively analyze the impact of \\\\(\\\\tau\\\\) on the recall and precision of semantic predictions. The recall and precision for class \\\\(j\\\\) is defined as follows.\\n\\n\\\\[ \\\\text{recall}_j = \\\\frac{\\\\sum_{i=1}^{N} (s_{ij} > \\\\tau) \\\\land (s^*_{i} = j)}{s^*_{i} = j} \\\\] (3)\\n\\n\\\\[ \\\\text{precision}_j = \\\\frac{\\\\sum_{i=1}^{N} (s_{ij} > \\\\tau) \\\\land (s^*_{i} = j)}{s_{ij} > \\\\tau} \\\\]\\n\\n**Figure 4.** The recall and precision of semantic prediction with varying score threshold \\\\(\\\\tau\\\\). The dashed lines denote the recall and precision with hard semantic prediction.\\n\\nFigure 4 shows the recall and precision (averaged over classes) with the varying score thresholds \\\\(\\\\tau\\\\) compared with those of hard semantic prediction. With hard semantic prediction, the recall is 79.1%, indicating more than 20% amount of points over classes are not covered by the predictions. When using the score threshold, the recall increases as the score threshold decreases. However, the small score threshold also leads to low precision. We propose a top-down refinement stage mitigate the low precision problems. The precision can be interpreted as the relation between foreground and background points of object instances. We set the threshold to 0.2 with precision near 50%, leading to the ratio between foreground and background points for ensuring stage is balanced.\\n\\n### 3.3. Top-Down Refinement\\n\\nThe top-down refinement stage classifies and refines the instance proposals from the bottom-up grouping stage. A feature extractor layer processes each proposal to extract its corresponding backbone features. The extracted features are fed into a tiny U-Net network (a U-Net style network with a small number of layers) before predicting classification scores, instance masks, and mask scores at the ensuing branches.\\n\\n**Classification Branch.** The classification branch starts with a global average pooling layer to aggregate the feature of all points in the instance, followed by a MLP to predict the classification scores \\\\(C = \\\\{c_1, \\\\ldots, c_K\\\\} \\\\in \\\\mathbb{R}^{K \\\\times (N_{\\\\text{class}} + 1)}\\\\), where \\\\(K\\\\) is the number of instances. We directly derive the object category and classification confidence score from the output of the classification branch.\\n\\nWe note that existing grouping-based methods typically derive the object category from semantic predictions. However, instances may come from objects with noisy semantic predictions. The proposed method directly uses the output of the classification branch as the instance class. The classification branch aggregates all point features of the instance and classifies the instance with a single label, leading to more reliable predictions.\"}"}
{"id": "CVPR-2022-1727", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As shown in Section 3.2, the instance proposals contain both foreground and background points, we construct a segmentation branch to predict an instance mask within each proposal. The segmentation branch is a point-wise MLP of two layers that output an instance mask $m_k$ for each instance $k$.\\n\\nThe mask scoring branch shares the same structure as the classification branch. This branch outputs the mask scores $E = \\\\{e_1, \\\\ldots, e_K\\\\} \\\\in \\\\mathbb{R}^{K \\\\times N_{class}}$, which estimate the IoU of a predicted mask with the ground truth. The mask score is combined with the classification score by multiplication to get the final confidence score.\\n\\n**Learning Targets.**\\nTraining the top-down refinement branches requires the target labels for each branch. To this end, we follow the logic in existing 2D object detection and segmentation methods. We treat all instance proposals having IoU with a ground-truth instance higher than 50% as the positive samples and the rest as negatives. Every positive sample is assigned to a ground-truth instance with the highest IoU. The classification target of a positive sample is the category of the corresponding ground-truth instance. The total number of classes is $N_{class} + 1$ ($N_{class}$ foreground classes and one background class). The segmentation and mask scoring branches are trained on positive samples only. The mask target of a positive sample is the mask of the assigned ground-truth instance. The mask score target is the IoU between the predicted mask and the ground truth. The training loss of these branches is the combination of cross-entropy, binary cross-entropy, and $\\\\ell_2$ regression losses, following [10, 14].\\n\\n$$L_{class} = 1_K \\\\sum_{k=1}^K \\\\text{CE}(c_k, c^*_k),$$  \\\\hspace{1cm} (4)\\n\\n$$L_{mask} = \\\\frac{1}{K} \\\\sum_{k=1}^K \\\\text{BCE}(m_k, m^*_k),$$  \\\\hspace{1cm} (5)\\n\\n$$L_{mask\\\\text{score}} = \\\\frac{1}{K} \\\\sum_{k=1}^K \\\\|e_k - e^*_k\\\\|_2.$$  \\\\hspace{1cm} (6)\\n\\nHere, $c^*_k, m^*_k, e^*_k$ are the classification, segmentation, and mask scoring targets, respectively. $K$ is the total number of proposals and $\\\\{\\\\}$. indicates whether the proposal is a positive sample.\\n\\n### 3.4. Multi-task Learning\\nThe whole network can be trained in an end-to-end manner using a multi-task loss.\\n\\n$$L = L_{semantic} + L_{offset} + L_{class} + L_{mask} + L_{mask\\\\text{score}},$$  \\\\hspace{1cm} (7)\\n\\nwhere $L_{semantic}$ and $L_{offset}$ are the semantic and offset losses defined at subsection Section 3.1 while $L_{class}, L_{mask}$ and $L_{mask\\\\text{score}}$ are the classification, segmentation and mask score losses defined at Section 3.3.\\n\\n### 4. Experiments\\n\\n#### 4.1. Experimental Settings\\n\\n**Datasets.** The experiments are conducted on standard benchmarked ScanNet v2 [6] and S3DIS [1] dataset. The ScanNet dataset contains 1613 scans which is divided into training, validation, and testing sets of 1201, 312, 100 scans, respectively. Instance segmentation is evaluated on 18 object classes. Following existing methods, the benchmarked results are reported on the hidden test split. The ablation study is conducted on the validation set.\\n\\nThe S3DIS dataset contains 3D scans of 6 areas with 271 scenes in total. The dataset consists of 13 classes for instance segmentation evaluation. Following existing methods, two settings are used to evaluate the instance segmentation results: testing on Area 5 and 6-fold cross-validation.\\n\\n**Evaluation Metrics.** The evaluation metric is the standard average precision. Here, AP$_{50}$ and AP$_{25}$ denote the scores with IoU thresholds of 50% and 25%, respectively. Likewise, AP denotes the averaged scores with IoU threshold from 50% to 95% with a step size of 5%. Additionally, the S3DIS is also evaluated using mean coverage ($mCov$), mean weighed coverage ($mWCov$), mean precision ($mPrec$), and mean recall ($mRec$).\\n\\n**Implementation Details.** The implementation details follow those of existing methods [4, 15]. The model is implemented using PyTorch deep learning framework [28] and trained on 120k iterations with Adam optimizer [16]. The batch size is set to 4. The learning rate is initialized to 0.001 and scheduled by a cosine annealing [24]. The voxel size and grouping bandwidth $b$ are set to 0.02m and 0.04m, respectively. The score threshold for soft grouping $\\\\tau$ is set to 0.2. At training time, the scenes are randomly cropped at a maximum number of points of 250k. At inference, the whole scene is fed into the network without cropping. For the S3DIS with high point density, scenes are randomly downsampled at a ratio of 1/4 before cropping. At inference, the scene is divided into four parts before feeding into the model, and then the features of these parts are merged right after the U-Net backbone. The ensuing components process the merged features as those on ScanNet dataset.\\n\\nWe note that the source code and trained models for existing high-performing methods are publicly available on ScanNet v2 only. In this work, the source code and trained models on both ScanNet v2 and S3DIS will be released to support result reproducibility.\"}"}
{"id": "CVPR-2022-1727", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Method         | AP 50 | GSPN | 3D-SIS | MASC | PanopticFusion | 3D-Bonet | MTML | 3D-MPA | Dyco3D | PE | PointGroup | GICN | OccuSeg | SSTNet | HAIS | SoftGroup (Ours) |\\n|---------------|-------|------|--------|------|---------------|----------|------|--------|--------|----|------------|------|---------|--------|------|-----------------|\\n| SEMANTIC GT   |       |      |        |      |               |          |      |        |        |    |            |      |         |        |      |                 |\\n| SEMANTIC PRED |       |      |        |      |               |          |      |        |        |    |            |      |         |        |      |                 |\\n| INSTANCE PRED |       |      |        |      |               |          |      |        |        |    |            |      |         |        |      |                 |\\n| INSTANCE GT   |       |      |        |      |               |          |      |        |        |    |            |      |         |        |      |                 |\\n\\nTable 1. 3D instance segmentation results on ScanNet v2 hidden test set in terms of AP 50 scores. The proposed SoftGroup achieves the highest average AP 50, outperforming the previous strongest method by a significant margin. Reported results are from the ScanNet benchmark on 13/11/2021.\\n\\n4.2. Benchmarking Results\\n\\nScanNet v2. Table 1 shows the results of SoftGroup and recent state-of-the-art methods on the hidden test set of ScanNet v2 benchmark. We submit our model and report the results from the server. The proposed SoftGroup achieves the highest average AP 50 of 76.1%, surpassing the previous strongest methods a significant margin of 6.2%.\\n\\nRegarding class-wise scores, our method achieves the best performance in 12 out of 18 classes.\\n\\nS3DIS. Table 2 summaries the results on Area 5 and 6-fold cross-validation of S3DIS dataset. On both Area 5 and cross-validation evaluations, the proposed SoftGroup achieves higher overall performance compared to existing method. Notably, on Area 5 evaluation, SoftGroup achieves AP/AP 50 of 51.6/66.1(%), which is 8.9/6.8(%) improvement compared to the second-best. The state-of-the-art performance on both ScanNet v2 and S3DIS datasets shows the generalization advantage of our method.\\n\\nSegmentation and Detection Results. We further report the instance segmentation and object detection results on ScanNet v2 validation set. To obtain object detection results, we follow the approach in [7] to extract a tight axis-aligned bounding box from the predicted point mask. Table 3 reports the instance segmentation and object detection results. Our method achieves significant improvement compared to the second-best by 3.2, 3.3, 6.3, and 7.3(%) of AP 50, AP 25, box AP 50, and box AP 25, respectively.\"}"}
{"id": "CVPR-2022-1727", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2. 3D instance segmentation results on S3DIS dataset. Methods marked with \u2020 are evaluated on Area 5, and methods marked with \u2021 are evaluated on 6-fold cross validation.\\n\\n| Method     | AP 50 | AP 25 | Box AP 50 | Box AP 25 |\\n|------------|-------|-------|-----------|-----------|\\n| SGPN       | 50    | 50    | 50        | 50        |\\n| ASIS       | 50    | 50    | 50        | 50        |\\n| PointGroup | 50    | 50    | 50        | 50        |\\n| SSTNet     | 50    | 50    | 50        | 50        |\\n| HAIS       | 50    | 50    | 50        | 50        |\\n| SoftGroup  | 50    | 50    | 50        | 50        |\\n\\nTable 3. Instance segmentation and object detection results on ScanNet v2 validation set. Our method achieves better results on both mask and box AP.\\n\\nTable 4. Inference time per scan of different methods on ScanNet v2 validation set. For a fair comparison, the runtime is measured on the same Titan X GPU model. The inference time of our method is 345ms per scan, which is extra 6ms over the fastest model. Regarding our component-time, the point-wise prediction network, soft grouping algorithm, and top-down refinement latencies are 152ms, 132ms, and 70ms, respectively. The results show that our method achieves high accuracy while remaining computationally efficient.\\n\\n4.3. Qualitative Analysis\\n\\nFigure 5 shows the visualization examples from ScanNet v2 dataset. Without SoftGroup, the semantic prediction errors are propagated to instance segmentation predictions. In contrast, SoftGroup effectively corrects the semantic prediction errors and thus generates more accurate instance masks.\\n\\n4.4. Ablation Study\\n\\nComponent-wise Analysis. We provide experimental results of SoftGroup when different components are omitted. The considered baseline is a model with hard grouping and the confidence scores of output instances are ranked by a ScoreNet branch [15, 20]. Table 5 shows the ablation results. The baseline achieves 39.5/61.1/75.5(%) in terms of AP/AP 50/Box AP 50. Significant improvement is obtained by either applying soft grouping or top-down refinement. Combining these two components achieves the best overall performance AP/AP 50/Box AP 50 of 46.0/67.6/78.9(%), which is 2714 times better than the baseline.\"}"}
{"id": "CVPR-2022-1727", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5. Component-wise analysis on ScanNet v2 validation set. Our model achieves significant improvement over the baseline.\\n\\nTable 6. Ablation experiments on varying score threshold $\\\\tau$ for soft grouping. \\\"None\\\" denotes the threshold is not used, and the hard semantic prediction is used for grouping. The baseline is with $\\\\tau$ being \\\"None\\\", indicating the threshold is deactivated and the hard predicted label is used for grouping. The baseline achieves AP/AP$_{50}$/AP$_{25}$ of 44.3/65.4/78.1(%). When $\\\\tau$ is too high or too low the performance is even worse than the baseline. The best performance is obtained at $\\\\tau$ of 0.2, which confirms our analysis at the Section 3.2, where the number of positive and negative samples are balanced.\\n\\nTop-Down Refinement. We further provide the ablation results on the top-down refinement, on Table 7. With only the classification branch, our method achieves AP/AP$_{50}$/AP$_{25}$ of 41.1/64.6/79.7(%). When mask branch and mask scoring branch are in turn applied, the performance tends to improve on the higher IoU threshold regions. Combining all branches yields the performance AP/AP$_{50}$/AP$_{25}$ of 46.0/67.6/78.9(%).\\n\\nTable 7. The impact of each branch in top-down refinement on ScanNet v2 validation set.\\n\\nTable 8. Ablation study on instance category. \\\"N\\\" indicates that the instance category is taken from majority vote of semantic prediction. \\\"Y\\\" indicates that the instance category is taken from classification branch output of the classification branch as the instance class. The classification branch aggregates all point features of the instance and classifies the instance with a single label, leading to more reliable prediction. The results show that directly using classification output as object category improves the AP/AP$_{50}$/AP$_{25}$ to 46.0/67.6/78.9(%).\\n\\n5. Conclusion\\n\\nWe have presented SoftGroup, a simple yet effective method for instance segmentation on 3D point clouds. SoftGroup performs grouping on soft semantic scores to address the problem stemming from hard grouping on locally ambiguous objects. The instance proposals obtained from the grouping stage are assigned to either positive or negative samples. Then a top-down refinement stage is constructed to refine the positives and suppress the negatives. Extensive experiments on different datasets show that our method outperforms the existing state-of-the-art method by a significant margin of +6.2% on the hidden ScanNet v2 test set and +6.8% on S3DIS Area 5 in terms of AP$_{50}$.\\n\\nAcknowledgements\\n\\nThis work was partly supported by Institute for Information communications Technology Planning Evaluation(IITP) grant funded by the Korea government(MSIT) (2021-0-01381, Development of Causal AI through Video Understanding, and partly supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-01371, Development of brain-inspired AI with human-like intelligence).\\n\\n2715\"}"}
