{"id": "CVPR-2024-210", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Balancing Act: Distribution-Guided Debiasing in Diffusion Models\\n\\nRishubh Parihar, Abhijnya Bhat, Abhipsa Basu, Saswat Mallick, Jogendra Nath Kundu, R. Venkatesh Babu\\n\\n1 Indian Institute of Science, Bangalore\\n2 Meta Reality Labs\\n\\nAbstract\\n\\nDiffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (e.g., female vs male). In this work, we present a method for debiasing DMs without relying on additional reference data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by augmenting the training set with our generated data.\\n\\nCode is available at - project page.\\n\\n1. Introduction\\n\\nRecent advancements in Diffusion Models (DM) [12, 37, 47] have garnered much interest among researchers in evaluating the quality of the generated content. These models are not only used to generate realistic content but also to augment real datasets [27, 50] for downstream tasks. However, existing DMs have been found to synthesize biased content with respect to multiple demographic factors like gender, race, etc., which can be detrimental to society once these models are deployed in the real world [24, 32, 38].\\n\\n* Equal contribution\\n\\nFigure 1.\\n\\na) Random sampling from a pretrained DM [37] generates images with gender imbalance.\\nb) Proposed method takes a user-defined reference attribute \\\\( p_{ref} \\\\) and performs distribution guidance on a pretrained DM.\\nc) Sampling with distribution guidance results in fair generation that follow user define \\\\( p_{ref} \\\\).\\n\\nThe problem is largely caused by the images used to train these models, as the outputs of these models are governed by these training datasets [25, 32]. Effects of such harmful biases have been shown by multiple recent works involving studies on DMs [24, 32, 38], GANs and other generative models [5, 13, 25]. In fact, Perera et al. [32] show that unconditional DMs\u2014even when trained with balanced data\u2014amplify racial biases, leading to the generation of more white-skinned faces than dark-skinned ones. Biases in the generated data are even more evident in large text-to-image DMs, e.g., models mostly tend to generate a specific gender with a given profession (like male and doctor) [26, 44, 57].\\n\\nExisting works on debiasing, either require a reference dataset [5, 57] and/or allow retraining of the model [5, 55, 44] to achieve a fair output. To address this issue, we present Distribution Guidance for debiasing DMs.\\n\\nDistribution Guidance enforces the generated images to follow the prescribed attribute distribution. To realize this, we leverage the latent features of denoising UNet to perform attribute distribution guidance. The distribution predictor is trained with pseudo labels generated from existing attribute classifiers.\\n\\nThe proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models.\"}"}
{"id": "CVPR-2024-210", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"On the contrary, our work aims to mitigate biases in both unconditional and conditional DMs, enabling fair generation without model retraining. We propose a practical setting where we provide a reference attribute distribution \\\\( p_{a_{\\\\text{ref}}} \\\\) for sensitive attribute \\\\( a \\\\) and query the DM to sample images following \\\\( p_{a_{\\\\text{ref}}} \\\\). This framework allows for adapting any existing DM to a pre-defined distribution. E.g., a user can provide \\\\( p_{a_{\\\\text{ref}}} \\\\) as a uniform distribution for a given sensitive attribute to generate balanced attribute distribution. We believe defining \\\\( p_{a_{\\\\text{ref}}} \\\\) provides just enough information to condition the DM for fair generation. This is an extremely practical setting for debiasing and is particularly important for large text-to-image DMs [35, 37, 41] where retraining or fine-tuning is computationally intensive.\\n\\nOne plausible approach for fair generation is to guide every generated sample with attribute classifiers following classifier guidance [8]. However, such a framework, though simple, is overly restrictive as it requires presetting and enforcing attributes for each sample individually (which we call sample guidance). Such constraints during denoising result in inferior generation quality, as discussed in Sec. 4.1. Instead, we propose to jointly denoise a whole batch of samples and guide the process with \\\\( p_{a_{\\\\text{ref}}} \\\\) (which we call distribution guidance). Specifically, we push the generated batch attribute distribution \\\\( p_{a_{\\\\theta}} \\\\) and \\\\( p_{a_{\\\\text{ref}}} \\\\) close to each other during the reverse process. Distribution guidance provides more flexibility to each sample during generation as it does not enforce a preset of attributes on a sample basis. Intuitively, distribution guidance prioritizes transforming easier samples close to the decision boundary. This results in fair generation without sacrificing the generation quality.\\n\\nA major challenge for guidance-based conditioning is that it requires separate image classifiers for each noise scale of the diffusion process. To overcome this, we propose to perform guidance in a semantically rich feature space - \\\\( h\\\\)-space [21] of DMs. Specifically, we train an Attribute Distribution Predictor (ADP) that predicts attribute distribution directly from the \\\\( h\\\\)-space features. As ADP is trained on rich and discriminative \\\\( h\\\\)-space features, it - a) is implemented as a linear layer, b) requires minimal training data, and c) is fast in training and inference. Finally, during inference, we steer the \\\\( h\\\\)-space representation by matching the predictions from ADP to \\\\( p_{a_{\\\\text{ref}}} \\\\).\\n\\nWe extensively evaluate our proposed method for the fair generation of single and multi-attribute cases for face generation. Additionally, we present the results of our method on Stable Diffusion [37], a large text-to-image DM. Further, as downstream application train debiased attribute classifiers by augmenting the training data for minority subgroups.\\n\\nThe major contributions of this work are the following:\\n\\n1. A novel setting for debiasing existing DMs without retraining, given a reference attribute distribution.\\n2. Distribution guidance to condition the reverse diffusion process on a reference attribute distribution.\\n3. Propose guidance in the intermediate features of diffusion network (\\\\( h\\\\)-space), which leads to data-efficient training and fast generation.\\n\\nRelated Works\\n\\nBiases in Generative Models: While generative models like Generative Adversarial Networks and Diffusion Models have become the de-facto tools for image generation in recent times, studies show that they are not free of biases [14, 24, 25, 32, 38]. Perera et al. [32] show that unconditional diffusion models amplify the biases in the training data with respect to gender, race, and age. Luccioni et al. [24] identify and quantify social biases in images generated by popular text-to-image models like DALL-E 2, and Stable Diffusion v1.4 and 2. Maluleke et al. [25] study racial biases in GANs and find that GANs mimic the racial distribution in the training data.\\n\\nDebiasing generative models by retraining. This line of work focuses on mitigating biases in generative models by retraining them [5, 30, 43, 49, 51, 52, 55, 56]. Some of these works [43, 52, 55] assume knowledge of the labels of the sensitive attribute and then debias the models such that there is no correlation between the decision attribute and the sensitive attribute. IMLE-GAN [56] ensures coverage of minority groups by combining GAN adversarial training with Implicit Maximum Likelihood Estimation (IMLE) [23]. Another body of works employs a balanced unlabelled reference dataset to ensure unbiased generations [5, 49, 51]. Choi et al. [5] use a density-ratio based technique to identify the bias in datasets via the reference dataset, and learn a fair model based on importance reweighting with the help of both the original biased and the reference dataset. To capture the distance between the small reference data and the generated data, Um et al. [51] use the LeCam Divergence [22]. On the other hand, Teo et al. [49] introduce a transfer learning approach to solve this problem by training the model on the biased dataset first and then adapting the model to the reference set.\\n\\nDebiasing generative models without training. As training of GANs and DMs can be resource-consuming, many methods prefer fair generation of images without explicit training [13, 27, 34, 48]. MaGNET [13] aims to produce uniform sampling on the learned manifold of any generative model like GANs or V AEs, while Ramaswamy et al. [34] and Tan et al. [48] manipulate the latent space of GANs to generate balanced outputs. GANDiffFace [27], on the other hand, generates balanced synthetic for face recognition by first generating high-quality images from different demographics using GANs and then finetuning Stable Diffusion [37] using DreamBooth [39] to generate more images of such identities with different poses, expressions, etc. Multiple works attempt to mitigate biases in vision-language models and text-conditioned diffusion models.\"}"}
{"id": "CVPR-2024-210", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Chuang et al. [6] debias the text embedding using a calibrated projection matrix and shows unbiased generations without any additional training or data. However, debiasing the unconditional DMs has received less attention, which is the main focus of this work.\\n\\nGuidance in Diffusion Models\\n\\nOne of the primary techniques to condition the diffusion model is to guide the reverse diffusion model with the gradients of additional networks [8]. GLIDE [31] used CLIP [33] based guidance for open world caption to image generation. Guidance is used for image-to-image translation [54], counterfactual generation [42]. However, guidance in its original form requires retraining of guiding networks on the noisy data from scratch. Few works overcome this by learning a mapping function from the diffusion feature space to sketches for sketch-guidance [53] and a universal guidance that re-purposes pretrained networks for guidance [1].\\n\\n3. Method\\n\\nWe assume a setting where we are given a pretrained DM trained on biased data and a reference distribution of the sensitive attributes \\\\( p_{a_{\\\\text{ref}}} \\\\). Our goal is to generate data from the DM, whose generated attribute distribution \\\\( p_{a_{\\\\theta}} \\\\) best approximates the reference \\\\( p_{a_{\\\\text{ref}}} \\\\) without retraining. The key idea is to jointly guide the denoising of a batch of samples such that \\\\( p_{a_{\\\\text{ref}}} \\\\approx p_{a_{\\\\theta}} \\\\).\\n\\nDirectly computing \\\\( p_{a_{\\\\theta}} \\\\) in a closed form is intractable. Instead, we train an Attribute Distribution Predictor, a linear projection that maps the intermediate batch features from the h-space of a denoising network to an estimate of attribute distribution \\\\( \\\\hat{p}_{a_{\\\\theta}} \\\\).\\n\\n3.1. Preliminary\\n\\nDiffusion models have emerged as a powerful family of generative models trained to learn the data distribution by gradual denoising from a Gaussian distribution. Starting from a clean point \\\\( x_0 \\\\), and a set of scalar values \\\\( \\\\{\\\\alpha_t\\\\}_{t=1}^T \\\\), applying \\\\( t \\\\) steps of the forward diffusion process yields a noisy data point \\\\( x_t \\\\), where \\\\( \\\\bar{\\\\alpha}_t = \\\\sum_{i=1}^Q \\\\alpha_i \\\\) and \\\\( x_t = \\\\sqrt{\\\\bar{\\\\alpha}_t} x_0 + (\\\\sqrt{1-\\\\bar{\\\\alpha}_t}) \\\\epsilon \\\\), \\\\( \\\\epsilon \\\\approx N(0, I) \\\\).\\n\\nA diffusion model is learned as a neural network \\\\( \\\\epsilon_{\\\\theta} \\\\) that predicts the noise from given \\\\( x_t \\\\) and \\\\( t \\\\). The reverse process takes the form \\\\( q(x_{t-1}|x_t, x_0) \\\\), which is parameterized as a Gaussian distribution. In this work, we consider DDIM [47] sampling which first computes an estimate of the clean data point \\\\( \\\\hat{x}_0 \\\\) and then sample \\\\( x_{t-1} \\\\) from \\\\( q(x_{t-1}|x_t, \\\\hat{x}_0) \\\\).\\n\\nClassifier guidance is proposed to condition a diffusion model on class labels with the help of a pretrained classifier [8]. Specifically, a classifier \\\\( f_{\\\\phi}(c| x_t, t) \\\\) is trained on noisy images to predict the class label \\\\( c \\\\). The gradients of the classifier are used to guide the diffusion sampling process to generate an image of the prescribed class \\\\( c \\\\). Concretely, the classifier guidance performs sampling by updating the noise prediction \\\\( \\\\hat{\\\\epsilon}_{\\\\theta}(x_t, t) \\\\) as follows:\\n\\n\\\\[\\n\\\\hat{\\\\epsilon}_{\\\\theta}(x_t, t) = \\\\epsilon_{\\\\theta}(x_t, t) - \\\\sqrt{1-\\\\alpha_t} \\\\nabla_{x_t} \\\\log f_{\\\\phi}(c|x_t, t) \\\\]\\n\\n3.2. Classifier guidance for debiasing\\n\\nA promising approach is to leverage pretrained attribute classifiers to guide towards balanced generation. Assuming a reference attribute distribution \\\\( p_{a_{\\\\text{ref}}} \\\\) for a binary attribute \\\\( a \\\\) (e.g., gender) and corresponding attribute classifier \\\\( f_{\\\\phi} \\\\), we parameterize \\\\( p_{a_{\\\\text{ref}}} \\\\) as a Bernoulli distribution with parameter \\\\( r \\\\) denoting fraction of male samples. To generate samples following \\\\( p_{a_{\\\\text{ref}}} \\\\), we can randomly select \\\\( N_r \\\\) samples from the batch size of \\\\( N \\\\) and guide them towards male class using predictions from \\\\( f_{\\\\phi} \\\\). Similarly, for the remaining \\\\( N(1-r) \\\\) samples, we guide them towards female class.\\n\\nIn practice, such a sample guidance follows \\\\( p_{a_{\\\\text{ref}}} \\\\) up to some extent, but results in inferior sample quality (see Fig. 3b).\\n\\nInsight 1:\\n\\nTransforming samples close to the decision boundary is easier and results in higher quality generation.\\n\\nRemark:\\n\\nWe performed an insightful experiment for changing gender attribute (female to male) using classifier guidance. We group the samples in four quantiles based on their distance from the decision boundary of a pre-trained gender classifier in Fig. 2a). Next, we perform sample-based guidance over the samples from each quantile in Fig. 2b). The samples which are close to the decision boundary (quantiles Q1 and Q2) are easily transformed with guidance, whereas the samples away from the decision boundary (quantiles Q3 and Q4) are distorted during the guidance process. This is also quantified with the quantile-wise FID against a real set (of male images), where the samples from Q1/Q2 have better FID after conversion.\\n\\nInsight 2:\\n\\nAttempting to steer the generation of individual samples towards a pre-defined attribute class is overly restrictive and leads to inferior generation quality.\\n\\nRemark:\\n\\nSample guidance requires enforcing a preset attribute state (male/female) to each sample of a batch during the denoising process, which is too stringent and results in distorting the outputs. This is particularly bad in the case when samples from quantiles Q4 are selected for transformation, as shown in Fig. 2. Given an intermediate time-stamp \\\\( \\\\tau \\\\), the samples in the earlier stages (\\\\( t > \\\\tau \\\\)) of the reverse diffusion process are close to the noise space, resulting in the poor classifier of the corresponding stages. The guidance becomes effective only in the later stage of denoising (\\\\( t < \\\\tau \\\\)). However, till timestep \\\\( \\\\tau \\\\), some facial features are...\"}"}
{"id": "CVPR-2024-210", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Training of Attribute Feature Projector (AFP)\\n\\nExtracted UNet Features\\n\\nDiffusion Model\\n\\nAFP\\n\\nAttributes\\n\\nPredicted\\n\\na 3\\n\\na 2\\n\\na 1\\n\\na 0\\n\\nGlass\\n\\nSmile\\n\\nMale\\n\\nOld\\n\\nwith Guidance\\n\\nb)\\n\\na)\\n\\nSample Guidance\\n\\nDistribution Guidance\\n\\nMale\\n\\nFemale\\n\\nSample has formed dominant female reference, i.e., we guide the batch of samples to bring \\\\( \\\\hat{p} \\\\) the batch samples to an estimate of generated attribute distribution \\\\( p \\\\). During denoising, we measure the similarity of two distributions. During denoising network instead of \\\\( \\\\epsilon \\\\), we define a loss function \\\\( \\\\mathcal{L} \\\\) of denoising network instead of classifying the generated image as shown in Fig. 5. Hence, we use the trained fusion U-Net, termed as the \\\\( h \\\\)-space feature space -\\n\\nAttribute Distribution Predictor that maps the batch samples and transforms easier samples close to the decision boundary to match the required distribution. Distribution guidance provides flexibility to modify the attribute states during the denoising process. The key idea is to use the intermediate semantic features from the diffusion model instead of image space for efficiency (Sec.3.4). Hence, the batch estimate is given by, \\\\( \\\\hat{p} \\\\) the batch samples to an estimate of generated attribute distribution \\\\( p \\\\). For e.g., for gender attribute, if a differentiable distribution prediction function \\\\( g \\\\) has been successfully used for segmentation [2] and classification. The trained classifiers achieve good classification performance across multiple attributes, as shown in Fig. 5. Hence, we use the trained h-space classifiers.\\n\\nDistribution Guidance\\n\\n3.3. Distribution Guidance\\n\\nInsight.3\\n\\nRemark:\\n\\nAs distribution guidance does not require pre-defined exact distribution, it is overly restrictive, which is a major design decision for implementing distribution guidance. To realize distribution guidance, we define a refinement function \\\\( \\\\psi \\\\) that maps \\\\( \\\\theta \\\\) to conversion enforcing samples with dominant features to also change. However, distribution guidance majorly transforms samples close to the decision boundary (Q1/Q2), whereas images with sample guidance looking without any distortion, whereas images with sample guidance\\n\\n...\"}"}
{"id": "CVPR-2024-210", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"$n_t = h_{1:N}^t - \\\\gamma^* \\\\nabla h_{1:N}^t L(\\\\hat{p}_a^\\\\theta, p_{a ref})$\\n\\n$\\\\hat{p}_a^\\\\theta = g_p^\\\\psi(h_{1:N}^t, t)$\\n\\nFinally, we obtain the distribution guided noise predictions $\\\\tilde{\\\\epsilon}$ by passing the $h_{1:N}^t$ through the U-Net decoder $\\\\epsilon_{D \\\\theta}$, i.e., $\\\\tilde{\\\\epsilon}(x_{1:N}^t, t) = \\\\epsilon_{D \\\\theta}(h_{1:N}^t, t)$. The predicted noise is then used to update batch $x_{1:N}^t-1$ using DDIM [47].\\n\\n**Insight 4.** H-space guidance is extremely effective and efficient as compared to image space guidance.\\n\\n**Remark.** As compared to conventional image space guidance, guidance in h-space has multiple advantages: i) it requires only a set of linear layers to implement the classifiers, ii) it is fast to backpropagate during guidance as compared to image models, iii) highly data-efficient and can be trained with only a few thousand examples due to semantically rich h-space. In the experiments section, we compare these properties of the h-space guidance.\\n\\n### Table: Classification Accuracy\\n\\n| Attribute | H-space Classifier | Image Space Classifier |\\n|-----------|--------------------|-----------------------|\\n| Eyeglass  | \u2714                  | \u2714                     |\\n| Gender    | \u2714                  | \u2714                     |\\n| Race      | \u2714                  | \u2714                     |\\n| Eyeglass  | \u2714                  | \u2714                     |\\n| Gender    | \u2714                  | \u2714                     |\\n| Race      | \u2714                  | \u2714                     |\\n\\nFigure 5. Classification accuracy for linear h-space classifiers and ResNet-18 image space classifiers trained on 2K training examples. h-space classifiers are data efficient and achieve superior performance even with a linear layer.\\n\\n### 4.1. Evaluation Metrics\\n\\nA fair generative model is evaluated on two grounds: image quality and fairness. We discuss the metrics used to measure these two aspects of the generated images below.\\n\\n#### Fairness\\n\\nThe primary goal of this paper is to generate images based on the reference distribution $p_{a ref}$. We follow Choi et al. [5] to define the Fairness Discrepancy (FD) metric. Given an attribute $a$, we assume access to a high-accuracy classifier for $a$ (denoted as $C_a$), and using the predictions from the latter, we compute the following [5, 49]:\\n\\n$$||\\\\bar{p} - E_{x \\\\sim p^\\\\theta(x)}(y)||^2_2$$\\n\\nwhere $y$ is the softmax output of the classifier $C_a^\\\\theta(x)$, $\\\\bar{p}$ is a uniform vector of the same dimension as $y$, $p^\\\\theta$ is the distribution of the generated images. The lower the FD score, the closer the distribution of the attribute values is to the uniform distribution \u2013 i.e., the generated images are fairer with respect to attribute $a$.\\n\\n#### Image Quality\\n\\nTo measure the quality of generation, we follow the standard Fr\u00e9chet Inception Distance (FID) [11]. We compute this metric with the help of an attribute-wise balanced dataset sampled from the original training data.\\n\\n### 4.2. Implementation Details\\n\\n#### Training h-space classifiers.\\n\\nWe start with creating a paired dataset $D_{h clf}$ of h-vector and attribute labels. Specifically, we take a subset $D$ of the CelebA-HQ [18] dataset and obtain attribute labels for the images using the pretrained attribute classifier $C_a$. Next, we embed image $I_i \\\\in D$ to obtain the corresponding h-space representation $H_i = \\\\{h_i^t\\\\}_{t=0:T}$ using DDIM [47] inversion. This yields a labelled dataset $D_{h clf}$ with pairs $(H_i, y_i)$, where $y_i = C_a(I_i)$ is the predicted attribute label for image $I_i$ (e.g., male / female).\\n\\nNext, we train h-space attribute classifiers $C_h^a(h_t, t)$ as a linear head over $h_t$ and conditioned on time $t$ (ignored sample index $i$ for brevity). These obtained classifiers generate high-accuracy attribute predictions, as shown in Fig. 5. Further details about the dataset and classifiers are provided in Sec.D of supplement.\\n\\n#### Distribution guidance.\\n\\nTo perform distribution guidance, we realize the distribution prediction function, $ADP$ with h-space classifiers $C_h^a$. Specifically for a generating batch $x_{1:N}^t$, we obtain the corresponding h-space representation $h_{1:N}^t$ and obtain a set of attribute predictions $\\\\hat{y}_{1:N}^t$ from classifiers $C_h^a$. Finally, we add all the softmax values for all the $N$ images in the batch for each class to obtain the estimate of $p_a^\\\\theta$. We use Chi-square distance as the loss $L$ with the reference distribution $p_{a ref}$.\\n\\n#### Diffusion Model Architecture.\\n\\nWe evaluated our proposed debiasing method on two state-of-the-art pretrained DMs: a) an unconditional DM, P2 [4], trained on CelebA-HQ dataset, and b) a text conditional DM StableDiffusion v1.5 [37] trained on the LAION [45] dataset. Both these models have exceptional image generation quality; however, they have significant bias concerning the sensitive face attributes, as shown in the following subsections.\\n\\n### 4.3. Baselines\\n\\nWe compare our proposed method against two techniques for guidance-based generations for DMs, one Latent-based editing method [21], and a state-of-the-art sampling-based technique for debiasing generative models, MagNet [13].\"}"}
{"id": "CVPR-2024-210", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Distribution Guidance balances (close to the ratio of 0.50 : 0.50) both the attributes and generates high-quality images.\\n\\nSample guidance. We use classifier guidance as explained in Sec. 3.2 in the h-space using the trained h-space attribute classifiers \\\\( C_h \\\\). Such guidance requires presetting an attribute state for each generating image and pushing the trajectory to change the attribute state.\\n\\nUniversal guidance \\\\([1]\\\\) performs guidance in the image space but uses pretrained classifiers trained on the clean image. This resolves the additional requirement of training image classifiers on noisy images. The key idea is to use the DDIM scheduler and predict the approximation of \\\\( \\\\hat{x}_0 \\\\) from noise image \\\\( x_t \\\\), and pass it through pretrained image classifier \\\\( C_A \\\\). However, this process has two shortcomings: it is slow as it backpropagates the gradients from the image classifier (Experimentally, we found it to be 7 times slower than h-space guidance) and it performs poorly at the early stage due to an inaccurate approximation of \\\\( x_0 \\\\). We use two settings where we vary the number of images in the training set of the image space attribute classifier: (1) Using the same training set \\\\( |D_{clf}| = 2K \\\\) as the h-space classifier and (2) Using the entire CelebA-HQ dataset, i.e. 30k images.\\n\\nLatent-based Editing \\\\([21]\\\\) generates images with a specific set of attributes. Such a technique is popularly used in debiasing GANs \\\\([16, 34]\\\\) because of the well-known disentangled latent spaces of GANs that allow for such edits. Recent works have shown \\\\([21]\\\\) that similar semantic control is also present in the h-space of DMs and can be used for latent-based editing. We capitalize on this finding and perform latent editing in the h-space to generate images of desired attributes for fair generation.\\n\\nMagNet \\\\([13]\\\\) is an unsupervised method enabling fair sampling from a pretrained model. They propose a method for uniform sampling on the image manifold to generate underrepresented groups equally. We generated results by MagNet sampling from a StyleGAN2 \\\\([20]\\\\) model trained on the FFHQ \\\\([19]\\\\) dataset from their official codebase. Notably, Table 1. Evaluation of balanced generation for single attribute\\n\\n| Method                        | FD \u2193 | FID \u2193 | FD \u2193 | FID \u2193 | FD \u2193 | FID \u2193 |\\n|-------------------------------|------|-------|------|-------|------|-------|\\n| Random Sampling               | 0.178| 54.59 | 0.334| 60.01 | 0.251| 75.21 |\\n| Universal Guidance (2k) \\\\([1]\\\\)| 0.193| 52.10 | 0.377| 93.42 | 0.189| 64.55 |\\n| Universal Guidance (30k) \\\\([1]\\\\)| 0.127| 48.94 | 0.326| 58.52 | 0.051| 78.57 |\\n| Latent Editing \\\\([21]\\\\)        | 0.001| 37.40 | 0.214| 42.69 | 0.330| 75.04 |\\n| H-Sample Guidance (ours)      | 0.113| 51.46 | 0.184| 56.53 | 0.118| 57.63 |\\n| H-Distribution Guidance (ours)| 0.049| 50.27 | 0.113| 52.38 | 0.014| 51.78 |\\n| StyleGAN2 - Random sampling   | 0.307| 112.28| 0.463| 123.97| 0.276| 117.83|\\n| StyleGAN2 - Magnet \\\\([13]\\\\)    | 0.267| 91.15 | 0.454| 97.05 | 0.281| 106.55|\\n\\nas the base model for MagNet is StyleGAN2, we cannot directly compare FIDs with our DM debiased results and report random generations from StyleGAN2 as a reference.\\n\\n4.4. Main Results\\n\\nWe first present the quantitative and qualitative results on debiasing single binary attributes. Second, we debias multiple attributes simultaneously. We finally present the case of debiasing attributes with multi-class labels.\\n\\nQuantitative evaluation. We evaluate our debiasing method for the single attribute case by generating balanced generations of individual sensitive attributes - gender, eyeglasses, and race, in Tab. 1. As these attributes are binary, the synthesized images are expected to have a 1 : 1 ratio of the sensitive attributes (for e.g. 0.50 fraction of males and 0.50 fraction of females in case of gender). Specifically, we generate \\\\( 10^k \\\\) images from each method per attribute and compute the metrics defined in Sec. 4.1. For most attributes, the proposed guidance method outperforms all the baselines in terms of visual quality as measured by FID and bias metric measured by FD. Although Latent editing has a better FID and FD for gender, on qualitative evaluation (as elaborated in the next section), artifacts are seen in the images (Fig. 6). Moreover, this methods fails to mitigate bias in case of multiple attributes (Tab.3). Sample guidance achieves comparable FID for gender; however, higher FD indicates inferior debiasing. The tradeoff between FD and...\"}"}
{"id": "CVPR-2024-210", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2. Evaluation of balanced generation for multiple attribute\\n\\n| Method                      | FD \u2193 | FID \u2193 |\\n|-----------------------------|------|-------|\\n| Gender + Race               |      |       |\\n| Random Sampling             | 0.256| 60.68 |\\n| Latent Editing [21]         | 0.124| 64.84 |\\n| Universal Guidance (2k) [1] | 0.283| 71.84 |\\n| H-Sample Guidance (ours)    | 0.241| 59.78 |\\n| H-Distrib Guidance (ours)   | 0.075| 49.91 |\\n\\nFID is discussed in Sec.A.1 of supplement. This supports our thesis that the distribution guidance provides enough flexibility during generation, resulting in high-quality outputs even with a high guidance scale.\\n\\nQualitative evaluation. We present results for balancing gender and eyeglasses attributes in Fig. 6. We randomly sample 20 starting noise and use individual guidance methods for debiasing. Without guidance, the DM mostly generates female faces for the gender attribute. Although latent editing achieved better quantitative metrics, it produces images with artifacts and leads to collapsed results. Although Sample and Universal guidance increase the number of males, some images collapse. On the other hand, distribution guidance generates an almost equal number of males and females without affecting the generation quality. Moreover, all the baselines are not able to generate eyeglasses, whereas our method leads to highly balanced generations.\\n\\nMultiple attributes. We apply our method for debiasing multiple attributes simultaneously in Tab. 3. Specifically, given two reference distributions $p_{a1}^{\\\\text{ref}}$ and $p_{a2}^{\\\\text{ref}}$, we add guidance from two pretrained attribute distribution predictors $g_\\\\psi_1$ and $g_\\\\psi_2$. For this experiment, we define both the reference distribution as uniform for each attribute (50%-50% splits). The generated results follow the reference, resulting in a balanced generation across attributes. Further analysis is provided in Sec.B of supplement.\\n\\nMulti Class attributes. We evaluate the efficacy of our approach in balancing multi-class attributes - age and race in Tab. 3. We use FFHQ [19] dataset for both attributes and obtained annotations using pretrained models as ground truth labels are unavailable. For age attribute, we use a pretrained VIT age classifier [36] to produce 3 classes: Young (<20 yrs), Adult (20\u221260 yrs) and Old (>60 yrs). For race, we use the Fairface race classifier [15] to obtain 4 classes: White, Black, Asian, and Indian. Our method successfully debiases multi-class attributes and beats the random and sample guidance in all cases.\\n\\n4.5. Generating Imbalanced Distributions\\nWe test our distribution guidance for generating imbalanced attribute distribution by providing skewed $p_{a_i}^{\\\\text{ref}}$. ii) $0.90$ black race and $0.10$ white race. These two settings are extremely challenging given that male and black race are minority groups in the dataset. We present qualitative results for both the settings in Fig. 7, where our distribution guidance is able to generate the defined distribution with majority males. Note, we have binarized the race attribute as black and whites for simplicity, and hence in the generation, brown race is considered under black category. We report quantitative metrics in Tab. 4, where the proposed method can achieve good FD scores with the same FID. Additional experimental results are tabulated in Sec.B.1 of supplement.\\n\\nTable 3. Balanced generation for multi-class attribute\\n\\n| Age (3 classes) | Race (4 classes) |\\n|-----------------|------------------|\\n| Method          | FD \u2193 | FID \u2193 | FD \u2193 | FID \u2193 |\\n| Random Sampling | 0.256| 60.68 | 0.292| 89.14 |\\n| Latent Editing  | 0.124| 64.84 | 0.219| 90.63 |\\n| Universal       | 0.283| 71.84 | 0.264| 91.54 |\\n\\nTable 4. Distribution guidance for imbalanced generation\\n\\n| Method                      | FD \u2193 | FID \u2193 |\\n|-----------------------------|------|-------|\\n| Random Sampling             | 0.478| 72.26 |\\n| H-Distribution Sampling     | 0.168| 51.65 |\\n\\n4.6. Ablations\\nWe provide ablation over the batch size here and that over the guidance scale, h-space classifier architectures and number of training examples in Sec.A of supplement.\\n\\nBatch size. As we approximate $p_{a\\\\theta}$ with an estimate $\\\\hat{p}_{a\\\\theta}$ over a batch of size $N$, we ablate over different values of $N$ in Tab. 5. Intuitively, using a larger batch size yields a better estimate of $p_{a\\\\theta}$. We have found that the $N=100$ works best for our experiments, balancing both FD and FID. Additionally, our model can also handle low data regime effectively.\\n\\nTable 5. Ablation over batch size for gender balancing.\\n\\n| Batch size | FD \u2193 | FID \u2193 |\\n|------------|------|-------|\\n| 2          | 0.108|       |\\n| 4          | 0.088|       |\\n| 8          | 0.073|       |\\n| 10         | 0.062|       |\\n| 25         | 0.059|       |\\n| 50         | 0.049|       |\\n| 75         | 0.059|       |\\n| 100        | 0.046|       |\\n| 125        | 0.052|       |\\n| 150        | 0.053|       |\\n| 200        | 0.058|       |\\n\\n4.7. Debiasing Text-to-Image Diffusion Models\\nWe implemented our distribution guidance technique for debiasing a text-to-image generation model, Stable Diffusion (SD) v1.5 [37] concerning the gender attribute in this subsection. We provide results on other attributes and on mitigating spurious correlation on WaterBirds [40] generation in Sec.C of supplement. First, we generate a dataset $D$ of 10K images from SD, with prompts 'a photo of a male' and 'a photo of a female' to generate a labeled dataset for training h-space classifiers. If the h-space classifier is\"}"}
{"id": "CVPR-2024-210", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 8. Debiasing results on stable diffusion for gender. Distribution guidance can balance the gender attributes in prompts involving other professions e.g. firefighter and doctor.\\n\\nTable 6. Balancing gender on Stable Diffusion model.\\n\\n| Method                        | Gender | Doctor | Firefighter |\\n|-------------------------------|--------|--------|-------------|\\n| Random Sampling               | 0.317  | 72.37  | 0.355       |\\n| ITI-Gen [57]                  | 0.049  | 64.79  | 0.072       |\\n| Fair Diffusion [9]            | 0.227  | 71.22  | 0.035       |\\n| H-Sample Guidance (ours)      | 0.026  | 70.96  | 0.021       |\\n| H-Distribution Guidance (ours)| 0.024  | 70.69  | 0.015       |\\n\\ntrained on CelebA-HQ dataset, guidance is ineffective due to a significant domain shift from the SD generations. Next, we obtain the corresponding labeled dataset $D_{clf}$ in the $h$-space and train a gender classifier in the $h$-space. We used the trained classifier for distribution guidance following Sec. 3.4 to generate images with balanced gender.\\n\\nIt is observed that SD increases the gender bias when queried to generate certain professions (e.g., male and doctor) [57]. To this end, we implement our distribution guidance along the prompts 'a photo of a doctor' and 'a photo of a firefighter' to evaluate the effectiveness in this challenging setting. The qualitative results are shown in Fig.8, and the quantitative results are reported in Tab.6.\\n\\nBaselines. We compare our method with the following methods.\\n\\n1. Random sampling from SD [37].\\n2. ITI-Gen [57] that learns prompt embeddings for each category of the attribute given image reference sets of each category. It then appends these prompts during generation to produce balanced images.\\n3. Fair Diffusion [9] that uses a lookup table to recognize the biased concept from the text input and adds scaled attribute expressions to the prompt. Note, these baselines are explicitly designed to debias text-conditioned diffusion model; however, our method can debias both conditional and unconditional diffusion models.\\n\\n4.8. Class-imbalance in attribute classification\\n\\nWe explore an important downstream application of our proposed approach in balancing minority classes by augmenting the under-represented classes with generated data. Specifically, we train a race classifier (labels obtained from CA) on the CelebA-HQ [17] dataset. The race classifier is an ImageNet [7]-pretrained ResNet-18 [10] encoder, followed by 2 MLP layers and a classifier. We manually oversample the Whites and undersample the Blacks in the training dataset such that the imbalanced dataset consists of $10k$ samples of white people and $1k$ black people (we keep the genders balanced within a race class). Consequently, the model performs poorly on the minority class (i.e., Black) due to under-representation. Next, we augment (class-balanced) the training data by generating samples whose distribution is inversely proportional to the class counts in the training set to increase images of minority classes using our distribution guidance approach. This adds $9k$ images of only Black race, and the classifier trained on this balanced data performs significantly better (Tab. 7). Even when gender is balanced in both the classes, we observe a significant disparity in the accuracies for Male and Female Black samples in the vanilla classifier. However, our proposed method helps reduce the accuracy gap between Black males and Black females. This shows a potential application in generating 'class' balanced datasets to train models for other downstream tasks, which can also mitigate bias.\\n\\n5. Discussion.\\n\\nLimitations. Although our method performs guidance in the $h$-space, which is efficient compared to the image space guidance, it still requires additional training of $h$-space classifiers. Another limitation is reliance on accurate attribute classifiers to obtain labels for training $h$-space classifiers.\\n\\nFuture works. An important future work is extending distribution guidance beyond de-biasing for controlled generation and data augmentation. In the context of debiasing DMs, extending the proposed approach without needing an attribute classifier or labeled data.\\n\\n6. Conclusion\\n\\nIn this work, we aim to mitigate biases from pretrained diffusion models without retraining - given only a desired reference attribute distribution. We propose a novel approach leveraging distribution guidance that jointly guides a batch of images to follow the reference attribute distribution. The proposed method is effective and results in both high-quality and fair generations across multiple attributes and outperforms sample guidance strategies based on conditioning each sample individually. Extensive experiments demonstrate the effectiveness of our method in balancing both single and multiple attributes on unconditional DMs and conditional text-to-image diffusion models. We believe such a setting of debiasing without retraining is practical, especially in today's era of large-scale generative models.\\n\\nAcknowledgements.\\n\\nThis work was supported by the Kotak IISc AIML Centre (KIAC) and Meesho. Rishubh Parihar and Abhipsa Basu are supported by PMRF fellowship.\"}"}
{"id": "CVPR-2024-210", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\n[1] Arpit Bansal, Hong-Min Chu, Avi Schwarzschild, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Universal guidance for diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 843\u2013852, 2023.\\n\\n[2] Dmitry Baranchuk, Ivan Rubachev, Andrey Voynov, Valentin Khrulkov, and Artem Babenko. Label-efficient semantic segmentation with diffusion models. arXiv preprint arXiv:2112.03126, 2021.\\n\\n[3] Hugo Berg, Siobhan Hall, Yash Bhalgat, Hannah Kirk, Aleksandar Shtedritski, and Max Bain. A prompt array keeps the bias away: Debiasing vision-language models with adversarial learning. In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 806\u2013822, Online only, 2022. Association for Computational Linguistics.\\n\\n[4] Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, and Sungroh Yoon. Perception prioritized training of diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11472\u201311481, 2022.\\n\\n[5] Kristy Choi, Aditya Grover, Trisha Singh, Rui Shu, and Stefano Ermon. Fair generative modeling via weak supervision. In International Conference on Machine Learning, pages 1887\u20131898. PMLR, 2020.\\n\\n[6] Ching-Yao Chuang, Varun Jampani, Yuanzhen Li, Antonio Torralba, and Stefanie Jegelka. Debiasing vision-language models via biased prompts. arXiv preprint arXiv:2302.00070, 2023.\\n\\n[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009.\\n\\n[8] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:8780\u20138794, 2021.\\n\\n[9] Lukas Struppek Dominik Hintersdorf Patrick Schramowski Sasha Luccioni Kristian Kersting Felix Friedrich, Manuel Brack. Fair diffusion: Instructing text-to-image generation models on fairness. arXiv preprint arXiv:2302.10893, 2023.\\n\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.\\n\\n[11] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.\\n\\n[12] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020.\\n\\n[13] Ahmed Imtiaz Humayun, Randall Balestriero, and Richard Baraniuk. Magnet: Uniform sampling from deep generative network manifolds without retraining. In International Conference on Learning Representations, 2021.\\n\\n[14] Niharika Jain, Alberto Olmo, Sailik Sengupta, Lydia Manikonda, and Subbarao Kambhampati. Imperfect imagination: Implications of gans exacerbating biases on facial data augmentation and snapchat selfie lenses. arXiv preprint arXiv:2001.09528, 2020.\\n\\n[15] Jungseock Joo. Fairface attribute model. https://github.com/joojs/fairface, 2021.\\n\\n[16] Cemre Efe Karakas, Alara Dirik, Eyl\u00fcl Yalc\u0131nkaya, and Pinar Yanardag. Fairstyle: Debiasing stylegan2 with style channel manipulations. In European Conference on Computer Vision, pages 570\u2013586. Springer, 2022.\\n\\n[17] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.\\n\\n[18] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. In International Conference on Learning Representations, 2018.\\n\\n[19] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4401\u20134410, 2019.\\n\\n[20] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8110\u20138119, 2020.\\n\\n[21] Mingi Kwon, Jaeseok Jeong, and Youngjung Uh. Diffusion models already have a semantic latent space. arXiv preprint arXiv:2210.10960, 2022.\\n\\n[22] Lucien Le Cam. Asymptotic methods in statistical decision theory. Springer Science & Business Media, 2012.\"}"}
{"id": "CVPR-2024-210", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ke Li and Jitendra Malik. Implicit maximum likelihood estimation. arXiv preprint arXiv:1809.09087, 2018.\\n\\nSasha Luccioni, Christopher Akiki, Margaret Mitchell, and Yacine Jernite. Stable bias: Evaluating societal representations in diffusion models. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2023.\\n\\nV ongani H Maluleke, Neerja Thakkar, Tim Brooks, Ethan Weber, Trevor Darrell, Alexei A Efros, Angjoo Kanazawa, and Devin Guillory. Studying bias in gans through the lens of race. In European Conference on Computer Vision, pages 344\u2013360. Springer, 2022.\\n\\nAbhishek Mandal, Susan Leavy, and Suzanne Little. Measuring bias in multimodal models: Multimodal composite association score. In International Workshop on Algorithmic Bias in Search and Recommendation, pages 17\u201330. Springer, 2023.\\n\\nPietro Melzi, Christian Rathgeb, Ruben Tolosana, Ruben Vera-Rodriguez, Dominik Lawatsch, Florian Domin, and Maxim Schaubert. Gandiffface: Controllable generation of synthetic datasets for face recognition with realistic variations. arXiv preprint arXiv:2305.19962, 2023.\\n\\nChenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. SDEdit: Guided image synthesis and editing with stochastic differential equations. In International Conference on Learning Representations, 2022.\\n\\nSoumik Mukhopadhyay, Matthew Gwilliam, Vatsal Agarwal, Namitha Padmanabhan, Archana Swnathan, Srinidhi Hegde, Tianyi Zhou, and Abhinav Shrivastava. Diffusion models beat gans on image classification. arXiv preprint arXiv:2307.08702, 2023.\\n\\nJunhyun Nam, Sangwoo Mo, Jaeho Lee, and Jinwoo Shin. Breaking the spurious causality of conditional generation via fairness intervention with corrective sampling. Transactions on Machine Learning Research, 2023.\\n\\nAlex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.\\n\\nMalsha V Perera and Vishal M Patel. Analyzing bias in diffusion-based face generation models. arXiv preprint arXiv:2305.06402, 2023.\\n\\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748\u20138763. PMLR, 2021.\\n\\nVikram V Ramaswamy, Sunnie SY Kim, and Olga Russakovsky. Fair attribute classification through latent space de-biasing. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9301\u20139310, 2021.\\n\\nAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.\\n\\nNate Raw. Vit attribute model. https://huggingface.co/nateraw/vit-age-classifier, 2021.\\n\\nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.\\n\\nHarrison Rosenberg, Shimaa Ahmed, Guruprasad VRamesh, Ramya Korlakai Vinayak, and Kassem Fawaz. Unbiased face synthesis with diffusion models: Are we there yet? arXiv preprint arXiv:2309.07277, 2023.\\n\\nNataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22500\u201322510, 2023.\\n\\nShiori Sagawa, Pang Wei Koh, Tatsunori BHashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019.\\n\\nChitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems, 35:36479\u201336494, 2022.\\n\\nPedro Sanchez and Sotirios A Tsaftaris. Diffusion causal models for counterfactual estimation. In Conference on Causal Learning and Reasoning, pages 647\u2013668. PMLR, 2022.\\n\\nPrasanna Sattigeri, Samuel C Hoffman, Vijil Chenthamarakshan, and Kush R Varshney. Fairness gan: Generating datasets with fairness properties using a...\"}"}
{"id": "CVPR-2024-210", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Patrick Schramowski, Manuel Brack, Bj\u00f6rn Deiseroth, and Kristian Kersting. Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22522\u201322531, 2023.\\n\\nChristoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. Laion-5b: An open large-scale dataset for training next generation image-text models. Advances in Neural Information Processing Systems, 35:25278\u201325294, 2022.\\n\\nAshish Seth, Mayur Hemani, and Chirag Agarwal. Dear: Debiasing vision-language models with additive residuals. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6820\u20136829, 2023.\\n\\nJiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2020.\\n\\nShuhan Tan, Yujun Shen, and Bolei Zhou. Improving the fairness of deep generative models without retraining. arXiv preprint arXiv:2012.04842, 2020.\\n\\nChristopher TH Teo, Milad Abdollahzadeh, and Ngai-Man Cheung. Fair generative models via transfer learning. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 2429\u20132437, 2023.\\n\\nBrandon Trabucco, Kyle Doherty, Max Gurinas, and Ruslan Salakhutdinov. Effective data augmentation with diffusion models. arXiv preprint arXiv:2302.07944, 2023.\\n\\nSoobin Um and Changho Suh. A fair generative model using lecam divergence. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 10034\u201310042, 2023.\\n\\nBoris van Breugel, Trent Kyono, Jeroen Berrevoets, and Mihaela van der Schaar. Decaf: Generating fair synthetic data using causally-aware generative networks. Advances in Neural Information Processing Systems, 34:22221\u201322233, 2021.\\n\\nAndrey Voynov, Kfir Aberman, and Daniel Cohen-Or. Sketch-guided text-to-image diffusion models. In ACM SIGGRAPH 2023 Conference Proceedings, pages 1\u201311, 2023.\\n\\nJulia Wolleb, Florentin Bieder, Robin Sandk\u00fchler, and Philippe C Cattin. Diffusion models for medical anomaly detection. In International Conference on Medical image computing and computer-assisted intervention, pages 35\u201345. Springer, 2022.\\n\\nDepeng Xu, Shuhan Yuan, Lu Zhang, and Xintao Wu. Fairgan: Fairness-aware generative adversarial networks. In 2018 IEEE International Conference on Big Data (Big Data), pages 570\u2013575. IEEE, 2018.\\n\\nNing Yu, Ke Li, Peng Zhou, Jitendra Malik, Larry Davis, and Mario Fritz. Inclusive gan: Improving data and minority coverage in generative models. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXII 16, pages 377\u2013393. Springer, 2020.\\n\\nCheng Zhang, Xuanbai Chen, Siqi Chai, Chen Henry Wu, Dmitry Lagun, Thabo Beeler, and Fernando De la Torre. Iti-gen: Inclusive text-to-image generation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3969\u20133980, 2023.\\n\\nBeier Zhu, Yulei Niu, Saeil Lee, Minhoe Hur, and Hanwang Zhang. Debiased fine-tuning for vision-language models by prompt regularization. arXiv preprint arXiv:2301.12429, 2023.\"}"}
