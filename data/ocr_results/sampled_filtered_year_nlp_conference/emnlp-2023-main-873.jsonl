{"id": "emnlp-2023-main-873", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Prompt template for the generation of a triplet of sentences from (NEUT/FEM/MASC) seed words.\\n\\nFigure 5: Prompt template for the rewriting of a triplet of (NEUT/FEM/MASC) seed sentences.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus\\n\\nAndrea Piergentili, Beatrice Savoldi, Dennis Fucci, Matteo Negri, Luisa Bentivogli\\n\\n1 University of Trento\\n2 Fondazione Bruno Kessler\\n{apiergentili, bsavoldi, dfucci, negri, bentivo}@fbk.eu\\n\\nAbstract\\nGender inequality is embedded in our communication practices and perpetuated in translation technologies. This becomes particularly apparent when translating into grammatical gender languages, where machine translation (MT) often defaults to masculine and stereotypical representations by making undue binary gender assumptions. Our work addresses the rising demand for inclusive language by focusing head-on on gender-neutral translation from English to Italian. We start from the essentials: proposing a dedicated benchmark and exploring automated evaluation methods. First, we introduce GeNTE, a natural, bilingual test set for gender-neutral translation, whose creation was informed by a survey on the perception and use of neutral language. Based on GeNTE, we then overview existing reference-based evaluation approaches, highlight their limits, and propose a reference-free method more suitable to assess gender-neutral translation.\\n\\n1 Introduction\\nSocietal gender asymmetries and inequalities are reflected and perpetuated through language (Stahlberg et al., 2007; Menegatti and Rubini, 2017). Such awareness has grown also within the Natural Language Processing (NLP) field (Blodgett et al., 2020), where extensive research has highlighted how several applications suffer from gender bias (Sun et al., 2019; Sheng et al., 2021). As also noted by MT users themselves (Olson, 2018; Dev et al., 2021), among these applications are translation systems used at large scale, which pose the concrete risk of misrepresenting gender minorities by over-producing masculine forms, while reinforcing binary gendered expectations and stereotypes (Savoldi et al., 2021; Lardelli and Gromann, 2022).\\n\\nTo foster greater inclusivity and break free from the constraints of masculine/feminine language, neutral strategies have emerged and are increasingly adopted in academia (APA, 2020), institutions (H\u00f6glund and Flinkfeldt, 2023), and industry alike (Langston, 2020). These strategies aim to overcome marked forms that treat the masculine gender as the conceptually generic, default human prototype (e.g., \\\\textit{humankind} vs. \\\\textit{mankind}) (Silveira, 1980; Bailey et al., 2022). Thus, they challenge gender norms and embrace all gender identities by avoiding gendered terms when unnecessary (e.g. \\\\textit{chair} vs. \\\\textit{chairman} / \\\\textit{chairwoman}) (Hord, 2016).\\n\\nEnglish, being at the forefront of inclusive language changes and with its limited gendered grammar (Ackerman, 2019), has faced fewer obstacles in adapting to neutral forms, which have already been modeled into monolingual generative tasks (Sun et al., 2021; Vanmassenhove et al., 2021). As recently underscored by Amrhein et al. (2023), however, the resources and approaches made available for English are not portable to grammatical gender languages. Such need for dedicated efforts is exemplified in Italian, where neutral solutions must navigate the extensive encoding of masculine/feminine marking (e.g. \\\\textit{the doctors are qualified} \u2192 \\\\texti{it:} \\\\textit{i} / \\\\textit{le} \\\\textit{dottori} / \\\\textit{esse sono qualificate} / \\\\textit{i} / \\\\textit{le} \\\\textit{dottori} / \\\\textit{esse sono qualificate}) through synonymy or more complex rephrasing (Papadimoulis, 2018) (e.g. \\\\textit{\u2192 il personale medico} [the medical staff]). While indeed more challenging, pursuing inclusivity in Italian is relevant exactly because sexist attitudes are more visible and impactful in grammatical gender languages (Wasserman and Weseley, 2009). Nonetheless, the implementation of neutral language in MT remains to date a basically uncharted territory, despite the desirability of neutral outputs under several circumstances where gender is ambiguous or irrelevant.\\n\\nIn light of the above, by focusing on English \\\\texti{\u2192} Italian as an exemplary and representative translation pair and direction, we hereby lay the groundwork toward gender-neutral MT. Starting from a survey aimed to understand the challenges...\"}"}
{"id": "emnlp-2023-main-873", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of neutral translation in cross-lingual settings, we provide the necessary tools and resources to foster research on the topic by estimating gender neutral translation in MT. Hence, our main contributions are:\\n\\n(1) A study on the feasibility of neutral translation, by surveying the potential trade-off among fluency, adequacy, and neutrality;\\n\\n(2) The creation of GeNTE, the first natural, parallel corpus designed to test MT systems' ability to generate neutral translations;\\n\\n(3) A comprehensive analysis of the (un)suitability of existing automatic metrics to evaluate neutral translation. As an inherent benchmark component, we indicate an alternative solution capable to better assess the task.\\n\\nWe make the GeNTE dataset freely available at https://mt.fbk.eu/gente/ and release the evaluation code under Apache License 2.0 at https://github.com/hlt-mt/fbk-NEUTR-evAL.\\n\\n2 Background\\n\\nEmerging research has highlighted the importance of reshaping gender in NLP technologies in a more inclusive manner (Dev et al., 2021), also through the representation of non-binary identities and languages (Wagner and Zarrie\u00df, 2022; Lauscher et al., 2022; Ovalle et al., 2023). Foundational works in this area have included several applications, such as coreference resolution systems (Cao and Daum\u00e9 III, 2020; Brandl et al., 2022), intra-lingual fair rewriters (Amrhein et al., 2023), and automatic classification of gender-neutral text (Attanasio et al., 2021).\\n\\nIn MT, the research agenda has mainly focused on the improvement of masculine/feminine gender translation. Along this line, different mitigation methods have been devised to ensure that unambiguous gendered referents (e.g., *he/she* is a doctor) are properly resolved in the target language (Costajuss\u00e0 and de Jorge, 2020; Choubey et al., 2021; Saunders et al., 2022). These methods are often tested on synthetic template-based datasets such as WinoMT (Stanovsky et al., 2019) or Simple-GEN (Renduchintala and Williams, 2022). As also stressed by Saunders and Olsen (2023), however, in realistic scenarios MT systems are also confronted with ambiguous input sentences that do not convey any gender distinction (e.g., *I called the doctor*).\\n\\nNonetheless, to date the resources and solutions envisioned for resolving such cases into grammatical gender languages like Arabic (Alhafni et al., 2022), Italian (Vanmassenhove and Monti, 2021), Spanish, or French (Rarrick et al., 2023) entail offering two possible translation outputs, still constrained to binary gender forms (e.g., *it: Ho chiamato il dottore* MASC vs. *la dottoressa* FEM).\\n\\nAs an exception within the current MT landscape, Cho et al. (2019) and Ghosh and Caliskan (2023) investigate the preservation of gender-ambiguous pronouns for Korean/Bengali \u2192 English. Since English can already boast the well-established neutral pronoun *they*, their study does not face the additional challenges of preserving such unmarked vagueness into grammatical gender languages. Such challenges are exemplified by Saunders et al. (2020), who created parallel test and fine-tuning data to develop MT systems able to generate non-binary translations for English \u2192 German/Spanish. However, their target sentences are artificial \u2013 created by replacing gendered morphemes and articles with synthetic place-holders \u2013 thus serving only as a proof-of-concept.\\n\\nTo the best of our knowledge, Piergentili et al. (2023) are the first to advocate the use of target gender-neutral rephrasings and synonyms as a viable paradigm toward more inclusive MT when gender is unknown or simply irrelevant. Despite this call to action, no concrete steps have been taken yet to actually facilitate research in this direction, not even toward suitable benchmarks to recognize the neutral forms occasionally generated by current systems (Savoldi et al., 2022).\\n\\nIn light of the above, the path toward gender-neutral translation in MT is bottlenecked by the lack of dedicated datasets and automated evaluations. Here, we fill this gap so to guide and allow research on this novel topic. To this aim, we start in \u00a73 by first ensuring that gender-neutral language can enable acceptable translations, not being perceived as inappropriate or intrusive.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Questionnaire example of English sentences with translation alternatives. For each example, participants\u2019 responses\u2014GT and NT are equivalent, NT is preferable, GT is preferable\u2014are shown (percentage).\\n\\nTable:<br>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1"}
{"id": "emnlp-2023-main-873", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The GeNTE corpus\\n\\nGeNTE is the first test set designed to evaluate MT models\u2019 ability to perform gender-neutral translations, but only under desirable circumstances. In fact, when referents\u2019 gender is unknown or irrelevant, undue gender inferences should not be made and translation should be neutral. However, neutralization should not be always enforced; for instance, when a referent\u2019s gender is relevant and known, MT should not over-generalize to neutral translations. The corpus hence consists of 1,500 English-Italian parallel sentences with mentions to human referents that equally represent two translation scenarios:\\n\\n1) Set-N, featuring gender-ambiguous source sentences that require to be neutrally rendered in translation;\\n2) Set-G, featuring gender-unambiguous source sentences, which shall be properly rendered with gendered (masculine or feminine) forms in translation. Altogether, these sets allow to benchmark whether systems are able to perform gender-neutral translation, and if they do so when appropriate.\\n\\nWe build GeNTE on naturally occurring instances of both scenarios retrieved from Europarl (Koehn, 2005). Besides being a widely popular and high-quality MT resource, we chose this corpus inasmuch it represents formal communicative situations from the administrative/institutional domain. Accordingly, it reflects the context for which gender-neutral forms are traditionally intended, also in line with the stakeholders\u2019 preference highlighted in \u00a73. Also, as examined by Saunders (2022), Europarl exhibits a large amount of gender-ambiguous cases that \u2013 although translated with gendered forms in the original references of the corpus \u2013 lend themselves as suitable candidates for neutralization. As explained in the forthcoming paragraphs (\u00a74.2), for each of these original Europarl gendered target sentences, we create an additional gender-neutral reference translation.\\n\\n4.1 Data selection and annotation\\n\\nData extraction.\\n\\nTo retrieve Europarl segments representing our two translation scenarios of interest, we crafted regular expressions to: i) identify source sentences containing mentions to human referents, ii) maximize the variability of linguistic phenomena included in the corpus, and iii) ensure a balanced distribution of both unambiguous and ambiguous gender translation cases. To this aim, we targeted Set-G segments by matching source English sentences that contained explicit gender cues, e.g. lexically gendered words (e.g., sister, woman), titles (Mr, Mrs) and marked pronouns (him, her). Set-N, instead, was populated by matching several word classes that do not convey any gender distinction in English (e.g. you, citizens, went), but typically correspond to masculine/feminine expressions in the target language. Also, we searched for masculine terms used generically, such as man and its derived compounds (e.g., chairman, layman). In fact, masculine generics are unreliable gender cues and, following the survey findings (\u00a73), should not be propagated in MT.\\n\\nSentence editing.\\n\\nOn the collected material, a first intervention was carried out to streamline the evaluation of gender-neutral translation. In fact, some of the source sentences contained mentions of multiple referents, which required the combination of different forms in translation (i.e. neut/masc/fem). In those cases, the parallel sentences were manually edited so as to ensure that they only include referents that require the same type of (either neutral or gendered) forms. In this way, each sentence pair can be handled as a whole coherent unit, thus avoiding the complexities of evaluating intricate combinations of phenomena. To ensure a balanced distribution of instances from both Set-N and Set-G, a second intervention was required to compensate for the under-representation of unambiguous cases. Although these edits slightly reduce the naturalness of the data, they allow for a simpler and sound evaluation, crucial to shed light on a complex task such as gender-neutral MT. Instead, other edits were made to enhance the quality of the corpus; all of them are reported in Appendix \u00a7B.1. Once the editing phase was concluded, all sentence pairs were annotated as N in Set-N, and as F or M in Set-G. In the annotation process, it was verified that the initial pool of \u2013 automatically extracted \u2013 candidate sentences were correctly assigned to Set-N and Set-G by accounting for the sentence context. In this way, we could differentiate between the use of gendered words as either masculine generics (e.g. It is up to an accused employer to prove his innocence \u2013 identified as N) or as informative of a referent\u2019s gender (e.g. I would like to thank Commissioner Byrne for his cooperation. \u2013 identified as G).\\n\\nSuch lack confirms the vast representation of generic and unknown referents in Europarl, as found in Saunders (2022).\"}"}
{"id": "emnlp-2023-main-873", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As a confirmation of the predominant use of gendered forms when translating into grammatical gender languages, it is worth remarking that almost all (97.2%) segments collected from Europarl have gendered references in Italian. Inspired by the design of natural (binary) gender bias benchmarks such as MuST-SHE (Bentivogli et al., 2020) and MT-GenEval (Currey et al., 2022), we thus created a second translation, so to allow for a reference-based contrastive evaluation of gender-neutral MT (see \u00a75.2). To this aim, for each sentence pair, we created an additional Italian reference, which differs from the original one only in that it refers to the human entities with neutral expressions. This makes it possible to isolate gender-related linguistic elements as the only source of variation in the score of system outputs when evaluated against both the gendered and the neutral references. As neutralization is an open-ended task that entails a high degree of variability in the possible solutions, we wanted such variability accounted for in the neutral references. Therefore, their creation was assigned to three professional translators hired via a translation agency.\\n\\nEach of them was assigned a different portion of the collected Italian references, to be post-edited so as to only replace gendered terms with neutral formulations. An expert linguist native speaker of Italian prepared detailed instructions drawing from existing guidelines for the institutional domain. After an initial training session, the linguist supported the translators throughout the process and finally checked all the neutralizations. The cost paid to the agency was of 60 euros/hour, for a total of 14 hours of work for each translator. The linguist is one of the authors of the paper. Released together with the GeNTE corpus.\\n\\nIn Appendix B.2, we provide qualitative insights regarding revisions and supervision of the linguist. GeNTE COMMON-SET. Whereas each translator was in charge of post-editing one given portion of the corpus, we also selected a common set of 200 references to be neutralized by all translators (henceforth referred to as the COMMON-SET); 100 were taken from the gendered set (COMMON-SET-G), and 100 from the neutral one (COMMON-SET-N). Thus, we obtained 200 source sentences, each paired with one (original) gendered reference and three (post-edited) neutral references. The creation of a COMMON-SET was primarily motivated by the goal of having a subset of the corpus that could be used to test the robustness of evaluation protocols and metrics across the three different neutral references (see \u00a75.2). Orthogonally, it allowed us to measure linguistic variability among the neutral and gendered references (see Appendix B.3). Table 2 shows examples from the COMMON-SET, which confirm the findings of our preliminary survey (\u00a73). Example i is representative of the variability that is inherent to the neutralization task. Example ii, instead shows a rare situation where all translators used the same neutralization device and produced an identical sentence. Finally, iii shows a gendered term, whose neutralization requires verbose periphrases that compromise the original text\u2019s fluency and style. This case was signaled as particularly difficult to neutralize: two translators out of three did not create a neutral reference. Overall, based on a manual analysis of the COMMON-SET, the translators produced three identical gender-neutral references in 13.57% of the cases, while an additional 8% of translations exhibited a high degree of similarity (e.g., the same neutral words are used, but in a different order).\"}"}
{"id": "emnlp-2023-main-873", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Corpus statistics for GeNTE and its subset COMMON-SET. Both sets requiring gendered translations (Set-G) are equally balanced between F and M sentences. Average lengths are calculated ignoring punctuation. In the last column, we provide the number of gendered words in the REF-Gs that had to be neutralized in the REF-Ns. These statistics are positive: they show that the GeNTE COMMON-SET exhibits a good level of variability (\u223c79%), which is desirable to test open-ended generation tasks like MT. Also \u2013 and especially in light of the fact that the translators worked independently \u2013 the \u223c21% of identical/similar neutralizations suggests that neutralizing translation is a challenging but feasible task.\\n\\nTo conclude, relevant statistics for GeNTE and its COMMON-SET are provided in Table 3.\\n\\n5 Gender-neutral Evaluation Protocols\\n\\nWe complement our benchmark creation effort with a study on the possible approaches for using GeNTE to conduct automated evaluations of neutral MT. To this aim, we first define sound test-bed conditions (\u00a75.1). On this basis, we then experiment with a contrastive, reference-based protocol to inspect the effectiveness of standard MT metrics to assess neutral translation (\u00a75.2). Then, to overcome the limitations encountered with the reference-based approach, we implement a reference-free protocol (\u00a75.3), which shows promise in advancing the task's evaluation.\\n\\n5.1 Test-bed\\n\\nTo ensure a sound comparison between different automatic evaluation protocols, we built a test-bed based on the GeNTE COMMON-SET (\u00a74.2, Table 3). Our test-bed includes relevant instances in relation to our task, namely gendered and gender-neutral automatic translations in equal proportion. On this basis, the analyzed evaluation approaches can be compared in their ability to reward systems that generate neutralized outputs only when due.\\n\\nThe automatic Italian translations of the COMMON-SET sources were generated with two leading commercial MT systems: Amazon Translate and DeepL. However, a manual inspection showed an almost complete lack of representation of gender-neutral translations in the outputs: gendered translations were generated for all but one of the COMMON-SET-N inputs. This result revealed the unsuitability of such outputs for investigating the automated evaluation of neutral translation itself. Accordingly, to obtain neutral (MT-like) outputs to be included in the test-bed, we resorted to manually post-editing the 100 COMMON-SET-N translations generated with undue gender assignments. To do so, we leveraged our manually-created neutral references (\u00a74.2): we substituted the neutral forms produced by the three professional translators to the gendered forms in the MT outputs, so as to make them neutral without altering the rest of the sentence.\\n\\nFor each system, we thus obtained three sets of neutral output sentences (one per translator), so to account for the robustness of different evaluation methods to the linguistic variability expressed in the inventory of neutralization strategies potentially applicable by humans and machines.\\n\\n5.2 Reference-based Evaluation\\n\\n5.2.1 Setting\\n\\nIn this evaluation protocol we aim to verify whether common reference-based MT metrics can be effectively used to identify gendered and neutral translations. The protocol is based on the idea that if a system generates a gendered translation, its output will be rewarded when evaluated against a gendered reference and penalized when evaluated against a gender-neutral one. This provides a glimpse into the shortcomings of inclusivity within the current MT landscape.\\n\\nOn average, 12% of the words present in the systems' output were substituted through post-editing, thus these edits have a minimal and circumscribed impact that does not alter the original output sentence.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Corpus-level scores for DeepL and Amazon Translate, and percentage gains (\u2206%, with sign changed for TER) with respect to the correct references.\\n\\nCOMMON-SET-G: the original MT output is evaluated against each of the three available references, resulting scores are averaged.\\n\\nCOMMON-SET-N: each of the three edited MT outputs is evaluated against the two references not used to neutralize it, all resulting scores are averaged.\\n\\nScores are computed with respect to a gendered and a neutral reference. On the contrary, if a system produces a neutral translation, this is expected to be rewarded when compared to a neutral reference and penalized when compared to a gendered one.\\n\\nContrastive Protocol. Given a system output and a reference-based metric, we compute corpus-level scores against both the gendered and the neutral references provided in COMMON-SET. Then, for COMMON-SET-G the metric is effective if the scores are higher when computed against the gendered translations than the neutral ones; vice versa for COMMON-SET-N.\\n\\nMetrics. We study the effectiveness of a set of widely used metrics. These can be categorized as:\\n\\ni) n-gram overlap metrics: BLEU, chrF, TER, and METEOR, which are sensitive to surface form differences between outputs and references (Glushkova et al., 2023);\\n\\nii) neural model-based metrics: BERTScore, BLEURT, and COMET, which compare semantic representations based on the respective underlying models.\\n\\n5.2.2 Results\\n\\nTable 4 reports the results computed with each metric on our test-bed. First, results are consistent between DeepL and Amazon Translate. With respect to COMMON-SET-G, all the metrics correctly give higher scores for gendered references than for neutral ones: positive percentage differences thus indicate that the metrics correctly reward systems' gendered translations. However, in COMMON-SET-N there is a divergence in performance between n-gram overlap metrics and neural metrics. Only three metrics based on n-gram overlap \u2013 BLEU, TER, and METEOR \u2013 correctly assign higher scores to systems evaluated against the neutral references.\\n\\nThese results show that, compared to neural metrics, n-gram overlap metrics appear more suitable for assessing gender-neutrality. The lower effectiveness of the neural metrics could be attributed to the lower frequency of neutral expressions in the training data of these models, leading to a lower probabilities assignment. Also, neural metrics are sensitive to semantic variations, but robust to surface lexical or morphological differences. Thus, since gender neutralizations preserve the essential semantics of their gendered equivalents, neural metrics are unable to properly frame their differences in this contrastive setting. This is evident in the consistently higher \u2206 percentages observed in COMMON-SET-G for n-gram overlap metrics (all above 8%) compared to the lower percentages obtained with neural metrics (all below 5%).\\n\\nWe further experimented with BLEU, TER, and METEOR to investigate their ability to provide more fine-grained evaluations. We thus tested them on the same data and the same contrastive principle, but at the sentence level (i.e. a neutral output sentence should obtain higher scores on the neutral reference compared to the gendered reference, and vice versa for a gendered output translation). In this way, the \u2206 obtained with the contrastive reference-based evaluation protocol that relies on BLEU, TER and METEOR can be used to categorize each sentence as either gendered or gender-neutral: higher BLEU on the neutral reference wrt. the gendered reference \u2192 output sentence classified as neutral; higher BLEU on the gendered reference wrt. the neutral reference \u2192 output sentence classified as gendered. By distinguishing the sentences belonging to COMMON-SET-N and COMMON-SET-G in advance, we can thus calculate an overall accuracy that represents the proportion of sentences correctly categorized. The results are...\"}"}
{"id": "emnlp-2023-main-873", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"presented in Table 5. For COMMON-SET-G, the performance is rather promising for all the three metrics, with accuracy scores always above 90% for the outputs of both Amazon Translate and DeepL. This is in line with the corpus-level results for the same set. Interestingly, though, for COMMON-SET-N the accuracy scores are very low, worse than or close to random choice for METEOR and BLEU. Only TER-based evaluations are higher (65.17% for Amazon Translate, 65.83% for DeepL).\\n\\nIn conclusion, through this closer inspection, we find that none of the n-gram overlap metrics is actually reliable for the evaluation of gender-neutral translation. This is possibly due to the fact that our reference-based evaluation approach, just like the metrics it is based on, is heavily dependent on the reference sentences. Outputs that deviate from the reference, even if they are acceptable translations, may therefore be penalized. This issue becomes particularly critical when evaluating gender-neutral translations, as periphrasis or synonymy are among the most common and accepted techniques used for achieving neutrality (\u00a73). These strategies are inherently penalized by n-gram overlap metrics and do not seem to entail significant differences in meaning according to neural metrics, thus advocating for alternative, reference-free solutions.\\n\\n5.3 Reference-free Evaluation\\n\\n5.3.1 Setting\\n\\nOur reference-free protocol for the evaluation of gender-neutral translation explores a classification-based approach. We cast the problem as a binary task to classify if automatically-translated sentences are gendered or neutral. Implementing this procedure requires\\n1) generating training data, and\\n2) training the classifier on the collected data. Then, results are computed on our test-bed in terms of classification accuracy.\\n\\nSynthetic Data Generation. Confronted with the lack of Italian corpora featuring gender-neutral language, we resorted to synthetic data generation by prompting GPT (gpt-3.5-turbo). To do so, we devised a three-step approach that allowed for a more controlled generation procedure with reduced risk of noise (for full details, see Appendix C.1).\\n\\nFirst, similarly to Attanasio et al. (2021), we manually created 800 triplets of neutral, masculine, and feminine referents (e.g. the neighbours: il vicinato - i vicini - l vicine). Then, we used such triplets as seedwords to prompt GPT and generate triplets of sentences, which only differ for the inserted (neut/masc/fem) seedword. This resulted in \u223c60,000 sentences with a very low level of noise, but featuring a rather simple and repetitive syntactic structure. Therefore, we finally carried out a second generation round, prompting GPT to rewrite each triplet adding context to increase sentence variability and length. This led to a final synthetic corpus of \u223c380,000 sentences, equally distributed across neut/masc/fem instances, and with varied structures to favor generalization.\\n\\nGender-Neutral Classifier. To implement the classification model, we leveraged UmBERTo, a Roberta-based language model (LM) fine-tuned on the Italian section of the web corpus OSCAR (Ortiz Su\u00e1rez et al., 2019). In the survey by Tamburini (2020), UmBERTo was proven to be one of the best-performing LMs for Italian. Given a sequence of tokens, UmBERTo returns a contextualized vector for each token, including the special [CLS] token placed at the beginning of the sentence. As suggested by Devlin et al. (2019), we added a linear layer on top of the [CLS] vector to predict the neutral or gendered class. We trained the parameters of both the linear layer and UmBERTo on the classification task using the synthetic corpus labeled with neutral or gendered \u2013 for feminine and masculine \u2013 tags. Since this solution yielded the best results, our final classifier was trained in unbalanced data conditions, by making use of all synthetic gendered sentences (e.g. 1/3 fem and 1/3 masc) and all neutral sentences (1/3 neut). For complete details on the training setup see Appendix C.2.\\n\\n5.3.2 Results\\n\\nCompared to the accuracy scores obtained via sentence-level contrastive evaluation based on BLEU, TER, and METEOR (first three rows of Table 5), our final classifier achieved an accuracy score of 91.00% on the test-set.\\n\\n| Metric   | COMMON-SET-G | COMMON-SET-N | All Metrics |\\n|----------|--------------|--------------|-------------|\\n| BLEU     | 92.00        | 52.00        | 72.00       |\\n| TER      | 90.33        | 65.83        | 78.08       |\\n| METEOR   | 94.67        | 42.71        | 68.69       |\\n| Classifier | 91.00        | 88.67        | 89.83       |\\n\\nTable 5: Accuracy scores for reference-based (BLEU, TER, and METEOR) and reference-free (classifier) evaluation protocols.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5, it is evident that the scores achieved by the trained classifier (row 4) are notably higher. These discrepancies primarily arise from the performance on the neutral outputs (Set-N), where the classifier outperforms the best n-gram overlap metric (TER) by a margin of up to 22.67 points for DeepL. However, for gendered outputs, the classifier demonstrates slightly lower results compared to the three reference-based metrics (except for DeepL, where it outperforms TER). As a result, for our reference-free approach, the gap between the scores obtained on gendered and neutral outputs is small (especially for Amazon Translate), attesting a balanced performance across the two classes.\\n\\nAll in all, the proposed reference-free evaluation protocol appears a promising evaluation method to accompany the release of GeNTE and favour its future utilization as a benchmark for gender-neutral MT. It proves to be a robust approach, capable of handling the linguistic variability associated with gender neutralization strategies, and overcoming the limitations of the reference-based approaches.\\n\\n6 Conclusions\\n\\nIn this work, we investigated gender-neutral translation as a path for inclusive MT. To this aim, we focused on English \u2192 Italian, a pair that is highly representative of the challenges of implementing neutral forms into grammatical gender languages. As a novel area of inquiry, we started from the fundamentals. First, we conducted a survey on the acceptability of gender-neutral translation, which highlighted the openness of potential MT end-users, especially in formal communicative situations. Second, informed by the survey, we built GeNTE, the first natural benchmark for evaluating gender-neutral translation in MT. Third, we investigated the (un)suitability of existing automatic evaluation protocols to assess gender-neutral translation, and thus proposing an alternative, reference-free solution. Having taken the first steps toward gender-neutral MT, our resources and evaluation method are made available to foster and inform the future development of more inclusive MT.\\n\\nLimitations\\n\\nNaturally, this work presents some limitations. In the paper we took the very first steps to enable evaluation and research on the task of gender-neutral translation for inclusive MT into grammatical gender languages. To do so, we provided data (\u00a74 & \u00a75.3) and modeling (\u00a75.3) for the specific English \u2192 Italian language pair. Thus, except for the GPT prompts written in English, the released GeNTE neutral references and the trained classifier cannot be directly used for other target languages. However, Italian was chosen as a highly representative example of the challenges faced in cross-lingual transfer from English. Accordingly, we believe that our design considerations, the methodology for the creation of GeNTE, as well as the presented evaluation protocols broadly apply to other target grammatical gender languages, too.\\n\\nIn the experiments, we relied on different closed-source models: Amazon Translate, DeepL and GPT (gpt-3.5-turbo). This has reproducibility consequences, since these models are regularly updated, thus potentially yielding future results that differ from those reported in this paper. Also, their access via API (paid in US dollars) might not be affordable for all institutions/researchers.\\n\\nFinally, due to the inability of current MT models to generate gender-neutral translations, the output sentences used to test different MT metrics and evaluation protocols (\u00a75) were partially post-edited. Indeed, this solution does not completely reflect standard evaluation practices conducted on fully MT generated output. However, this post-editing process only targeted gender-related aspects of the output sentences, thus still vastly preserving the MT generation and offering a controlled, realistic scenario. It should be recognized though that, by design, we enacted evaluation conditions where the MT models succeeded in generating the expected (either neutral or gendered) output translation. Instead, since the models' outputs did not exhibit cases where MT failed at generating the expected (gendered) translation, we could not test the robustness of our evaluation protocols for such a scenario.\\n\\nEthics Statement\\n\\nBy addressing inclusivity in MT, this work presents an inherent ethical component. It builds from concerns toward the societal impact of widespread translation technologies that reflect and propagate discriminatory and exclusionary language. Concretely, by potentially feeding into existing stereotypes, reinforcing male-grounded visibility, and perpetuating the erasure of non-binary gender identities.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Still, our work is not without risks either and thus warrants some ethical considerations. In particular, we propose the use of gender-neutralization strategies that avoid the use of unnecessary gendered terms via the retooling of established forms and grammars. These strategies can be considered as a form of Indirect Non-binary Language (INL) (Attig and L\u00f3pez, 2020), which are intended \u2013 as we do in this paper \u2013 to equally elicit all gender identities in language and prevent misgendering by excluding any kind of gender assumption (Strengers et al., 2020). Instead, Direct Non-binary Language (Attig and L\u00f3pez, 2020) \u2013 emerging via grassroots efforts and more predominately in online social medias (Lauscher et al., 2022) \u2014 resort to the creation of neologisms, neopronouns or even neomorphology to typically enhance the visibility of non-binary individuals.\\n\\nIn light of the above, several, concurring forms can serve different inclusive language needs (Commandini, 2021; Knisely, 2020). Thus, it should be stressed that the neutralization strategies incorporated in our MT work are not prescriptively intended. Rather, they are orthogonal to other attempts and non-binary expressions for inclusive language (technologies) (Lauscher et al., 2023; Ginel and Theroine, 2022).\\n\\nAcknowledgements\\n\\nThis work is part of the project \\\"Bias Mitigation and Gender Neutralization Techniques for Automatic Translation\\\", which is financially supported by an Amazon Research Award AWS AI grant. Moreover, we acknowledge the support of the PNRR project FAIR - Future AI Research (PE00000013), under the NRRP MUR program funded by the NextGenerationEU.\\n\\nWe thank Lisiana Bucci, Nicoletta Aresca, and Cinzia Bertoletti, for the production of the gender-neutral references we included in GeNTE and used in our experiments. We also thank Paolo Mainardi for the preliminary study on the topic carried out during his internship at FBK.\\n\\nReferences\\n\\nLauren Ackerman. 2019. Syntactic and cognitive issues in investigating gendered coreference. Glossa: a journal of general linguistics, 4(1).\\n\\nBashar Alhafni, Nizar Habash, and Houda Bouamor. 2022. User-centric gender rewriting. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 618\u2013631, Seattle, United States. Association for Computational Linguistics.\\n\\nChantal Amrhein, Florian Schottmann, Rico Sennrich, and Samuel L\u00e4ubli. 2023. Exploiting biased models to de-bias text: A gender-fair rewriting model. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4486\u20134506, Toronto, Canada. Association for Computational Linguistics.\\n\\nAPA. 2020. Publication Manual of the American Psychological Association, 7th edition. American Psychological Association.\\n\\nGiuseppe Attanasio, Salvatore Greco, Moreno La Quatra, Luca Cagliero, Michela Tonti, Tania Cerquitelli, and Rachele Raus. 2021. E-mimic: Empowering multilingual inclusive communication. In 2021 IEEE International Conference on Big Data (Big Data), pages 4227\u20134234. IEEE.\\n\\nRemy Attig and \u00c1rtemis L\u00f3pez. 2020. Queer Community Input in Gender-Inclusive Translations. Linguistic Society of America [Blog].\\n\\nApril H Bailey, Adina Williams, and Andrei Cimpian. 2022. Based on billions of words on the internet, people= men. Science Advances, 8(13):eabm2463.\\n\\nSatanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65\u201372, Ann Arbor, Michigan. Association for Computational Linguistics.\\n\\nLuisa Bentivogli, Beatrice Savoldi, Matteo Negri, Matitia A. Di Gangi, Roldano Cattoni, and Marco Turchi. 2020. Gender in Danger? Evaluating Speech Translation Technology on the MuST-SHE Corpus. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6923\u20136933, Online. Association for Computational Linguistics.\\n\\nSu Lin Blodgett, Solon Barocas, Hal Daum\u00e9 III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of \\\"bias\\\" in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5454\u20135476, Online. Association for Computational Linguistics.\\n\\nStephanie Brandl, Ruixiang Cui, and Anders S\u00f8gaard. 2022. How conservative are language models? adapting to the introduction of gender-neutral pronouns.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "emnlp-2023-main-873", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Anne Lauscher, Debora Nozza, Archie Crowley, Ehm Miltersen, and Dirk Hovy. 2023. What about em? how commercial machine translation fails to handle (neo-)pronouns.\\n\\nMichela Menegatti and Monica Rubini. 2017. Gender Bias and Sexism in Language. In Oxford Research Encyclopedia of Communication vol.1, pages 451\u2013468. Oxford University Press, New York, USA.\\n\\nParmy Olson. 2018. The Algorithm That Helped Google Translate Become Sexist. https://bit.ly/olson_google_sexist. Accessed: 2023-06-20.\\n\\nPedro Javier Ortiz Su\u00e1rez, Beno\u00eet Sagot, and Laurent Romary. 2019. Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures. In 7th Workshop on the Challenges in the Management of Large Corpora (CMLC-7), Cardiff, United Kingdom. Leibniz-Institut f\u00fcr Deutsche Sprache.\\n\\nAnaelia Ovalle, Palash Goyal, Jwala Dhamala, Zachary Jaggers, Kai-Wei Chang, Aram Galstyan, Richard Zemel, and Rahul Gupta. 2023. \\\"i'm fully who i am\\\": Towards centering transgender and non-binary voices to measure biases in open language generation. In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, pages 1246\u20131266.\\n\\nDimitrios Papadimoulis. 2018. GENDER-NEUTRAL LANGUAGE in the European Parliament. European Parliament 2018.\\n\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.\\n\\nAndrea Piergentili, Dennis Fucci, Beatrice Savoldi, Luisa Bentivogli, and Matteo Negri. 2023. Gender neutralization for an inclusive machine translation: from theoretical foundations to open challenges.\\n\\nMaja Popovi\u0107. 2015. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392\u2013395, Lisbon, Portugal. Association for Computational Linguistics.\\n\\nSpencer Rarrick, Ranjita Naik, Varun Mathur, Sundar Poudel, and Vishal Chowdhary. 2023. Gate: A challenge set for gender-ambiguous translation examples.\\n\\nRicardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020. COMET: A neural framework for MT evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2685\u20132702, Online. Association for Computational Linguistics.\\n\\nAdithya Renduchintala and Adina Williams. 2022. Investigating failures of automatic translation in the case of unambiguous gender. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3454\u20133469, Dublin, Ireland. Association for Computational Linguistics.\\n\\nDanielle Saunders. 2022. Domain adaptation for neural machine translation. In Proceedings of the 23rd Annual Conference of the European Association for Machine Translation, pages 9\u201310, Ghent, Belgium. European Association for Machine Translation.\\n\\nDanielle Saunders and Katrina Olsen. 2023. Gender, names and other mysteries: Towards the ambiguous for gender-inclusive translation.\\n\\nDanielle Saunders, Rosie Sallis, and Bill Byrne. 2020. Neural machine translation doesn\u2019t translate gender coreference right unless you make it. In Proceedings of the Second Workshop on Gender Bias in Natural Language Processing, pages 35\u201343, Barcelona, Spain (Online). Association for Computational Linguistics.\\n\\nDanielle Saunders, Rosie Sallis, and Bill Byrne. 2022. First the worst: Finding better gender translations during beam search. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3814\u20133823, Dublin, Ireland. Association for Computational Linguistics.\\n\\nBeatrice Savoldi, Marco Gaido, Luisa Bentivogli, Matteo Negri, and Marco Turchi. 2021. Gender bias in machine translation. Transactions of the Association for Computational Linguistics, 9:845\u2013874.\\n\\nBeatrice Savoldi, Marco Gaido, Luisa Bentivogli, Matteo Negri, and Marco Turchi. 2022. Under the morphosyntactic lens: A multifaceted evaluation of gender bias in speech translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1807\u20131824, Dublin, Ireland. Association for Computational Linguistics.\\n\\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881\u20137892, Online. Association for Computational Linguistics.\\n\\nEmily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2021. Societal biases in language generation: Progress and challenges. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4275\u20134293, Online. Association for Computational Linguistics.\\n\\nJeanette Silveira. 1980. Generic Masculine Words and Thinking. Women\u2019s Studies International Quarterly, 3(2-3):165\u2013178.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Gender-Neutral Translation Survey\\n\\nThe questionnaire was released online in April 2023. We distributed it via targeted emails and social media posts, with a request to share with relevant groups. Participation in this survey was voluntary, uncompensated and anonymous, as no identifying or personal information about the participant was collected. Also, participants were free to withdraw at any time without penalty or consequence.\\n\\nAn anonymized version of the survey is accessible here: https://forms.gle/YL76UeWbe4NWdCPPA.\\n\\nNote that we did not target individuals who use MT as a professional tool. Rather, generic stakeholders that might have used MT directly or indirectly (e.g. being offered translations of web pages). They were made aware that results of the questionnaire would have been put to use for research on inclusive MT.\\n\\nScreening questions.\\nAs the survey required judging English \u2192 Italian translations, only participants with high competence of both Italian (C1 or higher) and English (B2 or higher) were eligible to take part in the survey. Accordingly, screening questions aimed to verify such language skills were placed at the beginning of the survey. Of the 101 received responses, 98 were from eligible participants and thus included in our analysis. The screening questions also excluded participants under 18.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sociodemographic information.\\n\\nTo gain sociodemographic information about our participant pools, the survey consisted of a short section asking for background information (e.g., educational level and field), as well as age and self-reported gender information. Overall, our pool of participants was quite homogeneous in terms of education levels (i.e., the majority of respondents had a master's degree) and age (with 24-35 being most represented age range). This was expected, because of the channels through which the survey was distributed, but especially in light of the high English competence required to take part in the survey. In terms of gender, the breakdown in Figure 6 shows an higher representation of the feminine segment of the population in the survey. Since participation to the survey was voluntary, it might have attracted individuals more interested in the topic.\\n\\nWe do not consider this homogeneity as a limitation per se. Rather, it allowed us to gauge the opinions of relevant, interested stakeholders, which are mostly affected by discriminatory language.\\n\\nLinguistic acceptability.\\n\\nThe pairs of source English sentences aligned with an Italian GT and NT were created by a professional linguist with prior experience on gender-inclusive language. The original source and GT parallel sentences were retrieved from the administrative/legislative domain of EU multilingual documents. The linguist then created the second NT.\\n\\nFrom a methodological perspective, we decided to pair the GT and NT alternatives so to allow for a fixed comparative term. Otherwise, different judgments of different NT translations alone would have not allowed for the isolation of gender-related factors from other aspects of the translations that could have influenced participants' perception of acceptability.\\n\\nThough not shown in the paper due to space constraints, for each example sentence in the survey the participants were directed to follow up questions, so to motivate their choice and provide more insights on the limits of the offered NT (see Figure 2). Overall, in this section, a total of 7 example translation were shown. Additionally, for 3 source English sentences, participants were asked to pick a preferred neutral translation from 4 different options.\\n\\nUse and attitude.\\n\\nThe last portion of the survey directly investigates users' attitude and perception toward gender-neutral language. For instance, in Figure 3, we attest that participants seem inclined to sacrifice brevity in favor of neutrality. Note that, since these questions focus on gender-neutral language \u2013 rather than translation \u2013 they conceptually preceded the section on linguistic acceptability. However, we placed them afterwards, so as to avoid influencing participants' responses on gender-neutral translations.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B GeNTE corpus details\\n\\nB.1 Data editing report\\n\\nIn our data editing process, we performed two types of interventions:\\n\\n(i) editing which was functional to the creation and the optimal use of the corpus (motivation described in \u00a74.1);\\n\\n(ii) editing aimed to improve the overall quality of corpus data.\\n\\nFunctional interventions (i) include two procedures:\\n\\n(A) the editing of source and reference sentences so as to have them only include referents that require the same type of either neutral or gendered forms (203 entries total);\\n\\n(B) the duplication of gendered entries, in which, then, the gendered words were replaced with equivalents of the opposite gender \u2013 thus we produced 126 masculine entries and 247 feminine ones (373 entries total).\\n\\nSome of the entries underwent both procedures. These procedures were performed on a total of 576 entries.\\n\\nWith the second type of interventions (ii) we improved the quality of the corpus data. We did so by correcting translation errors in the original references and removing extra elements in both source and reference sentences. For example, from the source sentence \\\"EN ) I would like, in particular, to thank Mrs Van den Burg, a Dutch Social Democrat who worked particularly hard on Article 25.\\\" we removed the segment \\\"EN ).\\\" We performed these corrections on a total of 89 corpus entries. Moreover, to improve the variability within the data, we replaced the most frequent noun which entailed a gendered translation, rapporteur, with other terms from the institutional/administrative linguistic domain (e.g., spokesperson, delegate, deputy). We performed this operation on 70 corpus entries.\\n\\nOverall, we edited 314 original source sentences and 393 original reference sentences.\\n\\nB.2 Challenges in the creation of gender-neutral references.\\n\\nFrom a qualitative perspective, two main type of challenges were identified in the creation of the neutral references:\\n\\n- Articles: in 11 instances, the translators produced partial neutralizations, as they overlooked masculine articles. This possibly suggests that, in Italian, articles may be perceived as secondary in expressing gender compared to nouns, adjectives, and verbs, even by native speakers. Regardless, all errors were spotted by the linguist and corrected.\\n\\n- Lexical gender: translators were unable to produce a neutralization for 4 instances of lexically gendered nouns such as 'sorella' (sister) and 'figlia' (daughter). Such cases all concerned the creation of neutral references for the SET-G \u2013 which served the purpose of the contrastive evaluation (Sec. 5) \u2013 but were particularly challenging as they required the use of neutral strategies for unequivocally gendered terms.\\n\\nLess problematic and systematic difficulties involved specific terms which the translators struggled with, such as 'deputato' (deputy). This is possibly due to the fact that some domain-specific terms and their translations, like 'deputy-deputato', are established and rooted in the language to the point where producing a gender-neutral translation is counter-intuitive and challenging. In all cases, the linguist intervened and proposed a solution e.g., 'persona deputata' (lit. deputed person).\\n\\nB.3 Linguistic diversity in GeNTE's gender-neutral references\\n\\nTable 7 reports our evaluation of the linguistic variability within the references of the COMMON-SET.\\n\\nTo perform such evaluation we computed BLEU scores matching every reference of each entry with the other two references of that entry. The scores show how there is a noticeable variability, which is attributable to the different neutralization strategies employed by the three translators. On one hand, the rather high BLEU scores indicate that the references are very similar \u2013 as expected, since they share all the original content of the gendered reference, except for the gender-related terms. On the other hand, their distance from a score of 100 BLEU points indicates that they are not perfectly identical. The variability appears coherent among the sets: the scores of the neutral references evaluated against other neutral references are especially similar in COMMON-SET-N, where the highest and the lowest scores differ by less than 1 BLEU point, possibly indicating that the neutralization strategies employed in this set were indeed different, but had very similar impact on the original sentences.\"}"}
{"id": "emnlp-2023-main-873", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 7: BLEU scores representing the linguistic variability in COMMON-SET\u2019s references.\\n\\n| Reference 1 | Reference 2 | Reference 3 |\\n|-------------|-------------|-------------|\\n| 75.14       | 77.65       | 74.14       |\\n| 75.14       | 75.09       | 72.08       |\\n| 77.59       | 75.03       | 74.89       |\\n\\nREF-G: 74.04 71.98 74.82\\n\\n| Reference 1 | Reference 2 | Reference 3 |\\n|-------------|-------------|-------------|\\n| 76.88       | 76.27       | 75.89       |\\n| 76.91       | 76.15       | 73.36       |\\n| 76.28       | 76.14       | 73.02       |\\n\\nREF-G: 75.78 73.26 72.92\\n\\nwere sourced from Europarl training data by means of keyword extraction, the other 100 were instead created from scratch. We then manually augmented this initial list of triplets by re-generating them with various inflectional morphology, which is relevant to distinguish for the task of neutralization (e.g., make them plural, use indefinite article etc.). Accordingly, we obtained \u223c800 triplets of seedwords.\\n\\nGeneration: first round. We prompted the gpt-3.5-turbo model from the GPT LLM family to generate triplets of sentences given the triplets of seed words. We used a few-shot approach with given examples of the task to be performed (see Figure 4.). We access the model via OpenAI paid API and setting a temperature of 0.5. In total, approximately 60,000 sentences were generated. A random sample of 100 sentences was manually inspected, revealing that noise was very low (10%), but that the sentences exhibited a simple structure, consistently placing the subject at the beginning.\\n\\nGeneration: second round. To enhance the quality and textual context of the generated sentences, a second round of generation was performed using a lower temperature of 0.3 (see Figure 5). Each triplet of sentences was rewritten multiple times in different forms. This process resulted in the generation of approximately 320,000 sentences, which had a higher occurrence of incorrect alternatives for the seedwords, estimated to be around 40% based on the inspection of 100 randomly selected sentences. The final synthetic corpus consists of approximately 380,000 sentences, featuring varied sentence structures. Specifically, one-third of the sentences contain a masculine seedword, another third contain a feminine seedword, and the remaining third contain a neutral seedword. Overall, a cost of $13.12 USD was estimated.\\n\\nC.2 Training Setup\\n\\nWe trained the parameters of both the linear layer and UmBERTo on the classification task for 2 epoch, with learning rate of 5e-5, batch size of 64 and maximum sequence length of 64, on a p3.2xlarge instance on AWS (featuring one NVIDIA V100 GPU). The code for finetuning relies on Huggingface transformers library (Wolf et al., 2020).\"}"}
