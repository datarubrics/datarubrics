{"id": "lrec-2022-1-442", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Tweet Emotion Dynamics: Emotion Word Usage in Tweets from US and Canada\\n\\nKrishnapriya Vishnubhotla\u2217\u2021 and Saif M. Mohammad\u2020\\n\\n\u2217Department of Computer Science, University of Toronto\\n\u2021Vector Institute for Artificial Intelligence\\nvkpriya@cs.toronto.edu\\n\u2020National Research Council Canada\\nsaif.mohammad@nrc-cnrc.gc.ca\\n\\nAbstract\\nOver the last decade, Twitter has emerged as one of the most influential forums for social, political, and health discourse. In this paper, we introduce a massive dataset of more than 45 million geo-located tweets posted between 2015 and 2021 from US and Canada (TUSC), especially curated for natural language analysis. We also introduce Tweet Emotion Dynamics (TED)\u2014metrics to capture patterns of emotions associated with tweets over time. We use TED and TUSC to explore the use of emotion-associated words across US and Canada; across 2019 (pre-pandemic), 2020 (the year the pandemic hit), and 2021 (the second year of the pandemic); and across individual tweeters. We show that Canadian tweets tend to have higher valence, lower arousal, and higher dominance than the US tweets. Further, we show that the COVID-19 pandemic had a marked impact on the emotional signature of tweets posted in 2020, when compared to the adjoining years. Finally, we determine metrics of TED for 170,000 tweeters to benchmark characteristics of TED metrics at an aggregate level. TUSC and the metrics for TED will enable a wide variety of research on studying how we use language to express ourselves, persuade, communicate, and influence, with particularly promising applications in public health, affective science, social science, and psychology.\\n\\nKeywords: Emotions, Sentiment analysis, Tweets, Valence, Arousal, Dominance, Corpus Linguistics\\n\\n1. Introduction\\nOver the last decade, Twitter has emerged not only as one of the most influential micro-blogging platforms, but also one of the most actively engaging (if sometimes polarizing) fronts for social, political, and even health discourse. Early work (Pak and Paroubek, 2010; Dodds et al., 2011) identified tweets as a crucial indicator of public sentiment. Since then, various samples of tweet data have been used to analyze a wide variety of phenomena, including the recent COVID-19 pandemic. However, past work largely uses topic-based keywords to obtain datasets of interest (often at the expense of geo-location information); for example, work that analyzes emotions in tweets that mention COVID-19-associated terms (Banda et al., 2020; Lwin et al., 2020). Further, very little work explores changes in patterns of emotions of individuals over time.\\n\\nThis paper introduces a new framework to analyze patterns of emotions associated with tweets over time, which we refer to as Tweet Emotion Dynamics (TED). TED builds on ideas first introduced in Hipson and Mohammad (2021), and applies metrics such as home base, variability, and rise rate to tweets. We also introduce a new dataset of geo-located English Tweets from US and Canada (TUSC). TUSC is not restricted to specific topics and so can be used to study tweets in general, as well as to study notable phenomena (such as a pandemic, climate change, or polarizing political events) on tweets at large (as opposed to examining tweets directly discussing those phenomena). TUSC also includes a subset, (TUSC100), made up of tweets from 170K tweeters who each posted at least a 100 tweets between 2020 and 2021. TUSC100 is especially well suited for longitudinal analysis. The creation of the datasets included careful post-processing to make the resource particularly suitable for textual analysis. TUSC and TED can each be used, together or independently, to explore a wide range of research questions pertaining to tweets and emotions that may be of interest to researchers in Psychology, Affective Science, Social Science, Behavioural Science, Public Health, NLP, and Linguistics. In this paper, we use them to explore questions about how people use emotion-associated words in English tweets from US and Canada.\\n\\nWe record the common characteristics of emotion word usage from 2015 to 2021, with a special focus on 2020 \u2014 the year that the WHO declared the Novel Coronavirus Disease (COVID-19) outbreak to be a pandemic \u2014 and its adjoining years (2019 and 2021). Finally, we benchmark individual tweeter behaviour in terms of various TED metrics. Recording this information holds considerable promise in future work; for example, for studying the emotional impact of the pandemic, for helping clinicians and patients track emotional well-being before and after health interventions, studying emotion regulation and coping strategies, etc. The data (tweet IDs), Emotion Dynamics code, and visualizations are freely available through the project homepage.\\n\\n1 Words have associations with emotions; e.g., success with pleasure, illness with displeasure, etc.\\n\\n2 https://github.com/Priya22/EmotionDynamics\"}"}
{"id": "lrec-2022-1-442", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We group related work into two kinds: 1. psychological and psychology-inspired research on the theory of emotions and utterance emotion dynamics; and 2. NLP research in analyzing emotions in tweets.\\n\\n2.1. Emotions\\n\\nSeveral influential studies have shown that the three most fundamental, largely independent, dimensions of affect and connotative meaning are valence (V) (positiveness\u2013negativeness / pleasure\u2013displeasure), arousal (A) (active\u2013sluggish), and dominance (D) (dominant\u2013submissive / in control\u2013out of control) (Osgood et al., 1957; Russell and Mehrabian, 1977; Russell, 2003). Valence and arousal specifically are commonly studied in a number of psychological and neuro-cognitive explorations of emotion.\\n\\nThe NRC V AD Lexicon (Mohammad, 2018) contains about twenty thousand commonly used English words (lemmas and common morphological variants) that have been scored on valence (0 = maximally unpleasant, 1 = maximally pleasant), arousal (0 = maximally calm/sluggish, 1 = maximally active/intense), and dominance (0 = maximally weak, 1 = maximally powerful).\\n\\nAs an example, the word nice has a valence of .93, an arousal of .44, and dominance of .65, whereas the word despair has a valence of .11, an arousal of .79, and dominance of .25.\\n\\nHipson and Mohammad (2021) introduced Utterance Emotion Dynamics (UED), a framework to quantify patterns of change of emotional states associated with utterances along a longitudinal (temporal) axis. Specifically, they proposed a series of metrics, including:\\n\\n1. Density or Mean: A measure of the average utterance emotional state. For example, the proportion of emotion words a person utters over a given span of time. If each word has a real-valued emotion score (say, for V, A, and D), then this is calculated as the mean of emotion scores of the words in the utterance window. This roughly captures the utterance emotional state.\\n\\n2. Variability: The extent to which a speaker's utterance emotional state changes over time (measured as the standard deviation of the emotion states).\\n\\n3. Home Base: A speaker's home base is the subspace of high-probability emotional states where they are most likely to be found. This is formulated as the range of values within one standard deviation of the average of the emotion states at each timestep.\\n\\n4. Rise and Recovery Rates: Sometimes a speaker moves out of their home state, reaches a peak value of emotion state, before returning to the home state. The rise rate quantifies the rate at which a speaker moves towards the peak; recovery rate is the rate at which they go from the peak to the home state.\\n\\nOne can determine UED metrics using: 1. the utterances by a speaker, 2. the temporal information about the utterances, for e.g., time stamps associated with the utterances, or simply an ordering of utterances by time, and 3. features of emotional state drawn from text. The emotional state at a particular instant can be determined using simple lexical features (say, drawn from emotion lexicons), predictions of supervised machine learning systems, etc.\\n\\nHipson and Mohammad (2021) apply this framework to utterances from a corpus of movie dialogues, which are naturally ordered along a temporal axis. They represented emotional state in a two-dimensional valence\u2013arousal space. The co-ordinates are determined by the average valence and arousal scores of the words (using the NRC V AD lexicon) in a small window of recent utterances (usually spanning 20 to 50 words). Rolling windows of words (moving forward one-word at a time) determine the sequence of emotional states. Here, we apply that framework to tweets. However, in this work we consider each of the valence, arousal, and dominance dimensions separately (separate one-dimensional axes).\\n\\n2.2. Analyzing Emotions in Tweets\\n\\nDodds et al. (2011) analyzes large amounts of Twitter data to explore temporal patterns of 'societal happiness'. Larsen et al. (2015) show a correlation between patterns of emotional expression in tweets with WHO data on anxiety and suicide rates, across geographical location. Snefjella et al. (2018) analyze differences in language use in 40 million tweets from Canada and the USA, and find that the former tend to use more positive language, which correlates with national character stereotypes of Canadians being more agreeable and less aggressive. Twitter data has been used to study people's emotions during significant events, commonly revolving around certain tragedies and natural disasters, and significant political events. Dore et al. (2015) studied the changes in intensity of emotions of anxiety, anger, and sadness expressed on Twitter regarding the Sandy Hook Elementary School shooting. The 2016 US Presidential Election spurred several studies on the language used across geographical and political lines (Littman et al., 2016). Twitter was also used to measure the impacts of the COVID-19 pandemic on the emotional states and mental health of tweeters (Banda et al., 2020). Lwin et al. (2020), for example, looked at changes in the usage of tweets that expressed fear, anger, sadness, and joy in COVID-associated tweets from January 28 to April 9 2020. In our work, we focus on the emotion dimensions of valence, arousal, and dominance, rather than categorical dimensions such as anger, fear, sadness, etc. We also study these patterns of emotion usage across a large time period (2015\u20132021), and in geo-located tweets.\"}"}
{"id": "lrec-2022-1-442", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3. Tweets Dataset: TUSC\\n\\n3.1. Sampling Tweets\\n\\nTwitter\u2019s regular API allows one to obtain a random sample of tweets from the past week. However, the search is limited to only the tweets from the past week. The Academic search API provides access to historical tweets, but with a lower rate limit. To benefit from both APIs and to confirm that our results are consistent regardless of the API and search method, we compiled two separate tweet datasets using each of the APIs:\\n\\n1. using Twitter\u2019s free API and its geo-location and random-sample switches to collect tweets from 46 prominent American and Canadian cities. Data collection began in April 1, 2020 and is ongoing. We refer to the dataset created with this method as TUSC-City.\\n\\n2. using Twitter\u2019s Academic API to collect tweets emanating from US and Canada from Jan 2015 to Dec 2021. The Academic API provides switches to specify the country of origin and the time span of search. However, the sample of results it provides tend to be in reverse chronological order for the specified time span. Thus, to obtain a sample of tweets from various time spans across the various years of interest, we employed the following strategy: For each year of interest, we randomly generated a date time (using unix epoch seconds). We then specified a search interval of 8 hours starting from that date time. We repeated this procedure thousands of times for each year. Since we were especially interested in the years of 2019, 2020, and 2021, we collected more data from these years. We refer to the resulting dataset as TUSC-Country.\\n\\n3.2. Tweet Curation\\n\\nWe curated the tweet collection to make it more suitable for computational natural language analyses by applying the following steps:\\n\\n- Kept one tweet per user, per day. This mitigates the impact of highly prolific tweeters and commercial accounts on the dataset.\\n- Kept only English language tweets (since the English set is the focus of this project). These are identified by the iso language tag provided by Twitter for each tweet.\\n- Removed all retweets.\\n- Removed all tweets containing a URL and/or links to media (to focus on textual tweets). This also limits tweets by commercial organizations.\\n- Discarded all tweets with less than three tokens. This eliminates certain formulaic tweets such as wishes for holidays. The tweet text is tokenized using the Python implementation of the Twokenizer package (Gimpel et al., 2010; Owoputi et al., 2013). We kept quotes and replies as they include new textual information.\\n\\n3.3. Key Data Statistics and Distribution\\n\\nWe organize the TUSC tweets as per the sampling strategy used to obtain them (see TUSC-Country and TUSC-City in \u00a73.1) as well as the year of posting (2015 through 2021), and country of origin (US, Canada). Table 1 shows the number of tweets, number of tweeters, and average number of tokens per tweet in each of these dataset groupings. (Table 3 in the Appendix shows a breakdown by city for TUSC-City.) It is interesting that an average Canadian tweet has about two more tokens per tweet than a US tweet (one possible explanation is the tendency of American tweeters to use more informal and non-standard language, as found in Snefjella et al. (2018)).\\n\\nTUSC-City is the larger dataset, and contains millions of tweets for many of the 46 cities for 9 months in 2020 (Apr\u2013Dec), and all the months of 2021. It is useful for analyzing trends at the city\u2013level, and also at the user-level, since we are more likely to have a large number of tweets from the same user.\"}"}
{"id": "lrec-2022-1-442", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4. Emotion Word Usage in American and Canadian Tweets\\n\\nThe TUSC datasets can be used to answer several important questions about emotion word usage in English tweets from US and Canada, including:\\n\\n- Are there notable trends across years in the valence, arousal, and dominance of tweets? Are we tweeting with more positive words, more negative words, more high arousal words, etc. than in past years?\\n- How has the COVID-19 pandemic impacted the emotionality of our tweets? At what point of time in the pandemic did we use the most amount of words conveying a lack of control and uncertainty? How were individual cities impacted?\\n- How are Canada and US different in terms of emotion word usage? Did the pandemic impact the emotionality differently in the two countries?\\n\\nWe will explore these, and other, questions below.\\n\\nWe used the NRC Valence, Arousal, and Dominance (NRC VAD) Lexicon (Mohammad, 2018) to determine the emotion associations of the words in tweets. Specifically, we used the subset with entries for only the polar terms: i.e., only those valence entries that had scores \\\\( \\\\leq 0.33 \\\\) (negative words) or scores \\\\( \\\\geq 0.67 \\\\) (positive words). Similarly, only those arousal and dominance entries were included that had scores \\\\( \\\\leq 0.33 \\\\) or \\\\( \\\\geq 0.67 \\\\). The entries with scores between 0.33 and 0.67 are considered neutral for that dimension.\\n\\nMethodological Note 1: As is good practice in lexicon-based analysis (Mohammad, 2020), we removed lexicon entries for a small number of words that were highly ambiguous (e.g., will, like) or were expected to be frequently used in our tweets in a sense that is different from the usual predominant sense of the word (e.g., trump). The list of the 23 terms removed from the lexicon, and a description of the process of discovering them, is available in the Appendix.\\n\\nMethodological Note 2: Similar analyses can also be performed using categorical emotions, such as joy, sadness, fear, anger, etc., using the NRC Emotion Lexicon (Mohammad and Turney, 2010; Mohammad and Turney, 2013).\\n\\n4.1. Average V, A, and D Across US\u2013Canada\\n\\nFor each tweet, we take the average of the valence, arousal, and dominance values of each of the words in the tweet text. The averages are computed for TUSC-City over all tweets from each city, and for TUSC-Country at the country-level. We test whether the differences in values between countries and years are statistically significant by using the paired t-Test, with the significance threshold for the \\\\( p \\\\)-value set to 0.001.\\n\\nYearly Trends: Figure 1 shows the average V, A, and D scores of tweets when aggregated at the country and year level, for the various data subsets. The gradient bars at the top show the colors used to indicate where the values lie in the spectrum from lowest to highest.\\n\\nValence: Observe that the average valence of Canadian tweets is consistently higher (more positive) than the tweets from the US (statistically significant); the differences are steady across years. There is a slight downward trend for valence in both countries from 2015 to 2019. We see the lowest values of mean valence occur in 2020 for both TUSC-Country and TUSC-City (the year the pandemic hit) for both the US and Canada. Average valence rises back up in 2021.\"}"}
{"id": "lrec-2022-1-442", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Arousal: Overall, tweets from Canada have lower average arousal (more calm, less active) than the US (statistically significant). Again, the difference in mean between the two countries remains relatively steady across years. Across years, arousal values for both countries increase from 2015 till 2017; they then drop steadily for Canada, while the USA sees a peak in 2019 followed by slight drops in subsequent years.\\n\\nDominance: Canada on the whole consistently has higher dominance values (greater feeling of control) than the US across the years. For all three dimensions, we note that the yearly trends observed in TUSC-Country are largely also observed in the TUSC-City trends, across 2020\u20132021.\\n\\nMonthly Trends: Figure 2 shows a breakdown of the average valence scores at the month level, across years. (Figures 6 and 7 in the Appendix show the breakdown for arousal and dominance.) We immediately notice from the color shading that Canada consistently has higher valence (green), lower arousal (blue), and higher dominance (purple) than the US, across the months and years. June 2020 is particularly notable as it has the lowest values of valence for both USA and Canada; we hypothesize that this is an effect of both the COVID-19 pandemic (the seriousness of which was starting to become evident a couple of months earlier in March 2020) and the Black Lives Matter protests (which peaked after the Dylan Roof shooting incident). By contrast, the final months of 2021 have the highest positivity. This could be attributed to feelings of a potential return to normalcy, and a general uptick in mood due to the holiday season (this was just before the Omicron variant took root in early 2022). The dominance numbers indicate that April and May of 2020 for Canada and the USA are marked by some of the lowest scores, suggestive of a feeling of loss of control due to the onset of the global COVID-19 pandemic.\\n\\n4.2. Tweets with Emotional Terms\\n\\nThe experiments above showed notable differences in the average V/A/D scores of tweets across US and Canada. However, they also lead to further questions such as whether the higher valence in Canadian tweets is because of a greater usage of positive words or a lower usage of negative words. To explore such questions, we determine how frequently people post tweets with at least one high valence word, how frequently people post tweets with at least one low valence word, how frequently people post tweets with at least one high arousal word, and so on. High and low categorization of a word is based on whether their score (for V/A/D) is \\\\( \\\\geq 0.67 \\\\) or \\\\( \\\\leq 0.33 \\\\), respectively. Figure 3 shows the results.\\n\\nThe darker shades of the color indicate a greater percentage of tweets had at least one of the relevant emotional words. Observe that in both American and Canadian tweets:\\n\\n- people post markedly more tweets with at least one positive word than tweets with at least one negative word (about 100% more).\\n- people post markedly more tweets with at least one low arousal word than tweets with at least one high-arousal word (about 40% more).\\n- people post markedly more tweets with at least one high dominance word than tweets with at least one low-dominance word (about 33% more).\\n\\nIn terms of their differences, we see that the tweets from Canada are marked by both a higher usage of high-valence words, as well as a lower usage of low-valence words, than the US (statistically significant). Tweets from Canada have a higher proportion of low arousal words, whereas high arousal word usage is similar in both countries. Canadian tweeters use about the same number of low dominance words as those in the US, but use a greater number of high dominance words. Across years, low valence words increase in usage relatively steadily until 2020, and drop in 2021. For all dimensions, the sharpest rise in usage occurs from 2016 to 2017. When comparing TUSC-Country 2020 with 2021, observe that the higher number of low valence words used is more prominent than the lower number of high valence words \u2014 thus, the drop in average valence in 2020 (Figure 1) is because people tweeted more negative words (and not because people tweeted less positive words).\"}"}
{"id": "lrec-2022-1-442", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Percentage of tweets with at least one \u2014 low valence word, high valence word, low arousal word, high arousal word, low dominance word, high dominance word \u2014 across datasets (years).\\n\\nSee Vishnubhotla and Mohammad (2022) for an analysis of the topics driving the differences across V, A, and D: across the years, and across US and Canada.\\n\\n5. Tweet Emotion Dynamics\\n\\nWhile the previous section looked at samples of tweets emanating from countries and cities as a whole, in this section we explore individual tweeter behaviours and metrics of emotion word usage over time. Specifically, we apply the framework of Utterance Emotion Dynamics (UED) (Hipson and Mohammad, 2021) to tweets to explore a number of questions, such as:\\n\\n- What is the usual range and distribution of various metrics of tweet emotion dynamics (TED), such as mean and recovery rate, for American and Canadian tweeters? Establishing benchmarks for these metrics is crucial for subsequent studies that may explore, for example, the impact of a health intervention on one's TED metrics.\\n- Are there notable differences in the distributions of TED metrics across American and Canadian tweeters?\\n- Are there notable differences in the distributions of TED metrics across 2020 and 2021?\\n\\nRecall that computing UED metrics requires: 1. a set of texts associated with each speaker, 2. a temporal ordering of these texts, and 3. a way to determine emotions associated with the texts. The timestamp of a tweet provides the temporal order. The tweets from each speaker are then concatenated together and tokenized to obtain an ordered list of tokens. Next, a rolling window of 20 tokens is considered to determine the average V, A, and D scores of the words in that window. These scores are a representation of utterance emotional state corresponding to that window. The rolling window is moved forward one word at a time to determine the subsequent averages.\\n\\nIn the rest of this section, we use the term mean to refer to the mean of all the rolling window averages for a speaker. We re-implemented the Hipson and Mohammad (2021) R code in Python. Also, rather than using the valence\u2013arousal two-dimensional (ellipse-based) representation of emotions explored in their work, we analyse the dynamics of each emotion dimension separately along one-dimensional axes. This eases the interpretation of the UED metrics, and allows for considering more dimensions such as dominance. We also break down the rise and recovery rates into separate rates corresponding to when one is moving from the home base to higher emotion values (Hm\u2013Hi), from the highest value to home (Hi\u2013Hm), from the home base to lower emotion values (Hm\u2013Lo), and from the lowest value to home (Lo\u2013Hm). This allows us to explore whether, for example, some tweeters have close-to-median Hi\u2013Hm rates, but markedly low Lo\u2013Hm rates (indicating that once they start uttering negative words, then they tend to dwell in the negatives and only gradually return to their home state).\\n\\nWe use the code to determine TED metrics for the tweeters in the TUSC-Country dataset. Only tweeters with at least 100 tweets in a year were considered, since drawing inferences about one's tweeting behaviour requires a sufficient sample size. There were about 40K such tweeters in the 2020 subset and about 130K such tweeters in the 2021 subset. We refer to their tweets (5.6M from 2020 and 19M from 2021) as the TUSC100-2020 and TUSC100-2021 datasets, respectively. Average number of tweets by a tweeter in these datasets is 153 (no tweeters had more than 365 tweets due to our earlier stated \u2018one tweet per user per day\u2019 pre-processing policy). See Table 4 in the Appendix for detailed statistics.\\n\\nFigure 4 plots the distributions of some of the metrics for the joint set of 2020 and 2021 tweeters. The plots in (a) are distributions of the mean values for the three emotion dimensions (V, A, D). The x-axis is made up of bins of size 0.005 (from 0\u20130.005 to 0.995\u20131). The variations of this approach that do not use rolling windows across tweet boundaries produce similar results.\"}"}
{"id": "lrec-2022-1-442", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Distributions of Means, Rise Rates, and Recovery Rates for Valence, Arousal, and Dominance (TUSC100).\\n\\nThe y-axis indicates the number of tweeters with mean values in each of the bins. Observe that the means for V, A, and D all follow a near-normal distribution. Mean valence and dominance values are more spread out compared to arousal values. For V, most fall between 0.5\u20130.8, with a median value of around 0.65, though we can see that there is a long tail of outliers. Dominance scores are spread around a median score of 0.6, and the median is even lower for arousal (0.49).\\n\\nFigure 4(b) shows distributions for rises rates and recovery rates. Observe that these have a much narrower spread, and the distributions for all three dimensions are roughly the same.\\n\\nFigure 5 shows box and whisker plots of the same three metrics: mean, rise rate, and recovery rates. However, separate plots are shown for tweeters from US and Canada, and across 2020 and 2021. The shaded region (the box) indicates the \u201cmiddle portion\u201d of the data distribution, i.e., the range covered between the first quartile (the 25% mark) and the third quartile (the 75% mark), with the median (50% mark) lying at the border of the light and dark shaded regions. The whiskers, the lines on either end of the plot, are at a distance of 1.5 times the inter-quartile length (inter-quartile length is the distance between the first and third quartiles). Points beyond the whiskers are considered outliers. Additionally, the average value (mean) is indicated with the pink horizontal dashed line.\\n\\nObserve that the mean valence is lower in 2020 than in 2021, and Canadian tweeters on average use more positive words than their US counterparts. The trends align with the trends observed in Table 2.\\n\\nThe distributions for mean arousal are quite similar across 2020 and 2021, but US tweeters have slightly higher mean arousal values. Canadian tweeters have a slightly higher median of dominance scores than US tweeters; whereas the US tweeters tend to have a wider range of dominance values. The difference in the distributions of the mean values for Canada and US is statistically significant for all three dimensions ($p$-values < 0.001).\\n\\nThe median rise rates and recovery rates do not differ markedly across countries or years. However, there is a notably large range of the third quartile (the quartile above the median) for Canadian tweeters in 2021. These are tweeters who are quicker to jump in and out of their home base. Tables 5, 6, 7 of the Appendix report mean scores for all of the TED metrics, averaged across all tweeters by country and year. This includes a breakdown of the rates into Hm-Hi, Hi-Hm, Hm-Lo, and Lo-Hm. Notable trends there are that the average rise and recovery rates on the high side of the home state (Hm-Hi, Hi-Hm) are lower than for the low side of the home state (Lo-Hm, Hm-Lo), for the valence and dominance dimensions. This says that tweeters are slower to rise to more positive and more dominant states, but quicker to both descend to more negative and less dominant states, and recover from them; similarly, they are slower to transit to and from states of high activity (high dominance). This difference between Hi and Lo rates is reversed for arousal. Thus, we are quicker to rise to states of high arousal, and come back down from them to the home state.\\n\\nWe also noticed in our analyses that there exist several tweeters that have very high rise rates but normative recovery rates, and also tweeters that have very high rise rates but normative recovery rates. Identifying such characteristics and tracking them in the context of health interventions is particularly promising future work. However, it should be noted that we strongly encourage such studies, when conducted, to be led by clinicians and psychologists, with appropriate consent and ethics approvals.\\n\\n5.1. City as Speaker\\n\\nAn interesting variation of the experiments above, is to consider each city as a \u2018speaker\u2019, rather than individual tweeters. Figure 8, in the Appendix, shows the average TED metrics for each of the 46 cities in TUSC-City. The color gradients make it easy to spot which cities have had markedly high V/A/D means across 2020 and 2021. Consistent with some of the earlier country-level results, we see that the Canadian cities tend to have higher valence, lower arousal, and higher dominance, than the US cities. London, Ottawa, Halifax, and Victoria have the highest valence (most positive). From the set of Canadian cities, Windsor stands out as an anomaly with valence close to many US cities. Detroit, Houston, Los Angeles, and Philadelphia have some of the lowest valence values of all cities. All cities improve from 2020 to 2021, some more drastically than...\"}"}
{"id": "lrec-2022-1-442", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Box plots of means, rise rates, and recovery rates of Valence, Arousal, and Dominance of tweeters in 2020 and 2021 (TUSC100-2020 and TUSC100-2021).\\n\\nQuebec City and Windsor have the highest arousal rates in Canada; in the US, El Paso is at the top for both years. Nashville, San Francisco, San Jose, and Seattle have lower arousal rates (more in line with the average Canadian city). Washington, San Jose, and Boston also show markedly high dominance, as well as San Francisco. Among Canadian cities, Ottawa and Victoria have the highest dominance scores for 2020 and 2021, and Windsor again the lowest.\\n\\nFigure 9, in the Appendix, shows values of the variabilities, rise rates, and recovery rates for the valence dimension. Looking at the column for variability, Windsor jumps out among the Canadian cities for having comparatively higher variability. Washington and Phoenix in 2020 have relatively high variability. Moving to the next columns, Windsor again has the highest rise and recovery rates among Canadian cities; US cities are the on the whole quicker to rise and fall.\\n\\nThe various metrics listed for various cities should be useful to those interested in the tweets from particular cities. Future work will drill down further into the data for individual cities to determine the factors driving the emotion word usage.\\n\\n6. Conclusion\\n\\nWe introduced the Tweet Emotion Dynamics (TED) framework to quantify changes in emotions associated with tweets over time. We also released TUSC \u2014 a large collection of English geo-located tweets from Canada and the USA that were posted between 2015 and 2021. We studied emotion word usage in this data, using multiple metrics, for the primary dimensions of valence, arousal, and dominance. Our results showed interesting trends in the emotions expressed by tweeters from the two countries across different years, and also uncovered contrasts between Canadian and US tweeters. An expanded version of this paper presents further experiments, including a deeper analysis of the words and topics driving the TED metrics (Vishnubhotla and Mohammad, 2022). Future work will explore tweets from other countries and also tweets in languages other than English. We will also examine how the TED framework can be useful to clinicians and psychologists for measuring mental health outcomes, at an aggregate level, from social media data. Additionally, we will study the applications of Utterance Emotion Dynamics in other contexts such as novels, personal diaries, forum posts, and speech.\"}"}
{"id": "lrec-2022-1-442", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We thank Will Hipson for early discussions on his R code for utterance emotion dynamics. The first author is supported by funding from the Natural Sciences and Engineering Research Council of Canada, and resources provided by the Vector Institute of Artificial Intelligence.\\n\\n7. Bibliographical References\\n\\nBanda, J. M., Tekumalla, R., Wang, G., Yu, J., Liu, T., Ding, Y., and Chowell, G. (2020). A large-scale COVID-19 twitter chatter dataset for open scientific research - an international collaboration. CoRR, abs/2004.03688.\\n\\nDodds, P. S., Harris, K. D., Kloumann, I. M., Bliss, C. A., and Danforth, C. M. (2011). Temporal patterns of happiness and information in a global social network: Hedonometrics and twitter. PloS one, 6(12):e26752.\\n\\nDor\u00e9, B., Ort, L., Braverman, O., and Ochsner, K. N. (2015). Sadness shifts to anxiety over time and distance from the national tragedy in Newtown, Connecticut. Psychological Science, 26(4):363\u2013373. PMID: 25767209.\\n\\nGimpel, K., Schneider, N., O'Connor, B., Das, D., Mills, D., Eisenstein, J., Heilman, M., Yogatama, D., Flanigan, J., and Smith, N. A. (2010). Part-of-speech tagging for twitter: Annotation, features, and experiments. Technical report, Carnegie-Mellon Univ Pittsburgh Pa School of Computer Science.\\n\\nHipson, W. E. and Mohammad, S. M. (2021). Emotion dynamics in movie dialogues. PLOS ONE, 16:1\u201319, 09.\\n\\nLarsen, M. E., Boonstra, T. W., Batterham, P. J., O'Dea, B., Paris, C., and Christensen, H. (2015). We feel: mapping emotion on twitter. IEEE journal of biomedical and health informatics, 19(4):1246\u20131252.\\n\\nLittman, J., Wrubel, L., and Kerchner, D. (2016). 2016 United States Presidential Election Tweet Ids.\\n\\nLwin, M. O., Lu, J., Sheldenkar, A., Schulz, P. J., Shin, W., Gupta, R., and Yang, Y. (2020). Global sentiments surrounding the covid-19 pandemic on twitter: Analysis of twitter trends. JMIR Public Health Surveill, 6(2):e19447, May.\\n\\nMohammad, S. M. and Turney, P. D. (2010). Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon. In Proceedings of the NAACL-HLT Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, LA, California.\\n\\nMohammad, S. M. and Turney, P. D. (2013). Crowdsourcing a word-emotion association lexicon. Computational Intelligence, 29(3):436\u2013465.\\n\\nMohammad, S. M. (2018). Obtaining reliable human ratings of valence, arousal, and dominance for 20,000 english words. In Proceedings of The Annual Conference of the Association for Computational Linguistics (ACL), Melbourne, Australia.\\n\\nMohammad, S. M. (2020). Practical and ethical considerations in the effective use of emotion and sentiment lexicons. arXiv:2011.03492.\\n\\nMohammad, S. M. (2021). Sentiment analysis: Automatically detecting valence, emotions, and other affectual states from text. In Herbert L. Meiselman, editor, Emotion Measurement (Second Edition), pages 323\u2013379. Woodhead Publishing, second edition edition.\\n\\nMohammad, S. M. (2022). Ethics sheet for automatic emotion recognition and sentiment analysis. To Appear in Computational Linguistics.\\n\\nOsgood, C. E., Suci, G. J., and Tannenbaum, P. (1957). The measurement of meaning. University of Illinois Press.\\n\\nOwoputi, O., O'Connor, B., Dyer, C., Gimpel, K., Schneider, N., and Smith, N. A. (2013). Improved part-of-speech tagging for online conversational text with word clusters. In Proceedings of the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies, pages 380\u2013390.\\n\\nPak, A. and Paroubek, P. (2010). Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10).\\n\\nRussell, J. A. and Mehrabian, A. (1977). Evidence for a three-factor theory of emotions. Journal of research in Personality, 11(3):273\u2013294.\\n\\nRussell, J. A. (2003). Core affect and the psychological construction of emotion. Psychological review, 110(1):145.\\n\\nSnefjella, B., Schmidtke, D., and Kuperman, V. (2018). National character stereotypes mirror language use: A study of canadian and american tweets. PloS one, 13(11):e0206188.\\n\\nVishnubhotla, K. and Mohammad, S. M. (2022). Tweet emotion dynamics: A framework to analyze emotions over time. In ArXiv.\"}"}
{"id": "lrec-2022-1-442", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"rather, we draw inferences on the emotions that are conveyed by users via the language that they use.\\n\\n- The language used in an utterance may convey information about the emotional state (or perceived emotional state) of the speaker, listener, or someone mentioned in the utterance. However, it is not sufficient for accurately determining any of their momentary emotional states. Deciphering true momentary emotional state of an individual requires extra-linguistic context and world knowledge. Even then, one can be easily mistaken.\\n\\n- The inferences we draw in this paper are based on aggregate trends across large populations. We do not draw conclusions about specific individuals or momentary emotional states.\\n\\n- We do not recommend the use of TED metrics to draw inferences about individuals, unless: 1. it is exercised with extreme caution, 2. for the express benefit, and with consent, of the people whose data is used, 3. the work is led by subject-matter experts such as psychologists or clinicians, and 4. automatically drawn information is used as one source of information among many by human experts.\\n\\n- Any information drawn from these metrics regarding one's language use should not be used to negatively impact the individual.\\n\\nSee Mohammad (2022) for a detailed discussion on the ethical considerations of automatic emotion recognition and Mohammad (2020) for practical and ethical considerations in the effective use of emotion lexicons.\\n\\n9. Additional Emotion Word Usage Statistics from TUSC\\n\\nWe present, in this section, additional tables and figures that record details of emotion word usage broken down by city (for the 46 cities considered) and by month of year. Table 4 shows the number of tweets and tweeters in each subset of the TUSC100 dataset. Tables 5, 6, and 7 tabulate the numbers corresponding to the plots in Figure 5 in the main paper.\\n\\n10. Modified NRC V AD Lexicon\\n\\nWhen applying lexicon-based analyses to datasets from a specific domain, Mohammad (2020) recommends updating the emotion lexicons to remove terms that can be used in a sense different from the predominant word sense. Since manual examination of all the words in a large dataset is difficult, this step is recommended for at least the frequent terms.\\n\\nFor our analyses, we first compiled a list of all the terms from the NRC V AD lexicon that occurred in at least 0.1% of the tweets from either Canada or the USA, for any of the years in the TUSC-Country dataset (2015\u20132021). Both of the authors of this work examined the list and identified words that were highly ambiguous or occurred in the tweets predominantly in a sense different from what would be expected if people have will one high may way kind be thing things number seem do look three third five senate say talk president trump like were shown the word out of context (as was the case of the original annotations in the NRC V AD lexicon).\\n\\nIn all, 23 such words were identified (shown in Table 2). The entries for these words were removed from the lexicon before conducting the experiments described in the paper.\\n\\nTo examine the impact of the above lexicon update, we repeated all the experiments with the unmodified lexicon as well. We observed that while the numerical values of the UED metrics changed slightly (as would be expected), all relative trends remained the same, across countries and across years. The interested reader can find the scores for the UED metric and the complete set of experiments with the unmodified lexicon in version 2 (an older version) of the paper on ArXiv.\"}"}
{"id": "lrec-2022-1-442", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| City          | 2020    | 2021    | 2020    | 2021    |\\n|--------------|---------|---------|---------|---------|\\n| Canada       |         |         |         |         |\\n| Brampton     | 1,436,865 | 159,974 | 2,430,329 | 188,216 |\\n| Calgary      | 294,911  | 31,988  | 503,173 | 39,416  |\\n| Edmonton     | 806,116  | 43,427  | 1,319,950 | 49,058 |\\n| Etobicoke    | 1,318,119 | 157,429 | 2,379,928 | 191,653 |\\n| Halifax      | 572,562  | 23,733  | 678,033 | 23,541  |\\n| Hamilton     | 446,038  | 37,023  | 702,761 | 43,537  |\\n| Laval        | 453,670  | 48,145  | 733,844 | 58,344  |\\n| London       | 298,615  | 16,977  | 428,929 | 18,928  |\\n| Mississauga  | 450,835  | 97,328  | 977,517 | 142,817 |\\n| Montreal     | 627,159  | 52,396  | 1,048,093 | 64,363 |\\n| North York   | 1,274,462 | 148,271 | 1,685,201 | 152,105 |\\n| Okanagan     | 30,771   | 1,814   | 37,424  | 1,813   |\\n| Ottawa       | 1,055,035 | 55,430  | 1,332,680 | 56,621 |\\n| Quebec       | 284,665  | 16,380  | 377,342 | 18,100  |\\n| Scarborough  | 720,165  | 108,498 | 710,181 | 86,328  |\\n| Surrey       | 1,115,467 | 84,001  | 1,679,642 | 94,177 |\\n| Toronto      | 2,058,494 | 182,730 | 2,557,606 | 182,792 |\\n| Vancouver    | 402,418  | 53,655  | 634,307 | 63,561  |\\n| Victoria     | 340,720  | 14,787  | 436,905 | 15,565  |\\n| Windsor      | 443,712  | 58,545  | 893,922 | 72,975  |\\n| Winnipeg     | 608,704  | 27,954  | 824,223 | 29,365  |\\n| US           |         |         |         |         |\\n| Austin       | 1,244,776 | 102,841 | 2,242,561 | 125,526 |\\n| Boston       | 764,257  | 100,276 | 1,641,142 | 130,145 |\\n| Charlotte    | 997,197  | 76,528  | 1,566,062 | 86,892 |\\n| Chicago      | 721,075  | 142,591 | 1,652,701 | 194,565 |\\n| Columbus     | 809,160  | 69,931  | 1,445,275 | 81,135 |\\n| Dallas       | 674,613  | 129,304 | 1,671,887 | 181,895 |\\n| Denver       | 1,198,813 | 98,697  | 1,712,785 | 106,959 |\\n| Detroit      | 749,506  | 77,560  | 1,418,484 | 94,202  |\\n| El Paso      | 692,705  | 38,096  | 781,937  | 37,335  |\\n| Fort Worth   | 1,649,842 | 188,443 | 2,794,053 | 215,169 |\\n| Houston      | 1,557,488 | 195,548 | 2,358,286 | 209,520 |\\n| Indianapolis | 710,808  | 65,665  | 1,287,399 | 78,214  |\\n| Jacksonville | 723,513  | 48,230  | 1,000,620 | 53,257  |\\n| Los Angeles  | 1,028,102 | 246,491 | 2,470,750 | 337,004 |\\n| Memphis      | 876,988  | 49,835  | 1,263,728 | 54,254  |\\n| Nashville    | 584,997  | 68,306  | 963,947  | 79,006  |\\n| New York     | 1,079,557 | 281,109 | 2,288,500 | 361,670 |\\n| Philadelphia | 1,142,818 | 127,257 | 2,579,605 | 161,491 |\\n| Phoenix      | 531,390  | 81,093  | 1,454,042 | 117,145 |\\n| San Antonio  | 1,213,537 | 91,427  | 1,835,376 | 98,868  |\\n| San Diego    | 1,080,361 | 101,554 | 1,940,120 | 122,278 |\\n| San Francisco| 1,123,356 | 132,023 | 2,179,371 | 159,727 |\\n| San Jose     | 790,511  | 72,049  | 1,184,999 | 78,750  |\\n| Seattle      | 940,092  | 114,848 | 1,968,319 | 141,016 |\\n| Washington   | 585,393  | 123,576 | 1,991,694 | 189,873 |\\n\\nTable 3: The number of tweets and tweeters in TUSC-City for 2020 and 2021.\"}"}
{"id": "lrec-2022-1-442", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 6: Monthly trends in Arousal of tweets across years (TUSC-Country).\\n\\nFigure 7: Monthly trends in Dominance of tweets across years (TUSC-Country).\"}"}
{"id": "lrec-2022-1-442", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"| Year | Dataset | Canada | USA |\\n|------|---------|--------|-----|\\n| 2020 | tweets  | 3,038,530 | 2,641,694 |\\n|      | tweeters | 20,887 | 19,709 |\\n| 2021 | tweets  | 7,467,446 | 11,675,372 |\\n|      | tweeters | 45,573 | 76,223 |\\n\\nTable 4: Number of tweets and tweeters in the TUSC100 dataset.\\n\\n| Year | Data | Canada | USA |\\n|------|------|--------|-----|\\n| 2020 | Mean | 0.6320 | 0.6132 |\\n|      | Variability | 0.0708 | 0.0714 |\\n| 2021 | Mean | 0.6387 | 0.6257 |\\n|      | Variability | 0.0700 | 0.0705 |\\n\\nTable 5: Tweet Valence dynamics metrics of tweeters in TUSC100. Averaged across all tweeters (not considering the cities they came from).\\n\\n| Year | Data | Canada | USA |\\n|------|------|--------|-----|\\n| 2020 | Mean | 0.4828 | 0.4935 |\\n|      | Variability | 0.0599 | 0.0593 |\\n| 2021 | Mean | 0.4854 | 0.4932 |\\n|      | Variability | 0.0599 | 0.0595 |\\n\\nTable 6: Arousal dynamics metrics of tweeters in TUSC100. Averaged across all tweeters (not considering the cities they came from).\\n\\n| Year | Data | Canada | USA |\\n|------|------|--------|-----|\\n| 2020 | Mean | 0.5821 | 0.5671 |\\n|      | Variability | 0.0573 | 0.0556 |\\n| 2021 | Mean | 0.5873 | 0.5733 |\\n|      | Variability | 0.0569 | 0.0557 |\"}"}
{"id": "lrec-2022-1-442", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 8: TED: Tweet Valence Means (left), Arousal Means (centre), and Dominance Means (right) across American and Canadian cities in 2020 and 2021 (using tweets from TUSC-City).\"}"}
{"id": "lrec-2022-1-442", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 9: TED: Tweet Valence Variability (left), Rise Rate (centre), and Recovery Rate (right) across American and Canadian cities in 2020 and 2021 (using tweets from TUSC-City).\"}"}
