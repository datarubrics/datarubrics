{"id": "lrec-2024-main-298", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation\\n\\nYujie Shao 2*, Xinrong Yao 3*, Xingwei Qu 1,6*, Chenghua Lin 6, Shi Wang 8, Stephen W. Huang 9, Ge Zhang 1,4,5,7, Jie Fu 1,5\\n\\n1 HKUST\\n2 University of California, San Diego\\n3 Massachusetts Institute of Technology\\n4 University of Waterloo\\n5 Multimodal Art Projection Research Community\\n6 University of Manchester\\n7 Stardust.ai\\n8 Institute of Computing Technology, Chinese Academy of Sciences\\n9 harmony.ai\\n\\nAbstract\\nMetaphor is a prominent linguistic device in human language and literature, as they add color, imagery, and emphasis to enhance effective communication. This paper introduces a large-scale high quality annotated Chinese Metaphor Corpus, which comprises around 28K sentences drawn from a diverse range of Chinese literary sources, such as poems, prose, song lyrics, etc. To ensure the accuracy and consistency of our annotations, we introduce a comprehensive set of guidelines. These guidelines address the facets of metaphor annotation, including identifying tenors, vehicles, and grounds to handling the complexities of similes, personifications, juxtapositions, and hyperboles. Breaking tradition, our approach to metaphor generation emphasizes grounds and their distinct features rather than the conventional combination of tenors and vehicles. By integrating \u201cground\u201d as a CoT (Chain of Thoughts) input, we are able to generate metaphors that resonate more with real-world intuition. We test generative models such as Belle, Baichuan, and Chinese-alpaca-33B using our annotated corpus. These models are able to generate creative and fluent metaphor sentences more frequently induced by selected samples from our dataset, demonstrating the value of our corpus for Chinese metaphor research. The code is available in the https://anonymous.4open.science/r/Chinese_Metaphor_Explanation-63F2.\\n\\nKeywords: chinese metaphor corpus, metaphor annotation\\n\\nFigure 1: Sketch Map of the Metaphorical Language Writing Process.\\n\\n1. Introduction\\nMetaphor is a prominent linguistic device in human language and literature, typically to draw a comparison between disparate objects or concepts with the intent to make the expression more vivid, or make abstract concepts easier to understand. With the progression of computational linguistics, there is an increasing focus on metaphor generation through machine learning techniques, notably in chatbot applications. Zheng et al. (2020) shows how machine-generated nominal metaphors (NMs) can significantly enhance user interest during interactions with chatbots. Li et al. (2022a) finds substantial applications in shaping downstream task outputs in Natural Language Generation (NLG). Notably, a series of evaluations by Chakrabarty et al. (2020, 2021) conduct human evaluations comparing literal expressions from machine-generated stories and poems with machine-generated metaphors and find users prefer the text with metaphors.\\n\\nHowever, metaphors are referred to as novel linguistic expressions where an object or concept is used outside of its normal conventional meaning to express another meaning under a given context. Intrinsically, metaphors do not reside within the language itself but in the way they conceptually map one mental domain onto another in application (Lakoff, 1992), as shown in Fig. 1. With this consideration, we establish metaphor sentences centered on identifying the conceptual mappings within metaphors, specifically GROUNDS (\u55bb\u610f). Metaphors consist of two components: TENORS (\u672c\u4f53), representing the actual subject, and VEHICLES (\u55bb\u4f53), symbolizing the comparative element. Employing GROUNDS can enhance sentence fluency and creativity, achieving human-like metaphorical expression (Yang et al., 2023). This work introduces an annotated Chinese metaphor corpus (CMDAG) that is derived from a diverse range of Chinese literature. Every metaphorical sentence within the corpus is accompanied by its corresponding GROUNDS. The central aim of our annotation effort is to accurately annotate each metaphor with a well-defined tuple of features (TENOR, VEHICLE and GROUND), capturing its in-\"}"}
{"id": "lrec-2024-main-298", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"To evaluate the effectiveness of our annotated corpus for Chinese metaphor generation, we undertake two evaluative setups, both incorporating GROUNDS and the Chain of Thought (CoT) capability of language models. In the first setup, we prompt with TENOR and VEHICLE, and we allow the language model to deduce GROUNDS. For the second setup, we prompt TENORS and GROUNDS, and fine-tune metaphorical sentence generation by asking the language model to deduce a plausible VEHICLE. In summary, our paper outlines the following three contributions:\\n\\n1. We present CMDAG, a unique Chinese metaphor dataset, wherein a key feature is the inclusion of GROUNDS. This dataset's thoughtful design enables the intuitive generation of metaphorical constructs, addressing a notable absence in contemporary research literature.\\n\\n2. We introduce a metaphor annotation pipeline by leveraging academically specialized annotators' expertise, achieving enhanced precision in pinpointing the GROUNDS of metaphors.\\n\\n3. We propose the first work introducing CoT into metaphor generations. Given TENOR and VEHICLE, deriving GROUNDS using CoT, language models can generate coherent and integrative metaphor sentences. Furthermore, by combining TENORS and GROUNDS, we enhance the generation of VEHICLE, improving the quality of the generated metaphorical expressions.\\n\\n2. Related Work\\n\\n2.1. Chinese Metaphor Corpora\\n\\nMetaphor is not only a literature of rhetoric but also a way of thinking rooted in Chinese culture (Lin, 2021). However, due to the shortage of Chinese corpora (Zhang et al., 2023), researchers are still in lack of high-quality Chinese metaphor corpora. Lyrics and Poetry corpora released by (Liu et al., 2019) provide a great source of metaphorical Chinese language, but they do not dig in and provide fine-grained annotations of existing Chinese similes and metaphors in Lyrics and Poetry corpora. CS (Zhang et al., 2021), another large Chinese rhetorical corpus, is in shortage of Fine-grained annotation as well. CMC (Li et al., 2022b) is a valuable Chinese metaphor corpus with cautious annotation of tenors and vehicles, but CMC is pretty small and without the annotation of GROUNDS (\u55bb\u610f). GraCe (Yang et al., 2023), an amazing contemporary research work, claims to provide a carefully annotated Chinese simile corpus but hasn't been released yet, and only focuses on clearly stated Chinese similes. As a sharp contrast, CMDAG is a carefully annotated large Chinese metaphor (also with simile) corpus with annotations of all TENOR, VEHICLES, and GROUNDS, which is a valuable resource for researchers interested in Chinese metaphor processing. We briefly compare the existing major Chinese metaphor/simile corpora in Tab. 1.\\n\\n2.2. Boosting NLG via Chain-of-Thought\\n\\nChain-of-Thought (CoT) is the most important inference trick inducing Large-scale Language Models (LLMs) to output reasonable results (Wang et al., 2023) since proposed by Wei et al. (2022). It has been widely used in different LLM-based Natural Language Generation (NLG) tasks, including human moral value alignment (Liu et al., 2023, 2022), math problem solving (Yue et al., 2023), and evaluation of NLG results (Jiang et al., 2023; Chan et al., 2023).\\n\\nAs illustrated in Fig. 1, we believe that GROUNDS is the natural CoT connecting TENOR with VEHICLE, which has been discussed in literature research works (Black et al., 1979; End, 1986) and NLP research works (Gong, 2003; Stowe et al., 2021; Wachowiak and Gromann, 2023). Specifically, Li et al. (2023) propose to introduce explicit basic meaning modeling to boost metaphor detection. Additionally, Yang et al. (2023) reveal that simile generation could benefit from pre-specified constraints, especially explicitly stated GROUNDS. As a sharp comparison, CMDAG directly verifies how LLMs perform on Chinese metaphor generation in various settings, especially with the assistance of GROUNDS (\u55bb\u610f) as CoT.\\n\\n3. Chinese Metaphor Dataset\\n\\nIn this section, we present our annotated dataset of Chinese metaphors. Subsequent subsections establish basic definitions used in our dataset, and provide detailed insights into the data collection and annotation processes.\\n\\n3.1. Definition\\n\\nA Metaphor (\u6697\u55bb/\u9690\u55bb) is a linguistic device in which a word or phrase literally denoting one kind of object or idea is used in place of another to suggest a likeness or analogy between them. For example, the metaphor \\\"\u4f55\u7b49\u52a8\u4eba\u7684\u4e00\u7ae0!\\\" compares the tenor, the pages of literature (\u4e00\u7ae0), to the vehicle, bloom of human thoughts (\u4eba\u7c7b\u601d\u7ef4\u7684\u82b1), to convey the beautiful nature of the literature's expressions. In CMDAG, we uniformly formalize and\"}"}
{"id": "lrec-2024-main-298", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistic characteristics and annotation information of main existing Chinese metaphor/simile datasets of metaphor and simile and CMDAG dataset. W and F separately denote the tenor/vehicle words and the corresponding feature words.\\n\\n| Dataset         | # Nums | Tenor | Vehicle | Ground | Open-source |\\n|-----------------|--------|-------|---------|--------|-------------|\\n| Poetry (Liu et al., 2019) | 43,051  | \u2212     | /       | \u2212      | \u2713           |\\n| Lyrics (Liu et al., 2019)   | 246,669 | \u2212     | /       | \u2212      | \u2713           |\\n| CS (Zhang et al., 2021)   | 5,490,721 | \u2212   | /       | \u2212      | \u2713           |\\n| CMC (Li et al., 2022b)   | 2,787   | \u2713     | /       | \u2212      | \u2713           |\\n| GraCe (Yang et al., 2023) | 61,360  | \u2713     | /       | \u2713      | \u2713           |\\n| CMDAG           | 27,989  | \u2713     | /       | \u2713      | \u2713           |\\n\\nTable 2: Statistics of CMDAG and its raw data collection literature sources.\\n\\n| Source Type          | # Literature Works | # Likely-Metaphors | # Annotated Metaphors |\\n|----------------------|--------------------|--------------------|-----------------------|\\n| Prose/Poem           | 3,459              | 28,553             | 5,294                 |\\n| Song Lyrics          | 102,197            | 109,827            | 21,276                |\\n| Contemporary Poem    | 4,494              | 7,268              | 939                   |\\n| HipHop/Rap Lyrics    | 3,004              | 7,603              | 480                   |\\n| **Total**            | **113,154**        | **153,251**        | **27,989**            |\\n\\nTo further explain other annotated elements, Tenor (\u672c\u4f53) is the literal object or idea being described, and Vehicle (\u55bb\u4f53) is the object or idea carrying the weight of comparison. The Ground (\u55bb\u610f) of a metaphor/simile is the concept or concepts the tenor and vehicle share, enabling the metaphor to align with common sense.\\n\\n3.2. Data Collection\\n\\nIn constructing our corpus, we first collect a raw set of \u223c153K probable metaphorical sentences from various Chinese literary sources online, with a focus on genres such as prose, poems, and song and rap/hip-hop lyrics, which are often renowned for their rich usage of literary techniques and devices. Statistics of our raw and annotated metaphor datasets, separated by source types, are shown in Tables 2 and 3. We applied the following set of heuristic rules to detect sentences which are likely to be of metaphoric usage, as opposed to literal ones, if either:\\n\\n\u2022 The sentence contains Chinese simile comparators (\\\"\u50cf\\\", \\\"\u597d\u4f3c\\\", \\\"\u5982\u540c\\\", etc.), or\\n\u2022 We identify metaphors by applying a similar method as in Su et al. (2017), where the sentence is classified as metaphoric if its subject and object, identified through dependency parsing, are not highly related and do not have a hyponym/hypernym relationship. We query whether the subject is a hyponym or a hypernym of the object in WordNet, and determine the relatedness between the subject and object by computing their cosine similarity score (a low score indicates the subject and object are less related, and hence there exists little shared information between them).\\n\\nSuppose the subject and object are represented by n-dimensional vectors \\\\( w \\\\) and \\\\( v \\\\) respectively, then their cosine similarity score is computed as:\\n\\n\\\\[\\n\\\\cos(w, v) = \\\\frac{\\\\sum_{i=1}^{n} w_i v_i}{\\\\sqrt{\\\\sum_{i=1}^{n} w_i^2} \\\\sqrt{\\\\sum_{i=1}^{n} v_i^2}}\\n\\\\]\\n\\nwhere sentences with a score below a set threshold of \\\\( \\\\cos(w, v) \\\\leq 0.575 \\\\) (which from the results by Su et al. (2017) gives the best performance and accuracy) are considered likely-metaphors and are kept for annotation.\\n\\n3.3. Data Annotation\\n\\nOur data annotation goal is to accurately mark each metaphor with a well-defined tuple of features: \\\\((\\\\text{TENOR}, \\\\text{VEHICLE}, \\\\text{GROUND})\\\\).\"}"}
{"id": "lrec-2024-main-298", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"| Source Type          | Average Context Length (Tokens) |\\n|---------------------|---------------------------------|\\n| Prose/Poem          | 101                             |\\n| Song Lyrics         | 49                              |\\n| Contemporary Poem   | 51                              |\\n| HipHop/Rap Lyrics   | 52                              |\\n| Overall             | 59                              |\\n\\nTable 3: Statistics of CMDAG and its raw data collection sources.\\n\\nConsider the metaphor \u201c\u5929\u4e0a\u7684\u4e91\u50cf\u5954\u817e\u7684\u9a8f\u9a6c\u201d (translates to: \u201cclouds in the sky are like galloping horses\u201d), annotated as: (\u4e91 (clouds), \u5954\u817e\u7684\u9a8f\u9a6c (galloping horses), \u76f8\u4f3c\u7684\u5f62\u6001 (similar forms)).\\n\\nA compilation of examples from our annotated dataset is presented in Table 4.\\n\\nOur annotation process consists of two main stages, focusing on both coarse-level and fine-level annotations:\\n\\n**Preliminary Annotation**: Here, we engage a 20-people team of Chinese college students to identify genuine metaphors from the initial dataset, and highlight potential TENOR\u2019s and VEHICLE\u2019s. Each sample is annotated by two annotators at this stage.\\n\\n**Refined Annotation**: Leveraging the groundwork from the initial round, a second cohort of annotators, primarily Chinese native speakers with at least undergraduate credentials in Chinese Literature, refines the annotations. Their specialized background enables them to further pinpoint the GROUND of the metaphors with higher precision.\\n\\nWe provide comprehensive guidelines to ensure consistent annotation quality, which mandates that each data piece is assessed by at least three annotators, improving label consistency and accuracy. Our labeling strategy emphasizes sophisticated composition of our GROUND labels, ensuring a structure combining an Adjective and a Noun (\u5f62\u5bb9\u8bcd + \u540d\u8bcd). The noun part delineates the shared characteristic between the TENOR and VEHICLE, while the adjective highlights the dimension underscoring their connection. Fig. 2 showcases the diverse adjectives and noun elements of our annotated grounds via word clouds.\\n\\n**Guidelines for Refined Annotation in Chinese**:\\n\\nOur rigorous annotation approach is demonstrated through strict guidelines for the second annotation round, focusing on intricate annotation of metaphorical components in Chinese text.\\n\\n1) **Annotation and Quality Inspection Rules**: Given Chinese rhetoric\u2019s complexity, it\u2019s essential to label all rhetorical devices like metaphor, metonymy, simile, personification, etc., in a unified standard. Annotators reference prior annotations, remaining cautious against possible inaccuracies, especially regarding previous GROUND labels, as we standardize the formatting requirements in the second round. A large proportion of statements contain multiple possible tuples of (TENOR, VEHICLE, GROUND). Annotators separate different tenors, vehicles, and grounds by three predetermined quotation marks when labeling each statement. Correctness verified, multiple tuples of one statement are automatically retrieved by string matching, forming the current open-sourced corpora.\\n\\n2) **Selection of Nouns for Grounds**: To uphold annotation authenticity and precision, a curated list of nouns is provided. The emphasis is on opting for more descriptive nouns, avoiding generic terms like \u6837\u5b50 (appearance), \u7279\u5f81 (feature), \u7279\u70b9 (characteristic), \u611f\u53d7 (feeling), \u611f\u89c9 (sensation), and other similar broad terms. This curated list is crucial for ensuring that the grounds aptly reflect the nuanced connections between the TENOR and VEHICLE.\\n\\n4. **Methodology**\\n\\nWe consider two common scenarios that people often encounter with metaphor usage in writing. By utilizing our metaphor dataset with annotated grounds and applying a Chain-of-Thought (CoT) prompting technique with generated knowledge, we examine the importance of GROUND labels in metaphor generation tasks, including:\\n\\n**Task 1: Ground Identification**\\n\\nThe first task that we consider is a situation where given a potential pair of TENOR and VEHICLE as the subject and object which we would like to connect and compare, the model is to generate a corresponding metaphor.\\n\\n**Task 2: Vehicle Identification**\\n\\nOur second task requires the model to produce a metaphor when provided with a TENOR as the topic and a potential GROUND that signifies the features of the TENOR we aim to emphasize.\"}"}
{"id": "lrec-2024-main-298", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The rain is like silver-gray sticky spider silk, weaving a soft net that captures the entire realm of autumn.\\n\\nBuddhism is like a piece of jade in your hand, if you have not held many ordinary stones, you cannot understand how precious the jade is.\\n\\nI thought travelers would burn out all my passion, you love letter, which feels so elementary.\\n\\nLove is like a gust of wind, it blows away and then goes away.\\n\\nThe fragrance of flowers is like the dissipation of bells, light feeling.\\n\\nMy cheeks are like melted snow, and my heart is like warm wine; my face is like snow, my heart is like wine.\"}"}
{"id": "lrec-2024-main-298", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: A flowchart that illustrates our experiment with an example of task 1.\\n\\n5.1. Experimental Setting\\nThe evaluations were consistently carried out across six standardized settings to maintain a uniform benchmark, three for each of our two metaphor generation tasks, across our selected models. For each language model:\\n\\n- In Setting 0 of Task 1, we prompt the model with TENOR-VEHICLE pairs and for each pair we ask it to generate a corresponding metaphor.\\n- In Setting 1 of Task 1, we prompt the model with TENOR-VEHICLE pairs, as well as annotated examples selected based on our first clustering method, and for each pair we ask it to generate a corresponding GROUND. We then prompt the model again with the same TENOR-VEHICLE pairs and annotated examples, as well as the inferred GROUND, and for each pair we ask it to generate a corresponding metaphor.\\n- In Setting 2 of Task 1, we conduct a similar process as in Setting 1, except we select the annotated examples based on our second clustering method.\\n- In Task 2, we apply a similar procedure of settings as in Task 1, but instead of prompting with TENOR-VEHICLE pairs, we prompt the model and provide annotated examples with TENOR-GROUND pairs, and ask it to infer the corresponding VEHICLE for each pair in Settings 1 and 2.\\n\\n5.1.1. Models\\nChinese metaphor generation is a novel task, we select three general generative models, a Chinese nominal metaphor generation method, and a Chinese metaphor generation model as baselines.\\n\\n- **GPT-3.5**\\n  - GPT-3.5 (OpenAI, 2023b) is a version of OpenAI\u2019s Generative Pretrained Transformer series. It is capable of handling a variety of language-processing tasks.\\n\\n- **GPT-4.0**\\n  - GPT-4 (OpenAI, 2023a) is a large-scale, multimodal model capable of accepting both image and text inputs to produce text outputs. It showcases human-level performance on various professional and academic benchmarks.\\n\\n- **Belle**\\n  - Belle (Yunjie et al., 2023) is a Chinese LLM (Large Language Model) trained specifically on Chinese data and thus is able to generate precise Chinese metaphoric information.\\n\\n- **Baichuan**\\n  - Baichuan (Baichuan, 2023) is a robust 13-billion parameter Chinese AI language model that is open-source and freely available for business and research purposes.\\n\\n- **Chinese-alpaca-33B**\\n  - Chinese-alpaca-33B (Cui et al., 2023) is a state-of-the-art language model that holds a massive 33 billion parameters, specifically designed for Chinese language tasks.\\n\\n- **ERNIE**\\n  - Baidu ERNIE (Research, 2023) is an innovative language model developed by Baidu Research, focusing on understanding and generating text in a more human-like manner.\"}"}
{"id": "lrec-2024-main-298", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Model Name    | Setting Clarity | Creativity | Authentic | Expression | Final Score |\\n|--------------|----------------|------------|-----------|-----------|-------------|\\n| Baichuan     |\u2299               |2.94        |2.06       |2.36       |2.4         |\\n| Baichuan     |\u2662               |2.98        |2.09       |2.29       |2.49        |\\n| Baichuan     |\u22c6               |2.98        |2.07       |2.20       |2.32        |\\n| Belle        |\u2299               |2.61        |1.71       |2.18       |2.07        |\\n| Belle        |\u2662               |2.83        |1.90       |2.37       |2.33        |\\n| Belle        |\u22c6               |2.97        |1.69       |2.23       |2.17        |\\n| GPT -4       |\u2299               |2.92        |1.64       |2.16       |2.25        |\\n| GPT -4       |\u2662               |2.96        |1.60       |2.11       |2.21        |\\n| GPT -4       |\u22c6               |2.98        |1.66       |2.24       |2.36        |\\n| GPT -3.5     |\u2299               |2.99        |1.78       |2.23       |2.21        |\\n| GPT -3.5     |\u2662               |2.99        |1.75       |2.16       |2.25        |\\n| GPT -3.5     |\u22c6               |2.98        |1.45       |1.94       |2.03        |\\n| Chinese-alpaca-33B |\u2299               |2.99        |1.83       |2.14       |2.28        |\\n| Chinese-alpaca-33B |\u2662               |2.97        |1.68       |2.14       |2.11        |\\n| Chinese-alpaca-33B |\u22c6               |2.99        |1.86       |2.29       |2.20        |\\n| ERNIE        |\u2299               |2.87        |1.86       |2.30       |2.27        |\\n| ERNIE        |\u2662               |2.97        |1.56       |2.16       |2.27        |\\n| ERNIE        |\u22c6               |2.90        |1.73       |2.02       |2.17        |\\n\\nTable 5: The human evaluation results for each model under three settings for task1. According to the section 5.1, \u2299 is the symbol of Setting 0, \u2662 is the symbol of Setting 1 and \u22c6 represents the Setting 2.\\n\\nTable 6: The human evaluation results for each model under three settings for task2. The symbols for the settings are consistent with those in Table 5.\\n\\n5.1.2. Evaluation Metrics\\nEvaluating models' performance on metaphor sentences is extremely challenging because determining the vividness of a metaphor is often intuitive. Many of these tasks cannot be measured by automatic metrics or even be judged by normal crowd workers. To get a more faithful evaluation, we hire expert annotators to judge model predictions. All the annotators conducting the human evaluation have a Master's or Doctor's degree in Chinese Literature, Philology, or Literature. Due to cost, each sample is only analyzed by one annotator. To illustrate the annotators' responsibility, they are allowed to join the project only if their trial annotation results are verified by the authors of CMDAG. The annotators are asked to rate the output based on whether it accurately and vividly generates the metaphors. We implemented a four-aspects rating system for categorizing the quality...\"}"}
{"id": "lrec-2024-main-298", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 7: Percentage of model-generated sentences that are reasonable Chinese metaphors.\\n\\n| Model   | \u2299 Clarity | \u2662 Creativity | \u22c6 Authentic Expression |\\n|---------|-----------|--------------|------------------------|\\n| Belle   | 0.112     | 0.236        | 0.14                   |\\n| GPT-4   | 0.38      | 0.484        | 0.448                  |\\n| GPT-3.5 | 0.372     | 0.384        | 0.32                   |\\n\\nThe symbols for the settings are consistent with those in Table 5.\\n\\n5.2. Discussion\\n\\nWe propose an analysis of how grounds-based CoT assists LLMs in metaphor generation in Tab. 7. Additionally, we provide expert-level human evaluation results on how different LLMs perform on Task 1 and Task 2 in Tab. 5 and Tab. 6. As supplementary material, we also reveal different human evaluation criteria' relationships in Tab. 8. The experiments of Tab. 7 are conducted on a selected 250-sample test set selected from CMDAG. Only and all reasonable metaphorical sentences of various models and settings are manually evaluated and analyzed in Tab. 5 and Tab. 6.\\n\\n#### 5.2.1. Grounds-based CoT\u2019s Influence\\n\\nTab. 7 reveals that Grounds-based CoT can improve the percentage of model-generated sentences that are reasonable Chinese metaphors. Given Tab. 5 and Tab. 6, we notice that LLMs with Grounds-based CoT achieve comparable performance on Task 1 and Task 2, compared with LLMs without Grounds-based CoT. Nota bene that LLMs without grounds-based CoT often generate fewer reasonable metaphorical sentences, so their experiment results might slightly benefit from it. We also propose that Grounds-based CoT leads to a slight performance decline, especially in the Creativity and Authentic Expression criteria. An assumption of the observation is that Grounds-based CoT limits LLMs\u2019 tendency to explore novel Vehicle (\u55bb\u4f53) and Ground (\u55bb\u610f), which is a promising future research direction.\\n\\n#### 5.2.2. Various LLMs\u2019 Performance\\n\\nBased on Tab. 7, Tab. 5, and Tab. 6, we have two major observations. First, since Baichuan performs similarly or even surpasses GPT-4 and GPT-3.5 in Task 1 and Task 2, we point out that LLMs with more Chinese corpora in their pretraining procedure might perform better on Chinese metaphor generation. Second, Belle generates much fewer reasonable metaphorical sentences compared to GPT-4 and GPT-3.5. Additionally, GPT-4 and GPT-3.5 cannot always generate reasonable Chinese metaphorical sentences as well. The observations reveal that the Chinese metaphor generation is still an under-explored task, and a larger model size and training corpus can lead to a noticeable performance gain on the task.\\n\\n#### 5.2.3. Criteria\u2019s Relationships\\n\\n| Clarity | Creativity | Authentic Expression |\\n|---------|------------|----------------------|\\n| Task 1  | 0.28       | 0.71                 |\\n| Task 2  | 0.85       | 0.72                 |\\n\\nTable 8: Pearson Correlation between final score and evaluation criteria.\\n\\nBased on Tab. 8, we point out that expert-level annotators attach importance to creativity when conducting an evaluation on Chinese metaphor generation. Additionally, compared to the conventional Task 1, expert-level annotators pay more attention to clarity instead of authentic expression. We propose an assumption that human annotators...\"}"}
{"id": "lrec-2024-main-298", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3365\\n\\nhold an implicit belief of GROUND in the conven-\\ntional Task 1 setting which decreases their relia-\\n\\nbility on clarity. However, writers practically only\\n\\nTENOR and the features of TENOR, in other\\n\\nwords GROUND, in their mind, when they want to\\n\\nwrite a metaphorical expression. As a result, we\\n\\npoint out that future metaphor generation models\\n\\nand benchmarks should pay more attention to the\\n\\nclarity of generated metaphorical sentences.\\n\\n6. Conclusion\\n\\nIn this paper, we present an annotated Chinese\\n\\nMetaphor Dataset, encompassing approximately\\n\\n28,000 sentences sourced from a wide array of\\n\\nChinese literary forms, including poems, prose,\\n\\nand song lyrics. To ensure the precision and uni-\\n\\nformity of our annotations, we have developed a\\n\\nthorough set of guidelines. These guidelines are in-\\n\\nstrumental in aiding annotators in the identification\\n\\nof tenors, vehicles, and grounds. Further more, we\\ndesign a evaluation method for metaphor sentence\\n\\ngeneration that leverages a Chain of Thoughts (CoT) framework. Our experimental setup em-\\nploys open-source multilingual Large Language\\n\\nModels (LLMs), which are tested to underscore\\n\\nthe corpus\u2019s capability to facilitate the generation\\n\\nof creative and linguistically metaphors. This un-\\nderscores the significant potential of our dataset\\nto fuel advancements in the understanding and\\n\\ncreation of Chinese metaphors.\\n\\nBaichuan. 2023. Baichuan 2: Open large-scale lan-\\nguage models. arXiv preprint arXiv:2309.10305.\\n\\nMax Black et al. 1979. More about metaphor. Metaphor and thought, 2:19\u201341.\\n\\nTuhin Chakrabarty, Smaranda Muresan, and Nanyun Peng. 2020. Generating similes effort-\\nlessly like a pro: A style transfer approach for simile generation.\\n\\nTuhin Chakrabarty, Xurui Zhang, Smaranda Mure-\\nsan, and Nanyun Peng. 2021. Mermaid: Metaphor generation with symbolism and dis-\\n\\ncriminative decoding.\\n\\nChi-Min Chan, Weize Chen, Yusheng Su, Jianxuan\\n\\nYu, Wei Xue, Shanghang Zhang, Jie Fu, and\\n\\nZhiyuan Liu. 2023. Chateval: Towards better llm-based evaluators through multi-agent debate. arXiv preprint arXiv:2308.07201.\\n\\nYiming Cui, Ziqing Yang, and Xin Yao. 2023. Efficient and effective text encoding for chi-\\nnese llama and alpaca. arXiv preprint arXiv:2304.08177.\\n\\nLaure J End. 1986. Grounds for metaphor compre-\\n\\nhension. In Advances in psychology, volume 39,\\n\\npages 327\u2013345. Elsevier.\\n\\nShu-Ping Gong. 2003. A corpus-based study\\n\\non mapping principles of metaphors in politics. In\\n\\nProceedings of the ROCLING 2003 Student\\n\\nWorkshop, pages 287\u2013294.\\n\\nDongfu Jiang, Yishan Li, Ge Zhang, Wenhao\\n\\nHuang, Bill Yuchen Lin, and Wenhu Chen. 2023. Tigerscore: Towards building explainable met-\\n\\nric for all text generation tasks. arXiv preprint arXiv:2310.00752.\\n\\nGeorge Lakoff. 1992. The contemporary theory of\\n\\nmetaphor. In Andrew Ortony, editor, Metaphor\\n\\nand Thought (2nd edition), chapter 11, pages\\n\\n202\u2013251. Cambridge University Press, Cam-\\n\\nbridge.\\n\\nYucheng Li, Chenghua Lin, and Frank Geurin. 2022a. Nominal metaphor generation with multi-\\ntask learning.\\n\\nYucheng Li, Chenghua Lin, and Frank Guerin. 2022b. Nominal metaphor generation with multi-\\ntask learning. In Proceedings of the 15th Inter-\\nnational Conference on Natural Language Gen-\\n\\neration, pages 225\u2013235, Waterville, Maine, USA and virtual meeting. Association for Computa-\\ntional Linguistics.\\n\\nYucheng Li, Shun Wang, Chenghua Lin, and Guerin Frank. 2023. Metaphor detection via ex-\\n\\nplicit basic meanings modelling. arXiv preprint arXiv:2305.17268.\\n\\nSu Lin. 2021. Metaphor and metonymy: Differ-\\n\\nences in chinese language and culture. Open\\n\\nJournal of Modern Linguistics, 11(2):135\u2013139.\\n\\nRuibo Liu, Chenyan Jia, Ge Zhang, Ziyu Zhuang,\\n\\nTony Liu, and Soroush Vosoughi. 2022. Second\\n\\nthoughts are best: Learning to re-align with hu-\\n\\nman values from text edits. Advances in Neural\\n\\nInformation Processing Systems, 35:181\u2013196.\\n\\nRuibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang,\\n\\nDenny Zhou, Andrew M Dai, Diyi Yang, and\\n\\nSoroush Vosoughi. 2023. Training socially\\n\\naligned language models in simulated human\\n\\nsociety. arXiv preprint arXiv:2305.16960.\\n\\nZhiqiang Liu, Zuohui Fu, Jie Cao, Gerard de Melo,\\n\\nYik-Cheung Tam, Cheng Niu, and Jie Zhou. 2019. Rhetorically controlled encoder-decoder\\n\\nfor Modern Chinese poetry generation. In\\n\\nProceedings of the 57th Annual Meeting of the As-\\n\\nsociation for Computational Linguistics, pages\\n\\n1992\u20132001, Florence, Italy. Association for Com-\\nputer Linguistics.\"}"}
{"id": "lrec-2024-main-298", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
