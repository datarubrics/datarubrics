{"id": "emnlp-2023-main-349", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Analysing State-Backed Propaganda Websites: \\na New Dataset and Linguistic Study\\n\\nFreddy Heppell, Kalina Bontcheva and Carolina Scarton\\n\\nDepartment of Computer Science, University of Sheffield, Sheffield, UK\\n{frheppell1, k.bontcheva, c.scarton}@sheffield.ac.uk\\n\\nAbstract\\n\\nThis paper analyses two hitherto unstudied sites sharing state-backed disinformation, Reliable Recent News (rrn.world) and WarOnFakes (waronfakes.com), which publish content in Arabic, Chinese, English, French, German, and Spanish. We describe our content acquisition methodology and perform cross-site unsupervised topic clustering on the resulting multilingual dataset. We also perform linguistic and temporal analysis of the web page translations and topics over time, and investigate articles with false publication dates. We make publicly available this new dataset of 14,053 articles, annotated with each language version, and additional metadata such as links and images. The main contribution of this paper for the NLP community is in the novel dataset which enables studies of disinformation networks, and the training of NLP tools for disinformation detection.\\n\\n1 Introduction\\n\\nCoordinated, state-backed disinformation operations have become an increasing problem in recent years, particularly surrounding the war in Ukraine (Mork\u00afunas, 2022). In September 2022, a sophisticated network of doppelganger websites (impersonating genuine news sites from across Europe) was discovered by EUDisinfoLab (Alaphilippe et al., 2022) and later expanded on in a report from Meta (Nimmo and Torrey, 2022). Among these was also a small number of conventional false news sites.\\n\\nThe focus of this study is on two related disinformation sites in particular: Reliable Recent News (RRN) and War On Fakes (WoF). Both sites are multilingual, publishing in Arabic, Chinese, English, French, German, and Spanish, and RRN additionally in Italian. They have been promoted by Russian government sources, including being shared by Russian embassies (Maitland, 2022; Roache, 2022), and publicised by the Ministry of Foreign Affairs of Russia's official Twitter account. We focus on these two \u201cnews\u201d sources due to their links to the Doppelganger network, their potential to deceive unsuspecting citizens (compared to better known propaganda sources such as Russia Today), and their prior exposure as disinformation spreaders (see Appendix A).\\n\\nBackovic and Walter (2023) investigated the ownership of WarOnFakes, and stated it was operated by Russian journalist Timofey Vasiliev, a known affiliate of Russian propaganda groups, due to the presence of his name, email and phone number on the website. However, they do not state precisely how they found this information, and do not attempt to establish a link between Vasiliev and RRN or the Doppelganger operation.\\n\\nHanley et al. (2022) included selected articles from WarOnFakes and nine other disinformation websites in an analysis of narratives spread on Reddit. In contrast, our dataset includes all WarOnFakes posts and extracts the full article content.\\n\\nPropaganda is defined as content that intentionally influences opinion to advance its creators\u2019 goals (Bolsover and Howard, 2017). Numerous propaganda datasets have previously been created, with both document-level (Rashkin et al., 2017; Barr\u00f3n-Cede\u00f1o et al., 2019) and span-level (Da San Martino et al., 2019b) technique annotations, using articles collected from multiple disinformation sites. At article-level, classifiers using combinations of multiple linguistic representations based on style and readability outperform content representation (Barr\u00f3n-Cede\u00f1o et al., 2019), whereas content-based transformer models such as BERT have seen use at span-level (Da San Martino et al., 2019a). Detectors are often evaluated on single datasets, prompting concerns on generalisation (Martino et al., 2020).\\n\\nWe are not aware of any prior work including RRN, nor of any work which has released a comparable dataset of disinformation.\\n\\n4https://twitter.com/mfa_russia/status/150022\\n3302941487107\"}"}
{"id": "emnlp-2023-main-349", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thus the contributions of this paper are: i) a new publicly available dataset of content from two state-backed disinformation websites; ii) a linguistic, topic, and temporal analysis of their articles; and iii) our open-source toolkit for processing site data and extraction of translations.\\n\\n2 Methodology\\n\\n2.1 Data Collection\\nIn March 2023 we used the WordPress REST API to obtain all posts from WoF and RRN. Each post was parsed to extract its text, removing non-article content (such as figure captions). The webpage of each post was then analysed to extract the different translations from the language picker. Our extraction tool supports the specific markup used by these two sites, but can be easily extended to support others. An example of an extracted article is shown in Appendix B.\\n\\nPublication and modification times, which are provided in GMT by the API, were also converted to Moscow local time for analysis, since it is believed that at least one of the sites is based in Russia (Backovic and Walter, 2023).\\n\\n2.2 Topic Analysis\\nThe articles were clustered using BERTopic (Grootendorst, 2022). We assume that whilst each article may discuss many topics, each sentence of an article is likely to discuss a single topic. Articles were split using spaCy's dependency-parse-based sentenceizer, and sentences with less than 5 tokens were removed. The remaining sentences were embedded with Sentence Transformers MPNET (Reimers and Gurevych, 2019; Song et al., 2020). The dimensionality of each embedding was reduced using UMAP (McInnes et al., 2020) from 768 to 5, whilst keeping the structure of the higher-dimensional space. This is necessary to avoid the 'curse of dimensionality'.\\n\\nThe 5d embeddings were clustered with HDBSCAN (Campello et al., 2013), which notably allows for embeddings to not be included in a cluster, preventing overly broad clusters by forcing nearby but unrelated sentences in. It is expected that this produces a large number of outliers, since it is natural that many of the sentences in the articles will have meanings unrelated to any other. A minimum cluster size of 25 is set to prevent too many small clusters from being generated.\\n\\nKeyword representations are generated by creating a bag-of-words vector of the unigrams and bigrams of each topic (excluding English stopwords) which is L1-normalized to account for cluster size. An adapted class-based TF-IDF is used to calculate the most significant words in each cluster. This representation is then fine-tuned by selecting keywords with a high Maximal Marginal Relevance, in order to maximise their diversity. The diversity parameter was set to 0.5. The top 3 most significant keywords are used to name the cluster.\\n\\nEach article is then labelled with the unique set of clusters assigned to its sentences.\\n\\n2.3 Article Backdating\\nIn WordPress, article publication dates can be set to any given date, however this does not affect the auto-incrementing IDs which are generated in the order of article creation. Thus backdated articles can be detected based on their IDs being higher than that of their following articles, when they are ordered by supposed publication date.\\n\\n2.4 n-gram Frequency\\nFrequent 2-4-grams were extracted using NLTK, after tokenisation, lowercasing, and stopword and punctuation removal. N-gram frequency was calculated monthly, and the most frequent 10 n-grams per month were selected, excluding the phrase \\\"armed forces\\\", and n-grams which are part of another, longer n-gram of equal frequency (e.g. removing \\\"ukrainian armed\\\" in favour of \\\"ukrainian armed forces\\\"). We include ties for 10th place.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Monthly post counts across both sites, by reported article date. Partial data for March 2023 excluded.\\n\\n| Language   | RRN  | WoF  | Total | Toks. | Sents. |\\n|------------|------|------|-------|-------|--------|\\n| Arabic (ar)| 509  | 324  | 833   | 201.89| 10.44  |\\n| German (de)| 2032 | 473  | 2505  | 339.90| 15.91  |\\n| English (en)| 2265 | 864  | 3129  | 341.31| 15.84  |\\n| Spanish (es)| 1229 | 468  | 1697  | 345.22| 14.99  |\\n| French (fr)| 1968 | 683  | 2651  | 386.91| 15.42  |\\n| Italian (it)| 1288 | -    | 1288  | 429.89| 19.03  |\\n| Chinese (zh)| 1220 | 730  | 1950  | 261.47| 13.41  |\\n| All        | 10511| 3542 | 14053 | 338.89| 15.37  |\\n\\nTable 1: Number of articles per site, per language, and mean token and sentence counts\\n\\n3.2 Article Frequency\\n\\nFigure 1 shows the proportion of each language over time for each site. The first WoF article is published on the 4th March 2022, and the first RRN article on the 11th. WarOnFakes has an unusual pattern of publication in its first few days, publishing sixty articles on the first day, and an average of 34 articles/day over the first 7 days, whereas RRN published only 7 articles on day one and an average of 21 articles/day over the first week.\\n\\nGenerally, posts are published on weekdays, with only 9.5% of posts having publication dates and 7.0% having modification dates on a Saturday or Sunday. The week beginning 2nd January 2023, much of which is public holidays in Russia, has the lowest activity in the sites' history, with only 60 articles published on RRN and 19 on WoF. For comparison, the mean in other weeks is 200 (RRN) and 66 (WoF).\\n\\n25 identical articles were published on both sites predominantly in March 2022, and in all but one case they were a WoF-style debunk. They were not published simultaneously on the two sites, nor is it consistent which site published first.\\n\\n3.3 Language Coverage\\n\\nOnly a small minority of posts (\u223c9.1%) are not available in English, and the majority of these do not have any translations at all, suggesting they are likely \u2018orphaned\u2019 translations. The mean number of available languages for a post is 4 \u00b1 1.5 (1 std). All site-language pairs continued to be published until the end of the collection period, except Arabic and Spanish on WoF and Chinese on RRN, which stopped in July and October 2022 respectively. Spanish posts resumed in December 2022.\\n\\n3.4 Topics\\n\\nAmongst the 45,991 English sentences in the English articles, 24,800 were considered outliers and 21,191 were assigned one of 144 topics. These topics ranged from broad, recurrent themes (e.g. #0, the donation of arms and aid to Ukraine) to more specific, time-limited ones (e.g. #139, the burning of the Quran by far-right activist Rasmus Paludan). The mean number of topics assigned per article is 4.33 \u00b1 2.66 (1 std). In the first week of the war in Ukraine (beginning 28th Feb 2022), the vast majority of articles are categorised as #2 (russian\"}"}
{"id": "emnlp-2023-main-349", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"military, ukranian telegram, telegram channels, according to ukranian). These articles are all from WarOnFakes (since RRN did not start publishing until the following week) and are claiming that various evidence from the war in Ukraine is fake.\\n\\nOf the 144 topics we identified, 126 were assigned to articles from both RRN and WoF, and only 18 were assigned to posts from just one of the two sites. This demonstrates the significant topical overlap between the sites. Further details and figures are provided in Appendix C.\\n\\n3.5 LIWC Analysis\\nWe use LIWC2015 (Pennebaker et al., 2015) to compare the linguistic properties of English RRN and WoF posts against the metrics for genuine New York Times (NYT) articles provided by Pennebaker et al. (see Table 2 and Appendix C.1).\\n\\nEmotional tone, which is on a scale of 0-100 (negative to positive), shows that RRN and WoF are written more negatively than real news, with WoF being even more negative than RRN. This is confirmed by the values for Affective Processes, which show that both sites use more emotion-laden words than NYT. The sub-metrics show this is skewed towards negativity, particularly anger (where both sites have over double the proportion of anger-indicating words than NYT).\\n\\nAll three sources focus most commonly on the present (e.g. words like \u201ctoday\u201d, \u201cis\u201d, \u201cnow\u201d), however RRN and WoF do so at a higher rate than the NYT. RRN and WoF also use more future focus terms (e.g. \u201cmay\u201d, \u201cwill\u201d, \u201csoon\u201d) compared to the NYT, and past focus terms (e.g. \u201cago\u201d, \u201cdid\u201d, \u201ctalked\u201d) less frequently. This suggests that the content of RRN and WoF comments is more speculative as compared to reputable journalism and is more focused on covering current events than past ones.\\n\\nTable 3 shows the top 5 LIWC categories with the strongest correlation for each of the two sites. The strong correlation of colons and interrogatives for WoF is unsurprising, given its repeated use of the phrase \u201cWhat\u2019s really going on:\u201d. RRN\u2019s correlation with conjunctions suggests it tends to use more complex sentences. The remaining attributes are below the 0.3 threshold of strong correlation. However RRN is weakly correlated to personal pronouns which is due to its tendency to cover individual politicians (see Table 6 in Appendix C), while WoF is weakly correlated to impersonal pronouns.\\n\\n| Metric         | RRN | WoF | NYT |\\n|----------------|-----|-----|-----|\\n| Tone           | 27.71 | \u2193 | 15.06 | \u2193 | 43.61 |\\n| Affective       | 4.67 | \u2191 | 3.97 | \u2191 | 3.82 |\\n| Positive Emotion | 2.12 | \u2193 | 1.23 | \u2193 | 2.32 |\\n| Negative Emotion | 2.49 | \u2191 | 2.72 | \u2191 | 1.45 |\\n| Anger           | 1.01 | \u2191 | 0.98 | \u2191 | 0.47 |\\n| Past Focus      | 3.67 | \u2193 | 3.77 | \u2193 | 4.09 |\\n| Present Focus   | 6.42 | \u2191 | 6.40 | \u2191 | 5.14 |\\n| Future Focus    | 1.12 | \u2191 | 1.00 | \u2191 | 0.80 |\\n\\nTable 2: Comparison of selected LIWC2015 attributes, compared to the New York Times\\n\\n3.6 Article Backdating\\nBoth sites tend to backdate non-English posts (by as much as 136 days in two cases, see Appendix C, Table 5), in order to make translations appear published at a similar time. The two most backdated articles are Spanish and Chinese translations of an English article, which were actually published 136 days later.\\n\\nOur hypothesis for the backdating is due to limited resources articles were only translated into a given language when that became necessary for a particular disinformation campaign. In order to convey timeliness, the translations were then backdated to the date of the original.\\n\\n3.7 n-gram Analysis\\nTables 6 and 7 in Appendix C show the top occurring n-grams per month for the respective websites. The most frequent \u201creally going\u201d n-gram on WoF is part of the phrase \u201cWhat\u2019s really going on\u201d, which appears in all of its fact-check-style articles. The n-gram also appears frequently in the first month of RRN data, due to the articles copied from WoF.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Frequency of Cyrillic usage reasons\\n\\n| Category          | RRN | WoF |\\n|-------------------|-----|-----|\\n| Accidental Cyrillic | 58  | 34  |\\n| Forgotten Cyrillic | 15  | 25  |\\n| Intentional        | 36  | 10  |\\n| Unclear            | 0   | 2   |\\n\\nOn WoF, the most frequent n-grams typically relate directly to the war in Ukraine itself (\u201crussian troops\u201d, \u201cukranian armed forces\u201d), whereas on RRN they relate to the consequences of the conflict for the rest of the world (\u201cunited states\u201d, \u201crussian gas\u201d). Consequently, the most frequent n-grams on WoF are relatively constant across the different months, whereas RRN\u2019s n-grams change from one month to the next as they tend to be connected to current affairs. For example, the bigram \u201canti-russian sanctions\u201d enters the top 10 in June 2022, and remains the second most used bigram from July to September, and refers to the damage allegedly caused to Western economies. Other terms demonstrate that RRN also covers some genuine news, e.g. \u201celizabeth ii\u201d in September 2022 and \u201cworld cup\u201d in November and December 2022.\\n\\nEven though to a much lesser degree, WoF still responds to specific highly controversial events from the conflict. For example in August 2022, in response to Ukraine and Russia blaming each other for the shelling of the Zaporizhzhia nuclear power station, the n-grams \u201cnuclear power\u201d and \u201cnuclear power plant\u201d both appear with high frequency in WoF articles that promote the Russian perspective on these events.\\n\\n3.8 Presence of Cyrillic Characters\\n\\n178 of the articles were found to contain characters in the Cyrillic codepoint range (Table 4), which were manually examined to determine the reason.\\n\\n- **Accidental Cyrillic**: Incorrect usage of Cyrillic characters instead of the intended character in the Latin alphabet. For example, 11 times the \u201cc\u201d in Robert Habeck, a German politician, is actually the identical-looking lowercase Cyrillic Es.\\n- **Forgotten Cyrillic**: Issues with translation where a Russian sentence was left in the article, with or without the target language translation.\\n- **Intentional**: Expected usage of Cyrillic characters e.g. the name of a Russian organisation.\\n- **Unclear**: We were unable to determine why the characters were used.\\n\\nGiven that both RRN and WoF had forgotten Russian text in all languages, we hypothesise that all articles were originally written in Russian. Two Arabic articles on RRN contain the phrases \u201cthe translation is too long\u201d and \u201csave translation\u201d in Russian, likely copied from a machine translation tool\u2019s UI, although we were not able to determine the specific tool used. Although this was only found in one language on one of the sites, it suggests it is more likely the articles are machine than human translated.\\n\\n4 Future Work\\n\\nThere is much additional work which could be performed on this dataset. Although we identify the subject of articles via topic clustering and n-grams, we do not attempt to identify stance towards it. More complex topic analysis, such as identifying commonly co-occuring topics, would also be possible. Given the mixture of true and false posts on the sites, this dataset may be a useful resource for automated fact-checking, although this would require human annotation and ground-truth may be difficult to establish in the complex information environment of the war in Ukraine.\\n\\n5 Conclusion\\n\\nThis paper presented an analysis of the Russian disinformation sites Recent Reliable News and WarOnFakes, including an analysis of the articles' topics, publication times, and linguistic properties. We show that the sites cover a diverse range of topics, and that their linguistic properties differ from those of reputable media. We analysed the presence of Cyrillic characters due to site operator errors, and their practice of backdating articles, showing that a significant proportion of translations are falsely dated. This new multilingual dataset will facilitate further research in disinformation analysis and promote repeatability.\\n\\nLimitations\\n\\nAlthough our work provides a complete collection of WoF and RRN, since these two websites seem to be highly related, it is unsurprising that they tend to publish similar types of content. Therefore this dataset cannot be considered fully representative.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of all kinds of Russian disinformation. Nevertheless, it is complementary to overtly Russian state media, such as Sputnik and Russia Today. Unfortunately, due to the ban on accessing their content from the EU, we could not supplement the dataset from those sources or compare against them.\\n\\nOur topic analysis model has not been formally validated, for example by comparing topics to those assigned by human or expert annotators. Some small scale manual validation was performed in order to find good hyperparameters, however this consisted of inspecting a small random sample of some of the categories. A particular area warranting validation in future work is examining the texts not assigned categories. These are only a very small number, however as we aggregate sentence classifications at article level, which means that an article can be assigned the correct topics even if some of its sentences may not be.\\n\\nIn our LIWC analysis, we compare to the New York Times data provided by Pennebaker et al. (2015). Although this is the closest source out of the provided LIWC baselines, the New York Times represents a more formal style of journalism than many online media. In future work we plan to compare these two disinformation sites against official state-affiliated news sources such as Russia Today.\\n\\nFinally, we did not analyse the separate Russian-language edition of WarOnFakes. As it is a separate site in Russian only, there is no reliable way to connect its articles to their similar English-language versions (if such are published). Analysing the Russian WoF website is planned for future work, as it requires adaptation of the analysis to be bilingual, which is out of scope for this paper.\\n\\nEthics\\nThe data collection was carried out in accordance with our institutional ethics policy.\\n\\nCollection was via the Wordpress API, followed by automated processing and a limited amount of manual analysis by the authors. No external volunteers or crowd-workers were recruited. Due to the disinformation nature of these two websites, the data may contain content which is disturbing or distressing. Therefore we limited the possibility of harm during analysis by: i) minimising the number of individual articles studied by the authors as much as possible; ii) where necessary, viewing only the text of articles, to avoid the possibility of viewing distressing media; iii) ensuring familiarity with supporting resources for researchers working with potentially disturbing content.\\n\\nAs the websites in question are not legitimate news websites, they do not have a terms of use to allow or prohibit the acquisition of their content. We consider the collection and distribution of their articles in the public interest, due to the prominence of their disinformation and the harm that results from it. It is not feasible to contact them to obtain permission, as they have previously been unresponsive to enquiries. The dataset does not include images, as in many cases they appear to have been taken from stock agencies. This is a commonly used tactic by disinformation websites.\\n\\nWe have checked that the dataset does not contain personally identifiable information in the user data files, as all users have either generic (e.g. \u201cAdmin\u201d) or random (e.g. \u201cUiXnZyvH\u201d) names. No user comments were available to collect.\\n\\nIt is possible that the process of creating a disinformation dataset increases the spread and prominence of the disinformation. We would argue that is not the case with this dataset as we: i) are only focusing on content from disinformation websites, the low credibility of which has already been widely publicised (see Appendix A); iii) are not increasing the longevity of disinformation narratives by preserving them after they have being taken down, since the two independent websites that are publishing them are still publicly accessible via all common search engines.\\n\\nSome articles make reference to individuals, albeit only public figures to our knowledge, and many contain narratives which are hateful towards individuals and groups. We encourage researchers who use this dataset to do so responsibly, and in particular to avoid highlighting specific individuals and to ensure that the disinformation narratives are presented alongside authoritative evidence of their untrue nature. We would like to specifically discourage the use of this dataset for training generative models that are capable of creating new disinformation. The dataset is released under a license which prohibits commercial activity.\\n\\nAcknowledgments\\nThis work is partially supported by the UK\u2019s innovation agency (InnovateUK) grant number 5734.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Charu C. Aggarwal, Alexander Hinneburg, and Daniel A. Keim. 2001. On the surprising behavior of distance metrics in high dimensional spaces. In International Conference on Database Theory.\\n\\nAlexandre Alaphilippe, Gary Machado, Raquel Miguel, and Francesco Poldi. 2022. Doppelganger - media clones serving russian propaganda. Technical report, EU DisinfoLab.\\n\\nNick Backovic and Kyle Walter. 2023. Logically investigations: Russian propaganda disguised as fact checking. Technical report, Logically.\\n\\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni Da San Martino, and Preslav Nakov. 2019. Proppy: Organizing the news based on their propagandistic content. Information Processing & Management, 56(5):1849\u20131864.\\n\\nGillian Bolsover and Philip Howard. 2017. Computational propaganda and political big data: Moving toward a more critical research agenda. Big Data, 5(4):273\u2013276.\\n\\nRicardo J. G. B. Campello, Davoud Moulavi, and J\u00f6rg Sander. 2013. Density-based clustering based on hierarchical density estimates. In Advances in Knowledge Discovery and Data Mining, pages 160\u2013172, Berlin, Heidelberg. Springer Berlin Heidelberg.\\n\\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and Preslav Nakov. 2019a. Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection. In Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda, pages 162\u2013170, Hong Kong, China. Association for Computational Linguistics.\\n\\nGiovanni Da San Martino, Seunghak Yu, Alberto Barr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov. 2019b. Fine-grained analysis of propaganda in news article. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5636\u20135646, Hong Kong, China. Association for Computational Linguistics.\\n\\nMaarten Grootendorst. 2022. BERTopic: Neural topic modeling with a class-based TF-IDF procedure. Computing Research Repository, arXiv:2203.05794. Version 1.\\n\\nHans W. A. Hanley, Deepak Kumar, and Zakir Durumeric. 2022. Happenstance: Utilizing semantic search to track russian state media narratives about the russo-ukrainian war on reddit. Computing Research Repository, arXiv:2205.14484v2. Version 2.\\n\\nRuixuan Luo, Jingjing Xu, Yi Zhang, Zhiyuan Zhang, Xuancheng Ren, and Xu Sun. 2022. Pkuseg: A toolkit for multi-domain chinese word segmentation. Computing Research Repository, arXiv:1906.11455. Version 3.\\n\\nEva Maitland. 2022. RRN.world nutrition label. Technical report, NewsGuard.\\n\\nGiovanni Da San Martino, Stefano Cresci, Alberto Barron-Cedeno, Seunghak Yu, Roberto Di Pietro, and Preslav Nakov. 2020. A survey on computational propaganda detection. Computing Research Repository, arXiv:2007.08024.\\n\\nLeland McInnes, John Healy, and James Melville. 2020. UMAP: Uniform manifold approximation and projection for dimension reduction. Computing Research Repository, arXiv:1802.03426.\\n\\nMangirdas Mork\u016bnas. 2022. Russian disinformation in the baltics: Does it really work? Public Integrity, pages 1\u201315.\\n\\nBen Nimmo and Mike Torrey. 2022. Taking down coordinated inauthentic behavior from russia and china. Technical report, Meta.\\n\\nJames W Pennebaker, Ryan L Boyd, Kayla Jordan, and Kate Blackburn. 2015. The development and psychometric properties of LIWC2015.\\n\\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and political fact-checking. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2931\u20132937, Copenhagen, Denmark. Association for Computational Linguistics.\\n\\nNils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.\\n\\nMadeline Roache. 2022. WarOnFakes.com nutrition label. Technical report, NewsGuard.\\n\\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. MPNet: Masked and permuted pre-training for language understanding. Computing Research Repository, arXiv:2004.09297. Version 2.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Evidence of Disinformation\\n\\nFor WarOnFakes, there is a substantial number of articles and fact-checks establishing it as a disinformation source. PolitiFact undertook a review of over 380 of their fact-checks and found a significant number of falsehoods. In an article by AFP via France24, Roman Osadchuk, from the Atlantic Council's Digital Forensic Research Lab (DFRLab), is quoted as saying \u201cSince Russia's invasion, the 'War On Fakes' initiative has become a powerhouse of spreading false debunks\u201d and \u201cIt is an effective tool of state propaganda and disinformation.\u201d The Institute of Network Cultures describes it as \u201cKremlin-Sponsored Participatory Propaganda,\u201d and highlights connections between the Russian state and the website, including promotion from organisations under the Russian Ministry of Foreign Affairs, and on the Russian Ministry of Defence\u2019s Telegram channel. BBC Monitoring, the specialist media source analysis division of BBC News, states \u201cSome of its fact-checks are genuine but most content is Russian talking points on the invasion which do not stand up to scrutiny.\u201d\\n\\nThe site has also been covered by EUvsDisinfo, DFRLab, the European Digital Media Observatory, and Media Bias/Fact Check. RRN has received comparatively less attention from fact checkers, however was described as disinformation by NewsGuard (Maitland, 2022), which additionally claims that they reuse content from WarOnFakes, and EU Disinfo Lab have noted a connection in the hosting infrastructure of the two sites (Alaphilippe et al., 2022). It is therefore probable that the apparent state-backing of WarOnFakes also applies to RRN.\\n\\nB Data Example\\n\\nFigure 3 shows an example of an article published on WoF in English, French, Spanish, Chinese and Arabic. Full texts are omitted for languages other than English. This story was judged to be fake by fact-checkers. Usage of guillemets (\u00ab \u00bb) as quote marks is reproduced as returned by the WordPress API, but this appears to be normalised when the page is rendered.\\n\\nC Detailed Dataset Statistics\\n\\nFigure 4 shows a weekly chart of the 10 most common topics on the site. In general, there is no clear variation between these topics, with the exception of the initial popularity of the topic #2 due to the majority of posts that week being from WarOnFakes. The significant dip in January 2023 is due to the Russian public holidays discussed in section 3.2.\\n\\nFigure 2 shows the distribution of sentence-level topic counts aggregated for each article. 78 posts were not assigned any topic, the majority of articles...\"}"}
{"id": "emnlp-2023-main-349", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"have 1-3 topics, however in the extreme some have as many as 21 - this is an article from WarOnFakes \u201cWhat happened in Bucha? A full analysis of the Ukrainian provocation\u201d, a long article supposedly explaining the truth about many elements of the Bucha massacre.\\n\\nTable 5 shows the proportion of backdated articles per language, and the mean and maximum backdating period for each. For English, a small number of posts are backdated after a short period of time. It is likely this is caused by posts that have been forward-dated (i.e. set to be published in the future) by one or two days, resulting in subsequent posts appearing to be backdated until the publication date catches up. However, for other languages, backdates are for a much longer period.\\n\\nC.1 Complete LIWC2015 Data\\n\\nThe complete listing of LIWC2015 is included in Table 8, in the hope it can be used for comparison in future work.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Fake: Russian aircraft attacked a maternity hospital with mothers and children inside\\n\\nWhat is fake about:\\n\\nInformation that Russia launched an airstrike on a maternity hospital in Mariupol is being spread online. Ukrainian President Volodymyr Zelensky called it \u00aban atrocity\u00bb and said that women and children remained under the rubble.\\n\\nThe fact\\n\\nDespite the fact that information about the strike appeared in the middle of the day of March 8, no single patient was visible on numerous videos and photos. The footage of pregnant women appeared on the Internet much later \u2013 in the evening of March 9. However, it immediately was circulated by all news agencies, social media, popular communities and bloggers, which may be the result of a preplanned campaign. Moreover, it was happening despite the fact that the locals themselves claimed that there were no patients or members of the staff in the maternity hospital.\\n\\nThis story is rather dubious. It is logical to assume that if there really had been patients then the rescue service officers and eyewitnesses who arrived at the scene would immediately have taken photos of the accident scene with their phones, without waiting for a well-known photographer. However, it so happened that the well-known Ukrainian propaganda activist Evgeniy Maloletka was the first to prepare and publish the photographs.\\n\\nToday we received indisputable confirmation that the \u00abphotos of pregnant women\u00bb were staged. The Ukrainians used a model called Marianna who comes from Mariupol for the most striking photos (there are three in total). It is notable that she played roles of two different pregnant women at the same time: she even had to change clothes and the color of her hair, which, however, is not surprising: in fact, Marianna is a well-known beauty blogger in the region. It's worth noting that the girl is indeed pregnant, but she just could not have been in the maternity hospital: the Azov militants had used the medical facility for several days as a fortified stronghold that does not function as a maternity hospital any longer. The main heroine of this hoax has already been caught in the spotlight. In the comment section of her Instagram account there are already more than 500 comments under her last post written by real users condemning the girl for participating in information manipulations.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Week       | Number of articles |\\n|------------|--------------------|\\n| Mar 2022   |                    |\\n| May 2022   |                    |\\n| Jul 2022   |                    |\\n| Sep 2022   |                    |\\n| Nov 2022   |                    |\\n| Jan 2023   |                    |\\n\\nFigure 4: Weekly frequency of top 10 clusters. Partial data for March 2023 excluded.\"}"}
{"id": "emnlp-2023-main-349", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Top n-grams for RRN\\n\\nMar 22 Apr May Jun Jul Aug\\nreally going really going really going really going really going really going\\nfake message telegram channels telegram channels really going war fakes ukrainian propaganda fake russian\\n\\nTable 7: Top n-grams for WoF\\n\\n5740\"}"}
{"id": "emnlp-2023-main-349", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Category          | RRN | WoF | All  |\\n|-------------------|-----|-----|------|\\n| Word count (mean) | 313.80 | 249.24 | 295.74 |\\n| Summary Variables |     |     |      |\\n| Analytic          | 94.37 | 95.12 | 94.58 |\\n| Clout             | 63.62 | 56.75 | 61.70 |\\n| Authentic         | 23.13 | 22.95 | 23.08 |\\n| Emotional Tone    | 27.71 | 15.06 | 24.17 |\\n| Language Metrics  |     |     |      |\\n| Words/sentence    | 19.92 | 20.15 | 19.98 |\\n| Words > 6 letters | 27.97 | 29.12 | 28.30 |\\n| Dictionary words  | 76.81 | 75.33 | 76.40 |\\n| Function Words    | 45.94 | 46.86 | 46.20 |\\n| Total pronouns    | 6.30  | 6.20  | 6.27  |\\n| Personal pronouns | 2.70  | 1.54  | 2.38  |\\n| 1st pers singular | 0.16  | 0.06  | 0.14  |\\n| 1st pers plural   | 0.50  | 0.38  | 0.46  |\\n| 2nd person        | 0.16  | 0.09  | 0.14  |\\n| 3rd pers singular | 0.95  | 0.41  | 0.80  |\\n| 3rd pers plural   | 0.94  | 0.60  | 0.84  |\\n| Impersonal pronouns | 3.59  | 4.66  | 3.89  |\\n| Articles          | 10.30 | 11.06 | 10.51 |\\n| Prepositions      | 15.81 | 16.09 | 15.89 |\\n| Auxiliary verbs   | 6.53  | 7.21  | 6.72  |\\n| Adverbs           | 3.23  | 3.83  | 3.40  |\\n| Conjunctions      | 4.44  | 3.37  | 4.14  |\\n| Negations         | 1.17  | 1.16  | 1.17  |\\n| Other Grammar     |     |     |      |\\n| Common verbs      | 11.01 | 11.03 | 11.02 |\\n| Common adjectives | 3.97  | 3.62  | 3.87  |\\n| Comparisons       | 2.02  | 1.46  | 1.86  |\\n| Interrogatives    | 0.92  | 1.66  | 1.13  |\\n| Number            | 2.13  | 1.75  | 2.02  |\\n| Quantifiers       | 1.62  | 1.24  | 1.51  |\\n| Psychological Processes |     |     |      |\\n| Affective processes | 4.67  | 3.97  | 4.47  |\\n| Positive emotion  | 2.12  | 1.23  | 1.87  |\\n| Negative emotion  | 2.49  | 2.72  | 2.55  |\\n| Anxiety           | 0.38  | 0.22  | 0.34  |\\n| Anger             | 1.01  | 0.98  | 1.00  |\\n| Sadness           | 0.37  | 0.21  | 0.33  |\\n| Social processes  | 6.82  | 4.84  | 6.26  |\\n| Family            | 0.15  | 0.09  | 0.13  |\\n| Friends           | 0.16  | 0.09  | 0.14  |\\n| Female references | 0.34  | 0.19  | 0.30  |\\n| Male references   | 0.85  | 0.41  | 0.72  |\\n| Cognitive processes | 8.26  | 7.69  | 8.10  |\\n| Insight           | 1.52  | 1.36  | 1.48  |\\n| Causation         | 1.72  | 1.91  | 1.77  |\\n| Discrepancy       | 0.96  | 0.47  | 0.82  |\\n| Tentative         | 1.36  | 1.13  | 1.30  |\\n| Certainty         | 1.11  | 1.02  | 1.09  |\\n| Differentiation   | 2.34  | 2.26  | 2.32  |\\n| Perceptual processes | 1.72  | 2.03  | 1.81  |\\n| See               | 0.65  | 1.32  | 0.84  |\\n| Hear              | 0.63  | 0.42  | 0.57  |\\n| Feel              | 0.34  | 0.22  | 0.30  |\\n| Biological processes | 1.24  | 1.06  | 1.19  |\\n| Body              | 0.40  | 0.36  | 0.39  |\\n| Health            | 0.56  | 0.57  | 0.57  |\\n| Sexual            | 0.04  | 0.03  | 0.04  |\\n| Ingestion         | 0.27  | 0.14  | 0.24  |\\n| Drives            | 8.41  | 6.95  | 8.00  |\\n| Affiliation        | 1.57  | 1.25  | 1.48  |\\n| Achievement       | 1.54  | 1.06  | 1.40  |\\n| Power             | 4.60  | 4.05  | 4.44  |\\n| Reward            | 0.77  | 0.51  | 0.70  |\\n| Risk              | 0.97  | 0.64  | 0.88  |\\n| Time orientations |     |     |      |\\n| Past focus        | 3.67  | 3.77  | 3.70  |\\n| Present focus     | 6.42  | 6.40  | 6.42  |\\n| Future focus      | 1.12  | 1.00  | 1.09  |\\n| Relativity        | 13.77 | 13.05 | 13.57 |\\n| Motion            | 1.70  | 1.78  | 1.72  |\\n| Space             | 7.73  | 8.02  | 7.81  |\\n| Time              | 4.39  | 3.21  | 4.06  |\\n| Personal Concerns |     |     |      |\\n| Work              | 3.77  | 3.32  | 3.64  |\\n| Leisure           | 0.76  | 1.29  | 0.91  |\\n| Home              | 0.34  | 0.31  | 0.33  |\\n| Money             | 1.48  | 0.67  | 1.25  |\\n| Religion          | 0.38  | 0.35  | 0.37  |\\n| Death             | 0.38  | 0.43  | 0.39  |\\n| Informal Language | 0.23  | 0.19  | 0.22  |\\n| Swear words       | 0.01  | 0.01  | 0.01  |\\n| Netspeak          | 0.06  | 0.09  | 0.07  |\\n| Assent            | 0.04  | 0.04  | 0.04  |\\n| Nonfluencies      | 0.08  | 0.06  | 0.07  |\\n| Fillers           | 0.02  | 0.00  | 0.02  |\\n| Punctuation       |     |     |      |\\n| Total Punctuation | 15.09 | 13.87 | 14.75 |\\n| Periods           | 5.26  | 5.31  | 5.28  |\\n| Commas           | 4.91  | 4.14  | 4.70  |\\n| Colons           | 0.36  | 1.08  | 0.56  |\\n| Semicolons       | 0.05  | 0.03  | 0.04  |\\n| Question marks    | 0.13  | 0.03  | 0.11  |\\n| Exclamation marks | 0.09  | 0.01  | 0.07  |\\n| Dashes           | 0.69  | 0.70  | 0.69  |\\n| Quotation marks  | 2.09  | 1.52  | 1.93  |\\n| Apostrophes      | 0.97  | 0.57  | 0.86  |\\n| Parentheses       | 0.25  | 0.37  | 0.28  |\\n| Other punctuation | 0.28  | 0.12  | 0.23  |\\n\\nTable 8: Complete LIWC2015 listings\"}"}
