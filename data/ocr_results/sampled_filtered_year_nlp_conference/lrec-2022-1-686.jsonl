{"id": "lrec-2022-1-686", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in Social Media Posts\\n\\nMuskan Garg, Chandni Saxena, Veena Krishnan, Ruchi Joshi, Sriparna Saha, Vijay Mago, Bonnie J Dorr\\n\\n1 Thapar Institute of Engineering & Technology, India, 2 The Chinese University of Hong Kong, Hong Kong SAR, 3 University of Petroleum And Energy Studies, India, 4 Amity University Rajasthan, India, 5 Indian Institute of Technology, Patna, 6 Lakehead University, Canada, 7 University of Florida, USA.\\n\\n{muskangarg, bonniejdorr}@ufl.edu, chandnisaxena@cuhk.edu.hk, sriparna@iitp.ac.in, vkrishnan@ddn.upes.in, rjoshi@jpr.amity.edu, vmago@lakeheadu.ca\\n\\nAbstract\\n\\nResearch community has witnessed substantial growth in the detection of mental health issues and their associated reasons from analysis of social media. We introduce a new dataset for Causal Analysis of Mental Health Issues in Social Media Posts (CAMS). Our contributions for causal analysis are two-fold: causal interpretation and causal categorization. We introduce an annotation schema for this task of causal analysis. We demonstrate the efficacy of our schema on two different datasets: (i) crawling and annotating 3155 Reddit posts and (ii) re-annotating the publicly available SDCNL dataset of 1896 instances for interpretable causal analysis. We further combine these into the CAMS dataset and make this resource publicly available along with associated source code: https://github.com/drmuskangarg/CAMS. We present experimental results of models learned from CAMS dataset and demonstrate that a classic Logistic Regression model outperforms the next best (CNN-LSTM) model by 4.9% accuracy.\\n\\nKeywords: clinical depression, clinical psychology, intent classification, suicidal tendency\\n\\n1. Introduction\\n\\nWith substantial growth in digitization of psychological phenomena, automated Natural Language Processing (NLP) has been applied by academic researchers and mental health practitioners to detect, classify or predict mental illness on social media. However, there is a critical need for identifying underlying causes of mental illness in the face of dire outcomes. For example, a person commits suicide every 11.1 minutes in the US and 23% of deaths in the world are associated with mental disorders according to the World Health Organization. The pandemic lockdown has heightened the mental health crisis in UK (Pierce et al., 2020) and US (McGinty et al., 2020).\\n\\nIn this context, people with mental disorders who decide to visit mental health practitioners for social well-being may face difficulty due to social stigma or unavailability of mental health practitioners, leaving those most in need to be neglected by the community. As a result, sufferers of mental health conditions are unable to take necessary steps for their treatment. Unfortunately, 80% of those with mental health conditions do not undergo clinical treatment and about 60% of those who take their own lives previously denied having any suicidal thoughts (Sawhney et al., 2021). Accordingly, social media platforms (e.g., Reddit, Twitter) are important resources for investigating the mental health of users based on their writings.\\n\\n1.1. Motivation\\n\\nThe research community has witnessed tremendous growth in the study of mental health classification on social media since 2013 (Garg, 2021). However, there is minimal automation for identifying potential causes that underlie mental illness. Online users suffering from depression may express their thoughts and grievances on social media unintentionally, for instance, the post (P).\\n\\nP: I cannot deal with this breakup anymore and want to finish my life\\n\\nThe reason behind depression in P is clearly interpreted from the word breakup, which serves as an indicator of a cause related to the notion of relationship. Through the application of automatic causal analysis, underlying reasons of this type may be extracted and potentially leveraged to address mental health problems.\\n\\nSocial, financial and emotional disturbances have a\"}"}
{"id": "lrec-2022-1-686", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Different mental health datasets and their availability. A: Available, ASA: Available via Signed Agreement, AR: Available on Request for research work\\n\\nHuge impact on the mental health of online users. Here, we consider three levels of mental disorder analysis from automation to latent cause as shown in Figure 1. We identify the intent (level 0 task) of a user by mental illness prediction and classification of social media posts. We further automate the process of identifying and categorizing the direct cause (Level 1) that a user may mention in the post. In the future, causal analysis may discern crucial protective factors for mental health and address some important societal needs. Domain experts refer to level 1 as a direct cause mentioned by a user, often accompanied by a latent cause (Level 2) when they are posted on social media. In this work, we focus on automation by introducing a dataset for Level 1: interpretable causal analysis.\\n\\n1.2. Challenges and Contributions\\n\\nMental health illness detection and analysis on social media presents many linguistic, technical and psychological challenges. Among many under-explored dimensions, some substantial research gaps are addressed as follows:\\n\\n1. Dataset availability may be limited due to the sensitive nature of personal information.\\n2. There are many existing Level 0 studies for mental health detection but no substantial study for Level 1, e.g., in-depth causal analyses of disorders.\\n\\nTo address these challenges, we introduce the task of causal analysis. We first introduce an annotation scheme for causal analysis. The dataset annotations are carried out in two ways: (i) crawling and annotation of the Reddit dataset (ii) re-annotation of the existing SDCNL dataset (Haque et al., 2021) for the proposed task of Causal Analysis of Mental health on Social media (CAMS). There are no existing studies for this task as observed from Table 1. To the best of our knowledge, our work is the first to address causal analysis and to provide a publicly available dataset for this purpose. Our major contributions are:\\n\\n1. Definition of Interpretable Causal Analysis and construction of an annotation schema for this new task.\\n2. Annotated web-crawled Reddit dataset of 3362 instances using our annotation schema.\\n3. Re-annotation of the existing SDCNL dataset as a robustness test for our annotation schema.\\n4. Combination of the datasets above and introduction of our new, publicly available CAMS dataset.\\n5. Demonstration of the performance of machine learning and deep learning models using CAMS.\\n\\nBelow we discuss relevant background (Section 2) and introduce the annotation scheme for causal analysis (Section 3). Section 4 presents our new CAMS resource, annotation, and validation. Annotations are verified by experts (clinical psychologist and rehabilitation counselor) and validated using statistical testing of Fleiss' Kappa agreement (Falotico and Quatto, 2015). We further use existing multi-class classifiers for interpretable causal analysis in Section 5. Section 6 provides concluding remarks and future research directions.\"}"}
{"id": "lrec-2022-1-686", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2.1. Evolution of Mental Health Studies\\n\\nNew NLP questions have emerged from investigations into predicting depression (De Choudhury et al., 2013) and suicidal tendencies (Masuda et al., 2013). Researchers consider users' profiles (Conway and O'Connor, 2016) to introduce the CLPsych shared task dataset (Coppersmith et al., 2015) for solving the problem of Mental Illness Detection and Analysis on Social media (MIDAS). MIDAS has further benefited from exploiting social network features (Lin et al., 2017), attention mechanisms (Nam et al., 2017), handling imbalanced dataset (Cong et al., 2018), and explainability (Cao et al., 2019).\\n\\nAdditional research directions have emerged from the use of knowledge graphs (Cao et al., 2020), feature optimization techniques (Shah et al., 2020), longitudinal studies (Sawhney et al., 2021), and handling noisy labels (Haque et al., 2021). The 3-step theory (3ST) (Klonsky et al., 2021) of suicide supports the argument of gradual development of suicidal tendencies (over time) associated with a range of potential causes.\\n\\n2.2. Historical Perspective: Causal Analysis on Social Media\\n\\nOur work is relevant to causal analysis of human behavior on social media. Recent approaches are developed to study 'why online users post fake news' (Cheng et al., 2021), beliefs and stances behind online influence (Mather et al., 2022), and causal explanation analysis on social media (Son et al., 2018). The work of Son et al. (2018) is the closest to ours in that it detects a connection between two discourse arguments to extract a causal relation based on annotated Facebook data. However, the dataset is limited and is not publicly available; thus, no recent developments are observed.\\n\\nTo address this issue, we annotate the Reddit dataset (the nature of Reddit data is different from that of Facebook) and further categorize causal explanations.\\n\\n3. Annotation Scheme\\n\\n3.1. Inferences from Literature\\n\\nPotential reasons behind mental illness may be detected in posts that refer to insomnia, weight gain, or other indicators of worthlessness or excessive or inappropriate guilt. Underlying reasons may include: bias or abuse (Radell et al., 2021), loss of jobs or career (Mandal et al., 2011), physical/emotional illness leading to, or induced by, medication use (Smith, 2015; Tran et al., 2019), relationship dysfunction, e.g., marital issues (Beach and Jones, 2002), and alienation (Edition and others, 2013). This list is not exhaustive, but it is a starting point for our study, giving rise to five categories of reasons (plus 'no reason') for our automatic causal analysis: no reason, bias or abuse, jobs and careers, medication, relationship, and alienation.\\n\\nWe recognize 'medication' as both an indicator of physical/emotional illness (e.g., an intent to alleviate illness) and\\n\\n### Classification\\n\\n| Social Media | Data |\\n|--------------|------|\\n| T1:         | Suicide is the major cause of death |\\n| T2:         | I will commit suicide now |\\n| T3:         | I want to die because I cannot deal with this breakup |\\n| T4:         | I have no job, want to end my life |\\n\\n#### Normal Text\\n\\nMental disorder\\n\\nDirect cause of mental disorder found?\\n\\nC0: No reason\\n\\nC1: Bias/ Abuse\\n\\nC2: Jobs/ Career\\n\\nC3: Medication\\n\\nC4: Relationship\\n\\nC5: Alienation\\n\\nYes\\n\\nT4\\n\\nT3\\n\\nT1\\n\\nT2, T3, T4\\n\\nT2\\n\\n#### Figure 2: Architecture of the causal analysis for mental health in social media posts\\n\\n3.2. Annotation Task\\n\\nTable 2 presents examples of data annotation involving the labeling of direct causes of mental health disorders in social media posts. There are two types of annotations: cause category and Inference. The Inference column contains textual data which represents the actual reason behind mental disorders. This inferred reason is further classified as one of the six different causal categories.\\n\\n3.3. Problem Formulation\\n\\nThe architecture for our automatic causal analysis is shown in Figure 2. Social media text is provided to prediction/classification algorithms that filter out non-mental disorder from posts. The remaining mental disorder posts are then analyzed to detect reasons behind users' depression or suicidal tendencies. Finally, the reasons are classified into 5 causal categories and one 'no reason' category.\\n\\nMore formally, we introduce the problem of Causal Analysis of Mental health on Social media (CAMS) as a multi-class classification problem. We extract a set of social media posts as \\\\( p = p_1, p_2, p_3, ..., p_n \\\\) for \\\\( n \\\\) number of posts. We interpret the cause for every \\\\( i \\\\)th post \\\\( p_i \\\\) as \\\\( C_{p_i} \\\\) and classify it into one of the predetermined categories \\\\( y = y_0, y_1, y_2, y_3, y_4, y_5 \\\\) where \\\\( y_0 \\\\): 'no reason', \\\\( y_1 \\\\): 'bias or abuse', \\\\( y_2 \\\\): 'Jobs and career', \\\\( y_3 \\\\): 'Medication', \\\\( y_4 \\\\): 'Relationship', and \\\\( y_5 \\\\): 'Alienation' as \\\\( y_{p_i} \\\\).\\n\\n3.4. Guidelines for Annotation\\n\\nOur professional guidelines support annotation of the post \\\\( p_i \\\\) with causal inference \\\\( C_{p_i} \\\\) and class \\\\( y_{p_i} \\\\). The potential cause of illness (e.g., medication-induced depression).\"}"}
{"id": "lrec-2022-1-686", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"That's all I can really say. Nothing is worth the effort... I don't think I am capable of taking steps to improve my life, because I just don't even fucking care. Why try... I just... ugh...\\n\\nDoes anyone feel like the only person that could understand your depression would be someone else that was depressed? It might suck you into a place that you don't want to be in again.\\n\\nGod help me.... I know I should go to the hospital. I know I have to keep fighting....if only to prove to my children, cursed with these genetic tendencies of mine, that life is worth living. My scars and cynicism are just a little too hard for anyone who tries to stay around too long.\\n\\nI hate my job .. I cant stand living with my dad.. Im afraid to apply to any developer jobs or show my skills off to employers..I dont even have a car rn... I just feel like a failure.\\n\\n5 of my closest friends from high school have stopped responding to my calls or texts. i thought it was just a phone issue at first, but it is too unlikely of just coincidence.\\n\\n...Then, on the way to the pub, a group of girls basically called me unattractive. Funny how girls are never shy about calling me ugly, but they're apparently too shy to \\\"approach me\\\".\\n\\nTable 2: Sample of the CAMS dataset for causal analysis in the format of <text, cause, inference>\\n\\nRange Interpretation\\n\\n< 0: Less than chance agreement\\n0.01\u20130.20: Slight agreement\\n0.21\u2013 0.40: Fair agreement\\n0.41\u20130.60: Moderate agreement\\n0.61\u20130.80: Substantial agreement\\n0.81\u20130.99: Almost perfect agreement\\n\\nTable 3: Interpretation of resulting values of Fliess' Kappa agreement study (McHugh, 2012).\\n\\nguidelines are developed through collaborative efforts with a clinical psychologist and a rehabilitation counselor. Student annotators label posts with their causal inference and causal class. The latter are annotated as follows:\\n\\n1. No reason: When there is no reason that identifies the cause of mental disorder in the post.\\n   \\n2. Bias or abuse: A strong inclination of the mind or a preconceived opinion about something or someone. To avoid someone intentionally, or to prevent someone from taking part in the social activities of a group because they dislike the person or disapprove of their activities. It includes body shaming, physical, sexual, or emotional abuse.\\n   \\n3. Jobs and careers: Financial loss can have catastrophic effects on mental illness, relationships and even physical health. Poor, meaningless and unmanageable education, unemployment, unaffordable home loans, poor financial advice, and losing a job are some of the major concerns. It includes gossiping and/or social cliques, aggressive bullying behavior, poor communication and unclear expectations, dictatorial management techniques that don't embrace employee feedback. The educational problems like picking up courses under some external pressure and poor grades are also part of this category.\\n   \\n4. Medication: The general drugs and other antiviral drugs can increase the risk of depression. The habit of using substances and alcohols can aggravate the problem of mental disorders. Moreover, medical problems like tumors, cancer, and other prolonged diseases can boost the presence of mental depression.\\n   \\n5. Relationships: When two people or a group of people fight, it may lead to a relationship or friendship drifting apart, for example, regular fights, breakups, divorce, mistrust, jealousy, betrayal, difference in opinion, inconsistency, conflicts, bad company, non-commitment, priority, envy. Problems like bad parenting and childhood trauma are also part of this category.\\n   \\n6. Alienation: Alienation is the feeling of life being worthless even after doing everything. There may be indicators of meaninglessness, loneliness, tired of daily routines, powerlessness, normlessness, isolation, and cultural estrangement.\\n\\nThe student annotators were trained by experts (clinical psychologist and rehabilitation counselor) to pick those words and/or phrases through which they have identified the cause of the post, and rank them. The student annotators followed these guidelines thoroughly.\"}"}
{"id": "lrec-2022-1-686", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.5. Annotation Perplexity\\n\\nThe judgement of reasons behind online users' intentions is a complex task for human annotators, generally due to mentions of multiple reasons or the presence of ambiguity in human interpretations. Causal analysis can be viewed as a multivariate problem, resulting in multiple labels. The annotation scheme is not sophisticated enough to capture all the aspects of this phenomenon. We thus propose perplexity guidelines to simplify the task and facilitate future annotations.\\n\\nOur mental health therapists and social NLP practitioners have constructed perplexity guidelines to handle the trade-off between task complexity and simplicity of the annotation scheme. The perplexity guidelines are:\\n\\n1. Multiple reasons in the post: There are some posts with multiple reasons for conveyed feelings. To resolve this, annotators must find a root cause among the direct causes mentioned by the user.\\n\\nExample 1: I was of 11 years since when i realized and facing constant ignorance of my parents. 8 yrs later i lost my first girlfriend and alcoholic since then. My beer belly and obesity has made people biased towards me. I have lost everything and want to end up now.\\n\\nIn Example 1, the root cause of the mental disorder is negligence of parents. Thus, this post is assigned the Relationship category. That is, we handle multiple causes by prioritizing the root cause or the most emphasized reason by the user. This perplexity guideline reduces annotation ambiguity and helps develop better models for automation of this task in the near future.\\n\\n2. Ambiguity in human interpretations: The subjective nature of causal analysis makes this task even more complicated for human annotators. The six different causes are not atomic in nature. The human interpretation of the same post and the same inference may vary, even among experts.\\n\\nExample 2: I wish I could stay alone somewhere and cry my self to sleep. I wish i won't wake up.\\n\\nExample 2 contains some important words like alone and cry which convey the category as Alienation. However, two out of three annotators considered this to be the No reason category. As this is the subjective decision of every human annotator, we leave it at their discretion. However, the final category assigned by the human expert (following human annotation) is based on \\\"majority rules,\\\" in this case, 'no reason.'\\n\\n3. Subject of intent in the post: Many posts refer to the depression of loved ones and other acquaintances. Given that the goal of this task is to identify the cause behind mental depression of online users, experts agree that such posts are candidates for causal analysis.\\n\\nExample 3: I love to do prepare meals for my cousin because I think he is suffering from depression due to his car accident last month.\\n\\nIn Example 3, the user is talking about their cousin who is purportedly suffering from depression. This text is passed through classification to detect depression; however, the third person usage precludes detection of a reason behind this condition. Although the user presents their own perspective on the reason for their cousin's condition (car accident), the input must include self-reported evidence for the reason. Thus, this example is annotated as No reason.\\n\\nThe professional training and guidelines are supported by perplexity guidelines. We have further deployed student annotators to label the dataset after they annotate the first 25 posts under the supervision of experts.\\n\\n4. CAMS Dataset\\n\\nWe introduce a new language resource for CAMS and elucidate the process of data collection (4.1) and data annotations (4.2). We further discuss the challenges and discuss future research directions (4.3). We make our dataset and the source code publicly available for future use.\\n\\n4.1. Overview of Data Collection\\n\\nWe demonstrate the efficacy of our annotated scheme as follows:\\n\\n1. We collect 3362 Reddit posts which are available with subreddit r/depression using Python Reddit API Wrapper (PRAW). Experts remove empty and irrelevant instances from the crawled dataset resulting in 3155 samples.\\n\\n2. We leverage the existing SDCNL dataset comprised of 1,896 posts: 1,517 training samples and 378 testing samples, assumed as the cleaned dataset.\\n\\n3. We combine these two corpora, introducing them as the CAMS dataset, which is further annotated by our trained student annotators.\\n\\n4. We consult mental health practitioners, a clinical psychologist and a rehabilitation counselor, to verify the combined dataset.\\n\\n4.2. Dataset Annotations\\n\\nAfter verification of the dataset by experts, three duly trained student annotators manually annotate the data in the format:\\n\\n<text, cause, inference>\\n\\nas shown in Table 2. In this section, we discuss the annotation process,\"}"}
{"id": "lrec-2022-1-686", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Word length variation in posts across causal classes for each dataset.\\n\\n| Class                | Min | Max | Avg |\\n|----------------------|-----|-----|-----|\\n| No reason            | 1   | 508 | 59.78 |\\n| Bias or Abuse        | 6   | 2109 | 347.48 |\\n| Jobs and career      | 13  | 2258 | 228.28 |\\n| Medication           | 5   | 1552 | 213.83 |\\n| Relationship         | 2   | 3877 | 229.35 |\\n| Alienation           | 3   | 1592 | 153.86 |\\n\\nTable 5: Sample distribution of the CAMS dataset for different causes where CC is Crawled Corpus, Train S is the Training data of SDCNL dataset, Test S is the Test data of SDCNL dataset, and CAMS column contains the total number of samples in the dataset for each cause.\\n\\nIn the crawled corpus, the highest number of samples is observed for the Relationship and Alienation causal categories, which is perhaps an indicator that our society is less equipped to deal with issues pertaining to 'near & dear ones' and 'loneliness / worthlessness', respectively. The number of posts with 'no reason' is smaller in the crawled corpus due to the cleaning of the dataset. Interestingly, there are fewer posts assigned 'Bias or abuse'\u2014less than half of each of the two additional categories: Jobs and careers and Medication.\"}"}
{"id": "lrec-2022-1-686", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of some causes, e.g., Alienation and Relationship, point to the importance of the ability to take a societal pulse on a regular basis, especially in these unprecedented times of pandemic-induced distancing and shut-downs. Other problems, e.g., Jobs and careers and bias and abuse depend upon good governance. The problem of medication depends upon technological/medical advances and accessible healthcare, or lack thereof. Additionally, online users often feel depressed but do not address any specific reason behind it, indicating that inferring relevant causes is a challenge if one uses NLP alone.\\n\\n4.4. Ethical Considerations\\nWe emphasize that the sensitive nature of our work necessitates that we use the publicly available Reddit dataset (Haque et al., 2021) in a purely observational manner (Broer, 2020). We claim that the given dataset does not disclose the user's personal information or identity. We further acknowledge the trade-off between privacy of data and effectiveness of our work (Eskisabel-Azpiazu et al., 2017). We ensure that our CAMS corpus is shared selectively and is subject to IRB approval to avoid any misuse. Our dataset is susceptible to the biases and prejudices of annotators who were trained by experts. There will be no ethical issues or legal impact with this causal analysis of mental illness.\\n\\n5. Corpus Utility for Machine Learning\\nWe include traditional multi-class classifiers trained on CAMS training dataset and evaluate it on the CAMS test data. We choose the following Recurrent Neural Network (RNN) architectures: Long Short Term Memory (LSTM) model, Convolution Neural Network (CNN), Gated Recurrent Unit (GRU), Bidirectional GRU/LSTM (Bi-GRU/Bi-LSTM) and other hybrid models. In this section, we discuss the experimental setup (5.1) and analyze the results (5.2).\\n\\n5.1. Experimental Setup\\nWe use the existing re-annotated SDCNL dataset for experimental results and analysis. We clean the dataset, pre-process the posts and then use GloVe word embedding with 100 dimensions trained on Wikipedia for each token. We further set up RNN architectures with default settings ($lr = 0.001, \\\\beta_1 = 0.9, \\\\beta_2 = 0.999, \\\\epsilon = 1e^{-08}$) for the batch-size of 256. The categorical Cross Entropy loss function and the ADAM optimizer are used to perform the back-propagation learning on 20 epochs.\\n\\nThe number of samples for three classes of the existing SDCNL dataset ('Bias or abuse', 'Jobs and career', and 'Medication') are very few in comparison to the other three classes. We add 120+120+120 samples from the crawled corpus, to help balance the number of instances across the classes. As a result, the number of instances becomes more balanced.\\n\\n5.2. Results and Discussion\\nWe use multi-class classifiers to find causal categories and obtain the results reported in Table 6. We test our performance with both machine learning and deep learning approaches. The two top-performing machine learning algorithms are based on Logistic Regression and Support Vector Machine. Whereas the former outperforms all existing techniques, the latter shows comparative results with deep learning models. The hybrid model, CNN-LSTM, attains the best performance among all deep learning mechanisms with 47.78% accuracy. It is interesting to observe that the results are consistent for all the classifiers with few exceptions for classes Bias or abuse and Medication. We further analyze the best performing deep-learning classifier below.\\n\\n5.2.1. Error Analysis\\nThe accuracy of multi-class classification is found to be around 40% to 50%. We undertake a comprehensive error analysis to explore the intricacies of our task. 1. Cause classification error: We obtain the confusion matrix for CNN+LSTM as shown in Figure 3. We highlight the cells with more than 40% incorrect predictions. The predictions for Alienation and Relationship are incorrect and overlap with Bias or Abuse and Medication. This is due to complex interactions, as illustrated in the following perceivable overlap between Bias or Abuse and Relationship:\\n\\nExample 4: My friends are ignoring me and I am feeling bad about it. I have lost all my friends.\\n\\nExample 4 is associated with biasing and friendship, in a case where someone feels ostracized by their friends. The emphasis on friends tips the balance in favor of the class Relationship. However,\"}"}
{"id": "lrec-2022-1-686", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Experimental results with CAMS dataset. F1 is computed for all six causal classes: 'No reason' (C0), 'Bias or abuse' (C1), 'Jobs and careers' (C2), 'Medication' (C3), 'Relationship' (C4), 'Alienation' (C5).\\n\\n2. Overlapping class: The overlapping problem of classes is observed with ambiguous results for samples, e.g., for Relationship and Alienation. This class representation problem can be resolved with data augmentation (Ansari et al., 2021) and demarcation of boundaries among classes. In a real-time scenario, demarcation of fixed boundaries is not possible due to subjectivity of the task. We recommend the approximation of a newly built model over handcrafted/automated features accordingly. Further, we obtain low performance for class 1 ('Bias or abuse') due to annotators' perceived overlap with classes 4 and 5 ('Relationship' and 'Alienation'). Future work is needed to mitigate such uncertainty. For example, delineation of discourses within the text would support a more definitive interpretation and reliable annotation.\\n\\n5.2.2. Implications and Limitations\\nThe CAMS dataset provides a means for exploring the identification of reasons behind mental health disorders of online users. The notion of causal categorization is defined and used to proactively identify cases where users are at potential risk of mental depression and suicidal tendencies. The results of this work may be employed to explore the impact of unemployment, low grades, etc. Our analysis may also be useful for the study of online behavior. A major limitation of the CAMS dataset is that the users may intentionally post their intent of mental disorder on social media, e.g., for deliberately making new friends. In this work, we have assumed that the data has no such biasing.\\n\\n6. Conclusion\\nThis paper introduces the task of causal analysis to identify the reasons behind mental depression and suicidal tendencies (intent). We have introduced CAMS: a dataset of 5051 instances, to categorize the direct causes of mental disorders through mentions by users in their posts. We transcend the work of Level 0 studies, moving to the next level (Level 1) for causal analysis. Our work is the combined effort of experts in the field of Social Natural Language Processing (Social NLP), including a rehabilitation counselor and clinical psychologists (CPsych). We have further implemented machine learning and deep learning models for causal analysis and found that Logistic Regression and CNN+LSTM gives the best performance, respectively.\\n\\nIn the future, we plan to extend the problem of causal analysis of mental health detection on social media as a multi-task problem. Another major future challenge for this work is the generation of explanations for multi-class classification, by leveraging causal analysis within the CAMS framework.\\n\\n8. References\\nAlada\u02d8g, A. E., Muderrisoglu, S., Akbas, N. B., Zahmacioglu, O., and Bingol, H. O. (2018). Detecting suicidal ideation on forums: proof-of-concept study. Journal of medical Internet research, 20(6):e215.\"}"}
{"id": "lrec-2022-1-686", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ansari, G., Garg, M., and Saxena, C. (2021). Data augmentation for mental health classification on social media. arXiv preprint arXiv:2112.10064.\\n\\nBeach, S. R. and Jones, D. J. (2002). Marital and family therapy for depression in adults.\\n\\nBroer, T. (2020). Technology for our future? exploring the duty to report and processes of subjectification relating to digitalized suicide prevention. Information, 11(3):170.\\n\\nCampos, R., Mangaravite, V., Pasquali, A., Jorge, A., Nunes, C., and Jatowt, A. (2020). Yake! keyword extraction from single documents using multiple local features. Information Sciences, 509:257\u2013289.\\n\\nCao, L., Zhang, H., Feng, L., Wei, Z., Wang, X., Li, N., and He, X. (2019). Latent suicide risk detection on microblog via suicide-oriented word embeddings and layered attention. arXiv preprint arXiv:1910.12038.\\n\\nCao, L., Zhang, H., and Feng, L. (2020). Building and using personal knowledge graph to improve suicidal ideation detection on social media. IEEE Transactions on Multimedia.\\n\\nCheng, L., Guo, R., Shu, K., and Liu, H. (2021). Causal understanding of fake news dissemination on social media.\\n\\nCohan, A., Desmet, B., Yates, A., Soldaini, L., Macavaney, S., and Goharian, N. (2018). Smhd: a large-scale resource for exploring online language usage for multiple mental health conditions. In 27th International Conference on Computational Linguistics, pages 1485\u20131497. ACL.\\n\\nCong, Q., Feng, Z., Li, F., Xiang, Y., Rao, G., and Tao, C. (2018). Xa-bilstm: A deep learning approach for depression detection in imbalanced data. In 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 1624\u20131627. IEEE.\\n\\nConway, M. and O\u2019Connor, D. (2016). Social media, big data, and mental health: current advances and ethical implications. Current opinion in psychology, 9:77\u201382.\\n\\nCoppersmith, G., Dredze, M., Harman, C., Hollingshead, K., and Mitchell, M. (2015). Clpsych 2015 shared task: Depression and ptsd on twitter. In Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 31\u201339.\\n\\nDe Choudhury, M., Gamon, M., Counts, S., and Horvitz, E. (2013). Predicting depression via social media. In Seventh international AAAI conference on weblogs and social media.\\n\\nEdition, F. et al. (2013). Diagnostic and statistical manual of mental disorders. Am Psychiatric Assoc, 21.\\n\\nEskisabel-Azpiazu, A., Cerezo-Menendez, R., and Gayo-Avello, D. (2017). An ethical inquiry into youth suicide prevention using social media mining. Internet Research Ethics for the Social Age, 227.\\n\\nFalotico, R. and Quatto, P. (2015). Fleiss\u2019 kappa statistic without paradoxes. Quality & Quantity, 49(2):463\u2013470.\\n\\nGarg, M. (2021). Quantifying the suicidal tendency on social media: A survey. arXiv preprint arXiv:2110.03663.\\n\\nGaur, M., Alambo, A., Sain, J. P., Kursuncu, U., Thirunarayan, K., Kavuluru, R., Sheth, A., Welton, R., and Pathak, J. (2019). Knowledge-aware assessment of severity of suicide risk for early intervention. In The World Wide Web Conference, pages 514\u2013525.\\n\\nHaque, A., Reddi, V., and Giallanza, T. (2021). Deep learning for suicide and depression identification with unsupervised label correction. arXiv preprint arXiv:2102.09427.\\n\\nJi, S., Yu, C. P., Fung, S.-f., Pan, S., and Long, G. (2018). Supervised learning for suicidal ideation detection in online user content. Complexity, 2018.\\n\\nKlonsky, E. D., Pachkowski, M. C., Shahnaz, A., and May, A. M. (2021). The three-step theory of suicide: Description, evidence, and some useful points of clarification. Preventive medicine, 152:106549.\\n\\nLin, H., Jia, J., Qiu, J., Zhang, Y., Shen, G., Xie, L., Tang, J., Feng, L., and Chua, T.-S. (2017). Detecting stress based on social interactions in social networks. IEEE Transactions on Knowledge and Data Engineering, 29(9):1820\u20131833.\\n\\nLosada, D. E., Crestani, F., and Parapar, J. (2018). Overview of erisk: early risk prediction on the internet. In International conference of the cross-language evaluation forum for european languages, pages 343\u2013361. Springer.\\n\\nMandal, B., Ayyagari, P., and Gallo, W. T. (2011). Job loss and depression: The role of subjective expectations. Social Science & Medicine, 72(4):576\u2013583.\\n\\nMasuda, N., Kurahashi, I., and Onari, H. (2013). Suicide ideation of individuals in online social networks. PloS one, 8(4):e62262.\\n\\nMather, B., Dorr, B. J., Dalton, A., de Beaumont, W., Rambow, O., and Schmer-Galunder, S. M. (2022). From stance to concern: Adaptation of propositional analysis to new tasks and domains. In Findings of the Association for Computational Linguistics: Human Language Technologies, Dublin, Ireland, May.\\n\\nMcGinty, E. E., Presskreischer, R., Han, H., and Barry, C. L. (2020). Psychological distress and loneliness reported by US adults in 2018 and april 2020. Jama, 324(1):93\u201394.\\n\\nMcHugh, M. L. (2012). Interrater reliability: the kappa statistic. Biochemia medica, 22(3):276\u2013282.\\n\\nNam, H., Ha, J.-W., and Kim, J. (2017). Dual attention networks for multimodal reasoning and matching. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 299\u2013307.\\n\\nPierce, M., Hope, H., Ford, T., Hatch, S., Hotopf, M., John, A., Kontopantelis, E., Webb, R., Wessely, S., McManus, S., et al. (2020). Mental health before and during the covid-19 pandemic: a longitudinal.\"}"}
{"id": "lrec-2022-1-686", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"probability sample survey of the UK population.\\nThe Lancet Psychiatry, 7(10):883\u2013892.\\nPirina, I. and Coltekin, C. (2018). Identifying depression on Reddit: The effect of training data. In Proceedings of the 2018 EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task, pages 9\u201312.\\nRadell, M. L., Abo Hamza, E. G., Daghustani, W. H., Perveen, A., and Moustafa, A. A. (2021). The impact of different types of abuse on depression. Depression research and treatment, 2021.\\nSawhney, R., Joshi, H., Flek, L., and Shah, R. (2021). Phase: Learning emotional phase-aware representations for suicide ideation detection on social media. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2415\u20132428.\\nShah, F. M., Haque, F., Nur, R. U., Al Jahan, S., and Mamud, Z. (2020). A hybridized feature extraction approach to suicidal ideation detection from social media post. In 2020 IEEE Region 10 Symposium (TENSYMP), pages 985\u2013988. IEEE.\\nShen, G., Jia, J., Nie, L., Feng, F., Zhang, C., Hu, T., Chua, T.-S., and Zhu, W. (2017). Depression detection via harvesting social media: A multimodal dictionary learning solution. In IJCAI, pages 3838\u20133844.\\nShing, H.-C., Resnik, P., and Oard, D. W. (2020). A prioritization model for suicidality risk assessment. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8124\u20138137.\\nSmith, H. R. (2015). Depression in cancer patients: Pathogenesis, implications and treatment. Oncology letters, 9(4):1509\u20131514.\\nSon, Y., Bayas, N., and Schwartz, H. A. (2018). Causal explanation analysis on social media. arXiv preprint arXiv:1809.01202.\\nTran, B. X., Ho, R., Ho, C. S., Latkin, C. A., Phan, H. T., Ha, G. H., Vu, G. T., Ying, J., and Zhang, M. W. (2019). Depression among patients with HIV/AIDS: Research development and effective interventions (gapresearch). International journal of environmental research and public health, 16(10):1772.\\nTurcan, E. and McKeown, K. (2019). Dreaddit: A Reddit dataset for stress analysis in social media. arXiv preprint arXiv:1911.00133.\\nYates, A., Cohan, A., and Goharian, N. (2017). Depression and self-harm risk assessment in online forums. arXiv preprint arXiv:1709.01848.\"}"}
