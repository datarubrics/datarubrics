{"id": "emnlp-2022-main-638", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Unsupervised Entity Linking with Guided Summarization\\nand Multiple-Choice Selection\\nYoung-Min Cho Li Zhang Chris Callison-Burch\\nUniversity of Pennsylvania {jch0, zharry, ccb}@seas.upenn.edu\\n\\nAbstract\\nEntity linking, the task of linking potentially ambiguous mentions in texts to corresponding knowledge-base entities, is an important component for language understanding. We address two challenges in entity linking: how to leverage wider contexts surrounding a mention, and how to deal with limited training data. We propose a fully unsupervised model called SumMC that first generates a guided summary of the contexts conditioning on the mention, and then casts the task to a multiple-choice problem where the model chooses an entity from a list of candidates. In addition to evaluating our model on existing datasets that focus on named entities, we create a new dataset that links noun phrases from WikiHow to Wikidata. We show that our SumMC model achieves state-of-the-art unsupervised performance on our new dataset and on existing datasets.\\n\\n1 Introduction\\nEntity linking (EL) is an important Natural Language Processing (NLP) task that associates ambiguous mentions to corresponding entities in a knowledge base (KB, also called knowledge graph). EL is a crucial component of many NLP applications, such as question answering (Yih et al., 2015) and information extraction (Hoffart et al., 2011). Although there have been significant and continuous developments of EL, most work requires sufficient labeled data and a well-developed KB (Zhang et al., 2021; Mulang\u2019 et al., 2020; van Hulst et al., 2020; Raiman and Raiman, 2018). However, many real-world applications, especially those in specific domains, suffer from scarcity of both training data and a fully-populated KB. Previous research has tackled this problem by learning EL models without data labeled entity links, but requires indirect supervision in the form of textual descriptions attached to entities in KBs, drawn from sources such as Wikipedia (Cao et al., 2017; Logeswaran et al., 2019). However, such descriptions may not be available in KBs in low-resource domains such as medicine or law. Thus, we focus on fully unsupervised EL, which only has access to the entities\u2019 names and their KB relations like subclass-of (Le and Titov, 2019; Arora et al., 2021).\\n\\nOne challenge of unsupervised EL is leveraging useful information from potentially noisy and misleading context (Pan et al., 2015). Specifically, a local context (the sentence containing the mention) may not be sufficient for disambiguating the target mention without the global context (other sentences in the document). For example, in Figure 1, the target mention \u2018band\u2019 cannot be disambiguated solely with the local context \u201cThis band is so lovely\u201d, but needs to consider the global context that also includes \u201cI can\u2019t wait for my wedding.\u201d\\n\\nTo address this problem, we introduce an unsupervised approach to EL that builds on the strengths of large neural language models like GPT-3 (Brown et al., 2020). We use zero-shot GPT-3 prompting for two sub-tasks. First, we perform guided summary, which summarizes the input document conditioned on the target mention and outputs a condensed global context. Then, we cast EL to a multiple-choice selection problem where the model chooses an entity from a list of candidates. We refer to our unsupervised EL model as SumMC (Summarization+Multiple-Choice).\\n\\nWith a few exceptions (Ratinov et al., 2011; Cheng and Roth, 2013), the majority of EL work targets named entities, such as names of people...\"}"}
{"id": "emnlp-2022-main-638", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Pipeline of SumMC. Texts highlighted with green are machine generated.\\n\\nand organizations (Mulang\u2019 et al., 2020; van Hulst et al., 2020), neglecting entities such as physical objects or concepts. To comprehensively evaluate our model, we create the first EL dataset on procedural texts, WikiHow-Wikidata, which links noun phrases from WikiHow to Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014).\\n\\nOur SumMC model outperforms current state-of-the-art (SoTA) unsupervised EL models on our new WikiHow-Wikidata data, as well as existing benchmarks including AIDA-CoNLL (Hoffart et al., 2011), WNED-Wiki and WNED-Clueweb dataset (Guo and Barbosa, 2018). In addition, we also provide ablation studies to show the positive influence of generating guided summaries.\\n\\nMethodology\\n\\nFully unsupervised EL is the task that links a target mention from a given document to some entities in a KB without requiring any text data to be labeled with explicit links to the KB. The only available information in the KB is the names of the entities and the relations among them. In this paper, we follow previous work (Le and Titov, 2019; Arora et al., 2021) and use Wikidata as our target KB, which defines instance-of and subclass-of relations between entities. Wikidata can be seen as a knowledge graph with entities as nodes and relations as edges, and the popularity of an entity can be represented by its degree.\\n\\nWe now introduce SumMC, our proposed unsupervised EL model which consists of two instances of a generative language model. The first performs guided summarization by generating a summary of the document conditioned on a mention. The second casts EL to a multiple-choice selection problem and chooses an appropriate entity from a list of candidates generated by some heuristics. In our work, we use GPT-3 as the language model due to its superior performance on various NLP tasks (Brown et al., 2020).\\n\\nCandidate Generation.\\n\\nFollowing previous work (Le and Titov, 2019; Arora et al., 2021), we first select all entities from Wikidata whose name or alias contains all tokens in a mention. Then, we narrow it down to the top 20 entities with the highest degree (in-degree + out-degree) in the KB. For each entity in the final list, we produce a textual representation by concatenating the names of all related entities. For example, the representation of the candidate ribbon in Figure 1 is ribbon: costume component, textile.\\n\\nSumMC.\\n\\nThe first application of GPT-3 performs a guided summarization of the input document. With zero-shot prompting, GPT-3 summarizes the texts using the prompt \u201c[D] Summarize the text above in one sentence: [M]\u201d, where [D] is the input document and [M] is the target mention. Here, we force GPT-3\u2019s summarization to start with the mention to ensure that the conditioned summary contains both the target mention and related global context. At this point, the generated summary serves as a global context while the sentence containing the mention serves as a local context, both of which help disambiguate the target mention.\\n\\nThe second application of GPT-3 casts the task to multiple-choice selection following many successful cases (Ouyang et al., 2022). With the two contexts, GPT-3 transforms EL to a multiple-choice question using the prompt \u201cAccording to the context above, which of the following best describes [M]?\u201d, followed by the representations of the mention [M]\u2019s candidates as choices.\"}"}
{"id": "emnlp-2022-main-638", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Most work on EL has targeted named entities, especially in the news. To account for more diverse entities in different styles of texts, we create a human-annotated dataset called WikiHow-Wikidata that links noun phrases in procedural texts to Wikidata. The research revolving around entities in procedural texts have long received much attention in the community (Dalvi et al., 2018; Zhang et al., 2020; Tandon et al., 2020; Zhang, 2022), without existing large-scale datasets of entity links in such a style of texts.\\n\\nTo create the dataset, we first extract 40,000 articles from the WikiHow corpus (Zhang et al., 2020) detailing everyday procedures. To select mentions to link, we choose the top 3 most-frequently-occurring nouns from each article using a part-of-speech tagger, assuming that most mentions in a document share the same word sense (Gale et al., 1992). Then, we ask students from a university in the U.S. to manually link these mentions to some Wikidata entity. Finally, to measure and control annotation quality, we manually annotate a subset of examples beforehand as control questions. Details about our data collection process, interface, and measures for quality control can be found in Appendix B. Eventually, WikiHow-Wikidata consists of 11,287 triples of a WikiHow article, a target mention, and a Wikidata entity.\\n\\nWe evaluate our SumMC model along with other strong baselines on some widely used EL datasets and our WikiHow-Wikidata dataset.\\n\\n### 4 Experiments\\n\\n#### 4.1 Models\\n\\n\\\\[ \\\\tau \\\\text{MIL-ND} \\\\]: Le and Titov (2019) introduced the first EL model that did not require an annotated dataset. Their model casts the EL task to a binary multi-instance learning (Dietterich et al., 1997) problem along with a noise-detecting classifier.\\n\\n\\\\[ \\\\text{Eigentheme} \\\\]: Arora et al. (2021) created Eigentheme, the current state-of-the-art among fully unsupervised EL models. By representing each entity with its graph embedding, the model identifies a low-rank subspace using SVD on the embedding matrix and ranks candidates by the distance to this hyperplane.\\n\\nTo analyze the effect of using global context in our SumMC model, we report the evaluation results using three variations.\\n\\n| Dataset | Mentions | #Documents | #Easy | #Hard | #Not-found |\\n|---------|----------|------------|-------|-------|------------|\\n| WikiWiki | 2,727 (24%) | 8,560 (76%) | 0     | 7,097 |\\n| AIDA-B   | 2,555 (57%) | 1,136 (25%) | 787 (18%) | 230 |\\n| WNED-Wiki | 2,731 (41%) | 1,475 (22%) | 2,488 (37%) | 318 |\\n| WNED-Cweb | 4,667 (42%) | 3,056 (28%) | 3,317 (30%) | 320 |\\n\\n### Table 1: Statistics of datasets showing distributions of mention difficulty.\\n\\nSumMC: Our proposed model integrates GPT-3 guided summarization and multiple-choice selection models. We use the Curie model for summarization conditioned on the target mention and the Davinci model for multiple-choice. As discussed before, both global and local contexts are provided.\\n\\n- **Guide**: This is an ablated version of SumMC that generates summaries without being conditioned on the target mention. While both global and local contexts are provided, the global context is not guaranteed to be related to the target mention.\\n\\n- **Sum**: This is another ablated version that does not generate summaries of a whole document but directly performs multiple-choice selection, given only with the local context of the mention.\\n\\n#### 4.2 Dataset\\n\\nWe choose AIDA-CoNLL-testb (AIDA-B), WNED-Wiki, and WNED-Clueweb (WNED-Cweb) to measure models' performance on disambiguating named entities and use our WikiHow-Wikidata (WikiWiki) dataset for evaluating on noun phrases.\\n\\nFollowing previous settings (Tsai and Roth, 2016; Guo and Barbosa, 2018; Arora et al., 2021), we report micro precision@1 (P@1) and categorize each mention into 'easy' and 'hard' by whether the candidate entity with the highest degree in the knowledge graph is the correct answer. Performance on 'hard' mention is important since it shows the model's ability on highly ambiguous mentions. 'Not-found' is for mentions whose candidate list does not contain the correct answer. 'Overall' performance is reported considering all mentions, including 'Not-found' by treating it as a false prediction. The distribution of each dataset is shown in Table 1.\\n\\n#### 5 Results and Discussion\\n\\nWe show our results in Table 2. Our SumMC model achieves significantly better results than other unsupervised EL models in all evaluation datasets. Specifically, SumMC has a strong performance on...\"}"}
{"id": "emnlp-2022-main-638", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Performance comparison across SoTA models. Result is reported with Precision@1. We get results of \u03c4MIL-ND and Eigentheme on public datasets from Arora et al. (2021). \u2018Overall\u2019 shows result considering \u2018Not-found\u2019 mentions.\\n\\n| Model                  | Overall Easy | Hard       | Overall Easy | Hard       |\\n|------------------------|--------------|------------|--------------|------------|\\n| SumMC (ours)           | 0.76         | 0.62       | 0.80         | 0.64       |\\n\\nTable 3: Ablation study showing the effects on our SumMC model by removing the mention condition on summary or the global context.\\n\\n\u2018hard\u2019 mentions. In comparison, Eigentheme, the current SoTA model, has slightly higher scores on \u2018easy\u2019 mentions on most datasets but performs worse on \u2018hard\u2019 mentions.\\n\\nComparison with Previous Models. Overall, SumMC achieves 63% precision, while Eigentheme scores 47%. Although SumMC has 1% less precision on \u2018easy\u2019 cases (75% vs. 76%), it outperforms Eigentheme on \u2018hard\u2019 cases by 26% (73% vs. 47%). Eigentheme assumes that gold entities in a document are topically related (Arora et al., 2021). It captures global context only using the relations between mentions while neglecting the texts in the document. However, this assumption might not always hold. Our model, in contrast, removes this assumption by producing a guided summary of texts in the document.\\n\\nEffect of Global Context. We show the results of our ablation study in Table 3. On all datasets, SumMC outperforms the variation without having the summary guided by the mention (\u2013Guide), which outperforms the variation without summarization (\u2013Sum). This result shows the efficacy of not only using summaries as global contexts, but also forcing the summaries to contain information about the mention. Indeed, in many cases, we find that the mention might not be central to the document so that a standard summary might contain noise or insufficient signal for disambiguating the mention.\\n\\nInterestingly, we observe that the performance gap between variations on WikiHow-Wikidata is relatively small. We speculate that WikiHow\u2019s instructional sentences are usually self-explanatory, so the local context often provides enough information to disambiguate the mention.\\n\\nEffect of Multiple-Choice Selection. Using similarity measures to link a mention to an entity is one of the most successful EL methods (Pan et al., 2015). We also examine this approach using Sentence-BERT (Reimers and Gurevych, 2019) and cosine similarity instead of the multiple-choice selection model. As a result, it has only 42% P@1 on AIDA-B dataset. The text-based embedding approach might not be practical in our setting because entity candidates can only be represented by minimal texts, making text embedding unstable.\\n\\nError Analysis. In some cases, common sense is required to disambiguate mentions. For example, \u201cJapan\u201d in an article about a soccer tournament should be linked to the entity \u201cJapan national football team\u201d instead of the country \u201cJapan.\u201d The correct answer can be inferred from the term \u201cAsian Cup\u201d in the text. However, our model fails such a case when the word \u2018soccer\u2019 is not included in the context.\\n\\nCurrently, each of our multiple choices is a concatenation of the target entity and its related entities based on two KB relations: instance-of and subclass-of. However, these might be insufficient. For example, most person entities have \u2018human\u2019 as the only related entity, which is uninformative. Conversely, considering other relations might also introduce unnecessary noise.\\n\\n6 Conclusion\\n\\nWe introduce SumMC, a fully unsupervised Entity Linking model that first produces a summary of the document guided by the mention, and then casts the task to a multiple-choice format. Our model achieves new state-of-the-art performance on various datasets.\"}"}
{"id": "emnlp-2022-main-638", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ious benchmarks, including our new WikiHow-Wikidata, the first EL dataset on procedural texts. Notably, our approach of guided summarization may be applied to other tasks that benefit from global contexts. Future work might also extend our methods to supervised settings.\\n\\nLimitations\\nBecause we focus on fully unsupervised models, we do not consider fine-tuning GPT-3 nor provide a direct comparison with other supervised approaches.\\n\\nA potential criticism of this work is our use of GPT-3. Although GPT-3 is publicly available to everyone, it is not an open-source model and can be expensive to use at scale.\\n\\nFor direct comparison, we use the candidate generation method from (Le and Titov, 2019) and Arora et al. (2021), which has a low recall on datasets. Although there are better methods (Sil et al., 2012; Charton et al., 2014), we do not consider them in this work.\\n\\nAcknowledgements\\nThis research is based upon work supported in part by the DARPA KAIROS Program (contract FA8750-19-2-1004), the DARPA LwLL Program (contract FA8750-19-2-0201), the IARPA BETTER Program (contract 2019-19051600004), and the NSF (Award 1928631). Approved for Public Release, Distribution Unlimited. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, IARPA, NSF, or the U.S. Government. We thank the students from the CIS-421/521 course in 2021 at the University of Pennsylvania for annotating WikiHow-Wikidata dataset.\\n\\nReferences\\nAkhil Arora, Alberto Garcia-Duran, and Robert West. 2021. Low-rank subspaces for unsupervised entity linking. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8037\u20138054, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901.\\n\\nYixin Cao, Lifu Huang, Heng Ji, Xu Chen, and Juanzi Li. 2017. Bridge text and knowledge by learning multi-prototype entity mention embedding. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1623\u20131633, Vancouver, Canada. Association for Computational Linguistics.\\n\\nEric Charton, Marie-Jean Meurs, Ludovic Jean-Louis, and Michel Gagnon. 2014. Improving entity linking using surface form refinement. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), pages 4609\u20134615, Reykjavik, Iceland. European Language Resources Association (ELRA).\\n\\nXiao Cheng and Dan Roth. 2013. Relational inference for wikification. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1787\u20131796, Seattle, Washington, USA. Association for Computational Linguistics.\\n\\nBhavana Dalvi, Lifu Huang, Niket Tandon, Wen-tau Yih, and Peter Clark. 2018. Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1595\u20131604, New Orleans, Louisiana. Association for Computational Linguistics.\\n\\nThomas G Dietterich, Richard H Lathrop, and Tom\u00e1s Lozano-P\u00e9rez. 1997. Solving the multiple instance problem with axis-parallel rectangles. Artificial intelligence, 89(1-2):31\u201371.\\n\\nWilliam A. Gale, Kenneth W. Church, and David Yarowsky. 1992. One sense per discourse. In Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992.\\n\\nZhaochen Guo and Denilson Barbosa. 2018. Robust named entity disambiguation with random walks. Semantic Web, 9(4):459\u2013479.\\n\\nJohannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F\u00fcrstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 782\u2013792, Edinburgh, Scotland, UK. Association for Computational Linguistics.\\n\\nFilip Ilievski, Daniel Garijo, Hans Chalupsky, Naren Teja Divvala, Yixiang Yao, Craig Rogers, Ronpeng Li, Jun Liu, Amandeep Singh, Daniel Schwabe, and Pedro Szekely. 2020. KGTK: A toolkit for large knowledge graph manipulation and analysis. In International Semantic Web Conference, pages 278\u2013293. Springer.\"}"}
{"id": "emnlp-2022-main-638", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Phong Le and Ivan Titov. 2019. Distant learning for entity linking with automatic noise detection. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4081\u20134090, Florence, Italy. Association for Computational Linguistics.\\n\\nLajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, and Honglak Lee. 2019. Zero-shot entity linking by reading entity descriptions. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3449\u20133460, Florence, Italy. Association for Computational Linguistics.\\n\\nIsaiah Onando Mulang\u2019, Kuldeep Singh, Chaitali Prabhu, Abhishek Nadgeri, Johannes Hoffart, and Jens Lehmann. 2020. Evaluating the impact of knowledge graph context on entity disambiguation models. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management, pages 2157\u20132160.\\n\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback.\\n\\nXiaoman Pan, Taylor Cassidy, Ulf Hermjakob, Heng Ji, and Kevin Knight. 2015. Unsupervised entity linking with Abstract Meaning Representation. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1130\u20131139, Denver, Colorado. Association for Computational Linguistics.\\n\\nBryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 701\u2013710.\\n\\nJonathan Raiman and Olivier Raiman. 2018. Deeptype: multilingual entity linking by neural type system evolution. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.\\n\\nLev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to Wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1375\u20131384, Portland, Oregon, USA. Association for Computational Linguistics.\\n\\nNils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.\\n\\nAvirup Sil, Ernest Cronin, Penghai Nie, Yinfei Yang, Ana-Maria Popescu, and Alexander Yates. 2012. Linking named entities to any database. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 116\u2013127, Jeju Island, Korea. Association for Computational Linguistics.\\n\\nNiket Tandon, Keisuke Sakaguchi, Bhavana Dalvi, Dheeraj Rajagopal, Peter Clark, Michal Guerquin, Kyle Richardson, and Eduard Hovy. 2020. A dataset for tracking entities in open domain procedural text. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6408\u20136417, Online. Association for Computational Linguistics.\\n\\nChen-Tse Tsai and Dan Roth. 2016. Cross-lingual wikification using multilingual embeddings. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 589\u2013598, San Diego, California. Association for Computational Linguistics.\\n\\nJohannes M van Hulst, Faegheh Hasibi, Koen Dercksen, Krisztian Balog, and Arjen P de Vries. 2020. Rel: An entity linker standing on the shoulders of giants. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2197\u20132200.\\n\\nDenny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. 2014. Wikidata: a free collaborative knowledgebase. Communications of the ACM, 57(10):78\u201385.\\n\\nWen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jianfeng Gao. 2015. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1321\u20131331, Beijing, China. Association for Computational Linguistics.\\n\\nLi Zhang. 2022. Reasoning about procedures with natural language processing: A tutorial.\\n\\nLi Zhang, Qing Lyu, and Chris Callison-Burch. 2020. Reasoning about goals, steps, and temporal ordering with WikiHow. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4630\u20134639, Online. Association for Computational Linguistics.\\n\\nWenzheng Zhang, Wenyue Hua, and Karl Stratos. 2021. Entqa: Entity linking as question answering. arXiv preprint arXiv:2110.02369.\"}"}
{"id": "emnlp-2022-main-638", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday. But China saw their luck desert them in the second match of the group, crashing to a surprise 2-0 defeat to newcomers Uzbekistan. China controlled most of the match and saw several chances missed until the 78th minute when Uzbek striker Igor Shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing Chinese keeper and into an empty net. Oleg Shatskiku made sure of the win in injury time, hitting an unstoppable left foot shot from just outside the area. The former Soviet republic was playing in an Asian Cup finals tie for the first time. Despite winning the Asian Games title two years ago, Uzbekistan are in the finals as outsiders. Two goals from defensive errors in the last six minutes allowed Japan to come from behind and collect all three points from their opening meeting against Syria. Takuya Takagi scored the winner in the 88th minute, rising to head a Hiroshige Yanagimoto cross towards the Syrian goal which goalkeeper Salem Bitar appeared to have covered but then allowed to slip into the net. It was the second costly blunder by Syria in four minutes. Defender Hassan Abbas rose to intercept a long ball into the area in the 84th minute but only managed to divert it into the top corner of Bitar's goal. Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute. Japan then laid siege to the Syrian penalty area for most of the game but rarely breached the Syrian defence. Bitar pulled off fine saves whenever they did. Japan coach Shu Kamo said: \u201cThe Syrian own goal proved lucky for us. The Syrians scored early and then played defensively and adopted long balls which made it hard for us.\u201d Japan, co-hosts of the World Cup in 2002 and ranked 20th in the world by FIFA, are favourites to regain their title here. Hosts UAE play Kuwait and South Korea take on Indonesia on Saturday in Group A matches. All four teams are level with one point each from one game.\"}"}
{"id": "emnlp-2022-main-638", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C Effect of GPT-3 Engine Size\\n\\nWe also compare the impact of GPT-3 engine size to SumMC model. Guided summarization is very powerful regardless of the engine. Only changing engine size, our model with Ada achieves 0.631 P@1, and Babbage scores 0.633 P@1 on AIDA-B, which tie with 0.636 P@1 by Curie. This gives an alternative option to users with a limited budget but who still want a moderate performance. Compared to Curie, the pricing of Ada is 87% cheaper, but it is still equivalent to the result that Curie achieved.\\n\\nOn the other hand, multiple-choice selection requires a large model. Compared with the 0.633 P@1 on AIDA-B with Davinci engine, Curie and Babbage only score 0.204 and 0.196 P@1, respectively, while the Ada engine fails to complete the evaluation.\\n\\nUsing our model's setting, it costs around $0.002 for guided summarization and $0.01 for multiple-choice selection.\\n\\nD Model Setting Details\\n\\nSince most of our code is API call of GPT-3, SumMC does not require a strong requirement on computational resources.\\n\\nIn our model, we used default hyperparameter setting for both guided summarization and multiple-choice selection. In detail, we set temperature=0.7, max_tokens=256, top_p=1. frequency_penalty=0, and presence_penalty=0.\\n\\nDue to the input token limit of GPT-3 engines, we truncated the input document to 512 words surrounding the target mention during guided summarization.\\n\\nWe used the '2021-09-13' dump of Wikidata in our model, and used Knowledge Graph Toolkit (Ilievski et al., 2020) to extract entities and their relations.\"}"}
