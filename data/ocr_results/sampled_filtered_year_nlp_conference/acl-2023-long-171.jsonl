{"id": "acl-2023-long-171", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nCollaborative stories, which are texts created through the collaborative efforts of multiple authors with different writing styles and intentions, pose unique challenges for NLP models. Understanding and generating such stories remains an underexplored area due to the lack of open-domain corpora. To address this, we introduce STORY WARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform. We design 12 task types, comprising 7 understanding and 5 generation task types, on STORY WARS, deriving 101 diverse story-related tasks in total as a multi-task benchmark covering all fully-supervised, few-shot, and zero-shot scenarios. Furthermore, we present our instruction-tuned model, INSTRUCTORY, for the story tasks showing that instruction tuning, in addition to achieving superior results in zero-shot and few-shot scenarios, can also obtain the best performance on the fully-supervised tasks in STORY WARS, establishing strong multi-task benchmark performances on STORY WARS.\\n\\n1 Introduction\\n\\nStorytelling is crucial due to its vital role in human experience, history, and culture dating back to the earliest days of humanity. Humans possess the unique storytelling ability to structure a sequence of events, whether factual, fictional or a mixture of both, and create a coherent narrative that conveys a big picture while also including intricate details. Current story generation systems usually mimic this ability by starting with a plot then crafting the story. This can be done by linearly expanding (Peng et al., 2018, Yao et al., 2019, Martin et al., 2017) or hierarchically developing (Xu et al., 2018, Fan et al., 2018, Fan et al., 2019, Rashkin et al. 2020, Goldfarb-Tarrant et al., 2020) the story based on the given plot. Collaborative storytelling is distinctly challenging because there is no predetermined plot or story outline of events. Instead, collaborative stories are created through the collective efforts of multiple authors. Each author contributes a section sequentially, while also attempting to express their own personal intentions within the context of the jointly crafted and jointly owned story. It is a more challenging problem as it requires not only the ability to generate text, but also the capability to understand the previous context and contributions written by other authors.\\n\\nTitle: Diaries of a Reaper\\n\\nlikes: 505, stars: 319, genres: [horror]\\n\\nChapter 2, Author: Ailyn Koay\\n\\nChapter 7, Author: Artemis\\n\\nChapter 1, Author: Jarno\\n\\n... (4 chapters omitted)\\n\\n... (5 chapters omitted; 12 Chapters in total)\\n\\n... (somewhere in Chapter 3)\\n\\n... (somewhere in Chapter 6)\\n\\n... (somewhere in Chapter 8)\\n\\nFigure 1: An example story with 12 turns in the STORY WARS dataset. In each turn, the author leaves a \\\"floor\\\" for the next author to continue collaboratively.\"}"}
{"id": "acl-2023-long-171", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Large Language Models (LLMs) (Devlin et al. 2019, Liu et al., 2019, Yang et al. 2019, Raffel et al. 2019, Brown et al. 2020, Zhang et al. 2022, Chowdhery et al. 2022, Touvron et al. 2023) have demonstrated exceptional performance on various understanding and generation benchmarks, indicating their potential in addressing natural language processing (NLP) challenges related to collaborative storytelling. This prompts an intriguing question within the research community: How could LLMs synergize both their understanding and generation capabilities via multitask learning to address the challenges of collaborative storytelling?\\n\\nWe present STORYWARS, a dataset of over 40,000 stories gathered from an online collaborative storytelling platform. Figure 1 shows an example story in the STORYWARS dataset. Each story contains rich information including its title, genres given by the initial author, chapters written by different authors, and human ratings including stars and likes. Each chapter was written by exactly one author and the previous author might leave a collaborative floor (Coates, 1997) for the next author to continue. Therefore, for a model to generate a continuing chapter, it needs to understand the preceding context, including the title, genres, and the writing styles and intentions of previous authors conveyed in the collaborative floor.\\n\\nDue to the multitask nature of collaborative storytelling and the rich information of the STORYWARS dataset, we design 12 task types, including both understanding and generation task types, as a multitask benchmark for an initial probe of collaborative storytelling. We follow the task definition from FLAN (Wei et al., 2021), where each task type contains multiple tasks. In the end, our benchmark contains 101 tasks in total, split such that it covers all fully-supervised, few-shot, and zero-shot learning application scenarios. It is important to note that prevailing multitask NLP benchmarks are either focusing on understanding (e.g. Wang et al., 2018, Wang et al., 2019) or generation (e.g. Gehrmann et al., 2021, Khashabi et al., 2021, Liu et al., 2021) alone, or only a subset of the learning scenarios. To our knowledge, we are the first to propose a story benchmark that contains both understanding and generation in all three scenarios.\\n\\nLarge language models have been shown to not only be fully-supervised, few-shot, and zero-shot learners but also multitask ones. Instruction Tuning (Wei et al., 2021, Sanh et al., 2022, Chung et al., 2022) has been the state-of-the-art approach for zero-shot and few-shot scenarios. However, it has not yet been applied in the fully-supervised setting. We evaluated Instruction Tuning on the benchmark and we found that in addition to achieving state-of-the-art results in zero-shot and few-shot scenarios, when combined with single-task fine-tuning, Instruction Tuning can surpass single-task fine-tuning alone, resulting in a consistent performance boost of 1.53 points on average for all tasks.\\n\\nOur contributions are as follows:\\n\\n\u2022 We introduce a novel collaborative story dataset STORYWARS that comprises 40k stories written by 9.4k different authors, with rich information such as genres and human ratings, to promote research in the field of collaborative storytelling.\\n\\n\u2022 We propose a new benchmark based on STORYWARS that consists of 7 understanding and 5 generation task types, totaling in 101 tasks for testing the fundamental abilities of LLMs to model collaborative stories. The benchmark covers the fully-supervised, few-shot, and zero-shot scenarios.\\n\\n\u2022 We present INSTRUCTORY, a instruction-tuned model that demonstrates strong performance on the STORYWARS benchmark in all three learning scenarios. In addition, we show for the first time that we could extend Instruction Tuning with a single-task finetuning stage to achieve superior performance and obtain robust performance boost.\\n\\n2 Related Work\\n\\n2.1 Story Datasets\\n\\nThe most popular story datasets that have been widely used by many story generation systems in the past are ROCStories (Mostafazadeh et al., 2016) and WritingPrompts (Fan et al., 2018). ROCStories comprises five-sentence commonsense short stories, and WritingPrompts includes 300k open-domain prompt-story pairs, neither of which are collaboratively written. On the other hand, Storium (Akoury et al., 2020) and roleplayerguild (Louis and Sutton, 2018), are collaborative and written by multiple authors in turns, but in a game setting. The key distinction of our STORYWARS dataset is that the stories are both collaborative and open-domain. For a comparison of these datasets, refer to Table 1.\"}"}
{"id": "acl-2023-long-171", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Comparison of our STORYWARS dataset with previous story datasets.\\n\\n2.2 Multitask NLP Benchmarks\\n\\nExisting multitask NLP benchmarks tend to focus on evaluating either understanding (Wang et al., 2018, Wang et al., 2019) or generation (Gehrmann et al., 2021, Khashabi et al., 2021, Liu et al., 2021) capabilities of NLP models. There are task-specific benchmarks that address both, such as those for dialog (Mehri et al., 2020) and code (Lu et al., 2021). For the task of storytelling, the LOT benchmark (Guan et al., 2022) focuses on both aspects but is limited to Chinese and has fewer tasks than our proposed STORYWARS dataset. BIG-bench (Srivastava et al., 2022), which includes 204 tasks for understanding and generation, only tests zero-shot and few-shot abilities without fine-tuning. STORYWARS provides a benchmark for story understanding and generation with 101 tasks spanning all zero-shot, few-shot, and full-supervised scenarios for various applications.\\n\\n2.3 Multitask NLP and Instruction Tuning\\n\\nCurrent multitask LLMs mainly follow two approaches. The first approach involves fine-tuning, such as with ExT5 (Aribandi et al., 2022) and Muppet (Aghajanyan et al., 2021), where the model is made more generalized through multitask fine-tuning and then fine-tuned again on downstream tasks. The second approach focuses solely on zero-shot and few-shot performance, with the goal of bridging the gap between finetuning and these performance levels, as seen in FLAN (Wei et al., 2021), T0 (Sanh et al., 2022), FLAN-T5 (Chung et al., 2022), and ZeroPrompt (Xu et al., 2022). These models often utilize Instruction Tuning or similar frameworks. In this paper, we extend Instruction Tuning's capabilities to achieve superior performance in the full-supervised scenario as well.\\n\\n3 Methodology\\n\\n3.1 The STORYWARS Dataset\\n\\nWe obtained the STORYWARS dataset from storywars.net, an online collaborative storytelling platform where users can pitch ideas and create stories. However, once an initial chapter is published, the story becomes part of the Story Wars community and can be contributed to by other users. For a continuing chapter to be officially recognized, it must be voted in by other users, resulting in a high quality of stories on the platform.\\n\\nWe scraped and parsed the stories on Story Wars, ending up in obtaining 76k stories. We then used FastText (Bojanowski et al., 2017) language identification to filter for English stories and further cleaned the dataset by removing noisy stories based on GPT-2 perplexity (Radford et al., 2019). We also removed stories that are shorter than 30 words or stories with chapters that are shorter than 10 words. To further ensure the quality of the dataset, we also remove stories that have very low human ratings, such as likes and stars.\\n\\nIn consideration of ethical issues, we employed OpenAI Content Moderation APIs\\\\(^3\\\\) and the Detoxify\\\\(^4\\\\) toxicity classifier to identify and remove potentially harmful content, such as toxicity, obscenity/sexual content, threats, insults, identity hate, and self-harm posts from the dataset. Furthermore, to safeguard user privacy, we replaced all URLs, email addresses, and phone numbers with special tokens <URL>, <EMAIL>, and <PHONE>.\\n\\nAfter thorough data cleaning, we obtained a final dataset of 40,135 stories written by 9,494 authors. Due to the fact that the long tail of genres is very noisy, we made the simplifying assumption that each story contains a single dominant genre, if any. Each story in the dataset was structured with several...\\n\\n---\\n\\n\\\\(^3\\\\) https://beta.openai.com/docs/api-reference/moderations\\n\\n\\\\(^4\\\\) https://github.com/unitaryai/detoxify\"}"}
{"id": "acl-2023-long-171", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"general key elements, including a title, a genre (which could be empty), the numbers of likes and stars received, the authors and the corresponding chapters.\\n\\nWe denote an arbitrary story in the dataset as $s \\\\in S$, where $S = \\\\{(p, (c_i, a_i))_{t=0}^t, g, r_l, r_s)\\\\}$. That is, each story $s_i$ is denoted by a 5-tuple of a title $p$, chapter-author pairs $(c_i, a_i)$ of turns, a genre $g$, a likes rating $r_l$, and a stars rating $r_s$.\\n\\n3.2 The Multitask Benchmark\\n\\n3.2.1 Story Understanding Tasks\\n\\nGenre Classification\\nUnderstanding the genre of a story is essential for collaborative storytelling models to comprehend the context. The genre classification task involves identifying the genre of a story. This task can be formulated as a binary text classification problem, where given a story, the task is to predict whether it belongs to a specific genre $g$. This can be represented as $g = f(c_1, c_2, \\\\ldots, c_t)$.\\n\\nAuthorship Attribution\\nIdentifying the author of a text is a crucial step in understanding the writing style of an individual. Authorship attribution, traditionally, is the task of determining the author of a given text. In this paper, we formulate the task of authorship attribution as identifying the author of a specific chapter, represented as $a = f(c)$.\\n\\nAuthorship Verification\\nAuthorship Verification, in contrast to author attribution, is the task of determining whether two texts have been written by the same author by comparing their writing styles. The task is represented as $y = f(c_i, c_j)$, where $y$ is a binary variable.\\n\\nConnectivity Inference\\nUnderstanding the chapter shifts in long-range stories can be a beneficial ability for collaborative storytelling. Following Sun et al. (2022), we also include the connectivity inference task, where the goal is to determine whether two given chapters are consecutive in a story. The task is represented as $y = f(c_n, c_m)$.\\n\\nTemporal Inference\\nInspired from the Connectivity Inference task, we also aim to evaluate a model's ability to understand the temporal relationships between chapters in a story. The Temporal Inference task involves determining whether two chapters in the same story are in the correct chronological order. For example, $(c_i, c_{i+1})$ and $(c_i, c_{i+5})$ would be considered positive instances, while $(c_{i+5}, c_i)$ would not. The task is represented as $y = f(c_n, c_m)$, where $y$ is a binary variable.\\n\\nStory Scoring\\nUnderstanding human ratings of a story is crucial for generating texts that align with human preferences. Many dialog-related applications rely on human labelers to rate texts based on different criteria, e.g. LAMDA (Thoppilan et al., 2022). Since STORYWARS contains human ratings in the form of likes and stars, we propose to include a regression task for story scoring as a task type. We follow Raffel et al. (2019) and normalize the story ratings to a range from 0-10, with rounded scores to the nearest increment of 0.1, and convert the float to string. Given a rating score, such as $r_l$, the task is represented as $r_l = f(c_1, c_2, \\\\ldots, c_t)$.\\n\\n3.2.2 Story Generation Tasks\\n\\nNext Chapter Generation\\nThe next chapter generation problem is defined as an generation task that takes previous chapters and genre information as input, and then generates the subsequent chapter. This is represented as $c_{k+1} = f(c_1, c_2, \\\\ldots, c_k, g)$.\\n\\nConditional Story Generation\\nThe conditional story generation problem is defined as an generation task that also takes previous chapters and genre information as input, but then generates the entire continuation of the story until the conclusion instead. It further evaluates an NLP model's capability to plan and organize the story. This is represented as $c_{k+1}, c_{k+2}, \\\\ldots, c_t = f(c_1, c_2, \\\\ldots, c_k, g)$.\\n\\nChapter Infilling\\nIn line with Ippolito et al. (2019), the chapter infilling task evaluates an NLP model's ability to generate an intermediate chapter given the context of a preceding and subsequent chapter. This is represented as $c_k = f(c_{k-1}, c_{k+1})$.\\n\\nGlobal Infilling\\nBuilding on the chapter infilling task, the global infilling problem considers more extensive context information, including both preceding and subsequent chapters. This is represented as $c_k = f(c_1, c_2, \\\\ldots, c_{k-1}, c_{k+1}, \\\\ldots, c_t)$.\\n\\nTemporal Ordering\\nFollowing Lin et al. (2021), we also include a task that unscrambles chapter sequences based on temporal information, except that we simplify the problem by eliminating the requirement for the NLP model to infill masked chapters. This is represented as $c_1, c_2, \\\\ldots, c_t = f(\\\\text{permute}(c_1, c_2, \\\\ldots, c_t))$. \\n\\n3047\"}"}
{"id": "acl-2023-long-171", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"### Table 2: Task statistics for the STORY benchmark.\\n\\n| Task Type                  | #Tasks | Train | Dev | Test |\\n|----------------------------|--------|-------|-----|------|\\n| Fully-supervised           |        |       |     |      |\\n| Genre Classification       | 27     | 2,000 | 250 | 250  |\\n| Author Attribution         | 30     | 2,000 | 250 | 250  |\\n| Author Verification        | 1      | 144,000 | 20,925 | 20,925 |\\n| Connectivity Inference     | 1      | 59,402 | 7,521 | 6,963 |\\n| Temporal Inference         | 1      | 84,632 | 9,480 | 8,928 |\\n| Story Scoring              | 2      | 17,046 | 1,485 | 1,484 |\\n| Story Segmentation         | 1      | 17,256 | 1,500 | 1,500 |\\n| Next Chapter Generation    | 1      | 40,729 | 5,845 | 5,043 |\\n| Conditional Story Generation| 1    | 23,473 | 4,345 | 3,543 |\\n| Chapter Infilling          | 1      | 23,473 | 4,345 | 3,543 |\\n| Global Infilling           | 1      | 23,473 | 4,345 | 3,543 |\\n| Temporal Ordering          | 1      | 78,554 | 8,932 | 8,407 |\\n| Few-shot                   |        |        |     |      |\\n| Genre Classification       | 10     | 32     | 32  | 200  |\\n| Zero-shot                  |        |        |     |      |\\n| Genre Classification       | 23     | 0      | 0   | 200  |\\n\\n#### 3.2.3 The Benchmark\\n\\nBenchmark task statistics\\n\\nThe 12 task types translate into 101 tasks based on STORYWARS, with 96 understanding tasks and 5 generation tasks. It is worth noting that the majority of the understanding tasks are genre classification tasks (60) and author attribution tasks (30). Out of the 60 genre classification tasks, we split them into 27 fully-supervised, 10 few-shot, and 23 zero-shot datasets, according to the genre frequency so that the split closely aligns with realistic data distribution. For the fully-supervised and few-shot tasks, we divided the data into training, dev, and test sets. For the zero-shot tasks, we used all the data as a test set by sampling. The remaining task types were used for fully-supervised scenarios. It is important to mention that all of the data in the fully-supervised, few-shot, and zero-shot scenarios are disjoint to prevent data leakage. The overall task data statistics can be found in the Table 2.\\n\\n#### Evaluation metrics\\n\\nFor the genre classification, author attribution, author verification, temporal inference, and connectivity inference tasks, we use F-1 score as the evaluation metric, due to the imbalance nature of the task data. For the story scoring tasks, in line with Raffel et al. (2019) for regression tasks, we use Spearman correlation coefficients as the evaluation metric, because it measures monotonic relationships. For the story segmentation task, we use Boundary Similarity (Fournier, 2013) as the evaluation metric. For the generation tasks, following the suggestions introduced in Chhun et al. (2022), Qin et al. (2019), and Gangal et al. (2021), we use BERTScore (Zhang* et al., 2020) as the evaluation metric, as it has been shown by Chhun et al. (2022) to have better correlation with human evaluation at both the story-level and system-level for story generation systems than other automatic metrics including frequently-used BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004). Also, Gangal et al. (2021) points out that in the narrative reordering problem, similar to our temporal ordering task, BERTScore also correlates quite well with human evaluations. We recognize that there is currently no widely accepted or reliable automatic evaluation metric in the field of story generation, and the use of automatic evaluation in this field is often criticized. However, for the purpose of fast and fair comparison, we chose to follow previous work and use the current best available metric, even though we acknowledge that it may not be perfect.\\n\\nFor evaluating the model performance, we calculate the macro-average of the performance on all tasks within each task type, this allows us to compare models across different task types. The metrics for understanding, generation, and overall performance are determined by the macro-average of the scores across the corresponding task types.\\n\\n#### 3.3 The INSTRUCT STORY Framework\\n\\nThe main goal of instruction tuning is to evaluate the performance of unseen tasks in zero-shot and few-shot learning scenarios, and to show that it can improve the gap between zero-shot and fully-supervised learning performances. Additionally, we are interested in how instruction tuning can improve the performance of fully-supervised tasks.\\n\\nTo accomplish our goal, we propose a two-stage training approach called INSTRUCT STORY. In the first stage, we use instruction tuning as a form of pre-finetuning Aghajanyan et al. (2021). During this stage, we use instructions instead of task prefixes proposed in Muppet Aghajanyan et al. (2021) to enhance the model's ability to generalize to new instructions. In the second stage, after instruction tuning with the fully-supervised task mix, we use single-task finetuning to continually train the model for each fully-supervised task. We use T5-large-lm-adapt (770m) as the base model for instruction tuning INSTRUCT STORY and all of the training tasks are from the STORYWARS fully-supervised training split. Figure 2 illustrates the overall INSTRUCT STORY framework. The instructions we used are included in Appendix A.1.\"}"}
{"id": "acl-2023-long-171", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"It wasn't always like this, you know.\\n\\nThe castle? Of course, but I was referring more to my predicament.\\n\\nBeautiful. That was the only word that did it justice. Other than all the synonyms.\\n\\n\u2026\u2026\\n\\nIs this a mystery story?\\n\\nIn fact, so long ago, that it was when Arrendal the Silver still reigned in the kingdom of Hallendel. Yes, I remember it well; a beautiful land Hallendel was; vast forests, large mountains and the like.\\n\\n\u2026\u2026\\n\\nIs this story written by KylePrince?\\n\\nAnd here is the sixth wing. The last test. The vile damp place with the vile old man in a shabby armchair. Yes, my hero, the voice you were hearing all this time was mine. Did you expect something more magnificent? Well, expectations are deceptive.\\n\\n\u2026\u2026\\n\\nHow do you like the story above? Please rate the story from 0 to 10:\\n\\nWhat do you mean, you think it would be unfair to kill me? No, wait, come back here! Let me explain to you the concept of euthanasia. I'm just joking here. All right. If you want your prize, and refuse to kill me, it won't happen.\\n\\n\u2026\u2026\\n\\nPlease write a next chapter for the above story:\\n\\nChapter A: I have been the guardian of this labyrinth for years. It is my curse. It has never left me. I cannot die. I cannot live\u2026\\n\\nChapter B: For a long time, heroes have come here. Adventurers have come here. They have all tried to kill me.\\n\\n\u2026\u2026\\n\\nPlease write a chapter between Chapter A and Chapter B:\\n\\nYes.\\n\\nNo.\\n\\n9.4\\n\\nYour prize, that is, not my death, but all the same, neither will happen. Would it make you feel better if I was the antagonist all along? If I was secretly leading you into a trap so that I could kill you? Would that encourage your killing me?\\n\\nThis maze was made to protect the unnamed sword. It was requested by King Seriokald himself. It spans the entire Keep, evolving and changing with every step. I cannot guide you through it. My memory has been destroyed by my curse. By the time you get into the maze, the entrance you came in with would be closed. And with that Sibriex on the loose, the sword will be even more secure.\"}"}
{"id": "acl-2023-long-171", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Task Type | Task         | BERT | RoBERTa | DeBERTa | T5       | InstructStory |\\n|-----------|--------------|------|---------|---------|----------|---------------|\\n| Genre Classification\u2020 |             |      |         |         |          |               |\\n| animals   |              | 82.69| 86.02   | 82.24   | 82.88    | 86.79         |\\n| fantasy   |              | 43.70| 47.37   | 48.75   | 47.95    | 50.98         |\\n| horror    |              | 45.67|         |         |          | 60.15         |\\n| war       |              | 59.77|         |         |          | 78.26         |\\n| poetry    |              | 78.90|         |         |          | 85.71         |\\n| drama     |              | 42.67| 45.30   | 46.43   | 44.21    | 47.40         |\\n| mystery   |              | 43.58| 51.47   | 48.53   | 47.48    | 51.97         |\\n| fanfiction|              | 55.28| 62.26   |         |          | 67.27         |\\n| dystopia  |              | 43.48| 57.14   | 61.16   | 52.23    | 63.55         |\\n| sci-fi    |              | 65.42|         |         |          | 67.24         |\\n| A VG      |              | 51.86|         |         |          | 61.15         |\\n| Author Attribution\u2020 |      |      |         |         |          |               |\\n| aspiringwriter |          | 66.67|         |         |          | 69.57         |\\n| sagittarius |           | 50.94| 54.74   | 58.02   | 48.52    | 64.81         |\\n| Hope!     |              | 61.82|         |         |          | 81.13         |\\n| Shasta    |              | 52.17| 55.56   | 58.49   | 37.04    | 59.38         |\\n| Scorpio :)|              | 61.82|         |         |          | 81.13         |\\n| Zed       |              | 67.27|         |         |          | 81.82         |\\n| Nathan.N  |              | 82.61|         |         |          | 86.00         |\\n| Ellipsis  |              | 78.85|         |         |          | 83.67         |\\n| Luke V.   |              | 72.09|         |         |          | 69.77         |\\n| Amelia Rose|             | 50.00|         |         |          | 70.10         |\\n| A VG      |              | 64.52|         |         |          | 72.31         |\\n| Author Verification |          |      |         |         |          |               |\\n| author_verification |      | 23.19| 23.41   | 23.17   | 22.94    | 23.57         |\\n| Temporal Inference |            |      |         |         |          |               |\\n| temporal_inference |             | 72.90|         |         |          | 77.74         |\\n| Connectivity Inference |          |      |         |         |          |               |\\n| connectivity_inference |           | 65.03| 62.97   | 67.61   | 67.20    | 68.72         |\\n| Story Scoring |            |      |         |         |          |               |\\n| likes_scoring |             | 53.54|         |         |          | 75.74         |\\n| stars_scoring |             | 55.34|         |         |          | 66.60         |\\n| Story Segmentation |          |      |         |         |          |               |\\n| story_segmentation |           | 31.38| 47.28   | 41.09   | 46.87    | 47.33         |\\n| Understanding A VG |            |      |         |         |          |               |\\n| understanding_agreement |       | 51.90| 59.43   | 57.39   | 57.56    | 59.62         |\\n| Task Type | Task         | GPT2-l | GPT2-m | OPT-350m | T5       | InstructStory |\\n| Next Chapter Generation |             | 81.35| 80.90   | 83.25    | 82.17    | 82.43         |\\n| Conditional Story Generation |          | 79.40| 79.33   | 82.39    | 81.10    | 81.24         |\\n| Chapter Infilling |            | 80.93| 80.67   | 82.89    | 82.34    | 82.51         |\\n| Global Infilling |           | 81.49| 81.30   | 83.70    | 82.22    | 82.44         |\\n| Temporal Ordering |            | 76.49| 76.33   | 92.77    | 90.08    | 93.14         |\\n| Generation A VG |            | 79.93| 79.71   |         |          | 85.00         |\\n| Understanding and Generation Overall A VG | | 68.40 | 69.93 | - | - | - |\\n\\nTable 3: Fully-supervised results of InstructStory and other baselines. Bold numbers indicate the best score across all models, and underlined numbers indicate cases where InstructStory outperforms the T5 baseline. Due to space limits, only 10 random tasks from the task type are shown. Full results can be found in the Appendix A.3.\\n\\nThe best results. For generation tasks, InstructStory outperforms T5 by 0.77 points. It also achieves favorable performance when compared to other strong generation baselines such as GPT2-medium and GPT2-large, although performing a little bit worse than OPT-350m. We hypothesize that the difference in performance between OPT-350m and InstructStory is due to the base model, specifically the size of the pretraining corpus (35B tokens vs 180B tokens). (Zhang et al., 2022)\\n\\nFew-shot Results\\nThe few-shot results are shown in Table 4. For the few-shot scenario, InstructStory achieves the highest score of 61.44, followed by FLAN-T5 which achieved the second highest score of 59.45, outperforming all the T5, BERT, RoBERTa, and DeBERTa baselines. This demonstrates that even when instruction-tuned on a different dataset distribution, FLAN-T5 can still achieve competitive results when further fine-tuned for few-shot tasks.\"}"}
{"id": "acl-2023-long-171", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Task      | BERT | RoBERTa | DeBERTa | T5 | FLAN-T5 | InstructStory |\\n|-----------|------|---------|---------|----|---------|---------------|\\n| Wordgames | 59.65| 80.90   | 77.27   | 62.40| 71.05   | 73.68         |\\n| Rebellion | 38.38| 45.87   | 33.33   | 43.24| 50.00   | 50.00         |\\n| Mythology | 47.27| 59.79   | 61.54   | 62.07| 66.67   | 67.33         |\\n| Future    | 30.00| 40.00   | 50.90   | 36.23| 44.86   | 54.70         |\\n| Friendship| 38.82| 46.96   | 44.62   | 49.23| 53.33   | 55.36         |\\n| Fairytale | 45.93| 60.32   | 65.52   | 74.07| 72.09   | 79.59         |\\n| Dreams    | 47.48| 64.15   | 58.62   | 78.16| 71.26   | 76.74         |\\n| Crime     | 48.54|        | 36.04   | 65.42| 62.22   | 65.26         |\\n| Change    | 44.00|        | 32.91   | 33.90| 47.89   | 39.19         |\\n| Action    | 38.30| 40.25   | 36.47   | 41.13|        | 55.10         |\\n| AVG       | 43.84| 55.53   | 49.72   | 54.59| 59.45   | 61.44         |\\n\\nTable 4: Few-shot benchmark results. InstructStory outperforms all other baselines.\\n\\n| Task      | T5 | FLAN-T5 | InstructStory |\\n|-----------|----|---------|---------------|\\n| Reality   | 32.56| 39.56   | 39.47         |\\n| Lies      | 30.22| 46.34   | 70.33         |\\n| Vampire   | 19.12| 63.33   | 58.82         |\\n| Surreal   | 31.41| 33.86   | 46.25         |\\n| Suspense  | 31.82| 42.77   | 43.68         |\\n| Supernatural | 39.34| 48.28   | 45.33         |\\n| Family    | 14.88| 51.16   | 60.00         |\\n| Revenge   | 35.00| 58.06   | 57.14         |\\n| Crazy     | 30.00| 42.31   | 43.08         |\\n| World     | 30.63| 34.92   | 50.75         |\\n| AVG       | 32.09| 47.79   | 60.00         |\\n\\nTable 5: Zero-shot benchmark results. InstructStory outperforms T5 and even FLAN-T5. \u2020: Due to space limits, we only show 10 random tasks. Full results can be found in Appendix A.3.\\n\\nZero-shot Results\\nWe can see the zero-shot results in Table 5. In the zero-shot scenario, we compare InstructStory with T5 and FLAN-T5, and we can see that InstructStory has a significant improvement in zero-shot performance, a 28.08 increase from T5 and a 12.21 increase from FLAN-T5. This is expected because our instruction tuning training task mix has a similar, though unseen, data distribution to the zero-shot test sets.\\n\\n4.4 Discussions\\nInstructStory brings a robust improvement in performance. By comparing T5 and InstructStory in Table 3, we see that InstructStory scores higher than T5 in every task type. The performance gain is consistent across all task types. Even on the task level, InstructStory achieves better results than T5 in 24 out of 27 genre classification tasks and 23 out of 30 authorship attribution tasks. This indicates that in fully-supervised scenario, one can confidently use the power of instruction tuning to improve performance.\\n\\nTable 6: InstructStory vs its variants IS and ISG. Ablation: Instruction tuning with both understanding and generation tasks is more effective than instruction tuning with only understanding tasks or only generation tasks. Table 6 illustrates this by comparing the fully-supervised, few-shot, and zero-shot genre classification scores of InstructStory, its variants ISU and ISG, where IS and ISG are instruction tuned with understanding tasks mix and generation tasks mix, separately. From the table, we can see that IS > ISU > ISG > T5 across all zero-shot, few-shot, and fully-supervised learning scenarios, which indicates that instruction tuning with a mix of understanding and generation tasks is better than instruction tuning with only one of them.\\n\\n5 Conclusion\\nWe introduced a novel dataset STORYWARS and a multitask benchmark for collaborative story understanding and generation. Our proposed InstructStory model, which leverages instruction tuning as multitask pre-finetuning, outperformed both its single-task finetuning baseline and other strong models on the STORYWARS benchmark and established strong performance in all zero-shot, few-shot, and fully-supervised learning scenarios. We hope that our newly proposed STORYWARS dataset will serve as a catalyst for research in the field of collaborative storytelling and inspire further advancements in this area.\"}"}
{"id": "acl-2023-long-171", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Our proposed INSTRUCT STORY method utilizes both single-task finetuning and instruction tuning to achieve good results. However, when finetuned on a new task, the model may suffer from the problem of catastrophic forgetting and lose its multitasking generalization abilities. Recent research by Scialom et al. (2022) has investigated this issue in instruction-tuned models and proposed a technique called Rehearsal to mitigate it. However, this work primarily focuses on zero-shot scenarios and does not address fully-supervised learning. It would be of interest to explore whether it is possible to fine-tune on a single task while preserving the model's multitasking abilities and generalization capabilities. We leave this question as an area for future research.\\n\\nAdditionally, it is important to note that our approach of single-task finetuning for each downstream task results in multiple models being required to be served simultaneously, which can lead to increased computational costs. In practice, this is a trade-off that must be carefully considered, as it requires balancing performance requirements with the resources available. It can be an important factor to consider when implementing this approach in real-world settings.\\n\\nIn the end, a proper and thorough evaluation of collaborative story generation remains an ongoing research. While automatic evaluation metrics such as BERTScore has the best human correlations at story-level and system-level per Chhun et al. (2022), it may not be comprehensive enough in evaluating the highly creative output of collaborative story generation. There is a need for more nuanced and sophisticated metrics that can capture the complexity and diversity of collaborative stories. Therefore, the development and validation of appropriate evaluation methods is crucial for progress in this field.\\n\\nEthical Considerations\\n\\nIn Section 3.1, we have discussed our procedures to identify and remove potential harmful content and user privacy information. However, it is important to also consider the broader ethical implications of using AI in collaborative storytelling. These include issues such as ensuring fair and unbiased representation, protecting data privacy, and preventing the use of AI-generated content for harmful purposes. For example, AI-generated stories or characters may perpetuate stereotypes or reinforce societal biases if they are trained on biased data. Therefore, it is crucial to consider and address these ethical issues in order to create inclusive and responsible AI-generated stories that do not harm individuals or groups.\\n\\nReferences\\n\\nArmen Aghajanyan, Anchit Gupta, Akshat Shrivas-tava, Xilun Chen, Luke Zettlemoyer, and Sonal Gupta. 2021. Muppet: Massive multi-task representations with pre-finetuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5799\u20135811, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nNader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, and Mohit Iyyer. 2020. STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6470\u20136484, Online. Association for Computational Linguistics.\\n\\nVamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Hon-glei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Gupta, Kai Hui, Sebastian Ruder, and Donald Metzler. 2022. Ext5: Towards extreme multi-task scaling for transfer learning. In International Conference on Learning Representations.\\n\\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135\u2013146.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877\u20131901. Curran Associates, Inc.\\n\\nCyril Chhun, Pierre Colombo, Fabian M. Suchanek, and Chlo\u00e9 Clavel. 2022. Of human criteria and automatic metrics: A benchmark of the evaluation of story generation. In Proceedings of the 29th International Conference on Computational Linguistics, pages 5794\u20135836, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.\"}"}
{"id": "acl-2023-long-171", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "acl-2023-long-171", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "acl-2023-long-171", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thomas Scialom, Tuhin Chakrabarty, and Smaranda Muresan. 2022. Fine-tuned language models are continual learners.\"}"}
{"id": "acl-2023-long-171", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"nath, Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo hwan Lee, Spencer Bradley Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Rose Biderman, Stephanie C. Lin, S. Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq A. Ali, Tatsuo Hashimoto, Te-Lin Wu, Theo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, T. N. Kornev, Timothy Telleen-Lawton, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler O'Brien Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Venkatesh Ramasesh, Vinay Uday Prabhu, Vishakh Padmakumar, Vivek Srikumar, William F\u00e9dus, William Saunders, William Zhang, W Vossen, Xiang Ren, Xiaoyu F Tong, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yang Song, Yasaman Bahri, Ye Ji Choi, Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yu Hou, Yuntao Bai, Zachary Seid, Zhao Xinran, Zhuoye Zhao, Zi Fu Wang, Zijie J. Wang, Zirui Wang, Ziyi Wu, Sahib Singh, and Uri Shaham. 2022. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. ArXiv, abs/2206.04615.\\n\\nSimeng Sun, Katherine Thai, and Mohit Iyyer. 2022. ChapterBreak: A challenge dataset for long-range language models. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3704\u20133714, Seattle, United States. Association for Computational Linguistics.\\n\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Souraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. 2022. Lambda: Language models for dialog applications. CoRR, abs/2201.08239.\\n\\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aur'elien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models. ArXiv, abs/2302.13971.\\n\\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2019. Superglue: A stickier benchmark for general-purpose language understanding systems. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.\\n\\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353\u2013355, Brussels, Belgium. Association for Computational Linguistics.\\n\\nJason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2021. Finetuned language models are zero-shot learners. CoRR, abs/2109.01652.\\n\\nHanwei Xu, Yujun Chen, Yulun Du, Yanggang Wang, Haiyu Li, and Zhilin Yang. 2022. Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization. CoRR, abs/2201.06910.\\n\\nJingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xiaoyan Cai, and Xu Sun. 2018. A skeleton-based model for promoting coherence among sentences in narrative story generation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4306\u20134315, Brussels, Belgium. Association for Computational Linguistics.\\n\\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carabonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.\\n\\nLili Yao, Nanyun Peng, Weischedel Ralph, Kevin Knight, Dongyan Zhao, and Rui Yan. 2019. Plan-and-write: Towards better automatic storytelling. In The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19).\\n\\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022. Opt: Open pre-trained transformer language models.\\n\\nTianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.\"}"}
{"id": "acl-2023-long-171", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Appendix\\n\\nA.1 Instruction Template examples\\nPlease refer to Table 7 for the instruction template examples.\\n\\nA.2 Hyperparameters\\nPlease refer to Table 8 for the hyperparameters.\\n\\n| name       | value     |\\n|------------|-----------|\\n| batch size | 64        |\\n| learning rate | 5e-5     |\\n| training steps | 50000     |\\n| warmup steps | 2000      |\\n\\nTable 8: Hyperparameters for INSTRUCT STORY\\n\\nA.3 Full results tables\\nPlease refer to Table 9, Table 10, Table 11, and Table 12 for all full results.\"}"}
{"id": "acl-2023-long-171", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Task Type                        | Input Format                                                                 | Output Format |\\n|---------------------------------|-----------------------------------------------------------------------------|---------------|\\n| Genre Classification            | {story} Is this a {genre} story?                                             | Yes or No     |\\n| Authorship Attribution          | {story} Is this story written by {author}?                                   | Yes or No     |\\n| Authorship Verification         | Chapter A: {chapter a} Chapter B: {chapter b} Are the two story chapters above written by the same author? | Yes or No     |\\n| Connectivity Inference          | Chapter A: {chapter a} Chapter B: {chapter b} Can Chapter B be the next chapter of Chapter A? | Yes or No     |\\n| Temporal Inference              | Chapter A: {chapter a} Chapter B: {chapter b} Does Chapter A happen before Chapter B? | Yes or No     |\\n| Story Scoring                   | {story} How do you like the story above? Please rate the story from 0 to 10: | 0.0 - 10.0    |\\n| Story Segmentation              | {story} Please segment the story into chapters:                             |               |\\n| Next Chapter Generation         | {story 0:i} Please write a next chapter for the above story:                |               |\\n| Conditional Story Generation    | {story 0:i} Please finish the whole story:                                  |               |\\n| Chapter Infilling              | Chapter A: {chapter a} Chapter B: {chapter b} Please write a chapter between Chapter A and Chapter B: |               |\\n| Global Infilling                | Previous chapters: {story prev} Next chapters: {story next} Based on the context of previous and next chapters, please fill in a chapter in between: |               |\\n| Temporal Ordering               | {story permute} Please rewrite the story in correct temporal order:          | {story correct} |\\n\\nTable 7: Instruction template examples.\"}"}
{"id": "acl-2023-long-171", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Task              | BERT  | RoBERTa | DeBERTa | T5    | InstructStory |\\n|-------------------|-------|---------|---------|-------|---------------|\\n| War               | 59.77 | 68.97   | 76.0    | 70.59 | 78.26         |\\n| Life              | 35.41 | 40.0    | 37.5    | 51.75 | 46.48         |\\n| Fanfiction        | 55.28 | 62.26   | 67.27   | 63.41 | 66.07         |\\n| Poetry            | 78.9  | 85.71   | 79.65   | 81.97 | 84.96         |\\n| Music             | 69.14 | 83.87   | 85.42   | 83.17 | 86.6          |\\n| Fantasy           | 43.7  | 47.37   | 48.75   | 47.95 | 50.98         |\\n| Humor             | 60.61 | 54.12   | 62.22   | 61.95 | 56.07         |\\n| LGBT              | 48.08 | 60.24   | 63.83   | 59.81 | 55.77         |\\n| School            | 36.14 | 63.24   | 65.22   | 51.22 | 51.76         |\\n| Game              | 58.62 | 77.55   | 77.42   | 68.24 | 69.57         |\\n| Sad               | 48.35 | 56.93   | 53.97   | 53.44 | 55.17         |\\n| Nature            | 39.51 | 51.43   | 48.08   | 51.85 | 47.17         |\\n| Magic             | 60.61 | 63.74   | 61.9    | 59.42 | 61.76         |\\n| Adventure         | 40.43 | 55.24   | 46.38   | 44.32 | 45.64         |\\n| Sci-fi            | 65.42 | 61.07   | 67.24   | 62.69 | 66.67         |\\n| Romance           | 54.84 | 59.68   | 60.29   | 56.52 | 62.12         |\\n| Hero              | 32.26 | 56.14   | 61.9    | 70.97 | 71.84         |\\n| Euphoric          | 28.26 | 40.35   | 44.83   | 44.59 | 43.1          |\\n| Space             | 72.73 | 74.23   | 78.72   | 80.0  | 78.9          |\\n| Survival          | 29.73 | 58.59   | 59.32   | 53.06 | 52.38         |\\n| Mystery           | 43.58 | 51.47   | 48.53   | 47.48 | 51.97         |\\n| Drama             | 42.67 | 45.3    | 46.43   | 44.21 | 47.4          |\\n| Royalty           | 72.73 | 74.0    | 68.18   | 74.75 | 75.47         |\\n| Dystopia          | 43.48 | 57.14   | 61.16   | 52.23 | 63.55         |\\n| Death             | 51.57 | 60.87   | 66.67   | 53.59 | 60.94         |\\n| Horror            | 45.67 | 55.64   | 60.15   | 52.05 | 53.33         |\\n| Animals           | 82.69 | 86.02   | 82.24   | 82.88 | 86.79         |\\n| Intellikat        | 76.47 | 80.43   | 72.41   | 72.0  | 80.0          |\\n| Hope!             | 61.82 | 81.13   | 62.3    | 56.21 | 68.22         |\\n| ArtemisNine       | 46.58 | 68.42   | 58.14   | 65.98 | 69.09         |\\n| Mockingjay        | 50.98 | 64.52   | 57.97   | 31.58 | 55.63         |\\n| Rosetta           | 70.83 | 78.72   | 73.79   | 69.81 | 78.0          |\\n| Ember             | 46.6  | 68.09   | 59.26   | 55.71 | 55.12         |\\n| CheshireinWonderland | 47.31 | 55.42   | 63.04   | 40.7  | 58.41         |\\n| Ellipsis          | 78.85 | 83.67   | 59.38   | 67.89 | 78.0          |\\n| Scorpio :)        | 58.82 | 73.08   | 61.54   | 53.42 | 64.83         |\\n| DANDAN THE DANDAN | 63.27 | 70.73   | 76.6    | 65.22 | 71.11         |\\n| Luke V .          | 72.09 | 69.77   | 69.23   | 63.24 | 73.79         |\\n| Windlion          | 87.13 | 90.38   | 93.07   | 88.89 | 92.16         |\\n| Kitin             | 86.87 | 83.72   | 78.18   | 80.0  | 74.42         |\\n| Tricia L          | 43.84 | 70.09   | 61.29   | 45.59 | 64.71         |\\n| Nathan.N          | 82.61 | 84.78   | 86.0    | 86.32 | 87.23         |\\n| Zed               | 67.27 | 72.94   | 81.82   | 73.27 | 78.85         |\\n| CAPSLOCK          | 77.59 | 74.38   | 80.81   | 67.96 | 80.37         |\\n| R                | 65.26 | 88.89   | 85.71   | 78.26 | 88.89         |\\n| Golden-in-the-mist | 78.85 | 84.96   | 78.9    | 66.17 | 72.73         |\\n| Libra (inactive)  | 54.14 | 62.3    | 57.89   | 54.55 | 57.66         |\\n| Silverfroststorm  | 75.79 | 67.83   | 55.7    | 51.5  | 63.16         |\\n| Shasta            | 52.17 | 55.56   | 58.49   | 37.04 | 59.38         |\\n| SaintSayaka       | 71.43 | 75.21   | 77.06   | 61.87 | 75.23         |\\n| Amelia Rose       | 50.0  | 70.1    | 68.57   | 53.62 | 68.97         |\\n| Sagittarius       | 50.94 | 54.74   | 58.02   | 48.52 | 64.81         |\\n| Phantim           | 66.67 | 81.55   | 78.1    | 70.59 | 76.79         |\\n| Ara Argentum Aurum! | 50.94 | 49.28   | 56.41   | 63.46 | 67.33         |\\n| Aspiringwriter    | 66.67 | 69.57   | 62.02   | 60.4  | 67.18         |\\n| Camel             | 71.15 | 73.12   | 77.06   | 64.41 | 66.67         |\\n| Darcy             | 62.65 | 65.98   | 63.64   | 66.67 | 64.86         |\\n\\nTable 9: Fully-supervised understanding results of INSTRUCT STORY and other baselines.\"}"}
{"id": "acl-2023-long-171", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Task             | GPT2-l | GPT2-m | OPT-350m | T5   | InstructStory |\\n|------------------|--------|--------|----------|------|---------------|\\n| next_chapter     | 81.35  | 80.90  | 83.25    | 82.17| 82.43         |\\n| conditional      | 79.40  | 79.33  | 82.39    | 81.10| 81.24         |\\n| chapter_infilling| 80.93  | 80.67  | 82.89    | 82.34| 82.51         |\\n| global_infilling | 81.49  | 81.30  | 83.70    | 82.22| 82.44         |\\n| temporal_ordering| 76.49  | 76.33  | 92.77    | 90.08| 93.14         |\\n\\nTable 10: Fully-supervised generation results of INSTRUCT STORY and other baselines.\\n\\n| Task             | BERT   | RoBERTa| DeBERTa | T5   | FLAN-T5 | InstructStory |\\n|------------------|--------|--------|---------|------|--------|---------------|\\n| wordgames        | 59.65  | 80.90  | 77.27   | 62.40| 71.05  | 73.68         |\\n| rebellion        | 38.38  | 45.87  | 33.33   | 43.24| 50.00  | 50.00         |\\n| mythology        | 47.27  | 59.79  | 61.54   | 62.07| 66.67  | 67.33         |\\n| future           | 30.00  | 40.00  | 50.90   | 36.23| 44.86  | 54.70         |\\n| friendship       | 38.82  | 46.96  | 44.62   | 49.23| 53.33  | 55.36         |\\n| fairytale        | 45.93  | 60.32  | 65.52   | 74.07| 72.09  | 79.59         |\\n| dreams           | 47.48  | 64.15  | 58.62   | 78.16| 71.26  | 76.74         |\\n| crime            | 48.54  | 66.67  | 36.04   | 65.42| 62.22  | 65.26         |\\n| change           | 44.00  | 50.36  | 32.91   | 33.90| 47.89  | 39.19         |\\n| action           | 38.30  | 40.25  | 36.47   | 41.13| 55.10  | 52.54         |\\n\\nTable 11: Few-shot results of INSTRUCT STORY and other baselines.\\n\\n| Task         | T5      | FLAN-T5 | InstructStory |\\n|--------------|---------|---------|---------------|\\n| disease      | 30.36   | 62.30   | 67.69         |\\n| harrypotter  | 29.63   | 84.21   | 85.71         |\\n| dragons      | 30.22   | 70.42   | 95.00         |\\n| art          | 34.53   | 54.84   | 87.36         |\\n| memories     | 32.65   | 40.00   | 70.18         |\\n| suspense     | 31.82   | 42.77   | 43.68         |\\n| supernatural | 39.34   | 48.28   | 45.33         |\\n| angel        | 34.48   | 55.17   | 82.61         |\\n| revenge      | 35.00   | 58.06   | 57.14         |\\n| surreal      | 31.41   | 33.86   | 46.25         |\\n| history      | 38.60   | 54.12   | 60.34         |\\n| choices      | 40.51   | 28.70   | 50.00         |\\n| vampire      | 19.12   | 63.33   | 58.82         |\\n| lies         | 30.22   | 46.34   | 70.33         |\\n| crazy        | 30.00   | 42.31   | 43.08         |\\n| secret       | 36.19   | 39.49   | 44.59         |\\n| pirates      | 35.97   | 41.51   | 65.63         |\\n| world        | 30.63   | 34.92   | 50.75         |\\n| hope         | 36.99   | 38.60   | 57.14         |\\n| reality      | 32.56   | 39.56   | 39.47         |\\n| family       | 14.88   | 51.16   | 60.00         |\\n| emotions     | 34.67   | 34.67   | 60.18         |\\n| strange      | 28.19   | 34.55   | 38.64         |\\n\\nTable 12: Zero-shot results of INSTRUCT STORY and other baselines.\"}"}
{"id": "acl-2023-long-171", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A For every submission:\\n\u25a1 A1. Did you describe the limitations of your work?\\nLimitation is section 6 after conclusion.\\n\u25a1 A2. Did you discuss any potential risks of your work?\\nunder ethical considerations in section 7.\\n\u25a1 A3. Do the abstract and introduction summarize the paper's main claims?\\nLeft blank.\\n\u25a1 A4. Have you used AI writing assistants when working on this paper?\\nLeft blank.\\n\\nB \u25a1 Did you use or create scientific artifacts?\\nSection 3 dataset.\\n\u25a1 B1. Did you cite the creators of artifacts you used?\\nNot applicable. Left blank.\\n\u25a1 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\\nNot applicable. Left blank.\\n\u25a1 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\\nNot applicable. Left blank.\\n\u25a1 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?\\nSection 3.1.\\n\u25a1 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?\\nNot applicable. Left blank.\\n\u25a1 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.\\nLeft blank.\\n\\nC \u25a1 Did you run computational experiments?\\nsection 4.\\n\u25a1 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?\\nSection 4 specifies the number of parameters of models.\"}"}
{"id": "acl-2023-long-171", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?\\n\\nC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run?\\n\\nNot applicable. Left blank.\\n\\nC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?\\n\\nsection 3.2.3\\n\\nD. Did you use human annotators (e.g., crowdworkers) or research with human participants?\\n\\nLeft blank.\\n\\nD1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.?\\n\\nNo response.\\n\\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?\\n\\nNo response.\\n\\nD3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?\\n\\nNo response.\\n\\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\\n\\nNo response.\\n\\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?\\n\\nNo response.\"}"}
