{"id": "lrec-2024-main-110", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Annotation of Transition-Relevance Places and Interruptions for the Description of Turn-Taking in Conversations in French Media\\n\\nR\u00e9mi Uro 1, 2, 3, Marie Tahon 3, Jane Wottawa 3, David Doukhan 1, Albert Rilliard 2, 4, Antoine Laurent 3\\n\\n1 Institut National de l\u2019Audiovisuel, 2 Universit\u00e9 Paris-Saclay, CNRS, LISN, 3 LIUM, Le Mans Universit\u00e9, 4 Universidade Federal do Rio de Janeiro.\\n\\n{ruro,ddoukhan}@ina.fr, albert.rilliard@lisn.fr\\n{marie.tahon,jane.wottawa,antoine.laurent}@univ-lemans.fr\\n\\nAbstract\\n\\nFew speech resources describe interruption phenomena, especially for TV and media content. The description of these phenomena may vary across authors: it thus leaves room for improved annotation protocols. We present an annotation of Transition-Relevance Places (TRP) and Floor-Taking event types on an existing French TV and Radio broadcast corpus to facilitate studies of interruptions and turn-taking. Each speaker change is annotated with the presence or absence of a TRP, and a classification of the next-speaker floor-taking as Smooth, Backchannel or different types of turn violations (cooperative or competitive, successful or attempted interruption). An inter-rater agreement analysis shows such annotations\u2019 moderate to substantial reliability. The inter-annotator agreement for TRP annotation reaches $\\\\kappa = 0.75$, $\\\\kappa = 0.56$ for Backchannel and $\\\\kappa = 0.5$ for the Interruption/non-interruption distinction. More precise differences linked to cooperative or competitive behaviors lead to lower agreements.\\n\\nThese results underline the importance of low-level features like TRP to derive a classification of turn changes that would be less subject to interpretation. The analysis of the presence of overlapping speech highlights the existence of interruptions without overlaps and smooth transitions with overlaps. These annotations are available at https://lium.univ-lemans.fr/corpus-allies/.\\n\\nKeywords: Spoken interaction, Media, TV, Radio, Transition-Relevance Places, Turn Taking, Interruption, Backchannel, Overlapping Speech, Simultaneous Speech\\n\\n1. Introduction\\n\\nInterruptions constitute an important aspect of social interactions. While interruption-related incivilities are often evoked in public debates (Bennet, 2015), quantifying these phenomena in media is an essential but complex issue. For example, two studies of the same French 2007 Presidential debate (Sandr\u00e9, 2009; Constantin de Chanay and Kerbrat-Orecchioni, 2010), that focused on interruptions between the second turn candidates reached opposite conclusions on who committed most turn-taking violations. While both works were manually produced by experts, large differences may be found in the end: this shows the complexity of the interruption phenomena and the need for other approaches of quantifiable robustness. To study speaker changes in French TV and Radio conversations, we present a set of annotations of an existing French speech corpus (Larcher Anthony et al., 2021) in terms of Transition-Relevance Places (TRPs) (Sacks et al., 1974) and types of transitions between turns. One aim is to determine whether human TRP annotation is more reliable than the direct annotation of various interruption types and whether detecting TRPs automatically can help analyze interruptions in general.\\n\\nTRPs are defined by Sacks et al. (1974) as the end of a Turn-Constructional Unit \u2013i.e., a place where the speaker may change. Building upon this concept, Levinson (1983) proposes that taking the floor outside a TRP constitutes a violation and may be considered an interruption. Wells and Macfarlane (1998) state that TRPs must be identifiable by all participants in a conversation to allow for a smooth transition.\\n\\nOverlapping speech correlates with interruptions (Makri-Tsilipakou, 1994), but also commonly occurs in anticipated turn-taking (Heldner and Edlund, 2010; Adda-Decker et al., 2008; Gravano and Hirschberg, 2012). Levinson and Torreira (2015) show that a floor-taking action needs to be planned to minimize floor transfer offsets: this requires the next speaker to anticipate TRPs. There shall thus be cues to the future end of a speech turn. Grosjean (1983) shows that human listeners can predict a sentence\u2019s remaining number of words. Swerts and Geluykens (1993); Swerts (1997); Moneglia and Raso (2014); Gambi et al. (2015), among others, showed there are cues to the terminality of an utterance; the exact nature of those cues \u2013lexical, prosodic\u2013 are debated.\\n\\nSeveral corpora propose annotations of turn-taking events. Gravano and Hirschberg (2011) offer an annotation scheme used in Gravano...\"}"}
{"id": "lrec-2024-main-110", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"and Hirschberg (2012) and Brusco and Gravano (2023); this scheme is based on the notion of Inter-Pausal Units (IPU) and uses six transition types on task-oriented dialogues: Smooth Switch, Overlap, Pause Interruption, Simple Interruption, Butting-in, Hold. Hara et al. (2019) present an annotation scheme of TRPs on simulated human-robot dialogues. In ten Bosch et al. (2004), the authors classify utterances as continuation, interruption, or turn change. Adda-Decker et al. (2008) focus on overlapping speech segments from French political interviews to annotate them as interruptions, backchannels, anticipated turn-taking, and complementary.\\n\\nWe are not aware of an available corpus of French broadcast media that focuses on interruptions and not only on overlapped speech. Lebourdais (2023) reports it is difficult to annotate different categories of interruptions. We thus focus here on terminality and its relationship to the type of floor-taking events. This paper presents a dataset of annotations for TRPs and types of floor-taking events made on French TV and Radio content.\\n\\n2. Method\\n\\n2.1. Data\\n\\n2.1.1. Allies clean\\n\\nThe ALLIES corpus (Tahon et al., 2024) is a French meta-corpus whose publication is planned in 2024 and designed to gather and extend previous French data collected for diarization and transcription evaluation campaigns. It consists of 328 hours of audio extracted from 1998 to 2020 in 1048 shows. In terms of duration, the proportion of overlaps fluctuates widely between broadcast news and debates. ALLIES-clean is a subset of ALLIES, composed of 23 shows at the time of the annotation presented in this paper. The description of each show is reported in Appendix A. The dataset presented here is part of a collective effort to produce richly annotated speech resources to help develop better automatic processing.\\n\\n2.1.2. Selection of speech samples to be annotated\\n\\nSamples of speaker changes with and without overlapping speech were selected. Each sample comprises two or three intervals, depending on whether overlapping speech was included. Samples without overlapping speech comprise one segment before and after speaker changes. For overlapping speech, we only kept turns shorter than 2 seconds and with only two speakers to maximize speaker changes and avoid segments with cumbersome structures and unintelligible speech (Gay, 2023).\\n\\nThe samples with overlapped speech are composed of 3 intervals: the part of the segment preceding the overlap, the overlap, and the segment following the overlap.\\n\\nA total of 2041 samples were extracted, among which 1064 contain an overlapped speech interval. The samples last from 0.48s to 31.27s, with a mean duration of 5s. The overlapping speech intervals range from 0.1s to 1.99s, with a mean duration of 0.65s and 80% lasting less than 1s.\\n\\n2.1.3. Speaker categories\\n\\nTable 1 presents the distribution of speakers found in the selected speech samples. The gender and role of the 128 unique speakers, including only 38 women, were manually annotated using categories inspired from Doukhan et al. (2020) to help the description of turn-taking dynamics. The categories of Anchors and Invited Journalists were separated to differentiate the ones in charge of managing the conversation from those invited to give their opinions. The Experts, Politicians, and Celebrities categories are individuals used to appearing in the media, whereas Witnesses (whose profession may be unknown) are not. Speech turns from 2 Witnesses and 6 Celebrities not speaking in French are followed by the corresponding French version uttered by a Translator. The most represented roles are male Anchor Journalists, followed by male Witnesses and Politicians.\\n\\n| Role                  | Women | Men |\\n|-----------------------|-------|-----|\\n| Anchor Journalist (AJ)| 12    | 24  |\\n| Invited Journalist (IJ)| 1    | 7   |\\n| Witness (W)           | 11    | 18  |\\n| Politician (P)        | 4     | 15  |\\n| Celebrity (C)         | 2     | 14  |\\n| Expert (E)            | 2     | 12  |\\n| Translator (T)        | 2     | 4   |\\n| Total                 | 38    | 90  |\\n\\nTable 1: Distribution of the retained role categories observed in the corpus, by gender.\\n\\n2.2. Annotation\\n\\nA paid linguistics student annotated the speech samples. The estimated annotation time for each sample was around 30 seconds. The annotator was instructed to identify two phenomena: the TRPs and the types of floor-taking events. The...\"}"}
{"id": "lrec-2024-main-110", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"types of floor-taking events were inspired by existing classifications of interruptions (Yang, 2001; Li, 2001; Makri-Tsilipakou, 1994). The annotator had to determine for each spoken interval if it ended with a TRP or not and to qualify each floor-taking event as either Smooth, Backchannel (abbr. Back), Competitive Interruption (abbr. CompI), Cooperative interruption (abbr. CoopI), Competitive interruption attempt (abbr. CompIA) or Cooperative interruption attempt (abbr. CoopIA). An interruption attempt happens when the next speaker fails to take the floor from the initial speaker. The Cooperative / Competitive distinction was inspired from Yang (2001): Cooperative violations are defined as a violative floor-taking event aiming to help the current speaker or asking for or giving clarification, whereas a Competitive violation happens when the interrupter tries to steal the turn. A Backchannel is defined by Traverso (2005) as a short intervention that does not contribute to the thematic development of the conversation.\\n\\nIf a span was deemed irrelevant (e.g., no speech, no floor-taking event, translation) or could not be annotated (i.e., a sample artificially cut before the end of a turn or without speech), the field would be left empty. The annotator was provided with a Praat (Boersma and Weenink, 2023) interface, with the mandatory fields pre-filled with all possible labels. The first (resp. second) group of three tiers corresponds to the speaker's name, the TRP annotation, and the Floor-taking event type of the first (resp. second) speaker; the seventh tier is for possible comments of the annotator. The complete annotation guidelines are reported in Appendix B, and a screen capture of the prefilled Praat interface can be seen in Appendix C.\\n\\n3. Results\\n\\n3.1. Annotations distribution\\n\\nOf the 3070 annotationsof TRP, TRPs are present in 1151 intervals including 23% with overlapped speech, and absent in 1919 intervals including 39% with overlapped speech. Table 2 presents the distributions of 1898 floor-taking annotations obtained from 1991 speech samples. Annotation statistics are detailed according to their realization context (within/without overlap). 50 irrelevant speech samples (e.g., ALLIES-clean annotation errors) were discarded from the TRPs and the turn-taking annotation process.\\n\\nLet us note that 25% of the transitions annotated as smooth occur within overlapping speech intervals, which may be related to turn-end anticipation as described in e.g., Grosjean (1983); B\u00f6gels and Levinson (2017). Likewise, 19% of labeled violations were realized without being associated with overlapped speech.\\n\\n| Label     | Number | Percentage within overlap |\\n|-----------|--------|---------------------------|\\n| Back      | 524    | 80%                       |\\n| Smooth    | 929    | 25%                       |\\n| CompI     | 265    | 79%                       |\\n| CoopI     | 37     | 78%                       |\\n| CoopIA    | 21     | 86%                       |\\n| CompIA    | 122    | 89%                       |\\n| Total     | 1898   | 1015                      |\\n\\nTable 2: Number of floor-taking labels and percentage within overlapped speech\\n\\n3.2. Interaction pattern\\n\\nTable 3 lists the five most frequent annotation patterns out of the 161 distinct annotation sequences in the corpus. They correspond to smooth transitions, backchannels, anticipated turn-taking, and successful and aborted competitive interruptions. While these five patterns represent 69% of the annotations, each of the remaining patterns' frequencies represent less than 2%.\\n\\n| Sequence                                      | Percentage |\\n|-----------------------------------------------|------------|\\n| [S1: TRP] [S2: Smooth]                       | 32%        |\\n| [S1: nTRP] [S1: nTRP | S2: Back] | 17%        |\\n| [S1: nTRP] [S1: TRP | S2: Smooth] | 8%         |\\n| [S1: nTRP] [S1: nTRP | S2: CompI] | 7%         |\\n| [S1: nTRP] [S1: nTRP | S2: CompIA] | 5%         |\\n\\nTable 3: Top 5 sequences of labels forming the most common interaction patterns, and their proportion in the corpus\\n\\n3.3. Speakers\\n\\nJournalists are the category that interrupts the most. Of the 437 turns labeled as violative (i.e., something other than Smooth or Back), 301 are produced by journalists. Interestingly, one-third of those journalists are not presenters (Anchor) but are invited.\\n\\nThe two main interruptive patterns \u2014 non-terminal turns with an interruption or interruption attempt \u2014 mostly present interruptions by anchors, between invited journalists, or between experts. It is also interesting to note that while witnesses are rarely interrupted by journalists (6 in total), journalists seem to let themselves be interrupted by witnesses (1 interruption attempt and 16 actual interruptions). This is primarily true for shows where journalists interview people unaccustomed to speaking to the media. Gender does not seem relevant in turn-taking dynamics in this corpus. About 25% of male-male, male-female, female-male dyads are interruptions, and 30% of female-female ones. However, there are only 23 female-\"}"}
{"id": "lrec-2024-main-110", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"females vs. 1588 males; the percentage difference is likely irrelevant because of the gender imbalance.\\n\\n3.4. Inter-rater agreement\\n\\n338 samples were selected as described for multi-rater annotation to evaluate the quality and reproducibility of the proposed annotation scheme. This subset was annotated by two of the authors: one speech sciences computer scientist and one phonetician. Examples to be annotated by multiple raters were selected to encompass all possible label sequences as well as maximize the number of examples from the most represented sequences in the main annotation to obtain a precise agreement for those sequences. All three raters agreed on 74% of examples for TRP classification. When looking only at the five most represented categories, comprising 195 annotated intervals (i.e., 70% of the intervals), the agreement is 88%, showing that the main categories are the most robust ones.\\n\\nA substantial inter-annotator agreement was observed for first speaker TRP annotations (Fleiss\u2019 Kappa = 0.75 (Fleiss, 1971)), showing the reliability of our proposed annotation scheme. Table 4 shows the agreements for each possible label for the type of floor-taking event and their grouping in the following meta-labels:\\n\\n- **Inter**: CoopI + CompI\\n- **Coop**: CoopI + CoopIA\\n- **Comp**: CompI + CompIA\\n- **Attempt**: CoopIA + CompIA\\n- **Violation**: All of the above\\n\\nIt indicates that Backchannels, Smooth transitions, and Violations \u2013i.e., taking the floor when it's not expected\u2013 (especially competitive ones, which are more represented than cooperative ones) are reliably annotated. However, the type of violation seems more complicated to classify. Those findings are consistent with results reported in Lebourdais (2023) and Adda-Decker et al. (2008).\\n\\n| Label    | Main Annotator | Annotator 1 | Annotator 2 | Annotator 3 |\\n|----------|----------------|-------------|-------------|-------------|\\n| Back     | 0.56           | 0.57        | 0.60        |             |\\n| Smooth   | 0.42           | 0.66        | 0.62        |             |\\n| CoopI    | 0.13           | 0.33        | 0.18        |             |\\n| CompI    | 0.48           | 0.51        | 0.49        |             |\\n| CoopIA   | 0.10           | 0.08        | 0.11        |             |\\n| CompIA   | 0.09           | 0.34        | 0.16        |             |\\n| Inter    | 0.51           | 0.54        | 0.50        |             |\\n| Coop     | 0.22           | 0.21        | 0.23        |             |\\n| Comp     | 0.36           | 0.61        | 0.44        |             |\\n| Attempt  | 0.16           | 0.22        | 0.19        |             |\\n| Violation| 0.41           | 0.66        | 0.51        |             |\\n\\nTable 4: Fleiss' Kappa values for each label\\n\\nTable 5 shows the confusion between labels. The Main column states the number of phenomena annotated with each label by the main annotator, and the other columns the corresponding phenomena annotated by the two other annotators. If there is little confusion between Smooth or Backchannel vs. others labels, we also observe that apart from Competitive Interruptions, the violative labels are more prone to confusion.\\n\\n4. Discussion\\n\\nWe proposed an annotation of TRPs and floor-taking events classification on French media. Out of the 2041 labeled samples, the most commonly observed interaction patterns correspond to smooth speaker changes, backchannels, competitive interruptions -successful or not- and anticipated starts. An analysis of the inter-rater agreement shows that the manual annotation of TRPs is reliable. If classifying different types of interruptions is more variable across annotators, the general concept of interruption itself seems identifiable. An in-depth analysis of randomly selected examples of the five main patterns was conducted to determine possible reasons for annotation disagreements. It highlights that when all annotators agree, the samples are textbook examples of TRP respect or violation. Disagreements seem to be related to the attention paid to non-verbal characteristics\u2013underlining the importance of prosody for TRPs\u2013, and the complexity of some samples that escape explicit criteria.\\n\\nFor instance, cooperative and competitive interruptions may be used depending on the perception of the listener and the interpretation of the speakers' communicative aim. Although in our dataset, gender doesn't seem to play a role in turn-taking dynamics \u2013the primary factor being the role\u2013 it is important to remember that this corpus has a highly imbalanced gender distribution. The effect of gender is thus to be considered with caution.\\n\\nOne important takeaway of this analysis is that about a quarter of smooth transitions occur with overlapped speech, while a fifth of the violative turn-taking occurs without overlap. This added to the fact that TRP annotations are more reliable than turn-taking events, hinting that analyzing TRPs may be a good proxy to study interruptions, even without overlapping speech. The annotations of this corpus are available at [https://lium.univ-lemans.fr/corpus-allies/](https://lium.univ-lemans.fr/corpus-allies/).\\n\\n5. Acknowledgements\\n\\nThis work has been partially funded by the French National Research Agency (project Gender Equality Monitor - ANR-19-CE38-0012).\\n\\nThe authors would also like to thank the main annotator for this study.\"}"}
{"id": "lrec-2024-main-110", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 5: Confusion table between the main and the secondary annotators\\n\\n|             | Backchannel | Smooth | CoopI | CompI | CoopIA | CompIA | Not relevant |\\n|-------------|-------------|--------|-------|-------|--------|--------|--------------|\\n| Main        | 80          | 6.8    | 13    | 39    | 9      | 23     | 48           |\\n| Secondary   |             |        |       |       |        |        |              |\\n| Number      |             |        |       |       |        |        |              |\\n| Interactions| 69.4        | 72.6   | 11.5  | 5.1   | 16.7   | 15.2   | 14.6         |\\n| Coop        | 8.1         | 4.0    | 34.6  | 51.3  | 22.2   | 13.0   | 12.5         |\\n| Comp        | 0.6         | 3.2    | 7.7   | 1.3   | 5.56   | 10.3   | 4.2          |\\n| CoopIA      | 1.9         | 4.8    | 4.8   | 4.8   | 5.56   | 0.00   | 5.2          |\\n| CompIA      | 6.9         | 4.8    | 11.5  | 10.3  | 0.00   | 0.00   | 26.1         |\\n| Not relevant| 10.0        | 4.0    | 0.00  | 0.00  | 0.00   | 0.00   | 44.8         |\\n\\n1. Bibliographical References:\\n   - Martine Adda-Decker, Claude Barras, Gilles Adda, Patrick Paroubek, Philippe Boula de Mareuil, and Benoit Habert. 2008. Annotation and analysis of overlapping speech in political interviews. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08).\\n   - Jessica Bennet. 2015. How not to be 'manterrupted' in meetings. Time.\\n   - Paul Boersma and David Weenink. 2023. Praat: doing phonetics by computer (version 6.3.10).\\n   - Pablo Brusco and Agust\u00edn Gravano. 2023. Automatic offline annotation of turn-taking transitions in task-oriented dialogue. Computer Speech Language, 78:101462.\\n   - Sara B\u00f6gels and Stephen C. Levinson. 2017. The brain behind the response: Insights into turn-taking in conversation from neuroimaging. Research on Language and Social Interaction, 50(1):71\u201389.\\n   - Hugues Constantin de Chanay and Catherine Kerbrat-Orecchioni. 2010. Les interruptions dans les d\u00e9bats m\u00e9diatiques: une strat\u00e9gie interactionnelle. Pratiques. Linguistique, litt\u00e9rature, didactique, (147\u2013148):83\u2013104.\\n   - David Doukhan, C\u00e9cile M\u00e9adel, and Coulombe Marl\u00e8ne. 2020. En p\u00e9riode de coronavirus, la parole d'autorit\u00e9 dans l'info t\u00e9l\u00e9 reste largement masculine. La revue des m\u00e9dias.\\n   - Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378\u2013382.\\n   - Chiara Gambi, Torsten Jachmann, and Maria Staudte. 2015. The role of prosody and gaze in turn-end anticipation. Proceedings of the 37th Annual Conference of the Cognitive Science Society.\\n   - D\u00e9borah Gay. 2023. Radio libre (Skyrock) ou la libre antenne comme dispositif d'encadrement d'une sexualit\u00e9 h\u00e9t\u00e9ronormative. R\u00e9seaux, N\u00b0 237(1):37\u201365.\\n   - Agust\u00edn Gravano and Julia Hirschberg. 2011. Turn-taking cues in task-oriented dialogue. Computer Speech Language, 25(3):601\u2013634.\\n   - Agust\u00edn Gravano and Julia Hirschberg. 2012. A corpus-based study of interruptions in spoken dialogue. In Interspeech 2012, page 855\u2013858. ISCA.\\n   - Fran\u00e7ois Grosjean. 1983. How long is the sentence? prediction and prosody in the online processing of language. Linguistics, 21(3).\\n   - Kohei Hara, Koji Inoue, Katsuya Takanashi, and Tatsuya Kawahara. 2019. Turn-taking prediction based on detection of transition relevance place. In INTERSPEECH, pages 4170\u20134174.\\n   - Mattias Heldner and Jens Edlund. 2010. Pauses, gaps and overlaps in conversations. Journal of Phonetics, 38(4):555\u2013568.\\n   - Martin Lebourdais. 2023. Interactions entre locuteurs : de la d\u00e9tection de la parole superpos\u00e9e \u00e0 la d\u00e9tection des interruptions. Ph.D. thesis, Le Mans Universit\u00e9.\\n   - Stephen C. Levinson. 1983. Pragmatics. Cambridge[England]; New York: Cambridge University Press.\\n   - Stephen C. Levinson and Francisco Torreira. 2015. Timing in turn-taking and its implications for processing models of language. Frontiers in Psychology, 6:731.\\n   - Han Z. Li. 2001. Cooperative and intrusive interruptions in inter- and intracultural dyadic discourse. Journal of Language and Social Psychology, 20(3):259\u2013284.\\n   - Marianthi Makri-Tsilipakou. 1994. Interruption revisited: Affiliative vs. disaffiliative intervention. Journal of Pragmatics - J PRAGMATICS, 21:401\u2013426.\"}"}
{"id": "lrec-2024-main-110", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6 shows the description of each show with the number of separate broadcasts, the number of extracted samples, the total duration of those samples, the number of unique speakers and the type of show.\\n\\nB. Annotation guidelines\\n\\nFor each of the following, if it is not possible to annotate a phenomenon (e.g. no speech), leave empty or fill in \u201cNA\u201d.\\n\\nThe TextGrid files are prefilled with tiers 1 to 3 corresponding to Speaker 1, tiers 4 to 6 to Speaker 2 and tier 7 is to be used for comments:\\n\\n- Tiers 1 and 4: prefilled with the speakers name, do not change them\\n- Tiers 2 and 5: fill with terminality annotation for the relevant speaker\\n- Tiers 3 and 6: fill with floor-taking event type for the relevant speaker\\n- Tier 7: use for comments\\n\\nTerminality:\\n\\nAnnotate with \u201cTerm\u201d if the segment ends with a TRP, \u201cNonTerm\u201d if it doesn\u2019t. Do not annotate the last segment, as it may have been artificially cut.\\n\\nTurn-taking event type:\\n\\nAnnotate with the following categories:\\n\\n- Smooth\\n- Back\\n- CompI: Competitive interruption\\n- CoopI: Cooperative interruption\\n- CompIA: Competitive interruption attempt\\n- CoopIA: Cooperative interruption attempt\\n\\nDo not annotate the first segment, as it lacks previous context.\\n\\nDefinitions:\\n\\n- Smooth: Speaker takes the floor when expected, at a TRP\\n- Backchannel: Short verbal regulator indicating attention; may or may not be during an overlapping speech segment\\n- Interruption: Speaker to take the floor outside a TRP\\n- Competitive: Speaker wants to take the floor for themselves\"}"}
{"id": "lrec-2024-main-110", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Show Channel | Nb Broad. | Samples Dur. | Nb Spk. | Type          |\\n|--------------|----------|--------------|--------|---------------|\\n| BFMStory     | BFMTV 2  | 2            | 204    | 1550 News + itw |\\n| CaVousRegarde| LCP 4    | 282          | 4860   | 24 News + itw  |\\n| CultureEtVous| BFMTV 2  | 8            | 25     | 11 Culturemagazine |\\n| DEBATE       | FranceInter 2 | 147     | 567    | 17 Casual itw  |\\n| EntreLesLignes| LCP 3 | 312          | 2173   | 8 News + debate |\\n| LaPlaceDuVillage | TV8 2 | 803          | 2569   | 14 Casual itw  |\\n| PileEtFace   | LCP 2    | 153          | 1069   | 6 Debate      |\\n| PlaneteShowbiz| BFMTV 2 | 12           | 47     | 13 Culturemagazine |\\n| TopQuestions | LCP 2    | 8            | 44     | 7 Parliament questions |\\n| fm           | France Inter 2 | 112     | 501    | 37 News+ itw   |\\n\\nTable 6: Description of each show with the broadcasting channel, the number of separate broadcasts, number of extracted samples, total duration of the samples in second, number of speakers and type of show.\\n\\n- Cooperative: Speaker wants to help, add or ask for clarifications\\n- Attempt: Speaker does not keep the floor after interrupting the other\\n\\nSpecial cases:\\n- Music, noise: specify in the comments field\\n- Segmentation error: flag as Invalid if not deemed usable, else specify in the comments field\\n- A segment contains only laughs, breathing, silences: leave empty and specify in the comments fields\\n- Speaker change is not an interaction (e.g. speech playback, translation): annotate TRPs but not floor-taking event type; specify in the comments field\\n\\nC. Prefilled Praat interface\\n\\nFigure 1 shows a screen capture of a prefilled Praat Textgrid opened in Praat, for a sample with an overlapped speech interval.\"}"}
{"id": "lrec-2024-main-110", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Screenshot of a pre-filled Praat TextGrid, showing a sample with S1 speaking in all three intervals and an overlapped utterance of S2 in the second interval only.\"}"}
