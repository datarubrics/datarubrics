{"id": "acl-2023-long-318", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A For every submission:\\n\\n\u25a1 A1. Did you describe the limitations of your work?\\n\\nSection 7. Limitations\\n\\n\u25a1 A2. Did you discuss any potential risks of your work?\\n\\nSection 8. Ethical Considerations\\n\\n\u25a1 A3. Do the abstract and introduction summarize the paper's main claims?\\n\\nAbstract and Section 1. Introduction\\n\\n\u25a1 A4. Have you used AI writing assistants when working on this paper?\\n\\nLeft blank.\\n\\nB \u25a1 Did you use or create scientific artifacts?\\n\\nSection 3. Dataset and Section 4. Methodology\\n\\n\u25a1 B1. Did you cite the creators of artifacts you used?\\n\\nSection 3. Dataset. We extend the original dataset and cite the dataset.\\n\\n\u25a1 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\\n\\nSection 1: Introduction, Section 2: Related Works\\n\\n\u25a1 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\\n\\nSection 1: Introduction\\n\\n\u25a1 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?\\n\\nNot applicable. Left blank.\\n\\n\u25a1 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?\\n\\nSection 3. Dataset\\n\\n\u25a1 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.\\n\\nTable 3\\n\\nC \u25a1 Did you run computational experiments?\\n\\nSection 5. Experimental Setup and Results\\n\\n\u25a1 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?\\n\\nAppendix B. Additional details on Experiments. Experimental setup\\n\\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\"}"}
{"id": "acl-2023-long-318", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?\\n\\nC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run?\\n\\nC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?\\n\\nD. Did you use human annotators (e.g., crowdworkers) or research with human participants?\\n\\nD1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.?\\n\\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?\\n\\nD3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?\\n\\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable. Left blank.\\n\\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?\"}"}
{"id": "acl-2023-long-318", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation\\n\\nRishabh Gupta, Shaily Desai, Manvi Goel, Anil Bandhkavi, Tanmoy Chakraborty, and Md Shad Akhtar\\n\\nIIIT Delhi, India, Logically, U.K., IIT Delhi, India\\n\\n{rishabh19089, shailyd, manvi19472, shad.akhtar}@iiitd.ac.in, anil@logically.ai, tanchak@iitd.ac.in\\n\\nAbstract\\n\\nCounterspeech has been demonstrated to be an efficacious approach for combating hate speech. While various conventional and controlled approaches have been studied in recent years to generate counterspeech, a counterspeech with a certain intent may not be sufficient in every scenario. Due to the complex and multifaceted nature of hate speech, utilizing multiple forms of counter-narratives with varying intents may be advantageous in different circumstances. In this paper, we explore intent-conditioned counterspeech generation. At first, we develop IntentCONAN, a diversified intent-specific counterspeech dataset with 6831 counterspeeches conditioned on five intents, i.e., informative, denouncing, question, positive, and humour. Subsequently, we propose QUARC, a two-stage framework for intent-conditioned counterspeech generation. QUARC leverages vector-quantized representations learned for each intent category along with PerFuMe, a novel fusion module to incorporate intent-specific information into the model. Our evaluation demonstrates that QUARC outperforms several baselines by an average of ~10% across evaluation metrics. An extensive human evaluation supplements our hypothesis of better and more appropriate responses than comparative systems.\\n\\nWarning: This work contains offensive and hateful text that some might find upsetting. It does not represent the views of the authors.\\n\\n1 Introduction\\n\\nThe quantity and accessibility of information on the Internet are constantly growing in the 21st century. This has made it increasingly simpler for users on social media to post hateful or attacking speech, all while hiding behind the veil of anonymity (Mondal et al., 2017). Hate speech (Awal et al., 2021; Chakraborty and Masud, 2022) is an offensive dialogue that uses stereotypes to communicate a hateful ideology, and it can target several protected HS:\\n\\nDo you have any proof that the Holocaust happened?\\n\\nIntent-conditioned CS generation \u2013 QUARC\\nCS: The physical evidence of the concentration camps are undeniable.\\n\\nCS: How can you deny the deaths of more than 6 million Jews?\\n\\nCS: Historians agree that the concentration camps were a great example of a systematic persecution of Jews by the Nazi regime occurred.\\n\\nCS: It is a myth perpetuated by anti-Semites to justify their hatred of Jews.\\n\\n(Detected Intent: Denouncing)\\n\\nCS: Do you have any proof on your claim about hate?\\n\\n(Detected Intent: Question)\\n\\nGPS\\n\\nDialoGPT\\n\\nAdequate, but the informative counter argument would be more effective.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\\n\\nThese examples show different intents generated by different models. This raises the need for a system that, along with producing multiple counter-arguments, also ensures that the generated sentence is effective.\\n\\nClassical CS generation\\n\\nDenouncing\\n\\nQuestion\\n\\nInformative\\n\\nFigure 1: Outputs compared to pre-existing methods.\"}"}
{"id": "acl-2023-long-318", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"and Bhat, 2021) in this domain is limited to generating one counterspeech instance for every hate speech. However, while appropriate, a single counterspeech style could fail to produce the desired effect on the attacker and bystanders alike. Mathew et al. (2019) showed that different victimized communities could be perceptible to different types of counterspeeches. The authors analyzed comments from YouTube and compared the popularity of various intents of counterspeeches for different affected communities like POC, LGBT+, and Jews. They concluded that most likes and replies were received by different kinds of counterspeech instances for different communities \u2013 e.g., facts and humor in the case of LGBT+. These observations indicate that a counterspeech generation model would benefit from a diverse output pool, and generating appropriate counterspeeches for different scenarios would provide a better opportunity to educate the attacker and the general public. We support our argument with an example in Figure 1. For a given hate speech, we generate counterspeeches from Generate-Prune-Select (GPS) (Zhu and Bhat, 2021) \u2013 a popular counterspeech generation model, and fine-tuned DialoGPT (Zhang et al., 2020b). Though the counterspeeches with intents question and denouncing, respectively, are semantically appropriate and can be used as valid responses, we argue that the legitimacy of the evidence supporting the Holocaust would be best addressed by a factual/informative counterspeech. To the best of our knowledge, this paper presents the first successful pipeline for intent-controlled counterspeech generation.\\n\\nOur Contribution:\\nWe propose a novel task of intent-specific counterspeech generation that aims to generate a counterspeech for a given hate speech and a desired counterspeech intent. In total, we consider five counterspeech intents, namely \u2013 informative, question, denouncing, humor, and positive. We curate IntentCONAN, an intent-specific counterspeech generation dataset consisting of 6,831 counterspeeches for 3,583 hate speech instances. Further, we propose QUARC, a novel two-phased counterspeech generation framework. In the first stage, QUARC learns vector-quantized representations for every intent and leverages the learned representations to generate desired intent-specific counterspeech in the second stage. Our comparative analysis and human evaluation demonstrate QUARC\u2019s superior performance over several baselines both empirically and qualitatively.\\n\\nIn brief, we make the following contributions:\\n\u2022 Novel task \u2013 Intent-specific counterspeech generation, which results in a diverse pool of counterarguments for a given hate speech.\\n\u2022 Novel dataset \u2013 IntentCONAN with 6,831 counterarguments for 3,583 hate speeches spanning across five counterspeech intents.\\n\u2022 Novel model \u2013 QUARC, a two-phased intent-specific counterspeech generation framework.\\n\u2022 Evaluation \u2013 An extensive comparison and human evaluation to quantify the efficacy of our approach w.r.t state-of-the-art baselines.\\n\\nReproducibility:\\nWe open-source the code and dataset at: https://github.com/LCS2-IIITD/quarc-counterspeech.\"}"}
{"id": "acl-2023-long-318", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"for generating diverse counterspeeches. While research has shown the potency of using conditioned counterspeech depending on the context (Mathew et al., 2019; Hangartner et al., 2021), the generation task is still in its infancy. Recently, Saha et al. (2022) proposed CounterGEDI, a model to control attributes like politeness, detoxification, and emotions of the generated counterspeeches using class-conditioned language models. However, the model does not include specific intents described in Benesch et al. (2016).\\n\\nControlling Methods for Generation:\\n\\nPrior studies on controlled language generation aimed to enforce user-specified constraints while generating texts. These approaches can exploit constraints at inference time (Dathathri et al., 2020) or be applied during the training of the model (Wu et al., 2021). For controlled dialogue generation, Lin et al. (2021) used a series of lightweight adapters on top of a language model for high-level control of dialogues generated. In other work, Keskar et al. (2019) fine-tuned separate models for each attribute. While the above models show promising results for the task of controlled generation, we find that these models cannot be used directly for generating controlled counterspeeches with hate speech and intent as the input. This is due to the scarcity of counterspeeches for each intent and the overlap between the intents that make it harder for the model to learn the differences.\\n\\n3 Dataset\\n\\nWe begin by analyzing existing works to determine the intent categories for IntentCONAN. CONAN (Chung et al., 2019) derives nine intent categories from Benesch et al. (2016), whereas Mathew et al. (2019) defined seven intent categories with minor variation. In contrast, due to the scarcity of data points, we club a few semantically-similar intents together in IntentCONAN, e.g., we combine the positive and affiliation intents as positive. In total, we consider five intent categories, i.e., informative, question, denouncing, humor, and positive in this work. Table 7 in Appendix A highlights the relationship among the three sets of intent categories.\\n\\nThe publicly-available Multi-Target CONAN dataset (Fanton et al., 2021) consists of ~5,000 HS-CS pairs. However, it does not comprise any intent label for the counterspeeches. First, we extract the HS-CS pairs and clean them to remove redundancy. Subsequently, we employ three domain experts to annotate the existing CS with an intent and write new CS for the remaining intent categories. Although, we capped the annotations at the values mentioned in Table 1 so as to not induce repetitiveness; i.e. not every hate speech in IntentCONAN has five counterspeeches. The count-wise statistics are: 5 CS-per-HS: 10%, 4 CS-per-HS: 5%, 3 CS-per-HS: 20%, 2 CS-per-HS: 10%, and 1 CS-per-HS: 55%. An example of annotated counterspeeches for various intents is shown in Table 2.\\n\\nAnnotation Guidelines:\\n\\nPrior to the annotation, we make sure that the annotators have a comprehensive understanding of the field-manual for \\\"responding to online abuse\\\". In our pilot study, we conduct several rounds of deliberation with all annotators over the understanding of the counterspeech. In particular, annotators consider the following objectives for every intent of speech: Establishing the context, stating the reason, providing a solution, and maintaining politeness.\\n\\nThe annotators are experts in NLP and social media. \\n\\nhttps://onlineharassmentfieldmanual.pen.org/\"}"}
{"id": "acl-2023-long-318", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"lish the Goal: Each type of counterspeech necessi-\\ntates a distinct fundamental idea, speech style, and\\ngoal. \\n\\nDe-escalate: Each counterspeech instance\\nshould be written in a manner that would neutralize\\nthe situation and, ideally, not provoke retaliation\\nor further hate speech.\\n\\nAvoid Hostile Language: Under no circumstance was threatening speech,\\nname-calling, profanity, or hostility to be displayed\\nwhile annotating counterspeech instances. Sub-\\nsequently, annotators label and write the intent-\\nspecific counterspeeches for 3,583 distinct hate\\nspeech instances. Table 1 shows\\nIntentCONAN\u2019s\\ndetailed statistics. Appendix A contains more in-\\nformation about the dataset.\\n\\n4 Proposed Methodology\\nIn this section, we define the architecture and\\nthe structural details of our proposed framework,\\nQUARC.\\n\\nOur key insight is that a counterspeech\\ninstance can be decomposed into two distinct com-\\nponents \u2013 its semantics and intent. In particular,\\nwe can convey the semantics of the same counter-\\nspeech (which can be regarded as the compositional\\nmessage) in multiple manners, such as through hu-\\nmor, as a question, in an informative manner, etc.,\\ndepending upon the desired intent. More formally,\\ngiven the counterspeech $y_i$, the semantics $s_i$ and the\\nintent $c_i$, we posit that there exists a function\\n$\\\\zeta$ such\\nthat $y_i \\\\sim \\\\zeta(y_i | s_i, c_i)$.\\n\\nThe primary goal of our method is to learn contextually-\\nrich representations to seamlessly integrate the de-\\nsired intent information with the semantics of the\\ncounterspeech to yield effective intent-conditioned\\ncounterspeeches. To this end, we design a novel\\ntwo-phase training pipeline in which we attempt to\\nlearn the vector-quantized representations of each\\nintent and propose a fusion mechanism,\\nPerFuMe,\\nto integrate this information into the model.\\n\\nLet us denote the dataset $D = \\\\{(x_1, t_1, c_1, y_1), \\\\ldots, (x_n, t_n, c_n, y_n)\\\\}$, where $x_i$ denotes the\\n$i$th hate-speech instance, $t_i$ denotes\\nthe target of $x_i$, $y_i$ denotes the counterspeech\\ncorresponding to $x_i$, and $c_i$ denotes the cate-\\ngory/intent of $y_i$. Our end goal is to learn a\\nstochastic counterspeech generation function\\n$\\\\chi$, such that $y_i \\\\sim \\\\chi(\\\\cdot | x_i, c_i)$. We decompose this task\\ninto two phases, where we design two models:\\nCLIME and COGENT.\\n\\nCLIME is designed to learn\\nthe quantized codebook vectors corresponding\\nto each intent. This is done by learning a func-\\ntional mapping $\\\\zeta$, which aims to reconstruct the\\ncounter\\nspeech $y_i$ from its semantic encoding $z_{s_i}$ and the intent encoding\\n$e_{f_i}$ corresponding to $c_i$ as $\\\\hat{y}_i \\\\sim \\\\zeta(\\\\cdot | z_{s_i}, e_{f_i})$.\\n\\nFor COGENT, we utilize the\\nIntent Codebook $C$, assimilated through\\nCLIME to\\nlearn $\\\\chi$, which takes as input the semantic encoding\\nof the hate speech $x_{s_i}$, as well as the encoding of\\ndesired intent $e_{f_i}$, to yield $\\\\tilde{y}_i \\\\sim \\\\chi(\\\\cdot | x_{s_i}, e_{f_i})$. The\\noverall architecture is depicted in Figure 2.\\n\\n4.1 Codebook Learning Model (CLIME)\\nThe overall purpose of\\nCLIME is to learn the\\ncodebook representations for each intent category.\\nIt comprises two modules:\\nITEM and\\nQUINCE; ITEM is utilized to generate the semantic encoding,\\nwhile\\nQUINCE is utilized to procure the represen-\\ntation of the desired intent. The representations\\nobtained from these modules are passed through\\nour novel fusion mechanism,\\nPerFuMe, and the\\nemitted output is passed onto the decoder for the\\nreconstruction of the original counterspeech. Note\\nthat\\nCLIME does not utilize the hate speech in-\\nstance $x_i$, and solely works on the counterspeech\\n$y_i$ and its intent $c_i$ in a reconstructive fashion.\\n\\nIntent-Unaware Semantic Encoding Module (ITEM):\\nThe counterspeech $y_i$ is first tokenized\\ninto its sub-word embeddings $y_{t_i} \\\\in \\\\mathbb{R}^{n \\\\times D}$, where $n$ is the maximum input length and\\n$D$ is the latent di-\\nmension of the model. These embeddings are then\\npassed through the semantic encoder, $\\\\phi_s$, which\\nis parameterized by a BART encoder, to yield the\\nsemantic representation $z_{s_i} \\\\sim \\\\phi_s(z_{s_i} | y_{t_i}) \\\\in \\\\mathbb{R}^{n \\\\times D}$.\\n\\nIt is crucial that the information contained in\\n$z_{s_i}$ reflects\\nonly the semantics\\nof the counterspeech, and\\nnot the intent, in order to enable effective learning\\nof intent representations separately. If the intent\\ninformation were distilled within\\n$z_{s_i}$, the model\\nwould not need to rely on the codebook vector\\n$e_{f_i}$ to reconstruct the sample, rendering the learned in-\\ndent distribution trivial. To combat this, we train an\\nintent classification module on top of\\n$z_{s_i}$, and use a\\ngradient-reversal layer to expunge intent-specific\\ninformation from within\\n$z_{s_i}$. The intent classifier is\\ntrained jointly with the reconstruction module.\\n\\nQuantized Intent Encoding Module (QUINCE):\\nThe tokenized embedding $y_{t_i}$ is passed to the intent\\nencoder, $\\\\phi_i$ (parameterized by a BART encoder),\\nto obtain the form encoding,\\n$z_{f_i} \\\\sim \\\\phi_i(z_{f_i} | y_{t_i})$.\\n\\nTo\\nlearn a globally applicable quantized distribution\\nfor all intents, we employ a codebook similar to a\\nVQ-V AE (van den Oord et al., 2017). The intent-\"}"}
{"id": "acl-2023-long-318", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 2: Architecture of our proposed framework, QUARC, which consists of two phases. The first-phase model, CLIME, is composed of two core modules, ITEM and QUINCE, which are synchronised through the fusion module, PerFuMe, to learn the Intent Codebook via reconstruction. The second-phase model, COGENT, uses TREAD to learn the contextual semantic mapping from hate speech to counterspeech, and fuses it with the intent vector from the learnt Intent Codebook using PerFuMe to generate intent-conditioned counterspeeches.\\n\\nOur aim is to jointly learn the codebook for further utilization in generating intent-conditioned counter-speeches. We accomplish this by using the reconstruction objective as well as using a loss function similar to van den Oord et al. (2017), which moves the pooled version of $z_fi$ closer to the codebook vector $ef_i$ corresponding to $ci$ ($ef_i = C(ci)$), and vice versa, using a stop-gradient operator, $sg(.)$. $sg(.)$ is defined as identity and zero during forward and backward propagation, respectively. Since the semantic encoding $zs_i$ has had its intent-specific information stripped through the gradient reversal layer, this information must be distilled in the quantized $ef_i$ in order to facilitate effective reconstruction.\\n\\nReconstruction: The generated embeddings $zs_i$ and $ef_i$ (from ITEM and QUINCE, respectively) are then passed into our adaptive-gated fusion mechanism, PerFuMe to yield $zi \u2208 \\\\mathbb{R}^n \u00d7 D$. $zi$ is then given to the decoder as input to generate $\\\\hat{y}_i \u2248 \\\\zeta(\u00b7|zs_i,ef_i)$, the reconstructed output. We train the model by minimizing the negative log-likelihood of $\\\\hat{y}_i$ with respect to the reference $y_i$ as well as incorporating auxiliary losses from ITEM and QUINCE, as follows:\\n\\n$$L = \\\\mathbb{E}_{D}[-\\\\log p_\\\\zeta(\\\\cdot|zs_i,ef_i) + ||z_{fp,i} - sg(ef_i)||^2_2 + ||sg(z_{fp,i}) - ef_i||^2_2 + \\\\log p(c_i|zs_i)]$$ (1)\\n\\nwhere $zs_i \u223c \u03d5_s(\u00b7|y_i)$, $ef_i = C(ci)$, $z_{fp,i} = \\\\text{Pool}(z_{fi})$. \\n\\n4.2 Conditioned Counterspeech Generation Model (COGENT) The objective of the second phase is to generate counterspeeches that are conditioned on the desired intent, given an input hate speech. This is achieved through the utilization of COGENT, which comprises TREAD, a module designed to map the input hate speech $x_i$ to a semantic encoding of the counterspeech, which can then be fused with the codebook vector $ef_i$ corresponding to the specified intent as learned through CLIME. The following sections provide a more in-depth description of the functions of these modules.\\n\\nTarget-Aware Semantic Mapping Module (TREAD): The hate speech $x_i$ is passed through the semantic encoder $\u03d5_s$ to obtain its semantic representation $\\\\hat{x}_s_i \u223c \u03d5_s(\u00b7|x_i) \u2208 \\\\mathbb{R}^n \u00d7 D$. \u2013 Target Information Incorporation: Since the semantics of the hate speech should inherently possess discriminative characteristics to determine the intended target of hate speech, we explicitly strengthen $\\\\hat{x}_s_i$ by incorporating target category $t_i$ through a joint classification loss. $\\\\hat{x}_s_i$ is passed through a target classification module to yield $\\\\hat{t}_i \u2208 \\\\mathbb{R}^{|T|}$, where $|T|$ denotes the total number of target categories in the dataset. $\\\\hat{t}_i$ denotes the probability distribution over all targets for $x_i$ and is optimized via the negative log-likelihood loss with the actual target $t_i$. \u2013 Semantic Mapping: The semantic representation $\\\\hat{x}_s_i$ encompasses information about the semantics of hate speech; however, we require the semantics...\"}"}
{"id": "acl-2023-long-318", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of the corresponding counterspeech to coalesce with the desired intent. To facilitate this, we define a mapping function \\\\( \\\\xi \\\\), which maps the semantics of hate speech to the desired counterspeech as\\n\\\\[\\n\\\\hat{z}_{si} \\\\sim \\\\xi(\\\\cdot|\\\\hat{x}_{si}).\\n\\\\]\\nIn practice, \\\\( \\\\xi \\\\) is parameterized by a multi-layered Transformer Encoder (Vaswani et al., 2017), which is learned jointly. We term the parameterized version of \\\\( \\\\xi \\\\) as the contextual mapper.\\n\\nCounterspeech Generation: The semantic mapping of counterspeech, \\\\( \\\\hat{z}_{si} \\\\in \\\\mathbb{R}^{n \\\\times D} \\\\) is then fused with the codebook vector \\\\( e_{fi} \\\\) through PerFuMe and passed to the decoder to yield the generated counterspeech \\\\( \\\\tilde{y}_{i} \\\\sim \\\\chi(\\\\cdot|\\\\hat{z}_{si}, e_{fi}) \\\\in \\\\mathbb{R}^{n \\\\times D} \\\\).\\n\\nCOGENT is trained by minimizing the negative log-likelihood loss of generating \\\\( y_{i} \\\\), as well as the auxiliary target loss as follows:\\n\\\\[\\nL = \\\\mathbb{E}_{D}[-\\\\log p(y_{i}|\\\\hat{z}_{si}, e_{fi}) - \\\\log p(t_{i}|\\\\hat{x}_{si})],\\n\\\\]\\nwith \\\\( \\\\hat{x}_{si} \\\\sim \\\\phi_{s}(\\\\cdot|x_{i}) \\\\), \\\\( \\\\hat{z}_{si} \\\\sim \\\\xi(\\\\cdot|\\\\hat{x}_{si}) \\\\) and \\\\( e_{fi} = C(c_{i}) \\\\).\\n\\n4.3 Persistent Fusion Mechanism with Adaptive Gating (PerFuMe)\\nCoalescing intent-specific information with the semantics of a counterspeech can prove to be a challenging task as the model may not pay heed to the desired intent and generate a counterspeech that respects the desired semantics but has a different form than required. To address this problem, we propose PerFuMe, a persistent fusion module where we repeatedly synchronize the intent-encoded information with the semantic information to ensure that the desired form is not overlooked. We also enhance this fusion procedure with adaptive gating, where we design two distinct gates to control the degree of semantic and intent-specific information leveraged during integration.\\n\\nMore formally, let the semantic and intent-specific information be denoted by \\\\( z_{si} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\) and \\\\( e_{fi} \\\\in \\\\mathbb{R}^{1 \\\\times D} \\\\), respectively. \\\\( e_{fi} \\\\) is stacked on top of itself \\\\( N \\\\) times to obtain \\\\( \\\\tilde{e}_{fi} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\). We obtain \\\\( \\\\hat{z}_{i} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\) as:\\n\\\\[\\n\\\\hat{z}_{i} = a(...a((z_{si} \\\\oplus \\\\tilde{e}_{fi})W_{1} + b_{1}) \\\\oplus \\\\tilde{e}_{fi})W_{2} + b_{2}) \\\\cdots \\\\oplus \\\\tilde{e}_{fi})W_{k} + b_{k})(3)\\n\\\\]\\nwhere \\\\( a \\\\) denotes a non-linear activation function, \\\\( \\\\oplus \\\\) represents concatenation, \\\\( W_{1}, W_{2}, \\\\ldots W_{k} \\\\in \\\\mathbb{R}^{2D \\\\times D} \\\\), and \\\\( b_{1}, b_{2}, \\\\ldots b_{k} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\) are trainable matrices. We also introduce two gates, \\\\( s \\\\)-gate and \\\\( i \\\\)-gate, which control the flow of semantic and intent-specific information, respectively.\\n\\n\\\\[\\n\\\\mu_{s} = \\\\sigma(z_{si}W_{s1} + \\\\tilde{e}_{fi}W_{i2} + b_{s})\\n\\\\]\\n\\\\[\\n\\\\mu_{i} = \\\\sigma(z_{si}W_{s2} + \\\\tilde{e}_{fi}W_{i1} + b_{i})\\n\\\\]\\n(4)\\n\\\\[\\nW_{s1}, W_{s2}, W_{i1}, W_{i2} \\\\in \\\\mathbb{R}^{D \\\\times D}, \\\\text{ and } b_{s}, b_{i} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\text{ are trainable parameters.}\\n\\\\]\\n\\\\[\\nz_{sem} = \\\\mu_{s} \\\\odot z_{si} + (1 - \\\\mu_{s}) \\\\odot \\\\tilde{e}_{fi}\\n\\\\]\\n\\\\[\\nz_{int} = (1 - \\\\mu_{i}) \\\\odot z_{si} + \\\\mu_{i} \\\\odot \\\\tilde{e}_{fi}\\n\\\\]\\n(5)\\n\\\\[\\n\\\\text{where } \\\\odot \\\\text{ denotes the Hadamard product. Finally, we resolve the information obtained from s-gate (}z_{sem}, i-gate (}z_{int}) and the persistent fusion mechanism (}\\\\hat{z}_{i}) to produce the fused matrix \\\\( z_{i} \\\\in \\\\mathbb{R}^{N \\\\times D} \\\\).\\n\\n5 Experimental Setup and Results\\nIn this section, we delineate an exhaustive analysis of our model's performance and also carry out a predictive comparison against text generation models using both human and automatic evaluation.\\n\\nComparative Systems:\\n\u2022 Generate Prune Select (GPS) (Zhu and Bhat, 2021) uses a three-stage pipeline for generating counterspeeches. The first stage generates a large number of counterspeeches using an autoencoder architecture which is further pruned using a grammatical model. Finally, the most suitable counterspeeches are chosen for hate speech using a vector-based response selection model.\\n\u2022 Plug And Play Language Model (PPLM) (Dathathri et al., 2020) We utilize fine-tuned GPT-2 as the base language model for PPLM.\\n\u2022 In addition, we fine-tune DialoGPT (Zhang et al., 2020b) and BART (Lewis et al., 2020) on IntentCONAN as well. For all four comparative models, we provide the desired intent as prompt.\\n\\nEvaluation Metrics:\\nWe employ Rouge (Lin and Hovy, 2003) and Meteor (Banerjee and Lavie, 2005) scores to evaluate the syntactic correctness of the generated counterspeech. Given that Rouge and Meteor metrics primarily assess surface-level overlap, their standalone usage may not provide a comprehensive evaluation of the effectiveness of the generated counterspeech instances, considering the possibility of multiple correct outputs. To address this limitation, we augment these metrics by...\"}"}
{"id": "acl-2023-long-318", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Comparative results for QUARC. CI: Codebook Initialization; MB: Memory Bank.\\n\\nIncorporating measures of semantic richness and conducting thorough human evaluations to ensure a more comprehensive assessment. For semantic richness, we report BERTScore (BS) (Zhang et al., 2020a) along with cosine similarity (SS) obtained from a sentence-transformers model (all-miniLM-v2) (Reimers and Gurevych, 2019). Moreover, to check the efficacy of the models in incorporating the desired intent in the generated counterspeeches, we compute category accuracy (CA) through an intent classification (IC) model.\\n\\nResult Analysis: The results are reported in Table 3. We observe that QUARC beats the baselines across all metrics. In terms of lexical similarity, GPS is the best-performing baseline as it demonstrates high scores on R1, R2, RL, and Meteor. However, QUARC reports higher scores by a margin of ~10% on the syntactic similarity measures except for R2. On the semantic similarity measure, QUARC outperforms the best baseline (GPS) by ~2% and ~5% on BS and SS scores, respectively. This demonstrates the ability of our framework to generate semantically coherent counterspeeches to a given hate speech. In the context of generating intent-conditioned counterspeeches, CA evaluates the appropriateness of the generated counterspeeches. We observe that the majority of the baselines are notably inferior in producing outputs corresponding to the desired intent. For instance, while GPS is able to produce syntactically and semantically coherent outputs, it falls short in terms of accurately preserving the intended intent and is outperformed by our framework by 79%. Due to the explicit design of our pipeline, QUARC is able to efficaciously generate counterspeeches that preserve the desired intent (c.f. Appendix C).\\n\\nTo obtain a deeper insight into the performance of QUARC and the best baselines (GPS and BART), we compute novelty and diversity in line with Wang and Wan (2018) (c.f. Table 4). These metrics measure the lexical dissimilarity between the generated instances and the training corpus, as well as the dissimilarity between the generated instances themselves. They convey the degree of originality and variety in the generated text and can serve as an indicator of over-reliance on memorization of the training corpus or repetition of outputs. The scores achieved by QUARC (0.68 and 0.67) indicate a relatively higher degree of originality and variety in the generated text, while GPS exhibits the lowest scores across these metrics, indicating a tendency to memorize data from the training set and generate similar outputs more frequently. This might also be one of the reasons for its relatively high performance on similarity metrics. We must observe, however, that a high score on these metrics, when accompanied by a low semantic and syntactic similarity, marks that the generated outputs may not be entirely aligned with the intended ones.\\n\\nAblation Study: To dissect and identify the individual components that drive our framework, we perform multiple ablations on its architecture. In the standard version of QUARC, we initialize the codebook vectors by using the mean-pooled version of the representations of each intent obtained from an intent classifier. When we remove this initialization strategy and initialize the codebook vectors randomly for CLIME, we observe a slight drop-off in all metrics. However, when we retain this initialization strategy and directly use these vectors in COGENT without undergoing the first phase, a higher drop in almost all scores (except CA) is observed. The drop is especially high in diversity, which demonstrates that the generated texts have more repeated tokens across test samples, explaining the higher CA score as compared to the first ablation.\\n\\nWe performed another ablation in which we added a memory bank component to COGENT. We\"}"}
{"id": "acl-2023-long-318", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Qualitative evaluation. The intent and CS columns are appropriately labelled by human experts to assess the validity of outputs corresponding to the input intent and relevance to the specific hate speech.\\n\\n| Hate Speech | Desired CS | Intent | Counterspeech | Intent CS |\\n|-------------|------------|--------|---------------|-----------|\\n| H1 Every Muslim is a potential terrorist. | Positive | QUARC: Islam is a religion of peace and love. Muslims are not terrorists. They are just like us. | Positive | Yes |\\n| | | Best Baseline: How can you say a person is a potential terrorist? | | |\\n| | Denouncing | QUARC: What you are saying has nothing to do with Muslims. You are wrong to think that all Muslims are terrorists. | Denouncing | Yes |\\n| | | Best Baseline: Not all Muslims are Muslims. Ignoring all Muslims are peaceful citizens, but some people are terrorists. | | No |\\n\\nH2 Women are basically childlike, incapable of serious thought and emotion. |\\n\\n| Desired CS | Intent | Counterspeech | Intent CS |\\n|------------|--------|---------------|-----------|\\n| Informative | QUARC: There is no evidence that women are \u201cchildlike\u201d or \u201cignorant\u201d. Women are human beings with feelings and emotions. | Informative | Yes |\\n| | GPS: the problem is founded on the age of women to article rights, and society. Why is it possible for those in the world to take a world? | Question | No |\\n| | Humor | QUARC: So you think women are \u201cchildlike\u201d because they are incapable of thinking? | Question | Yes |\\n| | | GPS: Of course a woman won\u2019t remain a child most of her life. Otherwise you can\u2019t call them women. Your statement just reflects the patriarchy | Denouncing | Yes |\\n\\nQualitative Analysis:\\n\\nFor qualitative evaluation, we report the outputs of QUARC and the best baseline (GPS) for two instances in Table 5. In each case, we show the outputs for two desired CS intents. We observe that QUARC does a fair job in generating CS with the desired intents in three out of four cases, whereas the intents of generated CS in GPS align with the desired intent in only one out of four cases \u2013 even for the correct case, GPS produces an incoherent statement. For H2 with the desired humor intent, both QUARC and GPS commit mistakes for the intent (i.e., question for QUARC and denouncing for GPS); however, the output is a valid CS, ignoring the desired intent. Our analysis suggests that GPS and other baselines perform poorly in generating the desired intent-conditioned CS as compared to QUARC.\\n\\nHuman Evaluation:\\n\\nGiven the limitations of empirical evaluation in holistically assessing the efficacy of generation models, we conduct a comprehensive human evaluation on a random subset of the generated counterspeeches from QUARC and GPS (detailed instructions in Appendix E). The subset was uniformly distributed across intents. We ask our evaluators to rate the outputs on the following metrics:\\n\\n- Independent CS (IC) denotes whether the generated instance can be considered as CS without any context;\\n- Conditioned CS (CC) shows whether the generated output is an appropriate response to the given hate speech;\\n- Adequacy (A) depicts whether the generated CS is grammatically sound, coherent and fluent;\\n- Toxicity (T) indicates whether the output can be considered toxic.\\n\\nFor each of the above metrics, the evaluators are instructed to rate every counterspeech on a 5-point Likert scale. For example, considering the Toxicity metric (T), a score of 1 denotes that the counterspeech can be considered completely non-toxic, 3 denotes neutral and 5 denotes highly toxic.\\n\\nCategory Accuracy (CA) determines if the counterspeech adheres to the desired intent; here the evaluators are told to assign the counterspeech to one of the five intents to the best of their ability.\\n\\nThe results of the human evaluation (c.f. Table 6) indicate that QUARC outperforms the best baseline by a significant margin in all metrics except toxicity. These results demonstrate that the outputs generated by our model are not only more effectively recognized as counterspeeches but are also more appropriate responses to the given hate speech.\\n\\nA total of 60 evaluators in the field of NLP and social science participated, having ages between 20-30 years with a 60:40 male to female ratio.\"}"}
{"id": "acl-2023-long-318", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Model Human Evaluation Metric\\n\\nIC \u2191 CC\u2191 A \u2191 T \u2193 CA\u2191\\n\\nQUARC 3.69 3.76 4.10 2.42 0.7\\nGPS 3.16 3.04 3.32 2.30 0.1\\n\\nTable 6: Human evaluation on 5-point Likert scale (except for CA, which represents the proportion of counter-speeches with matching intents as annotated by evaluators).\\n\\nInformative Question Denouncing Positive Humor\\n\\n0.1 0.2 0.3\\n\\nImplicit Similarity\\n\\nI, D I, P\\nP, D\\nI, Q Q, H I, H Q, P\\nP, H\\n\\nI : Informative\\nQ : Question\\nP : Positive\\nH : Humor\\nD : Denouncing\\n\\nFigure 3: Left: A scatter plot of the codebook vectors (after dimensionality reduction) corresponding to different intents. Right: The Implicit Similarity (IS) between intent pairs captured through human evaluation.\\n\\nmore closely aligned with the intended response to the consumed hate speech. Moreover, the results attest to the efficacy of our intent-specific representation and fusion-based approach through the CA metric. We observe fair agreement (\u03ba = 0.32) on Fleiss' Kappa scale amongst the evaluators (Fleiss and Cohen, 1973).\\n\\nCongruence: We introduce Implicit Similarity (IS), a metric that utilizes implicit feedback from human evaluation to reflect the similarity between intent pairs. Intuitively, the core idea behind IS is that when different evaluators assign a different intent category to the same counterspeech, there exists a certain affinity between those categories. As an example, if evaluator A assigns the intent Informative to a counterspeech, and evaluator B assigns the intent Positive to the same counterspeech, then there exists a certain similarity between the intents Informative and Positive. The strength of this affinity can be approximated via its relative frequency of occurrence, and the method for its computation is described below.\\n\\nWe calculate IS for every possible intent pair; since there are 5 intents, there are a total of 5C2 = 10 distinct pairs. Let the counterspeech \\\\( y_i \\\\) be generated in response to the hate speech \\\\( x_i \\\\) with the desired intent \\\\( c_i \\\\). The human evaluators are asked to classify the intent of \\\\( y_i \\\\) from the defined set of 5 intents \u2013 \\\\{I_1, I_2, I_3, I_4, I_5\\\\} without knowledge of the actual intent \\\\( c_i \\\\). Each evaluator from the group of \\\\( N \\\\) evaluators assigns the intent for \\\\( y_i \\\\) and we obtain the relative frequency of the classified intents as \\\\( V_{i} = \\\\{I_1:v_i^1, I_2:v_i^2, I_3:v_i^3, I_4:v_i^4, I_5:v_i^5\\\\} \\\\), where \\\\( \\\\sum_{j=1}^{5} v_i^j = 1 \\\\), and \\\\( v_i^j \\\\) denotes the fraction of evaluators that assigned \\\\( y_i \\\\) to the intent class \\\\( I_j \\\\). The implicit similarity for a pair of intents \\\\( (I_a, I_b) \\\\) for the \\\\( i \\\\)th counterspeech is computed as\\n\\n\\\\[\\nIS_{a,b}^i = v_i^a \\\\times v_i^b \\\\times NS,\\n\\\\]\\n\\nwhere \\\\( NS = 4 \\\\) is the normalizing factor applied to standardize the range of \\\\( IS_{a,b}^i \\\\) to \\\\([0, 1]\\\\) (since the maximum value of \\\\( v_i^a \\\\times v_i^b \\\\) is 0.25).\\n\\n\\\\( IS_{a,b}^i \\\\) is indicative of the similarity between a pair of intents, as a higher value of \\\\( IS_{a,b}^i \\\\) deems that the same sample was assigned to both \\\\( I_a \\\\) and \\\\( I_b \\\\) consistently by evaluators (without knowledge of the desired \\\\( c_i \\\\)), and thus, there exists a certain affinity between these intent classes. Hence, we compute the overall implicit similarity between \\\\( (I_a, I_b) \\\\) for the set of \\\\( K \\\\) counterspeeches given to the human evaluators as\\n\\n\\\\[\\nIS_{a,b} = \\\\frac{\\\\sum_{k=1}^{K} IS_{a,b}^k}{K}.\\n\\\\]\\n\\nNote that IS is calculated without the knowledge of the desired intent \\\\( c_i \\\\) to provide a more faithful picture.\\n\\nWe plot the learnt representation of each intent category (after dimensionality reduction through PCA) along with the computed IS scores (Figure 3). We note that the IS scores closely align with the distances between the learnt representations. This congruence not only demonstrates the robustness of the learnt representations, but also provides a key insight into a critical factor behind the superior performance of QUARC (more details in Appendix D).\\n\\n6 Conclusion\\n\\nIn an effort to address the pervasive issue of hateful speech on the internet, we proposed the novel task of intent-conditioned counterspeech generation. We developed IntentCONAN, the first intent-specific dataset for diverse counterspeech generation. Further, to benchmark the dataset, we proposed a novel framework (QUARC) that decomposes the task into two phases \u2013 CLIME learns the intent distribution which is subsequently leveraged by COGENT to generate the intent-conditioned counterspeeches. We conducted an extensive evaluation (i.e., empirical, qualitative, and human) to establish the effectiveness of QUARC.\\n\\nAcknowledgement\\n\\nAuthors acknowledge the partial support of Logically and Infosys Center of AI (CAI), IIIT Delhi.\"}"}
{"id": "acl-2023-long-318", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Limitations\\n\\nThe current work marks the first step towards intent-conditioned counterspeech generation, and as we noted, even though our model excels in fluency, a larger and more diverse dataset paired with knowledge grounding is necessary to improve and ensure factual correctness. Although the annotators kept the quality of counterspeech as high as possible, it is possible that this data is not at par with other datasets that are annotated by more skilled NGO operators, as is the case with the Multi-Target CONAN dataset (Fanton et al., 2021). A more large-scale annotation of our dataset with higher instances for under-represented target communities would hence be beneficial to learn more accurate distributions of every counterspeech class. Another limitation of the current work is that it exhibits a slightly higher-degree of toxicity compared to the baseline. It, therefore, pertains to accounting for lowering the amount of toxicity present in the generated counterspeeches as future research. Lastly, humor in counterspeech is a very subjective topic, and inspite of including only a few datapoints from that class as compared to the others in our dataset, it is likely that QUARC could generate vague and/or offensive text under the pretext of humor. We intend on keeping the dataset private and only provide access for research and educational purposes.\\n\\nEthics Statement\\n\\nWe recognize that combating online hate speech can be a delicate matter, and we fully acknowledge that research in this domain might raise ethical and moral concerns. This work is simply the beginning of efforts to create a consistent and diversified compendium of counterspeeches for every hateful instance. We also agree that models used to automate counterspeech could end up producing factually erroneous statements, and a more efficient method of incorporating real-world knowledge into these models is required. On the other hand, even if generative models could perform well, there is still a pressing need for a large-scale counterspeech dataset with a more diversified response pool to ensure a net positive outcome. Furthermore, while a deployable model for counterspeech is not completely feasible as of now, there are organizations like United Against Hate who are making considerable contributions to mitigate hate online.\\n\\nReferences\\n\\nMd. Rabiul Awal, Rui Cao, Roy Ka-Wei Lee, and Sandra Mitrovic. 2021. Angrybert: Joint learning target and emotion for hate speech detection. In Advances in Knowledge Discovery and Data Mining - 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11-14, 2021, Proceedings, Part I, volume 12712 of Lecture Notes in Computer Science, pages 701\u2013713. Springer.\\n\\nSatanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65\u201372, Ann Arbor, Michigan. Association for Computational Linguistics.\\n\\nSusan Benesch, Derek Ruths, Kelly P Dillon, Haji Mohammad Saleem, and Lucas Wright. 2016. Considerations for Successful Counterspeech. Dangerous Speech Project.\\n\\nRui Cao, Roy Ka-Wei Lee, and Tuan-Anh Hoang. 2021. Deepfate: Hate speech detection via multi-faceted text representations. CoRR, abs/2103.11799.\\n\\nTanmoy Chakraborty and Sarah Masud. 2022. Nipping in the bud: detection, diffusion and mitigation of hate speech on social media. SIGWEB Newsl., 2022(Winter):3:1\u20133:9.\\n\\nEshwar Chandrasekaran, Umashanthi Pavalanathan, Anirudh Srinivasan, Adam Glynn, Jacob Eisenstein, and Eric Gilbert. 2017. You Can\u2019t Stay Here: The Efficacy of Reddit\u2019s 2015 Ban Examined Through Hate Speech. Proc. ACM Hum.-Comput. Interact., 1(CSCW).\\n\\nNaganna Chetty and Sreejith Alathur. 2018. Hate Speech Review in the Context of Online Social Networks. Aggression and violent behavior, 40:108\u2013118.\\n\\nYi-Ling Chung, Elizaveta Kuzmenko, Serra Sinem Tekiroglu, and Marco Guerini. 2019. CONAN - COunter NArratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2819\u20132829, Florence, Italy. Association for Computational Linguistics.\\n\\nSumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. 2020. Plug and Play Language Models: A Simple Approach to Controlled Text Generation. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\"}"}
{"id": "acl-2023-long-318", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Margherita Fanton, Helena Bonaldi, Serra Sinem Tekiro\u011flu, and Marco Guerini. 2021. Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3226\u20133240, Online. Association for Computational Linguistics.\\n\\nJoseph L. Fleiss and Jacob Cohen. 1973. The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability. Educational and Psychological Measurement, 33(3):613\u2013619.\\n\\nDominik Hangartner, Gloria Gennaro, Sary Alasiri, Nicholas Bahrich, Alexandra Bornhoft, Joseph Boucher, Buket Buse Demirci, Laurenz Derksen, Aldo Hall, Matthias Jochum, et al. 2021. Empathy-Based Counterspeech Can Reduce Racist Hate Speech in a Social Media Field Experiment. Proceedings of the National Academy of Sciences, 118(50):e2116310118.\\n\\nNitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. CTRL: A conditional transformer language model for controllable generation. arXiv Computing Research Repository (CoRR), abs/1909.05858.\\n\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871\u20137880, Online. Association for Computational Linguistics.\\n\\nChin-Yew Lin and Eduard Hovy. 2003. Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 150\u2013157.\\n\\nZhaojiang Lin, Andrea Madotto, Yejin Bang, and Pascale Fung. 2021. The Adapter-Bot: All-In-One Controllable Conversational Model. Proceedings of the AAAI Conference on Artificial Intelligence, 35(18):16081\u201316083.\\n\\nSarah Masud, Manjot Bedi, Mohammad Aflah Khan, Md. Shad Akhtar, and Tanmoy Chakraborty. 2022. Proactively reducing the hate intensity of online posts via hate speech normalization. In KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022, pages 3524\u20133534. ACM.\\n\\nBinny Mathew, Punyajoy Saha, Hardik Tharad, Subham Rajgaria, Prajwal Singhania, Suman Kalyan Maity, Pawan Goyal, and Animesh Mukherjee. 2019. Thou Shalt Not Hate: Countering Online Hate Speech. In Proceedings of the 13th International AAAI Conference on Web and Social Media, volume 13, pages 369\u2013380, Munich, Germany.\\n\\nMainack Mondal, Leandro Ara\u00fajo Silva, and Fabr\u00edcio Benevenuto. 2017. A Measurement Study of Hate Speech in Social Media. In Proceedings of the 28th ACM Conference on Hypertext and Social Media, HT \u201917, page 85\u201394, New York, NY, USA. Association for Computing Machinery.\\n\\nJing Qian, Anna Bethke, Yinyin Liu, Elizabeth Belding, and William Yang Wang. 2019. A Benchmark Dataset for Learning to Intervene in Online Hate Speech. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4755\u20134764, Hong Kong, China. Association for Computational Linguistics.\\n\\nNils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.\\n\\nPunyajoy Saha, Kanishk Singh, Adarsh Kumar, Binny Mathew, and Animesh Mukherjee. 2022. CounteGeDi: A Controllable Approach to Generate Polite, Detoxified and Emotional Counterspeech. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22, pages 5157\u20135163, Vienna, Austria. International Joint Conferences on Artificial Intelligence Organization.\\n\\nCarla Schieb and Mike Preuss. 2016. Governing Hate Speech By Means of Counterspeech on Facebook. In Proceedings The 66th Annual Conference of the International Communication Association, pages 1\u201323, Fukuoka, Japan.\\n\\nSerra Sinem Tekiro\u011flu, Yi-Ling Chung, and Marco Guerini. 2020. Generating Counter Narratives against Online Hate Speech: Data and Strategies. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1177\u20131190, Online. Association for Computational Linguistics.\\n\\nAaron van den Oord, Oriol Vinyals, and koray kavukcuoglu. 2017. Neural Discrete Representation Learning. In Advances in Neural Information Processing Systems, volume 30, Long Beach, CA. Curran Associates, Inc.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All...\"}"}
{"id": "acl-2023-long-318", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ke Wang and Xiaojun Wan. 2018. SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, pages 4446\u20134452, Stockholm, Sweden. International Joint Conferences on Artificial Intelligence Organization.\\n\\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierrick Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-Art Natural Language Processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online. Association for Computational Linguistics.\\n\\nLucas Wright, Derek Ruths, Kelly P Dillon, Haji Mohammad Saleem, and Susan Benesch. 2017. Vectors for Counterspeech on Twitter. In Proceedings of the First Workshop on Abusive Language Online, pages 57\u201362, Vancouver, BC, Canada. Association for Computational Linguistics.\\n\\nZeqiu Wu, Michel Galley, Chris Brockett, Yizhe Zhang, Xiang Gao, Chris Quirk, Rik Koncel-Kedziorski, Jianfeng Gao, Hannaneh Hajishirzi, Mari Ostendorf, and Bill Dolan. 2021. A Controllable Model of Grounded Response Generation. Proceedings of the AAAI Conference on Artificial Intelligence, (16):14085\u201314093.\\n\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020a. BERTScore: Evaluating Text Generation with BERT. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia.\\n\\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020b. \\\"DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation\\\". In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270\u2013278, Online. Association for Computational Linguistics.\\n\\nWanzheng Zhu and Suma Bhat. 2021. \\\"Generate, Prune, Select: A Pipeline for Counterspeech Generation against Online Hate Speech\\\". In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 134\u2013149, Online. Association for Computational Linguistics.\"}"}
{"id": "acl-2023-long-318", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Dataset\\n\\nA.1 Objectives for the Annotators\\n\\nFollowing are the guidelines strictly adhered to by the annotators while constructing counterspeeches for the five intents:\\n\\nInformative Counterspeech:\\nInformative or Factual statements are the most popular form of counterspeech in which a counterspeech seeks to debunk or fact-check the claims made by the attacker. We found some instances of counterspeech in the CONAN dataset which were inconsistent with the definition of facts, a few being:\\n\\n(HS) \u201cDon\u2019t the Moslem\u2019s Holy books say \u2018kill infidels wherever they may be hiding\u2019\u201d\\n(CS) No, it doesn\u2019t.\\n(HS) \u201cMuslims are the ones who invented the slave trade.\u201d\\n(CS) Slavery has been rampant in early societies of all kinds. I am sure the Romans did not take inspiration for their slave trade directly from Muslims.\\n\\nTherefore, to ensure the validity of the counterspeeches without having to fact-check every statement from the Multi-Target CONAN dataset, we decide to rename the class to \u201cInformative Counterspeech\u201d; this seems more apt, and makes writing counterspeeches for our annotators easier. Furthermore, because our annotators were unfamiliar with facts from each target community, we relied on official sources like Red Cross, The Holocaust Encyclopedia, RAINN, The Anti-Defamation League, Brookings, and credible news sources like CNN, HuffingtonPost (among others) to verify that the annotations were factually correct as far as possible for this class.\\n\\nQuestioning Counterspeech:\\nFor this class, the annotators were instructed to frame countermeasures in the form of questions that would challenge the speaker\u2019s chain of reasoning and compel them to either answer convincingly or recant their original remark. If necessary, factual information was to be obtained from a pre-determined pool of data sources, as indicated in the preceding section.\\n\\nDenouncing Counterspeech:\\nThis category of counterspeech needed to be handled with caution, as denouncing can sometimes be used to propagate obscene language. Our annotators were directed to convey the impression that the opinions put forth by the hate speaker are not acceptable without using name-calling or profanity.\\n\\nHumorous Counterspeech:\\nA heated dispute or discussion can be effectively defused by humor and sarcasm (Mathew et al., 2019). By highlighting how absurd it is, humor undercuts the hate speech and aids in diverting the attention of those following the dialogue online. Annotators were asked to construct a sentence that would not incite resentment from other users while also making sure that it would not contain any controversial ideas or terms. It should be mentioned that the annotators had prior knowledge of the sarcasm and humour that are well-received on social media.\\n\\nPositive Counterspeech:\\nThe use of empathy and positive reinforcement in hate speech can lead to a decline in online animosity (Hangartner et al., 2021). Regardless of the severity of the hate speech, the annotators make an effort to compose a courteous, polite, and civil statement. Furthermore, we argue that if bystanders who are following the discourse online are a member of the group impacted by the comment, they would be instilled with a sense of support and humanness.\\n\\nA.2 Dataset Statistics\\n\\nFigure 4 gives an overview of our dataset: IntentCONAN. Figures 4a and 4b show the distributions of the target communities in the hate speech and intents across the counterspeeches, respectively.\\n\\nFor a more fine-grained perspective, Figure 4c and 4d show the uniform distributions of intents in the data splits and the intents across target communities. Figures 4e and 4f depicts the average token lengths for the five intent classes and eight target communities.\\n\\nB Additional Details on Experiments\\n\\nExperimental Setup:\\nAll the experiments were performed using a Tesla V100 and an RTX A6000.\"}"}
{"id": "acl-2023-long-318", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Visual exploration of various attribute distributions present within IntentCONAN.\\n\\nGPU. Our model (and the BART baseline) was trained for 20 epochs with the initial learning rate of 8e-5 using AdamW as the optimizer and a linear scheduler, with 10% of the total steps as warm-up having a weight decay of 0.03. Training the model took an average time of 3 hours with a batch size of 32, and the model with the best validation loss was employed for testing. We used the base version of BART (140M parameters) from the transformers library (Wolf et al., 2020) for parameterizing both $\\\\phi_s$ and $\\\\phi_i$. The baselines were trained using the recommended hyperparameter settings. To compute the ROUGE score, we use the rouge library in python with the default arguments, we compute METEOR through nltk (bir), semantic similarity by using the all-miniLM-v2 model from the sentence-transformers library (Reimers and Gurevych, 2019) and BERTScore using the original bert-score library. To check the efficacy of the models in incorporating the desired intent in the generated counterspeeches, we train an Intent Classification (IC) model on IntentCONAN for intent classification of each counterspeech instance, which achieves 75% accuracy on the test set for classification (we utilize the base version of RoBERTa). The IC model is used to classify whether the generated counterspeeches are compatible with the desired intent, and the accuracy obtained across the generated samples is reported as the category accuracy.\\n\\nC Analysis of Intent-Conditioning\\n\\nIn order to systematically evaluate the effects of intent conditioning, we begin by analyzing the accuracy of the IC model for each intent separately. The results are depicted in Figure 5. From the bar chart, we observe that the accuracy of the intents \u2013 informative and question, is higher than the other intents, while humor displays the lowest accuracy. To obtain a more comprehensive understanding, the confusion matrix illustrates that the intents denouncing and positive tend to be recognized as informative by the IC model in some cases, while humor can also be recognized as informative and denouncing. Since the IC model is susceptible to errors, it is hard to say with certainty whether the generated counterspeech belongs to the desired intent, or whether the model has misclassified it. Hence, we utilize the confusion matrices from human evaluation and design a new metric in the next section for analyzing the intent conditioning due to the inherent reliability of human evaluators.\\n\\nD Interpretability and Robustness of Intent Representations\\n\\nA key advantage afforded by our approach is the exploration of interpretability, which is enabled by our paradigm of learning the intent representations separately. The intent representations illustrated in Figure 3 (left) depict that the intents positive and denouncing are both mapped closely to informative, and are slightly farther away from each other, while question and humor are considerably distant to all other intents. This observation is further supported by computing the cosine similarity in the original dimension of the representations (Fig. 7c). To assess the robustness of the obtained representations, we use implicit feedback from human evaluations to gauge the similarity between intents. We employ two strategies: (i) we design a new metric, Implicit Similarity (IS) to compute the similarity between pairs of intents implicitly through human evaluation responses without the knowledge of the actual intent; (ii) we utilize the intent information and use the confusion matrices obtained from human evaluation (Fig 6a) for this purpose. We plot the IS values for each intent pair in Figure 7. The IS scores for the pairs (I,D) and (I,P) are the highest, followed by the pair (P,D),...\"}"}
{"id": "acl-2023-long-318", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":true,\"natural_text\":\"(a) A fine-grained analysis of intent identification accuracy of the generated outputs from QUARC on the test set as per the IC model.\\n\\n(b) Confusion matrix depicting the intent classification (from the IC model) of the generated outputs from QUARC.\\n\\nFigure 5: Automated evaluation of CA from the IC model for all intents. Note that informative and question achieve the highest accuracy demonstrating that QUARC is able to generate them more effectively than, say, humor, which achieves a relatively lower accuracy.\\n\\n(b) Confusion matrix of the human evaluation for QUARC.\\n\\nFigure 6: Human evaluation heatmaps for QUARC and GPS. The rows represent the desired intent (the input given to the models) and the columns denote the intent labeled by human evaluators. Darker shade denotes a higher frequency of identification. For QUARC, all intents but humor are generally identifiable, while GPS is unable to condition on any intent effectively.\\n\\nExplicit Similarity through Human Evaluation: To further analyze the intent representations, we also utilize the desired intent \\\\(c_i\\\\) to generate the confusion matrices for human evaluation in Figure 6. We observe a similar pattern to that observed through IS, as we can see that the bottom-right \\\\(3 \\\\times 3\\\\) square has a darker shade as compared to the rest of the matrix, denoting that the Informative, Positive and denouncing intents are closer together when compared to other pairings.\\n\\nE Human Evaluation\\n\\nThe evaluators recruited were well-versed in the field of NLP and social media. The form provided to them contained the descriptions of terminology such as Hate Speech and Counterspeech, and Intents. For further clarity, a few lines of description for each intent along with an example were also shown. The form also included information on the format of the questionnaire; the evaluators were made aware of how the evaluation data would be used in the study and were warned against the possibility of encountering foul or offensive language that could be upsetting.\\n\\nAnalysis: As shown in Figure 6, our model generates intent-identifiable outputs across all intents, with the exception of the humor, where the outputs were often assigned to denouncing. Conversely, GPS fails to effectively condition on intent, as evidenced by the mismatch between desired and obtained intents, with decent performance only on informative, perhaps due to its prevalence in the training set.\\n\\nTable 1: Accuracy of intent identification for QUARC and GPS.\"}"}
{"id": "acl-2023-long-318", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 7: Analysis and visualization of intent representations through: (a) dimensionality reduction to a 2-D space for plotting; (b) cosine similarity computed in the original dimension space of the representations. The similarity between informative, positive, and denouncing is higher as compared to other intents. (c) The IS scores are closely aligned with the closeness of the representations in (a) and cosine similarities in (b). This serves to inform that the quantized representations learnt for each intent are demonstrably sound due to their similarity with human feedback.\"}"}
