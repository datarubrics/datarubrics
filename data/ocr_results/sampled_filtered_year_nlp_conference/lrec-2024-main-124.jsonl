{"id": "lrec-2024-main-124", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Appraisal Framework for Clinical Empathy: A Novel Application to Breaking Bad News Conversations\\n\\nAllison Lahnala, B\u00e9la Neuendorf, Alexander Thomin, Charles Welch, Tina Stibane, Lucie Flek\\n\\nConversational AI and Social Analytics (CAISA) Lab, University of Bonn, Germany\\nMarburg Interactive Skills Lab (MARIS), Dr. Reinfried Pohl-Centre for Medical Education\\nPhilipps-University Marburg, Germany\\n{alahnala, lflek}@uni-bonn.de\\n\\nAbstract\\nEmpathy is essential in healthcare communication. We introduce an annotation approach that draws on well-established frameworks for clinical empathy and breaking bad news (BBN) conversations for considering the interactive dynamics of discourse relations. We construct Empathy in BBNs, a span-relation task dataset of simulated BBN conversations in German, using our annotation scheme, in collaboration with a large medical school to support research on educational tools for medical didactics. The annotation is based on 1) Pounds (2011)'s appraisal framework for clinical empathy, which is grounded in systemic functional linguistics, and 2) the SPIKES protocol for breaking bad news (Baile et al., 2000), commonly taught in medical didactics training. This approach presents novel opportunities to study clinical empathic behavior and enables the training of models to detect causal relations involving empathy, a highly desirable feature of systems that can provide feedback to medical professionals in training. We present illustrative examples, discuss applications of the annotation scheme, and insights we can draw from the framework.\\n\\nKeywords: clinical empathy, empathy annotation scheme, breaking bad news dialogues\\n\\n1. Introduction\\nEmpathy in medical encounters is considered a core element to high-quality patient care and an important skill to develop in medical training (Bonvicini et al., 2009; Dey and Girju, 2022). Theoretical models of clinical empathy suggest it fosters more open patient-clinician communication for more deeply understanding patients and their conditions, providing valuable information for diagnosis and addressing therapeutic needs. In turn, this leads to better treatment strategies and adherence, therapeutic outcomes, and higher patient satisfaction (Squier, 1990; Neumann et al., 2009; Pounds, 2011), and proper empathy can be intrinsically therapeutic (Suchman et al., 1997).\\n\\nEmpathy is crucial to breaking bad news conversations (BBNs), scenarios where a clinician must inform the patient about life-altering circumstances. Clinicians frequently must deliver bad news to patients, a high-stress and complex communication task (Baile et al., 2000). Many medical students must pass formal BBN training, an area where digital tools have the potential to support students via automated feedback and practice with virtual standardized patients (Borish et al., 2014; Lok and Foster, 2019; Reger et al., 2021). Models informed by clinical empathy could be made more transparent and explainable, leading to higher quality feedback on empathic responses or suggestions via an interface that suits their learning needs (Tanana et al., 2019; Girju and Girju, 2022). Natural language processing (NLP) researchers are currently exploring models for automatic empathy detection and generation, which are essential for such tools.\\n\\nObjectives: We introduce a new annotation scheme for clinical empathy communication in patient-clinician conversations, guided by three key objectives. First, we aim to identify precise discouragement elements and their dynamic interactions that constitute empathic successes and failures during these exchanges. Second, we aim to provide a novel structural representation of empathic conversations that can support addressing existing shortcomings of NLP models for empathy, which struggle in identifying finer-level empathy components and utilizing the broader conversational context necessary for accurate evaluation (Lee et al., 2023). Third, we aim to complement established pedagogical methods for training communication skills for breaking bad news conversations by integrating SPIKES, a protocol for breaking bad news commonly taught in medical didactics training (Baile et al., 2000).\\n\\nMethod Overview: We address these goals through a span-relation labeling method. Central to the scheme is identifying interactional sequences formally defined by Suchman et al. (1997)'s model of empathic communication in medical conversations. These sequences encompass three elements: 1) empathic opportunities (EO) in patient turns, 2) elicitation of such opportunities, and 3) empathic responses within clinician turns. We label specific spans of patient and clinician turns...\"}"}
{"id": "lrec-2024-main-124", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"containing one of these three elements according to Pounds (2011)'s appraisal framework for clinical empathy (AF) which defines types of EOs and responses based on linguistic aspects (see \u00a73.1).\\n\\nThe scheme provides two further innovations. After labeling the spans, we create relations between identified empathic opportunities and the identified elicitations and empathic responses that correspond to them. Furthermore, we incorporate the structure of BBN conversations by labeling the six stages of BBN conversations defined by the SPIKES protocol within the clinician turns (see \u00a73.2). This integration aligns the appraisal framework with the stages of BBN conversations, facilitating the examination of communicative strategies employed at each stage and informing the development of NLP models for digital training tools.\\n\\nThe BBN Empathy Dataset: Finally, as part of a collaboration between NLP researchers and medical didactics experts at large medical school to support research on educational tools for medical didactics, we construct a dataset of BBN conversations annotated with the new scheme. The dataset contains practice BBN conversations between medical students and standardized patients and fine-grained annotations of the componentsof empathic interactions. The BBN Empathy Dataset is the first dataset to contain discourse labels and relations for clinical empathy, which we make public for other researchers.\\n\\nSummary of Contributions: We contribute 1) an innovative annotation scheme for clinical empathy 2) made available on an open-source platform for other researchers (\u00a73), and 3) a public dataset of annotated BBN dialogues (\u00a74).\\n\\n2. Related work\\n\\nDigital tools have the potential to support training medical professionals in empathetic communication in ways such as offering communication practice with virtual standardized patients (Borish et al., 2014; Lok and Foster, 2019; Reger et al., 2021), assessing the quality of empathetic responses, and providing feedback on empathic responses or suggestions via an interface that suits their learning needs (Tanana et al., 2019; Girju and Girju, 2022). These tools require effective NLP models of empathic language and conversational behaviors. In NLP, there is current momentum toward models for empathy detection and generation. Recognition is the task of determining the presence (Sharma et al., 2020; Hosseini and Caragea, 2021) or degree of empathy (Buechel et al., 2018) or subtypes of empathic behaviors (Welivita and Pu, 2020; Svikhnushina et al., 2022). Detection models can be designed to evaluate empathic language and identify improvement areas to provide feedback (Wambsganss et al., 2021). Generative models attempt to generate a text response that is empathetic to a conversational partner. Research on generative models has focused on applications to open-domain dialogue (Rashkin et al., 2019), customer support (Firdaus et al., 2020), and counseling (Shen et al., 2020). Generative models can be designed to deliver feedback and provide suggestions for empathetic responses. For example, Sharma et al. (2021) developed a model for \u201cempathic rewriting\u201d to provide suggestions that increase the level of empathy in a given text, an approach that could support students in reflecting on ways to improve their empathic communication.\\n\\nDespite the progress, current shortcomings in this research include poor operationalization of empathy, tending to employ only abstract notions focused on emotional aspects and overlooking cognitive and behavioral aspects, and a lack of empathic language resources that incorporate these dimensions. These issues are exasperated by lacking measurements with construct validity (Lahnala et al., 2022). In turn, models trained on widely available datasets, such as the empathic dialogues dataset which grounds empathetic engagement in specific emotional situations, could help reveal patterns of emotional understanding, but this is only one facet of the empathy concept (Debnath and Conlan, 2023). Thus, such models are limited in providing detailed and reliable assessments, explanations of the relation between EOs and empathic responses, or validated guidance for developing clinical empathy skills. However, NLP can draw from extensive research in psychology and linguistics, which has empirically studied theoretical models of clinical empathy and measurement approaches.\\n\\nThough they are still few, NLP studies exploring tools for training and education in empathetic communication have generally integrated insights from these fields, often in collaborations with psychologists. For example, Wambsganss et al. (2021, 2022) investigate the effectiveness of digital empathy training tools in enhancing students' empathetic communication skills when writing peer feedback. Other work focuses on applications for psychotherapy (Imel et al., 2017), examining for instance, linguistic behaviors that signal empathy and session quality in Motivational Interviewing conversations (P\u00e9rez-Rosas et al., 2017, 2018, 2019), and crisis counseling conversations (Zhang and Danescu-Niculescu-Mizil, 2020; Zhang et al., 2020).\\n\\nSome recent NLP studies on clinical empathy started integrating linguistic theories and discourse analysis approaches. Dey and Girju (2022) cre-\"}"}
{"id": "lrec-2024-main-124", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ated a corpus of medical students' essays about breaking bad news to patients with sentence-level labels of cognitive, affective, and prosocial empathy. They built a novel system architecture informed by frame semantics (Baker et al., 1998) that outperformed state-of-the-art empathy classification models. On the same dataset, Dey and Girju (2023) showed that incorporating features of Construction Grammar (Michaelis, 2006) and Systemic Functional Grammar (Halliday and Matthiessen, 2013) also improves deep learning models for empathy classification. Shi et al. (2021) also demonstrated the potential of the discourse annotation resources to improve empathy NLP models. Nevertheless, creating clinical dialogue datasets with quality clinical empathy annotations suitable for training NLP models requires expertise, labor, and ethics and privacy protections.\\n\\nTo address the described shortcomings, we contribute a novel dataset of annotated clinical empathy in breaking bad news conversations, an annotation method based on a linguistic framework for structured analysis of clinical empathy, and a framework of communication strategies for BBNs developed by medical experts. We tailor these resources to support the development of NLP models that can be integrated with digital training tools. Related work outside of NLP has also used discourse analysis approaches to identify strategies in clinical BBN conversations (Pun, 2021). Recently, Rey Velasco et al. (2022) applied SFL approaches and Pounds (2011)'s clinical empathy framework to asynchronous health interactions, revealing insights into implicit/explicit EOs and their relationship to trust between healthcare providers and patients. To our knowledge, this work is the first to apply Pounds (2011)'s framework to live conversations and BBN scenarios, which we make public to support NLP research.\\n\\n### 3. Annotation Scheme\\n\\n#### 3.1. Appraisal Framework\\n\\n#### Background and Motivation.\\n\\nEmpathic opportunities (EOs) are expressions or behaviors that reveal a patient's feelings or views, which can be either explicit or implicit (Suchman et al., 1997).\\n\\nExplicit empathic opportunities directly reveal a patient's feelings or attitude via explicit expressions of behavior or emotive behaviors (e.g., crying).\\n\\nImplicit empathic opportunities are defined as \u201cpatient statements from which a clinician might infer an underlying emotion that has not been explicitly expressed\u201d (Suchman et al., 1997).\\n\\nThe appraisal framework for clinical empathy extends Suchman et al. (1997)'s model of clinical empathic communication (Pounds, 2011), by integrating a finer-grained taxonomy that categorizes EOs and doctor responses based on the linguistic functions of attitudinal expression. It draws on insights from Wynn and Wynn (2006)'s linguistic research on interactional sequences that build empathy in psychotherapy settings, and Martin and White (2005)'s appraisal framework, a systemic functional linguistics (SFL) approach to discourse analysis (Halliday and Matthiessen, 2013) that concerns the interpersonal, interactive functions of language in specific social settings. The framework aligns various linguistic functions with components of attitudinal expression within empathic communication in order to gain insights that support the teaching of empathic communication skills. The three dimensions of attitudinal expression are Feeling (i.e., affect), Judgment of oneself or other people, and Appreciation; an attitude or perception toward things, events, actions, and behaviors.\\n\\nPrevious research observed that clinicians often overlook empathic opportunities, hindering effective, satisfactory communication with patients (Levinson et al., 2000; Hsu et al., 2012). Moreover, Suchman et al. (1997) finds implicit EOs are more common in a medical interview than explicit empathic opportunities. As implicit EOs are hidden in patients' expressions, they are particularly challenging to identify and infer. Thus, the ability to model explicit and implicit EOs is an important step toward digital tools that support communicative skills training for BBNs. By developing a dataset of EOs and their relations to clinician expressions, not only do we enable training such NLP models, but we also provide a resource for investigating linguistic aspects that could add to the body of knowledge about BBN conversation strategies. This resource contributes to ongoing efforts in broader NLP empathy research seeking multidimensional representations of empathy, including affective and cognitive empathy and empathic behaviors (Lahnala et al., 2022). The segments of inferred implicit EOs provide opportunities, especially to better understand cognitive empathy, and can be leveraged in research on abductive social reasoning (Bhagavatula et al., 2020; Zhao et al., 2023).\\n\\nAs we present the framework, we provide descriptions and examples inspired Pounds (2011).\\n\\n#### Categories of Empathic Opportunities\\n\\nTable 1 contains examples and descriptions of the Feelings, Judgments, and Appreciations categories of explicit and implicit EOs, yielding six possible labels to apply to EO spans. Explicit EOs are directly observable in the patient's expressions and behaviors. Implicit EOs can be explored by the clinician to more deeply understand patient views and can lead to explicit EOs and a better consensus on empathic accuracy, which informs the clinician's...\"}"}
{"id": "lrec-2024-main-124", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Patient Role: Empathic Opportunities\\n\\nExplicit\\n\\nFeelings\\n- Describing or exhibiting emotion quality: \u201cI\u2019m sad\u201d\\n- Emotive behavior: \u201cI cried\u201d or \u201cI laughed\u201d\\n- Mental state: \u201cI\u2019m in pain\u201d or \u201cI feel alone\u201d\\n\\nImplicit\\n- May occur through expression of judgment or appreciation.\\n- Implicitly expresses feeling or perception by referring to:\\n  - Negative experiences: \u201cMy aunt had the same condition. She was in a lot of pain, and she didn\u2019t make it\u201d (fear)\\n  - Critical life stages and experiences: \u201cEverything was going well...I just started my master\u2019s thesis\u201d (surprise/disbelief)\\n\\nAppreciation\\n- Attitude or perception toward things, events, actions, and behaviors, e.g.\\n  - Event: \u201cThe MRI was boring,\u201d\\n  - Thing: \u201cThe medication is not helping me.\u201d\\n\\nJudgement\\n- Attitude or perception toward:\\n  - Self: \u201cI\u2019m not good at medication adherence\u201d\\n  - Others: \u201cThe nurses weren\u2019t helpful\u201d\\n\\nImplicit\\n- Indirectly conveys attitude or perception toward things, events, actions, and behaviors that a clinician may infer and explore:\\n  - Thing: \u201cMy symptoms don\u2019t seem to improve with the medication.\u201d\\n\\nClinician Role: Elicitations\\n\\nDirect\\n\\nFeelings\\n- Inquiring directly about the patient\u2019s emotions or mental state: \u201cHow do you feel about that?\u201d\\n- Emotive behaviors: \u201cWhat was your reaction?\u201d\\n\\nAppreciation\\n- Directly asking the patient about appreciation of things, events, actions, or behaviors:\\n  - Event: \u201cHow was the MRI for you?\u201d\\n  - Thing: \u201cDo you find the medication helpful?\u201d\\n\\nJudgement\\n- Asking the patient about judgement of:\\n  - Self: \u201cDo you think you are a good father?\u201d\\n  - Others: \u201cWas the nurse helpful?\u201d\\n\\nIndirect\\nInquire about behaviors or make statements that convey clinician\u2019s interpretation, which invites the patient to confirm, reject, or clarify:\\n- \u201cSo you\u2019re worried that the treatment won\u2019t work.\u201d\\n- \u201cSo the nurse was not very helpful then?\u201d\\n\\nTable 1: Description and examples of explicit and implicit functions (feeling, appreciation, judgement) in patients, representing empathic opportunities.\\n\\nTable 2: Description and examples of explicit and implicit functions (feeling, appreciation, judgement) in clinicians in how they elicit empathic opportunities.\"}"}
{"id": "lrec-2024-main-124", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Clinician Role: Responding to Patient Cues\\n\\nUnconditional Positive Regard\\n\\nAcceptance\\n\\nExplicit Positive Judgement\\n\\nImplicit Positive Judgement\\n\\nExpression of positive judgment of the patient as a person\\n\\n\u2022 \u201cYou are a reasonable parent\u201d\\n\u2022 \u201cYou\u2019re very responsible\u201d\\n\\nExpression of a judgement of the patient\u2019s thoughts or feelings\\n\\n\u2022 \u201cIt\u2019s really great that you\u2019ve been taking care of your parents\u201d\\n\u2022 \u201cIt sounds like you\u2019ve been working hard to improve your health\u201d\\n\\nRepetition\\n\\nAllowing Full Expression\\n\\nRepeating or paraphrasing the patient\u2019s words without countering statements or premature reassurance\\n\\n\u2022 (patient says they\u2019re worried about cancer spread) \u201cI understand you\u2019re worried about the cancer spreading\u201d\\n\\nAllowing patients to express feelings and views fully through minimal responses, nodding, and avoidance of interruption\\n\\nNeutral Support\\n\\nExplicit Appreciation\\n\\nExplicit Judgement\\n\\nAppreciation of ideas, feelings, or behaviors regarding the patient\u2019s normality or acceptability\\n\\n\u2022 \u201cIt\u2019s completely normal to be upset about this\u201d\\n\u2022 \u201cIt wouldn\u2019t be surprising to feel that way\u201d\\n\\nDenying negative self-assessment by the patient\\n\\n\u2022 \u201cYou\u2019re not crazy for being worried about that\u201d\\n\u2022 \u201cIt\u2019s not bad to be thinking about these things\u201d\\n\\nSharing\\n\\nSharing patient views or feelings through expressed agreement\\n\\n\u2022 \u201cI\u2019m sure I would also feel anxious in this situation if I were going through everything you have going on right now\u201d\\n\u2022 \u201cYes, this medication really does not taste good\u201d\\n\u2022 \u201cOh, no!\u201d\\n\\nUnderstanding\\n\\nUnderstanding and acknowledgement of the patient\u2019s views and feelings can be expressed directly as acknowledgement or interpretations\\n\\n\u2022 \u201cI get the sense that you found the other doctor unhelpful\u201d\\n\u2022 \u201cI see that the medication isn\u2019t working for you\u201d\\n\u2022 \u201cI understand that you\u2019re worried about infections and perhaps that makes you anxious\u201d\\n\\nTable 3: Descriptions and examples of categories of clinician responses to patient cues/empathic opportunities.\\n\\nThe former are expressions of positive judgment of the patient. Opportunities for such praise are possible when patients similarly show positive self-judgment. Neutral support can take the form of explicit appreciation or judgement; helping the patient understand their feelings are justified.\\n\\nRelations form Interactional Sequences\\n\\nHere, we describe different types of interactional sequences, observable via the relations drawn between empathic opportunities and elicitations or empathic responses.\\n\\nEmpathic response sequences are cases when an EO is directly linked to an empathic response that explicitly recognizes the attitudes conveyed in the EO.\\n\\nEO continuer sequences involve a \u201cpotential EO continuer\u201d that facilitates further exploration, which can lead to more explicit empathic opportunities, help the clinician gain more insight, increasing empathic understanding (Suchman et al., 1997). These are identifiable via span relationships that form a sequence of implicit EOs, elicitations, and explicit EOs.\\n\\nEO terminating sequences involve an empathic opportunity terminator, when a clinician directs the conversation away from an explicit EO in the patient\u2019s prior turn, or a potential EO terminator, which occurs after implicit empathic opportunities when the clinician does not explore the implied feeling via further elicitations, instead directing the conversation away from implied cues. The scenario in \u00a75 demonstrates examples of missed EOs.\\n\\n3.2. SPIKES Protocol\\n\\nBackground and Motivation.\\n\\nSPIKES is a pedagogical tool commonly employed for training medical students\u2019 communication skills for BBN scenarios. It provides a high-level conversation structure and communication strategies to help manage a BBN conversation compassionately while fulfilling four objectives: 1) gathering information from the patient; 2) transmitting the medical information; 3) providing support to the patient; and 4) eliciting the patient\u2019s collaboration in developing a strategy or treatment plan for the future (Baile et al., 2000).\\n\\nPrevious work observed significant increases in confidence in handling aspects of BBN conversations for medical students and faculty trained with the protocol. Mahendiran et al. (2023), similarly, found that it improved learner satisfaction, performance, and knowledge.\\n\\nCoding SPIKES stages.\\n\\nThe protocol contains six steps: (1) Establish a comfortable, private Setting, at a time free from interruptions, and determine the participants (e.g., a patient\u2019s support person). (2) Develop an understanding of the patient\u2019s Perception of their situation (i.e., what knowledge and feelings about it do they already have). (3) Determine the amount of information the patient is ready to hear by seeking their Invitation to provide...\"}"}
{"id": "lrec-2024-main-124", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"(4) Deliver the Knowledge (i.e., the information containing the bad news) clearly and compassionately. (5) Respond to the patient's reactions with Empathy. (6) Strategy and Summary: Discuss treatment strategies and follow-up steps, which can involve the Invitation step once more to determine how/when these are discussed. Concerning the empathic response of point (5), the SPIKES protocol provides a 4-step guide to responding empathetically, which can involve multiple turns exchanged between the patient and clinician. These include 1) observing and 2) identifying the type of reaction or emotion the patient is experiencing (asking open questions as necessary), 3) identifying the emotion reason, and 4) responding in a way that reflects the clinician's understanding and legitimizes the patient's feelings.\\n\\nExcept Empathy, which is covered by the appraisal framework labels, each of the SPIKES stages is labeled on clinician turns or segments of the clinician turns when identifiable. We note that Setting is rarely applied given that much of the behaviors involved in this stage occur prior to the BBN conversation.\\n\\n3.3. Annotation Procedure\\n\\nPlatform Integration. Our scheme is integrated in INCEpTION (Klie et al., 2018), an open-source tool for semantic annotations that supports labeling text spans and relations. We setup custom layers for each. The annotator highlights a text segment and selects a coarse-grained span category (EOs, EO elicitations, EO responses, and SPIKES) for the span. This opens tags representing the fine-grained labels for the selected category which the annotator then applies as the span label.\\n\\nAnnotator Training. Two native German speakers were trained to perform the annotations in three 1-hour sessions. The training included background on SFL, a tutorial on the full coding manual, additional training materials involving real samples for demonstration and practice applying the coding scheme, and a tutorial on the annotation tool. We explain how to approach the analysis and labeling throughout example scenarios in \u00a75.\\n\\nAfter the training sessions, the annotators performed three calibration rounds on dialogues that they coded independently. We met as a group to discuss the source of disagreements between annotators. The primary source in the first round was distinguishing between Judgments and Appreciations, which we clarified and added further examples with explanations to the coding manual. After this, the agreement improved in the subsequent calibration rounds. In those rounds, the main challenge related to identifying the implicit EOs. Some disagreements on this aspect are reasonable, as it requires the annotator to make their own inferences, which can vary subjectively. However, during our discussions, we reached a consensus for most implicit EOs. We met weekly to review coding conventions, clarify questions, and discuss specific cases throughout the months of the annotations. We present an analysis of interannotator agreement post-training and calibration in the next section.\\n\\n4. The BBN Empathy Dataset\\n\\nThe BBN Empathy Dataset is constructed via a collaboration with medical didactics experts at a large medical school. The dialogues are practice BBN conversations between medical students taking part in a medical didactics seminar and trained standardized patient actors. These simulate BBN scenarios as realistically as possible for student practice. They take place in rooms modeling medical environments, such as a doctor's office or a hospital bed. During the seminar, the students are trained in BBN communication skills with the SPIKES Protocol (\u00a73.2). The standardized patients are provided a role description and background for the scenario, and the students are provided a full scenario description and patient history. The scenarios included delivering cancer diagnoses, failures of treatments for serious diseases, and informing a family member of a severe accident, among others. We collected a total of 63 conversations in German over two semesters of the seminar. Four trained native German speakers transcribe them (see Appendices A and B for transcription and annotator details). Though these are practice conversations, we anonymize the names of the participants.\\n\\n4.1. Agreement Study\\n\\nAfter training and the calibration rounds, the annotators independently coded eight dialogues. For these, we study the interannotator agreement on the text spans and span labels.\\n\\nText span agreement. We measure the interannotator agreement on the text spans labeled by the annotators at the string level based on Wiebe et al. (2005)'s approach shown in Equation 1.\\n\\n$$\\\\text{agr}(a\\\\mid\\\\mid b) = \\\\frac{|A \\\\cap B|}{|A|}$$\"}"}
{"id": "lrec-2024-main-124", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A and B are the sets of spans highlighted by annotator a and b respectively. $\\\\text{agr}(a||b)$ is the proportion of text marked by annotator a that b marked, and $\\\\text{agr}(b||a)$ is the proportion of text marked by b that a marked. $\\\\text{agr}$ is the mean of both measures.\\n\\nAs with Wiebe et al. (2005)'s span labeling task, $\\\\text{agr}$ is a suitable metric for text span agreement for our task because we do not employ nor instruct strict rules about the precision of the text boundaries. The main concern, rather, is whether the annotators mark the same general expression. Example (1) shows a case where for turn $t$, annotator A marked an additional clause not marked by B, but the expression is generally the same in terms of the appraisals they convey.\\n\\n(1)\\n\\nA $t$: \u00c4hm, okay, Operation?\\n\\n$B t$: Okay, also das, das muss raus, oder was?\\n\\nEnglish: Um, okay, surgery? Okay, so that, that has to come out, or what?\\n\\nHere, $\\\\text{agr}(a||b) = 0.65$ and $\\\\text{agr}(b||a) = 1.0$. In example (2), $\\\\text{agr}(a||b) = 0.94$ and $\\\\text{agr}(b||a) = 0.86$.\\n\\nBold indicates the text was marked by both annotators and bold and italic are spans marked by only one annotator.\\n\\nFirst, we compute $\\\\text{agr}$ for each turn. Then, we take the average across all turns to get the $\\\\text{agr}$ for a dialogue. Table 4 shows the $\\\\text{agr}$ metrics for each dialogue and the means across all eight. The agreement on all spans improved notably between dialogue 0 and 1, which is due to our continued discussions after each dialogue annotation which focused on general clarifications about the scheme and coding conventions rather than resolving disagreements. In our analysis, we observed small differences between the annotator's choice to include punctuations and short subclauses in the annotations. Overall, the annotators match the same general expression.\\n\\nSpan label agreement. As a first point of reference, we computed Krippendorff's $\\\\alpha$ for all labels (strict) and report them in Table 4. We also study agreement on the span labels by computing $\\\\text{agr}$.\\n\\n| Dialogue | $\\\\text{agr}(a||b)$ | $\\\\text{agr}(b||a)$ | $\\\\alpha$ |\\n|----------|--------------------|--------------------|---------|\\n| Calibration Dialogues | | | |\\n| 1 | .789 | .738 | .840 | .30 |\\n| 2 | .910 | .850 | .970 | .43 |\\n| 3 | .902 | .844 | .960 | .47 |\\n| 4 | .952 | .923 | .981 | .50 |\\n| 5 | .931 | .865 | .997 | .58 |\\n| 6 | .912 | .935 | .890 | .63 |\\n| 7 | .905 | .948 | .862 | .85 |\\n| 8 | .948 | .933 | .963 | .89 |\\n| Mean | .92 \u00b1 .02 | .90 \u00b1 .04 | .95 \u00b1 .04 |\\n\\n| All Dialogues | $\\\\text{agr}(a||b)$ | $\\\\text{agr}(b||a)$ | $\\\\alpha$ |\\n|---------------|--------------------|--------------------|---------|\\n| Mean | .97 \u00b1 .03 | .96 \u00b1 .05 | .98 \u00b1 .03 |\\n\\nTable 4: Span text agreement for each of the eight calibration dialogues and the mean agreement with standard deviations across all 63 dialogues. The right column shows the span label agreement measured by Krippendorff's $\\\\alpha$.\\n\\n$\\\\text{agr}(a||b)$ represents annotator b's precision evaluated against annotator a's labels and $\\\\text{agr}(b||a)$ is a's with respect to b. We compute these metrics by a strict evaluation denoted by $\\\\cup$, which includes spans where there was no overlap between annotators, and by a matched evaluation denoted by $\\\\cap$, which includes spans where there was overlap.\"}"}
{"id": "lrec-2024-main-124", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As noted, the annotators improved their text span agreement after dialogue 1 following further clarifications. We observed a stark contrast in the agreements between dialogue 1 and the other dialogues. Dialogue 1 had very low $\\\\cap$ on the span labels: $\\\\cap$ for all labels was 0.5; AF coarse-grained and SPIKES $\\\\cap$ agreements were 0.85 and 0.60 respectively; the rest ranged from 0.22 (AF fine $\\\\cap$) to 0.38 (AF attitude $\\\\cap$). Meanwhile, the label agreements across the rest improved; Table 5 shows the mean values. We find that the annotators generally perform well at matching each other. Disagreement was mostly between implicit feelings and other implicit labels or explicit judgement. Implicit responses are more subjective or difficult to interpret. For SPIKES, the most common disagreement was between the invitation and knowledge steps, as determining how much the patient is ready to hear may be part of the step of delivering that information. After we reached substantial agreement across all categories, the remaining dialogues are annotated by one annotator and revised for quality by the other (see Table 9 in Appendix C for overall agreement).\\n\\n### Table 6: Counts of each type of Empathic Opportunity (EO) label and each type of EO Elicitation label from each annotator (A and B). For EOs, both annotators identified significantly more implicit rather than explicit feelings, whereas they identified more explicit than implicit appreciations and judgements. Implicit feeling is the most common type of EO. Both annotators identify more direct rather than indirect EO elicitations.\\n\\n| Patient Role: Empathic Opportunities | Explicit | Implicit |\\n|--------------------------------------|----------|----------|\\n| A                                    | 248      | 1043     |\\n| B                                    | 203      | 1146     |\\n| Feelings                             | 608      | 180      |\\n| Appreciation                         | 618      | 178      |\\n| Judgement                            | 991      | 135      |\\n|                                     | 107      | 107      |\\n|                                     | 203      | 172      |\\n|                                     | 149      | 96       |\\n| Clinician Role: Empathic Elicitations| Direct   | Indirect |\\n| Explicit                              | 151      | 40       |\\n| Appreciation                         | 149      | 89       |\\n\\n### Table 7: Counts of each type of Empathic Response label from each annotator (A and B). With all sublabels, unconditional positive regard is the most common response type, the most frequent among them being explicit positive judgement and explicit appreciation. Understanding rather than sharing feelings and views is more common; here, understanding feelings is most frequently observed.\\n\\n| Clinician Role: Empathic Responses   | Acceptance | Uncond. Positive Regard |\\n|--------------------------------------|------------|-------------------------|\\n| Explicit Positive Judgement          | 374        | 454                     |\\n| Implicit Positive Judgement          | 143        | 109                     |\\n| Repetition - no counter              | 31         | 27                      |\\n| Allowing Full Expression             | 156        | 184                     |\\n| Neutral Support                       | 185        | 141                     |\\n| Explicit Appreciation                | 373        | 405                     |\\n| Explicit Judgement                   | 185        | 141                     |\\n\\n### Table 8: The percentage of EOs by EO type that had no response or an EO response linked by a relation. The rate of responses is higher for implicit EOs than explicit EOs. The percentages broken down by response type are shown in Figure 1 in Appendix C.\\n\\n| EO type               | No Response | EO Response |\\n|-----------------------|-------------|-------------|\\n| Exp. Feel             | 35.4        | 64.6        |\\n| Imp. Feel             | 27.8        | 72.2        |\\n| Exp. Appreciate       | 46.9        | 53.1        |\\n| Imp. Appreciate       | 36.5        | 63.5        |\\n| Exp. Judge            | 34.3        | 65.7        |\\n| Imp. Judge            | 27.3        | 72.7        |\\n\\nWe quantify the relations between patient EOs and clinician responses, showing the percentage of EOs that are linked to responses in Table 8. Interestingly, we observe that the implicit EOs have a higher rate of clinician responses than explicit EOs. Explicit appreciations and judgements are more frequently identified than implicit ones. As the annotators remarked on the difficulty with identifying appreciations and judgements compared to feelings, it may be that observing the clinicians' responses aids the annotator in observing the implicit EOs, thus biasing the relation rates. However, the higher response rate to implicit EOs is also the case for feelings, for which implicit cases are more frequently marked. Future work could investigate\"}"}
{"id": "lrec-2024-main-124", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The possible effects further by testing the annotation scheme in a setup in which the identified EOs are locked before observing the rest of the dialogue.\\n\\nFigure 1 in Appendix C shows the percentages broken down by each EO response type. We observe higher proportions of relations between EOs and EO responses of the same attitude type.\\n\\n5. How do I tell my family?\\n\\nHere we present an illustrative example with our annotation scheme.\\n\\nContext.\\nA physician informs a patient that an MRI, performed as part of an anonymous research study, detected a mass in their brain. The patient is in disbelief, as they did not expect a follow-up and had no previous cause for concern, suggesting that the physician had mistaken the results for someone else's.\\n\\nScenario.\\nThe physician allows the patient to experience shock and express disbelief implicitly by denying that the results could indeed be for them (Implicit Feeling EO). The physician identifies the emotion of disbelief and responds, \u201cYou can\u2019t believe it quite yet, I have a feeling.\u201d The first clause is the physician\u2019s interpretation of how the patient feels (Understanding/Acknowledgement). The second serves to soften the delivery of the interpretation and to formulate the statement as an indirect elicitation: Feeling and/or Appreciation.\\n\\nThe patient speaks more openly, sharing that everything was going great for them. They state, \u201cIt is probably not easy. If there\u2019s really something there, it won\u2019t just go away on its own.\u201d This could signal that the patient is accepting the news. One may interpret this as an implicit EO, inferring a negative Appreciation that treatment will be difficult and a negative Feeling (anxiety/fear). The physician acknowledges the patient\u2019s view, confirming treatment probably will not be easy (empathic response: Acceptance, neutral support). The patient asks if, theoretically, one can die from such a mass; an implicit EO: Feeling (fear of severity/uncertainty).\\n\\nThe physician confirms this but says further analysis must clarify the type and severity. This balances the SPIKES/BBN principles of honesty and lending hope, delivering Knowledge clearly and compassionately.\\n\\nLater, the patient shares that their aunt had had a brain tumor a few years earlier, describing a quick escalation that was painful and fatal. The loss weighs heavily on the family. We consider this turn to have implicit EOs: negative Feeling (signaling fear/worry) and Appreciation (of this significant event in the family). The physician responds, saying it does not mean the patient\u2019s case will be the same. While aspects of this response reflect SPIKES/BBN principles (e.g., lending hope, attempting to reduce a sense of isolation), it is also an EO terminator since it directs the conversation away from the implicit EOs. The patient\u2019s underlying perspectives that this story communicates become clearer as the dialogue continues, suggesting there were indeed missed EOs.\\n\\nAfter the physician\u2019s response, the patient immediately expresses anxiety about telling their family, asking how to break the news, implying concern for how the family will react. The physician misses this EO, responding \u201cyou can figure that out for yourself.\u201d The patient asks again what to do, saying that they cannot simply go home and tell their family they might have cancer (implicit EOs: negative Feeling (anxiety) and Appreciation (anticipating significant difficulty in informing their family)). The physician says nothing, perhaps allowing space for the patient\u2019s emotive behaviors. As the conversation continues, the patient continues to express the same sentiment about their aunt and not knowing how to tell their family, EOs that are repeatedly missed by the physician.\\n\\n6. Conclusions and Future Work\\n\\nWe pursued three core objectives toward modeling clinical empathy in patient-clinician conversations:\\n\\n1) Develop an annotation scheme for labeling precise discourse elements and their relations in clinical empathy encounters; 2) Produce a structural representation of the dynamics of these elements over a full conversation toward addressing current shortcomings of NLP models for empathic interactions; and 3) Tailor the approach for medical didactics research for training empathic communication skills in BBN conversations. We developed a span-relation labeling method based on models of interactional sequences and semantic exchanges in clinical empathy conversations. This establishes links between empathic opportunities and empathic responses, enabling analysis of types of interactional sequences that achieve empathy. In addition, we produce the BBN Empathy dataset, the first of its kind curating discourse-level annotations tailored to clinical empathy, which is publicly available for fellow researchers. These contributions will foster open research and interdisciplinary collaboration addressing critical aspects of empathic communication in healthcare contexts.\\n\\nFuture work will explore the linguistic components of the discourse elements through computational linguistic analyses. We also plan to investigate dynamic models of the interactional sequences to study their impacts on empathic understanding. In addition, future work can investigate NLP models trained on the BBN Empathy dataset for supporting scaling up such resources in collaboration with trained human annotators.\"}"}
{"id": "lrec-2024-main-124", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. Acknowledgements\\n\\nWe sincerely thank research assistants Lilly Beil and Lilly Metten for their high-quality work on both the transcriptions and annotations, Maceo Kita and Lea Fischbach for their assistance in transcribing the dataset, and Ulvi Shukurzade for his support with the annotation tool. This work has been supported by the German Federal Ministry of Education and Research (BMBF) as a part of the Junior Scientists program under reference 01-S20060 and by the Humboldt Foundation through the Fellowship of Dr. Welch.\\n\\n8. Limitations\\n\\nWe acknowledge there may be unknown effects that the simulated scenarios have on the dialogues. Further research could investigate artifacts of the simulated scenarios and how this might affect future approaches. Although we see progress in applying the SPIKES protocol and its pedagogical benefits, there is still room for improvement, especially as SPIKES does not specify higher-level aspects of the interaction or the patient's role in the conversation, which an appraisal framework for clinician empathy helps address.\\n\\nThe Patient Perspective.\\n\\nHere, we discuss insights from studies on the patient perspective that may imply limitations of SPIKES that may warrant further research. Assessing patients' preferences for BBN communication and their perception and satisfaction of actual BBN disclosures, Seifart et al. (2014) administered the Marburg Breaking Bad News Scale (MABBAN), a questionnaire based on the SPIKES protocol, to 350 cancer patients. They observe that only 46.2% of the patients are fully satisfied by how the bad news was broken to them and that there is a highly significant discrepancy between the patients' preferences for receiving bad news and the actual disclosure. Furthermore, they find that the overall patient's satisfaction with the first BBN disclosure significantly correlates with their emotional state, including depression, anxiety, and sleeplessness, after receiving the bad news. von Blanckenburg et al. (2020) later administered MABBAN to 336 cancer patients. Analyzing its psychometric properties, they observed an accordance between the SPIKES protocol and the MABBAN scale, suggesting that SPIKES meets the preferences of German cancer patients. The study emphasizes that differentiated communication of BBN is highly important due to discrepancies in patient preferences.\\n\\nEthics Statement\\n\\nThis research and dataset were evaluated and approved by an IRB at Philipps-University Marburg, Germany, for the purpose of the initial annotation study and NLP experiments. For privacy considerations, the examples are adaptations of observed exchanges of parts of BBN dialogues, and all content is significantly summarized or paraphrased, including quotes (i.e., they do not portray the full context, nor are any part of the scenarios used directly verbatim).\\n\\n8. Bibliographical References\\n\\nWalter F. Baile, Robert Buckman, Renato Lenzi, Gary Glober, Estela A. Beale, and Andrzej P. Kudelka. 2000. SPIKES\u2014A Six-Step Protocol for Delivering Bad News: Application to the Patient with Cancer. The Oncologist, 5(4):302\u2013311.\\n\\nCollin F Baker, Charles J Fillmore, and John B Lowe. 1998. The Berkeley FrameNet Project. In COLING 1998 Volume 1: The 17th International Conference on Computational Linguistics.\\n\\nChandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen tau Yih, and Yejin Choi. 2020. Abductive commonsense reasoning. In International Conference on Learning Representations.\\n\\nKathleen A Bonvicini, Michael J Perlin, Carma L Bylund, Gregory Carroll, Ruby A Rouse, and Michael G Goldstein. 2009. Impact of communication training on physician expression of empathy in patient encounters. Patient Education and Counseling, 75(1):3\u201310.\\n\\nMichael Borish, Andrew Cordar, Adriana Foster, Thomas Kim, James Murphy, and Benjamin Lok. 2014. Utilizing real-time human-assisted virtual humans to increase real-world interaction empathy. Kansei Engineering & Emotion Research (KEER'14), 15.\\n\\nSven Buechel, Anneke Buffone, Barry Slaff, Lyle Ungar, and Jo\u00e3o Sedoc. 2018. Modeling empathy and distress in reaction to news stories. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4758\u20134765, Brussels, Belgium. Association for Computational Linguistics.\\n\\nAlok Debnath and Owen Conlan. 2023. A critical analysis of empathetic dialogues as a corpus for empathetic engagement. In Proceedings of...\"}"}
{"id": "lrec-2024-main-124", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Priyanka Dey and Roxana Girju. 2022. Enriching deep learning with frame semantics for empathy classification in medical narrative essays. In Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI), pages 207\u2013217, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.\\n\\nPriyanka Dey and Roxana Girju. 2023. Investigating stylistic profiles for the task of empathy classification in medical narrative essays. In Proceedings of the First International Workshop on Construction Grammars and NLP (CxGs+NLP, GURT/SyntaxFest 2023), pages 63\u201374, Washington, D.C. Association for Computational Linguistics.\\n\\nMauajama Firdaus, Asif Ekbal, and Pushpak Bhattacharya. 2020. Incorporating politeness across languages in customer care responses: Towards building a multi-lingual empathetic dialogue agent. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 4172\u20134182, Marseille, France. European Language Resources Association.\\n\\nRoxana Girju and Marina Girju. 2022. Design considerations for an NLP-driven empathy and emotion interface for clinician training via telemedicine. In Proceedings of the Second Workshop on Bridging Human\u2013Computer Interaction and Natural Language Processing, pages 21\u201327, Seattle, Washington. Association for Computational Linguistics.\\n\\nMichael Alexander Kirkwood Halliday and Christian MIM Matthiessen. 2013. Halliday's introduction to functional grammar. Routledge.\\n\\nMahshid Hosseini and Cornelia Caragea. 2021. Distilling knowledge for empathy detection. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3713\u20133724, Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nIan Hsu, Somnath Saha, Phillip Todd Korthuis, Victoria Sharp, Jonathon Cohn, Richard D. Moore, and Mary Catherine Beach. 2012. Providing support to patients in emotional encounters: A new perspective on missed empathic opportunities. Patient Education and Counseling, 88(3):436\u2013442. Patients, providers, and relationships in health care: investigations from the ICCH 2011 conference in Chicago.\\n\\nZac E Imel, Derek D Caperton, Michael Tanana, and David C Atkins. 2017. Technology-enhanced human interaction in psychotherapy. Journal of counseling psychology, 64(4):385.\\n\\nJan-Christoph Klie, Michael Bugert, Beto Boullosa, Richard Eckart de Castilho, and Iryna Gurevych. 2018. The inception platform: Machine-assisted and knowledge-oriented interactive annotation. In Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, pages 5\u20139. Association for Computational Linguistics. Event Title: The 27th International Conference on Computational Linguistics (COLING 2018).\\n\\nAllison Lahnala, Charles Welch, David Jurgens, and Lucie Flek. 2022. A critical reflection and forward perspective on empathy and natural language processing. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2139\u20132158, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\\n\\nAndrew Lee, Jonathan Kummerfeld, Larry An, and Rada Mihalcea. 2023. Empathy identification systems are not accurately accounting for context. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 1686\u20131695, Dubrovnik, Croatia. Association for Computational Linguistics.\\n\\nWendy Levinson, Rita Gorawara-Bhat, and Jennifer Lamb. 2000. A Study of Patient Clues and Physician Responses in Primary Care and Surgical Settings. JAMA, 284(8):1021\u20131027.\\n\\nBenjamin Lok and Adriana E. Foster. 2019. Can Virtual Humans Teach Empathy?, pages 143\u2013163. Springer International Publishing, Cham.\\n\\nMeera Mahendiran, Herman Yeung, Samantha Rossi, Houman Khosravani, and Giulia-Anna Perri. 2023. Evaluating the effectiveness of the spikes model to break bad news\u2013a systematic review. American Journal of Hospice and Palliative Medicine\u00ae.\\n\\nJ. R. Martin and P. R. R. White. 2005. The Language of Evaluation. Palgrave Macmillan UK, London.\\n\\nLaura A Michaelis. 2006. Construction grammar. The encyclopedia of language and linguistics, 3:73\u201384.\\n\\nMelanie Neumann, Jozien Bensing, Stewart Mercer, Nicole Ernstmann, Oliver Ommen, and Holger Pfaff. 2009. Analyzing the \\\"nature\\\" and \\\"specific effectiveness\\\" of clinical empathy: A theoretical overview and contribution towards a theory-based research agenda. Patient Education and Counseling.\"}"}
{"id": "lrec-2024-main-124", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ver\u00f3nica P\u00e9rez-Rosas, Rada Mihalcea, Kenneth Resnicow, Satinder Singh, and Lawrence An. 2017. Understanding and predicting empathic behavior in counseling therapy. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1426\u20131435, Vancouver, Canada. Association for Computational Linguistics.\\n\\nVer\u00f3nica P\u00e9rez-Rosas, Xuetong Sun, Christy Li, Yuchen Wang, Kenneth Resnicow, and Rada Mihalcea. 2018. Analyzing the quality of counseling conversations: the tell-tale signs of high-quality counseling. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).\\n\\nVer\u00f3nica P\u00e9rez-Rosas, Xinyi Wu, Kenneth Resnicow, and Rada Mihalcea. 2019. What makes a good counselor? learning to distinguish between high-quality and low-quality counseling conversations. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 926\u2013935, Florence, Italy. Association for Computational Linguistics.\\n\\nGabrina Pounds. 2011. Empathy as \u201cappraisal\u201d: developing a new language-based approach to the exploration of clinical empathy. Journal of Applied Linguistics and Professional Practice, 7(2):139\u2013162.\\n\\nJack Pun. 2021. A study of Chinese medical students' communication pattern in delivering bad news: an ethnographic discourse analysis approach. BMC Medical Education, 21(1):286.\\n\\nAlec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2023. Robust speech recognition via large-scale weak supervision. In International Conference on Machine Learning, pages 28492\u201328518. PMLR.\\n\\nHannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan Boureau. 2019. Towards empathetic open-domain conversation models: A new benchmark and dataset. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5370\u20135381, Florence, Italy. Association for Computational Linguistics.\\n\\nGreg M Reger, Aaron M Norr, Michael A Gramlich, and Jennifer M Buchman. 2021. Virtual standardized patients for mental health education. Current Psychiatry Reports, 23:1\u20137.\\n\\nElena Rey Velasco, Hanne S\u00e6derup Pedersen, Timothy Skinner, et al. 2022. Analysis of patient cues in asynchronous health interactions: Pilot study combining empathy appraisal and systemic functional linguistics. JMIR Formative Research, 6(12):e40058.\\n\\nCarola Seifart, Mareike Hofmann, Tobias B\u00e4r, J Ri\u00e9ra Knorrenschild, Ulf Seifart, and Winfried Rief. 2014. Breaking bad news\u2014what patients want and what they get: evaluating the spikes protocol in Germany. Annals of Oncology, 25(3):707\u2013711.\\n\\nAshish Sharma, Inna W Lin, Adam S Miner, David C Atkins, and Tim Althoff. 2021. Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach. In Proceedings of the Web Conference 2021, pages 194\u2013205.\\n\\nAshish Sharma, Adam Miner, David Atkins, and Tim Althoff. 2020. A computational approach to understanding empathy expressed in text-based mental health support. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5263\u20135276, Online. Association for Computational Linguistics.\\n\\nSiqi Shen, Charles Welch, Rada Mihalcea, and Ver\u00f3nica P\u00e9rez-Rosas. 2020. Counseling-style reflection generation using generative pretrained transformers with augmented context. In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 10\u201320, 1st virtual meeting. Association for Computational Linguistics.\\n\\nShuju Shi, Yinglun Sun, Jose Zavala, Jeffrey Moore, and Roxana Girju. 2021. Modeling clinical empathy in narrative essays. In 2021 IEEE 15th International Conference on Semantic Computing (ICSC), pages 215\u2013220.\\n\\nRoger W Squier. 1990. A model of empathic understanding and adherence to treatment regimens in practitioner-patient relationships. Social Science & Medicine, 30(3):325\u2013339.\\n\\nAnthony L. Suchman, Kathryn Markakis, Howard B. Beckman, and Richard Frankel. 1997. A Model of Empathic Communication in the Medical Interview. JAMA, 277(8):678\u2013682.\\n\\nEkaterina Svikhnushina, Iuliana Voinea, Anuradha Welivita, and Pearl Pu. 2022. A taxonomy of empathetic questions in social dialogs. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2952\u20132973, Dublin, Ireland. Association for Computational Linguistics.\"}"}
{"id": "lrec-2024-main-124", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A. Transcriptions\\n\\nThe time it takes to transcribe a full conversation is very dependent on the audio quality of the file. With prioritizing simulating a realistic setting for the students' practice, the microphone position reduces the audio quality. Some transcribers report that in especially low quality circumstances in which the voices are muffled and unclear, the time it takes to complete transcribing the dialogue can amount to 12 hours, since the writing, rewinding, correcting, rewinding, repeat, can take a lot of time.\\n\\nTo aid the transcription labor, we searched for effective ASR tools for German that can be run offline on a private server (to protect the data) and handle low quality. We found setting up Whisper 5 (Radford et al., 2023) offline was the most effective, and integrated it as a starting point for the transcribers. In the best-case scenario, with a quality Whisper base script, the task consists mostly of setting the correct timestamps in the right places, correcting the occasional misinterpretation, and filling in the parts that Whisper failed to recognize at all. The task of transcribing the dialogue can be done in two to three hours. Even so, it still depends on the audio quality, which impacts the quality of Whisper transcriptions.\\n\\nB. Annotator Details\\n\\nThe annotation task is complex and non-trivial, requiring dedicated time and work effort to properly reason through the types of spans. This requires expert annotators who have a comprehensive understanding of the theoretical frameworks, the dialogue setting, and experience applying the framework. The dialogues are privacy protected, so we carefully chose a small group of research assistants.\"}"}
{"id": "lrec-2024-main-124", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"to whom access is granted. Therefore, the people who perform the dialogue transcriptions also generally perform the annotations. All are L1 German speakers. Across all transcribers and annotators, their expertise and concentrations include psychology, political science, linguistics, informatics, and physics.\\n\\n### C. Additional Reference\\n\\nTable 9 shows the agreements over all dialogues. Note only the eight dialogues discussed in \u00a74.1 were annotated independently. Otherwise, they were annotated first by one annotator, and reviewed by the other. Table 10 shows the average and standard deviation of the label counts per dialogue.\\n\\n| Label       | Avg \u00b1 std |\\n|-------------|-----------|\\n| Patient EO  | 33.9 \u00b1 14.6 |\\n| exp.appreciate | 5.9 \u00b1 5.0 |\\n| exp.feel    | 2.4 \u00b1 2.3 |\\n| exp.judge   | 9.5 \u00b1 6.0 |\\n| imp.appreciate | 2.4 \u00b1 2.6 |\\n| imp.feel    | 12.5 \u00b1 5.6 |\\n| imp.judge   | 1.2 \u00b1 1.7 |\\n| imp.assent  | 1.7 \u00b1 1.8 |\\n| accept.nt.appreciate | 3.8 \u00b1 2.5 |\\n| accept.nt.judge  | 1.7 \u00b1 1.8 |\\n| accept.pos.allow | 1.7 \u00b1 1.5 |\\n| accept.pos.exp.judge | 3.5 \u00b1 2.8 |\\n| accept.pos.imp.judge | 1.2 \u00b1 1.7 |\\n| accept.pos.repeat | 0.4 \u00b1 1.0 |\\n| appreciate.share | 0.5 \u00b1 1.0 |\\n| appreciate.understand | 0.6 \u00b1 1.0 |\\n| feel.share    | 0.3 \u00b1 0.7 |\\n| feel.understand | 3.4 \u00b1 2.4 |\\n| judge.share   | 0.5 \u00b1 1.1 |\\n| judge.understand | 1.4 \u00b1 1.6 |\\n| EO elicitation | 6.8 \u00b1 6.4 |\\n| dir.appreciate | 1.8 \u00b1 3.0 |\\n| dir.feel     | 1.2 \u00b1 1.2 |\\n| dir.judge    | 1.6 \u00b1 1.4 |\\n| ind.appreciate | 0.9 \u00b1 1.6 |\\n| ind.feel     | 0.8 \u00b1 1.7 |\\n| ind.judge    | 0.5 \u00b1 1.0 |\\n| SPIKES       | 15.1 \u00b1 5.6 |\\n| invitation   | 1.8 \u00b1 1.5 |\\n| knowledge    | 5.0 \u00b1 3.0 |\\n| perception   | 2.3 \u00b1 2.2 |\\n| setting      | 0.7 \u00b1 0.6 |\\n| strategy/summary | 5.2 \u00b1 3.3 |\"}"}
{"id": "lrec-2024-main-124", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Exp. Feel | Imp. Feel | Exp. Appreciate | Imp. Appreciate | Exp. Judge | Imp. Judge |\\n|----------|----------|----------------|----------------|-----------|-----------|\\n|          |          |                |                |           |           |\\n\\nFigure 1: Relation heatmap. This heatmap reflects relations between patient EOs (rows) and subsequent EO responses (columns). The cell values reflect the percentage of the EOs of the type specified by the row that was responded to with the EO response type specified by the column.\"}"}
