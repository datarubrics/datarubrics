{"id": "acl-2022-long-142", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation\\n\\nXinyu Pi1\u2217, Bing Wang2\u2217, Yan Gao3, Jiaqi Guo4, Zhoujun Li2, Jian-Guang Lou3\\n\\n1 University of Illinois Urbana-Champaign, Urbana, USA,\\n2 State Key Lab of Software Development Environment, Beihang University\\n3 Microsoft Research Asia\\n4 Xi'an Jiaotong University, Xi'an, China\\n\\nxinyupi2@illinois.edu; {bingwang, lizj}@buaa.edu.cn\\njasperguo2013@stu.xjtu.edu.cn; {yan.gao, jlou}@microsoft.com\\n\\nAbstract\\n\\nThe robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications. Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables. Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure the robustness of Text-to-SQL models. Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs. All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing models' vulnerability in real-world practices. To defend against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach not only brings the best robustness improvement against table-side perturbations but also substantially empowers models against NL-side perturbations. We release our benchmark and code at: https://github.com/microsoft/ContextualSP.\\n\\n1 Introduction\\n\\nThe goal of Text-to-SQL is to generate an executable SQL query given a natural language (NL) question and corresponding tables as inputs. By helping non-experts interact with ever-growing databases, this task has many potential applications in real life, thereby receiving considerable interest from both industry and academia (Li and Jagadish, 2016; Zhong et al., 2017; Affolter et al., 2019).\\n\\nRecently, existing Text-to-SQL parsers have been found vulnerable to perturbations in NL questions (Gan et al., 2021; Zeng et al., 2020; Deng et al., 2021). For example, Deng et al. (2021) removed the explicit mentions of database items in a question while keeping its meaning unchanged, and observed a significant performance drop of a Text-to-SQL parser. Gan et al. (2021) also observed a dramatic performance drop when the schema-related tokens in questions are replaced with synonyms. They investigated both multi-annotations for schema items and adversarial training to improve parsers' robustness against permutations in NL questions. However, previous works only studied the robustness of parsers from the perspective of NL questions, neglecting variability from the other side of parser input \u2013 tables.\\n\\nWe argue that a reliable parser should also be robust against table-side perturbations since they are inevitably modified in the human-machine interaction process. In business scenarios, table main...\"}"}
{"id": "acl-2022-long-142", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"... rename columns due to business demands and user preferences. (ii) add new columns into existing tables when business demands change. Consequently, the extra lexicon diversity introduced by such modifications could harm performances of unrobust Text-to-SQL parsers. To formalize these scenarios, we propose a new attacking paradigm, **ATP (Adversarial Table Perturbation)**, to measure parsers' robustness against natural and realistic ATPs. In accordance with the two scenarios above, we consider both **RPL (REPLACE)** and **ADD** perturbations in this work. Figure 1 conveys an intuitive understanding of ATP.\\n\\nIdeally, ATP should be conducted based on two criteria: (i) Human experts consistently write correct SQL queries before and after table perturbations, yet parsers fail; (ii) Perturbed tables look natural and grammatical, and are free from breakage of human language conventions. Accordingly, we carefully design principles for RPL/ADD and manually curate the **ADVETA (Adversarial Table Perturbation)** benchmark based on three existing datasets. All evaluated state-of-the-art Text-to-SQL models experience drastic performance drops on ADVETA: On ADVETA-RPL, the average relative percentage drop is as high as 53.1%, whereas on ADVETA-ADD is 25.6%, revealing models' lack of robustness against ATPs.\\n\\nEmpirically, model robustness can be improved by adversarial training, i.e. re-train models with training set augmented with adversarial examples (Jin et al., 2020). However, due to the different natures of structured tables and unstructured text, well-established text adversarial example generation approaches are not readily applicable. Motivated by this, we propose an effective **CTA (Contextualized Table Augmentation)** approach that better leverages tabular context information and carry out ablation analysis. To summarize, the contributions of our work are three-fold:\\n\\n\u2022 To the best of our knowledge, we are the first to propose definitions and principles of **ATP (Adversarial Table Perturbation)** as a new attacking paradigm for Text-to-SQL.\\n\\n\u2022 We contribute **ADVETA**, the first benchmark to evaluate the robustness of Text-to-SQL models. Significant performance drops of state-of-the-art models reveals that there is much more to explore beyond high leaderboard scores.\\n\\n\u2022 We design **CTA**, a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach brings model best robustness gain and lowest original performance loss, compared with various baselines. Moreover, we show that adversarial robustness brought by CTA generalizes well to NL-side perturbations.\\n\\n2 Adversarial Table Perturbation\\n\\nWe propose the **ATP (Adversarial Table Perturbation)** paradigm to measure robustness of Text-to-SQL models. For an input table and its associated NL questions, the goal of ATP is to fool Text-to-SQL parsers by perturbing tables naturally and realistically. More specifically, human SQL experts can consistently maintain their correct translations from NL questions to SQL with their understanding of language and table context. Formally, ATP consists of two approaches: **RPL (REPLACE)** and **ADD**. In the rest of this section, we first discuss our consideration of table context, then introduce conduction principles of RPL and ADD.\\n\\n2.1 Table Context\\n\\nTables consist of explicit and implicit elements \u2013 both are necessary for understanding table context. **\u201cExplicit elements\u201d** refer to table captions, columns, and cell values. **\u201cImplicit elements\u201d,** in our consideration, contains **TPE (Table Primary Entity)** and domain. (Relational) Tables are structured data recording domain-specific attributes (columns) around some central entities (TPE) (Sumathi and Esakkirajan, 2007). Without the explicit annotation, humans could still make correct guesses on them. For example, it's intuitive that tables in Figure 1 can be classified as \u201ceducation\u201d domain, and all of the columns center around the TPE \u201cstudent\u201d. Combining both explicit and implicit elements, people achieve an understanding of table context, which becomes the source of lexicon diversity in column descriptions.\\n\\n2.2 REPLACE (RPL) Principles\\n\\nGiven a target column, the goal of RPL is to seek an alternative column name that makes sense to humans but misleads unrobust models. Gold SQL, as illustrated in Figure 1, should be correspondingly adapted by mapping the original column to its new name. In light of this, RPL should fulfill the following two principles:...\"}"}
{"id": "acl-2022-long-142", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Basic Statistics\\n\\n|                  | Spider | WTQ | WikiSQL |\\n|------------------|--------|-----|---------|\\n| Total tables     | 81     | 81  | 81      |\\n| Avg. columns per table | 5.45   | \u2013   | \u2013       |\\n| Avg. perturbed columns per table | 2.62   | 3.64 | \u2013       |\\n| Avg. candidates per column | 3.33   | 3.97 | \u2013       |\\n\\n### Unique columns\\n\\n|                  | Spider | WTQ | WikiSQL |\\n|------------------|--------|-----|---------|\\n| Unique columns   | 211    | 911 | 1,061   |\\n| Unique vocab     | 199    | 598 | 782     |\\n\\n### Analytical Statistics\\n\\n|                  | Spider | WTQ | WikiSQL |\\n|------------------|--------|-----|---------|\\n| Unique semantic meanings | 144   | 144 | 683     |\\n| Avg. col name per semantic meaning | 1.35   | 6  | \u2013       |\\n\\n1. We omit cell value alignment in ADD for simplicity.\\n2. We require semantic equivalency to be filtered out from highly semantic associations. Otherwise, the original gold SQL will not be the single correct output, which makes the perturbation unreasonable.\\n\\n2.3 ADD Principles\\n\\nADD perturbs tables with introductions of new columns. Instead of adding random columns that fit well into the table domain, we pertinently add adversarial columns with respect to a target column for the sake of adversarial efficiency. Gold SQL should remain unchanged after ADD perturbations.\\n\\n### Semantic Equivalency:\\nUnder the table context of target column, substituted column names are expected to convey equivalent semantic meaning as the original name.\\n\\n### Phraseology Correctness:\\nATP aims to be natural and realistic and does not target worst-case attacks. Therefore, replaced column names are expected to follow linguistic phraseology conventions:\\n(i) Grammar Correctness: Substituted column names should be free from grammar errors.\\n(ii) Proper Collocation with TPE: New column names should collocate properly with TPE. For example, height and tallness both collocate well with student (TPE), but conventionally not altitude.\\n(iii) Idiomaticity: New column names should sound natural to a native speaker to address target columns. For example, runner-up means second place, and racer-up is a bad replacement despite runner is synonymous to racer.\\n\\n3 ADVETA Benchmark\\n\\nFollowing RPL and ADD principles, we manually curate the ADVETA (Adversarial Table Perturbation A) benchmark based on three mainstream Text-to-SQL datasets, Spider (Yu et al., 2018), WikiSQL (Zhong et al., 2017) and WTQ (Papernot et al., 2017). For each table from the original development set, we conduct RPL/ADD annotation separately, perturbing only table columns. For its associated NL-SQL pairs, we leave the NL questions unchanged and adapt gold SQLs accordingly. As a result, ADVETA consists of 3(Spider/WTQ/WikiSQL) \u00d7 2(RPL/ADD) = 6 subsets.\\n\\nWe next introduce annotation details and characteristics of ADVETA.\\n\\n3.1 Annotation Steps\\n\\nFive vendors join the annotation process. Each base dev set is split into small chunks and is manually annotated by one vendor and reviewed by another, with an inter-annotator agreement to resolve annotation inconsistency.\\n\\nBefore annotation, vendors are first trained to understand table context as described in \u00a7 2, then are further instructed of the following details.\\n\\nRPL: RPL principles are the mandatory requirements. During annotation, vendors are given full Google access to ease the conception of synonymous names for a target column.\\n\\nADD: ADD principles will be the primary guideline. Unlike free-style RPL annotations, vendors are provided with\"}"}
{"id": "acl-2022-long-142", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"| Student Name | Citizenship | Score | Age |\\n|--------------|-------------|-------|-----|\\n| A            | Country X   | 92    | 19  |\\n| B            | Country Y   | 89    | 21  |\\n\\n| Student Name | Citizenship | Score | School Term |\\n|--------------|-------------|-------|-------------|\\n| A            | Country X   | 92    | Fall        |\\n| B            | Country Y   | 89    | Spring      |\\n\\n| Student Name | Citizenship | Score | Academic Year | Semester |\\n|--------------|-------------|-------|---------------|----------|\\n| A            | Country X   | 92    | Fall          | Fall     |\\n| B            | Country Y   | 89    | Spring        | Spring   |\\n\\n---\\n\\n**Candidate Tables**\\n\\n- WDC\\n- Dense Retrieval\\n- TAPAS\\n- Reranker\\n\\n---\\n\\n**Caption: School Scores Statistics**\\n\\n| Student ID | Age | Department | Enroll Year | Term |\\n|------------|-----|------------|-------------|------|\\n| 10086      | 19  | Psychology | 2018        |      |\\n| 12319      | 21  | Statistics | 2016        |      |\\n\\n---\\n\\n**Tables**\\n\\n| Student Name | Course ID | Title          | Instructor | School |\\n|--------------|-----------|----------------|------------|--------|\\n| Tom          | P         | Psychology     | P          |        |\\n| Lily         | F         | Statistics     | F          |        |\\n\\n---\\n\\n**Premise and Hypothesis**\\n\\n- **Premise:**\\n  - H1: Student semester (Text).\\n  - H2: Student academic year (Text).\\n- **Hypothesis:**\\n  - H1: Student semester (Text).\\n  - H2: Student school term (Text).\\n  - H3: Student age (Text).\\n\\n---\\n\\n**Contextualization Matching (Top 20)**\\n\\n- Dictionary Matching\\n- Synonym Dictionary\\n\\n---\\n\\n**Final Model:**\\n\\n- NLI\\n- Primary Entity Predictor\\n- RPL\\n- Template: \\\\{TPE\\\\} \\\\{Col Name\\\\} \\\\{Col Type\\\\}\\n\\n---\\n\\n**Figure 2:** Overview of our CTA framework. In rare cases where TPE is missing, we apply Primary Entity Predictor (addressed in B.2). Otherwise we simply use annotated TPE. e1 is obtained with premise-hypothesis as input; e2 with hypothesis-premise.\\n\\n---\\n\\n**Contextual Table Augmentation (CTA)**\\n\\nIn this section, we introduce our Contextualized Table Augmentation (CTA) framework as an adversarial training example generation approach tailored for tabular data. The philosophy of adversarial example generation is straightforward: Pushing augmented RPL/ADD lexicon distributions closer to human-agreeable RPL/ADD distributions. This requires maximization of lexicon diversity under the constraints of domain relevancy and clear differentiation between semantic association & semantic equivalency, as stated in ADD principle from \u00a7 2.\\n\\n---\\n\\n**Well-established text adversarial example generation approaches**, such as TextFooler (Jin et al., 2020) and BertAttack (Li et al., 2020), might fail to meet this objective because:\\n\\n- **(i)** They rely on syntactic information (e.g. POS-tag, dependency, semantic role) to perform text transformations. However, such information is not available in structured tabular data, leading to poor-quality adversarial examples generated by these approaches.\\n- **(ii)** They perform sequential word-by-word transformations, which could narrow lexicon diversity (e.g. written by will not be replaced by author).\\n- **(iii)** They cannot leverage tabular context to ensure domain relevancy.\\n- **(iv)** They generally fail to distinguish semantic equivalency from high semantic association according to our observations (e.g., fail to distinguish sales vs. profits).\\n\\nTo tackle these challenges, we construct the CTA framework. Given a target column from a table with NL questions, (i) a dense table retriever properly contextualizes the input table, thereby pinpointing top-k most domain-related tables (and columns) from a large-scale database while boosting lexicon diversity. (ii) A reranker further narrows down semantic-association and produces coarse-grained ADD/RPL candidates. (iii) NLI decision maker distinguishes semantic equivalency from semantic association and allocates candidate.\"}"}
{"id": "acl-2022-long-142", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"columns to RPL/ADD buckets. A detailed illustration of our CTA framework is shown in Figure 2. We next introduce each component of CTA.\\n\\n4.1 Dense Retrieval for Similar Tables\\nThe entire framework starts with a dense retrieval module to gather most domain-related tables of user queries. We utilize the Tapas-based (Herzig et al., 2020) dense retriever in this module (Herzig et al., 2021), due to its better tabular contextualization expressiveness over classical retrieval methods such as Word2Vec (Mikolov et al., 2013) and BM25 (Robertson, 2009). Following the original usage proposed by Herzig et al. (2020), we retrieve the top 100 most domain-related tables from the backend Web Data Commons (WDC) (Lehmberg et al., 2016) database consisting of 600k non-repetitive tables with at most five columns.\\n\\n4.2 Numberbatch Reranker\\nFrom these retrieved domain-related tables, we further narrow down the range of most semantically associated candidate columns. This is done by a ConceptNet Numberbatch word embedding (Speer et al., 2017) reranker, who computes the cosine similarity score for a given column pair. We choose ConceptNet Numberbatch due to its advantage of far richer (520k) in-vocabulary multi-grams compared with Word2Vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), and Counterfitting (Mrk\u0161i\u0107 et al., 2016), which is especially desirable for multi-gram columns. We keep the top 20 similar among them as RPL/ADD candidates for each column of the original table.\\n\\n4.3 Word-level Replacement via Dictionary\\nAside from candidates obtained from retriever-reranker for whole-column level RPL, we consider word-level RPL for a target column as a complement. Specifically, we replace each word in a given target column with its synonyms recorded in the Oxford Dictionary (noise is more controllable compared with synonyms gathered by embedding). With a probability of 0.25 for each original word to remain unchanged, we sample until the max predefined number (20) of candidates is reached or 5 consecutively repeated candidates are produced.\\n\\n4.4 NLI as Final Decision Maker\\nSo far we have pinpointed candidate columns whose domain relevancy and semantic association are already guaranteed. The final stage is to determine which one of RPL/ADD candidates is more suitable for based on its semantic equivalent against target column. Therefore, we leverage RoBERTa-MNLI (Liu et al., 2019; Williams et al., 2017), the expert in differentiating semantic equivalency from semantic association. Practically, we construct premise-hypothesis by contextualized columns and judge semantic equivalency based on output bidirectional entailment scores $e_1$ and $e_2$.\\n\\nNLI Premise-Hypothesis Construction\\nThe quality of premise-hypothesis plays a key factor for NLI\u2019s functioning. We identify three potentially useful elements for contextualizing columns with surrounding table context: TPE, column type, and column cell value. Through manual experiments, we observe that:\\n\\n(i) Adding cell value significantly hurt decision accuracy of NLI models.\\n(ii) TPE is the most important context information and cannot be ablated.\\n(iii) Column type information can be a desirable source for word-sense disambiguation.\\n\\nThus the final template for premise-hypothesis construction as python formatted string is expressed as:\\n\\n```\\nf\\\"{TPE}{CN}({CT})\\\"\"\n```\\n\\nRPL/ADD Decision Criterion\\nIn practice, we observe a discrepancy in output entailment scores between premise-hypothesis score $e_1$ and hypothesis-premise score $e_2$. Thus we take scores from both direction into consideration. For RPL, we empirically choose $\\\\min(e_1, e_2) > 0$ as the final RPL acceptance criterion to reduce occurrences of false positive entailment decision. For ADD, the criterion is instead $\\\\max(e_1, e_2) < 0$ to reduce false negative entailment decisions.\\n\\n5 Experiments and Analysis\\n5.1 Experimental Setup\\nDatasets and Models\\nThe five original Text-to-SQL datasets involves in our experiments are: Spider (Yu et al., 2018), WikiSQL (Zhong et al., 2017), WTQ (Shi et al., 2020), CoSQL (Yu et al., 2019a) and SParC (Yu et al., 2019b). Their corresponding perturbed tables are from our ADVETA.\\n\\nWe highly recommend reading our pilot study in B.1. To avoid semantic conflict between a new column $\\\\tilde{c}$ and original columns $c_1, \\\\cdots, c_n$, we apply to each pair of $(\\\\tilde{c}, c_i)$.\\n\\nNote that we use the version with SQL annotations provided by Shi et al. (2020) here, since the original WTQ (Pasupat and Liang, 2015) only contains answer annotations.\"}"}
{"id": "acl-2022-long-142", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Results on original dev and ADVETA (RPL and ADD subsets). Red fonts denote absolute percentage performance drop compared with original dev.\\n\\nWe evaluate open-source Text-to-SQL models that reach competitive performance on the aforementioned datasets. DuoRAT (Scholak et al., 2021) and ETA (Liu et al., 2021) are baselines for Spider; SQUALL (Shi et al., 2020) is the baseline for WTQ; SQLova (Hwang et al., 2019) and CESQL (Guo and Gao, 2019) are baselines for WikiSQL. For the two multi-turn datasets (CoSQL & SParC), baselines are EditSQL (Zhang et al., 2019) and IGSQL (Cai and Wan, 2020).\\n\\nExact Match (EM) is employed for evaluation metric across all settings. Training details are shown in C.2.\\n\\n5.2 Attack Details\\n\\nAll baseline models are trained from scratch on corresponding original training sets, and then independently evaluated on original dev sets, ADVETA-RPL and ADVETA-ADD. Since columns have around three manual candidates in ADVETA-RPL/ADD, the number of possible perturbed tables scales exponentially with column numbers for a given table from the original dev set. Therefore, models are evaluated on ADVETA-RPL/ADD by sampling perturbed tables. For each NL-SQL pair and associated table(s), we sample one RPL-perturbed table and one ADD-perturbed table in each attack. Each column mentioned from gold SQL is perturbed by a randomly sampled manual candidate from ADVETA. For performance stability and statistical significance, we run five attacks with random seeds for each NL-SQL pair.\\n\\nAttack Results\\n\\nTable 2 presents the performance of models on original dev sets, ADVETA-RPL and ADVETA-ADD. Across various task formats, domains, and model designs, state-of-the-art Text-to-SQL parsers experience dramatic performance drop on our benchmark: by RPL perturbations, the relative percentage drop is as high as 53.1%, whereas on ADD the drop is 25.6% on average.\\n\\nAnother interesting observation is that RPL consistently leads to higher performance drops than ADD. This is perhaps due to models\u2019 heavy reliance on lexical matching, instead of true understanding of language and table context. Conclusively, Text-to-SQL models are still far less robust than desired against variability from the table input side.\\n\\nAttack Analysis\\n\\nTo understand the reasons for parsers\u2019 vulnerability, we specifically analyze their schema linking modules which are responsible for recognizing table elements mentioned in NL questions. This module is considered a vital component for Text-to-SQL (Wang et al., 2020; Scholak et al., 2021; Liu et al., 2021). We leverage the oracle schema linking annotations on Spider (Lei et al., 2020) and test ETA model on ADVETA using the oracle linkings. Note that we update the oracle linkings accordingly when testing on RPL.\\n\\nTable 4 compares the performance of ETA with or without the oracle linkings, from which we make two observations:\\n\\n(i) When guided with the oracle linkings, ETA performs much better on both RPL (27.6% \u2192 55.7%) and ADD (39.9% \u2192 71.3%).\\n\\nTherefore, the failure in schema linking is one of the essential causes for the vulnerability of Text-to-SQL parsers.\\n\\n(ii) Even with the oracle linkings, the performance of ETA on RPL and ADD still lags behind its performance on the original dev set, especially on RPL. Through a careful analysis on failure cases, we find that ETA still generates table elements that have a high degree of lexical matching with NL questions, even though the correct table elements are specified in the oracle linkings.\\n\\n5.3 Defense Details\\n\\nWe carry defense experiments with SQLova, SQUALL and ETA on WikiSQL, WTQ and Spider, respectively. We compare CTA\\n\\nAverage relative performance presented in Appendix C.3.\"}"}
{"id": "acl-2022-long-142", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Some might worry about the validity of the CTA\u2019s effectiveness due to data leakage risks in-\"}"}
{"id": "acl-2022-long-142", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 6: EM on Spider/Spider-Syn dev-sets.\\n\\n| Model                  | Spider | Spider-Syn |\\n|------------------------|--------|------------|\\n| RAT-SQL BERT            | 69.7   | 48.2       |\\n| RAT-SQL BERT + MAS      | 67.4   | 62.6       |\\n| ETA                    | 70.8   | 50.6       |\\n| ETA + CTA              | 69.8   | 60.4       |\\n\\n5.4 CTA Ablation Study\\n\\nWe carry out an ablation study to understand the roles of two core components of CTA: dense retriever and RoBERTa-MNLI. Results are shown in Table 3.\\n\\nCTA w/o Retriever\\nRPL candidates are generated merely from the dictionary; ADD generation is the same as W2V baseline. Compared with complete CTA, models augmented with this setting experience \\\\( \\\\frac{1}{2} \\\\% \\\\sim 1 \\\\% \\\\) performance drop on RPL and ADD, respectively. We attribute RPL drops to loss of real-world lexicon diversity and ADD drops to loss of domain relevance.\\n\\nCTA w/o MNLI\\nRPL and ADD candidates are generated in the same way as CTA, but without denoising of MNLI. RPL/ADD decisions solely rely on ranked semantic similarity. Compared with complete CTA, models augmented by this setting experience significant performance drops (\\\\( 4.9\\\\% \\\\sim 7.9\\\\% \\\\)) on all RPL subsets, and moderate drops (\\\\( 1.5\\\\% \\\\sim 2.8\\\\% \\\\)) on all ADD subsets. We attribute these drops to the inaccurate differentiation between semantic equivalency and semantic association due to lack of MNLI, which results in noisy RPL/ADD adversarial examples.\\n\\n5.5 Generalization to NL Perturbations\\n\\nBeyond CTA's effectiveness against table-side perturbations, a natural question follows: could re-training with adversarial table examples improve model robustness against perturbations from the other side of Text-to-SQL input (i.e., NL questions)? To explore this, we directly evaluate ETA (trained with CTA-augmented Spider train-set) on Spider-Syn dataset (Gan et al., 2021), which replaces schema-related tokens in NL question with its synonym. We observe an encouraging 9.8% EM improvement compared with vanilla ETA (trained with Spider train-set). This verifies CTA's generalizability to NL-side perturbations, with comparable effectiveness as the previous SOTA defense approach MAS, which fails to generalize to table-side perturbations on ADVETA in Table 3.\\n\\n6 Related Work\\n\\nRobustness of Text-to-SQL\\nAs discussed in \u00a7 1, previous works (Gan et al., 2021; Zeng et al., 2020; Deng et al., 2021) exclusively study robustness of Text-to-SQL parsers against perturbations in NL question inputs. Our work instead focuses on variability from the table input side and reveals parsers' vulnerability to table perturbations.\\n\\nAdversarial Example Generation\\nExisting works on adversarial text example generations can be classified into three categories: (1) Sentence-Level. This line of work generates adversarial examples by introducing distracting sentences or paraphrasing sentences (Jia and Liang, 2017; Iyyer et al., 2018). (2) Word-Level. This dimension of work generates adversarial examples by flipping words in a sentence, replacing words with their synonyms, and deleting random words (Li et al., 2020; Ren et al., 2019; Jin et al., 2020). (3) Char-Level. This line of work flips, deletes, and inserts random chars in a word to generate adversarial examples (Belinkov and Bisk, 2018; Gao et al., 2018). All the three categories of approaches have been widely used to reveal vulnerabilities of high-performance neural models on various tasks, including text classification (Ren et al., 2019; Morris et al., 2020), natural language inference (Li et al., 2020) and question answering (Ribeiro et al., 2018). Previous work on robustness of Text-to-SQL and semantic parsing models primarily adopt word-level perturbations to generate adversarial examples (Huang et al., 2014).\"}"}
{"id": "acl-2022-long-142", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2021). For example, the Spider-Sync adversarial benchmark (Gan et al., 2021) is curated by replacing schema-related words in questions with their synonyms.\\n\\nDespite these methods' effectiveness in generating adversarial text examples, they are not readily applicable for structural tabular data, as we discussed in \u00a7 4. Apart from this, table-side perturbations enjoy much higher attacking efficiency: the attack coverage of a single table modification includes all affiliated SQLs, whereas one NL-side perturbation only affects a single SQL. Combined with the lighter cognitive efforts of tabular context understanding than NL-understanding, ATP is arguably lower in annotation costs.\\n\\nPrevious work on table perturbations (Cartella et al., 2021; Ballet et al., 2019) focuses on table cell values; another work, (Ma and Wang, 2020) study impacts of naively (i.e., without consideration of table context information and without human guarantee) renaming irrelevant columns and adding irrelevant columns. In this work, we focus on table columns and propose an effective CTA framework that better leverages tabular context information for adversarial example generation, as well as manually annotate ADVETA benchmark.\\n\\n7 Conclusion\\nWe introduce Adversarial Table Perturbation (ATP), a new paradigm for evaluating model robustness on Text-to-SQL and define its conduction principles. We curate the ADVETA benchmark, on which all state-of-the-art models experience dramatic performance drop. For defense purposes, we design the CTA framework tailored for tabular adversarial training example generation. While CTA outperforms all baseline methods in robustness enhancement, there is still an unfilled gap from the original performance. This calls for future exploration of the robustness of Text-to-SQL parsers against ATP.\\n\\nEthical Considerations\\nOur ADVETA benchmark presented in this work is a free and open resource for the community to study the robustness of Text-to-SQL models. We collected tables from three mainstream Text-to-SQL datasets, Spider (Yu et al., 2018), WikiSQL (Zhong et al., 2017) and WTQ (Papernot et al., 2017), which are also free and open datasets for research use. For the table perturbation step, we hire professional annotators to find suitable RPL/ADD candidates for target columns. We pay the annotators at a price of 10 dollars per hour. The total time cost for annotating our benchmark is 253 hours.\\n\\nAll the experiments in this paper can be run on a single Tesla V100 GPU. Our benchmark will be released along with the paper.\\n\\nReferences\\nKatrin Affolter, Kurt Stockinger, and Abraham Bernstein. 2019. A comparative survey of recent natural language interfaces for databases. The VLDB Journal, 28:793 \u2013 819.\\n\\nVincent Ballet, Xavier Renard, Jonathan Aigrain, Thibault Laugel, Pascal Frossard, and Marcin Detyniecki. 2019. Imperceptible adversarial attacks on tabular data. CoRR, abs/1911.03274.\\n\\nYonatan Belinkov and Yonatan Bisk. 2018. Synthetic and natural noise both break neural machine translation. ArXiv, abs/1711.02173.\\n\\nSamuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. CoRR, abs/1508.05326.\\n\\nYitao Cai and Xiaojun Wan. 2020. IGSQL: Database schema interaction graph based neural model for context-dependent text-to-SQL generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6903\u20136912, Online. Association for Computational Linguistics.\\n\\nFrancesco Cartella, Orlando Anuncia\u00e7\u00e3o, Yuki Funabiki, Daisuke Yamaguchi, Toru Akishita, and Olivier Elshocht. 2021. Adversarial attacks for tabular data: Application to fraud detection and imbalanced data. In Proceedings of the Workshop on Artificial Intelligence Safety 2021 (SafeAI 2021) co-located with the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI 2021), Virtual, February 8, 2021, volume 2808 of CEUR Workshop Proceedings. CEUR-WS.org.\\n\\nIdo Dagan, Dan Roth, Mark Sammons, and Fabio Masimmo Zanzotto. 2013. Recognizing Textual Entailment: Models and Applications. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers.\\n\\nXiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, and Matthew Richardson. 2021. Structure-grounded pretraining for text-to-SQL. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1337\u20131350, Online. Association for Computational Linguistics.\"}"}
{"id": "acl-2022-long-142", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang, Xu Han, Pengjun Xie, Hai-Tao Zheng, and Zhiyuan Liu. 2021. Few-nerd: A few-shot named entity recognition dataset. CoRR, abs/2105.07464.\\n\\nYujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, John R. Woodward, Jinxia Xie, and Peng-sheng Huang. 2021. Towards robustness of text-to-SQL models against synonym substitution. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2505\u20132515, Online. Association for Computational Linguistics.\\n\\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. 2018. Black-box generation of adversarial text sequences to evade deep learning classifiers. 2018 IEEE Security and Privacy Workshops (SPW), pages 50\u201356.\\n\\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. Simcse: Simple contrastive learning of sentence embeddings. CoRR, abs/2104.08821.\\n\\nTong Guo and Huilin Gao. 2019. Content enhanced bert-based text-to-sql generation. arXiv preprint arXiv:1910.07179.\\n\\nJonathan Herzig, Thomas M\u00fcller, Syrine Krichene, and Julian Martin Eisenschlos. 2021. Open domain question answering over tables via dense retrieval. 2019: Proceeding of the AAAI conference on artificial intelligence, volume 34, pages 8018\u20138025.\\n\\nJonathan Herzig, Pawel Krzysztof Nowak, Thomas M\u00fcller, Francesco Piccinno, and Julian Martin Eisenschlos. 2020. TAPAS: weakly supervised table parsing via pre-training. CoRR, abs/2004.02349.\\n\\nFelix Hill, Kyunghyun Cho, Sebastien Jean, Coline Devin, and Yoshua Bengio. 2015a. Embedding word similarity with neural machine translation.\\n\\nFelix Hill, Roi Reichart, and Anna Korhonen. 2015b. SimLex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics, 41(4):665\u2013695.\\n\\nShuo Huang, Zhuang Li, Lizhen Qu, and Lei Pan. 2021. On robustness of neural semantic parsers. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 3333\u20133342, Online. Association for Computational Linguistics.\\n\\nWonseok Hwang, Jinyeong Yim, Seunghyun Park, and Minjoon Seo. 2019. A comprehensive exploration on wikisql with table-aware word contextualization. arXiv preprint arXiv:1902.01069.\\n\\nMohit Iyyer, John Wieting, Kevin Gimpel, and Luke Zettlemoyer. 2018. Adversarial example generation with syntactically controlled paraphrase networks. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1875\u20131885, New Orleans, Louisiana. Association for Computational Linguistics.\\n\\nRobin Jia and Percy Liang. 2017. Adversarial examples for evaluating reading comprehension systems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2021\u20132031, Copenhagen, Denmark. Association for Computational Linguistics.\\n\\nDi Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2020. Is bert really robust? A strong baseline for natural language attack on text classification and entailment. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 8018\u20138025.\\n\\nOliver Lehmberg, Dominique Ritze, Robert Meusel, and Christian Bizer. 2016. A large public corpus of web tables containing time and context metadata. In Proceedings of the 25th International Conference Companion on World Wide Web, WWW '16 Companion, page 75\u201376, Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.\\n\\nWenqiang Lei, Weixin Wang, Zhixin Ma, Tian Gan, Wei Lu, Min-Yen Kan, and Tat-Seng Chua. 2020. Re-examining the role of schema linking in text-to-SQL. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6943\u20136954, Online. Association for Computational Linguistics.\\n\\nFei Li and H. V. Jagadish. 2016. Understanding natural language queries over relational databases. SIGMOD Record, 45:6\u201313.\\n\\nLinyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. 2020. BERT-ATTACK: Adversarial attack against BERT using BERT. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6193\u20136202, Online. Association for Computational Linguistics.\\n\\nQian Liu, Dejian Yang, Jiahui Zhang, Jiaqi Guo, Bin Zhou, and Jian-Guang Lou. 2021. Awakening latent grounding from pretrained language models for semantic parsing. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1174\u20131189, Online. Association for Computational Linguistics.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692.\\n\\nPingchuan Ma and Shuai Wang. 2020. Mt-teql: Evaluating and augmenting consistency of text-to-sql models with metamorphic testing.\"}"}
{"id": "acl-2022-long-142", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositional-ity. In Advances in neural information processing systems, pages 3111\u20133119.\\n\\nJohn Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. 2020. TextAttack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 119\u2013126, Online. Association for Computational Linguistics.\\n\\nNikola Mrk\u0161i\u0107, Diarmuid \u00d3 S\u00e9aghdha, Blaise Thomson, Milica Ga\u0161i\u0107, Lina M. Rojas-Barahona, Pei-Hao Su, David Vandyke, Tsung-Hsien Wen, and Steve Young. 2016. Counter-fitting word vectors to linguistic constraints. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013148, San Diego, California. Association for Computational Linguistics.\\n\\nNikola Mrksic, Diarmuid \u00d3 S\u00e9aghdha, Blaise Thomson, Milica Gasic, Lina Maria Rojas-Barahona, Pei-Hao Su, David Vandyke, Tsung-Hsien Wen, and Steve J. Young. 2016. Counter-fitting word vectors to linguistic constraints. CoRR, abs/1603.00892.\\n\\nNicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on computer and communications security, pages 506\u2013519.\\n\\nPanupong Pasupat and Percy Liang. 2015. Compositional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1470\u20131480, Beijing, China. Association for Computational Linguistics.\\n\\nJeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe: Global vectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532\u20131543, Doha, Qatar. Association for Computational Linguistics.\\n\\nShuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che. 2019. Generating natural language adversarial examples through probability weighted word saliency. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1085\u20131097, Florence, Italy. Association for Computational Linguistics.\\n\\nMarco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. Semantically equivalent adversarial rules for debugging NLP models. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 856\u2013865, Melbourne, Australia. Association for Computational Linguistics.\\n\\nS. Robertson. 2009. The Probabilistic Relevance Framework: BM25 and Beyond. Foundations and Trends\u00ae in Information Retrieval, 3(4):333\u2013389.\\n\\nTorsten Scholak, Raymond Li, Dzmitry Bahdanau, Harm de Vries, and Chris Pal. 2021. DuoRAT: Towards simpler text-to-SQL models. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1313\u20131321, Online. Association for Computational Linguistics.\\n\\nTianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\u00e9 III, and Lillian Lee. 2020. On the potential of lexico-logical alignments for semantic parsing to SQL queries. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1849\u20131864, Online. Association for Computational Linguistics.\\n\\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017. ConceptNet 5.5: An open multilingual graph of general knowledge. pages 4444\u20134451.\\n\\nSai Sumathi and S Esakkirajan. 2007. Fundamentals of relational database management systems, volume 47. Springer.\\n\\nBailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson. 2020. RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7567\u20137578, Online. Association for Computational Linguistics.\\n\\nJohn Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu. 2015. From paraphrase database to compositional paraphrase model and back. Transactions of the Association for Computational Linguistics, 3:345\u2013358.\\n\\nAdina Williams, Nikita Nangia, and Samuel R. Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference. CoRR, abs/1704.05426.\\n\\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online. Association for Computational Linguistics.\"}"}
{"id": "acl-2022-long-142", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We display some representative benchmark annotation cases to convey readers an intuitive feeling on our RPL and ADD subsets. As reflected in Figure 3, RPL reflects the following characteristics beyond RPL principles:\\n\\n(i) Abbreviation of common words. e.g. Cell number vs. Tel.\\n(ii) Idiomatic transformation e.g. Air date vs. Release time\\n(iii) Part of speech structure transformation e.g. Written by vs. Author.\\n\\nADD perturbations faithfully obey ADD principles and additions demonstrate high coherency with respect to original domain.\\n\\n### B CTA Details\\n\\n#### B.1 NLI-based Substitutability Verification Approach\\n\\n| Model         | Forward Entailment | Reverse Entailment |\\n|---------------|--------------------|--------------------|\\n| Roberta-RTE   | 0.48               | 0.46               |\\n| human         | 0.54               | 0.51               |\\n| ranodom       | 0.31               | 0.29               |\\n\\nTable 7: Average forward entailment score $e_1$, backward entail $e_2$, and corresponding standard deviations across 9 settings. In all human annotation cases, higher entailment is better. In all random replacement cases, lower is better.\\n\\n### Implementation Details\\n\\nFor each pair of target column and candidate column, we contextualize each column with the template described in Premise-Hypothesis Construction from section \u00a7 4. Then with the contextualized target column as the premise and the contextualized RPL candidate as the hypothesis, the NLI model computes both forward entailment score $e_1$ and backward score $e_2$. Notice that $e_2$ computation takes the contextualized RPL candidate as premise and the contextualized target column as hypothesis in input. We obtain entailment scores from both directions because of the observed score fluctuation caused by reversion in practicable cases.\"}"}
{"id": "acl-2022-long-142", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Pilot Study for Model Ability\\n\\nWe carry out a pilot study to test NLI models\u2019 capability of differentiating semantic equivalency and similarity in this section. RoBERTa (Liu et al., 2019) is chosen as the backbone model due to its outstanding performance and computational efficiency across various NLI datasets. Fine-tuned RoBERTa on three well-known NLI datasets: RTE (Dagan et al., 2013), SNLI (Bowman et al., 2015), and MNLI (Williams et al., 2017) are compared to demonstrate model ability difference due to training data.\\n\\nWe consider three levels of substitutability, from highest to lowest: human manual substitution (human-annotated replacements sampled from benchmark RPL subsets), embedding-based substitution (top-10 similar multi-grams from ConceptNet Numberbatch word embedding (Speer et al., 2017)), and random substitution (randomly sampled columns across benchmark(Speer et al., 2017)). Practically, we randomly sample 1000 pairs of data each time and repeat each setting five times.\\n\\nWe report the both average forward entailment scores $e_1$ and backward entailment scores $e_2$, as well their standard deviations for each setting across five runs (table 8). It is immediately obvious that RoBERTa-MNLI surpasses other models in verbal dexterity: the entailment score correlates best with true degrees of substitutability.\\n\\nPerformance on SimLex-999\\n\\nSimLex-999 (Hill et al., 2015b) is a gold standard resource for measuring how well models capture similarity, rather than relatedness or association between a input pair of words (e.g. cold and hot are closely associated but definitely not similar). Thus it is especially suitable for our purpose of further testing RoBERTa-MNLI\u2019s ability of semantic discrimination. We treat the entailment score produced by the model as its judgment of semantic similarity and report its Pearson correlation against the ground truth similarity score. Results suggest that RoBERTa-MNLI is quite competitive at discriminating association and relatedness from similarity.\\n\\nCase Study\\n\\nTo test the hard case performance of RoBERTa-MNLI, we come up with some tricky examples as shown in Table 9. The upper half of the table presents hard replaceable cases that emphasize idiomatic transformations or word-sense disambiguation. The lower half contains hard irreplaceable cases in which phrases have a high degree of conceptual association, yet still not semantically equivalent. Results reveal the surprisingly abundant and accurate lexicon knowledge condensed in RoBERTa-MNLI.\"}"}
{"id": "acl-2022-long-142", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B.2 Zero-shot TPE Classification\\n\\nWe build the previous premise-hypothesis construction in \u00a7 4.4 based on the assumption of availability of TPE, which is frequently not true. Thus our goal is to make a reasonable prediction on TPE for those missing cases. Practically, we make use of the HuggingFace (Wolf et al., 2020) implementation of zero-shot text classification (Yin et al., 2019) to classify missing TPE into 48 pre-defined categories with the input of concatenated table caption, columns, and cell values.\\n\\nImplementation Details\\n\\nBased on the 60+ fine-grained categories defined in Few-NERD (Ding et al., 2021), we modify and integrate them into 48 classes as candidate labels ($|L| = 48$). With a Roberta-MNLI as the workhorse model, our overall modeling process is modeled as:\\n\\n$$\\\\tilde{c}_t = \\\\arg \\\\max_i \\\\exp(f_\\\\theta(L_i|d;c;v;d))_{\\\\text{ent}}$$\\n\\n$$\\\\sum_{j \\\\in |L|} \\\\exp(f_\\\\theta(L_j|d;c;v))_{\\\\text{ent}}$$\\n\\nwhere $c$ is column names, $v$ is a randomly selected column value affiliated with a given column, and $d$ is table captions for a given table. Roberta-MNLI (annotated as $f_\\\\theta$) outputs raw logits of contradiction, neutral, and entailment scores. Softmax is finally applied entailment logits across 48 categories, with the top 1 label as final the primary entity prediction.\\n\\nHuman evaluation\\n\\nWe randomly sample 100 tables from our benchmark and ask three vendors to rate the reasonability of each predicted TPE from a scale of 1\u22125. 1 as totally unreasonable, 3 as mildly acceptable, and 5 as perfectly parallel with human guesses. We average out the rating from all three vendors and get a result of 4.13. This indicates the practicability of zero-shot TPE classification.\\n\\nB.3 Perturbation Case Study\\n\\nIn this section, we present a case study on adversarial training examples generated by CTA and baseline approaches in Table 10. We can make the following observations:\\n\\n(i) CTA tend to produce less low-frequency words (e.g. padrone, neosurrealist) in both RPL and ADD i.e. lower perplexity.\\n\\n(ii) CTA-generated samples fit better with the specificity level of table columns. For example, RPL pair (region, sphere) is overly broadened, whereas names such as ballads denomination, supermanager, thespian might be overly specified to fit into table headers.\\n\\n(iii) CTA incurs least semantic drift in RPL. In all baseline methods, there is a good chance to observe semantic-distinctive pairs such as (region, member), (type, number), (type, guy).\\n\\nWith CTA, such risk is minimal.\\n\\nC Experimental Details\\n\\nC.1 Original Datasets statistics\\n\\nThe detail statistics of five Text-to-SQL datasets are shown in Table 11. According to CoSQL (Yu et al., 2019a) and SParC (Yu et al., 2019b) paper, the two multi-turn Text-to-SQL datasets share the same tables with Spider (Yu et al., 2018).\\n\\nC.2 Baseline Details\\n\\nSQLova\\n\\nFor all defense results of the WikiSQL dataset, we employ the SQLova model, whose official codes are released in (Hwang et al., 2019). We use uncased BERT-large as the encoder. The learning rate is $1 \\\\times 10^{-3}$ and the learning rate of BERT-large is $1 \\\\times 10^{-5}$. The training epoch is 30 with a batch size of 12. The training process lasts 12 hours on a single 16GB Tesla V100 GPU.\\n\\nSQUALL\\n\\nWe employ the SQUALL model, following (Shi et al., 2020), to get all defense results of the WTQ dataset. The training epoch is 20 with a batch size of 30; The dropout rate is 0.2; The training process lasts 9 hours on a single 16GB Tesla V100 GPU.\\n\\nETA\\n\\nWe implement the ETA model following (Liu et al., 2021). We use an uncased BERT-large whole word masking version as the encoder. The learning rate is $5 \\\\times 10^{-5}$ and the training epoch is 50. The batch size and gradient accumulation steps...\"}"}
{"id": "acl-2022-long-142", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 10: Adversarial training examples generated by CTA and baseline approaches. Words with red color font are target columns.\\n\\nDatasets\\n\\n| Dataset | Train | Dev |\\n|---------|-------|-----|\\n| WTQ     | 1,290 | 9,030 |\\n| WikiSQL | 18,590 | 56,355 |\\n| Spider  | 795,997 | 5,525 |\\n| CoSQL   | 795,478 | 5,525 |\\n| SParC   | 795,1,011 | 5,525 |\\n\\nTable 11: Original datasets statistics. #T represents total number of tables in a dataset (#Q for questions). #Avg. Col stands for avg. number of columns per table. Spider, CoSQL and SParC share the same tables.\\n\\nC.3 Attack Performance Calculation Details\\n\\nTable 12 shows the attack performance of RPL and ADD perturbations. In this section, we show the calculation details of the average attack relative performance drop. For example, on the Spider dataset, the relative performance drop of the Duo-RAT model against RPL perturbation is 65.9%, and 61.0% for the ETA model. For RPL perturbation, we average out the relative performance drop of 9 models and report the average relative percentage drop (53.1%). Same as RPL, we get the average relative percentage drop (25.6%) for ADD perturbation.\\n\\n| Dataset | Model | Relative Performance Drop |\\n|---------|-------|---------------------------|\\n| WikiSQL | SQLova | -54.4 / -66.7% |\\n|          | CESQL | -32.1 / -38.1% |\\n| WTQ     | SQUALL | -21.3 / -48.3% |\\n| CoSQL   | EditSQL | -26.6 / -66.7% |\\n| SParC   | EditSQL | -16.7 / -35.4% |\\n\\nC.4 Schema Linking Calculation\\n\\nWe follow the work of Liu et al. (2021) to measure the performance of ETA schema linking predictions. Let \u03a9_{col} be a set \\\\{((c,q)_{i}|1 \\\\leq i \\\\leq N}\\\\} which contains N gold (column-question token) tuples. Let \u03a9_{col} be a set \\\\{((c,q)_{j}|1 \\\\leq j \\\\leq M}\\\\} which contains M predicted (column-question token) tuples. We define the precision (ColP), recall (ColR),...\"}"}
{"id": "acl-2022-long-142", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"F1-score \\\\( \\\\text{ColF} \\\\) as:\\n\\\\[\\n|\\\\Gamma_{\\\\text{col}}| \\\\quad \\\\mid \\\\quad |\\\\Omega_{\\\\text{col}}|, |\\\\Gamma_{\\\\text{col}}| \\\\quad \\\\mid \\\\quad |\\\\Omega_{\\\\text{col}}|, 2\\\\text{ColP}\\\\text{ColR}\\n\\\\]\\n\\\\[\\n\\\\text{ColP} + \\\\text{ColR}\\n\\\\]\\nwhere \\\\( \\\\Gamma_{\\\\text{col}} = \\\\Omega_{\\\\text{col}} \\\\cap \\\\Omega_{\\\\text{col}} \\\\).\\n\\nThe definitions of \\\\( \\\\text{TabP} \\\\), \\\\( \\\\text{TabR} \\\\), \\\\( \\\\text{TabF} \\\\) are similar.\\n\\n**D Baseline Approach Details**\\n\\nW2V\\n\\nTo generate candidates for a given column, W2V randomly samples five candidates from the top 15 cosine-similar \\\\( \\\\text{Numberbatch word embeddings} \\\\) for RPL and 15-50 for ADD. Textfooler and BERT-Attack also follow this hyper-parameter setting. For both TextFooler and BERT-Attack, we skip their word importance ranking (WIR) modules while only keeping the word transformer modules for candidate generation.\\n\\nTextFooler\\n\\nTextFooler is one of the state-of-the-art attacking frameworks for discriminative tasks on unstructured text. We skip its word importance ranking (WIR) step since our target column has already been located. Its word transformer module is faithfully re-implemented to generate candidates for a target column. Counter-fitted word embedding (Mrksic et al., 2016) are used for similarity computation, and modified sentences are constrained by both POS-tag consistency and Sim-CSE (Gao et al., 2021) similarity score.\\n\\nBERT-Attack\\n\\nBERT-Attack is another representative text attacking framework. Similar to our adaptation of TextFooler, we skip WIR and only keep the core masked language model-based word transformation. Following original work, low-quality or sub-word tokens predicted by BERT-Large are discarded; perturbed sentence similarities compared with the original are guaranteed by Sim-CSE.\\n\\n---\\n\\n\\\\( \\\\text{Sim-CSE} \\\\) is a similarity score that measures the consistency of POS tags and the structural similarity of sentences.\"}"}
