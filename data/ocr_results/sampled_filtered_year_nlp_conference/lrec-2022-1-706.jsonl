{"id": "lrec-2022-1-706", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"AsNER - Annotated Dataset and Baseline for Assamese Named Entity recognition\\n\\nDhrubajyoti Pathak, Sukumar Nandi, Priyankoo Sarmah\\n\\nIndian Institute of Technology Guwahati\\nNorth Guwahati, India\\n{drbj153, sukumar, priyankoo}@iitg.ac.in\\n\\nAbstract\\nWe present the AsNER, a named entity annotation dataset for low resource Assamese language with a baseline Assamese NER model. The dataset contains about 99k tokens comprised of text from the speech of the Prime Minister of India and Assamese play. It also contains person names, location names and addresses. The proposed NER dataset is likely to be a significant resource for deep neural based Assamese language processing. We benchmark the dataset by training NER models and evaluating using state-of-the-art architectures for supervised named entity recognition (NER) such as Fasttext, BERT, XLM-R, FLAIR, MuRIL etc. We implement several baseline approaches with state-of-the-art sequence tagging Bi-LSTM-CRF architecture. The highest F1-score among all baselines achieves an accuracy of 80.69% when using MuRIL as a word embedding method. The annotated dataset and the top performing model are made publicly available.\\n\\nKeywords:\\nNER dataset, Language Resources, Assamese NER, Assamese Language, Named Entity Recognition, NER model, AsNER\\n\\n1. Introduction\\n\\nNamed Entity Recognition (NER) aims to classify text in a sentence into predefined classes such as person, location, organization etc. It basically identifies a word or phrase that can be considered as names from a set of documents. NER plays a vital role in preprocessing task of various natural language processing (NLP) applications such as information retrieval (Neudecker, 2016), text understanding (Zhang et al., 2019), automatic text summarization (Larsen, 1999), question answering (Moll\u00e1 et al., 2006), machine translation (Babych and Hartley, 2003), and knowledge base construction (Etzioni et al., 2005) etc. Recent advances in deep neural network (DL) in NLP exhibit success in various domains. DL-based NER systems with minimal feature engineering have been flourishing. Over the past few years, several studies have been reported success in deep learning-based NER model and achieved state-of-the-art performance in resource-rich language (Chiu and Nichols, 2016; Lample et al., 2016; Akbik et al., 2019). The DL-based model requires high quality and large annotated datasets for training and evaluation. Therefore, datasets play an essential role in extracting the linguistic features of a language to achieve high performance in downstream tasks. On the other hand, data annotation for a language remains a time consuming and expensive process. It is a major challenge for many resource-poor languages, such as Assamese (Glottocode: asa1263), as it requires language experts to perform annotation tasks on a large amount of data. Suitable annotated corpora for Assamese NER, name dictionaries, morphological analyzers, dependency parser, POS taggers etc., are not yet publicly available for suitable use in downstream tasks. Although, Assamese has a very old and rich literary history, technology development in NLP is still in a nascent stage. The WikiAnn NER dataset (Pan et al., 2017) is the only publicly available dataset that contains annotated NER data for 282 languages that exist in Wikipedia; however, the size is not large enough to train a neural model. The lack of a suitable dataset may be the reason that we could not find any study about DL-based NER for Assamese. All the previous studies on Assamese NER are based on rule-based or statistical approaches. In this paper, we introduce a novel Assamese NER dataset, AsNER, comprising of annotated sentences with five entity classes. It also contains a large number of person names, locations and organization names. The corpus is built from the Assamese translation of the speeches of the Prime Minister of India, available online. Along with the annotation, preprocessing of the dataset and manual evaluation of the proposed AsNER, we verify the effectiveness of our dataset by using it to train neural-based NER models. To the best of our knowledge, AsNER is the first attempt to develop and evaluate NER dataset for Assamese language. The summary of our contribution is as follows:\\n\\n\u2022 We prepare and release a novel NER dataset for low-resourced Assamese language.\"}"}
{"id": "lrec-2022-1-706", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We present an evaluation of the AsNER by employing a state-of-the-art sequence tagging BiLSTM-CRF architecture.\\n\\nLastly, we report the performance of eight different NER models trained on AsNER.\\n\\nThe dataset and the best performing trained model are made available publicly.\\n\\nThis paper is organized as follows. We present a brief overview of the Assamese language in section 2. We describe our annotated dataset and annotation process in Section 3 and 4 respectively. We illustrate experiment details used to evaluate our dataset in Section 5. We discuss the results of the performance of different models in Section 6. In 7, we report the challenges encountered in the annotation process as well as in training the models. Finally, we conclude our paper in section 8.\\n\\n2. Assamese language\\n\\nAssamese or Asamiya, pronounced, is an Indo-Aryan language spoken mainly in Assam, a state of northeast India. It also refers to the native of Assam, whose mother tongue is Assamese. In this work, through Assamese, we refer to the Assamese language. It is a descendant of Magadhi Prakrit and bears affinities with Bengali, Hindi and Odia. Modern Assamese uses the Assamese script, which is developed from the Brahmi script. Assamese script is similar to Bengali script except for two characters, where Assamese differing from Bengali in one letter (\u09f0) for the /r/ sound, and an extra letter (\u09f1) for the /w/ or /v/ sound.\\n\\nAssamese is a highly inflectional, morphologically rich and agglutinating language. The rich linguistic feature of the language becomes the most challenging tasks in language processing. The morphological structure of words changes due to affixation, derivation and compounding. Affixes play an important role in word formation in Assamese. Affixes are used extensively in the formation of nouns, pronouns, and in the inflection of verbs with respect to number, person, tense, aspect and mood. Assamese is also a free word order Language.\\n\\n3. Dataset description\\n\\nThere are a few organized sources of monolingual corpora available for most of the Indian languages. Among the Indian languages, the Assamese corpus is one of the smallest in size. The WikiAnn NER dataset is the only publicly available dataset for Assamese NER. It is created from Wikipedia by transferring named entity labels from English to other languages by utilizing cross language link and Knowledge Base properties. The size of WikiAnn is not too large to train a neural model. The publicly available Assamese NER comprises of 12.5k tokens. The major part of the dataset is taken from the translated speech of the Prime Minister published by Press Information Bureau, Govt. of India. Text from Assamese Wikisource and Wikipedia is also included. Apart from that we include person names, location names and organization names into the dataset. These persons, locations and organization's names, are originally in English text collected from various sources, and translated to Assamese using Microsoft translator. The statistics of sentence and entity count from all the sources is presented in table 1. The final dataset comprises 24,040 sentences and approximately 99k tokens. We used 80% of the dataset for training, while approximately 10% of dataset is used for validation and 10% for testing. The additional person, location and organization names are proportionally distributed in the training, validation and test sets. We summarise the statistics of the dataset in table 4.\\n\\n4. Dataset Annotation\\n\\nThe annotated dataset is prepared in two phase; first by a POS tagger to tag all the words in the sentence with POS tag. After that, we use the tagged sentences for further named entity tagging by three native Assamese speakers with one linguist annotator. In second phase, only the nouns and the numbers are kept for further checking. The rest of the words of the sentence are annotated as \\\"not a named entity\\\". Table 3 shows the distribution of different classes in the dataset. Conflicts have been resolved manually. We discuss the conflicting cases in section 7. We focus on five classes of named entity during annotation, Location(LOC), Person (PER), Organization (ORG), Miscellaneous (MISC) and Number (NUM) (Sang and De Meulder, 2003; Chinchor and Robinson, 1997; Str\u00f6tgen and Gertz, 2013; Hvinigelby et al., 2020).\\n\\nLOC includes locations like regions (villages, towns, cities), roads (street name, highway), and natural locations (National park, forest reserve, river, garden), as well as both public and commercial places like tourist sites, museums, hospitals, airports, stations, markets, playgrounds, restaurants, hotels etc.\\n\\nPER consists of first, middle and last names of people, animals, fictional characters, as well as...\"}"}
{"id": "lrec-2022-1-706", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistic of various source\\n\\n| Corpus Source | #Sentence | #Entities  |\\n|---------------|----------|-----------|\\n| PM Speech text| 4534     | 6060      |\\n| Assamese play (Wiki) | 403  | 595      |\\n| Location text | 9769     | 16067     |\\n| Person text   | 8798     | 9776      |\\n| Organisation text | 518 | 2465     |\\n\\nTable 2: Dataset Statistics\\n\\n| Dataset | Train | Dev | Test |\\n|---------|-------|-----|------|\\n| # sentences | 21475 | 767 | 1798 |\\n| # tokens | 81422 | 8292 | 8909 |\\n| # entities | 29854 | 1326 | 3783 |\\n\\nTable 3: Frequency distribution of the NER tag set in the dataset\\n\\n| Class Name | Token count |\\n|------------|-------------|\\n| LOC        | 16688       |\\n| PER        | 10224       |\\n| ORG        | 712         |\\n| MISC       | 1574        |\\n| NUM        | 656         |\\n| O          | 51568       |\\n\\naliases. ORG includes public organisations (schools, colleges, universities, charities), companies (banks, stock markets, company name, brands), government bodies (ministries, institutions, courts, political unions of countries such as UNESCO).\\n\\nMISC includes a broad category such as nationalities, languages, political ideologies, religions, events (conferences, seminars, festivals, book fairs, expositions, sports competitions, forums, parties, concerts) etc. It also categorises words of which one part is a location, person or organisation, or other words derived from a word which is a location, organisation, or a person.\\n\\nNUM includes numbers, money, percentage and quantity etc.\\n\\nThe tag \\\"O\\\" is used for the remaining tokens.\\n\\nWe measure the inter-annotator agreement using Cohen\u2019s kappa (\u03ba). We observed inter-annotator agreement on 0.85 using \u03ba.\\n\\nThe annotated dataset is prepared in column format in which each line represents a word, and each column represents one level of linguistic annotation. An empty line separates sentences in the dataset.\\n\\n4.1. Resolving annotation conflict\\n\\nWe resolve the annotation conflict manually by following semantics and grammatical rules. Homonym ambiguity is prevalent in Assamese. Homonym ambiguity is resolved by looking at the context of the sentence. e.g. \u0989\u09a8 /zUn/ (Moon) would typically be a MISC, but when it is also often used in the name of a person in Assamese, it would be PER. Similarly, when an institution\u2019s name comprises a place name, it can act both ORG and LOC. e.g. \u0986\u0987\u0986\u0987\u0987 \u0997\u09c1\u09f1\u09be\u09b9\u09be\u099f\u09c0 /iit guwahati/ is an educational institute which generally implies as an organization (ORG); however, in some instances, it can be referred to as a location (LOC) also. Therefore, it is a context-dependent whether to annotate as ORG or LOC.\\n\\n5. Experiments\\n\\nWe choose a state-of-the-art neural sequence tagger framework based on standard BiLSTM-CRF architecture (Yu et al., 2020; Akbik et al., 2019; Huang et al., 2015) in our evaluation. It allows...\"}"}
{"id": "lrec-2022-1-706", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"to apply various state-of-the-art language models to train sequence tagging models such as Named Entity Recognition (NER), and POS tagging, especially for high resource languages such as English, German and Dutch (Akbik et al., 2018; Peters et al., 2018). Using the architecture, we evaluate our dataset using different pre-trained word embeddings.\\n\\n5.1. Word Embeddings used in evaluation\\n\\nWord embedding is a crucial component in machine learning-based NLP models. The real-valued vector representation of words has the ability to capture both semantic and syntactic meanings of words in a sentence, which led to significant advances in recent natural language processing (NLP) tasks such as sequence classification, POS tagging, Named Entity Recognition (NER), Sentiment Analysis, Machine Translation (MT), Question Answering (QA). There are various word embeddings to embed the words in sentences in multiple ways. These embeddings are usually trained and evaluated on high-resource languages, using a large collection of unlabeled corpora to build feature-rich word embeddings. Eventually, it becomes an integral part of neural models in NLP applications and is found to be achieved state-of-the-art performance in the downstream task. We used eight different pre-trained word embeddings in our experiment of developing Assamese NER. In the next part, we briefly describe all these word embeddings.\\n\\nWord2Vec (Mikolov et al., 2013; Kakwani et al., 2020): It is capable of capturing the context of a word in a sentence, semantic and syntactic similarity between the words. In Word2vec, word embeddings can be obtained by utilizing either of the two architectures, continuous bag-of-words (CBOW) or continuous skip-gram. We use the CBOW model in our experiment.\\n\\nFastText embedding (Bojanowski et al., 2017) are belongs to the type of sub-word embeddings where it is trained on character n-grams of words rather than whole words. FastText Embeddings can give word vectors for out of vocabulary (OOV) words by using the sub-word information from the previously trained model.\\n\\nByte-Pair Embeddings (Heinzerling and Strube, 2018) are pre-computed on sub-word level. They can embed by splitting words into subwords or character sequences, looking up the pre-computed subwords embeddings.\\n\\nBidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2018) uses masked language models (MLM). In masked language model, one or more words of the input strings are randomly masked and tries to predict the masked word based on its context. Embeddings from Language Models (ELMo) (Peters et al., 2018) word representation models complex features of words uses such as syntax and semantics. An embedding vector of a word varies according to the context of the sentences (i.e. to model polysemy). ELMo word vector representations are calculated based on the entire input sentence.\\n\\nFlair Embeddings (Akbik et al., 2018) is a contextual string embeddings for any string of characters in a sentential context. The embedding method based on recent advances in neural language modelling (LM) (Sutskever et al., 2014) that provides languages to be modelled as distributions over sequences of characters instead of words.\\n\\nMultilingual Representations for Indian Languages (MuRIL) (Khanuja et al., 2021) is based on BERT base architecture pre-trained on 17 Indian languages, including Assamese.\\n\\nXLM-R (Conneau et al., 2019) uses self-supervised training techniques in cross-lingual understanding. In cross-lingual understanding, a model is trained for a task in one language and then used with other languages without additional training data.\\n\\nMost of these word embeddings are trained on Assamese Wikipedia dataset (approx 8 million words) which size is limited for quality training. So, the performance in NER tagging is lower than most recently proposed MuRIL (Khanuja et al., 2021) which are trained on comparatively large size of training datasets.\\n\\n5.2. Hyperparameters\\n\\nWe train our models on Nvidia Tesla P100 403 GPU (3584 Cuda Cores). We choose similar hyperparameters in all the eight experiments in table 4 to evaluate the performance of different pre-trained Assamese word embeddings over the Assamese NER dataset. We kept the hidden layer size of 1024 with six hidden layers and a maximum sequence length of 128. To account for memory constraints, we use a mini-batch size of 32. Apart from hidden size, hidden layer, sequence length and batch size, we use the default values for the remaining hyperparameters as in (Akbik et al., 2019). We train the model for 50 epochs. We use learning rate annealing for early stopping.\\n\\n6. Results\\n\\nWe present the performance results of different experiments using our annotated dataset in this section. To conduct the experiments, we configure eight setups using different pre-trained word embedding models discussed in section 5.1. We use\"}"}
{"id": "lrec-2022-1-706", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Summary of the performance of individual word-embeddings in sequence labelling task\\n\\n| Experiment   | NER Accuracy (F1 Score) |\\n|--------------|-------------------------|\\n| Word2Vec     | 60.23%                  |\\n| FastTextEmbeddings | 67.94%            |\\n| BytePairEmbeddings | 76.24%            |\\n| BER T Embedding  | 72.74%                  |\\n| ELMO         | 71.81%                  |\\n| FlairEmbeddings (Multi) | 68.28%            |\\n| MuRIL        | 80.69%                  |\\n| XLM-R        | 69.42%                  |\\n\\nFigure 1: Confusion matrix of the NER model with performance 80.69%\\n\\nThis helps us evaluate the performance of these word embeddings on the AsNER dataset. The micro average score of each tagging model is presented in the table. Out of eight different configurations, the NER model that trained using MuRIL (Khanuja et al., 2021) word embedding achieves the highest F1-score of 80.69% among all the models. The FastText, FlairEmbedding and XLM-R show similar performance accuracy of 67.94%, 68.28% and 69.42%, respectively. Whereas the BytePairEmbeddings, BER T and ELMO embedding achieve comparatively higher tagging performance of 76.24%, 72.74% and 71.81%, respectively. The Word2vec reports the lowest performance of 60.23%. Figure 1 shows the confusion matrix of the best model. As there are no existing Assamese NER using the neural model, therefore the best performing model can be considered as a baseline model for Assamese NER.\\n\\nWe observe that ORG is predicted as LOC in numerous instances. PER is more often predicted as LOC. The model is also often confused with ORG, where it tags as \u201cO\u201d in the case of ORG.\\n\\n7. Challenges in Assamese Named Entity Recognition\\n\\nAssamese is a free order language and contains a vast number of polysemous words bearing different meanings. The same word changes meaning according to its grammatical positions in different sentences. In this section, we discuss various challenges in developing NER for Assamese AsNER.\\n\\nLack of resources: Linguistic resources, such as annotated data, gazetteers, and existing baselines, play a significant role in the named entity recognition process. Such resources are made significant...\"}"}
{"id": "lrec-2022-1-706", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"progress for various languages. However, linguis-\\ntics resources for Assamese are yet to either be de-\\nveloped or mature.\\n\\nAmbiguity: Most of Indian languages contain a\\nlarge number of polysemous words. They convey\\ndifferent meanings according to their positions in a\\nsentence. For example, \u09ae\u09be\u09a8\u09b8/manOs/ is a name of\\nboy tagged as PERSON. It is also a name of a river\\nand a national park located in Assam tagged as\\nLOCATION. It also means the name of the sacred\\nlake (/manOs sOrovOr/) located in\\nKailash moun-\\ntain which is also a LOCATION. In some cases,\\n\u09ae\u09be\u09a8\u09b8 is used as an ADJECTIVE in the Assamese\\nto convey\\na desire\\nor\\na wish\\nor sometimes\\nmind or\\nconscience.\\n\\nAbsence of Capitalization: Capitalization for a\\nnoun is an important feature of a language in rec-\\nognizing a named entity (NE). It helps to enhance\\nthe accuracy of NER system. Unlike English, there\\nis no distinction between plain dictionary words\\nand NEs in Assamese. It makes the named entity\\nrecognition process difficult. Examples are\\ne\u09b8\u09d7\u09f0\u09ad, \u0995\u09b2\u0995\u09be\u09a4\u09be, \u0986\u0987\u0986\u0987\u09bf\u099f \u0997\u09c1\u09f1\u09be\u09b9\u09be\u099f\u09c0 (Saurabh, Kolkata, IIT\\nGuwahati). In Assamese, as opposed to English,\\nthere is no capitalized concept in the case of nouns.\\nTherefore, a named entity may be missed by an-\\notators and NE recognizers.\\n\\nAgglutinative nature: Agglutination adds addi-\\ntional features in the root word to convey different\\nmeaning e.g. \u09ad\u09be\u09f0\u09a4/bharOt/ refers to the country\\nIndia whereas the word \u09ad\u09be\u09f0\u09a4\u09c0\u09af\u09bc/bharOtiyO/ refers\\nto the people who are from India.\\n\\nNested entities: Sometimes, NER tagging con-\\nfusion occurs in detecting a named entity class when\\na compound word consists of named entities of dif-\\nferent classes. In case of \u09bf\u09a6\u09b2\u09cd\u09b2\u09c0 \u09bf\u09ac\u09b6\u09ac\u09cd\u09bf\u09ac\u09a6\u09af\u09cd\u09be\u09b2\u09af\u09bc (delhi vis-\\nwOvidyalOy) (Delhi University) is an organization\\n(ORG), but Delhi refers to a location (LOC). Thus\\nit becomes difficult for the recognizer to tag an ap-\\npropriately named entity class.\\n\\n8. Conclusion\\n\\nWe presented the AsNER dataset and baseline\\nNER for low-resourced, morphologically rich As-\\nsamese language. Our contributions can be de-\\nscribed in three parts. Firstly, the develop-\\nment of AsNER dataset for Assamese. Secondly,\\nwe evaluated AsNER dataset using state-of-the-\\nart sequence tagging architecture by training sev-\\neral NER models using different word embeddings\\nsuch as Word2Vec (IndicBert), Fasttext, BytePair,\\nBERT, ELMO, MuRIL, XLM-R and FlairEmbed-\\nding. Thirdly, we compared the performance of\\ndifferent Assamese NER models trained on our\\ndataset. We found that the model with MuRIL\\nembedding yields the highest accuracy in NER tag-\\ning with an F1-score of 80.69%. Conclusively,\\nwe discussed various challenges encountered dur-\\ning the annotation and evaluation process.\\nWe believe, our dataset will be a potential resource\\nfor the technological development of Assamese lan-\\nguage. Our proposed baseline NER model is the\\nfirst of its kind for Assamese which is developed us-\\ning deep learning approach. We made the dataset\\nand top performing NER model publicly available.\\nThe tagging accuracy is still comparably less than\\nthe state-of-the-art NER tagging results. There\\nmay be two reasons- a) The POS training size is\\nstill not enough for training. b) The language mod-\\nels are still lacking to get the linguistic features of\\nthe morphologically rich, highly inflectional lan-\\nguage.\\n\\n9. Bibliographical References\\n\\nAkbik, A., Blythe, D., and Vollgraf, R. (2018).\\nContextual string embeddings for sequence la-\\nbeling. In Proceedings of the 27th international\\nconference on computational linguistics\\n, pages\\n1638\u20131649.\\n\\nAkbik, A., Bergmann, T., Blythe, D., Rasul, K.,\\nSchweter, S., and Vollgraf, R. (2019). Flair:\\nAn easy-to-use framework for state-of-the-art\\nnlp. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Associa-\\ntion for Computational Linguistics (Demonstra-\\ntions), pages 54\u201359.\\n\\nBabych, B. and Hartley, A. (2003). Improv-\\ning machine translation quality with automatic\\nnamed entity recognition. In Proceedings of the\\n7th International EAMT workshop on MT and\\nother language technology tools, Improving MT\\nthrough other language technology tools, Re-\\nsource and tools for building MT at EACL 2003.\\n\\nBojanowski, P., Grave, E., Joulin, A., and Mikolov,\\nT. (2017). Enriching word vectors with subword\\ninformation. Transactions of the Association for\\nComputational Linguistics, 5:135\u2013146.\\n\\nChinchor, N. and Robinson, P. (1997). Muc-7\\nnamed entity task definition. In Proceedings of\\nthe 7th Conference on Message Understanding,\\nvolume 29, pages 1\u201321.\\n\\nChiu, J. P. and Nichols, E. (2016). Named entity\\nrecognition with bidirectional lstm-cnns.\\nTransactions of the Association for Compu-\\ntational Linguistics, 4:357\u2013370.\\n\\nConneau, A., Khandelwal, K., Goyal, N., Chaud-\\nhary, V., Wenzek, G., Guzm\u00e1n, F., Grave,\\nE., Ott, M., Zettlemoyer, L., and Stoyanov,\\nV. (2019). Unsupervised cross-lingual rep-\\nresentation learning at scale. arXiv preprint\\narXiv:1911.02116.\\n\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova,\\nK. (2018). Bert: Pre-training of deep bidirec-\\ntional transformers for language understanding.\\narXiv preprint arXiv:1810.04805.\"}"}
{"id": "lrec-2022-1-706", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Etzioni, O., Cafarella, M., Downey, D., Popescu, A.-M., Shaked, T., Soderland, S., Weld, D. S., and Yates, A. (2005). Unsupervised named-entity extraction from the web: An experimental study. *Artificial intelligence*, 165(1):91\u2013134.\\n\\nHeinzerling, B. and Strube, M. (2018). BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages. In Nicoletta Calzolari (Conference chair), et al., editors, *Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)*, Miyazaki, Japan, May 7-12, 2018. European Language Resources Association (ELRA).\\n\\nHuang, Z., Xu, W., and Yu, K. (2015). Bidirectional lstm-crf models for sequence tagging. *arXiv preprint arXiv:1508.01991*.\\n\\nHvingelby, R., Pauli, A. B., Barrett, M., Rosted, C., Lidegaard, L. M., and S\u00f8gaard, A. (2020). Dane: A named entity resource for danish. In *Proceedings of the 12th Language Resources and Evaluation Conference*, pages 4597\u20134604.\\n\\nKakwani, D., Kunchukuttan, A., Golla, S., Gokul, N., Bhattacharyya, A., Khapra, M. M., and Kumar, P. (2020). inlpsuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for indian languages. In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings*, pages 4948\u20134961.\\n\\nKhanuja, S., Bansal, D., Mehtani, S., Khosla, S., Dey, A., Gopalan, B., Margam, D. K., Aggarwal, P., Nagipogu, R. T., Dave, S., Gupta, S., Gali, S. C. B., Subramanian, V., and Talukdar, P. (2021). Muril: Multilingual representations for indian languages.\\n\\nLample, G., Ballesteros, M., Subramanian, S., Kawakami, K., and Dyer, C. (2016). Neural architectures for named entity recognition. *arXiv preprint arXiv:1603.01360*.\\n\\nLarsen, B. (1999). A trainable summarizer with knowledge acquired from robust nlp techniques. Advances in automatic text summarization, 71.\\n\\nMikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation of word representations in vector space. *arXiv preprint arXiv:1301.3781*.\\n\\nMoll\u00e1, D., Van Zaanen, M., Smith, D., et al. (2006). Named entity recognition for question answering.\\n\\nNeudecker, C. (2016). An open corpus for named entity recognition in historic newspapers. In *Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916)*, pages 4348\u20134352.\\n\\nPan, X., Zhang, B., May, J., Nothman, J., Knight, K., and Ji, H. (2017). Cross-lingual name tagging and linking for 282 languages. In *Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pages 1946\u20131958.\\n\\nPeters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. (2018). Deep contextualized word representations. *arXiv preprint arXiv:1802.05365*.\\n\\nSang, E. F. and De Meulder, F. (2003). Introduction to the conll-2003 shared task: Language-independent named entity recognition. *arXiv preprint cs/0306050*.\\n\\nStr\u00f6tgen, J. and Gertz, M. (2013). Multilingual and cross-domain temporal tagging. *Language Resources and Evaluation*, 47(2):269\u2013298.\\n\\nSutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks. *arXiv preprint arXiv:1409.3215*.\\n\\nYu, J., Bohnet, B., and Poesio, M. (2020). Named entity recognition as dependency parsing. *arXiv preprint arXiv:2005.07150*.\\n\\nZhang, Z., Han, X., Liu, Z., Jiang, X., Sun, M., and Liu, Q. (2019). Ernie: Enhanced language representation with informative entities. *arXiv preprint arXiv:1905.07129*.\"}"}
