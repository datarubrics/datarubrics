{"id": "lrec-2022-1-342", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Borrowing or Codeswitching? Annotating for Finer-Grained Distinctions in Language Mixing\\n\\nElena \u00b4Alvarez Mellado 1, Constantine Lignos 2\\n1 NLP & IR Group, School of Computer Science, UNED\\n2 Michtom School of Computer Science, Brandeis University\\nelena.alvarez@lsi.uned.es, lignos@brandeis.edu\\n\\nAbstract\\nWe present a new corpus of Twitter data annotated for codeswitching and borrowing between Spanish and English. The corpus contains 9,500 tweets annotated at the token level with codeswitches, borrowings, and named entities. This corpus differs from prior corpora of codeswitching in that we attempt to clearly define and annotate the boundary between codeswitching and borrowing and do not treat common \u201cinternet-speak\u201d (lol, etc.) as a codeswitch when used in an otherwise monolingual context. The result is a corpus that enables the study and modeling of Spanish-English borrowing and codeswitching on Twitter in one dataset. We present baseline scores for modeling the labels of this corpus using Transformer-based language models.\\n\\nThe annotation itself is released with a CC BY 4.0 license, while the text it applies to is distributed in compliance with the Twitter terms of service.\\n\\nKeywords: codeswitching, borrowing, corpora\\n\\n1. Challenges in Annotating Codeswitching and Borrowing\\n\\nOver the last decade, several initiatives have drawn attention to codeswitching as a challenging NLP task, such as various shared tasks (Aguilar et al., 2018; Molina et al., 2016; Solorio et al., 2014) and a recent benchmark (Aguilar et al., 2020).\\n\\nPrior work on creating datasets of codeswitching has framed the task of language identification for codeswitched utterances as token-level annotation, where every token receives a language identification tag (Maharjan et al., 2015, among others). For example, in a collection of English-Spanish codeswitched tweets, tokens in Spanish will be labeled with a language identification tag for Spanish, and tokens in English will be labeled with a language identification tag for English.\\n\\nFurther labels have been proposed and adopted to the repertoire of tags in codeswitching datasets, such as ambiguous for words whose language is difficult to determine even in context, other for tokens in languages other than the main languages under study, mixed for intralexical codeswitching (words that combine morphemes from different languages), NE for named entities, and none for punctuation marks, emoji, Twitter mentions, etc.\\n\\nThis repertoire of labels has become the usual tagset in codeswitching shared tasks (Aguilar et al., 2018; Molina et al., 2016; Solorio et al., 2014). However, this tagset does not take into account that not all other-language inclusions are necessarily a codeswitch. In the prior work we examined, we were not able to identify explicit, published definitions or guidelines on what should constitute a codeswitch\u2014or perhaps more crucially, what is not a codeswitch. After all, language mixing can happen in cases that are not necessarily codeswitching. Given an utterance that is mostly monolingual, should we assume that any token from another language is a codeswitch, or could it be something else?\\n\\nLexical borrowing\u2014the incorporation of single lexical units from one language into another language (Haugen, 1950)\u2014is a process that resembles codeswitching in that it conveys the inclusion of tokens from another language into otherwise monolingual contexts, but it is different in nature (Poplack and Dion, 2012). Codeswitches are usually produced by multilingual individuals, and thus they comply with the grammatical structure of both languages at the same time. By definition, codeswitches are not integrated into the recipient language, unlike established borrowings.\\n\\nOn the other hand, lexical borrowings can be produced by monolingual speakers, and they are often accompanied by morphological and phonological modification. Lexical borrowings comply with the grammatical patterns of the recipient language and can eventually become assimilated into it until the perception of being an inclusion of \u201cforeign\u201d origin disappears (Lipski, 2005).\\n\\nWith this in mind, it seems unlikely that in a sentence such as \u201cIntentando comprar online uno de los nuevos discos duros que sac\u00f3 Samsung,\u201d the word \u201conline\u201d could be considered a codeswitch. Our analysis of existing codeswitching corpora suggests that tokens like \u201conline\u201d have usually been annotated as codeswitches, although in the absence of formal annotation guidelines, it is unclear whether that was intentional or not. On the other\"}"}
{"id": "lrec-2022-1-342", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Given that lexical borrowing and codeswitching are two distinct linguistic phenomena and the prevalence of lexical borrowings in social media messages (Luj\u00e1n Garc\u00eda, 2017; Sanou, 2018; Stewart et al., 2021), we believe that specific guidelines should be provided on how to deal with the codeswitching-borrowing distinction when annotating a dataset for codeswitching. If codeswitching is the phenomenon of interest, then only having a collection of tweets that are rich in other-language inclusions is not a sufficient solution. As Poplack and Dion (2012) state, distinguishing codeswitching and borrowing is \u201cthe thorniest issue in the field of contact linguistics today.\u201d\\n\\nHowever, previous work on codeswitching dataset design has rarely attempted to establish an explicit difference between intrasentential codeswitching\u2014codeswitching that happens inside one sentence\u2014and lexical borrowing. Previous work in Hindi by Bali et al. (2014) proposed a statistical approach based on frequency and linguistic typology to capture the distinction between borrowing and mixing, while Patro et al. (2017) proposed different metrics to compute the likelihood of a word being borrowed being codeswitched.\\n\\nWhile many codeswitching datasets include Spanish data, the codeswitching/borrowing distinction has not been explicitly explored, and to the best of our knowledge, no annotated dataset has made this distinction. In fact, a glance at the most frequent codeswitches in an English-Spanish codeswitched Twitter dataset (Maharjan et al., 2015) reveals that social media abbreviations and well-established internet terms (such as lol) are among the most frequent codeswitches annotated. It is debatable whether these words are in fact true codeswitches, as they can be considered examples of the internet dialect that monolinguals also use rather than evidence of bilinguals switching between languages, as Maharjan et al. (2015) point out:\\n\\nIn the case of abbreviations, some of them such as \u201clol\u201d and \u201clmao\u201d have become social media lingo rather than abbreviations of English words and thus cross language barriers.\\n\\n2. Dataset Description\\n\\nWith the previously mentioned challenges in mind, we developed a dataset consisting of tweets annotated to reflect codeswitching between Spanish and English as well as borrowing of English into Spanish. This section describes our annotation guidelines and the process of creating this dataset. In Section 2.1, we propose a set of guidelines to distinguish between codeswitching and borrowing that can be followed when annotating a corpus of English-Spanish codeswitched tweets. In Section 2.2, we describe how we reannotated an existing codeswitching dataset to match our guidelines. Section 2.3 presents the counts of the resulting dataset and the most frequent tokens per label in the annotation.\\n\\nThe stand-off annotation is released under a Creative Commons CC BY 4.0 license.\\n\\n2.1. Annotation guidelines\\n\\nOur annotation uses the following labels:\\n\\n\u2022 SPA: for tokens in Spanish\\n\u2022 ENG: for tokens in English\\n\u2022 OTH: for tokens in languages other than ENG or SPA\\n\u2022 BOR: for recent borrowings (in English or other languages)\\n\u2022 ENT: for named entities\\n\u2022 N: for punctuation marks, Twitter symbols (such as hashtags and mentions), URLs, etc.\\n\\nIn general, tokens in Spanish were annotated as SPA, tokens in English were annotated as ENG. Internet acronyms (such as lol) were considered part of the internet jargon and annotated as Spanish whenever they occurred in monolingual Spanish contexts. Non-Spanish words that appear in contexts where no other codeswitching was happening and where there was a strong indication that the word was being borrowed (rather than codeswitched) was annotated as BOR. Our goal with the borrowing tag was to address relatively recent borrowings into the Spanish language that might be spoken aloud in a normal conversational context, unlike the internet jargon referenced above.\\n\\nThe following were identified as borrowings, differentiating them from short codeswitches embedded in an otherwise monolingual segment:\\n\\n1. English words related to Twitter terminology: such as Follow Friday, tweet, follower, etc.\\n2. Technology words: server, hosting, user, post, blog, internet, template, app, online, chat.\\n3. English words that are already registered in Diccionario de la lengua espa\u00f1ola by Real Academia Espa\u00f1ola (Real Academia Espa\u00f1ola, 2021), the general dictionary of standard Spanish compiled by the Royal Spanish Academy, the main prescriptive institution on Spanish language.\\n4. English words that are already registered in Diccionario de Americanismos by Asociaci\u00f3n de Academias de la Lengua Espa\u00f1ola (Asociaci\u00f3n de Academias de la Lengua Espa\u00f1ola, 2021), an Americanism dictionary maintained by an association of Spanish-speaking universities.\\n\\n2.2. Reannotating an Existing Dataset\\n\\nIn order to provide a dataset annotated according to our guidelines, we reannotated an existing corpus of English-Spanish codeswitched tweets. This process involved manually going through each tweet and assigning the appropriate labels based on our guidelines.\\n\\n2.3. Dataset Counts and Analysis\\n\\nThe resulting dataset contains [insert number of tweets] tweets, with [insert percentage or number] of tweets annotated with codeswitching labels. The most frequent tokens per label were then analyzed to provide insights into the distribution of codeswitching and borrowing.\\n\\nThe stand-off annotation is released under a Creative Commons CC BY 4.0 license.\\n\\nReferences\\n\\nLuj\u00e1n Garc\u00eda, M. (2017). Lexical borrowing in social media messages. English Today, 33(3), 62\u201369.\\nSanou, N. (2018). Lexical borrowing in social media: A study of Japanese Twitter. Computer Speech & Language, 41, 180\u2013200.\\nStewart, B., et al. (2021). Lexical borrowing in social media: A multilingual study. Language Resources and Evaluation, 55(4), 1061\u20131085.\\nBali, M., et al. (2014). Identifying English borrowings in Hindi. In Proceedings of the 42nd annual meeting of the Association for Computational Linguistics (pp. 131\u2013141).\\nPatro, R., et al. (2017). Detecting English borrowings in Hindi. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 133\u2013143).\\nMaharjan, R., et al. (2015). Identifying codeswitching in English-Spanish tweets. In Proceedings of the 53rd annual meeting of the Association for Computational Linguistics (pp. 1433\u20131443).\\nPoplack, S., & Dion, L. (2012). The thorniest issue in the field of contact linguistics. In Contact linguistics: Perspectives from the field (pp. 19\u201350).\\nReal Academia Espa\u00f1ola. (2021). Diccionario de la lengua espa\u00f1ola. Retrieved from https://dle.rae.es/\\nAsociaci\u00f3n de Academias de la Lengua Espa\u00f1ola. (2021). Diccionario de Americanismos. Retrieved from https://www.asale.org/recursos/diccionarios/damer\\n\"}"}
{"id": "lrec-2022-1-342", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5. English words that are the headword of an entry in Spanish Wikipedia, such as music styles, genres and other cultural things (hip hop, whisky).\\n\\n6. Words that have English origin but are used following Spanish grammatical structure, such as noun-adjective word order (mensajes offline, rating online).\\n\\nThe intuition behind guidelines #3\u2013#5 was that if an English word either appears in some of the main prescriptive dictionaries of Spanish (which tend to be conservative in their approach to language change) or as the headword of a Wikipedia entry, then that would demonstrate that that English word is already well established among monolinguals at least in part of the Spanish-speaking world.\\n\\nThe criteria behind guideline #6 is that codeswitches by definition normally comply with the grammatical restrictions of both languages involved. On the other hand, when an item is borrowed from another language\u2014as opposed to codeswitching into the other language\u2014the borrowing will be produced with all the morphosyntactic requisites required by the recipient-language (Poplack and Dion, 2012). Consequently, when we encountered an English word that is used in an otherwise Spanish context and follows all the grammatical expectations of Spanish grammar rules, we annotated it as a borrowing, not a codeswitch.\\n\\nOur guidelines build on prior work developed to assist annotators when identifying English borrowings in Spanish monolingual texts (\u00c1lvarez-Mellado, 2020a; \u00c1lvarez-Mellado, 2020b; \u00c1lvarez-Mellado and Lignos, 2022). That prior work on borrowing annotation was designed exclusively to identify borrowings in Spanish from Spain and used sources whose Spain-centric criteria has been previously pointed out (Blanch, 1995; Fern\u00e1ndez Gordillo, 2014), which made them insufficient to identify well-established borrowings in a more geographically diverse collection of texts as our dataset. Consequently, our guidelines were adapted so that they could account for a more diverse representation of Spanish dialectal varieties than previous guidelines by considering additional lexicographic sources, such as Wikipedia or Diccionario de Americanismos.\\n\\nOur guidelines ensured that English words that are well-established borrowings in many parts of the Spanish speaking Americas (such as man, nice or party) would not be mistaken for codeswitches.\\n\\nWe have tried to create guidelines for distinguishing borrowing and codeswitching that can be applied somewhat objectively and in the most reliable fashion possible. As we have stated previously, the distinction is challenging; no annotation guidelines will be perfect, and there is not one universal set of distinctions that all researchers or speakers of the languages involved will agree on. However, we believe these guidelines can at the very least produce reliable and replicable annotation, and that is an important step forward in this area.\\n\\n2.2. Data Selection\\n\\nTo reduce the effort required to create our corpus and place it within existing work on codeswitching, we decided to select an existing corpus already annotated for codeswitching which we could reannotate to match our guidelines. We selected the codeswitching-dense corpus created by Lignos and Marcus (2013, hereafter LM2013) for several reasons.\\n\\nFirst, all tweets in the original LM2013 corpus had been annotated by two annotators and the original decisions made by each annotator were readily available, allowing us to identify and revisit any disagreements between the two annotators.\\n\\nSecond, the LM2013 annotators had been instructed to annotate the data to attempt to differentiate borrowing and codeswitching. While the annotation does not have a borrowing tag, the annotators were instructed not to annotate borrowed words as codeswitches. In the LM2013 annotation process, this was referred to as the \u201cmonolingual grandparent\u201d rule: if it is unclear whether a word is a borrowing or codeswitch, if one\u2019s monolingual grandparent would recognize it as part of their language, do not annotate it as a codeswitch. While this was intended to draw upon the life experiences of many bilinguals in that they are able to identify which words are understood by monolingual speakers, because it referred to an older relative it may have unintentionally had the effect of causing the annotators to annotate more recent borrowings as codeswitches.\\n\\nThird, the data used by LM2013 is primarily Spanish, which gives more opportunities to annotate borrowings into Spanish, especially those from English which is responsible for a large number of emergent borrowings (Furiassi et al., 2012; G\u00f6rlach, 2002).\\n\\nThe LM2013 dataset was reannotated following the guidelines from section 2.1 by a native speaker of Spanish that had a background in linguistics and had previous experience in annotating and identifying codeswitching.\\n\\n9 Perhaps future work would be better served by a \u201cmonolingual cousin\u201d rule instead.\\n\\n10 The tweets were selected from the Spanish subset of Burger et al. (2011), which was designed to be a general Spanish Twitter dataset created using automatic language identification without any intent to study language mixing. However, that dataset includes a significant amount of Spanish-English codeswitched tweets, making it a useful source for codeswitching data. The subset of the dataset selected by LM2013 was chosen to contain codeswitched tweets at a higher rate than the rest of the corpus.\"}"}
{"id": "lrec-2022-1-342", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ous experience in linguistic annotation. Our reannotation differs from the original annotation of LM2013 in several ways. We completed adjudication of all 9,500 tweets annotated by LM2013. Due to limited adjudicator availability, they had only completed adjudication of 7,018 tweets, with the remainder having unresolved disagreements. The LM2013 dataset assigned language tags to named entities\u2014names were annotated Spanish or English based on the surrounding language, not the source language of the name\u2014but we found that this annotation was extremely inconsistent and we removed it, making our data more consistent with other codeswitching datasets that do not make this distinction.\\n\\nLM2013's original annotation also distinguished between two types of entities: works of art (e.g., book titles) and other named entities. We removed this distinction as it was inconsistently annotated and most subsequent annotation either uses standard named entity types (PER, LOC, ORG, etc.) or a general \\\"named entity\\\" tag (Maharjan et al., 2015) like our annotation. Finally, we explicitly annotated borrowings as such. The original LM2013 annotation did not do so and the LM2013 annotators were instructed to not treat borrowings as codeswitches, but the annotators followed this advice inconsistently. While the annotators were not consistent, the fact that they were instructed to make this distinction was useful, as it resulted in inconsistencies that we could easily identify in adjudication.\\n\\nAs discussed in Section 1, a major difference between our annotation and previous codeswitching corpora that we are aware of (including the original LM2013 annotation) is that we do not count \\\"internet-speak\\\" as a codeswitch into English, reflecting the fact that monolingual communities may use internet shorthand adapted from English even in purely monolingual non-English contexts.\\n\\nIn order to identify borrowing candidates that could fall under the definition established in Section 2.1, we manually looked for frequently used English borrowings, checked for inter-annotator disagreements (for example, \\\"Send me your email address and I will sent it to you.\\\"), and automatically flagged inconsistencies in how certain tokens were sometimes labeled as SPA and sometimes annotated as ENG (such as \\\"man\\\", \\\"server\\\", or \\\"tweet\\\") across the whole corpus, even if annotators agreed on the individual annotations. This approach proved to be successful and revealed a high number of tokens that were actually borrowings and not true codeswitches (see Section 2.3).\\n\\nThe result of our reannotation process is a corpus that makes the distinction between borrowing and codeswitching and has a narrower definition of codeswitching than previous work, allowing for investigation of a finer-grained linguistic phenomenon.\\n\\n### Table 1: Token counts by label\\n\\n| Label | Count |\\n|-------|-------|\\n| SPA   | 134,110 |\\n| ENT   | 39,280 |\\n| ENG   | 6,819 |\\n| BOR   | 2,857 |\\n| OTH   | 267 |\\n| **Total** | **198,706** |\\n\\nIn order to identify borrowing candidates that could fall under the definition established in Section 2.1, we manually looked for frequently used English borrowings, checked for inter-annotator disagreements (for example, \\\"Send me your email address and I will sent it to you.\\\"), and automatically flagged inconsistencies in how certain tokens were sometimes labeled as SPA and sometimes annotated as ENG (such as \\\"man\\\", \\\"server\\\", or \\\"tweet\\\") across the whole corpus, even if annotators agreed on the individual annotations. This approach proved to be successful and revealed a high number of tokens that were actually borrowings and not true codeswitches (see Section 2.3).\\n\\nThe result of our reannotation process is a corpus that makes the distinction between borrowing and codeswitching and has a narrower definition of codeswitching than previous work, allowing for investigation of a finer-grained linguistic phenomenon.\"}"}
{"id": "lrec-2022-1-342", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: The ten most frequent tokens in the dataset for each label: Spanish, English, and borrowing\\n\\n| Token | Spanish Count | English Count | Borrowing Count |\\n|-------|---------------|---------------|-----------------|\\n| de    | 6,175         |               |                 |\\n| que   | 4,298         |               |                 |\\n| y     | 3,281         |               |                 |\\n| el    | 3,257         |               |                 |\\n| a     | 3,178         |               |                 |\\n| la    | 3,175         |               |                 |\\n| en    | 3,120         |               |                 |\\n| no    | 2,410         |               |                 |\\n| me    | 2,086         |               |                 |\\n\\nFully annotated dataset possible. This corpus is not designed to be an evenly-balanced English-Spanish codeswitching dataset. It is primarily a Spanish dataset, mainly composed of Spanish tweets that may have an English codeswitch or a borrowing. In addition, although our guidelines seek to establish a division as clearly as possible, the distinction between codeswitching and borrowing is fuzzy and is far from being solved. Many gray areas exist between social media jargon, nonce borrowing, and true codeswitching.\\n\\nAnother limitation is that as the original data selection process used generic Spanish language identification\u2014Burger et al. (2011) do not provide any details\u2014we do not know the geographic distribution of the speakers in the dataset and what dialects of Spanish and English they used. While we do believe this is a useful dataset for studying codeswitching and borrowing, caution should be exercised before drawing any global conclusions about the usage and mixing of either language.\\n\\n3. Baseline Models\\n\\nWe evaluated how well popular models perform in predicting the annotated labels of our dataset. The data was divided into a standard training, development, and test set split in 80/10/10 proportions.\\n\\nWe evaluated four Transformer-based models on the dataset:\\n\\n- mBERT: multilingual BERT, trained on Wikipedia in 104 languages (Devlin et al., 2019)\\n- BETO base cased model: a BERT-based model trained on Spanish (Ca\u00f1ete et al., 2020)\\n- RoBERTa BNE: a RoBERTa based model trained on Spanish (Guti\u00e9rrez-Fandi\u00f1o et al., 2021)\\n- RoBERTa Twitter: a RoBERTa based model trained on English Twitter data (Barbieri et al., 2020)\\n\\nThe aim behind this selection of models was to assess how Transformer-based models that had been trained on different types of text would perform on codeswitched data.\\n\\nThe only multilingual model that we included was mBERT. BETO is a BERT-based model trained on a diverse set of international Spanish texts from different origins, such as OpenSubtitles, Global Voices, and the United Nations (Ca\u00f1ete, 2019). RoBERTa BNE is a RoBERTa-based model that has been trained exclusively on data crawled from .es websites\u2014those using the top-level domain for Spain\u2014by the National Library of Spain. This means that while BETO training data is smaller (3 billion tokens vs BNE's 135 billion tokens), the model has probably been exposed to a more varied representation of the different varieties of Spanish spoken around the globe, which includes the area of Spanish where codeswitching may be more prevalent. Finally, we added a RoBERTa-based model trained on Twitter data under the assumption that an English monolingual model trained on social media text could potentially do better than other models trained on other genres.\\n\\nAll models were run using the Transformers library by HuggingFace (Wolf et al., 2020) with the same default (untuned) hyperparameters: 3 epochs, batch size 32, and a maximum sequence length of 256.\\n\\nTable 3 shows that both mBERT and BETO were the best performing models and achieved similar scores, with an F1 of 96.6. While we have bolded the highest number in each column, we have no reason to believe that any differences between the performance of mBERT and BETO are meaningful. Interestingly, the RoBERTa-based model trained on the crawled data by the National Library of Spain performed worse, despite being a larger model. This seems to suggest the importance that a diverse set of training material may have when modeling certain linguistic phenomena that are impacted by geographical and dialectal variation, such as codeswitching and borrowing.\\n\\n12 https://github.com/huggingface/transformers/tree/master/examples/pytorch/token-classification\"}"}
{"id": "lrec-2022-1-342", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Accuracy and micro-averaged precision, recall, and F1 score for baseline models (results from a single run)\\n\\nWhile we cannot directly compare our scores to other results as they are the first results on this dataset, these results are similar to those obtained on other datasets. For example, in the LinCE benchmark baseline (Aguilar et al., 2020), for the language identification task on Spanish-English codeswitching data the F1 scores were 94.16 with a BiLSTM, 98.12 with ELMo, and 98.53 with mBERT. The mBERT baseline F1 for our dataset is slightly lower at 96.65. One possible explanation is that our task is slightly more difficult for the model as it must make the borrowing-codeswitching distinction, but further experimentation and tuning would be required to support that claim.\\n\\nThe token-level accuracy of approximately 96.9 for mBERT and BETO baseline matches the accuracy of 96.9 reported by Lignos and Marcus (2013) on their data with a heuristic-based tagging approach. However, their evaluation excluded any tokens with named entity tags and their data was not annotated for borrowing, so it is likely their approach would get lower accuracy if evaluated on our reannotation.\\n\\n4. Conclusion\\nIn this paper we have introduced a new dataset of tweets annotated both with lexical borrowings and Spanish-English codeswitches. The annotation builds on previous approaches to codeswitching dataset creation, but distinguishes lexical borrowing from true codeswitching. This distinction that has been previously pointed out as crucial in the contact linguistics literature, but has not been made in previous codeswitching datasets. We have experimented with different Transformer-based models for the task of language identification and compared results in our dataset to previous work on other codeswitching datasets.\\n\\n5. Bibliographical References\\nAguilar, G., AlGhamdi, F., Soto, V., Diab, M., Hirschberg, J., and Solorio, T. (2020). Named entity recognition on code-switched data: Overview of the CALCS 2018 shared task. In Proceedings of The 12th Language Resources and Evaluation Conference, pages 1803\u20131813, Marseille, France, May. European Language Resources Association.\\n\\nAlvarez-Mellado, E. and Lignos, C. (2022). Detecting unassimilated borrowings in Spanish: An annotated corpus and approaches to modeling. arXiv preprint arXiv:2203.16169.\\n\\nAlvarez-Mellado, E. (2020a). An annotated corpus of emerging anglicisms in Spanish newspaper headlines. In Proceedings of the The 4th Workshop on Computational Approaches to Code Switching, pages 1\u20138, Marseille, France, May. European Language Resources Association.\\n\\nAlvarez-Mellado, E. (2020b). Lazaro: An extractor of emergent anglicisms in Spanish newswire. Master's thesis, Brandeis University.\\n\\nAsociaci\u00f3n de Academias de la Lengua Espa\u00f1ola. (2010). Diccionario de americanismos. https://lema.rae.es/damer/.\\n\\nBlanch, J. M. L. (1995). Americanismo frente a espa\u02dcnolismo ling\u00a8u\u00b4\u0131sticos. Nueva revista de filolog\u00b4\u0131a hisp\u00b4anica, 43(2):433\u2013440.\\n\\nBurger, J. D., Henderson, J., Kim, G., and Zarrella, G. (2011). Discriminating gender on Twitter. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1301\u20131309, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.\\n\\nCa\u02dcnete, J., Chaperon, G., Fuentes, R., Ho, J.-H., Kang, H., and P\u00b4erez, J. (2020). Spanish pre-trained BERT...\"}"}
{"id": "lrec-2022-1-342", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"model and evaluation data. In PML4DC at ICLR 2020.\\n\\nCa\u00f1ete, J. (2019). Compilation of large Spanish unannotated corpora.\\n\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota, June. Association for Computational Linguistics.\\n\\nFern\u00e1ndez Gordillo, L. (2014). La lexicograf\u00eda del espa\u00f1ol y el espa\u00f1ol hispanoamericano.\\n\\nFuriassi, C., Rodr\u00edguez Gonz\u00e1lez, F., and Pulcini, V. (2012). The anglicization of European lexis. The Anglicization of European Lexis, pages 1\u2013366.\\n\\nGamb\u00e4ck, B. and Das, A. (2016). Comparing the level of code-switching in corpora. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16), pages 1850\u20131855.\\n\\nG\u00f6rlich, M. (2002). English in Europe. OUP Oxford.\\n\\nGuti\u00e9rrez-Fandi\u00f1o, A., Armengol-Estap\u00e9, J., Pamies, M., Llop-Palao, J., Silveira-Ocampo, J., Carrino, C. P., Gonzalez-Agirre, A., Armentano-Oller, C., Rodr\u00edguez-Penagos, C., and Villegas, M. (2021). Spanish language models.\\n\\nHaugen, E. (1950). The analysis of linguistic borrowing. Language, 26(2):210\u2013231.\\n\\nLignos, C. and Marcus, M. (2013). Toward web-scale analysis of codeswitching. In 87th Annual Meeting of the Linguistic Society of America, volume 90.\\n\\nLipski, J. M. (2005). Code-switching or borrowing? No se so no puedo decir, you know. In Selected proceedings of the second workshop on Spanish sociolinguistics, pages 1\u201315. Cascadilla Proceedings Project Somerville, MA.\\n\\nLuj\u00e1n Garc\u00eda, C. (2017). Analysis of the presence of Anglicisms in a Spanish internet forum: some terms from the fields of fashion, beauty and leisure. Alicante Journal of English Studies.\\n\\nMaharjan, S., Blair, E., Bethard, S., and Solorio, T. (2015). Developing language-tagged corpora for code-switching tweets. In Proceedings of The 9th Linguistic Annotation Workshop, pages 72\u201384, Denver, Colorado, USA, June. Association for Computational Linguistics.\\n\\nMolina, G., AlGhamdi, F., Ghoneim, M., Hawwari, A., Rey-Villamizar, N., Diab, M., and Solorio, T. (2016). Overview for the second shared task on language identification in code-switched data. In Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 40\u201349, Austin, Texas, November. Association for Computational Linguistics.\\n\\nPatro, J., Samanta, B., Singh, S., Basu, A., Mukherjee, P., Choudhury, M., and Mukherjee, A. (2017). All that is English may be Hindi: Enhancing language identification through automatic ranking of the likeliness of word borrowing in social media. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2264\u20132274, Copenhagen, Denmark, September. Association for Computational Linguistics.\\n\\nPoplack, S. and Dion, N. (2012). Myths and facts about loanword development. Language variation and change, 24(3):279\u2013315.\\n\\nReal Academia Espa\u00f1ola. (2021). Diccionario de la lengua espa\u00f1ola, ed. 23.5. http://dle.rae.es.\\n\\nSanou, R. M. (2018). Anglicismos y redes sociales. Cuadernos de la ALFAL, 10:176\u2013191.\\n\\nSolorio, T., Blair, E., Maharjan, S., Bethard, S., Diab, M., Ghoneim, M., Hawwari, A., AlGhamdi, F., Hirschberg, J., Chang, A., and Fung, P. (2014). Overview for the first shared task on language identification in code-switched data. In Proceedings of the First Workshop on Computational Approaches to Code Switching, pages 62\u201372, Doha, Qatar, October. Association for Computational Linguistics.\\n\\nStewart, I., Yang, D., and Eisenstein, J. (2021). Tuitionamos o pongamos un tuit? investigating the social constraints of loanword integration in Spanish social media. In Proceedings of the Society for Computation in Linguistics 2021, pages 286\u2013297, Online, February. Association for Computational Linguistics.\\n\\nWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., and Rush, A. (2020). Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online, October. Association for Computational Linguistics.\"}"}
