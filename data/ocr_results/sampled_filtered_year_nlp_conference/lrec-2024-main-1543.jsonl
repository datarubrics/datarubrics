{"id": "lrec-2024-main-1543", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"XATU: A Fine-grained Instruction-based Benchmark for Explainable Text Updates\\n\\nHaopeng Zhang\u2020, Hayate Iso\u2021, Sairam Gurajada\u2021, Nikita Bhutani\u2021\\n\\nIFM Lab, UC Davis\u2020, Megagon Labs\u2021\\nhaopeng@ifmlab.org\\n{hayate, sairam, nikita}@megagon.ai\\n\\nAbstract\\n\\nText editing is a crucial task of modifying text to better align with user intents. However, existing text editing benchmark datasets contain only coarse-grained instructions and lack explainability, thus resulting in outputs that deviate from the intended changes outlined in the gold reference. To comprehensively investigate the text editing capabilities of large language models (LLMs), this paper introduces XATU, the first benchmark specifically designed for fine-grained instruction-based explainable text editing. XATU considers finer-grained text editing tasks of varying difficulty (simplification, grammar check, fact-check, etc.), incorporating lexical, syntactic, semantic, and knowledge-intensive edit aspects. To enhance interpretability, we combine LLM-based annotation and human annotation, resulting in a benchmark that includes fine-grained instructions and gold-standard edit explanations. By evaluating existing LLMs against our benchmark, we demonstrate the effectiveness of instruction tuning and the impact of underlying architecture across various editing tasks. Furthermore, extensive experimentation reveals the significant role of explanations in fine-tuning language models for text editing tasks. The benchmark will be open-sourced to support reproduction and facilitate future research at https://github.com/megagonlabs/xatu.\\n\\nKeywords: Text Editing, Large Language Model, Language Resources, Explainability\\n\\n1. Introduction\\n\\nText editing is the task of modifying text to better align with user intents. Recent advances in large language models (LLMs) have demonstrated remarkable zero-shot text generation capabilities across a wide range of downstream natural language processing (NLP) tasks like question answering, dialogue, and summarization (Radford et al., 2019; Raffel et al., 2020; Brown et al., 2020; Zhang et al., 2022, 2023a). It has been shown that incorporating instruction tuning (Wei et al., 2022) and reinforcement learning from human feedback (RLHF) (Bai et al., 2022; Ouyang et al., 2022) can further enhance a model\u2019s ability to align with the user\u2019s intent.\\n\\nText editing plays a crucial role in real-world text generation applications. While many current text generation models typically employ a one-shot manner, humans often engage in an iterative process when writing text, which entails multiple drafts and revisions (Faltings et al., 2021). Thus, approaching text generation as an iterative process with successive updates to the text is a more effective way to achieve higher alignment between the model\u2019s outputs and the user\u2019s intent.\\n\\nConsequently, instruction-based text editing tasks have received growing interest recently. They enable a user to interact with a model with commands to update existing text and achieve desirable text. Typically commands target broad edits such as\\n\\n```\\nIsidore Mankofsky (born September 22, 1931, in New York City, New York) was an American cinematographer.\\nHe died at his home in Los Angeles, California in March 2021 at the age of 89.\\n```\\n\\n```\\nUpdate the information\\n\\nIsidore Mankofsky (born September 22, 1931, in New York City, New York) was an American cinematographer, best known for his work on films such as ''The Muppet Movie'' (1979) and ''The Jazz Singer'' (1980).\\n```\\n\\nFigure 1: Illustrated examples of coarse- and fine-grained instructions for text editing. LLMs can accurately perform text editing based on coarse-grained instructions, but may not meet the user\u2019s intention. In contrast, fine-grained instructions lead to accurate and user-intended text editing.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: A detailed comparison of XATU with existing text editing datasets and benchmarks.\\n\\n| Dataset / Benchmarks                          | wiki |\u2717 |\u2713 |\u2717 |\\n|------------------------------------------------|------|---|---|---|\\n| WikiSemanticIntention (Yang et al., 2017)     |      |   |   |   |\\n| WikiAtomicEdits (Faruqui et al., 2018)        |      |   |   |   |\\n| WikiDocEdits (Faltings et al., 2021)          |      |\u2713 |   |   |\\n| ITERATER (Du et al., 2022)                    |      |   |   |   |\\n| EditEval (Dwivedi-Yu et al., 2022)            |      |\u2713 |   |   |\\n| XATU (Ours)                                   |      |\u2713 |\u2713 |\u2713 |\\n\\nAs adding or removing content, or changing the meaning of text (Faltings et al., 2021). To evaluate models' capabilities for text editing, instruction-based benchmarks such as EditEval (Dwivedi-Yu et al., 2022) have been proposed recently. Nevertheless, prior datasets and benchmarks only consider simple commands or instructions, such as 'Update the article' or 'Expand', resulting in three main limitations:\\n\\n(a) These instructions are often too coarse-grained, to the extent that even humans may struggle to understand the desired intent of the edit, limiting a model's capability to follow instructions.\\n\\n(b) It poses challenges for text editing evaluation since outputs obtained using coarse-grained instructions may not accurately reflect the true editing capabilities of LLM systems. The coarse-grained instructions cannot provide sufficient guidance for the editing system, so the edited output may appear correct but deviate from the intended changes, as shown in Figure 1. The edited output updates the death information of \\\"Isidore Mankofsky\\\" correctly but since the ground truth output updates the information about his famous works. This edit will receive very low evaluation scores since current automatic evaluation methods for text editing systems are mostly based on surface-level overlap with human-written gold references.\\n\\n(c) The current text editing systems lack explainability, which in turn limits the interpretability of the edits made. This lack of interpretability hampers our understanding of the underlying text editing behaviors.\\n\\nTo address the aforementioned limitations, we present XATU, a novel fine-grained instruction-based benchmark designed for explainable text updates. The benchmark leverages high-quality existing data sources from different tasks to enable automatic evaluation of LLM editing capabilities by incorporating an LLM-in-the-loop annotation process. In comparison to other datasets and benchmarks, XATU highlights its inclusion of a wider range of diverse topics, fine-grained edit instructions, and corresponding explanation rationales, as shown in Table 1. By utilizing XATU, we are able to evaluate and compare the performance of several state-of-the-art language models, considering both zero-shot and fine-tuning settings. Experiment results emphasize the significant role of explanations in the fine-tuning process of language models for text editing tasks. Our findings shed light on the importance of incorporating explanation rationales to enhance the performance of language models in text editing, ultimately leading to improved output quality. We summarize the contributions of this paper as follows:\\n\\n\u2022 We propose XATU, a new benchmark for instruction-based text editing. We collect high-quality data from a set of tasks and datasets for iterative text updates and provide gold fine-grained instructions and explanations with both LLM generation and human annotations. To the best of our knowledge, XATU is the first text editing dataset with fine-grained instructions and explanations.\\n\\n\u2022 We conduct a thorough evaluation of existing open and closed largelanguage models on our benchmark with different input formats to test their text editing capabilities. We further investigate the influence of instruction fine-tuning using explanations and fine-grained editing instructions.\\n\\n2. Related Work\\n\\n2.1. Text Editing\\n\\nSeveral prior studies have concentrated on the domain of text editing. Guu et al. (2018) introduced a method that involves generating sentences through the editing of training prototypes. Faruqui et al. (2018) presented the WikiAtomicEdits dataset, which comprises edits extracted from Wikipedia editing history. Subsequently, Yin et al. (2019) and Reid and Neubig (2022) leveraged Wikipedia editing history to propose the task of learning to represent edits. Furthermore, Iso et al. (2020) introduced a fact-based text editing task in their work. Recently, text editing has been approached as an interactive task, leading to the development of command-based editing systems (Faltings et al., 2021) and interactive editing systems (Schick et al., 2023). Researchers have also explored the integration of text editing into interactive self-refinement frameworks for text generation using large language models. Welleck et al. (2023) introduced a self-corrective learning framework that incorporates a corrector into the language model, enabling self-correction during sequence generation. Aky\u00fcrek et al. (2023) proposed a reinforcement learning-based approach for generating natural language feedback to correct generation errors. Furthermore,\"}"}
{"id": "lrec-2024-main-1543", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Zhang et al. (2023b) presented an iterative refinement framework for abstractive summarization.\\n\\n2.2. Text Editing Datasets\\n\\nPrevious research has also introduced various datasets and resources that focus on iterative text revisions within specific domains. For instance, datasets presented in Yang et al. (2017), Faruqui et al. (2018) and Anthonio et al. (2020) primarily concentrated on the domain of Wikipedia edit history, while Spangher et al. (2022) developed a dataset tailored to news articles. Researchers in the field have also proposed more comprehensive benchmarks that cover multiple domains. IteraTeR (Du et al., 2022) provides iterative tasks from multiple domains, but has only a limited number of tasks, such as fluency, coherence, clarity, style, and meaning change. EditEval (Dwivedi-Yu et al., 2022) is perhaps the closest to our benchmark XATU in that it covers data from multiple domains: Wikipedia, Wikinews, news articles, and arXiv.\\n\\nMoreover, it is important to note that only EditEval and WikiDocEdits (Faltings et al., 2021) provide short and simple instructions or commands to guide the editing process. In contrast, our benchmark XATU distinguishes itself by including fine-grained instructions for each data instance, which is necessary for assessing the genuine text editing capabilities of different systems. Furthermore, XATU also includes the rationale explanations for each of its instances, which have been proven to be significant for instruction fine-tuning models (Hsieh et al., 2023; Mukherjee et al., 2023).\\n\\n3. The XATU Benchmark\\n\\nWe introduced the XATU benchmark in this section. We outline the criteria for selecting datasets to construct XATU (\u00a73.1), how to annotate fine-grained instructions and explanations for the edits (\u00a73.2), and discuss various use cases (\u00a73.3). As shown in Figure 2, each instance in XATU comprises five key components: inputs, outputs, optional references, fine-grained instructions, and explanations.\\n\\n3.1. Data Source\\n\\nIn line with the systematic formulation of language style (DiMarco and Hirst, 1993), we adopt a similar approach to categorize text editing into four main editing aspects: lexical, syntactic, semantic, and knowledge. Our benchmark XATU aims to serve as a relatively comprehensive benchmark and a holistic evaluation framework for text editing tasks, covering all four aspects of text editing.\\n\\nTo ensure comprehensiveness and quality, we meticulously curate high-quality editing data from...\\n\\nInstruction: Modify the input text to incorporate details about the nature of the matches played, the players included in the tour, mention of Nat Sciver captaining the England team for the first time, and the simultaneous scheduling of New Zealand men's matches.\\n\\nInput: The England women's cricket team is scheduled to play against New Zealand women's cricket team in February and March 2021. The tour is scheduled to be played during the time that was originally scheduled to be used to host the ...\\n\\nReference: (0) The last three T201 matches took place on the same day as the New Zealand women's fixtures at the same venues...\\n\\n(7) Sophie_Ecclestone International career In February 2021, during England's tour of New Zealand, Ecclestone took her 100th international wicket.\\n\\n(8) Sarah_Glenn International career In 2021, Glenn was named in the squad for England's tour of New Zealand.\\n\\nOutput: The England women's cricket team played against the New Zealand women's cricket team in February and March 2021. The series was played during the time that was originally scheduled to be used to host the 2021 Women's Cricket World Cup, after the tournament was postponed by one year due to the COVID-19 pandemic...\\n\\nExplanation: The text editing system was instructed to update the text based on the references provided. It corrected the phrasing to past tense, indicating that the England and New Zealand women's cricket teams already 'played' the matches instead of 'scheduled to play'. The information about the tour, including the confirmation of fixtures...\\n\\nFigure 2: The instance format of the data in XATU benchmark. Data in blue (Input, Output, Reference) are extracted from the corresponding data sources, and data in green (Fine-grained instruction and explanation) are obtained from joint automatic and human annotations.\\n\\n4 distinct downstream NLP tasks, encompassing a total of 1000 annotated data from 9 data sources following DiMarco and Hirst (1993). A summary of the tasks and datasets, along with an overview of the editing aspects covered by each dataset, is presented in Table 2. We also transform all datasets within the XATU benchmark into a consistent format, extracting the input text, gold edits, task type, and optional reference documents from the following data sources, as illustrated in the example in Figure 2. This standardized format facilitates evaluation and comparison across different datasets within the benchmark.\\n\\nGrammar Error Correction\\n\\nThe first task in XATU is to identify and correct errors that don't follow grammar rules. We first incorporate data from JHU FLuency-Extended GUG (JFLEG) (Napoles et al., 2017), a dataset specifically designed for the task of grammar error correction. JFLEG uses holistic fluency edits to not only correct grammatical errors but also make the original text more native sounding. By including this dataset, we aim to assess the basic ability of text editing systems to improve fluency and grammatical accuracy simultaneously.\\n\\nSimplification\\n\\nWe also include ASSET (Alvamanchego et al., 2020), a text simplification dataset that provides manually produced simplifications through a wide range of transformation techniques. We aim to evaluate the text editing capabilities of systems when it comes to simplifying complex texts...\"}"}
{"id": "lrec-2024-main-1543", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: The detailed datasets included in the XATU benchmark.\\n\\n| Dataset             | Train | Test | Aspect                                      |\\n|---------------------|-------|------|---------------------------------------------|\\n| JFLEG               | 10    | 50   | Lexical, Syntactic                          |\\n| Simplification      | 10    | 50   | Lexical, Syntactic                          |\\n| Style Transfer      | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| ASSET               | 10    | 50   | Lexical, Syntactic                          |\\n| WNC                 | 10    | 50   | Lexical, Syntactic                          |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100  | Lexical, Semantic                           |\\n| StylePTB            | 20    | 100  | Lexical, Semantic                           |\\n| Wikibias            | 20    | 100 "}
{"id": "lrec-2024-main-1543", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"At least once an episode we see protestors marching around screaming slogans.\\n\\nOne or more times an episode protestors are seen walking around yelling blue slogans.\\n\\nInput:\\n\\nAt least once an episode we see protestors marching around screaming slogans.\\n\\nOutput:\\n\\nOne or more times an episode protestors are seen walking around yelling blue slogans.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"to investigate and address the following research questions:\\n\\n\u2022 **Q1**: What is the actual text editing ability of existing open/closed large language models? By evaluating the performance of LLMs, we aim to assess their effectiveness of instruction-based text editing and understand their limitations and strengths in this context.\\n\\n\u2022 **Q2**: How do fine-grained instructions in XATU differ from the coarse-grained instructions? By comparing the performance of models using fine-grained instructions from XATU, we seek to highlight the impact of instruction granularity on the quality and accuracy of text editing.\\n\\n\u2022 **Q3**: How do the explanations provided in XATU benefit model tuning under the fine-tuning settings? By examining the performance of models that incorporate the explanations provided in XATU during fine-tuning, we aim to evaluate the effectiveness of these explanations in improving model performance and understanding the role of explanations in the context of text editing.\\n\\n### 4.1. Experimental Setup\\n\\nWe include the following baseline LLMs in our experiments:\\n\\n\u2022 **GPT-3** (Brown et al., 2020) is a 175B parameter pre-trained decoder-only model.\\n\\n\u2022 **GPT-4** (OpenAI, 2023) is the most recent multimodal large language model created by OpenAI. It was pre-trained to predict the next token and was then fine-tuned with reinforcement learning from human and AI feedback. We evaluate both GPT-3 and GPT-4 through OpenAI\u2019s API.\\n\\n\u2022 **T5** (Raffel et al., 2020) is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks.\\n\\n\u2022 **Flan-T5** (Chung et al., 2022) is an enhanced version of T5 that has been instruction fine-tuned on a mixture of tasks.\\n\\n\u2022 **UL2** (Tay et al., 2023) is a unified framework for pre-training models with Mixture-of-Denoisers, a pre-training objective that combines diverse pre-training paradigms together.\\n\\n\u2022 **Flan-UL2** is an encoder-decoder model that uses the same configuration as the UL2 model. It was fine-tuned using the \u201cFlan\u201d prompt tuning and dataset collection.\\n\\n\u2022 **LLaMa** (Touvron et al., 2023) is a collection of foundation language models trained on trillions of tokens. It is an auto-regressive language model built on transformer architecture.\\n\\n\u2022 **Alpaca** (Taori et al., 2023) is an instruction-following language model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations.\\n\\nNote that PEER (Schick et al., 2023) is another strong text editing baseline according to results in Dwivedi-Yu et al. (2022). We didn\u2019t include it since the model checkpoint is not publicly available.\\n\\nFor evaluation, we use SARI scores (Xu et al., 2016), an n-gram based metric commonly used for measuring editing tasks such as simplification (Zhao et al., 2018) and sentence fusion (Malmi et al., 2019). It has been demonstrated to correlate most closely with human judgment and is computed as:\\n\\n$$SARI = \\\\frac{F_{1\\\\text{add}} + F_{1\\\\text{keep}} + P_{del}}{3},$$\\n\\nwhere \\\\(F_{1\\\\text{add}}\\\\), \\\\(F_{1\\\\text{keep}}\\\\), \\\\(P_{del}\\\\) represent the F1 scores and precision for add, keep, and delete operations, respectively. We utilize the Huggingface implementation of SARI, where \\\\(n = 4\\\\). EditEval (Dwivedi-Yu et al., 2022) includes more n-gram-based evaluation metrics, but the results do not demonstrate any significant difference from SARI scores.\\n\\n### Implementation Details\\n\\nWe use the Huggingface implementation of all models with LoRA (Hu et al., 2022) for the fine-tuning experiments. We instruction-tuned all models for 15 epochs with 200 training examples at a learning rate of \\\\(10^{-5}\\\\) and tested on the original 1000 test set, as shown in Table 2. We keep a small training data size as (Zhou et al., 2023a) found that alignment doesn\u2019t require too much data. We use LoRA (Hu et al., 2022) to instruction fine-tune all models for 15 epochs with 200 additional training examples at a learning rate of \\\\(10^{-5}\\\\).\\n\\n### 4.2. Zero-shot Results\\n\\nThe zero-shot evaluation results on the XATU benchmark are presented in Table 4, which highlights several important observations. GPT-4 demonstrates exceptional zero-shot editing performance, surpassing all other large\"}"}
{"id": "lrec-2024-main-1543", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Zero-shot text editing results of different LLMs under different prompt settings on XATU benchmark. We omit results on simple datasets that do not require fine-grained instruction. We use coarse, fine, and Exp. to represent text editing with coarse-grained instructions, fine-grained instructions, and explanations, respectively.\\n\\n| Model       | Setting | JFLEG | ASSET | WNC | Wikibias | PTB | FRUIT | Evidence | DeFacto | Factedit | Flan-T5 | Coarse | 64.98 | 52.01 | 62.54 | 55.58 | 51.05 | 19.06 | 39.13 | 36.77 | 7.98 |\\n|------------|---------|-------|-------|-----|----------|-----|-------|----------|---------|----------|---------|--------|-------|-------|-------|-------|-------|-------|-------|-------|------|\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |        |       |       |       |       |       |       |       |      |      |\\n|            |         |       |       |     |          |     |       |          |         |          |         |"}
{"id": "lrec-2024-main-1543", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"facing challenges in more complex tasks like information updates. In contrast, the Alpaca model performs well on information update tasks but achieves lower scores in simple neutralization tasks. We attribute this difference in performance to the underlying architecture of the foundation models: Flan-T5 and Flan-UL2 are both encoder-decoder models, while Alpaca is built upon the LLaMa decoder-only model. The results demonstrate that the encoder's ability to understand and represent the input text is more important for lexical and syntactic editing, while the decoder's capacity to generate new and relevant text appears to be more influential for knowledge-intensive tasks.\\n\\n4.3. Fine-tuning Results\\n\\nAfter fine-tuning all models using different prompting formats, we evaluate the fine-tuned models on XATU, and the results are presented in Table 5. A notable observation is the significant performance improvement compared to the zero-shot results across all datasets and under all settings. This demonstrates the effectiveness of instruction fine-tuning, even with a limited number of examples (200 in this case).\\n\\nAmong all the instruction fine-tuned models, Flan-UL2 consistently exhibits the strongest performance across all three settings. This indicates its strong adaptation capability during the fine-tuning process. Furthermore, we observe that the fine-grained instructions in XATU lead to larger performance improvements in tasks that have fine-grained instructions (e.g. FRUIT, DeFacto), while the improvements are comparatively smaller in simpler tasks that lack fine-grained instructions (e.g. WNC, PTB) in the fine-tuning data.\\n\\nComparing T5 and UL2 with their instruction-tuned versions (Flan-T5 and Flan-UL2), we observe that the instruction-tuned versions of LLM consistently outperform their base models. This is especially evident when the models are guided with fine-grained instructions or explanations. These results further emphasize the effectiveness of the instruction alignment ability that these models acquire through instruction fine-tuning.\\n\\nOverall, the fine-tuning process significantly improves the performance of the models on text editing tasks. The presence of fine-grained instructions and explanations further enhances the performance.\\n\\n4.4. Discussion\\n\\nAs illustrated in Figure 4, we compare the results of three models after instruction fine-tuning with fine-grained instructions in XATU vs. coarse-grained instructions. We observe that fine-grained instruction models consistently outperform their coarse-grained counterparts, indicating the effectiveness of detailed instruction in improving instruction following and text editing capabilities. Across both coarse-grained and fine-grained instruction settings, we find that the Flan-UL2 model achieves the largest average improvements. On the other hand, Alpaca demonstrates superior robustness across all text editing tasks compared to Flan-T5 and Flan-UL2.\\n\\nAs depicted in Figure 5, the Flan-UL2 model consistently outperforms the UL2 model across all settings. Similarly, the Flan-T5 model performs better than the base T5 model. These results highlight the effectiveness of instruction tuning in improving the performance of language models across different settings. The instruction-tuning procedure allows the models to better understand and follow the provided instructions, resulting in more accurate and appropriate text edits. We also notice edits generated with coarse-grained instructions show better robustness across all tasks.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"This paper introduces XATU, the first benchmark for explainable text updates with fine-grained instructions. XATU is a diverse benchmark covering a wide range of topics and text types and leverages high-quality data sources from various existing sources. We compare existing open and closed instruction-tuned language models under both the zero-shot and fine-tuning settings and reveal their capabilities to edit text and follow instructions. By releasing the benchmark to the community, we hope to stimulate further research in developing instruction-based text editing models and even potentially interactive text generation systems.\\n\\nAcknowledgements\\n\\nWe thank the anonymous reviewers for their valuable reviews. Additionally, we appreciate Tom Mitchell and the entire team at Megagon Labs for insightful discussions.\\n\\nBibliographical References\\n\\nAfra Feyza Aky\u00fcrek, Ekin Aky\u00fcrek, Aman Madaan, Ashwin Kalyan, Peter Clark, Derry Wijaya, and Niket Tandon. 2023. Rl4f: Generating natural language feedback with reinforcement learning for repairing model outputs. arXiv preprint arXiv:2305.08844.\\n\\nFernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton, Beno\u00eet Sagot, and Lucia Specia. 2020. ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4668\u20134679, Online. Association for Computational Linguistics.\\n\\nTalita Anthonio, Irshad Bhat, and Michael Roth. 2020. wikiHowToImprove: A resource and analyses on edits in instructional texts. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 5721\u20135729, Marseille, France. European Language Resources Association.\\n\\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, RewonChild, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, BenjaminChess, JackClark, ChristopherBerner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877\u20131901. Curran Associates, Inc.\\n\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.\\n\\nChrysanne DiMarco and Graeme Hirst. 1993. A computational theory of goal-directed style in syntax. Computational Linguistics, 19(3):451\u2013500.\\n\\nWanyu Du, Vipul Raheja, Dhruv Kumar, Zae Myung Kim, Melissa Lopez, and Dongyeop Kang. 2022. Understanding iterative revision from human-written text. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3573\u20133590, Dublin, Ireland. Association for Computational Linguistics.\\n\\nJane Dwivedi-Yu, Timo Schick, Zhengbao Jiang, Maria Lomeli, Patrick Lewis, Gautier Izacard, Edouard Grave, Sebastian Riedel, and Fabio Petroni. 2022. Editeval: An instruction-based benchmark for text improvements. arXiv preprint arXiv:2209.13331.\\n\\nFelix Faltings, Michel Galley, Gerold Hintz, Chris Brockett, Chris Quirk, Jianfeng Gao, and Bill Dolan. 2021. Text editing by command. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5259\u20135274, Online. Association for Computational Linguistics.\\n\\nManaal Faruqui, Ellie Pavlick, Ian Tenney, and Dipanjan Das. 2018. WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling language and discourse. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 305\u2013315, Brussels, Belgium. Association for Computational Linguistics.\\n\\nKelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. 2018. Generating sentences that are both helpful and correct. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 305\u2013315, Brussels, Belgium. Association for Computational Linguistics.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"by editing prototypes.\\n\\nTransactions of the Association for Computational Linguistics, 6:437\u2013450.\\n\\nOr Honovich, Uri Shaham, Samuel R. Bowman, and Omer Levy. 2023. Instruction induction: From few examples to natural language task descriptions. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1935\u20131952, Toronto, Canada. Association for Computational Linguistics.\\n\\nCheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023. Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. arXiv preprint arXiv:2305.02301.\\n\\nEdward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations.\\n\\nHayate Iso, Chao Qiao, and Hang Li. 2020. Fact-based Text Editing. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 171\u2013182, Online. Association for Computational Linguistics.\\n\\nRobert Iv, Alexandre Passos, Sameer Singh, and Ming-Wei Chang. 2022. FRUIT: Faithfully reflecting updated information in text. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3670\u20133686, Seattle, United States. Association for Computational Linguistics.\\n\\nZizhong Li, Haopeng Zhang, and Jiawei Zhang. 2023. A revisit of fake news dataset with augmented fact-checking by chatgpt. arXiv preprint arXiv:2312.11870.\\n\\nYixin Liu, Budhaditya Deb, Milagro Teruel, Aaron Halfaker, Dragomir Radev, and Ahmed Awadalhah. 2022. On improving summarization factual consistency from natural language feedback. arXiv preprint arXiv:2212.09968.\\n\\nYiwei Lyu, Paul Pu Liang, Hai Pham, Eduard Hovy, Barnab\u00e1s P\u00f3czos, Ruslan Salakhutdinov, and Louis-Philippe Morency. 2021. StylePTB: A compositional benchmark for fine-grained controllable text style transfer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2116\u20132138, Online. Association for Computational Linguistics.\\n\\nEric Malmi, Sebastian Krause, Sascha Rothe, Daniil Mirylenka, and Aliaksei Severyn. 2019. En-code, tag, realize: High-precision text editing. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5054\u20135065, Hong Kong, China. Association for Computational Linguistics.\\n\\nSubhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023. Orca: Progressive learning from complex explanation traces of gpt-4. arXiv preprint arXiv:2306.02707.\\n\\nCourtney Napoles, Keisuke Sakaguchi, and Joel Tetreault. 2017. JFLEG: A fluency corpus and benchmark for grammatical error correction. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 229\u2013234, Valencia, Spain. Association for Computational Linguistics.\\n\\nShashi Narayan, Shay B. Cohen, and Mirella Lapata. 2018. Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1797\u20131807, Brussels, Belgium. Association for Computational Linguistics.\\n\\nOpenAI. 2023. Gpt-4 technical report.\\n\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155.\\n\\nReid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, and Diyi Yang. 2020. Automatically neutralizing subjective bias in text. In Proceedings of the aaai conference on artificial intelligence, volume 34, pages 480\u2013489.\\n\\nAlec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. Technical report, Open AI.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1\u201367.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "lrec-2024-main-1543", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022. Opt: Open pre-trained transformer language models.\\n\\nSanqiang Zhao, Rui Meng, Daqing He, Andi Saptono, and Bambang Parmanto. 2018. Integrating transformer and paraphraserules for sentence simplification. In Proceedings of the 2018 Conference on Empirical Methodsin Natural Language Processing, pages 3164\u20133173, Brussels, Belgium. Association for Computational Linguistics.\\n\\nYang Zhong. 2021. WIKIBIAS: Detecting Multi-Span Subjective Biases in Language. Ph.D. thesis, The Ohio State University.\\n\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206.\\n\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2023b. Large language models are human-level prompt engineers. In The Eleventh International Conference on Learning Representations.\"}"}
{"id": "lrec-2024-main-1543", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A. Data Annotation\\n\\nThe human annotations were conducted on the Ap-\\npen platform, an example user interface is shown\\nin Figure 6.\\n\\nThe prompts used to generate the explanation\\nare:\\n\\n# Task:\\nYour task is to provide a two-sentence ex-\\nplanation of the edits made based on the\\ninstruction and reference by comparing the\\noriginal and revised texts.\\n\\n# Instruction:\\n\\n# Original text:\\n\\n# Reference:\\n\\n# Revised text:\\n\\n# Explanation:\\n\\nB. Implementation Details\\n\\nThe detailed instruction fine-tuning parameters are\\nsummarized in Table 6. We use LoRA (Hu et al.,\\n2022) to instruction fine-tune all models for\\n15 epochs with 200 additional training examples at\\na learning rate of $1 \\\\times 10^{-5}$.\\n\\nThe prompts used to generate the text editing\\nand fine-tuning are:\\n\\n| Prompt | Description |\\n|--------|-------------|\\n| Task   | Your task is to write a detailed instruction that enables the AI assistant to edit the original text into a revised text based on the references. The instruction must not cause information leakage about the revised text. |\\n| Original text: |  |\\n| Reference: |  |\\n| Revised text: |  |\\n| Instruction: |  |\\n\\nTable 6: Hyper-parameters used in the fine-tuning experiments.\\n\\n| Parameter     | Value       |\\n|---------------|-------------|\\n| lora           | \u03b1 = 0.1     |\\n| num_epochs    | 15          |\\n| lr            | $1 \\\\times 10^{-5}$ |\\n| dropout       | 0.1         |\\n| seed          | 634         |\\n| max_length    | 1024        |\"}"}
{"id": "lrec-2024-main-1543", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 6: The interface used for annotation.\"}"}
