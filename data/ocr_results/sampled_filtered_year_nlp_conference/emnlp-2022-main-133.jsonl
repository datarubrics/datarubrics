{"id": "emnlp-2022-main-133", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: Effect sizes obtained with the CA-WEAT tests in the CCeVMsup, CCeVMuns, CCe2langs and CCe9langs monolingual embedding models as a function of the difference in the number of pleasant and unpleasant attributes in the training corpus CCe.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### E Bias Statistic and Effect Size\\n\\n| Language | Original BERT | Original WP | WEAT 1: Flowers and Insects | BERT XGLM | CCeVM | CCe2langs | CCe9langs |\\n|----------|---------------|-------------|----------------------------|-----------|--------|-----------|-----------|\\n| English  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Arabic   | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Chinese  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Spanish  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| French   | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| German   | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Italian  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Russian  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n| Turkish  | 0             | 0           | 0                          | 0         | 0      | 0         | 0         |\\n\\nNote: The WEAT 1: Flowers and Insects statistic is shown for each language, along with the 95% confidence intervals obtained by bootstrap resampling of the lists.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"WEAT 1: Flowers and insects\\n\\n| Language | Median | 95% Confidence Interval |\\n|----------|--------|-------------------------|\\n| en       |        |                         |\\n| ca       |        |                         |\\n| de       |        |                         |\\n| es       |        |                         |\\n| hr       |        |                         |\\n| it       |        |                         |\\n| ru       |        |                         |\\n| tr       |        |                         |\\n\\nWe report the median and 95% confidence intervals.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"WEAT 1: Flowers and insects\\n\\nmBERT\\n\\nWPali\\n\\nCCeVMuns \u2013\\n\\nWPali\\n\\nXLM-R\\n\\nCCWP\\n\\nXLM-R\\n\\nCCe9langs\\n\\nXGLM\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0"}
{"id": "emnlp-2022-main-133", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"WEAT 1: Flowers and insects\\n\\nWP 1.7 1.4 +0.1\\n\\n\u22120.4 0.0 1...\\n\\nThe number of lists per language is shown as subindex of the language. We report the median and 95% confidence intervals.\\n\\nTable 9: Effect size for CA-WEAT tests with lists created for 9 languages; the original English WEAT (en) is shown for comparison. The number of lists per language is shown as subindex of the language. We report the median and 95% confidence intervals.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 8: Effect size as a function of EV and GH between English and each of the other 8 languages. Considered models are WP, WPali, CCWP, CCe, CCeVMuns, CCeVMsup, CCe2langs, CCe9langs, mBERT, XLM-R, and XGLM. Table 1 in the main text reports the values of the measures for these models.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nSome human preferences are universal. The odor of vanilla is perceived as pleasant all around the world. We expect neural models trained on human texts to exhibit these kind of preferences, i.e. biases, but we show that this is not always the case. We explore 16 static and contextual embedding models in 9 languages and, when possible, compare them under similar training conditions. We introduce and release CA-WEAT, multilingual cultural aware tests to quantify biases, and compare them to previous English-centric tests. Our experiments confirm that monolingual static embeddings do exhibit human biases, but values differ across languages, being far from universal. Biases are less evident in contextual models, to the point that the original human association might be reversed. Multilinguality proves to be another variable that attenuates and even reverses the effect of the bias, specially in contextual multilingual models. In order to explain this variance among models and languages, we examine the effect of asymmetries in the training corpus, departures from isomorphism in multilingual embedding spaces and discrepancies in the testing measures between languages.\\n\\n1 Introduction\\n\\nThe perception of odor pleasantness has been shown to be universal. Even if variations across individuals exist, they do not depend on culture (Arshamian et al., 2022). We call this a human bias: judging a phenomenon in terms of values that are inherent in human beings, regardless of their sociocultural background. On the contrary, a cultural bias is \u201cthe tendency to interpret and judge phenomena in terms of the distinctive values, beliefs, and other characteristics of the society or community to which one belongs\u201d.1 Racism, sexism, ageism, etc. are all social cultural biases and can be more or less present in distinct communities.\\n\\nAs long as neural systems are trained on general-domain texts written by humans, one would expect and desire human biases to be present in embedding models for all languages. One would also expect (but not always desire) cultural biases, but these would depend on the language or the culture behind it. Lots of work has been done on detecting social cultural biases and trying to mitigate them (Bolukbasi et al., 2016; Zhao et al., 2018; Gonen and Goldberg, 2019; Ravfogel et al., 2020; Dev et al., 2020; Schick et al., 2021; Zhou et al., 2022). Also recent work has investigated the presence of human biases in static word embeddings; first in English (Caliskan et al., 2017) and later in other languages (Lauscher and Glava\u0161, 2019; Lauscher et al., 2020a,b). These works make use of the Word Embedding Association Test (WEAT) for English \u2014lists of concepts and attributes that hide implicit human associations as described in Section 2\u2014 and X-WEAT, WEAT's translations, for other languages. To the best of our knowledge, research on language models and contextualised embeddings, has been done only in English, using extensions or variations of WEAT (May et al., 2019; Kurita et al., 2019; Guo and Caliskan, 2021).\\n\\nNatural language processing aspires to multilinguality. When talking about embeddings, one achieves multilinguality by mapping two or more spaces into a single one, or by joint training with text in two or more languages. These are the two main approaches to crosslingual word embeddings (Ruder et al., 2019) and the approaches used to train language models (Devlin et al., 2019; Lin et al., 2021; Conneau et al., 2020b).\\n\\nWe go deeper into the understanding of multilingual embedding models and the effect, if any, of the different approaches used to build them. For this purpose, we first review results and some of the implicit assumptions made in previous works.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"by investigating (i) whether translations from the original WEAT English lists (X-WEAT) are fair tests for other languages and (ii) whether a single list, either original or translated, is representative for a language. Second, for the first time we define and collect cultural aware WEAT lists (CA-WEAT) to enable multilingual analyses completely independent of English. Third, we use WEAT, X-WEAT and CA-WEAT to study the effect of cross-and multilinguality in embedding models; that is, how they differ with respect to the monolingual English. Since differences do exist, we try to explain them in terms of the testing measure (*-WEAT), the nature of the training corpora, the method to achieve multilinguality and the final differences in the topology of the embedding spaces between languages. We perform a systematic study over 9 languages of 3 families in word embeddings from 16 static and contextual models. Our premise is that biases should be equally present, and we analyse departures from this premise with the focus on multilinguality.\\n\\n2 Quantifying Bias with WEAT\\n\\nThe Word Embedding Association Test (WEAT) (Caliskan et al., 2017) is a bias measurement method for word embeddings. WEAT is inspired by the Implicit Association Test (IAT) for humans (Greenwald et al., 1998), which measures differences in response time when subjects are requested to pair items and attributes that they find similar and when pairing items and attributes that they find different. To give an example, subjects would be first asked to label the item orchid as flower-pleasant or insect-unpleasant. This would be repeated for several flowers and insects. In a second part, subjects would be asked to label the same list of items as insect-pleasant or flower-unpleasant. Experiments show that the response time for the first part is lower than for the second one. The cognitive effort for the latter is higher because the association flower-unpleasant is less expected than flower-pleasant. These results expose a human bias: flowers are more pleasant than insects and insects are more unpleasant than flowers. If this is a universal human bias, one would expect it to be present also in embeddings created from human texts. Flowers in a semantic space should be closer to pleasant attributes than insects, and insects closer to unpleasant attributes than flowers.\\n\\nMany WEAT (and IAT) tests exist; most of them are designed to measure biases (implicit associations) towards racial groups, gender, sexuality, age, and religion. Only two are non-social and therefore we expect them to be culture-and language-independent: flowers/insects vs. pleasant/unpleasant (WEAT1) and musical instruments/weapons vs. pleasant/unpleasant (WEAT2). These are considered \\\"universally accepted stereotypes\\\" (Greenwald et al., 1998; Toney and Caliskan, 2021). Each attribute and concept in these tests has associated a list of 25 English terms, collected as described in Section 3 (listed in Appendix C). The original WEAT measure (Caliskan et al., 2017) defines the association of each term \\\\( t \\\\) (e.g. orchid) as its average cosine similarity to the list of target attributes \\\\( A \\\\) (e.g. pleasant concepts):\\n\\n\\\\[\\n\\\\text{assoc}(t,A) = \\\\frac{\\\\sum_{a \\\\in A} \\\\text{sim}(t,a)}{|A|},\\n\\\\]\\n\\nwhere \\\\( t \\\\) is the embedding for \\\\( t \\\\) and \\\\( a \\\\) is the embedding for an element \\\\( a \\\\in A \\\\).\\n\\nThe association difference \\\\( \\\\Delta \\\\text{assoc} \\\\) for a term \\\\( t \\\\) between attributes \\\\( A \\\\) (pleasant) and \\\\( B \\\\) (unpleasant) is then\\n\\n\\\\[\\n\\\\Delta \\\\text{assoc}(t,A,B) = \\\\text{assoc}(t,A) - \\\\text{assoc}(t,B).\\n\\\\]\\n\\nGiven two sets of target terms \\\\( X \\\\) and \\\\( Y \\\\) with \\\\( n \\\\) elements each (e.g., flowers and insects), the statistic \\\\( s \\\\) is the difference in average similarity of their terms with elements from \\\\( A \\\\) and \\\\( B \\\\):\\n\\n\\\\[\\ns(X,Y,A,B) = \\\\sum_{x \\\\in X} \\\\Delta \\\\text{assoc}(x,A,B) - \\\\sum_{y \\\\in Y} \\\\Delta \\\\text{assoc}(y,A,B).\\n\\\\]\\n\\nWe use Cohen's \\\\( d \\\\) to estimate the effect size (i.e. the strength of the bias). Cohen's \\\\( d \\\\) is a standardised measure of the effect defined as the difference between the two means divided by the standard deviation for all instances in \\\\( X \\\\) and \\\\( Y \\\\):\\n\\n\\\\[\\nd = \\\\frac{\\\\mu(\\\\Delta \\\\text{assoc}(x,A,B) \\\\forall x \\\\in X) - \\\\mu(\\\\Delta \\\\text{assoc}(y,A,B) \\\\forall y \\\\in Y)}{\\\\sigma(\\\\Delta \\\\text{assoc}(w,A,B) \\\\forall w \\\\in X \\\\cup Y)}.\\n\\\\]\\n\\nSawilowsky (2009) defined the scale of magnitude for \\\\( d \\\\) as very small (\\\\(<0.01\\\\)), small (\\\\(<0.20\\\\)), medium (\\\\(<0.50\\\\)), large (\\\\(<0.80\\\\)), very large (\\\\(<1.20\\\\)), and huge (\\\\(<2.00\\\\)).\\n\\nLauscher and Glava\u0161 (2019) showed no significant difference in the results obtained with cosine similarity and Euclidean distance. We confirmed the results and only report those with cosine similarity.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Both IAT and WEAT have been traditionally created in the north east of the US and performed in English. The pleasant and unpleasant words used in WEAT1 and WEAT2 were selected from norms in Bellezza et al. (1986), where college students in Ohio rated a list of words for pleasantness. From this list, 25 elements were taken as pleasant words and 25 as unpleasant words by Greenwald et al. (1998). The lists for flowers, insects, musical instruments, and weapons were extracted from Battig and Montague (1969), where college students from Maryland and Illinois were given 30 seconds to write down as many objects within each category as possible. Greenwald et al. (1998) selected 25 unambiguous items that they thought their students would be familiar with. These two requests are relevant: they ensure taking frequent words in the language that have a single meaning.\\n\\nThe first experiment with word embeddings was done by Caliskan et al. (2017) who used pre-trained English GloVe embeddings (Pennington et al., 2014). They observed that, according to their results on social biases, the training corpus \u201cmay be disproportionately American\u201d. Subsequent studies used crosslingual WEAT (X-WEAT) to go beyond analyses in English (Lauscher and Glava\u0161, 2019; Lauscher et al., 2020a). The original lists were translated into several languages and biases estimated using the translated items and attributes. They found differences in the biases obtained across languages and connected them to differences in the size of the training corpora. They also explored bilingual spaces and observed that the bias effects were in the middle of the two corresponding biases in the monolingual spaces.\\n\\nAs discussed, WEAT1 and WEAT2 originate in the US. Even if a concept (flower) might be considered pleasant in every culture, the items themselves (orchid, broom, etc.) can be different across cultures. This is most evident for elements that depend on geography (a flower that grows in the US or an insect that lives there might not be present in other locations), but it could happen for all the other items in WEAT1 and WEAT2. As a result, the representation of the original translated items in the training data in other languages might be smaller or, even worse, the distribution of the opposite attributes asymmetric. As we will show, there is already a variation in the terms and attributes used by different people within a common culture, but testing the existence of human biases with translations from American English might be inducing an additional cultural bias in the results. There is a second argument to avoid X-WEAT: translations are not perfect and one cannot assure that the requirements in Greenwald et al. (1998) (unambiguous and frequent words) hold. For example, the Spanish X-WEAT translates blade as hoja (the edge of a knife, but also a sheet of paper) and turns both fiddle and violin into viol\u00edn. Whereas correct, translation introduces an ambiguous word lacking any association to (un)pleasant attributes in the former case, and reduces the size of the list in the latter.\\n\\nTo mitigate the problems introduced by translations and to estimate their impact in the analysis, we create CA-WEAT: a new collection of cultural-aware lists written by native speakers of different languages. We asked volunteers to create lists of flowers, insects, weapons and musical instruments, as well as both pleasant and unpleasant concepts with 25 elements each without any time constraint. The only requirement was that words needed to be common in their culture. Lists from different volunteers are semantically equivalent, since they characterise the same concepts, and can be seen as perturbations on a prototypical (or average) set.\\n\\nWe first conducted a pilot study with 14 volunteers from 11 nationalities to survey the difficulty of the task and prepare the guidelines of the experiment. Five of them failed to complete the task. After the pilot, we set up an online form with detailed instructions (see Appendix A) and distributed it to contacts in different countries. We collected 112 CA-WEAT lists in 26 languages from which we discarded 9 after a quality check. For the current experiments, we selected 9 of the 26 languages, for a total of 82 lists. The lists in the remaining 17 languages are provided in the CA-WEAT dataset but we do not use them in the subsequent analysis; statistics for all of them are reported in Appendix B. The languages considered here are chosen according to 3 criteria: high-quality embeddings could be obtained, the equivalent X-WEAT exists or could be created by a native speaker at hand, and different language families are covered. These constraints led to considering Arabic (ar), Catalan (ca), Croatian (hr), English (en), German (de), Italian (it), Russian (ru), Spanish (es) and Turkish (tr). The distribution among languages...\"}"}
{"id": "emnlp-2022-main-133", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"is not even: we collected 24 lists in Italian and German, 12 in Croatian, 10 in Spanish, 5 in English, 2 in Catalan, Romanian and Turkish, and 1 in Arabic. Instead of aggregating the highest ranked/most frequent words per concept into a single list as WEAT does, CA-WEAT uses all the words and provides a list per subject. This allows us to study statistically the variations and the relevance of the test sets.\\n\\nFor X-WEAT, we use the translations provided by Lauscher and Glava\u0161 (2019) and Lauscher et al. (2020b), after revising the Spanish ones and adding the Catalan translations.\\n\\n4 Embedding Models\\n\\nWe consider 16 embedding models for the 9 selected languages. We select two kinds of models. On the left-hand side, widely-used out-of-the-box pre-trained models. On the right-hand side, models trained in-house. For the latter, we control both the amount and domain of the training data, as well as the approach used to reach multilinguality.\\n\\nFor static embeddings, we use pre-trained fastText word embeddings:\\n\\n4 WP: Monolingual models trained on Wikipedia using the skip-gram architecture with subword information, as described by Bojanowski et al. (2017).\\n\\n4 WPali: WP aligned to English with the RCSLS method as described by Joulin et al. (2018).\\n\\n4 CCWP: Models trained on Common Crawl and Wikipedia using CBOW with position weights and subword information (Grave et al., 2018).\\n\\nWe also build 5 static in-house word embeddings on Common Crawl using a subset of the CC-100 corpus (Conneau et al., 2020a; Wenzek et al., 2020). We enforce to have the same number of words for all 9 languages under study (CCe) by ceiling the size to that of the language with the smallest corpus: Catalan, with $1.7 \\\\times 10^9$ words (see Appendix D). For comparison purposes, the training of the 5 models is done with the same architecture and hyperparameters as in CCWP: CBOW with position-weights, 300 dimensions, character 5-grams, a window of size 5 and 10 negatives. The five in-house embeddings are:\\n\\n- CCe: Monolingual embeddings trained on CCe.\\n- CCeVMuns: CCe aligned to the English space using unsupervised VecMap (Artetxe et al., 2018b).\\n- CCeVMsup: Supervised VecMap (Artetxe et al., 2018a) using the test part of the cross-lingual dictionaries in MUSE.\\n- CCe2langs: Bilingual embeddings trained on the concatenation of CCe-en and CCe-Li for one of the other 8 Li languages.\\n- CCe9langs: Multilingual embeddings trained on the concatenation of the 9 CCe-Li.\\n\\nPurely static embeddings are compared to word embeddings extracted from 3 pre-trained contextual models:\\n\\n- mBERT 0: Static embeddings (layer 0) in multilingual BERT (Devlin et al., 2019); trained on 104 languages including the ones we analyse with a BPE vocabulary of 110k.\\n- mBERT 11: Embeddings in the next-to-last layer (layer 11) of multilingual BERT.\\n- BERT 0: We use monolingual BERT for Arabic (Antoun et al., 2020), German, Italian (Schweter, 2020b), Spanish (Ca\u00f1ete et al., 2020), Turkish (Schweter, 2020a) and English (Devlin et al., 2019). For the other languages, the model is not available or it finetunes mBERT.\\n- BERT 11: Embeddings in the 11th layer of the same models as in BERT 0.\\n- XLM-R 0: Static embeddings in XLM-RoBERTa (Conneau et al., 2020a); trained on 100 languages with a BPE vocabulary of 250k.\\n- XLM-R 11: Embeddings in the next-to-last layer of XLM-RoBERTa.\\n- XGLM 0: Static embeddings in XGLM (Lin et al., 2021); trained on 30 languages with a BPE vocabulary of 250k, excluding Croatian.\\n- XGLM 11: Embeddings in the next-to-last layer (layer 47 in this case) of XGLM.\\n\\nWhile static word2vec-like embeddings have 300 dimensions, BERT embeddings have 768, XLM-RoBERTa 1024 and XGLM 2048.\\n\\n5 Experiments and Results\\n\\nWe calculate the statistic and the effect size (Cohen\u2019s $d$) for the 16 types of embeddings in the 9 languages for WEAT1, WEAT2, the 82 CA-WEAT1.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For the statistical analysis of the results, we estimate the uncertainty on the statistic and the effect size by (i) averaging the results with multiple lists for CA-WEAT and (ii) creating bootstrapped versions of a single instance in all cases: WEAT, X-WEAT and CA-WEAT. For the average version, we provide the median and 95% confidence intervals (CI) using order statistics given that the distributions are non-normal and contain few elements. For the bootstrapped version, we resample with replacement the four lists involved in an experiment to generate 5,000 synthetic sets per test. Tables 6, 7, 8 and 9 in Appendix E show the detailed results.\\n\\nBoth the source code and the data to reproduce our analysis, including the revised X- and the CA-WEAT lists, are available at https://github.com/cristinae/CA-WEAT.\\n\\nPrevious work reported $p$-values in permutation tests. Since we are interested in variances between languages and within a language itself, we chose to report confidence intervals instead. We adapt the code in Lauscher and Glava\u0161 (2019) for this purpose.\\n\\nFirst, we compare the conclusions one gets using each of the three testing alternatives. Figure 1 depicts the effect size estimations for X-WEAT and the median of the CA-WEAT tests. Biases measured with X-WEAT are in general higher than those with CA-WEAT, specially for pure static embeddings, but differences are not statistically significant at 95% level. The dispersion within a model and across languages is smaller for CA-WEAT than for X-WEAT; an indication that a single list is not representative for a language and the average of several lists helps to get closer to a universal effect size value.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Effect sizes for WEAT1 and 5 CA-WEAT1 tests in American English (top row). The other plots correspond to Italian for 9 representative word embedding models. The numbers displayed in Figure 1. The five lists show very different behaviours across models, but also within a single model. For the monolingual model CCe, we see that for three of the lists the effect is compatible with no bias at 95% level. One would expect the average of the English CA-WEAT lists to be close to WEAT, as the latter was obtained by combining inputs from several subjects. However, the variation is huge and depends on the model. In order to be able to substitute WEAT with CA-WEAT, one needs multiple samples. X-WEAT can be considered as just one of these samples and this can explain why the variation across languages is larger with X-WEAT than with CA-WEAT.\\n\\nThe remaining plots in Figure 2 compare X- and CA-WEAT1 by looking at the variation in more samples, the Italian lists. The variation among CA-WEATs is large for all models, and X-WEAT results are within the CIs of CA-WEAT. According to Sawilowsky (2009)'s scale, the magnitude of the biases ranges from medium (\\\\(d<0.5\\\\)) to very large (\\\\(d<1.2\\\\)) for X-WEAT and from small (\\\\(d<0.2\\\\)) to large (\\\\(d<0.8\\\\)) for CA-WEAT. Similar trends are seen for German, also with 24 CA-WEATs.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Effect sizes observed in the CCe model for only X-WEAT1 (top) and all *-WEAT1 tests (bottom) as a function of the asymmetry between counts of positive and negative attributes in the training corpus.\\n\\nComparable experiments with CCe. We compare the effect size across languages and multilingual methods in the setting where all the embedding models are trained in a similar domain, using the same amount of data. The size of the corpus is not the only deciding factor though, as the number of times that the items in the lists appear in the corpus might also have an effect. Words in the lists are frequent enough (billions of occurrences) to get high quality embeddings, but an asymmetry between the number of positive and negative concepts might create an artificial bias.\\n\\nWe test this hypothesis by studying the correlation between the bias effect size and the difference between the counts of the positive (pleasant) and the negative (unpleasant) attributes. Figure 3 shows the relation for the monolingual CCe embedding models. The correlation seems important for X-WEAT1 (top plot), which shows a positive trend with half of the variation in the effect size being explained by the number of counts $R^2 = 0.493$.\\n\\nHowever, this might be an effect of either having only 9 data points or X-WEAT and CA-WEAT coming from two different distributions. When we consider the 82 CA-WEAT1 tests and the 9 X-WEAT1 (bottom plot), we observe a flat slope where the variance is not explained by the counts ($R^2 = 0.001$). Results for X-/CA-WEAT2 are equivalent, with $R^2 = 0.334$ and $R^2 = 0.008$ respectively.\\n\\nCA-WEAT lists allow to see that the lack of trend is language independent. The average effect size for Spanish is higher than for German, the count difference is larger for English than for Croatian, but in none of the cases can the asymmetry counts explain the effect size variance.\\n\\nMultilinguality changes the distribution of effect sizes and also the attribute counts in the training corpus of some models. While CCeVMuns and CCeVMsup project the pre-trained spaces into a common one, CCe2langs and CCe9langs train the joint embeddings on the concatenated corpus. In this case, the counts change as different languages can share the same surface token for some words. This might be a reason why differences in biases with respect to English in languages with different scripts are more relevant than differences with languages in different families. But it is not the only reason, as we observe the same trend in the projection methods. In general, the 4 multilingual approaches share the same conclusions as their monolingual counterparts: for X-WEAT one observes a positive correlation between $d$ and the difference of counts but, when inspecting all the CA-WEAT lists, the correlation disappears.\\n\\nCCe9langs with the widest differences of counts shows almost no correlation for X-WEAT as well.\\n\\nMultilingual models and isomorphism. Going from monolingual CCe to bilingual CCeVMuns implies a mitigation of the bias for CA-WEAT but biases remain close to constant for X-WEAT (see Figure 1). Contrary to the findings by Lauscher and Glava\u0161 (2019), the bilingual embeddings do not show a bias halfway between that of the 2 languages. The effect of supervision (CCeVMuns vs CCeVMsup) is not consistent and results are in general equivalent. With few exceptions, the effect of CCe2langs and especially of CCe9langs is also a mitigation of the bias with respect to the one observed in the corresponding monolingual model CCe, but this is not statistically significant at 95% level. Arabic and Russian, both with non-Latin alphabets, have the lowest $d$ (together at times with Turkish, the only other non-Indo-European language), but we cannot attribute it to multilinguality, because their effect size is also low for the monolingual embeddings.\\n\\nTo further investigate what is behind the variance...\"}"}
{"id": "emnlp-2022-main-133", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Isomorphism measures (EV and GH) between the English (sub)space and the (sub)spaces for the other 8 languages for 11 representative embedding models. (\\\\(*)\\\\) XGLM does not include hr data in training.\\n\\nIn the multilingual setting, we evaluate the isomorphism between spaces. Intuitively, if spaces are isomorphic, multilinguality should not alter the properties of the monolingual embeddings; if spaces are far from being isomorphic, a joint training might distort semantics and translations could lie further apart in projected spaces. Some differences in \\\\(d\\\\) could be therefore explained if spaces are not (close to) isomorphic. We use two well known measures: the Eigenvector similarity (EV) (S\u00f8gaard et al., 2018) and the Gromov-Hausdorff distance (GH) (Patra et al., 2019).\\n\\nIn both cases, lower values indicate more isomorphic spaces. For \\\\(WP\\\\), \\\\(WPali\\\\), \\\\(CCWP\\\\), \\\\(CCe\\\\), \\\\(CCeVMuns\\\\) and \\\\(CCeVMsup\\\\), we calculate the values between English and each one of the other 8 languages \\\\(L_i\\\\). For \\\\(CCe2langs\\\\), \\\\(CCe9langs\\\\), \\\\(mBERT\\\\), \\\\(XLM-R\\\\) and \\\\(XGLM\\\\), we extract the subspaces for English and \\\\(L_i\\\\) using the vocabulary in the English CCe and in the \\\\(L_i\\\\) CCe and calculate the distance between the subspaces. Table 1 compiles the results. As noted by Patra et al. (2019) and Dutta Chowdhury et al. (2021), the metrics do not produce equivalent results; the correlation between EV and GH is \\\\(\\\\rho = 0.47\\\\) in our case. Interestingly, there is a systematic decrease of the effect size with increasing distances, both for EV and GH. The trend is more evident for GH and applies both to X-WEAT and CA-WEAT. Figure 4 shows the trend for *-WEAT1. The correlation between GH and the effect size is in this case \\\\(-0.29\\\\) and GH describes only a 10% of the variance. Similar results are obtained for EV, GH, X-WEAT2 and CA-WEAT2, as detailed in Appendix F.\\n\\nWe use \\\\(https://github.com/cambridgeltl/iso-study\\\\) for EV and GH (Vuli\u0107 et al., 2020) with the\\n\\nFigure 4: Effect size as a function of GH for X-/CA-WEAT1 in all the embedding models of Table 1.\\n\\nStatic embeddings in contextualised models. Previous work focused on simple English sentences. May et al. (2019) introduced the Sentence Encoder Association Test (SEAT). They generate templates such as \\\"This is \\\\[TARGET\\\\].\\\" or \\\"\\\\[TARGET\\\\] are things.,\\\" were \\\\[TARGET\\\\] is substituted by words in WEAT tests. Kurita et al. (2019) also use templates (\\\\\\\"[TARGET]\\\\ is a \\\\[ATTRIBUTE]\\\\\\\") for social biases and WEAT1 and compare the results from the standard WEAT measure and a new log probability bias score. Finally, Guo and Caliskan (2021) define yet another metric: the Contextualized Embedding Association Test (CEAT) which, instead of using a single template, collects sentences where WEAT terms appear in different contexts. The three methods have been evaluated on WEAT1 with BERT with May et al. (2019) default most frequent 10k words for EV and 5k for GH.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"containing an effect size of 0.22, Kurita et al. (2019) of 0.67 and Guo and Caliskan (2021) of 0.64. When we move to the multilingual setting in our experiments, we do not consider sentences, but single words for which we extract the corresponding embedding. Words are built from the subunits in the language model vocabulary but, other than that, no context is considered. This allows a fair comparison across languages. As Figure 1 shows, static embeddings in contextual models show almost no bias and even negative effect sizes. The trend is specially confirmed for the languages for which more CA-WEAT lists are available (it, de, hr, es). Also notice that multilinguality further blurs the biases. In general, monolingual BERT models present less (desired) biases than WP, WPali and CCWP for all languages but more biases than the multilingual language models. This is not a consequence of a lower isomorphism between language subspaces, as Table 1 shows. We conjecture that building word vectors from subunits might have an impact in semantics at the word level. Differences observed on models coming from different layers are neither consistent nor significant.\\n\\n6 Summary and Conclusions\\nNon-social human biases in embeddings are usually measured through WEAT association tests built in English, in the US. We hypothesise that this can be an issue when analysing embeddings in other languages or cultures. In order to address the question, we collected WEAT1 and WEAT2 lists written by natives of 9 languages, which we call cultural aware tests: CA-WEAT. We showed that different CA-WEATs produce a large variation in the biases and their effect size. The values for WEAT and X-WEAT always lie within the CA-WEAT confidence intervals. This supports the idea that a single list (test) is not suitable for the analysis. Since we do not have a gold standard for the real bias we should expect in embeddings, one could argue that the correct bias is the one given by the WEAT test, as it has been carefully designed. However, this argument only holds for (American) English. For any other language, X-WEAT cannot assure the same properties as WEAT. CA-WEAT, the multilingual crowdsourced versions of WEAT, are the alternative to X-WEAT.\\n\\nWe extend previous work to multilingual and language models taking this observation into account and perform in parallel the analysis for WEAT, X-WEAT and CA-WEAT. We confirm that monolingual static embeddings show signs of non-social human biases in all languages under study. When using the average CA-WEAT, the dispersion of among languages for each model is smaller than the dispersion with X-WEAT. This is an indication that the average of several lists helps to get closer to the expected universal results across languages. Multilinguality has the effect of mitigating biases. This is seen in static word embeddings but it is more evident in embeddings extracted from language models. On the other hand, word embeddings in language models already produce a huge mitigation with respect to their static counterparts, up to the point that effect sizes in multilingual language models can be negative. As a result, the trend can be inverse to the one observed in humans, being insects more pleasant than flowers in some languages.\\n\\nUnexpectedly, the asymmetry between the amount of pleasant and unpleasant attributes in the training corpus is not responsible for the variance in the embeddings biases. Since CA-WEAT includes only frequent words in our training corpora, reliable representations are obtained, irrespective of any asymmetry. Differences in departures from isomorphism between languages in multilingual models describe up to a 10% of the variance. Even the trend is clear, this alone cannot explain the mitigation of the biases in either multilingual or contextualised models.\\n\\nIn the light of these outcomes, we expect to broaden the analysis to a more diverse set of languages extending the CA-WEAT tests, and design a fair multilingual setting for language models at sentence level.\\n\\nLimitations\\nTo the best of our knowledge, only 2 IAT tests are non-social, the other ones relate to other kinds of biases, such as gender or race, which are not pertinent for our study. We observe a large variability in the results between models but sometimes also between *-WEAT1 and *-WEAT2. More non-social psychologically-motivated IAT tests would be relevant to strengthen our conclusions.\\n\\nWhen we defined CA-WEAT, we chose not to constrain the list of items and attributes to single words, multi-word terms were allowed for a wider coverage and also for a future reusability of the tests for sentence embeddings. As a result, some...\"}"}
{"id": "emnlp-2022-main-133", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"items in the lists can be out-of-vocabularies (OOV) in static word embeddings. This is relevant for Arabic, with 14 OOVs in both the WP embeddings and the CCe variants for X-WEAT1, and 6 and 7 OOVs for X-WEAT2 respectively. Turkish follows with 11 and 7 OOVs for X-WEAT1, and 5 and 3 for X-WEAT2. There are no OOVs in contextualised embeddings, where we sum the embeddings for all the subword units in a term.\\n\\nEthayarajh et al. (2019) showed that WEAT and the way how the effect size is calculated causes a systematic overestimation of the biases. They also showed that in word embedding models that do some kind of matrix factorisation, such as skip-gram with negative sampling (it factorises a shifted word-context PMI matrix (Levy and Goldberg, 2014)) or GloVe (it factorises a logarithmic co-occurrence count matrix (Pennington et al., 2014)) having no bias is only possible if the positive (pleasant in our case) and negative (unpleasant) attributes occur with equal frequency in the corpus. Since the main motivation of our work is to study the effect of multilinguality and not the base models, we dodge the limitation for static embeddings by using CBOW, and we empirically show in Section 5 that the bias in our CBOW experiments does not correlate with the differences between pleasant and unpleasant counts in the corpus. However, the pre-trained WP and WPali used skip-gram and might be affected.\\n\\nAcknowledgements\\n\\nWe thank the students of the Department of Interpreting and Translation at Universit\u00e0 di Bologna, colleagues at Universit\u00e4t des Saarlandes, DFKI and several other locations around the world for producing the CA-WEAT dataset. CEB was supported by the German Research Foundation (Deutsche Forschungsgemeinschaft) under grant SFB 1102: Information Density and Linguistic Encoding.\\n\\nReferences\\n\\nWissam Antoun, Fady Baly, and Hazem Hajj. 2020. AraBERT: Transformer-based model for Arabic language understanding. In Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection, pages 9\u201315, Marseille, France. European Language Resource Association.\\n\\nArtin Arshamian, Richard C. Gerkin, Nicole Kruspe, Ewelina Wnuk, Simeon Floyd, Carolyn O'Meara, Gabriella Garrido Rodriguez, Johan N. Lundstr\u00f6m, Joel D. Mainland, and Asifa Majid. 2022. The perception of odor pleasantness is shared across cultures. Current Biology, pages 1\u20136.\\n\\nMikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018a. Generalizing and improving bilingual word embedding mappings with a multi-step framework of linear transformations. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1):5012\u20135019.\\n\\nMikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018b. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 789\u2013798, Melbourne, Australia. Association for Computational Linguistics.\\n\\nWilliam F. Battig and William Edward Montague. 1969. Category norms of verbal items in 56 categories a replication and extension of the connecticut category norms. Journal of Experimental Psychology, 80:1\u201346.\\n\\nFrancis Bellezza, Anthony Greenwald, and Mahzarin Banaji. 1986. Words high and low in pleasantness as rated by male and female college students. Behavior Research Methods, Instruments, & Computers, 18:299\u2013303.\\n\\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135\u2013146.\\n\\nTolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings. In Advances in Neural Information Processing Systems, volume 29, pages 4349\u20134357. Curran Associates, Inc.\\n\\nAylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334):183\u2013186.\\n\\nJos\u00e9 Ca\u00f1ete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, and Jorge P\u00e9rez. 2020. Spanish Pre-Trained BERT Model and Evaluation Data. In Practical ML for Developing Countries (PML4DC) at ICLR 2020.\\n\\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020a. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440\u20138451, Online. Association for Computational Linguistics.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Alexis Conneau, Shijie Wu, Haoran Li, Luke Zettle-moyer, and Veselin Stoyanov. 2020b. Emerging cross-lingual structure in pretrained language models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6022\u20136034, Online. Association for Computational Linguistics.\\n\\nSunipa Dev, Tao Li, Jeff M. Phillips, and Vivek Srikanth. 2020. On measuring and mitigating biased inferences of word embeddings. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 7659\u20137666. AAAI Press.\\n\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.\\n\\nKoel Dutta Chowdhury, Cristina Espa\u00f1a-Bonet, and Josef van Genabith. 2021. Tracing source language interference in translation with graph-isomorphism measures. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), pages 375\u2013385, Held Online. INCOMA Ltd.\\n\\nKawin Ethayarajh, David Duvenaud, and Graeme Hirst. 2019. Understanding undesirable word embedding associations. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1696\u20131705, Florence, Italy. Association for Computational Linguistics.\\n\\nHila Gonen and Yoav Goldberg. 2019. Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 609\u2013614, Minneapolis, Minnesota. Association for Computational Linguistics.\\n\\nEdouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, and Tomas Mikolov. 2018. Learning word vectors for 157 languages. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).\\n\\nAnthony G. Greenwald, Debbie E. McGhee, and Jordon L. K. Schwartz. 1998. Measuring individual differences in implicit cognition: The implicit association test. Journal of personality and social psychology, 74(6):1464\u20131480.\\n\\nWei Guo and Aylin Caliskan. 2021. Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases, page 122\u2013133. Association for Computing Machinery, New York, NY, USA.\\n\\nGanesh Jawahar, Beno\u00eet Sagot, and Djam\u00e9 Seddah. 2019. What does BERT learn about the structure of language? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3651\u20133657, Florence, Italy. Association for Computational Linguistics.\\n\\nArmand Joulin, Piotr Bojanowski, Tomas Mikolov, Herv\u00e9 J\u00e9gou, and Edouard Grave. 2018. Loss in translation: Learning bilingual word mapping with a retrieval criterion. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2979\u20132984, Brussels, Belgium. Association for Computational Linguistics.\\n\\nKeita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, and Yulia Tsvetkov. 2019. Measuring bias in contextualized word representations. In Proceedings of the First Workshop on Gender Bias in Natural Language Processing, pages 166\u2013172, Florence, Italy. Association for Computational Linguistics.\\n\\nAnne Lauscher and Goran Glava\u0161. 2019. Are We Consistently Biased? Multidimensional Analysis of Biases in Distributional Word Vectors. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), pages 85\u201391, Minneapolis, Minnesota. Association for Computational Linguistics.\\n\\nAnne Lauscher, Goran Glavas, Simone Paolo Ponzetto, and Ivan Vulic. 2020a. A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 8131\u20138138. AAAI Press.\\n\\nAnne Lauscher, Rafik Takieddin, Simone Paolo Ponzetto, and Goran Glava\u0161. 2020b. AraWEAT: Multidimensional analysis of biases in Arabic word embeddings. In Proceedings of the Fifth Arabic Natural Language Processing Workshop, pages 192\u2013199, Barcelona, Spain (Online). Association for Computational Linguistics.\\n\\nOmer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In Advances in Neural Information Processing Systems, volume 27. Curran Associates, Inc.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "emnlp-2022-main-133", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: The CA-WEAT lists were obtained through an online form. In the first section, the interface presents the guidelines for the task. The second part collects a minimal amount of personal information such as birth place and native language. Finally, the third part collects the list of words per concept. The form was created in English, Spanish, Catalan, French, Italian and German for a greater reach.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The CA-WEAT Dataset\\n\\n| Language ISO 639-1 | CA-WEATs | X-WEATs |\\n|-------------------|----------|---------|\\n| Arabic ar          | 1        | 1       |\\n| Bengali bn         | 1        | 0       |\\n| Bulgarian bg       | 1        | 0       |\\n| Catalan ca         | 2        | 1       |\\n| Chinese zh         | 2        | 0       |\\n| Croatian hr        | 12       | 1       |\\n| Dutch nl           | 2        | 0       |\\n| English en         | 5        | 1       |\\n| Farsi fa           | 2        | 0       |\\n| French fr          | 1        | 0       |\\n| German de          | 24       | 1       |\\n| Greek el           | 3        | 0       |\\n| Indonesian id      | 1        | 0       |\\n| Italian it         | 24       | 1       |\\n| Korean ko          | 1        | 0       |\\n| Luxembourgish lb   | 1        | 0       |\\n| Marathi mr         | 1        | 0       |\\n| Norwegian no       | 1        | 0       |\\n| Polish po          | 1        | 0       |\\n| Portuguese pt      | 1        | 0       |\\n| Romanian ro        | 1        | 0       |\\n| Russian ru         | 2        | 1       |\\n| Spanish es         | 10       | 1       |\\n| Turkish tr         | 2        | 1       |\\n| Ukrainian uk       | 1        | 0       |\\n| Vietnamese vi      | 1        | 0       |\\n\\nTable 2: Number of lists per language in the CA-WEAT.v1 data set. We include the languages with an available X-WEAT translation, which coincide with the languages used in the current work.\\n\\nWEAT1 and WEAT2 Original Lists\\n\\n**WEAT1 target items**\\n\\n- Flowers: aster, clover, hyacinth, marigold, poppy, azalea, crocus, iris, orchid, rose, bluebell, daffodil, lilac, pansy, tulip, buttercup, daisy, lily, peony, violet, carnation, gladiola, magnolia, petunia, zinnia\\n\\n- Insects: ant, caterpillar, flea, locust, spider, bedbug, centipede, fly, maggot, tarantula, bee, cockroach, gnat, mosquito, termite, beetle, cricket, hornet, moth, wasp, blackfly, dragonfly, horsefly, roach, weevil\\n\\n**WEAT2 target items**\\n\\n- Musical instruments: bagpipe, cello, guitar, lute, trombone, banjo, clarinet, harmonica, mandolin, trumpet, bassoon, drum, harp, oboe, tuba, bell, fiddle, harpsichord, piano, viola, bongo, flute, horn, saxophone, violin\\n\\n- Weapons: arrow, club, gun, missile, spear, axe, dagger, harpoon, pistol, sword, blade, dynamite, hatchet, rifle, tank, bomb, firearm, knife, shotgun, teargas, cannon, grenade, mace, slingshot, whip\\n\\n**WEAT1 and WEAT2 attributes**\\n\\n- Pleasant: caress, freedom, health, love, peace, cheer, friend, heaven, loyal, pleasure, diamond, gentle, honest, lucky, rainbow, diploma, gift, honor, miracle, sunrise, family, happy, laughter, paradise, vacation\\n\\n- Unpleasant: abuse, crash, filth, murder, sickness, accident, death, grief, poison, stink, assault, disaster, hatred, pollute, tragedy, divorce, jail, poverty, ugly, cancer, kill, rotten, vomit, agony, prison\\n\\nTable 3: List of words in the original English WEAT1 and WEAT2 tests.\"}"}
{"id": "emnlp-2022-main-133", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 4: Number of lines, words and tokens resulting after pre-processing for the CC-100 and CCe, the subset used to build our in-house embeddings (cf. Section 4).\\n\\n| Language | CC-100 Lines | CC-100 Words | CCe Lines | CCe Words | CCe Tokens |\\n|----------|--------------|--------------|-----------|-----------|------------|\\n| ar       | 111,159,553  | 2,869,491,129| 68,000,000| 1,783,110,513| 1,990,019,767|\\n| ca       | 77,707,813   | 1,752,301,188| 70,697,475| 1,752,301,188| 2,073,242,760|\\n| de       | 348,047,236  | 10,297,244,661| 62,000,000| 1,784,586,244| 2,077,747,370|\\n| en       | 1,857,736,518| 55,607,824,084| 67,000,000| 1,792,874,585| 2,087,270,544|\\n| es       | 318,730,600  | 9,374,385,063| 65,000,000| 1,784,255,267| 2,024,552,573|\\n| hr       | 127,087,082  | 3,296,927,157| 67,000,000| 1,787,595,251| 2,068,302,605|\\n| it       | 154,163,562  | 4,982,929,393| 58,000,000| 1,797,623,314| 2,099,653,787|\\n| tr       | 109,279,716  | 2,736,027,827| 70,000,000| 1,751,214,765| 2,151,242,947|\\n| ru       | 725,664,405  | 23,408,093,897| 58,000,000| 1,785,123,381| 2,176,025,999|\\n\\n### Table 5: Billions of words (counts) in the CCe corpus belonging to the X-/CA-WEAT1 and X-/CA-WEAT2 tests.\\n\\n| Language | X-/CA-WEAT1 | X-/CA-WEAT2 |\\n|----------|-------------|-------------|\\n| en       | 0.13 \u00b10.04  | 0.10 \u00b10.05  |\\n| ar       | 0.04 \u00b10.00  | 0.03 \u00b10.00  |\\n| ca       | 0.35 \u00b10.00  | 0.10 \u00b10.03  |\\n| de       | 0.04 \u00b10.00  | 0.03 \u00b10.01  |\\n| es       | 0.20 \u00b10.05  | 0.05 \u00b10.00  |\\n| hr       | 0.08 \u00b10.01  | 0.06 \u00b10.01  |\\n| it       | 0.22 \u00b10.02  | 0.11 \u00b10.01  |\\n| ru       | 0.01 \u00b10.08  | 0.02 \u00b10.06  |\\n| tr       | 0.23 \u00b10.06  | 0.43 \u00b10.22  |\"}"}
{"id": "emnlp-2022-main-133", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Effect sizes obtained with the X-WEAT tests in the CCeVM_{sup}, CCeVM_{uns}, CCe_{2langs} and CCe_{9langs} monolingual embedding models as a function of the difference in the number of pleasant and unpleasant attributes in the training corpus CCe.\"}"}
