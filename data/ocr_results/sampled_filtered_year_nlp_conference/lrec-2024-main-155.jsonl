{"id": "lrec-2024-main-155", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Resource for Machine Translation\\n\\nManu Narayanan, No\u00ebmi Aepli\\nUniversity of Zurich\\nmanu.narayanan,noemi.aepli@uzh.ch\\n\\nAbstract\\nWe present the first parallel dataset for English\u2013Tulu translation. Tulu, classified within the South Dravidian linguistic family branch, is predominantly spoken by approximately 2.5 million individuals in southwestern India. Our dataset is constructed by integrating human translations into the multilingual machine translation resource FLORES-200. Furthermore, we use this dataset for evaluation purposes in developing our English\u2013Tulu machine translation model. For the model's training, we leverage resources available for related South Dravidian languages. We adopt a transfer learning approach that exploits similarities between high-resource and low-resource languages. This method enables the training of a machine translation system even in the absence of parallel data between the source and target language, thereby overcoming a significant obstacle in machine translation development for low-resource languages. Our English\u2013Tulu system, trained without using parallel English\u2013Tulu data, outperforms Google Translate by 19 BLEU points (in September 2023). The dataset and code are available here: https://github.com/manunarayanan/Tulu-NMT.\\n\\nKeywords: Dravidian Language Tulu, Low-Resource Languages, Parallel Dataset, Machine Translation\\n\\n1. Introduction\\nOver the past decade, the field of neural machine translation (NMT) has seen significant advances with the advent of sequence-to-sequence models (Sutskever et al., 2014), attention mechanisms (Bahdanau et al., 2015), and transformer architecture (Vaswani et al., 2017). However, these advancements fall short when confronted with languages lacking extensive parallel datasets. Challenges stemming from both the scarcity of abundant parallel data and the absence of domain-diverse data pose significant hurdles in crafting robust NMT models (Koehn and Knowles, 2017). Regrettably, a vast majority of the world's linguistic diversity, spanning over 7,000 languages, faces one or both of these challenges (Littauer and Paterson III, 2016; Lakew et al., 2020).\\n\\nAmong these languages stands Tulu (ISO 639-3 code: TCY), a South-Dravidian language spoken by approximately 2.5 million individuals in India (Madasamy et al., 2022), characterized by several dialects (Eberhard et al., 2023). Tulu is not recognized as an official language, neither in India nor in any other country. Hence, it is not used for official purposes and education, where Kannada or Malayalam is used instead. However, efforts to enhance accessibility to the language have been evident through Unicode proposals for a Tulu script and petitions urging the Indian government to recognize Tulu as an official state language (Thadthagath, 2023). Furthermore, Tulu demonstrates a notable online presence and engagement among its speakers through various social media platforms. For instance, Jai Tulu\\n\\nFigure 1: A sentence in Tulu taken from our human-translated extension of the FLORES-200 dataset. English: 'I am happy that there are people willing to support me.'\"}"}
{"id": "lrec-2024-main-155", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"to use existing knowledge to adapt pre-trained models. Instead of starting from scratch, this technique facilitates the adaptation of already-trained models to new languages, particularly when a related language with such resources is available. Tulu is fortunate in this regard, as Kannada (ISO 639-3 code: KAN) serves as a closely-related language with some readily available NLP resources.\\n\\nIn this study, we present the first parallel dataset for Tulu and use it to evaluate our machine translation system for English\u2013Tulu. Without access to parallel EN\u2013TCY data, we developed this system using a transfer learning ([Zoph et al., 2016]) to address translation challenges in this low-resource language. Our main contributions are:\\n\\n\u2022 Introducing a machine translation dataset for Tulu by extending FLORES-200 with human translations into Tulu.\\n\\n\u2022 Developing a machine translation system for English\u2013Tulu, leveraging the resources of related Dravidian languages and employing transfer learning.\\n\\n2. Linguistic Context\\n\\nLanguages spoken in the South Asian region belong to at least four major language families: Dravidian, Austro-Asiatic, Sino-Tibetan, and Indo-European (predominantly from the Indo-Aryan sub-branch). Among these, the Dravidian languages constitute the second-largest group. The Dravidian language family ranks as the fifth largest language family globally, comprising approximately 25 languages primarily spoken in India ([Subrahmanyam, 2006]). This family is divided into four subgroups: North Dravidian, South Dravidian, South-Central Dravidian, and Central Dravidian. Tulu, Kannada, and Malayalam belong to the South Dravidian subgroup.\\n\\nDravidian languages generally share the following main characteristics:\\n\\nVowels\\nMost of the Dravidian languages have 'a 10-vowel system, with five short and five long ones ([Subrahmanyam, 2006]).\\n\\nConsonants\\nRetroflex consonants, a distinctive feature rare outside the Indian subcontinent, are prominent in Dravidian languages. However, voiced stops and aspirated stops are notably absent in these languages.\\n\\nCases\\nAccording to ([Steever, 2017]), Dravidian languages typically feature between five and eight cases. These include nominative, accusative, dative, genitive, locative ('in'), ablative ('from'), sociative ('with'), and instrumental ('by'). Kannada and Malayalam exhibit all eight cases, while Malayalam has seven, with the absence of the ablative case.\\n\\nMorphology\\nDravidian languages are characterized as agglutinative, with grammatical relations such as voice or tense typically expressed through suffixation and compounding.\\n\\nSyntax\\nWord order is a flexible subject-object-verb, with the verb always in the final position.\\n\\nWriting\\nThe primary Dravidian scripts in current use include Kannada, Malayalam, Tamil, and Telugu. The Tigalari script, historically used for writing Tulu, has gradually fallen out of use over the past few centuries, leading to the adoption of the Kannada script for writing Tulu ([Steever, 2019]).\\n\\nKannada is spoken by approximately 43.7 million people in India, according to Office of the Registrar General & Census Commissioner, India ([2022]), with around 93% of them residing in Karnataka, where it holds the status of the official language. Kannada shares most of the typical characteristics of the Dravidian languages listed above. Tulu and Kannada have co-evolved in close geographical and cultural proximity since at least the 8th century CE. Since 1947, Kannada has served as the official language in the Tulu-speaking region, with the exception of Kasaragod district, where Malayalam holds official status. Consequently, there has been an increasing trend of using Kannada loanwords in contemporary Tulu. Numerous Tulu words exhibit notable similarities to their Kannada equivalents. Hence, Kannada resources can serve as a starting point for constructing NLP systems tailored to Tulu.\\n\\nTulu is spoken by around 2.5 million people ([Madasamy et al., 2022]) in the Dakshina Karnataka and Udupi districts of Karnataka state and the Kasargod district of the Kerala state, with scattered speakers found in Maharashtra and other regions of India. Malayalam and Kannada share linguistic ties with Tulu, which comprises several dialects ([Eberhard et al., 2023]). The benchmark dataset introduced in this study is closely aligned with Central Tulu, which is predominantly spoken in the Mangaluru region and serves as the primary city in the Tulu-speaking area. We employ the Kannada script for written communication, reflecting the prevailing practice among Tulu speakers. The grammatical aspects of Tulu are similar to other South Dravidian languages ([Brigel, 1982]). The majority of Tulu speakers are bilingual, often using Kannada or Malayalam when communicating with individuals outside their community within their respective states. The Tigalari script, traditionally used for writing Tulu, has been gradually replaced by Kannada. A significant contributing factor to this transition is the absence of a Unicode\"}"}
{"id": "lrec-2024-main-155", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"script that supports Tigalari characters. Additionally, the Tulu community has refrained from writing in Tulu for several generations, opting to use Kannada or Malayalam for official purposes and education. Consequently, the Tigalari script has fallen out of use over the generations.\\n\\n3. Related Work\\n\\nThe Shared Task on Translation of Under-Resourced Dravidian Languages at the DravidianLangTech-2022 workshop (Madasamy et al., 2022) involved Kannada\u2013Tulu as one of the language pairs to be translated. The participants were given a Kannada\u2013Tulu parallel training dataset of 8,300 sentences and development and test sets containing 1,000 sentences each. These datasets were created by collecting monolingual Tulu documents from digitally accessible sources and manually translating them into Kannada. The team that scored the highest BLEU score (Papineni et al., 2002) for Kannada\u2013Tulu translation trained a transformer model provided by OpenNMT (Klein et al., 2017) for five different Dravidian languages (Tamil, Malayalam, Telugu, Kannada and Tulu) and got a BLEU score of 61.49 (Goyal et al., 2022). They trained their model for Tulu using only the 8,300 sentences of the training set. They hypothesize that the BLEU score might be higher because of the similarity of training and test sentences and, thus, high word overlap in the source and target data. A word or even sentence overlap in source and target might occur since Kannada and Tulu are similar with quite some shared vocabulary.\\n\\nBala Das et al. (2023) focus specifically on translating low-resource Indic languages by developing a multilingual NMT system with a shared encoder-decoder containing 15 language pairs (i.e. English and 14 Indic languages). They utilize the similarity between Indic languages, along with back-translation and domain adaptation, to achieve better results in translating low-resource languages. However, all the language pairs explored in the paper have parallel training data available, and back-translation is used only to create synthetic parallel training data from monolingual sentences.\\n\\nThe transfer learning approach NMT-Adapt (Ko et al., 2021) aims to leverage the lexical and syntactic structure similarities between high-resource languages and low-resource languages and train a translation model without using any parallel data. It combines denoising autoencoding (Artetxe et al., 2018), back-translation (Sennrich et al., 2016), and adversarial objectives to utilize monolingual data for low-resource adaptation. Ko et al. (2021) experimented with three groups of languages, namely Iberian languages, Indic languages, and Arabic. Within the Indic languages, they treated Hindi as the high-resource language and Marathi, Nepali, and Urdu as related low-resource languages.\\n\\nSennrich et al. (2016) had already shown that pairing monolingual data with automatic back-translation and using that as additional parallel training data can improve the capability of an English\u2013German model to translate Turkish\u2013English. Ko et al. (2021) added denoising autoencoding to this task, such that the model learns a shared feature space for the high-resource and low-resource languages and enables the encoder and decoder to transform between the features and the sentences. This involves adding noise to datasets in both languages by randomly shuffling words by at most 3-word positions and masking words with a uniform probability of 0.1. A dataset with this 'noised' data, along with the original data, is used to do the denoising autoencoding. The denoising autoencoding trains the model to reconstruct the original version of a corrupted input sentence (Artetxe et al., 2018). According to Lampl et al. (2018), this enables the feature space to learn high-level semantic knowledge and make it more robust.\\n\\n4. The 1st Dataset for Tulu MT\\n\\nTo maximize the potential impact, we opted to extend an already existing and widely adopted benchmark dataset for the creation of a Tulu dataset: FLORES-200, \u2018Evaluation Benchmark for Low-Resource and Multilingual Machine Translation\u2019 (Goyal et al., 2022; NLLB Team et al., 2022), which contains over 200 language varieties to-date. The FLORES-200 dataset comprises 2009 sentences for each language.\\n\\nTo obtain the translations, we collaborated with the organization Jai Tulu nad 6, a volunteer organization headquartered in the southern Indian city of Mangaluru. This collaboration was crucial not only for us to find native Tulu speakers but also because an increasing number of researchers have underscored the significance for NLP researchers to prioritize the needs and preferences of the pertinent speaker community (Bird, 2020, 2022; Liu et al., 2022; Mukhija et al., 2021; Blaschke et al., 2024). The organization and the translators were happy to contribute to our project which makes us confident that this is in the interest of the Tulu community.\\n\\nJai Tulu nad is dedicated to preserving and promoting Tulu language and culture. Approximately\\n\\n5. The sentences were sampled in equal amounts from Wikinews (an international news source), Wikijunior (a collection of age-appropriate non-fiction books), and Wikivoyage (a travel guide).\\n\\n6. https://www.jaitulunad.com/about\"}"}
{"id": "lrec-2024-main-155", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"mately 15 volunteers from this organization, based in Mangaluru, Karnataka state, India, participated in translating the sentences from the FLORES-200 dataset into Tulu. While the volunteers are not professional translators, they are all native Tulu speakers fluent in English. Furthermore, they all have native proficiency in Kannada since Kannada is the language taught in schools, used for official purposes and for communicating with people in non-Tulu speaking communities in the same region.\\n\\nAmong the translators, two are Tulu language instructors, and one is a distinguished Tulu poet. During the translation process, translators referred to both English and Kannada sentences in the dataset and translated them into Tulu. They consulted with literary experts within the translator group to address questions regarding Tulu vocabulary and resolved decisions regarding the utilization of outdated Tulu words, colloquialisms, and loanwords from Kannada in the translation. Along with the original FLORES-200 dataset, we provided the translators with guidelines, which we adapted from the original guidelines that were published by (Goyal et al., 2022; NLLB Team et al., 2022).\\n\\n1. Translations must be neutral, informative, and clear to native speakers.\\n2. No assistance from any machine translation tools; this was easy since there are no existing machine translation tools for Tulu.\\n3. Proper nouns may be transliterated if no equivalent term exists in Tulu. Similarly, abbreviations must be translated in the manner they usually appear in Tulu.\\n4. Idioms, metaphors, etc. need not be translated word by word. They should be translated as they usually appear in Tulu.\\n5. The most knowledgeable individuals among the team (in this case, the Tulu school teachers and the poet) shall take on the role of experts, who will resolve any queries that the other translators may have. They shall also review all the sentences translated by every one, including themselves, to eliminate typos, grammatical errors, and any other translation errors.\\n\\nThroughout the translation process, we had regular conversations with two members of the team who coordinated the whole process. The major challenges the translators faced during this process are listed below:\\n\\n1. While the vocabulary of Tulu historically encompassed a vast array of words, many of them have fallen out of common use today, particularly as they are not taught in schools as part of contemporary Tulu. Additionally, many Tulu words have been replaced by Kannada or Sanskrit equivalents, further complicating the preservation of the language. As a result, the team encountered the need for frequent considerations to determine the appropriate word choices in specific instances, given the absence of a widely accepted standard Tulu.\\n2. Passive voice is not commonly used in Tulu, nor in any other modern Dravidian languages according to Krishnamurti (2003). Consequently, a literal translation of an English sentence in passive voice may sound unusual in Tulu. Hence, such sentences were translated into the commonly used active voice.\\n3. Dialectical variations exist within Tulu based on the region of origin of the speaker. Therefore, the team had to pay attention to using a consistent dialect. In this case, all translators adhered to the Mangaluru (Central Tulu) dialect.\\n4. There are two variations of the phonetic /e/ sound (a close-mid front unrounded vowel) in Tulu, which occur when it is in the word-final position, a unique feature of Tulu (Subrahmanyam, 2006). However, these distinctions cannot be represented in the English, Kannada, or Malayalam scripts. The proposal for a Unicode Tulu script, that was submitted by members of Jai Tulu to the Unicode Consortium, addresses these differences. An example usage of the two /e/ sounds is shown in Figure 2. It displays the Tulu translation of the sentences 'He will come' and 'I will come' written using Kannada and Malayalam scripts, with an apostrophe (') used to differentiate the two /e/ sounds.\\n5. Another challenge, which is also prevalent in other language pairs, is translating the word you into Tulu. Whereas English has only one you and Kannada has two (singular neenu and plural neevu), Tulu has three words for you: singular ee, plural nikulu and formal eeru. As a result, there could be some ambiguity regarding the specific Tulu word for you when translating standalone English sentences.\\n\\n7 https://www.ethnologue.com/language/san/\\n8 https://unicode.org/consortium/consort.html\"}"}
{"id": "lrec-2024-main-155", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5. Experiments\\n\\n5.1. Data\\n\\n**English\u2013Kannada training set**\\n\\nTo train the base model for EN\u2013KN translation, we use the Samanantar dataset (Ramesh et al., 2022), comprising 4 million sentences. This dataset primarily originates from Indian websites, government documents, and sources such as Coursera, Khan Academy, and select science YouTube channels, which offer parallel human-translated subtitles in various Indic languages (Ramesh et al., 2022).\\n\\n**English\u2013Kannada test set**\\n\\nTo test the EN\u2013KN models, we use the dev and dev-test sets of the FLORES-200 (Goyal et al., 2022; NLLB Team et al., 2022) dataset, consisting of 997 and 1,012 sentences, respectively. The domain mainly uses Wikimedia sources such as WikiNews, WikiJunior, and WikiVoyage. This stands in contrast to the training data from Samanantar, which is primarily derived from Indian sources situated within the Indian context.\\n\\n**English\u2013Tulu test set**\\n\\nTo evaluate our EN\u2013TCY models, we use our newly developed dataset introduced in Section 4, which comprises a set of 1,300 human-translated sentences from FLORES-200. We split this dataset into 647 sentences for the development set and 653 for the test set.\\n\\n**Monolingual Tulu dataset**\\n\\nThe method we apply requires a monolingual dataset in the low-resource language for the back-translation and denoising autoencoding steps. As there is no preexisting dataset readily accessible for Tulu, we have turned to the Tulu Wikipedia (https://tcy.wikipedia.org) containing 9,209 articles (Wikipedia, 2023). As a result of processing the articles, we obtained a monolingual Tulu corpus comprising 40,000 sentences.\\n\\n| Dataset Source | #sents |\\n|----------------|--------|\\n| EN\u2013KN training Samanantar | 4,093,524 |\\n| EN\u2013KN test FLORES-200 | 2,009 |\\n| TCY monolingual Wikipedia | 40,124 |\\n| EN\u2013TCY test Human transl. FLORES | 1,300 |\\n| EN\u2013TCY training DravidianLangTech-22 | 8,300 |\\n\\nTable 1: Datasets used in our experiments.\\n\\n5.2. IndicBARTSS & YANMTT\\n\\nThe original version of the method we use, NMT-Adapt (Ko et al., 2021), is based on the multilingual BART (mBART) language model (Liu et al., 2020) to initialize training. However, Kannada is not included neither in mBART nor mBART-50. Consequently, Tulu data would need to be transliterated into one of the languages included in mBART-50, such as Malayalam, which would affect the performance of the model.\\n\\nWe used WikiExtractor (Attardi, 2015) to get the text.\\n\\nWhen we conducted the experiments, not all of the 2,009 sentences have been translated.\\n\\nWe downloaded the Tulu Wikipedia (https://tcy.wikipedia.org) articles via Wikimedia Downloads (https://dumps.wikimedia.org/) and used the Dataset Source #sents EN\u2013KN training Samanantar 4,093,524 EN\u2013KN test FLORES-200 2,009 TCY monolingual Wikipedia 40,124 EN\u2013TCY test Human transl. FLORES 1,300 EN\u2013TCY training DravidianLangTech-22 8,300\\n\\nTable 1: Datasets used in our experiments.\\n\\nFigure 3: Experimental setup illustrating the steps involved in the training.\"}"}
{"id": "lrec-2024-main-155", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Therefore, we opted for IndicBARTSS, an updated version of IndicBART (Dabre et al., 2022). IndicBARTSS supports eleven Indic languages in their native scripts, including Kannada. It is a multilingual model trained on the IndicCorp corpus, which was introduced by Kakwani et al. (2020). IndicCorp is a collection of monolingual corpora in eleven Indic languages and English. It contains 452 million sentences (five billion tokens). These texts were crawled from online sources, primarily comprising news articles, magazines, and books. Additionally, Dabre et al. (2023) developed the Y ANMTT toolkit, which is independently maintained by some of the researchers associated with IndicBARTSS. We use this toolkit in our experiments for pre-training, fine-tuning, and decoding.\\n\\n5.3. NMT-Adapt\\n\\nWe adopted a slightly simplified version of the transfer learning approach NMT-Adapt introduced by Ko et al. (2021) to develop a machine translation system for English\u2013Tulu. This approach combines denoising autoencoding (Artetxe et al., 2018) and back-translation (Sennrich et al., 2016) into a multi-step, iterative procedure, as depicted in Figure 3. While striving to closely follow the original implementation, we omitted an adversarial step due to limitations of the pre-trained model and training library we utilized (see Section 8). Our aim was to replicate and compare the effectiveness of this process for our set of languages wherever possible (see Section 8).\\n\\n**Task 1: Fine-tuning for back-translation**\\n\\nThe initial step involved fine-tuning the IndicBARTSS model to translate from Kannada to English. To achieve this, we used the Samanantar dataset for training and the EN\u2013KN dataset from FLORES-200 for development and testing. Subsequently, we used this model to translate the monolingual Tulu dataset into English. This fine-tuned model serves as the base model for TCY\u2013EN translation.\\n\\n**Task 2: Training with back-translation**\\n\\nFor the training with back-translation, we used a second pre-trained IndicBARTSS model, which served as the base model for EN\u2013TCY translation. We trained this model using the back-translation pairs obtained in Task 1.\\n\\n**Task 3: Training with parallel data**\\n\\nIn the third step, we trained the model from the previous task with the parallel English\u2013Kannada training dataset from Samanantar.\\n\\n**Task 4: Denoising autoencoding**\\n\\nFor the denoising autoencoding, we generated 'noised' sentences from the monolingual Tulu and Kannada training datasets by implementing random shuffling and word masking. We followed the method described in Ko et al. (2021), where words are randomly shuffled with a maximum shift of three positions, and each word is masked with a uniform probability of 0.1. Subsequently, we trained the English\u2013Tulu base model using these 'noised' Tulu and Kannada sentences as the source data, with the unaltered Tulu and Kannada sentences as the target data.\\n\\n**Task 5: Fine-tuning with back-translation**\\n\\nIn the final step, we further fine-tuned the EN\u2013TCY model from the preceding step using the back-translated pairs. We used this model to generate the English side of the back-translated pairs again, forming the new back-translation set for the next step. These newly generated back-translated pairs are used to repeat Tasks 2\u20135 on the TCY\u2013EN base model obtained in Task 1. This process could then be repeated by each model supplying the back-translation pairs for the other one.\\n\\n5.4. Fine-tuning with EN\u2013TCY data\\n\\nMadasamy et al. (2022) released parallel training data for KN\u2013TCY, comprising 8,300 sentences as part of the Shared Task on Translation of Under-Resourced Dravidian Languages at the DravidianLangTech-2022 workshop. We used this data to create a parallel EN\u2013TCY dataset and fine-tuned the models obtained from the modified NMT-Adapt process we followed. To create the parallel EN\u2013TCY dataset from KN\u2013TCY sentences, we initially translated the Kannada sentences into English. We performed this translation using two methods: first, utilizing the 'base model TCY\u2013EN' obtained in Task 1, and second, using Google Translate for comparison. Note that Google Translate does not currently offer a translation service for Tulu. However, it does support Kannada translation. Given the shared script and substantial linguistic similarity between Tulu and Kannada, as described in Section 2, we opted to utilize Google Translate to translate Tulu text as if it were Kannada. Despite the absence of alternative online translation services for Tulu, we believe this approach serves as a meaningful and comprehensible starting point for benchmarking the performance of our model.\\n\\nAlthough the 'base model TCY\u2013EN' achieved a BLEU score (Papineni et al., 2002) of 30.65 when evaluated on the FLORES-200 Kannada dev-test split, it showed lower translation quality compared to Google Translate, as it omitted some information from the source sentence during translation. Therefore, we combined the English sentences translated by Google Translate with the\"}"}
{"id": "lrec-2024-main-155", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Tulsi sentences from the KN\u2013TCY dataset to obtain an EN\u2013TCY parallel dataset comprising 8,300 sentences. Finally, we fine-tuned the models obtained at the end of Task 5 in both the EN\u2013TCY and TCY\u2013EN directions using this dataset. Our aim was to assess whether we could further enhance the models beyond what NMT-Adapt offers.\\n\\n### Results\\n\\nWe evaluated the machine translation model and each task of the process with our new test set as introduced in Section 4, using SacreBLEU (Post, 2018). Table 2 presents the BLEU scores for each stage of the training process. The TCY\u2013EN model, obtained by fine-tuning the pre-trained IndicBARTSS on the Samanantar EN\u2013KN data, achieves a BLEU score of 1.84, suggesting that the model is not capable of translating Tulsi.\\n\\n#### English-Tulsi Translation\\n\\nThe fine-tuned TCY\u2013EN model from Task 1 was used to translate the monolingual Tulsi data into English. Subsequently, the sentence pairs obtained from the EN\u2013TCY translation were used to fine-tune the IndicBARTSS model, which served as the base model for translating from English to Tulsi. This resulted in a BLEU score of 12.83 for Tulsi. While this score signifies a certain level of learning, the translation cannot be considered useful.\\n\\nMoving on to Task 3, we trained the EN\u2013TCY model using the Samanantar EN\u2013KN data. This task improved the BLEU score for Tulsi, reaching 17.27. This enhancement suggests that training the model to translate into Kannada also enhanced its ability to translate into Tulsi. This improvement can be attributed to the high degree of similarity between Tulsi and Kannada and the effectiveness of transfer learning.\\n\\nIn Task 4a, after conducting denoising autoencoding with Kannada data, the BLEU score decreased to 3.20. However, it then increased slightly to 5.92 upon denoising autoencoding with Tulsi in Task 4b.\\n\\nThe adversarial training task, a component of the original NMT-Adapt method, was not implemented in this work. The adversarial training task involves blending the latent space of the encoder across English, Tulsi, and Kannada, enabling the model to learn language-agnostic features (Ko et al., 2021). Without this task, while denoising autoencoding enhanced the robustness of the model's learned feature space, its benefits were somewhat compromised.\\n\\nIn the final step, Task 5, of the first iteration for the EN\u2013TCY model, we performed additional fine-tuning using the EN\u2013TCY sentence pairs utilized in Task 2. This process further increased the BLEU score of the model to 11.06 as the decoder adapted more effectively to the target (TCY) side. We used this model to generate Tulsi sentences from the English side of the back-translated pairs. Subsequently, these new back-translated TCY\u2013EN sentence pairs were utilized in the first iteration of training the TCY\u2013EN model, the results of which are detailed in the following section.\\n\\n#### Tulsi-English Translation\\n\\nIn Task 2 of the TCY\u2013EN direction, the base TCY\u2013EN model was trained using the back-translated TCY\u2013EN pairs obtained from the previous step. This training resulted in a BLEU score of 19.53, indicating the effectiveness of transfer learning. The decoder demonstrated proficiency in generating English tokens, likely attributed to the pre-trained IndicBARTSS model's inherent language modeling capability in English. Since the model had already been exposed to parallel KN\u2013EN data in Task 1, the subsequent step involved denoising autoencoding with Kannada data (Task 4a). However, this led to a decline in the BLEU score to 7.08. Despite denoising autoencoding with Tulsi data afterward, the BLEU score remained unchanged. The absence of the adversarial training task significantly limited the effectiveness of denoising autoencoding, as previously mentioned. Nevertheless, in the subsequent task (Task 5), which involved fine-tuning with back-translated TCY\u2013EN pairs for a second time, the BLEU score increased to 25.97. This represented the highest score attained by either model thus far.\\n\\n### Further Iterations\\n\\nWe used the final TCY\u2013EN model, which we obtained in Task 5, to subsequently back-translate the Tulsi sentences that were used to train it in both Task 2 and Task 5. This newly generated set of back-translated EN\u2013TCY pairs served to start a second iteration of the entire process. However, as shown in Table 2, despite some initial improvement, the BLEU scores for the EN\u2013TCY model kept declining from the starting score of 11.06.\\n\\n| Iter. | Direction | old BLEU | new BLEU |\\n|-------|-----------|----------|----------|\\n| 1     | EN\u2013TCY    | 11.06    | 13.12    |\\n| 1     | TCY\u2013EN    | 25.97    | 21.85    |\\n| 2     | EN\u2013TCY    | 13.43    | 35.41    |\\n\\nTable 3: BLEU scores after additional fine-tuning using DravidianLangTech-2022 data.\\n\\n**Fine-tuning with DravidianLangTech data**\\n\\nWe used the parallel EN\u2013TCY data from DravidianLangTech-22 to further fine-tune the EN\u2013TCY and TCY\u2013EN models obtained at the\"}"}
{"id": "lrec-2024-main-155", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: BLEU scores for each step in the training with 2 iterations.\\n\\n| Iteration Direction | Task no. | Task Language 1 | Language 2 | BLEU Score |\\n|---------------------|----------|-----------------|------------|------------|\\n| TCY\u2013EN              | 1        | fine-tuning     | KN\u2013EN      | 1.84       |\\n|                     | 2        | back-translation | EN\u2013TCY      | 12.83      |\\n|                     | 3        | training        | EN\u2013KN      | 17.27      |\\n|                     | 4a       | denoising autoencoding | KN | 3.20       |\\n|                     | 4b       | denoising autoencoding | TCY | 5.92       |\\n|                     | 5        | fine-tuning     | back-translation data | 11.06 |\\n| EN\u2013TCY              | 1        | back-translation | EN\u2013TCY     | 12.09      |\\n|                     | 2        | training        | EN\u2013KN      | 9.09       |\\n|                     | 3        | denoising autoencoding | KN | 3.45       |\\n|                     | 4a       | denoising autoencoding | TCY | 6.59       |\\n|                     | 4b       | denoising autoencoding | back-translation data | 13.43 |\\n|                     | 5        | fine-tuning     | back-translation data | 13.43 |\\n\\nTable 3 illustrates the changes in BLEU scores resulting from this fine-tuning step. For the EN\u2013TCY model obtained at the end of Iteration 1, fine-tuning improved its BLEU score from 11.06 to 13.12. This moderate increase is not surprising, as the manually translated Tulu data would have further enhanced the decoder's performance. Conversely, for the TCY\u2013EN model obtained at the end of Iteration 1, the BLEU score decreased from 25.97 to 21.85. The English sentences in this training data, generated by Google Translate, are not perfect translations and often contain transliterated Kannada words, particularly in the form of names of mythological characters, places, and local flora and fauna. We hypothesize that these aspects contributed to the degradation of the TCY\u2013EN model's decoder.\\n\\nFinally, the EN\u2013TCY model obtained at the end of Iteration 2 was also fine-tuned with this data, resulting in a substantial increase in its BLEU score from 13.43 to 35.41. This dramatic improvement may be attributed to the high-quality Tulu data, which eliminated spurious correlations in the latent space and simultaneously enhanced the decoder's ability to generate Tulu tokens.\\n\\nTulu Translation Performance\\n\\nThe results suggest that the approach outlined by Ko et al. (2021) effectively achieves reasonable performance in translating from Tulu to English, as evidenced by the model's BLEU score of 25.97. To provide a point of comparison, we used Google Translate to translate the Tulu test data to English using Google Translate15. It automatically detected the sentences as Kannada and produced a translation with a BLEU score of 7.19. However, the NMT-Adapt approach did not yield the same level of performance in the reverse direction, from English to Tulu. The highest achieved BLEU score, 17.27, was obtained through training with back-translation pairs and parallel English-Kannada data exclusively. However, when we combined the NMT-Adapt pipeline with additional fine-tuning using the DravidianLangTech-22 data, we observed a substantial improvement, resulting in a BLEU score of 35.41.\\n\\nThe denoising autoencoding step generated good results only when followed by fine-tuning with back-translation data in our setting. However, there are a multitude of factors, including the unique characters of Tulu and Kannada, as well as the constrained size of the monolingual Tulu dataset, consisting of just over 40,000 entries. In the work by Ko et al. (2021), the monolingual datasets for all the 'low-resource' languages they examined contained at least one million sentences. This implies that the model's decoder had a larger number of examples to adapt its feature space and acquire high-level semantic knowledge of the low-resource language.\\n\\n6.1. Qualitative Error Analysis\\n\\nTo gain a qualitative understanding of the translations, we conducted an analysis by randomly selecting sentences from the model-generated translations and then comparing them with the reference translations. In the TCY\u2013EN model with the highest BLEU score, we identified multiple cases where words were transliterated from Tulu to English rather than accurately translated. Furthermore, we observed occurrences of Kannada characters appearing in English translations and, con-\"}"}
{"id": "lrec-2024-main-155", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"versely, instances of English characters appearing in Kannada translations. Additionally, there were situations where common Tulu words, which had distinct meanings in Kannada or closely resembled common Kannada words, were translated as Kannada instead of Tulu. For instance, the Tulu word *uppuna*, which should have been translated as *together*, was incorrectly translated to *salt*, which is *uppu* in Kannada. Similarly, the phrase *tenk\u0101yi am\u0113rik\u0101*, which means *South America* in Tulu, was translated into English as *United States* by the TCY\u2013EN model, ignoring the first word. However, *dak\u1e63i\u1e47a \u0101phrik\u0101*, which is the formal name for South Africa in both Tulu and Kannada, was correctly translated as *South Africa*. This discrepancy arises from the fact that *dak\u1e63i\u1e47a* is a loan word from Sanskrit for *south* used in both Kannada and Tulu, whereas *tenk\u0101yi* is unique to Tulu.\\n\\nFinally, we observed instances of word repetition or recurring sequences of words in the translations known as hallucinations. This phenomenon is a well-documented challenge in text generation tasks, as discussed in (Fu et al., 2021).\\n\\n7. Conclusion\\n\\nWe introduced the first parallel dataset for English\u2013Tulu by incorporating Tulu translations into the multilingual machine translation resource FLORES-200 (Goyal et al., 2022; NLLB Team et al., 2022).\\n\\nFurthermore, we developed a machine translation system for English\u2013Tulu by leveraging resources for Kannada, a related South Dravidian language. We employed a transfer learning approach that exploits the similarities between the languages, enabling the training of a machine translation system even in the absence of parallel data between the source and target languages.\\n\\nOur system achieved a BLEU score of 25.97 for Tulu\u2013English translation, significantly outperforming Google Translate in September 2023, which reached a BLEU of 7.19. However, the relatively low BLEU scores indicate that the usefulness of our system's translations is limited. In English\u2013Tulu translation, the model often retains elements of Kannada in the output. However, in Tulu\u2013English translation, we observe that certain parts of Tulu sentences in the test set are conveyed effectively enough for non-Tulu speakers to understand. Additionally, proper nouns are accurately transliterated into English in the results. However, the translation quality diminishes as sentences become longer, and in some cases, the model simply transliterates complex Tulu words into English.\\n\\n8. Limitations\\n\\nKo et al. (2021) implemented NMT-Adapt using the fairseq toolkit (Ott et al., 2019) and mBART (Liu et al., 2020) as the pre-trained model. However, since Kannada is not supported in mBART, we worked with the pre-trained IndicBARTSS model and the YANMTT toolkit. Unfortunately, YANMTT does not include the adversarial training with Wasserstein loss, a critical step in NMT-Adapt for achieving the objectives of denoising autoencoding. In future work, we plan to implement this step and integrate it into the toolkit.\\n\\nFurthermore, to benchmark against NMT-Adapt models, we attempted to train bilingual (EN\u2013KN) and trilingual (EN\u2013KN\u2013ML) transformer models with the intention of subsequently adapting them to translate Tulu. Nevertheless, due to resource constraints, particularly when initialized with sizes akin to mBART or IndicBARTSS, these models proved too large to train. Smaller models trained with the Samanantar dataset achieved a maximum BLEU score of only 8.60 when translating EN\u2013KN.\\n\\nFinally, we used the parallel EN\u2013TCY data adapted from DravidianLangT ech-22 to independently fine-tune models at the end of each iteration. To ensure that improvements are consistently incorporated into each subsequent iteration, this step should be incorporated into the NMT-Adapt pipeline. This would be important to gain a more comprehensive understanding of this step and potentially quantify its effects.\\n\\n9. Ethics Statement\\n\\nThis paper introduces a novel dataset for Tulu and presents initial efforts towards developing a machine translation system for English\u2013Tulu. We collaborated with Jai Tulu nad, a volunteer organization based in India, dedicated to preserving Tulu language and culture. Their enthusiastic contribution to our project assures us that our efforts align with the community's interests and needs.\\n\\n10. Acknowledgements\\n\\nWe thank Chantal Amrhein for her support, Anne G\u00f6hring, Amit Moryossef, and the anonymous reviewers for their insightful input. Additionally, we extend our appreciation to the organization Jai Tulu nad and the Tulu translators for their invaluable contributions to this study. This work was supported by the Swiss National Science Foundation (project no. 191934) and the Department of Computational Linguistics at the University of Zurich.\\n\\n16 https://github.com/facebookresearch/fairseq\"}"}
{"id": "lrec-2024-main-155", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Bibliographical References\\n\\nMikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018. Unsupervised neural machine translation. In International Conference on Learning Representations.\\n\\nGiuseppe Attardi. 2015. WikiExtractor. https://github.com/attardi/wikiextractor.\\n\\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.\\n\\nSudhansu Bala Das, Atharv Biradar, Tapas Kumar Mishra, and Bidyut Kr. Patra. 2023. Improving multilingual neural machine translation system for indic languages. ACM Trans. Asian Low-Resour. Lang. Inf. Process., 22(6).\\n\\nSteven Bird. 2020. Decolonising speech and language technology. In Proceedings of the 28th International Conference on Computational Linguistics, pages 3504\u20133519, Barcelona, Spain (Online). International Committee on Computational Linguistics.\\n\\nSteven Bird. 2022. Local languages, third spaces, and other high-resource scenarios. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7817\u20137829, Dublin, Ireland. Association for Computational Linguistics.\\n\\nVerena Blaschke, Christoph Purschke, Hinrich Sch\u00fctze, and Barbara Plank. 2024. What do dialect speakers want? a survey of attitudes towards language technology for german dialects.\\n\\nJ. Brigel. 1982. A Grammar of the Tulu Language. Asian Educational Services.\\n\\nRaj Dabre, Diptesh Kanojia, Chinmay Sawant, and Eiichiro Sumita. 2023. YANMTT: Yet another neural machine translation toolkit. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pages 257\u2013263, Toronto, Canada. Association for Computational Linguistics.\\n\\nRaj Dabre, Himani Shrotriya, Anoop Kunchukuttan, Ratish Puduppully, Mitesh Khapra, and Pratyush Kumar. 2022. IndicBART: A pretrained model for indic natural language generation. In Findings of the Association for Computational Linguistics: ACL 2022, pages 1849\u20131863, Dublin, Ireland. Association for Computational Linguistics.\\n\\nDavid M. Eberhard, Gary F. Simons, and Charles D. Fennig, editors. 2023. Ethnologue: Languages of the World, twenty-sixth edition. SIL International, Dallas, Texas. Online version: http://www.ethnologue.com.\\n\\nZihao Fu, Wai Lam, Anthony Man-Cho So, and Bei Shi. 2021. A theoretical analysis of the repetition problem in text generation. Proceedings of the AAAI Conference on Artificial Intelligence, 35(14):12848\u201312856.\\n\\nPiyushi Goyal, Musica Supriya, Dinesh U, and Ashalatha Nayak. 2022. Translation techies@DravidianLangTech-ACL2022-machine translation in Dravidian languages. In Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages, pages 120\u2013124, Dublin, Ireland. Association for Computational Linguistics.\\n\\nDivyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M. Khapra, and Pratyush Kumar. 2020. IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pretrained multilingual language models for Indian languages. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4948\u20134961, Online. Association for Computational Linguistics.\\n\\nGuillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, and Alexander Rush. 2017. Open-NMT: Open-source toolkit for neural machine translation. In Proceedings of ACL 2017, System Demonstrations, pages 67\u201372, Vancouver, Canada. Association for Computational Linguistics.\\n\\nWei-Jen Ko, Ahmed El-Kishky, Adithya Renduchintala, Vishrav Chaudhary, Naman Goyal, Francisco Guzm\u00e1n, Pascale Fung, Philipp Koehn, and Mona Diab. 2021. Adapting high-resource NMT models to translate low-resource related languages without parallel data. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 802\u2013812, Online. Association for Computational Linguistics.\\n\\nPhilipp Koehn and Rebecca Knowles. 2017. Six challenges for neural machine translation. In Proceedings of the First Workshop on Neural Machine Translation, pages 28\u201339, Vancouver. Association for Computational Linguistics.\"}"}
{"id": "lrec-2024-main-155", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "lrec-2024-main-155", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"12. Language Resource References\\n\\nNaman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc\u2019 Aurelio Ranzato, Francisco Guzm\u00e1n, and Angela Fan. 2022. The Flores-101 evaluation benchmark for low-resource and multilingual machine translation. Transactions of the Association for Computational Linguistics, 10:522\u2013538.\\n\\nAnand Kumar Madasamy, Asha Hegde, Shubhanker Banerjee, Bharathi Raja Chakravarthi, Ruba Priyadharshini, Hosahalli Shashirekha, and John McCrae. 2022. Overview of the shared task on machine translation in Dravidian languages. In Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages, pages 271\u2013278, Dublin, Ireland. Association for Computational Linguistics.\\n\\nNLLB Team, Marta R. Costa-juss\u00e0, James Cross, Onur \u00c7elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm\u00e1n, Philipp Koehn, Alexandre Mourachko, Christophe Ropeters, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022. No language left behind: Scaling human-centered machine translation.\\n\\nGowtham Ramesh, Sumanth Doddapaneni, Aravinth Bheemaraj, Mayank Jobanputra, Raghavan AK, Ajitesh Sharma, Sujit Sahoo, Harshita Diddee, Mahalakshmi J, Divyanshu Kakwani, Navneet Kumar, Aswin Pradeep, Srihari Nagaraj, Kumar Deepak, Vivek Raghavan, Anoop Kunchukuttan, Pratyush Kumar, and Mitesh Shantadevi Khapra. 2022. Samanantar: The largest publicly available parallel corpora collection for 11 Indic languages. Transactions of the Association for Computational Linguistics, 10:145\u2013162.\"}"}
