{"id": "lrec-2024-main-333", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Constructing Indonesian-English Travelogue Dataset\\n\\nEunike Andriani Kardinata\\n\\n1 Nara Institute of Science and Technology\\n2 RIKEN\\n{eunike.kardinata.ef9, hiroki.ouchi, taro}@is.naist.jp\\n\\nAbstract\\n\\nResearch in low-resource language is often hampered due to the under-representation of how the language is being used in reality. This is particularly true for Indonesian language because there is a limited variety of textual datasets, and majority were acquired from official sources with formal writing style. All the more for the task of geoparsing, which could be implemented for navigation and travel planning applications, such datasets are rare, even in the high-resource languages, such as English. Being aware of the need for a new resource in both languages for this specific task, we constructed a new dataset comprising both Indonesian and English from personal travelogue articles. Our dataset consists of 88 articles, exactly half of them written in each language. We covered both named and nominal expressions of four entity types related to travel: location, facility, transportation, and line. We also conducted experiments by training classifiers to recognise named entities and their nominal expressions. The results of our experiments showed a promising future use of our dataset as we obtained F1-score above 0.9 for both languages.\\n\\nKeywords: Corpus (Creation, Annotation, etc.), Less-Resourced/Endangered Languages, Multilinguality\\n\\n1. Introduction\\n\\nAs a low-resource language, Indonesian has an increasing number of speakers and potential developments. However, research in Indonesian language often face challenges, such as difficulty in collecting standardised dataset for specific task, which is causing the issues in the reproducibility of past research. To encourage more research in Indonesian by providing publicly available language resources, we constructed a new dataset which is more representative of how Indonesian language is being used in reality.\\n\\nCurrently, improving the accessibility of Indonesian language resources is crucial to support various demands in Indonesia. In particular, we focus on a geoparsing task among others that deal with entities of location. The COVID-19 outbreak has drawn more attention to the dynamics between tourists and major destinations, such as Indonesia. Texts are valuable resources to analyse these dynamics as they contain information about human behaviours, experiences, and reputations of tourist spots. Such information is essential for the local government to manage and promote the country.\\n\\nConsidering the challenges in geoparsing, such as ambiguous entity types due to common names (e.g., whether the word 'Soetomo' refers to a road, a hospital, or other entities), we designed an annotations scheme which covers not only named expressions, but also nominal expressions. For instance, the geographic entity 'Soetomo Hospital' is sometimes referred by nominal expressions, such as 'the hospital' and 'this building'. By recognising the nominal expressions, end-user applications based on geoparsing would be more accurate in disambiguating entities mentioned.\\n\\nIn this work, we present an Indonesian-English comparable (having almost the same content and similar mentions of entities) travelogue dataset. We covered English articles to provide a more diverse dataset and to improve language technologies for other languages. Figure 1 shows an example of annotated texts in our dataset. Our dataset includes two main characteristics: (i) Indonesian-English comparable contents and (ii) annotations of geographic expressions. In particular, we annotated not only named expressions (e.g., 'Daya Station' and 'Tana Toraja'), but also nominal expressions (e.g., 'bus' and 'route'). This point distinguishes our dataset from typical datasets of named entities.\\n\\nIn the following, we would further elaborate on the construction of our dataset and the subsequent evaluations. We conducted experiments on our dataset to clarify the performance level of current entity analysis systems. More specifically, we trained classifiers on our dataset to recognise both named entities and nominal expressions. The results showed a promising future use of our dataset as we obtained F1-score above 0.9 for both languages. Other potential utilisations of our dataset are for comparison analysis and transfer learning, where we attempt to leverage a model trained on high-resource languages to handle low-resource languages.\\n\\nWe will release our annotated dataset and experimental codes at https://github.com/naist-nlp/mtd-gem.\\n\\n1 Our dataset is not a parallel corpus because some phrases and sentences cannot be aligned between Indonesian and English travelogues.\\n2 This is the first step towards geoparsing where we covered the recognition of geographic entity mentions.\"}"}
{"id": "lrec-2024-main-333", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2. Related Work\\n\\nOur work is motivated by the fact that Indonesian is still considered as low-resource and that we perceive a substantial utilisation of the dataset constructed from personal travel documentation. Besides having mentions of named entities and nominal expressions, travelogue articles also include information, such as the sequence of visits to places and the author's impressions. The sequence of visits could be used to determine the trajectory of travel and factuality analysis (whether a location is indeed being visited or only mentioned), which would be useful for fellow travellers in trip planning. Then, the author's impressions could be used for semantic analysis, which would be helpful in providing feedback to the government or relevant organisations for event management and site maintenance.\\n\\n2.1. Low-Resource Languages\\n\\nLow-resource languages (LRLs) were defined as languages spoken in the world with less linguistic resources for language technologies (Cieri et al., 2016). In the research done by Joshi et al. (2020), the distribution of language resources was further divided into six clusters. Indonesian language was put under the category of languages which were lacking in terms of labelled data collection but having a growing presence in the digital world. This corresponded with the increasing effort to develop numerous datasets and language models (Wilie et al., 2020; Ariesandy et al., 2020; Winata et al., 2023).\\n\\nMoreover, with the rise of awareness to preserve language diversity, more researchers were studying the challenges faced by LRLs and their feasible solutions. As stated by Do\u011fru\u00f6z and Sitaram (2022), LRLs suffered a consequence of compromising between the accuracy of the system and the representativeness of the dataset. Besides, Magueresse et al. (2020) also discussed that it was necessary to collect new and diverse datasets as a way to resolve the problems faced by LRLs. Drawing from the current position of Indonesian language as an LRL with a lot of potential and is on the move, we would contribute by constructing a new language resource built from less formal texts to improve the representativeness of its actual daily use. As seen in past surveys in 2019 and 2022, we were yet to see such dataset for the task of geoparsing (see Appendix A). In the recent collaborative initiative to collect and unify existing resources for Indonesian languages called NusaCrowd (Cahyawijaya et al., 2023), we were also yet to see a dataset focusing on geographic entity (see Appendix B). Thus, our dataset would certainly add knowledge into Indonesian language learning and assist in the improvement of related technologies.\\n\\n2.2. Challenges in Geoparsing\\n\\nIn the research by Gritta et al. (2020), geoparsing consists of two main tasks: toponym extraction (geotagging) and toponym resolution (geocoding). Geotagging is similar to the task of named entity recognition (NER), but it is more focused on reference (mention) of location (toponym) in the text. Geocoding is regarded as entity linking where we aim to disambiguate location mentions in the text using available databases.\"}"}
{"id": "lrec-2024-main-333", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Several challenges exist in the task of geoparsing, such as metonymy resolution (Gritta et al., 2018b) and location inference based on the surrounding context (Farzana and Hecking, 2023). Metonymy occurs when a toponym word is used to substitute for something else. For example, in the sentence \u2018Japan wins the 2023 World Baseball Classic\u2019, the word \u2018Japan\u2019 refers to the Japanese baseball team instead of the country location. Other than that, sometimes a location is not explicitly mentioned in the text. Hence, to figure out the exact location being referred to, we need to infer from the surrounding context.\\n\\nGeoparsing task might be challenging if we were to solely rely on the conventional NER system. As such, we considered adding information of nominal expressions in the text, so that there would be more contextual information for the model to learn. With this in mind, we designed an annotation scheme which encompassed nominal expressions of location mentions categorised into four entity types. This categorisation would allow the model to better distinguish the types of entities being referred to. Henceforth, we expect our dataset to improve the performance of existing system for geoparsing.\\n\\n3. Dataset Construction\\n\\nThe process of dataset construction generally followed the guidelines provided by Higashiyama et al. (2023), with some modifications for the scope of our current research. More specifically, we only used annotation labels that specifically refer to the four entity types defined.\\n\\n3.1. Data Acquisition\\n\\nIn the beginning, we surveyed several possible sources for data collection. We determined that travelogue would fit our requirements and purposes because in personal journals, writers tend to use a more casual writing style like how they speak in daily life. Besides, travelogue would definitely contain location mentions and their nominal expressions as they were being described for the reader. We discovered that most Indonesian blog writers preferred to have their own websites rather than posting in community forums. Coupled with the issue of usage rights and recent pandemic that significantly reduced the number of travels, we only managed to obtain express consent from one author. The author wrote in two languages, namely Indonesian and English, albeit not at the same time and not encompassing the exact same content.\\n\\nInitially, we obtained 65 relevant travel blog entries in Indonesian, and then we obtained 57 articles with similar contents at a brief glance in English. As we read the articles in more detail, we only included articles with a similar structure (almost the same content, but different paragraph sequence). This was done to ensure that both pairs of Indonesian-English articles were mentioning the same entities and having almost the same number of mentions and article lengths. In the end, we selected 44 articles in each language, thus making a total of 88 articles in Indonesian and English.\\n\\n3.2. Annotation of Named Entity\\n\\nThe annotation process began by manually annotating the named entities found in the text using BRAT rapid annotation tool (Stenetorp et al., 2012) from scratch. We considered using automatic annotation for named entity candidates. However, our preliminary experiment showed that the results did not meet our expectation. In this step, we employed four named entity categories as follows:\\n\\n- LOC_NAME for naturally existing locations, e.g., country, mountain, lake, etc.\\n- FAC_NAME for man-made structures or area, e.g., park, building, station, etc.\\n- TRANS_NAME for transportation modes or vehicles, e.g., bus, train, ship, etc.\\n- LINE_NAME for roads or waterways, e.g., street, river, route, etc.\\n\\nAn example of the annotation in English is shown in Figure 2. In the text, \u2018Villa Ipanema\u2019 is a facility because it is built by human, whereas \u2018Canggu\u2019, and \u2018Seminyak\u2019 are locations because both are the names of beach resort areas in Bali.\\n\\nWe were aware of ambiguities due to common names shared between entity types. In this case, we tried to determine the most probable entity type based on the surrounding context. For instance, looking back at Figure 2, \u2018Batu Belig\u2019 may refer to the area or the road in Bali. Since the named entities following \u2018Batu Belig\u2019 are clearly locations, the writer is more likely to talk about \u2018Batu Belig\u2019 as the area (location). Next, when we checked the address of the villa, it was not located in Batu Belig road. Thus, we confirmed that in this case, \u2018Batu Belig\u2019 is being referred as an area (location). Although we provided the tag OTHER in the case that the type of entity was really difficult to determine, we generally did not use this tag as much.\"}"}
{"id": "lrec-2024-main-333", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3.3. Annotation of Nominal Expression\\n\\nThe next stage was annotating the nominal expressions associated with each category of the named entities. Some examples of nominal expressions are the words 'country', 'house', 'river', and such nouns. Following are the tags used: LOC_NOM, FAC_NOM, TRANS_NOM, and LINE_NOM.\\n\\nAt this stage, we particularly observed that TRANS_NOM and LINE_NOM had a tendency to not be associated with any named entities within the same document. We conjectured that it might be because there were many alternatives for transportation modes and routes to reach the same location, thus travellers could easily determine whichever they preferred as they took the trip.\\n\\n4. Evaluation\\n\\nWe evaluated the sufficiency of our dataset using common methods: the inter-annotator agreement, the statistics of our dataset, and the experiments using publicly available tools. We also provide a list of known geoparsing datasets to demonstrate the contribution of our dataset (see Appendix C).\\n\\n4.1. Inter-annotator Agreement\\n\\nFor each language covered, we involved two independent annotators with at least one native speaker. We measured the agreement scores (F1 score) for five articles selected for each language based on exact match of both the labels and the text spans. The scores are as shown in Table 1 for Indonesian and English blog entries (breakdown by each label is provided in Appendix D). In this table, we also provide the number of annotations by each annotator (Ann1 and Ann2) and the number of exact match of annotations by both annotators (Both).\\n\\nThe overall agreement score was higher for Indonesian articles (0.792) than that for English articles (0.766), but both scores were not that far apart. The agreement scores for named entities were higher than that for nominal expressions. Note that the selected articles happened to not have TRANS_NAME, hence the overall F1 scores were calculated based on macro average.\\n\\nNominal expressions were harder to recognise, and some of them were ambiguous (e.g., place, area) which made it more difficult to assign the appropriate labels. Besides, we found that the annotators marked different spans for the same nominal expressions. Since the scores were calculated based on exact match, differing spans were considered as a disagreement. An example is shown in Figure 3. We could see that both annotators recognised the nominal expression 'hills', but one annotator marked the whole span of 'range of hills'.\\n\\n4.2. Coverage of Dataset\\n\\nAnother dataset based on travelogue was released formerly by Ouchi et al. (2023). We would present the statistics of our dataset in similar manner in Table 2 for both Indonesian (id) and English (en).\\n\\nBoth the Indonesian and the English articles had in total around 1,000 mentions of unique named entities (Named (U)) for domestic and international travel trips. Apparently, the English articles had more variety of unique nominal expressions (Nominal (U)). This might explain why English had a lower agreement score: because it was more difficult to recognise the nominal expressions.\\n\\nIn comparison with existing geoparsing datasets (Appendix C), there was only one dataset in Indonesian language. Moreover, most datasets have the size below 10,000 mentions, except for one dataset that we referred to. Among all these datasets, there was also only one that used travelogue as the data source. Based on this, we could see that our dataset, with a total of approximately 11,000 mentions, is of sufficient size.\\n\\n4.3. Experiments\\n\\nThe aim of the experiments is to clarify the performance level of current entity analysis systems. We trained classifiers to recognise named entities and\"}"}
{"id": "lrec-2024-main-333", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 3: Experiment Results (Macro Ave.)\\n\\n| Language | Named | Nominal | Overall |\\n|----------|-------|---------|---------|\\n|          | 0.881 | 0.910   | 0.923   |\\n|          | 0.877 | 0.902   | 0.922   |\\n\\nForeachlanguage,wesplit44articlesintothetrain, validation, and test sets in the ratio of 8:1:1, giving 35, 4, and 5 articles respectively. Although the validation and test sets only contained small numbers of articles, there were about 500-600 mentions for each language. We considered that this was quite a reasonable size to evaluate the classifiers under the low-resource setting. The training was done using spaCy NER with corresponding transformers for Indonesian and English.\\n\\nFor both languages, the scores for nominal expressions were higher than that for named entities. This corresponded to the fact that there were more kinds of named entities than nominal expressions (see Table 2), hence it was easier to recognise nominal expressions. Some errors that we discovered happened when the entities were expressed in different ways. For example, the entity 'Heijo Palace' was sometimes written as 'Heijo-kyo'. Our classifier was able to recognise 'Heijo Palace' as one entity mention but separated 'Heijo' and 'kyo' as two entities. A possible reason for this is because dash (-), especially in Indonesian, is often used as a connector between two different locations (e.g., rute Makassar-Tana Toraja in Figure 1).\\n\\nFrom these results, we perceived the importance of further experiments with our dataset as well as our classifiers.\\n\\nOur classifiers managed to achieve overall F1-score of 0.931 for Indonesian and 0.922 for English. However, we were aware of a possible bias in the results due to the limitation of our data source. Thus, we tried our classifiers on texts from different authors with different writing styles and covering entities which were not present in our dataset. We observed that the results corresponded to the reported scores, i.e., majority of the spans and tags were correctly identified with a few misses (especially in cases such as the use of dash or entities with longer names). This indicated that we could use this new dataset for further improvements and evaluations of currently existing models.\\n\\n#### Limitations\\n\\nCurrently, our dataset is limited because we only managed to acquire one bilingual travelogue written by one author. As a result, our findings might be biased towards the author's writing style. In the future work, we plan to increase the diversity in our dataset by adding more articles by different authors. Further analysis could be done by evaluating the model's performance with existing NER dataset. We will also extend the coverage of our dataset by including coreference resolution and entity linking, as well as other types of information, such as expressions of human behaviours and experiences.\"}"}
{"id": "lrec-2024-main-333", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Acknowledgments\\n\\nWe would like to thank the anonymous reviewers and metareviewers for their constructive comments. This study was supported by JSPS KAKENHIGrant Number JP22H03648.\\n\\nBibliographical References\\n\\nAlham Fikri Aji, Genta Indra Winata, Fajri Koto, Samuel Cahyawijaya, Ade Romadhony, Rahmad Mahendra, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Timothy Baldwin, Jey Han Lau, and Sebastian Ruder. 2022. One country, 700+ languages: NLP challenges for underrepresented languages and dialects in Indonesia. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7226\u20137249, Dublin, Ireland. Association for Computational Linguistics.\\n\\nIka Alfina, Rio Mulia, Mohamad Ivan Fanany, and Yudo Ekanata. 2017a. Hate speech detection in the Indonesian language: A dataset and preliminary study. In 2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS), pages 233\u2013238.\\n\\nIka Alfina, Septiviana Savitri, and Mohamad Ivan Fanany. 2017b. Modified dbpedia entities expansion for tagging automatically ner dataset. In 2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS), pages 216\u2013221.\\n\\nAsrul Sani Ariesandy, Mukhlis Amien, Alham Fikri Aji, and Radityo Eko Prasojo. 2020. Synthetic source language augmentation for colloquial neural machine translation.\\n\\nValentina Kania Prameswara Artari, Rahmad Mahendra, Meganingrum Arista Jiwanggi, Adityo Anggraito, and Indra Budi. 2021. A multi-pass sieve coreference resolution for Indonesian. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), pages 79\u201385, Held Online.\\n\\nINCOMA Ltd.\\n\\nJessica Naraiswari Arwidarasti, Ika Alfina, and Adila Alfa Krisnadhi. 2019. Converting an Indonesian constituency treebank to the penn treebank format. In 2019 International Conference on Asian Language Processing (IALP), pages 331\u2013336.\\n\\nAnnisa Nurul Azhar, Masayu Leylia Khodra, and Arie Pratama Sutiono. 2019. Multi-label aspect categorization with convolutional neural networks and extreme gradient boosting. In 2019 International Conference on Electrical Engineering and Informatics (ICEEI), pages 35\u201340.\\n\\nSamuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Winata, Bryan Wilie, Fajri Koto, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Jennifer Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Muhammad Satrio Wicaksono, Ivan Parmonangan, Ika Alfina, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Septiandri, James Jaya, Kaustubh Dhole, Arie Suryani, Rifki Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Adilazuarda, Ryan Hadiwijaya, Ryandito Diandaru, Tiezheng Yu, Vito Giffari, Wenliang Dai, Yan Xu, Dyah Damapuspita, Haryo Wibowo, Cuk Tho, Ichwanul Karo Karo, Tirana Fatyanosa, Ziwei Ji, Graham Neubig, Timothy Baldwin, Sebastian Ruder, Pascale Fung, Herry Sujaini, Sakriani Sakti, and Ayu Purwaringati. 2023. NusaCrowd: Open source initiative for Indonesian NLP resources. In Findings of the Association for Computational Linguistics: ACL 2023, pages 13745\u201313818, Toronto, Canada. Association for Computational Linguistics.\\n\\nChristopher Cieri, Mike Maxwell, Stephanie Strassel, and Jennifer Tracey. 2016. Selection criteria for low resource language programs. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16), pages 4543\u20134549, Portoro\u017e, Slovenia. European Language Resources Association (ELRA).\\n\\nJonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki. 2020. TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages. Transactions of the Association for Computational Linguistics, 8:454\u2013470.\\n\\nAgung Dewandaru. 2020. Event geoparsing in Indonesian news dataset.\\n\\nAgung Dewandaru, Dwi Widyantoro, and Saiful Akbar. 2020. Event geoparser with pseudo-location entity identification and numerical argument extraction implementation and evaluation in Indonesian news domain. International Journal of Geographic Information, 9:712.\\n\\nA. Seza Do\u011fru\u00f6z and Sunayana Sitaram. 2022. Language technologies for low resource languages: Sociolinguistic and multilingual insights. In Proceedings of the 1st Annual Meeting of the ELRA/ISCA Special Interest Group on Under-Resourced Languages, pages 92\u201397, Marseille.\"}"}
{"id": "lrec-2024-main-333", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"France. European Language Resources Association. Sheikh Mastura Farzana and Tobias Hecking. 2023. Geoparsing at web-scale: challenges and opportunities. In Proceedings of the First Workshop on Geographic Information Extraction from Texts (GeoExT 2023) co-located with The 45th European Conference on Information Retrieval (ECIR 2023).\\n\\nMilan Gritta, Mohammad Taher Pilehvar, and Nigel Collier. 2018a. Which Melbourne? augmenting geocoding with maps. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1285\u20131296, Melbourne, Australia. Association for Computational Linguistics.\\n\\nMilan Gritta, Mohammad Taher Pilehvar, and Nigel Collier. 2020. A pragmatic guide to geoparsing evaluation. In Language Resources and Evaluation, volume 54, pages 683\u2013712.\\n\\nMilan Gritta, Mohammad Taher Pilehvar, Nut Limsoopatham, and Nigel Collier. 2018b. What's missing in geographical parsing? In Language Resources and Evaluation, volume 52, pages 603\u2013623.\\n\\nYohanes Gultom and Wahyu Catur Wibowo. 2017. Automatic open domain information extraction from Indonesian text. In 2017 International Workshop on Big Data and Information Security (IW-BIS), pages 23\u201330.\\n\\nShohei Higashiyama, Hiroki Ouchi, Hiroki Teranishi, Hiroyuki Otomo, Yusuke Ide, Aitaro Yamamoto, Hiroyuki Shindo, Yuki Matsuda, Shoko Wakamiya, Naoya Inoue, Ikuya Yamada, and Taro Watanabe. 2023. Arukikata travelogue dataset with geographic entity mention, coreference, and link annotation.\\n\\nDevin Hoesen and Ayu Purwarianti. 2018. Investigating Bi-LSTM and CRF with POS tag embedding for Indonesian named entity tagger. In 2018 International Conference on Asian Language Processing (IALP). IEEE.\\n\\nMuhammad Okky Ibrohim and Indra Budi. 2018. A dataset and preliminaries study for abusive language detection in Indonesian social media. Procedia Computer Science, 135:222\u2013229. The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life.\\n\\nMuhammad Okky Ibrohim and Indra Budi. 2019. Multi-label hate speech and abusive language detection in Indonesian Twitter. In Proceedings of the Third Workshop on Abusive Language Online, pages 46\u201357, Florence, Italy. Association for Computational Linguistics.\\n\\nArfinda Ilmania, Abdurrahman, Samuel Cahyawijaya, and Ayu Purwarianti. 2018. Aspect detection and sentiment classification using deep neural network for Indonesian aspect-based sentiment analysis. In 2018 International Conference on Asian Language Processing (IALP), pages 62\u201367.\\n\\nRini Jannati, Rahmad Mahendra, Cakra Wishnu Wardhana, and Mirna Adriani. 2018. Stance classification towards political figures on blog writing. In 2018 International Conference on Asian Language Processing (IALP), pages 96\u2013101.\\n\\nPratik Joshi, Sebastin Santy, Amar Budhiraja, Kaliha Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6282\u20136293, Online. Association for Computational Linguistics.\\n\\nEhsan Kamalloo and Davood Rafiei. 2018. An coherent unsupervised model for toponym resolution. In Proceedings of the 2018 World Wide Web Conference, WWW '18, page 1287\u20131296, Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.\\n\\nFajri Koto, Jey Han Lau, and Timothy Baldwin. 2020. Liputan6: A large-scale Indonesian dataset for text summarization. In Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 598\u2013608, Suzhou, China. Association for Computational Linguistics.\\n\\nKemal Kurniawan and Samuel Louvan. 2018. IndoSum: A new benchmark dataset for Indonesian text summarization. In 2018 International Conference on Asian Language Processing (IALP), pages 215\u2013220.\\n\\nZhaojiang Lin, Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya, Andrea Madotto, Yejin Bang, Etsuko Ishii, and Pascale Fung. 2021. XPersona: Evaluating multilingual personalized chatbot. In Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI, pages 102\u2013112, Online. Association for Computational Linguistics.\\n\\nAlexandre Magueresse, Vincent Carles, and Evan Heetderks. 2020. Low-resource languages: A review of past work and future challenges.\"}"}
{"id": "lrec-2024-main-333", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Rahmad Mahendra, Alham Fikri Aji, Samuel Louvan, Fahrurrozi Rahman, and Clara Vania. 2021. IndoNLI: An natural language inference dataset for Indonesian. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10511\u201310527, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nRahmad Mahendra, Heninggar Septiantri, Haryo Akbarianto Wibowo, Ruli Manurung, and Mirna Adriani. 2018. Cross-lingual and supervised learning approach for Indonesian word sense disambiguation task. In Proceedings of the 9th Global Wordnet Conference, pages 245\u2013250, Nanyang Technological University (NTU), Singapore. Global Wordnet Association.\\n\\nMiftahul Mahfuzh, Sidik Soleman, and Ayu Purwarianti. 2019. Improving joint layer rnn based keyphrase extraction by using syntactical features. In 2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA). IEEE.\\n\\nKoji Matsuda, Akira Sasaki, Naoaki Okazaki, and Kentaro Inui. 2017. Geographical entity annotated corpus of japanese microblogs. Journal of Information Processing, 25:121\u2013130.\\n\\nDavid Moeljadi, Aditya Kurniawan, and Debaditya Goswami. 2019. Building cendana: a treebank for informal indonesian. Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, pages 156\u2013164.\\n\\nSri Mulyana Muhammad Fachri. 2014. Pengenalan entitas bernama pada teks bahasa indonesia menggunakan hidden markov model.\\n\\nHiroki Ouchi, Hiroyuki Shindo, Shoko Wakamiya, Yuki Matsuda, Naoya Inoue, Shohei Higashiyama, Satoshi Nakamura, and Taro Watanabe. 2023. Arukikata travelogue dataset.\\n\\nXiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight, and Heng Ji. 2017. Cross-lingual name tagging and linking for 282 languages. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1946\u20131958, Vancouver, Canada. Association for Computational Linguistics.\\n\\nTiago Pimentel, Maria Ryskina, Sabrina J. Mielke, Shijie Wu, Eleanor Chodroff, Brian Leonard, Garrett Nicolai, Yustinus Ghanggo Ate, Salam Khalifa, Nizar Habash, Charbel El-Khaissi, Omer Goldman, Michael Gasser, William Lane, Matt Coler, Arturo Oncevay, Jaime Rafael Montoya Samame, Gema Celeste Silva Villegas, Adam Ek, Jean-Philippe Bernardy, Andrey Shcherbakov, Aziyana Bayyr-ool, Karina Sheifer, Sofya Ganieva, Matvey Plugaryov, Elena Klyachko, Ali Salehi, Andrew Krizhanovsky, Natalia Krizhanovsky, Clara Vania, Sardana Ivanova, Aelita Salchak, Christopher Straughn, Zoey Liu, Jonathan North Washington, Duygu Ataman, Witold Kiera\u015b, Marcin Woli\u0144ski, Totok Suhardijanto, Niklas Stoehr, Zahroh Nuriah, Shyam Ratan, Francis M. Tyers, Edoardo M. Ponti, Grant Aiton, Richard J. Hatcher, Emily Prud'hommeaux, Ritesh Kumar, Mans Hulden, Botond Barta, Dorina Lakatos, G\u00e1bor Szolnok, Judit \u00c1cs, Mohit Raj, David Yarowsky, Ryan Cotterell, Ben Ambridge, and Ekaterina Vylomova. 2021. SIGMORPHON 2021 shared task on morphological reinforcement: Generalization across languages. In Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 229\u2013259, Online. Association for Computational Linguistics.\\n\\nAyu Purwarianti and Ida Ayu Putu Ari Crisdayanti. 2019. Improving bi-lstm performance for indonesian sentiment analysis using paragraph vector. In 2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA), pages 1\u20135.\\n\\nPaul Rayson, Alex Reinhold, James Butler, Chris Donaldson, Ian Gregory, and Joanna Taylor. 2017. A deeply annotated testbed for geographical text analysis: The corpus of lake district writing. In Proceedings of the 1st ACM SIGSPATIAL Workshop on Geospatial Humanities, GeoHumanities \u201917, page 9\u201315, New York, NY, USA. Association for Computing Machinery.\\n\\nMei Silviana Saputri, Rahmad Mahendra, and Mirna Adriani. 2018. Emotion classification on indonesian twitter dataset. In International Conference on Asian Language Processing (IALP), pages 90\u201395.\\n\\nKen Nabila Setya and Rahmad Mahendra. 2023. Semi-supervised textual entailment on indonesian wikipedia data. In Computational Linguistics and Intelligent Text Processing: 19th International Conference, CICLing 2018, Hanoi, Vietnam, March 18\u201324, 2018, Revised Selected Papers, Part I, page 416\u2013427, Berlin, Heidelberg. Springer-Verlag.\\n\\nPontus Stenetorp, Sampo Pyysalo, Goran Topi\u0107, Tomoko Ohta, Sophia Ananiadou, and Jun\u2019ichi Tsujii. 2012. brat: a web-based tool for NLP-assisted text annotation. In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102\u2013107, Avignon,\"}"}
{"id": "lrec-2024-main-333", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"France. Association for Computational Linguistics.\\n\\nJan Oliver Wallgr\u00fcn, Morteza Karimzadeh, Alan M. MacEachren, and Scott Pezanowski. 2018. GeoCorpora: building a corpus to test and train microblog geoparsers. *International Journal of geographical Information Science*, 32(1):1\u201329.\\n\\nDavy Weissenbacher, Arjun Magge, Karen O'Connor, Matthew Scotch, and Graciela Gonzalez-Hernandez. 2019. SemEval-2019 task 12: Toponym resolution in scientific papers. In *Proceedings of the 13th International Workshop on Semantic Evaluation*, pages 907\u2013916, Minneapolis, Minnesota, USA. Association for Computational Linguistics.\\n\\nHaryo Akbarianto Wibowo, Tatag Aziz Prawiro, Muhammad Ihsan, Alham Fikri Aji, Radityo Eko Prasojo, Rahmad Mahendra, and Suci Fitriany. 2020. Semi-supervised low-resource style transfer of Indonesian informal to formal Language with iterative forward-translation.\\n\\nBryan Wilie, Karissa Vincentio, Genta Indra Winata, Samuel Cahyawijaya, Xiaohong Li, Zhi Yuan Lim, Sidik Soleman, Rahmad Mahendra, Pascale Fung, Syafri Bahar, and Ayu Purwarianti. 2020. IndoNLU: Benchmark and resources for evaluating Indonesian natural language understanding. In *Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing*, pages 843\u2013857, Suzhou, China. Association for Computational Linguistics.\\n\\nAndika William and Yunita Sari. 2020. Click-id: A novel dataset for Indonesian clickbait headlines. *Data in Brief*, 32:106231.\\n\\nGenta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade Romadhony, Kemal Kurniawan, David Moejadi, Radityo Eko Prasojo, Pascale Fung, Timothy Baldwin, Jey Han Lau, Rico Sennrich, and Sebastian Ruder. 2023. NusaX: Multilingual parallel sentiment dataset for 10 Indonesian local languages. In *Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics*, pages 815\u2013834, Dubrovnik, Croatia. Association for Computational Linguistics.\\n\\nDaniel Zeman, Jan Haji\u010d, Martin Popel, Martin Potthast, Milan Straka, Filip Ginter, Joakim Nivre, and Slav Petrov. 2018. CoNLL 2018 shared task: Multilingual parsing from raw text to Universal Dependencies. In *Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies*, pages 1\u201321, Brussels, Belgium. Association for Computational Linguistics.\"}"}
{"id": "lrec-2024-main-333", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Appendices\\n\\nA. Summary of Surveys in 2019 and 2022\\n\\nTasks Publications\\n\\n- Morphology Analysis (Pimentel et al., 2021)\\n- Part-of-Speech Tagging (Hoesen and Purwarianti, 2018)\\n- Named Entity Recognition (Hoesen and Purwarianti, 2018)\\n- Word Sense Disambiguation (Mahendra et al., 2018)\\n- Constituency Parsing (Arwidarasti et al., 2019; Moeljadi et al., 2019)\\n- Dependency Parsing (Zeman et al., 2018)\\n- Coreference Resolution (Artari et al., 2021)\\n- Chatbot (Lin et al., 2021)\\n- Question Answering (Clark et al., 2020)\\n- Summarization (Koto et al., 2020; Kurniawan and Louvan, 2018)\\n- Keyphrase Extraction (Mahfuzh et al., 2019)\\n- Natural Language Inference (Setya and Mahendra, 2023; Mahendra et al., 2021)\\n- Sentiment Analysis (Purwarianti and Crisdayanti, 2019; Azhar et al., 2019; Ilmania et al., 2018)\\n- Emotion Classification (Saputri et al., 2018)\\n- Stance Detection (Jannati et al., 2018)\\n- Hate Speech Detection (Ibrohim and Budi, 2019, 2018; Alfina et al., 2017a)\\n- Clickbait Detection (William and Sari, 2020)\\n- Style Transfer (Wibowo et al., 2020)\\n\\nTable 4: Research and Resources in Indonesian Language\\n\\nB. NER Datasets in NusaCrowd (as of 2023)\\n\\n| Dataset Name       | Year | Size   | Domain   | Publications                |\\n|--------------------|------|--------|----------|----------------------------|\\n| IndQNER            | 2022 | 3,118  | religion |                            |\\n| IndoNLU NERGrit    | 2020 | 2,090  | general  | (Wilie et al., 2020)       |\\n| NERGrit            | 2020 | 17,437 | general  |                            |\\n| NERP (IndoNLU Split) | 2018 | 8,400  | news     | (Hoesen and Purwarianti, 2018) |\\n| NER UI (IndoLEM split) | 2017 | 2,125  | general  | (Gultom and Wibowo, 2017)  |\\n| Singgalang         | 2017 | 48,957 | wiki     | (Alfina et al., 2017b)     |\\n| WikiAnn (multilingual) | 2017 | 254,240| wiki     | (Pan et al., 2017)         |\\n| NER UGM (IndoLEM split) | 2014 | 2,343  | news     | (Muhammad Fachri, 2014)    |\\n\\nTable 5: NER Datasets in NusaCrowd\\n\\nC. Geoparsing Datasets\\n\\n| Dataset Name       | Year | Language | Size   | Domain   | Publications |\\n|--------------------|------|----------|--------|----------|--------------|\\n| ATD-MCL            | 2023 | ja       | 12K    | Travelogue | (Ouchi et al., 2023) |\\n| Event Geoparsing   | 2020 | id       | 1.1K   | News     | (Dewandaru, 2020)  |\\n| GeoWebNews         | 2020 | en       | 2.4K   | News     | (Gritta et al., 2020) |\\n| SemEval-2019 T12  | 2019 | en       | 8.4K   | Science  | (Weissenbacher et al., 2019) |\\n| GeoCorpora         | 2018 | en       | 3.1K   | Microblog | (Wallgr\u00fcn et al., 2018) |\\n| TR-News            | 2018 | en       | 1.3K   | News     | (Kamalloo and Rafiei, 2018) |\\n| GeoVirus           | 2018 | en       | 2.2K   | News     | (Gritta et al., 2018a) |\\n| CLDW               | 2017 | en       | 3.7K   | Historical | (Rayson et al., 2017) |\\n| LRE Corpus         | 2017 | ja       | 1.0K   | Microblog | (Matsuda et al., 2017) |\\n\\nTable 6: Details of Geoparsing Datasets\"}"}
{"id": "lrec-2024-main-333", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Table 7: Inter-Annotator Agreement by Label\\n\\n| Label     | Ann1 | Ann2 | Both |\\n|-----------|------|------|------|\\n| LOC_NAME  | 0.949| 0.864| 0.803|\\n| FAC_NAME  | 0.817| 0.788| 0.782|\\n| TRANS_NAME| -    | -    | -    |\\n| LINE_NAME | 0.750| 0.833| 0.792|\\n| LOC_NOM   | 0.844| 0.551| 0.648|\\n| FAC_NOM   | 0.767| 0.633| 0.678|\\n| TRANS_NOM | 0.805| 0.900| 0.850|\\n| LINE_NOM  | 0.613| 0.792| 0.745|\\n\\n---\\n\\n**D. Breakdown of Inter-Annotator Agreement Scores by Label**\\n\\n- **LOC_NAME**: Agreement between annotators is high, with a F1 score of around 0.95 for both individual annotators and the combined analysis.\\n- **FAC_NAME**: Agreement is good, with individual F1 scores of 0.82 and combined F1 score of 0.78.\\n- **TRANS_NAME**: No agreement reported, as indicated by missing data.\\n- **LINE_NAME**: Agreement is moderate, with an F1 score of 0.75 for individual annotators and 0.83 for combined analysis.\\n- **LOC_NOM**: Agreement is good, with an F1 score of 0.84 for individual annotators and 0.65 for combined analysis.\\n- **FAC_NOM**: Agreement is moderate, with an F1 score of 0.77 for individual annotators and 0.63 for combined analysis.\\n- **TRANS_NOM**: Agreement is excellent, with an F1 score of 0.90 for individual annotators and 0.90 for combined analysis.\\n- **LINE_NOM**: Agreement is moderate, with an F1 score of 0.61 for individual annotators and 0.79 for combined analysis.\\n\\n---\\n\\n**E. Comparison on Travelogue Article from the Same Author**\\n\\n- **Figure 4**: Classification results using our method.\\n- **Figure 5**: Classification results using SpaCy.\"}"}
{"id": "lrec-2024-main-333", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"F. Comparison on Travelogue Article from a Different Author\\n\\nFigure 6: Our Classifier on Travelogue Article from a Different Author\\nFigure 7: SpaCy Classifier on Travelogue Article from a Different Author\\n\\nG. Comparison on Wikipedia Article\\n\\nFigure 8: Our Classifier on Wikipedia Article\\nFigure 9: SpaCy Classifier on Wikipedia Article\"}"}
{"id": "lrec-2024-main-333", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"H. Comparison on News Article\\n\\nFigure 10: Our Classifier on News Article\\n\\nFigure 11: SpaCy Classifier on News Article\"}"}
