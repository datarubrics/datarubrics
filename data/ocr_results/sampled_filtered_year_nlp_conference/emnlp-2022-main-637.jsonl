{"id": "emnlp-2022-main-637", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence\\n\\nChris Callison-Burch\u2217\\nUniversity of Pennsylvania\\nccb@upenn.edu\\n\\nGaurav Singh Tomar\\nGoogle Research\\ngtomar@google.com\\n\\nLara J. Martin\\nUniversity of Pennsylvania\\n\\nDaphne Ippolito\\nUniversity of Pennsylvania\\nGoogle Research\\n\\nSuma Bailis\\nGoogle Research\\n\\nDavid Reitter\\nGoogle Research\\n\\nAbstract\\n\\nAI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the gameplay. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game\u2014i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.\\n\\n1 Introduction\\n\\nArtificial Intelligence has a long and rich history of using games as challenge problems that lead to advances in the field. In many cases, AI game-playing systems have gone on to rival human champions of the game. Dungeons and Dragons has been identified as an appropriate challenge for the next stage of artificial intelligence (Ellis and Hendler, 2017; Louis and Sutton, 2018; Martin et al., 2018b). Ellis and Hendler (2017) proposed open-ended creative games like D&D as the next challenge for AI after the human-level successes of AI at Chess and Go, which are zero-sum, deterministic, sequential two-player games with perfect information. Louis and Sutton (2018) understood the importance of narrative in natural language processing (NLP) and generation (NLG). In particular, they saw how cooperative story generation between humans already exists in these games and can be used for automated generation. Martin et al. (2018b) outlined some of the specific challenges D&D presents to the NLP community; such as a state of the game world distributed across the Dungeon Master (DM) and other players or dealing with the intrinsic rewards players get from taking certain actions that would not necessarily provide them with points in the game.\\n\\nD&D involves multiple players who roleplay characters in a fantasy setting, guided by a Dungeon Master who sets obstacles and adventures and plays as monsters. In roleplaying games like Dungeons and Dragons, the gameplay happens through language rather than moves on a game board, making it an interesting domain for NLP research. To have an AI successfully play D&D, it would require abilities like\\n\\n\u2022 Language generation (multi-party dialog, generating descriptions of the world/actions, storytelling)\\n\u2022 Language understanding (knowledge acquisition and representation, state tracking, automated reasoning)\\n\u2022 Planning / strategic play during battles (similar to chess or go)\\n\\nAppendix A gives an example of D&D gameplay and the AI challenges presented by it.\\n\\nIs it possible to design an AI system that is capable of playing a game of D&D either as a character in the game or as the Dungeon Master using current AI technology? We argue that now is the perfect time for this challenge, since large scale neural language models like GPT have shown impressive generation results (Brown et al., 2020), and since\"}"}
{"id": "emnlp-2022-main-637", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"incorporating neural LMs into a game setting both exercises their strengths and exposes their weaknesses.\\n\\nIn this paper, we introduce a new dataset of \\\"actual play\\\" game transcripts. Each turn is labeled with game state variables like character information and whether the conversational turn was in-character or out-of-character. Our data is a novel, large scale, real-world conversational dataset. It is unique in that the dialog turns are generated entirely through player collaboration and written interaction in a multi-player game. We propose our dataset as a challenge for dialogue systems for the following reasons:\\n\\n- It is naturally occurring conversational dialog that covers a spectrum of task oriented and non-task oriented (e.g. chit chat) dialog.\\n- It is strongly history dependent \u2013 a substantial criticism of recent dialog datasets is their history independence (Mosig et al., 2020).\\n- It has many participants in the conversation, since there are several players in the game.\\n- It conveys narrative elements including descriptions of events that denote changes in the state of the game.\\n\\nUnlike existing dialog datasets, our data reflects the challenging nature of the D&D game as a multi-party dialogue with creative roleplaying and underlying game states.\\n\\n2 Tasks\\n\\nWe trained a large language model (LLM) to perform two tasks:\\n\\n- Next Utterance Prediction\\n- Game State Tracking\\n\\nNext Utterance Prediction. We trained our language model on a corpus of human conversations (see Section 3) to predict the next utterance. We varied the conditioning information to examine the effects on the quality of predicted next utterance. In all variations, we included the conversational history as input. Given the conversational input (and other input in the variant models), the LLM must generate the next utterance, such that it is both interesting and a plausible next turn in the D&D game.\\n\\nGame State Tracking. In this task, rather than producing the next utterance, we had the model predict the game state for a given dialogue turn in the conversation. We have kept the state definition similar to task-oriented dialogue state tracking. In DST, the dialogue state is a collection of slot-value pairs. In our case, each slot is a state variable feature related to D&D games. Our target slot values do not need to appear as a word in the dialogue context. We track several game states aspects including some that remain relatively static throughout the game (character attributes like their pronouns, class, fantasy race, and their inventory), some that change periodically (like being in combat or out of combat), and some that change from turn to turn (like what action the player is taking).\\n\\n3 Dataset\\n\\nFor this paper, we have created a novel dataset for our dialogue-oriented test of AI's ability to play Dungeons & Dragons. We scraped Play-By-Post data from a web forum where people play by taking turns posting on the forum to describe their move. Figure 1 shows an example of part of the game-play from the play-by-post forums from D&D Beyond. D&D Beyond provides a mechanism in its forum to roll dice using a \\\"roll\\\" tag. Their dice roller allows players to conduct the rolls that are used for D&D ability checks and in combat.\\n\\nTable 1 summarizes the amount of play-by-post data that we collected from the D&D Beyond website (with permission from the company).\\n\\n3.1 Heuristic annotation of game states\\n\\nWe designed a set of rule-based heuristics to extract game state information from the play by post. These were implemented using regular expressions and NLP tools like named entity recognizers (Gardner et al., 2018). Although this heuristically extracted information is not perfect, it provides a reasonable approximation of the game state. It is\\n\\n1https://www.dndbeyond.com/forums/d-d-beyond-general/play-by-post\"}"}
{"id": "emnlp-2022-main-637", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Example of 3 turns in the D&D Beyond play-by-post forum useful for testing whether large language models can benefit from inclusion of complex state information for next utterance prediction and whether LLMs can be used for state tracking. We designed rules to extract state information relating to character properties, combat and player actions.\\n\\n**Character properties**\\n\\n- **Name:** Perform NER on all the player's turns in a campaign. The character's name is assigned to be the player's most frequently mentioned name, on the assumption that they tend to describe their own character's actions.\\n- **Class:** Count how many times each D&D class is mentioned by each player. Most frequently mentioned class is their character's class.\\n- **Race:** On a player's first turn, check whether any of the D&D fantasy races are mentioned. Assign it to character. If not, guess based on the most frequently mentioned race.\\n- **Pronouns:** Count pronouns mentioned by a player. Assign their character's pronouns to be the most frequent pronouns used by the player.\\n- **Inventory:** Use regex to match items occurring after character's personal pronouns (e.g. her sword).\\n- **Spells known:** Regex that matches cast followed by a spell name. The DM is assumed to be the player who has the first post in the game. The DM's entries in the dataset are scrubbed of other character properties, since they play multiple NPCs (non-player characters) and monsters.\\n\\n**Combat**\\n\\n- We detect the start of combat when there is a roll for initiative, or when there are attack rolls before initiative (from surprise attacks).\\n- Combat continues while there are attack rolls happening.\\n- Combat concludes after there are no rolls for a number of turns.\\n- In a combat span, we extract a list of monsters mentioned, and heuristically guess the number of each kind of monster.\\n\\n**Actions**\\n\\n- Dice rolls are marked in D&D Beyond posts. We detect the associated actions based on the kind of die used (D20 = a check, other dice are used for calculating damage if an attack check is successful).\\n- We use a regex to match the nearest pattern, which includes attack or a list of abilities like acrobatics, animal handling, arcana, athletics, etc.\\n- Damage rolls are matched with damage, dmg,\"}"}
{"id": "emnlp-2022-main-637", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Control Feature Description | Expected Impact on Model's Output\\n--- | ---\\nPlayer ID | Player writing a given dialog turn | Connects the current turn to the player's previous turns, which is important in multi-party conversations.\\nIC versus OOC | Whether a player is in-character or out-of-character for a given dialog turn | Changes whether the generated text is more like descriptive text found in a novel, or more like a discussion of rules and strategies.\\nCharacter Name | Name of the character being played by the player of a given dialog turn | IC descriptions use the character's name.\\nCharacter Class | D&D classes | Character classes perform different actions (e.g. wizards cast spells, thieves pick locks).\\nCharacter Race | D&D fantasy races | Different physical characteristics (e.g. halflings are small, dragonborn have scales).\\nCharacter Pronouns | The character's pronouns | Uses the correct pronouns when describing the character.\\nCharacter Actions | List of actions taken by the character in the current turn | Allows a description to be generated for a given action. The action can be thought of as a goal for the description.\\nCombat | Whether the players are currently engaged in combat or not during a given dialog turn | Affects the likelihood of actions (e.g. attacks are more likely during combat and investigations checks are more likely outside of combat).\\n\\nTable 2: Our LLMs are conditioned on a variety of control features that allow the models to better learn what kind of text to generate for the next utterance prediction task.\\n\\nOur heuristics resulted in features for around 60% of all conversational turns. We train a convolutional neural network classifier using these conversational turns to predict all of the above control features for each conversational turn in training data. Appendix C estimates the accuracy of the model's prediction on these state features.\\n\\n3.2 In-Character Versus Out-Of-Character Text\\nIn addition to labeling the game states in our Play by Post data, we also labeled the text of each turn as being either spoken in-character (IC) or out-of-character (OOC). To do so, we crawled another Play by Post forum hosted at Giant in the Playground, where play happens on two discussion boards \u2013 one in-character and one out-of-character.\\n\\nFor example, here is an IC post:\\n\\nKuros pulls the feathered shaft of the arrow back to his cheek winning easily against the resistance of the bowstring. He pulls a lungful of air to keep himself steady, takes aim at the Bandit with the deer, and lets fly.\\n\\nAnd here is its corresponding OOC post:\\n\\nSurprise round so only 1 standard or move action. Shoot the bow: (1d20+6)[20] vs Flat Footed AC at Bandit 1. Damage: (1d8+2)[10].\\n\\nWe train a classifier to predict IC versus OOC text, and then apply it to each paragraph in our D&D Beyond forum data.\\n\\n4 Models\\nFor our large language model, we use a 64B parameter version of Google's LaMDA language model (Thoppilan et al., 2022), which was trained on conversations. LaMDA is similar to other Transformer-based pre-trained language models like GPT-3. As with other pre-trained language models (Howard and Ruder, 2018), LaMDA can be finetuned to different tasks. The two tasks that we finetune LaMDA to perform are game state tracking and response generation. In both cases, the LLM can be thought of as a function that maps inputs onto an output. For instance, game state tracking is a language understanding task where the function takes in inputs like \\\\( f(\\\\text{current utterance, previous state, history}) \\\\rightarrow \\\\text{new state} \\\\), and response generation is a language generation task where \\\\( f(\\\\text{current state, history}) \\\\rightarrow \\\\text{next utterance} \\\\). The LLM functions are trained via the fine tuning process.\\n\\nIn our experiments we try a variety of different inputs to our LLM functions to see how they enable better learning of the tasks. We train our LLMs on the conversation history (which is typical in dialog modeling) and we also augment the conversations by conditioning other explicit signals. These...\"}"}
{"id": "emnlp-2022-main-637", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"conditioning signals can be thought of as sophisticated \\\"control features\\\", inspired by the CTRL language model. Here is an example of the data used in our versions of LaMDA that are finetuned to our D&D data.\\n\\n### 4.2 D&D FineTuning Data\\n\\nWe finetune each model on 50K steps, and Table 2 describes the control features we have proposed and describes how they can be set dynamically during inference, one can explicitly influence dialogue \u2013 by setting the values of control features and appropriate responses. In turn, these control features steer generation. Note that we use the terms 'control features' and 'state variables' interchangeably when referring to our next utterance prediction.\\n\\nThe models with the best perplexity scores and token accuracy scores were LLM-DND-CURRENT-CTRL and LLM-DND-ALL-CTRL, which used our control features.\\n\\nEach of our models starts from a pretrained LLM-Dialog that has been finetuned on Play-by-post D&D gameplay dataset using control features (state variables) for all previous turns, not including the current turn. Figure 2 plots the Negative log perplexity of our models after pretraining on generic dialogue data for 600k steps, and then finetuning to our data for a further 60k steps.\\n\\nTable 3 shows the final perplexity and token accuracy scores on the dev set. At the end of finetuning, the best perplexity scores and token accuracy scores were LLM-DND-CURRENT-CTRL and LLM-DND-ALL-CTRL, which used our control features.\\n\\nFor all models, we use the 7 most recent turns as input, and predict turn 8.\\n\\n### 4.3 Next Utterance Prediction Models\\n\\nIn our D&D conversation dataset, each utterance is labeled with a series of verbal and non-verbal cues, colors and pronouns. For all models, we use the most recent 7 turns as input, and predict turn 8. For all models, we use 7 most recent turns, and predict turn 8.\\n\\nFor all models, we use 7 most recent turns, and predict turn 8. For all models, we use 7 most recent turns, and predict turn 8.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"5 Manual Evaluation\\n\\nTo evaluate the quality of our models for the task of next utterance prediction in D&D, we perform a human evaluation. We recruited professional raters to perform a manual evaluation. They read a version of the content that was provided to the models \u2013 the seven turns of conversational history plus a list of players and the names/classes of the characters that they played. Then they were shown several model outputs for the context (or the \u201cgold\u201d, which was the actual next turn in the game), The annotators asked to rate each output along the three dimensions, following the evaluation procedure used for the Meena LM (Adiwardana et al., 2020):\\n\\n- Does the response make sense? (yes/no)\\n- Is the response specific? (yes/no)\\n- How interesting is the response? (10 point scale)\\n\\nThe full annotator instructions and the annotation interface are given in Appendix D.\\n\\n5.1 Raters\\n\\nBecause of the specialized nature of the D&D domain, we recruited 6 professional raters rather than crowd workers to perform the task. The raters were selected based on their professed interest in the fantasy genre, and on their background with D&D. All raters were fantasy fans, and 5 of the 6 had played D&D. 3 raters had been the DM in a game before.\\n\\n5.2 Inter-Rater Agreement\\n\\nOur raters annotated 500 system outputs with 3-way redundancy on each output. For the binary sense and specific scores, pairwise annotator agreement was 0.8, with a chance-adjusted Randolph Kappa score of 0.6. For the scalar interestingness scores, the Kendall's Tau correlation was 0.46.\\n\\n5.3 Analysis\\n\\n| Model                  | Sense | Specific | Interest |\\n|------------------------|-------|----------|----------|\\n| LLM-Dialog             | 0.81  | 0.85     | 3.57     |\\n| LLM-DND                | 0.9   | 0.9      | 3.91     |\\n| LLM-DND-PREV-CTRL      | 0.86  | 0.88     | 3.96     |\\n| LLM-DND-CURRENT-CTRL   | 0.88  | 0.9      | 3.96     |\\n| LLM-DND-ALL-CTRL       | 0.87  | 0.88     | 3.92     |\\n| GOLD                   | 0.92  | 0.92     | 4.17     |\\n\\nTable 4: Average sense, specific and interestingness scores for our systems, and for human-written gold responses.\\n\\nvanilla dialogue system. On average, the adapted systems make sense 6.75% more often than the baseline, are specific 4% more often, and are 0.37 points more interesting. However, the added control features do not seem to differ substantially from the LLM that is adapted to the D&D data without any control features. Why then use the control features at all?\\n\\nControl Features.\\n\\nOne reason is that the control features are useful to allow the model to role-play. For example, we can ask the model to play an elf wizard via the control features. Table 5 gives a qualitative example of this. The Table shows outputs from two LLMs without control features, plus 3 outputs from our LLM-DND-CURRENT-CTRL model roleplaying different characters. As input, we gave the models the final seven turns in the game play example from Appendix A \u2013 from \u201cWith his eagle eyes, Magnus spots two dead horses. . . \u201d to \u201c... What do you do next?\u201d, and then generate what each model thinks the next utterance ought to be. The vanilla dialogue system with no D&D data generates an irrelevant reply about Discord. The dialogue system fine-tuned on D&D data without control feature generates a relevant response. The dialogue system that adds conditioning control features allows the model to generate specific replies for each of the different characters. These replies are relevant to the character classes \u2013 the wizard casts a spell, and the Dwarf cleric shouts a battle cry by invoking the name of a Dwarf god.\\n\\nIn-Character Turns Are More Interesting.\\n\\nAmong our most impactful control features was the one that allowed systems to generate in-character (IC) versus out-of-character (OOC) turns. Table 6 shows that control models' scores substantially increased on IC turns compared to when their output was generated OOC. The pronounced increase in interestingness makes sense because IC turns are ones where the players describe their characters.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"moon_monk you can just join our discord conversation. it's free and easier to deal with\\n\\nI turn from the goblin and go to help Merle and Taako with getting this wagon moving again. Magnus can't see them anymore with such a dense forest. They're likely in a battle right now... I have to find them as fast as I can!\\n\\nIf the goblins still don't look like they're getting closer, Taako will yell, \\\"Alright you little monsters! Let's see what ya got!\\\" And he'll cast Chill Touch on one of the goblins that isn't dead/on its doorstep. Attack: 22 Damage: 6\\n\\nMerle steps away from the wagon. He draws his sword and takes aim at the hidden goblin! Attack: 27 Damage: 8 He puts his free hand on the pommel of his sword and shouts his battle cry, \\\"For Clanggeddin!\\\" His eyes glow brightly red as he strikes!\\n\\nTable 5: Example model outputs for the next utterance prediction task, given the sample gameplay from Table 8 as input. The 3 LLM-DND-CURRENT-CTRL examples use the same model with different control features (in red).\\n\\n| Model   | Sense  | Specific | Interest |\\n|---------|--------|----------|----------|\\n| LLM-Dialog | -0.01  | -0.01    | +0.06    |\\n| LLM-DND  | -0.02  | +0.03    | +0.4     |\\n| LLM-DND-PREV-CTRL | +0.02 | +0.02    | +0.6     |\\n| LLM-DND-CURR-CTRL | +0.06 | +0.06    | +0.93    |\\n| LLM-DND-ALL-CTRL |        |          | +0.81    |\\n| GOLD    | +0.07  | +0.05    | +1.02    |\\n\\nTable 6: Improvements by generating in-character (IC) text rather than out-of-character (OOC) text. Numbers are IC scores minus OOC scores.\\n\\n| State variable | Majority | LLM-DND-GST |\\n|----------------|----------|-------------|\\n| All            | .73      | .82         |\\n| Combat         | .89      | .82         |\\n| Character Class| .58      | .76         |\\n| Character Name | .58      | .78         |\\n| Character Race | .75      | .79         |\\n| Character Pronouns | .58 | .89     |\\n| Character Actions | .80 | .85       |\\n\\nTable 7: Average accuracy for our Game State Tracking LLM on the slot-filling our state variables, compared to a majority class baseline.\\n\\nthe fictional world often with evocative language, whereas OOC turns usually discuss rules or mechanics. Our control features allowed the system to intentionally generate IC responses, resulting in substantially improved interestingness scores for those in-character turns.\\n\\n6 Game State Tracking Model\\n\\nWe conducted an experiment to evaluate whether a LLM could be finetuned to perform game state tracking for D&D using our heuristically annotated game state features. We trained a new model LLM-DND-GST (Game State Tracking). It is a LLM-Dialog that has been finetuned on our Play-by-post D&D gameplay dataset. As input, it takes all previous dialog turns and their state variables, plus the text of the current turn, and then it outputs the corresponding state variables for the current turn.\\n\\nWe analyzed the accuracy of the LLM-DND-GST model its ability to do slot-filling for each of the individual game states, and compared its performance to a simple baseline that always output the the majority class. The results are shown in Table 7. The average accuracy of the dialogue state tracker is better than the majority class baseline, but likely falls short of being useful when it comes to joint accuracy. The joint accuracy for LLM-DND-GST is 58%. This suggests that accurately tracking the full game state may require additional machinery beyond a finetuned LLM.\\n\\n7 Related Work\\n\\nPrevious work has examined AI to play text adventure games (Haroush et al., 2018; Yao et al., 2020; Dambekodi et al., 2020). These games are simpler than D&D because they have a limited vocabulary and more straightforward game states. Creating text adventure games (Ammanabrolu et al., 2020a; Fan et al., 2020) is more challenging than playing them, and is similar to the world-building job of the DM in D&D. There has also been work on persona/character generation in stories (Prabhumoye et al., 2019), and within D&D itself (Louis and Sutton, 2018). Others (Urbanek et al., 2019; Ammanabrolu et al., 2020b) have realized that NPCs are lacking in their abilities to speak and act in text games.\\n\\nFindings of the automated story generation community are relevant for D&D AI systems. Neural language models have become increasingly more popular for story generation (Roemmele, 2018; Martin et al., 2018a; Mathewson et al., 2019; Hou et al., 2019). We have also started to see storytelling with transformers (See et al., 2019; Peng et al., 2021; Branch et al., 2021). Transformer-\"}"}
{"id": "emnlp-2022-main-637", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"based storytelling systems have even been introduced to the general public thanks to the popularity of AI Dungeon (Walton, 2019). Although neural networks possess a lot of power in terms of what text they generate, they are still limited in their ability to produce longer spans of coherent text. Many (Fan et al., 2018; Yao et al., 2019; Ippolito et al., 2019; Tambwekar et al., 2019; Ammanabrolu et al., 2020b; Rashkin et al., 2020) have improved the coherence of neural storytellers by splitting the generation into two steps: ideation of the story plot, followed by the realization of sentences. This controllable story generation is the focus of a lot of current work in neural automated story generation. Due to the conversational nature of D&D, we decided to use a dialog-based system. Deep neural networks have been used for dialog agents for a while (Serban et al., 2016), with a shift toward using transformers in recent years (Zhang et al., 2019; Ghazarian et al., 2021). Like in automated story generation and other neural text generation tasks, we are also seeing controllability being an important factor being integrated into systems. This includes using deep reinforcement learning techniques to guide the dialog toward a goal (Li et al., 2016; Saleh et al., 2020) or controlling for style (Zhang et al., 2018; Smith et al., 2020).\\n\\nIn this paper, we use LaMDA, a transformer-based open-domain dialogue system that builds on the Meena model (Adiwardana et al., 2020). The original Meena model was an end-to-end model trained on public conversations found on social media. Controllable text generation with transformers has been seen before with CTRL (Keskar et al., 2019), a language model that is conditioned on a given \u201ccontrol code\u201d in addition to the textual history. This work takes a similar approach. We integrate contextual information such as character descriptions, actions, and in- and out-of-character classifications.\\n\\nWe have finetuned our LaMDA models on data crawled from D&D Beyond. This data contains both in-character and out-of-character dialog and can be used in conjunction with Rameshkumar and Bailey (2020)'s dataset from Critical Role (a D&D podcast), Louis and Sutton (2018)'s dataset from roleplayerguild.com (a D&D forum), Urbanek et al. (2019)'s crowdsourced LIGHT dataset, and/or Akoury et al. (2020)'s STORIUM dataset for human+AI collaborative story generation.\\n\\nDiscussion and Conclusions\\n\\nWe have demonstrated that training on D&D data results in much higher quality outputs than a vanilla dialogue system (as expected), that controlling the model to generate in-character responses results in substantially more interesting output, and that conditioning on game state information qualitatively results in responses that are appropriate to the character class. Our preliminary experiments with using the large language models to perform game state tracking show low performance even after finetuning, suggesting that other models may be required for an AI to play D&D track the full state of the game.\\n\\nAlthough our models are unable to play D&D fully autonomously by acting as the Dungeon Master, they could act as an aid for novice DMs. Since our models can generate evocative, in-character text that is appropriate for the context and the game state, DMs could use it as inspiration as they narrate the adventure to the other players. Here is some model output to inspire your next adventure:\\n\\n\u201cYou get a much closer look than the other two... the sarcophagi have the inscriptions of some sort of magic, probably to keep the dead inside, but you can not read them to save your life. What will you do next? Download our dataset to start your new adventure!\u201d\\n\\nLimitations\\n\\nOne limitation of our human evaluation is that it is a static evaluation. The raters are simply reading the outputs of the model, and there is no interactive evaluation wherein they engage in gameplay with the system. An interactive user-study would be required before any claims could be made about how well AI is able to play D&D alongside human players.\\n\\nBecause our state information was created heuristically, it therefore potentially contains errors. It is also incomplete. There are several kinds of state tracking variables that would be useful to include, but were not possible to heuristically extract from our data. To address this problem in the future, we have begun a collaboration with the developer of Avrae, which is a Discord bot for playing D&D.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"D&D online. Avrae contains many state variables that are missing from our current annotations, such as HIT points and slot-filler values for attacks.\\n\\nAcknowledgments\\n\\nWe would like to thank Antony Pegg of Fandom for granting us permission to use D&D Beyond\u2019s forum data for research purposes.\\n\\nThank you to Rich Burlew and forum moderator truemane for granting us permission to crawl the Giant in the Playground forum and to build models using the forum posts.\\n\\nWe would like to thank the many Google Researchers who gave valuable input on this project, especially Dipanjan Das and Suma Bailis.\\n\\nChris Callison-Burch is grateful for having the opportunity to be a part-time visiting researcher at Google for two years. It was amazing to spend time among such incredibly smart people, and it was eye opening to see large LMs before they became widely available. Thanks!\\n\\nReferences\\n\\nDaniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu Quoc, and V Le. 2020. Towards a Human-like Open-Domain Chatbot. arXiv preprint arXiv:2001.09977.\\n\\nNader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, and Mohit Iyyer. 2020. STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6470\u20136484, Online. Association for Computational Linguistics.\\n\\nPrithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul, and Mark O. Riedl. 2020a. Toward Automated Quest Generation in Text-Adventure Games. In International Conference on Computational Creativity (ICCC).\\n\\nPrithviraj Ammanabrolu, Jack Urbanek, Margaret Li, Arthur Szlam, Tim Rockt\u00e4schel, and Jason Weston. 2020b. How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds. In The North American Chapter of the Association for Computational Linguistics (NAACL-HLT).\\n\\nBoyd Branch, Piotr Mirowski, and Kory Mathewson. 2021. Collaborative Storytelling with Human Actors and AI Narrators. In International Conference on Computational Creativity (ICCC), pages 97\u2013101.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901.\\n\\nSahith Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, and Mark O Riedl. 2020. Playing Text-Based Games with Common Sense. In Wordplay: When Language Meets Games Workshop (NeurIPS 2020).\\n\\nSimon Ellis and James Hendler. 2017. Computers Play Chess, Computers Play Go...Humans Play Dungeons & Dragons. IEEE Intelligent Systems, 32(4):31\u201334.\\n\\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical Neural Story Generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 889\u2013898.\\n\\nAngela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian, Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rockt\u00e4schel, Arthur Szlam, and Jason Weston. 2020. Generating Interactive Worlds with Text. In AAAI Conference on Artificial Intelligence (AAAI), pages 1693\u20131700.\\n\\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Peters, Michael Schmitz, and Luke Zettlemoyer. 2018. AllenNLP: A deep semantic natural language processing platform. arXiv preprint arXiv:1803.07640.\\n\\nSarik Ghazarian, Zixi Liu, Tuhin Chakrabarty, Xuezhe Ma, Aram Galstyan, and Nanyun Peng. 2021. DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation. arXiv preprint arXiv:2102.02191.\\n\\nMatan Haroush, Tom Zahavy, Daniel J. Mankowitz, and Shie Mannor. 2018. Learning How Not to Act in Text-Based Games. In Workshop Track at ICLR 2018, pages 1\u20134.\\n\\nChenglong Hou, Chensong Zhou, Kun Zhou, Jinan Sun, and Sisi Xuanyuan. 2019. A survey of deep learning applied to story generation. In Smart Computing and Communication, pages 1\u201310. Springer International Publishing.\\n\\nJeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 328\u2013339, Melbourne, Australia. Association for Computational Linguistics.\\n\\nDaphne Ippolito, David Grangier, Chris Callison-Burch, and Douglas Eck. 2019. Unsupervised Hierarchical Story Infilling. In Proceedings of the First Workshop on Narrative Understanding, pages 37\u201343.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. CTRL: A Conditional Transformer Language Model for Controllable Generation. arXiv preprint arXiv:1909.05858.\\n\\nJiwei Li, Will Monroe, Alan Ritter, and Dan Jurafsky. 2016. Deep Reinforcement Learning for Dialogue Generation. In Conference on Empirical Methods in Natural Language Processing, pages 1192\u20131202.\\n\\nAnnie Louis and Charles Sutton. 2018. Deep Dungeons and Dragons: Learning Character-Action Interactions from Role-Playing Game Transcripts. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 708\u2013713.\\n\\nLara J. Martin, Prithviraj Ammanabrolu, Xinyu Wang, William Hancock, Shruti Singh, Brent Harrison, and Mark O. Riedl. 2018a. Event Representations for Automated Story Generation with Deep Neural Nets. In Thirty-Second AAAI Conference on Artificial Intelligence, pages 868\u2013875, New Orleans, Louisiana.\\n\\nLara J. Martin, Srijan Sood, and Mark O. Riedl. 2018b. Dungeons and DQNs: Toward Reinforcement Learning Agents that Play Tabletop Roleplaying Games. In Joint Workshop on Intelligent Narrative Technologies and Workshop on Intelligent Cinematography and Editing (INT-WICED), Edmonton, AB, Canada.\\n\\nKory W. Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster, and Marc G. Bellemare. 2019. Shaping the Narrative Arc: An Information-Theoretic Approach to Collaborative Dialogue. arXiv preprint arXiv:1901.11528, page 20.\\n\\nJohannes E. M. Mosig, Vladimir Vlasov, and Alan Nichol. 2020. Where is the context? - A critique of recent dialogue datasets. CoRR, abs/2004.10473.\\n\\nXiangyu Peng, Siyan Li, Sarah Wiegreffe, and Mark Riedl. 2021. Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning. In Workshop on Narrative Understanding at NAACL-HLT 2021.\\n\\nShrimai Prabhumoye, Khyathi Raghavi Chandu, Ruslan Salakhutdinov, and Alan W Black. 2019. \u201cMy Way of Telling a Story\u201d: Persona based Grounded Story Generation. In Storytelling Workshop at ACL 2019, pages 11\u201321.\\n\\nRevanth Rameshkumar and Peter Bailey. 2020. Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 5121\u20135134.\\n\\nHannah Rashkin, Asli Celikyilmaz, Yejin Choi, and Jianfeng Gao. 2020. PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4274\u20134295.\\n\\nMelissa Roemmele. 2018. Neural Networks for Narrative Continuation. Ph.D. thesis, University of Southern California.\\n\\nAbdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, and Rosalind Picard. 2020. Hierarchical Reinforcement Learning for Open-Domain Dialog. In AAAI Conference on Artificial Intelligence (AAAI), pages 8741\u20138748.\\n\\nAbigail See, Aneesh Pappu, Rohun Saxena, Akhila Yerukola, and Christopher D. Manning. 2019. Do Massively Pretrained Language Models Make Better Storytellers? In Conference on Computational Natural Language Learning (CoNLL), pages 843\u2013861.\\n\\nIulian Vlad Serban, Ryan Lowe, Laurent Charlin, and Joelle Pineau. 2016. Generative Deep Neural Networks for Dialogue: A Short Review. In Conference on Neural Information Processing Systems (NeurIPS), Workshop on Learning Methods for Dialogue, pages 1\u20136.\\n\\nEric Michael Smith, Diana Gonzalez-Rico, Emily Dinan, and Y-Lan Boureau. 2020. Controlling Style in Generated Dialogue. arXiv preprint arXiv:2009.10855.\\n\\nPradyumna Tambwekar, Murtaza Dhuliawala, Lara J. Martin, Animesh Mehta, Brent Harrison, and Mark O. Riedl. 2019. Controllable Neural Story Plot Generation via Reinforcement Learning. In International Joint Conference on Artificial Intelligence (IJCAI), Macau, China.\\n\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications. CoRR, abs/2201.08239.\\n\\nJack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rockt\u00e4schel, Douwe Kiela, Arthur Szlam, and Jason Weston. 2019. Learning to Speak and Act in a Fantasy Text Adventure Game. In Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 9388.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Example D&D Game Session\\n\\nInstead of the game being a series of moves on a game board, RPGs D&D are language-based. Players create characters that have a class (wizard, fighter, thief, etc.) that denotes their abilities, and a fantasy race (elf, dwarf, human, etc.). Players describe what they want their character to do and roll dice to determine if they are successful. The dungeon master (DM) acts as the narrator who shapes the overall story. The DM describes scenarios and locations, and takes on the role of non-player characters (NPCs), and monsters.\\n\\nA common element to the game play is an encounter with monsters. Battles are governed by rules, and unfold in a turn-based fashion where the DM controls the monsters and each player controls their character. Each player and monster has a health meter (called their HIT points), an armor class (which indicates the threshold of the dice roll needed to damage them), and a set of possible attack or move actions.\\n\\nTable 8 provides example dialogue from a game of D&D being played between 3 players \u2013 Travis (playing a human fighter named Magnus Burnside), Clint (playing Merle Highchurch, a dwarf cleric), Justin (playing Taako an elf wizard), and DM Griffin. We add comments about each dialogue turn to describe what is happening in the game, and to highlight the challenges that would need to be addressed if an AI system were to play the game either as a player or as the DM.\\n\\nThe game session is taken from the podcast The Adventure Zone. In this episode, the hosts are playing an adventure module called Lost Mine of Phandelver, an expert of which is given in Appendix B. In the first episode of the podcast 6, the hosts explain the rules of D&D.\\n\\nB Lost Mine of Phandelver Adventure\\n\\nHere is an excerpt from the adventure book that the Dungeon Master was using in our example game play. The adventure book provides boxed text, which is descriptive text to be read aloud verbatim or to paraphrase. It also gives details about the combat that is about to ensue, and links to relevant game rules (like stealth checks, and statistics about the monsters that the characters will be in combat with).\\n\\nThe adventure begins as the player characters are escorting a wagon full of provisions and supplies from Neverwinter to Phandalin. The journey takes them south along the High Road to the Triboar Trail, which heads east (as shown on the overland map). When they're a half-day's march from Phandalin, they run into trouble with goblin raiders from the Cragmaw tribe.\\n\\nRead the boxed text when you're ready to start. If you create a different adventure hook, skip to the second paragraph and adjust the details as necessary, ignoring the information about driving the wagon.\\n\\nIn the city of Neverwinter, a dwarf named Gundren Rockseeker asked you to bring a wagonload of provisions to the rough-and-tumble settlement of Phandalin, a couple of days' travel southeast of the city. Gundren was clearly excited and more than a little secretive about his reasons for the trip, saying only that he and his brothers had found \\\"something big,\\\" and that he'd pay you ten gold pieces each for escorting his supplies safely to Barthen's Provisions, a trading post in Phandalin. He then set out ahead of you on horse, along with a warrior escort named Sildar Hallwinter, claiming he needed to arrive early to \\\"take care of business.\\\"\\n\\nYou've spent the last few days following the High Road south from Neverwinter, and you've just recently veered east along the Triboar Trail. You've encountered no trouble so far, but this territory can be dangerous. Bandits and outlaws have been known to lurk along the trail.\\n\\nYou've been on the Triboar Trail for about half a day. As you come around a bend, you spot two\"}"}
{"id": "emnlp-2022-main-637", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Griffin (DM) A dwarf named Gundren Rockseeker has hired you to transport a wagonload of provisions to the rough-and-tumble settlement of Phandalin, which is a couple days' travel to the southeast. A day and a half after leaving, you turn off the high road that connects the major cities on the coast onto a smaller trail that will lead you to Phandalin. This trail is not as well maintained, and bandits and outlaws have been known to lurk along the trail.\\n\\nThis game is based on the D&D starter adventure called \\\"Lost Mine of Phadelver\\\". The adventure book is a mixture of rules and \\\"boxed text\\\" which is descriptive text for the DM to read aloud or paraphrase. See the appendix for the text that the DM is consulting.\\n\\nAI challenges:\\nGeneration of stories and descriptive text\\n\\nGriffin (DM) Roll a perception check for me. Perception is a wisdom skill, so be sure to add your wisdom modifier.\\n\\nThe previous text was descriptive text. Here the DM is asking the players to perform a game mechanic and referencing a game rule. This is called \\\"out of character\\\" dialogue.\\n\\nAI challenges:\\nKnowledge base population (extraction of rules from a rulebook)\\n\\nClint (out of character) I got an eight.\\n\\nClint has rolled his dice. The number is low so his character fails the check.\\n\\nAI challenges:\\nMulti-party dialogue\\n\\nJustin (out of character) I got a six.\\n\\nJustin also fails. Neither character sees the thing that requires the perception check.\\n\\nTravis (out of character) I rolled a natural twenty plus my wisdom modifier is 23.\\n\\nTravis rolls high number and succeeds on the check.\\n\\nAI challenges:\\nUnderstanding rules, determining success or failure\\n\\nGriffin (DM) With his eagle eyes, Magnus spots two dead horses lying in the middle of the road about 200 feet ahead of you.\\n\\nThe DM describes what happens as a result of the success. AI challenges:\\nReasoning about consequences of success or failure, descriptive text generation\\n\\nTravis (in-character as Magnus) I stop the wagon and motion silently to get the attention of Merle and Taako, and kinda pull them up towards the front of the wagon.\\n\\nTravis is describing what he is doing using \\\"in character\\\" language.\\n\\nAI challenges:\\nPersona-based chat\\n\\nGriffin (DM) As you warn them that shit has gone south, you notice a few goblins crouching in a part of the shaded woods off to the side of the road. Two of the goblins begin charging your wagon.\\n\\nThe DM describes the start of a battle with several monsters.\\n\\nAI challenges:\\nState tracking (in combat v. out of combat).\\n\\nTravis (out of character) How many goblins are there? AI challenges:\\nQuestion answering, state tracking (how many monsters).\\n\\nGriffin (DM) There are three goblins; two of them are rushing the group, one is pretty heavily obscured by the brush, probably about 40 feet out, sort of between you and the dead horses laying in the middle of the road.\\n\\nAI challenges:\\nQuestion answering, Descriptive text generation from game state.\\n\\nClint (Merle) I will cast sacred flame at the nearest one. If it fails a dexterity saving throw, it takes 6 points of damage.\\n\\nClint chooses an action based on what is allowed for his character class. He describes the rule that governs the spell in an out-of-character fashion.\\n\\nAI challenges:\\nIntent detection (perform attack action against a particular goblin)\\n\\nGriffin (DM) You attack. You launch some fire onto the goblin closest to the wagon. And with that, he looks like he is on death's door. And the other goblin that you can see, the one that's not in the brush somewhere, just sort of stops in his tracks. What do you do next?\\n\\nThe DM rolls for the monster, updates the state of its health meter, and describes the result of Merle's attack.\\n\\nAI challenges:\\nReasoning about rules, state tracking (monster's HIT points), descriptive text generation.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"dead horses sprawled about fifty feet ahead of you, blocking the path. Each has several black-feathered arrows sticking out of it. The woods press close to the trail here, with a steep embankment and dense thickets on either side.\\n\\nFour goblins are hiding in the woods, two on each side of the road. They wait until someone approaches the bodies and then attack. This will likely be the first of many combat encounters in the adventure. Here are the steps you should follow to run it effectively:\\n\\n- Review the goblin stat block. Since the goblins are hiding, you'll need their Stealth skill modifier: +6.\\n- Check to see who, if anyone, is surprised. The party can't surprise the goblins, but the goblins might surprise some or all of the characters. Make a Dexterity (Stealth) check for the goblins: roll one d20 for all of them, add their Stealth skill modifier (+6) to the roll, and compare the total to the characters' passive Wisdom (Perception) scores. A character whose score is lower than the goblins' check total is surprised and therefore can't do anything on his or her first turn in the combat (see \\\"Surprise\\\" in the Basic Rules).\\n- Use the initiative rules in the Basic Rules to determine who acts first, second, third, and so on. Keep track of everyone's initiative count on a piece of paper.\\n- When the time comes for the goblins to act, two of them rush forward and make melee attacks while two goblins stand 30 feet away from the party and make ranged attacks. The goblins' stat block contains the information you need to resolve these attacks. For more information on what the goblins can do on their turn, see chapter 9, \\\"Combat,\\\" in the Basic Rules. When three goblins are defeated, the last goblin attempts to flee, heading for the goblin trail.\\n\\nIn addition to the heuristics that we used to recover state variables for each turn in the game (described in Section 3.1), we used a CNN to fill in state values when our heuristics did not fire. Table 9 estimates gives an estimate of the CNN's performance on filling in the state variables where the rule-based heuristic did not extract a value. The CNN classifier only uses current post text as input (no additional context).\\n\\nD Annotation Guidelines and Annotation Interface\\n\\nD.1 Annotation task\\n\\nIn this task, you will see part of a conversation between a few people playing D&D. The players and their characters are listed at the beginning of the conversation. The conversations that are shown as context are real conversations from players. Your job is to read the context and then rate different responses for a player/character given conversational context. Please note that the context you are given represents only a part of the players' past conversations/interactions with one another during the game.\\n\\nFor each response, you would be asked the following questions.\\n\\n- Does the response make sense?\\n  - Use your common sense here. Is the response completely reasonable in terms of the rules of D&D?\\n  - The response \\\"makes sense\\\" if it is cohesive as a standalone statement, consistent with the rules of the game, and the elements/entities mentioned are plausible, given the prior context.\\n  - If anything seems off\u2014not fluent, confusing, illogical, out of context, or wrong according to the rules of D&D\u2014then rate it as Does not make sense. If in doubt, choose Does not make sense.\\n\\n- Is the response specific?\\n  - You may be asked to assess whether the response is specific to a given context. In other words, do you think that the response represents a good thing for the character to do now?\\n  - The response is \\\"specific\\\" if it flows logically from the narrative established by the prior context.\\n\\n* Note: It is possible for a response to \\\"make sense\\\" (due to being cohesive, consistent and plausible in and of itself), but be marked \\\"not specific\\\" when it is not a logical next step in the overall game progression.\\n\\n* Note: \\\"Specific\\\" for the purposes of this task does not have to do with how detailed the response is per se; a response can be fairly general in its language, but still qualify as \\\"specific\\\" when it is a logical next step in the overall game progression.\\n\\n- How interesting is the response?\\n  - You may be asked to score the response for its interestingness on a scale of 10. Choose a high score for \\\"Interesting\\\" if the response would likely catch someone's attention or arouse curiosity in the game; or it is insightful, creative, or witty with respect to the game. If the response is monotonous and predictable, or if you're unsure, then it is Less Interesting.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 9: The estimated performance of our CNN classifier on predicting state values for turns where our rule-based heuristics did not predict a value.\\n\\nD.2 Annotation Interface\\n\\nA mock up of the annotation user interface is given in Figure 3.\\n\\nD.3 Survey of Raters\\n\\nWe recruited raters who had a background in role-playing games and an understanding of the fantasy genre. We surveyed our raters, asking them the following questions:\\n\\n1. Have you ever played Dungeons and Dragons or another role playing game before?\\n2. If so, \u2022 roughly how many times have you played \u2022 were you a player or a game master or both\\n3. If not, \u2022 what kind of exposure do you have to Dungeons and Dragons? (For example, have you seen it referred to in TV or movies)\\n4. Are you a fan of the fantasy genre (like Lord of the Rings)?\\n\\nOur 6 raters responded to the survey as follows: 5 out of the 6 have played D&D or another role playing game before. All 5 of those who have played D&D /other role playing games before have played more than 6 times. Of the 5 who have played D&D /other role playing games before, 3 played as both Game Master and Player. For the one who had not played D&D /other role playing games, they indicated they had not had much exposure to D&D through TV or other channels. All 6 answered that they were fans of the fantasy genre.\"}"}
{"id": "emnlp-2022-main-637", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: The user interface that our raters used to evaluate the quality of our model's next utterance prediction.\"}"}
