{"id": "lrec-2022-1-784", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Annotation-Scheme Reconstruction for \\\"Fake News\\\" and Japanese Fake News Dataset\\nTaichi Murayama*, Shohei Hisada*, Makoto Uehara, Shoko Wakamiya, Eiji Aramaki\\n\\n1 SANKEN Osaka University, 2 NARA Institute of Science and Technology,\\n\\nAbstract\\nFake news provokes many societal problems; therefore, there has been extensive research on fake news detection tasks to counter it. Many fake news datasets were constructed as resources to facilitate this task. Contemporary research focuses almost exclusively on the factuality aspect of the news. However, this aspect alone is insufficient to explain \u201cfake news,\u201d which is a complex phenomenon that involves a wide range of issues. To fully understand the nature of each instance of fake news, it is important to observe it from various perspectives, such as the intention of the false news disseminator, the harmfulness of the news to our society, and the target of the news. We propose a novel annotation scheme with fine-grained labeling based on detailed investigations of existing fake news datasets to capture these various aspects of fake news. Using the annotation scheme, we construct and publish the first Japanese fake news dataset. The annotation scheme is expected to provide an in-depth understanding of fake news. We plan to build datasets for both Japanese and other languages using our scheme. Our Japanese dataset is published at https://hkefka385.github.io/dataset/fakenews-japanese/.\\n\\nKeywords: fake news, misinformation, disinformation, social media, computational social science, dataset\\n\\n1. Introduction\\nFake news has caused significant damage to various fields of society, such as the economy, politics, and health problems. For example, during the 2016 U.S. presidential election, 529 different low-credibility statements (Jin et al., 2017) were spread on Twitter. Moreover, 25% of the news outlets that were linked from tweets, which were either fake or extremely biased in supporting Trump or Clinton, potentially influenced the election (Bovet and Makse, 2019). Recently, the COVID-19 pandemic in 2020 resulted in the spread of disinformation and harmful content in the rapid influx of information, such as the relationship between the COVID-19 vaccine and infertility (Schraer, 2021).\\n\\nFake news has become a significant crisis that threatens a wholesome society and the social media ecosystem. Previous studies have proposed various tasks to combat the social problems caused by the spread of fake news. For example, the fake news detection task aims to classify whether the news content that is spread from news articles and social media posts is false. Additionally, many fake news datasets have been constructed as resources to facilitate the task, e.g., FakeNewsNet (Shu et al., 2020), Twitter16 (Ma et al., 2017), and CoAID (Cui and Lee, 2020). These existing studies on fake news detection and the corresponding dataset construction have focused almost exclusively on the factuality aspect of the news \u2013 Can we fully understand \u201cfake news\u201d and various events it causes based on these datasets given factuality labels?\\n\\nThis is exactly the motivation behind our work. To promote understanding of fake news, we consider that it is necessary to provide not only factual information, but also information from various perspectives, such as the intention of the false news disseminator, the harmfulness of the news to our society, and the target of the news.\\n\\nWe propose a novel annotation scheme to capture the various perspectives of false news, and it is based on our investigations of the definition of \u201cfake news\u201d and existing fake news detection datasets. We annotate each news story and its social media posts using the following points: (1) factuality, (2) intention of the disseminator, (3) target, (4) method to report the target, (5) purpose, (6) potential harm to society, and (7) types of harm. These annotations from various perspectives are useful in facilitating an in-depth understanding of fake news, which is a complex phenomenon. For example, it is interesting to consider how its spreading changes depending on the disseminator knowing whether the news is false or not. The annotations also provide a significant value to real-world applications, such as building a fake news detection system that reveals the potential dangers of false information for journalists, fact-checkers, policymakers, and government entities.\\n\\nWe then construct a first Japanese fake news dataset according to the annotation scheme. The construction of this dataset will facilitate our understanding of the spread of fake news in Japan. In the future, we plan to apply this method to other fake news datasets in English and other languages. Applying our annotation scheme to fake news in multiple countries and comparing the results is expected to enable a further detailed analysis of fake news.\\n\\nThis study makes the following contributions:\\n\u2022 We identify issues that need to be resolved in\"}"}
{"id": "lrec-2022-1-784", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2. Survey\\n\\nFirst, we discuss the definition of \u201cfake news\u201d and its ambiguity. We then identify issues that need to be resolved in the dataset construction through an extensive survey of existing fake news detection datasets. Our proposed annotation scheme builds on the discussions and findings in this section.\\n\\n2.1. Definition of Fake News\\n\\nResearchers primarily employ either broad or narrow definitions of fake news. A broad definition of fake news is that \u201cFake news is false news. (Zhou and Zafarani, 2020)\u201d Similarly, Lazer et al. (2018) states that \u201cfake news is fabricated information that mimics news media content in form but not in organizational process or intent.\u201d This broad definition emphasizes only information authenticity and does not consider information intention. This enables us to include different types of fake news, which can be identified by their motive or intent, such as satire and parody (Rubin et al., 2015). A few studies (Vosoughi et al., 2018; Jin et al., 2016) leverage the broad definition of fake news.\\n\\nAs the narrow definition of fake news, most research emphasizes its \u201cintention.\u201d Shu et al. (2017) and Allcott and Gentzkow (2017) define fake news as \u201ca news article that is intentionally and verifiably false.\u201d Zhang and Ghorbani (2020) states that \u201cfake news refers to all kinds of false stories or news that are mainly published and distributed on the Internet, in order to purposely mislead, befool, or lure readers for financial, political, or other gains.\u201d Many other studies (Mustafaraj and Metaxas, 2017; Conroy et al., 2015; Potthast et al., 2018) have also emphasized intention in the definition of fake news. They adopt a narrow definition of fake news; nevertheless, their dataset construction only focuses on the factuality of the news based on the judgment of fact-checking sites, not on the intention. Therefore, the definition of the phrase \u201cfake news\u201d is ambiguous, and there is some criticism of this ambiguity. For example, the British government decided that the phrase \u201cfake news\u201d would no longer be used in official documents because it is a poorly defined and misleading term that conflates a variety of false information (Newsweek, 2018). Claire Wardle, the co-founder and leader of First Draft, announced that the phrase \u201cfake news\u201d is woefully inadequate to describe the related issues and distinguishes between three types of information-content problems: misinformation, disinformation, and malinformation (Giuliani-Hoffman, 2017). Disinformation is related to the intention of users who create and share content, whereas malinformation is associated with the harmfulness of the information to society. Part of our annotation scheme refers to this suggestion. The concept of fake news has a variety of meanings, owing to current diverse circumstances.\\n\\n2.2. Issues in existing fake news detection datasets\\n\\nMany datasets have been constructed for the task of fake news detection, which assesses the truthfulness of a particular piece of news from news content or social media posts. We examined 51 fake news detection datasets and identified four issues that needed to be resolved. The details of each dataset are listed in Murayama (2021).\\n\\nIntention\\n\\nEven though many studies adopt a narrow definition of fake news, which considers the intent of the disseminators, all datasets have labels that focus only on the factual aspects of each news item, not on the intention, based on the broad definition. This situation implies a divergence between the definition of fake news in technical development and the original narrow definition of fake news. We consider that most fake news detection models that are built on existing datasets should be called \u201cfalse information detection models.\u201d Additionally, news created with malicious intent aims to be more persuasive than that without such aims, and malicious users typically participate in the propagation of false news to enhance its visibility on social media (Leibenstein, 1950). This background makes it necessary to annotate the intentions of news disseminators to build a highly explainable detection model.\\n\\nHarmfulness to society\\n\\nFake news may have a greater or lesser detrimental effect on society. For example, parody news that is clearly false is less harmful to society; however, false news about elections or COVID-19 vaccines is very harmful, owing to its strong influence on people\u2019s decision-making. This perspective is not reflected in most existing datasets. A dataset called COVID-Alam (Alam et al., 2021) annotates each COVID-19 fake news item with its degree of harm to society. We consider that it would be useful for the decision on the priority of fact-checking to make a detailed annotation to various types of news, not only COVID-19 news. For example, it is important to consider which aspects of society the news is harmful to and what the extent of the harm is. This covers the malinformation perspective mentioned by Claire Wardle.\"}"}
{"id": "lrec-2022-1-784", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The linguistic characteristics and diffusion patterns of fake news vary according to country and language. However, the language included in most fake news datasets is English, and they primarily focus on the US society. This has occurred because although there is a growing awareness that fact-checking is an important action worldwide, there are still only a few fact-checking organizations with adequate workforce, which forms the basis for dataset construction, in countries other than the US. However, fake news detection datasets in languages other than English have also increased since the global infodemic caused by COVID-19. Of the 51 datasets that we examined, 11 included languages other than English, and 8 of them were datasets on COVID-19. The construction of a non-English fake news dataset that targets various topics leads to an analysis of fake news across languages and the identification of unique non-variant characteristics that are independent of language.\\n\\nLabels\\n33 datasets out of 51 are assigned a binary label, fake or real, because binary classification makes machine learning models easier to apply. Other datasets have fine-grained labels, typically more than two labels; however, the criteria vary across datasets based on the rating given by fact-checking sites; e.g., Politifact has six labels (True, Mostly True, Half True, Mostly False, False, and Pants on Fire) and Snopes primarily has five labels (True, Mostly True, Mixture, Mostly False, and False.) Such variation in the categorization criterion in each dataset confuses the dataset users. Further related to the above-mentioned issues of \\\"intention\\\" and \\\"harmfulness to society,\\\" a fine-grained and consistent annotation scheme is required to build a more general and robust fake news detection model.\\n\\n3. Annotation Scheme\\nWe present an annotation scheme that was developed through careful discussion and insights gained from an examination of existing datasets. This section describes the key questions in our annotation. Q1\u2013Q5 are aimed at constructing a more fine-grained labeling than the binary labeling in existing datasets or the rating given by fact-checking sites. These questions primarily cover \\\"intention\\\" and \\\"labels\\\" issues in existing datasets. Q6 and Q7, which are extensions of Alam et al. (2021) applied to general news, try to identify the harmful effects on society related to the second issue. We ask annotators to answer these questions based on fact-checking articles and original texts. The reclassification of false news using the shared annotation scheme with fine-grained labeling can achieve a common framework for understanding false news, which is independent of the rating of various fact-checking sites. This is also useful in building detection models that are highly interpretable.\\n\\nQ1: What rating does the fact-checking site assign to the news?\\nThis is a very simple question, and it can be answered by simply searching the corresponding fact-checking site. This also plays a role in removing inappropriate annotators. Annotators generally choose a rating in the range between true and false, and the options vary depending on the fact-checking site. If the annotators select True or Half-True, it implies that they automatically skip subsequent questions (Q2\u2013Q7) that are asked only about false news.\\n\\nQ2-1: Does the news disseminator know that the news is false?\\nThis question asks for a subjective judgment. It covers \\\"intention,\\\" which is one of the issues in existing fake news detection datasets. We ask the annotators to determine whether the spreading of fake news is intentional and classify their responses into four categories based on their observations of fact-checking articles and original social media posts. If they select yes, the news can be considered fake news following the narrow definition; note that we call them \\\"disinformation\\\" based on Zhou and Zafarani (2020). However, we cannot definitively regard the news as the news with malicious because it may be satire or parody news. If they select no, it means that the disseminator does not intend to spread false news, which we call \\\"misinformation.\\\" Moreover, these decision branches are differentiated according to the degree of the annotator's belief, which is the distinction between \\\"definitely\\\" and \\\"probably.\\\" Such labeling of the intention may reveal the difference in users' behavior for each type of false information, such as the type of information people spread without knowing it is false. This is also important irrespective of a study's use of the broad or narrow definition. The possible answers to Q2-1 are as follows:\\n\\n1. Yes, the news disseminator definitely knows that the news is false (Disinformation)\\n2. Yes, the news disseminator probably knows that the news is false (Disinformation)\\n3. No, the news disseminator probably does not know the news is false (Misinformation)\\n4. No, the news disseminator definitely does not know that the news is false (Misinformation)\\n\\nIn addition, we set the following questions regarding the type of news, depending on the selection of Q2-1:\\n\\nQ2-2A: If yes (disinformation), how was the news created?\\nThis question is designed to annotate how intentionally disseminated news is created. As a result of our detailed discussion and the analysis of a previous study (Wardle, 2017), we observed that each intentionally spread news story can be classified according to at least one of four categories: fabricated content, manipulated image, manipulated text, and false context. First, these news stories can be categorized as either completely created news or news created by falsifying original resources. We call the former \\\"fabricated content.\\\" The latter can be divided into three classes\"}"}
{"id": "lrec-2022-1-784", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"depending on the object of falsification: \\\"manipulated image\\\" refers to content that has been manipulated for an image or video, \\\"manipulated text\\\" refers to content that has been manipulated for news text or social media messages related to the news, and \\\"false context\\\" refers to content that is shared with false contextual information despite the content itself being genuine.\\n\\n1. Fabricated content\\n2. Manipulated image\\n3. Manipulated text\\n4. False context\\n\\nQ2-2B: If no (misinformation), how does the disseminator misunderstand the news?\\n\\nWe label why the disseminator has spread the false news with no intention. This is an important annotation for us to consider to prevent the future spread of false news. Similar to Q2-2A, we observed that the reason for spreading false news with no intention can be classified into three categories: trusting other sources, inadequate understanding, and misleading. The first category refers to trusting information from other sources. This frequently occurs when non-native English speakers mistranslate English articles and research papers or trust false information that is originally disseminated in English. The second category refers to an inadequate understanding and uncertain assumptions made by the disseminator. This may be caused by the disseminator not having thoroughly read the news. The final category refers to the case in which the disseminator may adequately understand the news, but they insufficiently convey it to the reader; that is, it refers to representing information in a misleading way.\\n\\n1. Trusting other sources\\n2. Inadequate understanding\\n3. Misleading\\n\\nQ3: At whom or what is the false news targeted?\\n\\nThe main target of false news, namely the target that is primarily affected by the fact that the news is false, is useful information for news clustering and retrieval. The task of identifying such information has not yet been completed; however, we believe that it will be an important task to promote the understanding of fake news in the future. To enable the application of information-extraction techniques, we give the annotators the following instructions: \\\"Extract the targets that are primarily affected by the fact that the news is false from the claim sentences on fact-checking sites or the original social media post about the false news (multiple extractions possible).\\\"\\n\\nQ4: Does the news flatter or denigrate the target?\\n\\nWe annotate the stance that the news has toward the target, that is, flattery or denigration. Even within the category of false news, the reader's impression of good behavior news, such as donations, is very different from that of bad behavior news, such as criminal acts, even though the target has not actually done either act. This annotation provides important information for understanding the impact of fake news on society, particularly for analyzing the impact of fake news on polarisation. The annotations are as follows:\\n\\n1. Flattery\\n2. Denigration\\n3. Neither / No such intention\\n\\nQ5: What is the purpose of the false news?\\n\\nJust as some news media lean toward liberal or conservative views and report the news according to it, some false news stories are fabricated with some intention to spread the disseminator's own theory; for example, the COVID-19 vaccine is dangerous to human health. Although the purpose of some false news items cannot be inferred, we set the following categories of false news purpose. The first category is satire or parody news for the purpose of entertaining or criticizing readers (Brummette et al., 2018). These false news stories are not commonly referred to as fake news. The second is partisan news, which is extremely one-sided or biased news that has a political context. Biasing itself does not mean that the news is fake; however, some studies (Hine et al., 2017; Zannettou et al., 2018) report that it has a high possibility of being false in parts of partisan news. This annotation is important to understand the relationship between partisan news and false news. The third is propaganda, which is a form of persuasion that attempts to influence the emotions, attitudes, opinions, and actions of specified target audiences for ideological, religious, and other purposes (Jowett and O'donnell, 2018). Propaganda may also include political purposes in general; however, we instruct the annotators to categorize propaganda with political purposes in the partisan category to aid distinction. This question is expected to clarify the relationship between false news and the following categories:\\n\\n1. Satire / Parody\\n2. Partisan\\n3. Propaganda\\n4. No purpose / Unknown\\n\\nQ6: To what extent is the news harmful to society?\\n\\nThis is a particularly subjective question. Its purpose is to identify news stories that can negatively affect society, including specific people and companies. Specifically, we ask the annotators to indicate the degree of harm to society on a real scale of 0\u20135. A score of 0 indicates that the news poses no harm to society. A score of 5 indicates that the news is definitely harmful to society. To obtain the annotators' answers, which do not vary greatly, we ask them to label the degree of harm using a combination of two perspectives: how much truth is in the text description, and how much damage may be caused by believing the news.\\n\\nQ7: What types of harm can the news cause?\\n\\nThis question helps us understand what types of harm the news causes or has the potential to cause. We set up seven categories of harm that fake news can cause, and we added the option \\\"not sure\\\" for cases in which a decision cannot be made. The categories are described\"}"}
{"id": "lrec-2022-1-784", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Original tweet and the corresponding fact-checking article of its targeting for our annotation are shown on the left. Labeled information by our annotation is shown on the right. The targeting content is a video of a party debate attached by a social media influencer on Twitter. It is stated in the fact checker\u2019s judgment that this video creates a bad impression of the opposition leader (Mr. Edano) because it omits parts of the debate.\\n\\nFigure 2: The targeting content describes how to eat oysters for the prevention of food poisoning. The fact checker notes that the method prescribed for eating does not reduce the likelihood of food poisoning.\\n\\nBelow, some news stories may be aligned with more than one category; however, we ask the annotators to choose one category that they consider the most appropriate.\\n\\n1. Harmless (e.g., Satire / Parody)\\n2. Confusion and anxiety about society\\n3. Threat to honor and trust in people and companies\\n4. Threat to correct understanding of politics and social events\\n5. Health\\n6. Prejudice against country and race\\n7. Conspiracy Theory\\n8. Not sure\\n\\n4. Japanese Fake News Dataset\\n\\n4.1. Original Data\\n\\nTo construct the Japanese fake news dataset following our annotation scheme, we first collected verified articles published in Fact Check Initiative Japan (Japan, Japan). We targeted the news that was spread on Twitter via these verified articles. And we manually searched for posts or news articles that triggered the spread of false information using Twitter search function. We asked the annotators to annotate 307 news stories, which were featured by Fact Check Initiative Japan between July 2019 and October 2021. Examples of these annotations are shown in Figures 1 and 2.\\n\\n4.1.1. Annotation\\n\\nAs a pilot annotation, four annotators independently annotated 20 examples and attempted to resolve cases of disagreement in a meeting. Based on their discussions, the annotation scheme and guidelines were refined. Finally, we asked three annotators to answer the questions introduced in the Annotation section regarding the 307 verified news stories by checking the verification articles, triggered posts, and news articles. In the annotation process, we calculated the inter-annotator agreement using Fleiss\u2019 kappa. The results show that Fleiss\u2019 Kappa was generally high for each question. For example, it was higher than 0.8 for Q2-1 and 0.7 for Q4. Additionally, it was higher than 0.6 for Q7, for which eight options exist. In contrast, Fleiss\u2019 kappa for Q2-2A and Q2-2B, which were subjective questions, was approximately 0.5. Note that kappa values of 0.21\u20130.40, 0.41\u20130.60, 0.61\u20130.80, and 0.81\u20131.0, correspond to fair, moderate, substantial, and perfect agreement, respectively (Landis and Koch, 1977).\\n\\n4.1.2. Data statistics\\n\\nTable 1 shows relevant statistics on the annotations. Q1 shows the distribution of the fact-checking judgment for each news story. Most articles selected by Japanese fact-checking organizations for verification are false stories. Thus, the selection of articles by Japan\u2019s fact-checking organization is biased (only five news stories are true). For Q2-1, the labels \u201cdisinformation\u201d and \u201cmisinformation\u201d were applied to 13% and 87% of the news stories, respectively. In most cases, the disseminator was unaware that the news was false. The class distribution of Q2-2A, for which only the news stories labeled as disinformation were annotated, is relatively balanced. In Q2-2B, for misinformation, \u201cinadequate understanding\u201d accounts for approximately half of the annotations. For Q4, which asks whether the news flatters or denigrates the target, the distribution is skewed towards \u201cdenigration\u201d in 60% of the news stories. This suggests that most false news is written to discredit people. For Q5, which asks what the purpose of the false news is, most news stories are labeled as \u201cno purpose / Unknown.\u201d Propaganda and partisan false news were identified in approximately 20% of news stories each. For Q6, the extent to which the news is harmful to society, the annotators chose average scales of 1\u20132 and 2\u20133 for many false news stories from a range of 0\u20135. For Q7, which asks what types of harm the news has, the majority of news stories are labeled as\"}"}
{"id": "lrec-2022-1-784", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Distribution of the Japanese fake news dataset.\\n\\nIn the rows with a question, we show the total number of annotations.\\n\\nQ1: What rating does the fact-checking site attribute to the news?\\n\\n- True: 1\\n- Half-True: 4\\n- Inaccurate: 50\\n- Misleading: 52\\n- False: 153\\n- Pants on Fire: 16\\n- Unknown Evidence: 30\\n- Suspended Judgment: 1\\n\\nQ2-1: Does the news disseminator know that the news is false?\\n\\n- Yes, the news disseminator definitely knows that the news is false. (Disinformation): 20\\n- Yes, the news disseminator probably knows that the news is false. (Disinformation): 19\\n- No, the news disseminator probably does not know that the news is false. (Misinformation): 155\\n- No, the news disseminator definitely does not know that the news is false. (Misinformation): 107\\n\\nQ2-2A: If yes, how was the news created?\\n\\n- Fabricated content: 15\\n- Manipulated image: 12\\n- Manipulated text: 6\\n- False context: 6\\n\\nQ2-2B: If no, how does the disseminator misunderstand the news?\\n\\n- Trusting other sources: 61\\n- Inadequate understanding: 131\\n- Misleading: 70\\n\\nQ4: Does the news flatter or denigrate the target?\\n\\n- Flattery: 25\\n- Denigration: 181\\n- Neither / No such intention: 95\\n\\nQ5: What is the purpose of the false news?\\n\\n- Satire / Parody: 6\\n- Partisan: 70\\n- Propaganda: 67\\n- No purpose / Unknown: 158\\n\\nQ6: To what extent is the news harmful to society? (average)\\n\\n- 0 \u223c 1 (including 1): 17\\n- 1 \u223c 2 (including 2): 128\\n- 2 \u223c 3 (including 3): 112\\n- 3 \u223c 4 (including 4): 41\\n- 4 \u223c 5 (including 5): 3\\n\\nQ7: What types of harm can the news cause?\\n\\n- Harmless (e.g., Satire / Parody): 6\\n- Confusion and anxiety about society: 41\\n- Threat to honor and trust in people and companies: 109\\n- Threat to correct understanding of politics and social events: 63\\n- Health: 29\\n- Prejudice against country and race: 42\\n- Conspiracy theory: 11\\n- Not sure: 0\\n\\n\u201cthreat to honor and trust in people and companies\u201d (36%). Most news stories labeled as \u201chealth\u201d are related to COVID-19. The \u201charmless\u201d and \u201cconspiracy theory\u201d labels only constitute a small percent of news stories. Our fine-grained annotations can be a useful tool for understanding false news trends in the target country.\\n\\nIn addition to the annotation results, we collected posts and related context information on 186 news stories that triggered the spread of false information from Twitter using Twitter Search API. The data we collected from Twitter included 471,446 tweets (2,534 tweets per news story), 277,106 users (1,489 users per news story), and 17,401 conversations (93 conversations per news story). We publish these annotation results, the collected tweet IDs, fact-checked articles, and other related information in [GitHub](https://hkefka385.github.io/dataset/fakenews-japanese/).\"}"}
{"id": "lrec-2022-1-784", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7.2. Sentiment of responses\\n\\nPeople express their emotions or opinions about false news through social media posts, such as skeptical opinions and sensational reactions. These features are important signals for the study of false news in general (Qazvinian et al., 2011; Jin et al., 2016).\\n\\nWe performed sentiment analysis on the replies to user posts that spread false news using the sentiment classification API in Amazon Comprehend (Comprehend, ), which leverages a pretraining language model. This API classifies emotions from the input text into one of four categories: positive, negative, neutral, or mixed.\\n\\nFigure 5 shows the relationship between the positive, neutral, and negative replies to news stories from the perspectives of disinformation and misinformation obtained from Q2-1. It represents the ratio of sentiments (positive, negative, or neutral), which are predicted from all the replies to the related tweets of each news story. The ternary plots of both disinformation and misinformation show that most replies to each news item are neutral instead of emotional responses. An analysis of the emotional replies shows that although some news stories that were labeled misinformation had a high ratio of positive replies, most news stories had more negative replies. It is suggested that false news is likely to cause negative emotions, regardless of misinformation and disinformation.\\n\\n5.3. User profiles\\n\\nWe aim to analyze the users who spread false information. False news dissemination processes and user information are effective for fake news detection and understanding the formation of an echo chamber cycle (Del Vicario et al., 2016).\\n\\nFigure 6 shows the distribution of the count of followee/follower related to tweets labeled as disinformation or misinformation. X-axis represents the followee/follower count and Y-axis represents the number of users.\"}"}
{"id": "lrec-2022-1-784", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: The distribution of the time that elapsed since the user account creation date from two perspectives: disinformation and misinformation.\\n\\nUsers who spread disinformation tend to have more followers than those who spread misinformation. The follower and followee counts of the users generally follow a power-law distribution, which is commonly observed in social network structures. There is a spike around 5,000 in the followee count distribution for both, owing to Twitter restrictions.\\n\\nFigure 7 shows the distribution of the time that has elapsed since each user created their account. The distributions for disinformation and misinformation are similar. However, when compared with reports on the distribution of users that spread false news in the US (Shu et al., 2020), our results exhibit two features. One is that few users have created accounts less than a year ago. Another feature is that users who had been using Twitter for more than 10 years accounted for a large portion of disinformation and misinformation disseminators. We believe that these characteristics are due to the fact that social media \\\"bot accounts\\\" are less active in Japan than in the US.\\n\\nFinally, we investigated the ratio between \\\"bot accounts\\\" and human users that were involved in tweets related to misinformation and disinformation. We randomly selected 10,000 users from each category and performed bot detection using the Botometer API (Davis et al., 2016). As a result, the ratio of \\\"bot accounts\\\" to human users is similar in the two categories: approximately 8% for disinformation and 6% for misinformation. However, a comparison of reports on the ratio of bot users that spread false news in the US (Shu et al., 2020) and Japan shows that there are fewer bot users in Japan. Specifically, almost 22% of users that disseminate false news are bots in the US, whereas the corresponding percentage for Japanese users is less than 10%.\\n\\n6. Conclusion and Future Work\\n\\nWe proposed a novel annotation scheme to capture false news from various perspectives based on our investigations of the definition of \\\"fake news\\\" and existing fake news detection datasets. We expect to reach an in-depth understanding of the phenomenon of \\\"fake news\\\" using our annotation scheme, which utilizes fine-grained labeling that incorporates intent, negative social impact, targeting, and uniform labeling, and extends beyond factuality. Subsequently, the first Japanese fake news dataset was constructed based on the annotation scheme to facilitate the study of fake news in Japan.\\n\\nHowever, our Japanese fake news dataset is limited by a small sample size, owing to the small number of fact-checking articles that have been created. To mitigate this limitation, we will continue to expand the dataset. Furthermore, we will use our annotation scheme to construct datasets for false news in other languages. These research endeavors will enable the following future studies:\\n\\n\u2022 An examination of the extent to which existing fake news detection models and language models can classify the labels assigned to our annotation scheme from social media posts. This is an important task to understand the limits of what machine learning methods can automatically classify. Although we were not able to conduct this investigation, owing to the small sample size of our constructed dataset in this study, we can proceed with this investigation in future work by extending our dataset.\\n\\n\u2022 A comparison of the characteristics of fake news, such as the linguistic patterns and its diffusion patterns, across multiple countries. This task has rarely been performed. Section 5.3 compared statistics on the users who spread fake news from the existing English fake news dataset and our dataset. The construction of fake news datasets in other languages using the same scheme can enable multi-country comparisons on a more extensive scale. This may help us discover the unknown properties of fake news.\\n\\nBibliographical References\\n\\nAlam, F., Dalvi, F., Shaar, S., Durrani, N., Mubarak, H., Nikolov, A., Da San Martino, G., Abdelali, A., Sajjad, H., Darwish, K., et al. (2021). Fighting the covid-19 infodemic in social media: A holistic perspective and a call to arms. In Proc. of ICWSM, volume 15, pages 913\u2013922.\\n\\nAllcott, H. and Gentzkow, M. (2017). Social media and fake news in the 2016 election. Journal of economic perspectives, 31(2):211\u201336.\\n\\nBovet, A. and Makse, H. A. (2019). Influence of fake news in twitter during the 2016 us presidential election. Nature communications, 10(1):1\u201314.\"}"}
{"id": "lrec-2022-1-784", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Brummette, J., DiStaso, M., Vafeiadis, M., and Messner, M. (2018). Read all about it: The politicization of \\\"fake news\\\" on twitter. Journalism & Mass Communication Quarterly, 95(2):497\u2013517.\\n\\nComprehend, A. (). Amazon comprehend. https://docs.aws.amazon.com/comprehend. [accessed on November 23th, 2021].\\n\\nConroy, N. K., Rubin, V. L., and Chen, Y. (2015). Automatic deception detection: Methods for finding fake news. Proceedings of the association for information science and technology, 52(1):1\u20134.\\n\\nCui, L. and Lee, D. (2020). Coaid: Covid-19 healthcare misinformation dataset. arXiv preprint arXiv:2006.00885.\\n\\nDavis, C. A., Varol, O., Ferrara, E., Flammini, A., and Menczer, F. (2016). Botornot: A system to evaluate social bots. In Proc. of WWW, pages 273\u2013274.\\n\\nDel Vicario, M., Vivaldo, G., Bessi, A., Zollo, F., Scala, A., Caldarelli, G., and Quattrociocchi, W. (2016). Echo chambers: Emotional contagion and group polarization on facebook. Scientific reports, 6(1):1\u201312.\\n\\nGiuliani-Hoffman, F. (2017). 'f*** news' should be replaced by these words, claire wardle says. https://money.cnn.com/2017/11/03/media/claire-wardle-fake-news-reliable-sources-podcast/index.html. [accessed on November 9th, 2021].\\n\\nHine, G., Onaolapo, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, R., Stringhini, G., and Blackburn, J. (2017). Kek, cucks, and god emperor trump: A measurement study of 4chan's politically incorrect forum and its effects on the web. Proc. of ICWSM, 11(1):92\u2013101.\\n\\nJapan, F. C. I. (). Fact check initiative japan. https://fij.info/. [accessed on November 9th, 2021].\\n\\nJin, Z., Cao, J., Zhang, Y., and Luo, J. (2016). News verification by exploiting conflicting social viewpoints in microblogs. 30(1).\\n\\nJin, Z., Cao, J., Guo, H., Zhang, Y., Wang, Y., and Luo, J. (2017). Detection and analysis of 2016 us presidential election related rumors on twitter. In International conference on social computing, behavioral-cultural modeling and prediction and behavior representation in modeling and simulation, pages 14\u201324. Springer.\\n\\nJowett, G. S. and O'donnell, V. (2018). Propaganda & persuasion. Sage publications.\\n\\nLandis, J. R. and Koch, G. G. (1977). The measurement of observer agreement for categorical data. biometrics, pages 159\u2013174.\\n\\nLazer, D. M., Baum, M. A., Benkler, Y., Berinsky, A. J., Greenhill, K. M., Menczer, F., Metzger, M. J., Nyhan, B., Pennycook, G., Rothschild, D., et al. (2018). The science of fake news. Science, 359(6380):1094\u20131096.\\n\\nLeibenstein, H. (1950). Bandwagon, snob, and veblen effects in the theory of consumers' demand. The quarterly journal of economics, 64(2):183\u2013207.\\n\\nMa, J., Gao, W., and Wong, K.-F. (2017). Detect rumors in microblog posts using propagation structure via kernel learning. In Proc. of ACL, pages 708\u2013717.\\n\\nMurayama, T. (2021). Dataset of fake news detection and fact verification: A survey. arXiv preprint arXiv:2111.03299.\\n\\nMustafaraj, E. and Metaxas, P. T. (2017). The fake news spreading plague: was it preventable? In Proc. of WebSci, pages 235\u2013239.\\n\\nNewsweek. (2018). British government bans the phrase 'fake news'. https://www.newsweek.com/british-government-bans-phrase-fake-news-1182784. [accessed on November 9th, 2021].\\n\\nPotthast, M., Kiesel, J., Reinartz, K., Bevendorff, J., and Stein, B. (2018). A stylometric inquiry into hyperpartisan and fake news. In Proc. of ACL, pages 231\u2013240.\\n\\nQazvinian, V., Rosengren, E., Radev, D. R., and Mei, Q. (2011). Rumor has it: Identifying misinformation in microblogs. In Proc. of EMNLP, pages 1589\u20131599.\\n\\nRubin, V. L., Chen, Y., and Conroy, N. K. (2015). Deception detection for news: three types of fakes. Proceedings of the Association for Information Science and Technology, 52(1):1\u20134.\\n\\nSchraer, R. (2021). Covid vaccine: Fertility and miscarriage claims fact-checked. https://www.bbc.com/news/health-57552527. [accessed on November 9th, 2021].\\n\\nShu, K., Sliva, A., Wang, S., Tang, J., and Liu, H. (2017). Fake news detection on social media: A data mining perspective. ACM SIGKDD explorations newsletter, 19(1):22\u201336.\\n\\nShu, K., Mahudeswaran, D., Wang, S., Lee, D., and Liu, H. (2020). Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media. Big data, 8(3):171\u2013188.\\n\\nVosoughi, S., Roy, D., and Aral, S. (2018). The spread of true and false news online. Science, 359(6380):1146\u20131151.\\n\\nWardle, C. (2017). Fake news. it's complicated. https://firstdraftnews.org/articles/fake-news-complicated/. [accessed on November 9th, 2021].\\n\\nZannettou, S., Bradlyn, B., De Cristofaro, E., Kwak, H., Sirivianos, M., Stringini, G., and Blackburn, J. (2018). What is gab: A bastion of free speech or an alt-right echo chamber. In Companion Proc. of WebConf, pages 1007\u20131014.\\n\\nZhang, X. and Ghorbani, A. A. (2020). An overview of online fake news: Characterization, detection, and discussion. Information Processing & Management, 57(2):102025.\\n\\nZhou, X. and Zafarani, R. (2020). A survey of fake news: Fundamental theories, detection methods, and opportunities. ACM Computing Surveys (CSUR), 53(5):1\u201340.\"}"}
