{"id": "lrec-2022-1-250", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The CRECIL Corpus: a New Dataset for Extraction of Relations between Characters in Chinese Multi-party Dialogues\\n\\nYuru Jiang\u2217, Yang Xu\u2217, Yuhang Zhan\u2217, Weikai He\u2217, Yilin Wang\u2217, Zixuan Xi\u2217, Meiyun Wang\u2217, Xinyu Li\u2217, Yu Li\u2217, Yanchao Yu\u2020\\n\\n\u2217Computer School, Beijing Information Science and Technology University\\njiangyuru@bistu.edu.cn\\n\u2020School of Computing, Edinburgh Napier University\\ny.yu@napier.ac.uk\\n\\nAbstract\\nWe describe a new freely available Chinese multi-party dialogue data set for automatic extraction of dialogue-based character relationships. The data has been extracted from the original TV scripts of a Chinese sitcom called \\\"I Love My Family\\\" with complex family-based human daily spoken conversations in Chinese. First, we introduced human annotation scheme for both global Character relationship map and character reference relationship. And then we generated the dialogue-based character relationship triples. The corpus annotates relationships between 140 entities in total. We also carried out a data exploration experiment by deploying a BERT-based model to extract character relationships on the CRECIL corpus and another existing relation extraction corpus (DialogRE (Yu et al., 2020)). The results demonstrate that extracting character relationships is more challenging in CRECIL than in DialogRE.\\n\\nKeywords: Multi-Party Dialogue; Character Relation; Corpus; Annotation Scheme; Relation Extraction\\n\\n1. Introduction\\nWhile bringing intelligent systems/robots out of the laboratory into the physical world, especially into the daily environment, they must become capable of understanding natural daily conversations between two or more human speakers. Among other capabilities, this involves the ability to identify/speaker relationships by analyzing the semantic meanings of conversations between different users \u2013 this is widely known as the Relation Extraction (RE) problem. Solving such a problem has become a critical task in Natural Language Processing, and it plays an essential role in downstream tasks.\\n\\nIn the past decades, the RE problem in language processing has received considerable attention in computational linguistics. On the one hand, there is work that only addresses the relation extraction problem on the document level. Some datasets focus on the RE problem between two entities in one sentence, such as the SemEval-2010 Task 8 dataset (Hendrickx et al., 2010) and the TACRED dataset (Zhang et al., 2017). And some datasets focus on the cross-sentence relationships, i.e. two entities whose relationship need to be determined are not in the same sentence or even the same paragraph, such as BC5CDR (Li et al., 2016) and DocRED (Yao et al., 2019). Furthermore, different to the formal document, some RE datasets focus on annotating dialogues. There are much more complicated connections between different speakers in a dialogue, especially with more than two participants. The relationship in the dialogue is more character-related, and a complete dialogue exists between different speakers. In addition to many cross-sentence relationships, there is also a large amount of omission and co-reference information in the dialogue. So, researchers published some datasets for dialogue-based relation extraction tasks.\\n\\nChen et al. (2020b) published a multi-party dialogue dataset, called MPDD, for analysing emotions and interpersonal relationships based on the dialogue in five different TV series scripts. MPDD only focus on the relationship between speaker and listener. Yu et al. (2020) constructed a multi-party dialogue relationship extraction dataset DialogRE based on the English script - Friends. Moreover, they also published a Chinese version of the same dataset using machine translation technology, but it cannot represent practical daily conversations between Chinese native speakers. The statistical analysis of the \\\"Friends\\\" (Chinese episode) and \\\"I Love My Family\\\" (Chinese episode) shows that there are differences between them in terms of the number of characters, the number of character relationships, and the number of dialogue rounds in each episode. Therefore, the DialogRE dataset's Chi-\"}"}
{"id": "lrec-2022-1-250", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"nese version cannot cover all features/phenomena in Chinese multi-party dialogue. Furthermore, the character relationship schema defined by DialogRE is not suited for \\\"I Love My Family\\\". In this paper, we present a new dialogue data set - the CRECIL corpus constructed from the authentic TV scripts of a Chinese sitcom - I Love My Family - labelled using an inter-agreed annotation scheme, for the task of dialogue-based character relationship extraction. Different to the DialogRE, which directly annotates the relationship between two arguments, our corpus annotates the global character relationships between two character entities and the referential relationships between a reference in the utterance and the character entity. We, then, automatically generate the character relationship triples by fusing the relationships of each episode, as mentioned earlier. We carry out a data experiment by investigating the performance of a BERT-based model (as baseline) (proposed by (Yu et al., 2020)) on this dialogue dataset. The result shows that the extraction of relationships in CRECIL is more challenging than DialogRE's English version.\\n\\n2. Data annotation method on Multi-party Dialogue\\n\\nThis section describes our data annotation method and process, including the inter-agreed annotation scheme and character relationship triples generation.\\n\\nThe corpus is extracted from the original TV scripts of a Chinese sitcom called \\\"I Love My Family\\\" which contains a total of 120 episodes and 679 scenes. It is not annotated directly on audio data, and the data is also not naturally occurring real-world speech but rather television scripts.\\n\\n2.1. Cleaning up the data for Annotation\\n\\nTo annotate character relationships between speakers within the conversation in the scene, we cleaned up the original scripts as follows: 1) removing useless narrations, transitions, and text descriptions and 2) retaining only the content of the dialogue. (see dialogue example in Table 1).\\n\\n2.2. Annotation Scheme\\n\\nIn order to reach a new corpus with high quality but less labelling cost, we, in this paper, apply a simple annotation method for labelling both...\"}"}
{"id": "lrec-2022-1-250", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Chinese multi-party dialogue character relationship types\\n\\nname will depend on how he/she is mentioned the first time in the script. Otherwise, the node's name will be the speaker's name of the same character.\\n\\n\u2022 The character's name referring to the same character entity will be consistent for both the global character relationship labelling and the referential relationship labelling (see sec 2.2.2).\\n\\n\u2022 All the relationships between each pair of character entities should be annotated. We also need to tag the time stamp when such relationships appear for the first time because the relationship between two character entities could change over time.\\n\\n\u2022 When more than one name refers to the same character entity, their relationship will be alternate_name.\\n\\n\u2022 Relationship types that are not obvious or cannot be answered would not be annotated.\"}"}
{"id": "lrec-2022-1-250", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2.2.2. Annotation of the referential relationships\\n\\nWe also annotated two kinds of referential relationships (see the schematic diagram in Figure 2).\\n\\nOne referential relationship is between different pronouns (referents) in the utterance and the corresponding character entities in the conversation. The other referential relationship is between the speakers and the corresponding character entities. The referential relationship triples (RRT) is defined as $$(a', a, p)$$, where $$a'$$ is the pronouns (referents) in the utterance $$u_i$$ ($$a' \\\\in u_i$$ or the speaker), $$a$$ is the character entity's name referred to by $$a'$$ and $$p$$ represents the position index where $$a'$$ is located in $$u_i$$. (see an example of \u2018(\u03e1,\u0849\u11bd\u0753,0)\u2019 in Figure 2)\\n\\nHere, we also define and employ the annotation rules as follows:\\n\\n- If the reference to a character entity is a single word or the entity's name, create an RRT for it.\\n- If the reference to a character entity has some attribute, creating an RRT for the reference and the attributive modification together.\\n- Create an RRT for the character's nickname.\\n- When there is a pronoun before or after a reference, and they refer to the same character entity, creating an RRT only for the reference itself.\\n\\n2.2.3. Dialogue-based CRT Generation\\n\\n- Given that $$p_i$$ denote one speaker or reference to a character entity in the current scene (dialogue), if the relationship $$r$$ between $$p_i$$ and $$p_j$$ can be found in the global CRTs, we will set their relationship as $$r$$, otherwise set as 'unanswerable'.\\n- Given the same dialogue, we only keep a unique relationship triple between $$p_i$$ and $$p_j$$.\\n\\nFigure 3 presents an example of dialogue-based CRTs were generated from one of the conversations in the CRECIL corpus.\\n\\n| Average turns length(in tokens) | 23.8 |\\n|-------------------------------|------|\\n| Average dialogue length(in tokens) | 707.6 |\\n| Average # of turns | 29.7 |\\n| Average # of speakers | 4.1 |\\n| Average # of sentences | 39.4 |\\n| Average # of relational instances | 57.4 |\\n| Average # of no-relational instances | 21.6 |\\n\\nTable 3: Statistics per dialogue of CRECIL\\n\\n3. Comparison between CRECIL and DialogRE\\n\\nWe investigate the similarities and differences between our CRECIL and the DialogRE corpus.\\n\\n3.1. Statistics and Analysis of Corpus\\n\\nGiven the scripts of the \u201cI Love My Family\u201d Chinese sitcom, we have gathered 679 dialogues (each about one scene), with a total of 20,183 turns. Table 3 shows the distribution of dialogue length (i.e. the number of turns) in the CRECIL corpus, where the average number of turns per dialogue is 29.7 (which is significantly longer than English data in DialogRE (12.9 turns on average)). More speakers participated in a single conversation in CRECIL (4.1 speakers per dialogue on average) than those in DialogRE (3.3 speakers per dialogue on average). We show the distribution of multi-party conversations in CRECIL and DialogRE in Figure 4. The more multi-party dialogue occurs in the data, the more challenging the system can extract accurate character relationship triples.\\n\\n3.2. Statistics and Analysis of Relation Types\\n\\nWe have identified 30 character relationship types as mentioned in table 2. Using the above annotation scheme, we have finally labeled 121 character entities with 501 global CRTs across those categories (see the distribution of global CRTs across those categories in Figure 5). We have also annotated a total of 8282 RRTs. Based on the global CRTs and RRTs, we have generated over 53,646 dialogue-based CRTs (which is directly annotated in DialogRE), which are more than the ones in DialogRE (only 10,168 in the English version and 11,365 in the Chinese-translated version). Table 4 shows the number of ways to address each character in CRECIL and DialogRE respectively.\\n\\nEach character in the CRECIL corpus has about 71.83 different names/referents on average, significantly more than in the DialogRE corpus (only 19.67 per character on average). On the other hand, the top three of thesese categories in global character relationships (excluding unanswerable)\\n\\n| Character Name | number |\\n|----------------|--------|\\n| Fu Ming | 102 |\\n| Jia Zhiguo | 92 |\\n| Jia Zhixin | 81 |\\n| Chandler Bing | 31 |\\n| Ross Geller | 29 |\\n| Joey Tribiani | 20 |\\n| He Ping | 74 |\\n| Rachel Karen Green-Geller | 17 |\\n| Monica Geller | 13 |\\n| Phoebe | 8 |\\n\\nTable 4: Comparison between CRECIL and DialogRE on Character Referents\"}"}
{"id": "lrec-2022-1-250", "page_num": 5, "content": "{\"primary_language\":\"zh\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u7238\u7238\uff0c\u52a8\u753b\u7247\u5728\u54ea\u9891\u9053\u554a\uff1f\\n\\n\u770b\u54ea\u95e8\u5b50\u52a8\u753b\u7247\u5440\uff01\\n\\nDon't watch cartoons\u2014watch series.\\n\\n\u5c0f\u5f20\uff0c\u4f60\u7684\u83dc\u53ef\u54b8\u70b9\u513f\u554a\uff01\\n\\nBrother, you dominate the chicken thighs, can you eat it by yourself, can you not be salty? I only see it once a week!\\n\\n\u54ce\u54ce\u54ce\uff0c\u54b1\u7238\u4eca\u5929\u662f\u600e\u4e48\u56de\u4e8b\uff1f\u4ece\u5355\u4f4d\u4e00\u56de\u6765\u5c31\u6253\u852b\u513f\uff0c\u996d\u90fd\u4e0d\u5403\u5c31\u697c\u5e95\u4e0b\u6e9c\u8fbe\u53bb\u4e86\u3002\\n\\nHey, what's the matter with my dad today? As soon as he came back from the unit, he was listless, and he wandered downstairs without eating.\\n\\nFigure 2: Schematic diagram of referential relationship labelling in the CRECIL corpus\\n\\nAlgorithm 1 Generating the dialogue based CRTs\\n\\n1: function generate-dCRT(D, gCRTs, dRRTs)\\n\\n2: Input: dialogue D, global CRTs gCRTs, dialogue RRTs dRRTs\\n\\n3: Output: dialogue CRTs dCRTs\\n\\n4: Initiated the set of speakers S and references M\\n\\n5: $S = \\\\text{get speakers From dialogue}(D)$\\n\\n6: $M = \\\\text{get references from dialogue}(D)$\\n\\n7: Remove duplication $P = \\\\text{Set}(S + M)$\\n\\n8: $dCRTs = \\\\{ (a_1, a_2, r) | a_1 \\\\in P \\\\& a_2 \\\\in P \\\\& a_1 \\\\neq a_2 \\\\& r = \\\\text{'}unanswerable\\\\text{'} \\\\}$\\n\\n9: Update dCRTs with gCRTs\\n\\n10: for dcr in dCRTs do\\n\\n11: for drrt in dRRTs do\\n\\n12: if dcr.a_1 == drrt.a then\\n\\n13: $a_1 = drrt.a$\\n\\n14: end if\\n\\n15: if dcr.a_2 == drrt.a then\\n\\n16: $a_2 = drrt.a$\\n\\n17: end if\\n\\n18: end for\\n\\n19: dcr.r = gcrt.r where gcrt.a_1 = a_1 \\\\& gcrt.a_2 = a_2\\n\\n20: end for\\n\\n21: Return dCRTs\\n\\n22: end function\\n\\nswerable) are 'neighbours' (with 97 global CRTs), 'friends' (with 58 global CRTs) and 'acquaintances' (with 34 global CRTs), which overall account for 37.7% of the total. (see more details in Figure 5).\\n\\nFigure 6 shows the distribution of dialogue-based CRTs across different relationship types (excluding unanswerable) in the CRECIL and DialogRE corpus. 'alternate name' (around 6700 samples) and 'neighbour' (about 5400 samples) are significantly more than other categories. Such imbalanced data sample distribution also happens in the DialogRE corpus. For example, the relationship type of 'alternate name' (containing around 2150 samples in the English corpus and about 3400 samples in the Chinese-translated one) occurs more frequently than the ones in 'girl/boyfriend', 'positive' and 'friend' separately (around 800 only).\"}"}
{"id": "lrec-2022-1-250", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In order to demonstrate how the CRECIL corpus can be used, we deployed one of the existing approaches (BERT model) from Yu et al. (2020) to extract dialogue-based character relations. We follow the previous task and standard experiment settings (see (Yu et al., 2020)) to compare the overall performance and the performance of specific relationship types separately.\\n\\nUnlike previous work, this will compare the overall performance and the performance of specific relationship types separately.\\n\\n4.1. Experiment Task Formulation\\n\\nFollowing the previous work (Yu et al., 2020; Chen et al., 2020a), we, here, redefine the dialogue-based character relation extraction (DCRE) task. Given a dialogue $D = (s_1, u_1), (s_2, u_2), \\\\ldots, (s_n, u_n)$ and also a pair of arguments $(a_1, a_2)$, where $n$ represents the total number of utterances, and $s_i$ denote the speaker name of utterance $u_i$. The task aims at employing an appropriate approach to identify/extract the relationship between $a_1$ and $a_2$ that appears in the dialogue (see more details of 'standard' experiment settings in (Yu et al., 2020)).\\n\\nSince such a task can be viewed as a simple multi-classification task, we employ the Macro-F1 score ($F_1$), which is the harmonic mean of precision ($P$) and recall ($R$), for evaluation.\\n\\n4.2. Model\\n\\nThis paper adopts a Bert-based extraction model proposed by Yu et al. (2020) as a baseline model. The baseline employs a pre-trained language model BERT. We deploy this model on our CRECIL corpus, and the DialogRE (Yu et al., 2020) in both English and Chinese versions. The model's input...\"}"}
{"id": "lrec-2022-1-250", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Global Character Relationships distribution in the CRECIL corpus consists of a dialogue and a character entity pair to be recognized. The input to BERT has the format: \\\\( \\\\text{[CLS]}D\\\\text{[SEP]}a_1\\\\text{[SEP]}a_2\\\\text{[SEP]}\\\\). The output of the BERT encoding layer contains \\\\( \\\\text{[CLS]}\\\\), which encodes the entire dialogue and the argument pair to be recognized. We then feed the embeddings of \\\\( \\\\text{[CLS]}\\\\) into the LINEAR layer to predict the results of the relationship between \\\\( a_1 \\\\) and \\\\( a_2 \\\\).\\n\\nWe employed the chinese_wwm_ext as the pre-trained BERT model, and the hidden layer dimension is 768. The maximum length of the dialogue is 512, and the number of gradient accumulation steps is 2. The batch size is 24, the optimizer is Adam, and the learning rate is 3e-5. The epoch is 20. The loss function is cross-entropy.\\n\\n4.3. Results and Discussion\\n\\nThe F1 score for each relation type using the base-line BERT model on the newly created corpus is shown in Table 5. The result indicates the type of 'alternative name' (54.9% in the dev set, 55.7% in the test set) and 'neighbour' (64.2% in the dev set, 60.0% in the test set) have shown better performance than the other categories. This is because of imbalanced data across different relation types. Both 'alternative name' and 'neighbour' contain 6726 and 5464 examples respectively in CRECIL, which is almost as double as the others (see Figure 7) (https://github.com/ymcui/Chinese-BERT-wwm).\\n\\n| Relation Type | Dev  | Test  |\\n|---------------|------|-------|\\n| 'alternative name' | 54.9% | 55.7% |\\n| 'neighbour' | 64.2% | 60.0% |\\n| 'children' | 50.0% | 47.1% |\\n| 'parents' | 48.5% | 48.6% |\\n| 'others' | 51.4% | 46.2% |\\n\\nTable 5: Comparison between different categories (excluding the 'unanswerable' type)\\n\\nTable 6 shows the macro-F1 scores for each version of the DialogRE corpus (English vs Chinese) and our CRECIL corpus using the same baseline model. The model predicting argument relationship in DialogRE (F1-scores 59.4% in the development set and 57.9% in the test set) shows significantly better overall performance than the CRECIL data set (56.8% in the development set and 54.4% in the test set). This might be because compared with \\\"Friends\\\", 1) the dialogue in the Chinese episode \\\"I Love My Family\\\" is longer and more complex with multiple characters, and 2) there are more alternative referents in this Chinese script.\\n\\n| Corpus      | Dev  | Test  |\\n|-------------|------|-------|\\n| EN-DialogRE | 59.4% | 57.9% |\\n| CN-DialogRE | 63.7% | 63.2% |\\n| CRECIL      | 56.8% | 54.4% |\\n\\nTable 6: Comparison between the CRECIL corpus and the DialogRE corpus (%)\"}"}
{"id": "lrec-2022-1-250", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Relationship type distribution in CRECIL and DialogRE corpus (only present the top 4 relationship types per corpus, excluding the unanswerable type)\\n\\n5. Conclusion\\nWe presented a new dialogue-based relation extraction corpus (CRECIL) for multi-party conversations in Chinese. We introduced the Chinese-oriented character relationship categories and labelling rules for annotating the corpus. We also investigate the performance of a BERT-based extraction method on both CRECIL and another existing English TV-episode corpus (DialogRE). The results demonstrate that extracting character relationships is more challenging in CRECIL than in DialogRE.\\n\\nOngoing work further uses the data to explore the character relationship characteristics of Chinese multi-party dialogues and build a better-performance character relationship extraction model.\\n\\n6. Acknowledgement\\nThis work is supported by the National Natural Science Foundation of China (Grant No.61602044) and the funds for improving the quality of personnel training in 2021 of Beijing Information Science and Technology University (Grant No.5102110805).\\n\\n7. Bibliographical References\\nChen, H., Hong, P., Han, W., Majumder, N., and Poria, S. (2020a). Dialogue relation extraction with document-level heterogeneous graph attention networks. CoRR, abs/2009.05092.\\n\\nChen, Y.-T., Huang, H.-H., and Chen, H.-H. (2020b). Mpdd: A multi-party dialogue dataset for analysis of emotions and interpersonal relationships. In Proceedings of the 12th Language Resources and Evaluation Conference, pages 610\u2013614.\\n\\nHendrickx, I., Kim, S. N., Kozareva, Z., Nakov, P., \u00d3 S\u00e9aghdha, D., Pad\u00f3, S., Pennacchiotti, M., Romano, L., and Szpakowicz, S. (2010). SemEval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 33\u201338, Uppsala, Sweden, July. Association for Computational Linguistics.\\n\\nLi, J., Sun, Y., Johnson, R. J., Sciaky, D., Wei, C.-H., Leaman, R., Davis, A. P., Mattingly, C. J., Wiegers, T. C., and Lu, Z. (2016). Biocreative v cdr task corpus: a resource for chemical disease relation extraction. Database, 2016.\\n\\nYao, Y., Ye, D., Li, P., Han, X., Lin, Y., Liu, Z., Liu, Z., Huang, L., Zhou, J., and Sun, M. (2019). Docred: A large-scale document-level relation extraction dataset. arXiv preprint arXiv:1906.06127.\\n\\nYu, D., Sun, K., Cardie, C., and Yu, D. (2020). Dialogue-based relation extraction. arXiv preprint arXiv:2004.08056.\\n\\nZhang, Y., Zhong, V., Chen, D., Angeli, G., and Manning, C. D. (2017). Position-aware attention and supervised data improve slot filling. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017), pages 35\u201345.\"}"}
