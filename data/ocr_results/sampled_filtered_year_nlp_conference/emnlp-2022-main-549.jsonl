{"id": "emnlp-2022-main-549", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"black folks are very dangerous.\\n\\nWhy do you say that? Do you have any sources for this? I would appreciate it if you would provide such a source.\\n\\nWhy is this even a thing. Is there any source for this. If you could provide such source, I would appreciate it.\\n\\nIs this even a thing? Is there any source for this? If you could provide such source, I would appreciate it.\\n\\nBlacks are criminals, that's just who they are. They are a threat to society.\\n\\nSuch statements are just fear-mongering. There is no such thing as a criminal race.\\n\\nThis is a fearmongering statement. Criminal races don't exist.\\n\\nReally? Because blacks are a plague on society. They are vicious and cruel. They steal and corrupt the criminal justice system. They are basically just a bunch of thieves and murderers.\\n\\nCriminality and corruption are not the province of any specific racial or culture group.\\n\\nYou still haven't convinced me that black people aren't the source of crime in our society.\\n\\nIt is not true that blacks are the source of crime in our society. The problem is violence and poverty, not race.\\n\\nThat blacks are the source of crime in our society is simply not true. We need to search the problem in violence and poverty, not race.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The problem with Islam is that it is about killing infidels. It must be banned.\\n\\nIslam is about love, not death.\\n\\nIt is also about conquest and murder. I can't understand why anybody would want to murder infidels.\\n\\nThis is about human dignity and respect for people's rights. To murder infidels would be to remove human dignity and human respect. Since Islam cares for human rights and human dignity, I can assure you that it doesn't happen.\\n\\nIslam is an outdated and violent religion, which is incompatible with Western culture.\\n\\nAre you sure? Islam is an outdated and violent religion, which is incompatible with Western culture.\\n\\nIt is not incompatible with Western culture, but Islam is a dead cult and should be eliminated. Islam has existed in Europe for centuries and is part of our culture.\\n\\nIslam is a religion, and it is not a dead cult. It is not only about killing people, but also about love and peace.\\n\\nIslam is a totalitarian ideology that promotes rape, torture, and murder. I don't want it in my country!\\n\\nIslam is a totalitarian ideology that promotes rape, torture, and murder.\\n\\nIslam is a religion, not a totalitarian ideology. It is not about killing people, only about love and peace, so it has the same values as our country.\\n\\nIslam is a totalitarian ideology that promotes rape, torture, and murder.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Women are nothing but objects, unworthy of respect and protection.\\n\\nWomen are human beings, they deserve respect and protection. Like all human beings.\\n\\nWomen are animals too, they need to be protected.\\n\\nNo, they're nothing but objects to be exploited for.\\n\\nWomen are human beings with human rights and that includes the right to life.\\n\\nYou should check the Universal Declaration of Human Rights, especially the section where it says that men and women have the same rights.\\n\\nWell, women don't deserve human rights, they are parasitic and steal our jobs.\\n\\nWomen often work hard for themselves, but they do not have to steal their jobs, it's because of their gender.\\n\\nWomen work hard for themselves and their families, they don't steal jobs but simply apply for the ones they want, like it's in their right.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering\\n\\nHelena Bonaldi 1,3, Sara Dellantonio 2,3, Serra Sinem Tekiro\u02d8glu 3, Marco Guerini 3\\n\\n1 University of Trento, Italy\\n2 Free University of Bozen-Bolzano, Italy\\n3 Fondazione Bruno Kessler, Via Sommarive 18, Povo, Trento, Italy\\n\\nhbonaldi@fbk.eu, sdellantonio@fbk.eu, tekiroglu@fbk.eu, guerini@fbk.eu\\n\\nAbstract\\nFighting online hate speech is a challenge that is usually addressed using Natural Language Processing via automatic detection and removal of hate content. Besides this approach, counter narratives have emerged as an effective tool employed by NGOs to respond to online hate on social media platforms. For this reason, Natural Language Generation is currently being studied as a way to automatize counter narrative writing. However, the existing resources necessary to train NLG models are limited to 2-turn interactions (a hate speech and a counter narrative as response), while in real life, interactions can consist of multiple turns. In this paper, we present a hybrid approach for dialogical data collection, which combines the intervention of human expert annotators over machine generated dialogues obtained using 19 different configurations. The result of this work is DIALOCONAN, the first dataset comprising over 3000 fictitious multi-turn dialogues between a hater and an NGO operator, covering 6 targets of hate.\\n\\n1 Introduction\\nWhile hate towards vulnerable groups or individuals is not a new phenomenon, the upsurge of hate speech and its proliferation is relatively recent and it is enabled by the fast spread of information in online platforms. The rise in hate speech online can even provoke violent actions offline. Consequently, fighting online Hate Speech (HS) has become a vitally important \u201cjob for everyone\u201d especially for the NLP researchers. The contrast to HS and haters on social media platforms is usually carried on via user suspension, content removal or shadow banning, which can be mapped to a classification task in NLP terms. However, AI and NLP can play even a more crucial role that is not limited to classification. In fact, recently, NLG models have started to be proposed as an effective tool to counter HS by providing relevant responses. In particular, the idea is to imitate the operators of Non-Governmental Organizations (NGO) that are actually intervening in online discussions by replying to hateful content using so-called Counter Narratives (CN), defined by Schieb and Preuss (2016) as \u201ccommunicative actions aimed at refuting hate speech through thoughtful and cogent reasons, and true and fact-bound arguments\u201d. Through automatically generating CNs, it is possible to aid NGO operators in their day-to-day manual activities, and therefore to partially countervail the sheer amount of hateful content posted online (Chung et al., 2021b).\\n\\nDespite the invaluable attempts to create HS/CN...\"}"}
{"id": "emnlp-2022-main-549", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"datasets and systems (Mathew et al., 2019; Qian et al., 2019; Chung et al., 2019; Fanton et al., 2021), up to now only datasets containing 2-turn interactions have been proposed (i.e. a hate speech and a responding counter narrative), while in real scenarios, such as on social media platforms, multi-turn dialogues are the norm. In Figure 1 an example of such dialogues is provided. Therefore, multi-turn dialogue datasets are necessary for training models that can better handle online hate phenomenon.\\n\\nStill, obtaining expert-written quality data to train such models on is not trivial. To ameliorate this problem, a recently proposed approach is the use of hybrid data collection strategies where a human and a machine collaborate to build data starting from a seed dataset of expert-based examples (Fanton et al., 2021). In this paper we follow this line of research and investigate novel strategies and algorithms that are specifically designed for multi-turn dialogues collection.\\n\\nIn particular, we test 19 different hybrid strategies obtaining a novel dataset of more than 3K dialogical interactions between two interlocutors, one acting as the hater and the other as the NGO operator, for a total of more than 16K turns. We call this dataset DIALOCONAN (DIALOGical COunter-NArratives collectioN). This is the first and most comprehensive multi-target dataset that addresses expert-based counter narrative generation in fully dialogical scenarios, and it can be downloaded at the following link: https://github.com/marcoguerini/CONAN.\\n\\nRelated Work\\nIn this work, we consider four main research areas as relevant: in particular (i) available datasets for hate speech detection, (ii) available datasets for CN generation, (iii) CN generation approaches, and (iv) hybrid data collection methodologies.\\n\\nHate detection. Many benchmarks for automatic HS detection are currently available (Mathew et al., 2019; Cao et al., 2020; Kumar et al., 2018; Hosseinmardi et al., 2015; Waseem, 2016; Burnap and Williams, 2016). Regarding the systems built on top of these benchmarks, we refer the readers to the surveys by Poletto et al. (2020); Schmidt and Wiegand (2017); Fortuna and Nunes (2018) for detailed reviews. Other reviews include the analysis of ethical implications (Kiritchenko et al., 2021) and of problems such as bias replication (Binns et al., 2017; Davidson et al., 2019; Vidgen and Derczynski, 2020; Sap et al., 2019; Tsvetkov, 2020).\\n\\nCN data collection. Since CNs have been shown to be effective in reducing linguistic violence (Benesch, 2014; Gagliardone et al., 2015; Schieb and Preuss, 2016; Silverman et al., 2016; Mathew et al., 2019) and in changing the viewpoints of bystanders (Allison and Bussey, 2016; Anderson et al., 2014), they are beginning to be collected as training data for supervised NLG models. The investigated approaches for data collection can be listed as crawling (Mathew et al., 2018, 2019; Yu et al., 2022), crowdsourcing (Qian et al., 2019), nichesourcing (Chung et al., 2019) and hybrid approaches (Tekiro\u02d8glu et al., 2020; Fanton et al., 2021).\\n\\nThe most relevant datasets for our work are (i) Fanton et al. (2021) in terms of quality and target diversity, even if it only includes HS/CN pairs, and (ii) Qian et al. (2019) that hints at the issue of multi-turn dialogues. However, in the latter the CN is only the last turn of a forum-style dialogue among more than 2 interlocutors, rather than a HS/CN multi-turn dialogue between two opposing actors.\\n\\nCN generation. Neural approaches to generate CNs have started to be studied along with available datasets (Fanton et al., 2021; Tekiro\u02d8glu et al., 2020; Qian et al., 2019). Tekiroglu et al. (2022) present a thorough comparison of several pre-trained LMs for this task. Zhu and Bhat (2021) propose an entirely automated 2 stage pipeline where several CN candidates are generated and then filtered. Other lines of work include CN generation for under-resourced languages (Chung et al., 2020), or the generation of knowledge-bound CNs, to avoid hallucination phenomena (Chung et al., 2021a). Finally, Ashida and Komachi (2022) studied CN generation with LLMs, using few-shots prompting.\\n\\nHybrid models for data collection. A recently emerged data collection methodology is based on hybrid models, where humans and machines work together to collect better quality data in a more efficient way. Wallace et al. (2019) propose using model output to guide humans in the writing of adversarial examples for question-answering systems. Dinan et al. (2019) and Vidgen et al. (2020) perform a data collection for offensive language detection with repeated model-human interactions where the classifier output drives annotators in ex-\"}"}
{"id": "emnlp-2022-main-549", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ample creation at each round. A more recent study proposes a hybrid approach where an LM is trained to generate HS/CN pairs that are validated and post-edited by annotators (Tekiro\u02d8glu et al., 2020). Fan-\\nton et al. (2021) further expand this approach by making it iterative using several LM configurations.\\n\\n3 Methodology\\n\\nData collection can be very difficult and time con-\\nsuming when high quality data from experts are\\nnecessary. Given that we need to collect whole\\nHS/CN dialogues and not just pairs, the problem is\\neven harder. Moreover, scraping NGO operators'\\nreal interactions is not a viable solution, consider-\\ning that this data can be used for account \\\"doxing\\\".\\nIn fact, malicious users could reverse-search the\\n\\ntext included in a dataset to identify the operators'\\naccounts. This would undermine their work, since\\nthey usually operate undercover, and would expose\\nthem to possible attacks.\\n\\nTherefore, we decided to resort to hybrid\\napproaches and run 3 different data collection ses-\\nsions based on the aspects of the dialogue augmen-\\ntation we want to address (either the structure, in\\nterms of turns order, or the wording of the turns).\\nIn total we tested 19 different dialogue collec-\\ntion strategies. All the strategies are inserted in an\\nauthor-reviewer pipeline as described by Tekiro\u02d8glu\\net al. (2020), where the author is a single dialogue\\ncreation strategy at a time, and the reviewer is rep-\\nresented by a team of trained annotators, who are\\ntasked with post-editing the dialogues generated by\\nthe given author strategy.\\n\\nAuthor - Configurations.\\n\\nEach of the 3 data col-\\ncollection sessions we perform has different input data\\nand author tasks, in particular:\\n\u2022 Session 1: same wording, new dialogue struc-\\n\\n\u2022 Session 2: new wording, same dialogue struc-\\n\\n\u2022 Session 3: new wording, new dialogue struc-\\n\\nAuthor - Seed datasets.\\n\\nSince each author con-\\nfiguration needs some textual input, we employ (i)\\na dataset, created ad hoc, consisting of 222 ficti-\\ntional dialogues and (ii) HS/CN pairs coming from\\nthe dataset presented in Fanton et al. (2021).\\nThe ad hoc fictitious dialogues (DIALO\\n\\nhenceforth) are written by two expert NGO op-\\nerators, who have been working for over 10 years\\nin writing CNs on social media platforms. They\\nwere asked to write dialogues between a hypotheti-\\ncal hater and an NGO operator, following their real\\nexpertise in the task. The dialogues can have 4,\\n6, or 8 turns (these are typical lengths according\\nto their experience) and cover the following 6 tar-\\ngets of hate, defined beforehand:\\nLGBT+, MIGRANTS, MUSLIMS, JEWS, POC and WOMEN.\\n\\nGiven the small size of DIALO\\ngold, we also use\\npart of the dataset presented in Fanton et al. (2021)\\nas an additional resource. This dataset consists of\\n5000 HS/CN pairs covering, among others, the 6\\ntargets of hate present in DIALO\\ngold. Therefore,\\nwe extracted the pairs labeled with these 6 targets\\nso that the two resources can be 'aligned' by topic,\\nand we named it PAIRS\\ngold, since also this dataset\\nwas created with the help of expert NGO operators.\\n\\nReviewers - Training.\\n\\nFor post-editing the out-\\nput of the various author configurations, three an-\\notators were recruited from a pool of internship\\nstudents. They have been extensively trained using\\nthe methodology of Fanton et al. (2021), in order to\\nbecome \\\"experts\\\" on HS/CN post-editing. In par-\\nticularly, we first explained the aim of the task. Then,\\nthey had to read NGO guidelines and documenta-\\ntion on CN writing\\n3, together with all the dialogues\\npresent in DIALO\\ngold, which were provided as ex-\\namples of the material they would have to work\\nwith. We detailed the methodology, explaining that\\nthe main focus was to make the dialogues natural,\\nwith the minimum intervention possible and keep-\\ning the seed dataset as a reference for naturalness.\\nGeneral instructions about the post-editing proce-\\ndure were also provided, pointing out that for each\\nsession specific guidelines would have been given.\\n\\nReviewers - Mitigation procedure.\\n\\nFinally, we also implemented a mitigation procedure similar to\\nthe one presented by Vidgen et al. (2019). This pro-\\nprocedure is implemented to safeguard the annotators'\\nwell-being while working with abusive content and\\nincludes: (i) explaining to the annotators the pro-\\nsocial nature of the research and the purpose of\\n3See https://getthetrollsout.org/stoppinghate\\nas a reference.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"their post-editing activity, (ii) advising the annotators to work few hours per day and to take regular breaks (iii) having weekly meetings to let possible problems or distress emerge.\\n\\nData collection procedure.\\n\\nFor each session we applied the following procedure: (i) generate dialogue candidates according to session specific strategies, (ii) adapt the annotation guidelines to the specific session, (iii) let the annotators practice the task on a small \u201ctraining\u201d set of dialogue candidates, and (iv) update the guidelines with respect to their feedback. Lastly, (iv) annotators complete the post-editing on the remaining dialogues following the updated guidelines (the order of the dialogues was randomized to avoid comparison or primacy/recency effects over session strategies).\\n\\n4 Metrics\\n\\nWe use several metrics to assess the performance of each strategy. These metrics are aimed to assess either the efficiency of the procedure or the quality of the obtained data.\\n\\n**HTER**\\n\\nis an efficiency metric used to measure the post-editing effort of the annotator, and it is usually employed for sentence level translations (Specia and Farzindar, 2010). A value above 0.4 is generally used to account for low quality outputs, where rewriting from scratch is on par with correcting it (Turchi et al., 2013).\\n\\n**Turn deletion**\\n\\nis the percentage of turns that are discarded by the reviewers since their quality is too low and/or they do not fit in the current dialogue structure. The more content needs to be deleted, the less efficient the procedure is.\\n\\n**Turns swap**\\n\\nis the percentage of turns that are moved by the reviewers from the original position they were in, to another position in the final edited dialogue. Usually turns of this kind have a good quality but they do not fit the current position.\\n\\n**Novelty**\\n\\nis utilized to check the quality of a generated dialogue by measuring its lexical difference with respect to a reference set of dialogues, and it is grounded on Jaccard similarity (Dziri et al., 2019; Wang and Wan, 2018).\\n\\n**Repetition Rate** (RR)\\n\\nmeasures the language diversity within a corpus using the rate of non-singleton ngram types (Cettolo et al., 2014; Bertoldi et al., 2013). It is used in our experiments to evaluate each strategy in terms of its ability to provide diverse and varied examples.\\n\\n5 Session 1: Dialogue structure\\n\\nIn Session 1 we started from the HS/CN pairs in PAIRS $^\\\\text{gold}$ and concatenated them in order to produce dialogue candidates with different structures.\\n\\n5.1 Author Strategies\\n\\nWe employ 7 strategies to connect HS/CN pairs from PAIRS $^\\\\text{gold}$ to create 4, 6, and 8 turns examples (consistently with the DIALO$^\\\\text{gold}$ characteristics).\\n\\nDuring the concatenation, each pair is used only once in a dialogue. The connection strategies are: random concatenation (1 strategy), similarity concatenation (4 strategies), and keyword matching concatenation (2 strategies). In order to obtain a balanced dataset, for each strategy, each target, and each dialogue length combination we created 10 connected dialogues. In-detail descriptions of the 7 concatenation strategies we utilized are as follows:\\n\\n**Random connection.**\\n\\nFor the random connection (RND), the selected pairs for each target are randomly concatenated to form dialogues. This strategy represents a baseline to which we compare against while analysing the other strategies.\\n\\n**Similarity connection.**\\n\\nTo connect pairs depending on their similarity, we utilize (i) the Jaccard similarity and (ii) the cosine similarity. Both for the Jaccard and cosine similarity, we perform pair matching via two approaches to form the HS$_i$, CN$_i$, HS$_{i+1}$, CN$_{i+1}$ concatenation:\\n\\n1. **SIM$_{HS-HS}$** = the similarity between HS$_i$ and HS$_{i+1}$;\\n2. **SIM$_{CN-HS}$** = the similarity between CN$_i$ and HS$_{i+1}$.\\n\\nFor each pair, we randomly select 1 among the 10 most similar pairs according to the chosen similarity (either Jaccard or cosine) and concatenation elements (either HS-HS or CN-HS). The procedure is repeated until the desired number of turns for each dialogue is reached.\\n\\n**Keywords connection.**\\n\\nWe employ the YAKE keyword extractor (Campos et al., 2020) to extract two keywords from each HS and CN of PAIRS $^\\\\text{gold}$ and perform a concatenation similar to the previous strategies. We connect HS$_i$, CN$_i$ and HS$_{i+1}$, CN$_{i+1}$ according to the following criteria:\\n\\n4 Cosine Similarity is computed on their embeddings obtained with mpnet-base. The Sentence Transformer library (https://www.sbert.net/) has been employed.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Results for the first session. J-SIM and C-SIM are the connections via Jaccard and cosine similarity, respectively. RR\\n\\\\textit{gen} and RR\\\\textit{red} are respectively the RR of the data before and after post-editing, while NOV\\\\textit{g-e} and NOV\\\\textit{g-g} are the novelty of the data before and after post-editing with respect to DIALO\\\\textit{gold}.\\n\\n1. KW\\\\textit{HS-HS} = if \\\\(HS_i\\\\) and \\\\(HS_{i+1}\\\\) share two keywords; 2. KW\\\\textit{CN-HS} = if \\\\(CN_i\\\\) and \\\\(HS_{i+1}\\\\) share two keywords; We decided on a 2-keywords match since according to our preliminary manual analysis we found that the first keyword is often target-related; by considering two keywords we aim to include also a topic-related keyword.\\n\\nAs a final note, we should highlight that the two groups of connection strategies (HS-HS and CN-HS) represent either (i) a \\\\textit{global} semantic coherence across turns (all HS being similar) or (ii) a \\\\textit{local} semantic coherence (only CN-HS of adjacent turns being similar) both for SIM and KW. By using a \\\\textit{global} semantic coherence via HS-HS matching we attempted to simulate the attitude of the hater which is convinced of their own ideas and do not accept any external input, while with the \\\\textit{local} connections, we aimed to recreate a \\\"linguistic alignment\\\" phenomenon (Doyle and Frank, 2016). Details on the matching procedures and the description of the algorithms for SIM and KW we employed are reported in Appendix A.1.\\n\\n5.2 Reviewing phase and guidelines\\nIn order to obtain natural dialogues, the annotators in this session received specific post-editing instructions: 1. Since CNs are gold, it is strongly suggested to post-edit only the \\\\(HS_{i+1}\\\\) to \\\"align\\\" it with the \\\\(CN_i\\\\) belonging to the previous turn. 2. If a pair is in an unnatural position of the dialogue it should be moved to a better position. 3. If a pair is not fitting with the flow of the dialogue and cannot be moved elsewhere, it should be deleted. 4. If the whole dialogue makes no sense, or is too difficult to fix, it should be deleted. A characteristic example of the post-editing done in Session 1 is shown in Table 10 in Appendix C.\\n\\n5.3 Results\\nResults of this session in terms of \\\\textit{efficiency} and \\\\textit{quality} are reported in Table 1. In general, we observe that strategies using any HS-HS connection are less efficient, having higher HTER scores as compared to the CN-HS ones. HS-HS connections also have a high rate of deleted turns, in particular KW\\\\textit{HS-HS} and J-SIM\\\\textit{HS-HS}. The KW\\\\textit{HS-HS} strategy is even more inefficient than the random connection baseline (it reaches the highest number of deleted turns and the highest HTER), and it is the most repetitive before post-editing, as showed by the RR\\\\textit{gen}. These results are also confirmed by the annotators' feedback, who noted the presence of dialogues which were particularly difficult to edit since they contained the same HS repeated multiple times (see example in Table 11, Appendix C). A\\\\textit{posteriori} analysis showed that these dialogues were mainly obtained through the KW\\\\textit{HS-HS} connection. Moreover, each HS-HS connection strategy achieves a higher RR\\\\textit{gen} score than its CN-HS counterpart, showing that connecting through a \\\\textit{global} similarity generates a higher overall repetitiveness than using a \\\\textit{local} similarity. The particular high scores reached by the RR\\\\textit{gen} of both the keywords connection strategies can be explained by the procedure employed for connection: for keywords we performed an exact matching, whereas with the cosine or Jaccard similarity, the connection was selected from the 10 most similar candidates. After post-editing, all the strategies achieve a lower RR, between 4.5 and 9, indicating a more diversified content. The novelty is calculated against DIALO\\\\textit{gold}: the scores are similar for all the strategies.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Results for the second session. The showed paraphrasers are, from top to bottom: the Protaugment and Style paraphraser with basic, Twitter and Switchboard style, and the Style former paraphrasers with formal and casual style. NOV_{mt-g} and NOV_{mt-e} are the novelty of the generated and post-edited data with respect to the dialogues resulting from Session 1.\\n\\nFinally, it is worth noting that the strategies employing HS-HS connections have less turn swaps than C-SIM_{CN-HS} and J-SIM_{CN-HS}. The most probable explanation is that CN-HS strategies require less deletion, but this comes at the cost of more turn swaps.\\n\\n6 Session 2: Dialogue Wording\\n\\nIn the second session we focused on strategies aiming to obtain a new wording, given a structured dialogue. In particular, we tested 6 paraphrasing approaches on DIALO_{gold} and on a part of the dialogues resulting from the first session. In this session, our overall aim is to obtain novel and diverse responses to hate. Therefore, we chose to paraphrase only the CNs belonging to a subset of the data collected in Session 1, while keeping the corresponding HS as it is.\\n\\n6.1 Author Strategies\\n\\nWe carried out two exploratory studies to test different paraphrasing configurations and we selected the 6 most promising ones, as described in Appendix A.2. We use both paraphrasers with no specific style and with style transfer in order to attain a diverse data collection. The selection has been performed by assessing the aspects of dialogue wording that we deem the most relevant for our scenario.\\n\\nBasic paraphrasing. We use 2 paraphrasing tools as a 'baseline' where we do not impose any specific style to the paraphrases: the Protaugment paraphraser (Dopierre et al., 2021) and the Style paraphraser (Krishna et al., 2020) with basic style.\\n\\nStyle paraphrasing. This group includes 4 strategies in which we aimed to generate paraphrases with specific styles, in order to enhance the diversity of our data collection. Specifically, we focused on a style similar to that present in social media or in dialogues (Style paraphraser (Krishna et al., 2020) with Twitter and Switchboard style), and formal or casual (Style former paraphraser with casual and formal style).\\n\\nFor each CN, 3 different paraphrases are generated using the same paraphrasing strategy.\\n\\n6.2 Reviewing phase and guidelines\\n\\nIn order to obtain more natural examples, the post-editing instructions given to the annotators are adapted accordingly, emphasizing the significance of novel wording.\\n\\n1. The annotator should keep the gold HS as it is, while post-editing the most promising among the 3 CN paraphrasing suggestions, i.e. the one introducing the least errors and the most different one from the original.\\n\\n2. Turn swap in this case is not allowed, since turns order was already validated in these dialogues and paraphrasing would not affect it.\\n\\n3. For the same reason, turn and dialogue deletion are not allowed.\\n\\nAn example of a typical intervention of the annotators in Session 2 is shown in Table 12 in Appendix C.\\n\\n6.3 Results\\n\\nWe report the results in terms of efficiency and quality in Table 2. All the paraphrasers employed\\n\\n5https://github.com/PrithivirajDamodaran/Styleformer\"}"}
{"id": "emnlp-2022-main-549", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Results for the third session: the baseline models are signaled by the subscript \\\\( b \\\\), while the models trained on both DIALO\\\\( \\\\text{gold} \\\\) and the dialgues resulting from Session 1 have the subscript \\\\( mt \\\\). NOV\\\\( t-g \\\\) and NOV\\\\( t-e \\\\) are respectively the novelty scores of the generated and post-edited data with respect to each model\u2019s training data.\\n\\nReach similar HTER scores, which are below the 0.4 threshold, but higher than Session 1 results. Regarding the quality, generated paraphrases are highly novel with respect to the dialogues present in DIALO\\\\( \\\\text{gold} \\\\), but not as high if compared to the dialogues resulting from the connection of the gold pairs in Session 1. In addition, the annotators\u2019 intervention enhances the novelty of the generated paraphrases in almost all the cases, and reduces the RR for all the paraphrasers, with lower scores than in the first session (3,739 vs. 5,814 on average).\\n\\nTo sum up, we conclude that it is better to concatenate PAIRS\\\\( \\\\text{gold} \\\\) if we have a high number of pairs available, while paraphrasing is a viable solution if there is no pairs availability, since it implies a higher HTER and it is not justified by higher novelty.\\n\\n7 Session 3: Generation\\n\\nIn this session we follow the overall configuration presented in Fanton et al. (2021), where the author is an LM fine-tuned on the DIALO\\\\( \\\\text{gold} \\\\) together with the dialogues resulting from Session 1.\\n\\n7.1 Author Strategies\\n\\nWe tested the following configurations:\\n\\n- *DialoGPT*. An autoregressive model specific for dialogue generation (Zhang et al., 2020). We choose DialoGPT since it is proven to be effective in CN generation as well (Tekiroglu et al., 2022);\\n- *T5\\\\( _{2m} \\\\)*. Two T5 (Raffel et al., 2020) models conversing with each other: one fine-tuned to produce only HS and one to produce CNs. This configuration allows to completely decouple CN production from HS production.\\n- *T5\\\\( _{1m} \\\\)*. One T5 model able to produce both HS and CN. We test it as a comparison to the two T5 models conversing with each other.\\n\\nFor each configuration, we test a baseline model, fine-tuned on DIALO\\\\( \\\\text{gold} \\\\) only, and a model fine-tuned on both DIALO\\\\( \\\\text{gold} \\\\) and the post-edited dialogues resulting from Session 1. For each model we employed the Top-\\\\( p \\\\) decoding mechanism (Holtzmann et al., 2020) with \\\\( p = 0 \\\\).\\n\\nIn all cases, we split the employed dataset into training, development, and test sets with a ratio of 8:1:1. For the generation phase, we use as a prompt the initial HS of the test set dialogues. Then, we generate a single turn at a time by feeding the model with the context generated so far, until we reach 8 turns dialogues.\\n\\n7.2 Reviewing phase and guidelines\\n\\nThe data generated with the LMs include both HS and CN, therefore the annotators are allowed to post-edit both, unlike the previous session. The reviewing guidelines are similar to those for Session 1, with the following changes:\\n\\n1. it is possible to swap single turns and not only pairs, since the connection between HS/CN is not granted a-priori as in the previous sessions;\\n2. if some turns in a dialogue have a clearly different target than the labeled one, they should try to change turns wording to fit the original target.\\n3. the annotators should check the veracity of fact-based statements since they might derive from LM hallucinations.\\n\\nTraining details are reported in Appendix B. For example, a model can introduce hateful content when it is supposed to generate a CN, or viceversa (as showed in Table 13, Appendix C).\"}"}
{"id": "emnlp-2022-main-549", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Results of this session, in terms of efficiency and quality, are reported in Table 3. There are two major conclusions we can draw. Firstly, adding the post-edited dialogues obtained concatenating PAIRS gold to the training data (DIALO gold) strongly increases the efficiency. In fact, these models require much less deletion from the annotators with respect to the baselines, reaching a lower HTER (< 0.4). Also, even if the dialogues generated with the baselines have a higher novelty with respect to the training data, they are also extremely repetitive in almost all cases.\\n\\nSecondly, as already shown by Tekiroglu et al. (2022), autoregressive models are producing more varied and relevant content as compared to seq2seq models. In fact, even if DialoGPT requires more post-editing than T5 configurations (with comparatively higher HTER scores), its output dialogues require a lower number of deletion. This indicates that the DialoGPT generation is suboptimal but rarely unsuitable, while this often is not achieved by T5. In particular, turns swaps are present only for the DialoGPT models. According to the annotators, this is explained by the characteristics of T5 dialogues, which are more stereotypical, vague but have a better structure (see Table 14 in Appendix C). This is also confirmed by the quality results: T5 models generate content with similar novelty scores to DialoGPT, but they also tend to be more repetitive.\\n\\nFinally, Table 4 compares the results for each session over the main metrics of interest. We observe that concatenating pre-existing material that is already verified (i.e. HS/CN from PAIRS gold) requires less effort than generating new data from scratch or paraphrasing gold material, as Session 1 reaches a lower HTER than both Session 2 and Session 3. On the other hand, in terms of the structure of the dialogues, Session 1 requires the highest effort as shown by the high swap rate. Meanwhile, Session 2 is the least repetitive, but also the least novel, providing dialogues with a good wording, even if this is not accompanied with a novel content. In general, all the sessions reach an HTER lower or equal to 0.4, and similar novelty scores with respect to the gold data. Therefore, in all cases it was possible to enhance the novelty of the initial seed dataset, with a reasonable post-editing effort.\\n\\nTable 4 also shows a syntactic analysis of the data collected with each session, calculated at turn-level. The dialogues generated with the Language Models achieve the most balanced distribution in terms of number of turns, at the cost of simpler turns, as shown by the low maximum syntactic depth (MSD) and average syntactic depth (ASD) reached by Session 3. Paraphrasing instead provides the shortest generations both in terms of average turns length and of number of sentences (NST). By comparing the results of the different sessions, we can conclude that the choice of the preferable data collection strategy firstly depends on the available input data, e.g. we might not always have gold HS/CN pairs available or multiple turns dialogues. Secondly, depending on the desired output, if the priority is to obtain novel content, Session 2 strategies would be the least favorite. Also, the concatenation of existing pairs as in Session 1 is a more cautious approach than the generation of completely new dialogues through LMs. Thus, Session 1 strategies can be preferred for a more conservative approach, whereas Session 3 strategies are better suited for a more creative data collection that comes at the cost of higher human correction effort.\\n\\nAs a last step, we performed a sanity check in which a senior NGO expert conducted a qualitative evaluation by reading a random sample. We collected dialogues with 4, 6 and 8 turns, so a perfect balance would be of 6 turns.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: The distribution of targets in the final dataset. 'Other' indicates a few cases of intersectional targets among the 6 given, e.g., MUSLIMS/WOMEN.\\n\\nOverall, we collected 3059 dialogues for a total of 16625 turns.\\n\\n9 Conclusion\\n\\nIn this paper we have presented a hybrid approach for dialogue data collection in the realm of hate speech countering. These dialogues have been obtained starting from two expert-based seed datasets and then combining the intervention of human annotators over machine generated dialogues. We tested 19 different strategies for generation, focusing on two crucial aspects of dialogue, i.e. structure and wording. We analysed all these strategies in terms of efficiency of the procedure and quality of the data obtained. The result of this work is DIALOCONAN, the first dataset comprising over 3000 fictitious multi-turn dialogues between a hater and an NGO operator, covering 6 targets of hate.\\n\\nAcknowledgements\\n\\nWe are deeply thankful to Stop Hate UK and its volunteers for the help in writing the dialogues for the DIALOCONAN gold seed dataset and for sharing their expertise, fundamental to this work.\\n\\nLimitations\\n\\nThe datasets currently available for CN generation are mainly for the English language and this one is no exception. The problem is that getting in contact with NGO operators for other languages is not easily solvable. The alternatives, such as translating this dataset into other languages represent a suboptimal solution. In fact each language and country has (i) its own peculiar canards against minorities, (ii) even if HS can be ported across countries (e.g. \\\"Mi-grants steal our jobs.\\\"), the arguments to counter such HS may vary (e.g. different laws, different socioeconomic situations, different statistical data). When translating dialogues all these nuances get lost reducing the possible effectiveness and introducing possible unnatural answers making reference to the country for which the original CN was written.\\n\\nAlthough we tried to keep the overall quality of the final output as high as possible, since the dataset is created through a human-machine collaboration paradigm, it can still not be on par with the data that we can potentially obtain with niche sourcing the whole dataset to skilled NGO operators. Additionally, the number of turns in dialogues are strictly controlled and might not reflect the more natural number of turns that would have occurred under those circumstances.\\n\\nAs previously stated, scraping NGO operators real online intervention is not desirable (we need to protect their identity). Still, even when collecting DIALOCONAN we encountered some problems, i.e. even if the annotators were trained and used to the task, they told us that the simulation was really frustrating (e.g. \\\"repeating over and over again the same hateful content\\\").\\n\\nEthics Statement\\n\\nCounter Narrative generation task and corresponding datasets have been proposed as a contribution of scientific research to a more ethical world. However, even the best intentions in the minefield of online hate can still bring along certain risks of undesired impacts on data curators (i.e., expert/non-expert annotators), on researchers, and on society. Therefore, in this study, we took meticulous precautions in order to avoid such effects.\\n\\nAnnotation Guidelines:\\n\\nAs the most important stakeholders of this research, the annotators were constantly supported in terms of mental welfare. In particular, we put in practice a mitigation procedure similar to the one proposed by Vidgen et al. (2019), as described in Section 3.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Dataset. Since the dataset is created from scratch via an expert-machine collaboration schema (rather than scraping the dialogues among individuals online) it does not pose any threat to personal privacy or individual rights. Additionally, we avoid modeling inappropriate CNs (e.g. containing abusive language) that could be produced by scraping non-expert users in their online activity (Mathew et al., 2018).\\n\\nGeneration Task. We consider the generation task as an aid to boost the data collection in terms of time, quantity, and certain quality aspects. Therefore, the models we trained are not meant to be deployed as part of a live system. Moreover, our main focus is clearly on the counter narrative generation part and the corresponding CN quality/diversity. For this reason, and to limit possible misuses, in our dialogues we tried to keep the HS as simple and stereotypical as possible and we always left \u2018the last word\u2019 to a CN turn. We encourage other researchers to conduct the generation tasks in a similar manner and for this reason the dialogue dataset will be made available for research purposes together with the code/models used to generate it.\\n\\nReferences\\n\\nKimberley R Allison and Kay Bussey. 2016. Cyber-bystanding in context: A review of the literature on witnesses' responses to cyberbullying. Children and Youth Services Review, 65:183\u2013194.\\n\\nJenn Anderson, Mary Bresnahan, and Catherine Musat-ics. 2014. Combating weight-based cyberbullying on Facebook with the dissenter effect. Cyberpsychology, Behavior, and Social Networking, 17(5):281\u2013286.\\n\\nMana Ashida and Mamoru Komachi. 2022. Towards automatic generation of messages countering online hate speech and microaggressions. WOAH 2022, page 11.\\n\\nSusan Benesch. 2014. Countering dangerous speech: New ideas for genocide prevention. Washington, DC: United States Holocaust Memorial Museum.\\n\\nNicola Bertoldi, Mauro Cettolo, and Marcello Federico. 2013. Cache-based online adaptation for machine translation enhanced computer assisted translation. In MT-Summit, pages 35\u201342.\\n\\nReuben Binns, Michael Veale, Max Van Kleek, and Nigel Shadbolt. 2017. Like trainer, like bot? inheritance of bias in algorithmic content moderation. In Social Informatics, pages 405\u2013415, Cham. Springer International Publishing.\\n\\nPete Burnap and Matthew L Williams. 2016. Us and them: identifying cyber hate on Twitter across multiple protected characteristics. EPJ Data Science, 5(1):11.\\n\\nRicardo Campos, V\u00edtor Mangaravite, Arian Pasquali, Al\u00edpio Jorge, C\u00e9lia Nunes, and Adam Jatowt. 2020. Yake! keyword extraction from single documents using multiple local features. Information Sciences, 509:257\u2013289.\\n\\nRui Cao, Roy Ka-Wei Lee, and Tuan-Anh Hoang. 2020. DeepHate: Hate speech detection via multi-faceted text representations. In 12th ACM Conference on Web Science, pages 11\u201320.\\n\\nMauro Cettolo, Nicola Bertoldi, and Marcello Federico. 2014. The repetition rate of text as a predictor of the effectiveness of machine translation adaptation. In Proceedings of the 11th Biennial Conference of the Association for Machine Translation in the Americas (AMTA 2014), pages 166\u2013179.\\n\\nYi-Ling Chung, Elizaveta Kuzmenko, Serra Sinem Tekiro\u02d8glu, and Marco Guerini. 2019. CONAN - COunter NArratives through nichesourcing: a multilingual dataset of responses to fight online hate speech. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2819\u20132829, Florence, Italy. Association for Computational Linguistics.\\n\\nYi-Ling Chung, Serra Sinem Tekiro \u02d8glu, and Marco Guerini. 2020. Italian counter narrative generation to fight online hate speech. In Proceedings of the Seventh Italian Conference on Computational Linguistics CLiC-it.\\n\\nYi-Ling Chung, Serra Sinem Tekiro \u02d8glu, and Marco Guerini. 2021a. Towards knowledge-grounded counter narrative generation for hate speech. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 899\u2013914, Online. Association for Computational Linguistics.\\n\\nYi-Ling Chung, Serra Sinem Tekiro \u02d8glu, Sara Tonelli, and Marco Guerini. 2021b. Empowering ngos in countering online hate messages. Online Social Networks and Media, 24:100150.\\n\\nThomas Davidson, Debasmita Bhattacharya, and Ingmar Weber. 2019. Racial bias in hate speech and abusive language detection datasets. In Proceedings of the Third Workshop on Abusive Language Online, pages 25\u201335.\\n\\nEmily Dinan, Samuel Humeau, Bharath Chintagunta, and Jason Weston. 2019. Build it break it fix it for dialogue safety: Robustness from adversarial human attack. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4537\u20134546.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thomas Dopierre, Christophe Gravier, and Wilfried Logerais. 2021. Protaugment: Unsupervised diverse short-texts paraphrasing for intent detection meta-learning. arXiv preprint arXiv:2105.12995.\\n\\nGabriel Doyle and Michael C Frank. 2016. Investigating the sources of linguistic alignment in conversation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 526\u2013536.\\n\\nNouha Dziri, Ehsan Kamalloo, Kory Mathewson, and Osmar R Zaiane. 2019. Augmenting neural response generation with context-aware topical attention. In Proceedings of the First Workshop on NLP for Conversational AI, pages 18\u201331.\\n\\nMargherita Fanton, Helena Bonaldi, Serra Sinem Tekirda\u011fl\u0131, and Marco Guerini. 2021. Human-in-the-loop for data collection: a multi-target counter narrative dataset to fight online hate speech. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3226\u20133240.\\n\\nPaula Fortuna and S\u00e9rgio Nunes. 2018. A survey on automatic detection of hate speech in text. volume 51, page 85. ACM.\\n\\nIginio Gagliardone, Danit Gal, Thiago Alves, and Gabriela Martinez. 2015. Countering online hate speech. Unesco Publishing.\\n\\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.\\n\\nHoma Hosseinmardi, Sabrina Arredondo Mattson, Rahtat Ibn Rafiq, Richard Han, Qin Lv, and Shivakant Mishra. 2015. Detection of cyberbullying incidents on the Instagram social network. arXiv preprint arXiv:1503.03909.\\n\\nSvetlana Kiritchenko, Isar Nejadgholi, and Kathleen C Fraser. 2021. Confronting abusive language online: A survey from the ethical and human rights perspective. Journal of Artificial Intelligence Research, 71:431\u2013478.\\n\\nKalpesh Krishna, John Wieting, and Mohit Iyyer. 2020. Reformulating unsupervised style transfer as paraphrase generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 737\u2013762.\\n\\nRitesh Kumar, Atul Kr Ojha, Shervin Malmasi, and Marcos Zampieri. 2018. Benchmarking aggression identification in social media. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pages 1\u201311.\\n\\nBinny Mathew, Navish Kumar, Pawan Goyal, Animesh Mukherjee, et al. 2018. Analyzing the hate and counter speech accounts on Twitter. arXiv preprint arXiv:1812.02712.\\n\\nBinny Mathew, Punyajoy Saha, Hardik Tharad, Subham Rajgaria, Prajwal Singhania, Suman Kalyan Maity, Pawan Goyal, and Animesh Mukherjee. 2019. Thou shalt not hate: Countering online hate speech. In Proceedings of the International AAAI Conference on Web and Social Media, volume 13, pages 369\u2013380.\\n\\nBinny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan Goyal, and Animesh Mukherjee. 2021. Hatexplain: A benchmark dataset for explainable hate speech detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 14867\u201314875.\\n\\nFabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2020. Resources and benchmark corpora for hate speech detection: a systematic review. Language Resources and Evaluation, pages 1\u201347.\\n\\nJing Qian, Anna Bethke, Yinyin Liu, Elizabeth Belding, and William Yang Wang. 2019. A benchmark dataset for learning to intervene in online hate speech. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4757\u20134766, Hong Kong, China. Association for Computational Linguistics.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1\u201367.\\n\\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A Smith. 2019. The risk of racial bias in hate speech detection. In Proceedings of the 57th annual meeting of the association for computational linguistics, pages 1668\u20131678.\\n\\nCarla Schieb and Mike Preuss. 2016. Governing hate speech by means of counterspeech on Facebook. In 66th ICA Annual Conference, at Fukuoka, Japan, pages 1\u201323.\\n\\nAnna Schmidt and Michael Wiegand. 2017. A survey on hate speech detection using natural language processing. In Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media, pages 1\u201310.\\n\\nTanya Silverman, Christopher J Stewart, Jonathan Birdwell, and Zahed Amanullah. 2016. The impact of counter-narratives. Institute for Strategic Dialogue, London. https://www.strategicdialogue.org/wp-content/uploads/2016/08/Impact-of-Counter-Narratives_ONLINE.pdf\u201373. \"}"}
{"id": "emnlp-2022-main-549", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Lucia Specia and Atefeh Farzindar. 2010. Estimating machine translation post-editing effort with hter. In Proceedings of the Second Joint EM+/CNGL Workshop Bringing MT to the User: Research on Integrating MT in the Translation Industry (JEC 10), pages 33\u201341.\\n\\nSerra Tekiroglu, Helena Bonaldi, Margherita Fanton, and Marco Guerini. 2022. Using pre-trained language models for producing counter narratives against hate speech: a comparative study. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3099\u20133114.\\n\\nSerra Sinem Tekiro\u011flu, Yi-Ling Chung, and Marco Guerini. 2020. Generating counter narratives against online hate speech: Data and strategies. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1177\u20131190, Online. Association for Computational Linguistics.\\n\\nMengzhou Xia Anjalie Field Yulia Tsvetkov. 2020. Demoting racial bias in hate speech detection. SocialNLP 2020, page 7.\\n\\nMarco Turchi, Matteo Negri, and Marcello Federico. 2013. Coping with the subjectivity of human judgments in mt quality estimation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 240\u2013251.\\n\\nBertie Vidgen and Leon Derczynski. 2020. Directions in abusive language training data, a systematic review: Garbage in, garbage out. Plos one, 15(12):e0243300.\\n\\nBertie Vidgen, Alex Harris, Dong Nguyen, Rebekah Tromble, Scott Hale, and Helen Margetts. 2019. Challenges and frontiers in abusive content detection. In Proceedings of the Third Workshop on Abusive Language Online, pages 80\u201393, Florence, Italy. Association for Computational Linguistics.\\n\\nBertie Vidgen, Tristan Thrush, Zeerak Waseem, and Douwe Kiela. 2020. Learning from the worst: Dynamically generated datasets to improve online hate detection. arXiv preprint arXiv:2012.15761.\\n\\nEric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, and Jordan Boyd-Graber. 2019. Trick me if you can: Human-in-the-loop generation of adversarial question answering examples. Transactions of the Association for Computational Linguistics, 7(0):387\u2013401.\\n\\nKe Wang and Xiaojun Wan. 2018. Sentigan: Generating sentimental texts via mixture adversarial networks. In IJCAI, pages 4446\u20134452.\\n\\nZeerak Waseem. 2016. Are you a racist or am I seeing things? annotator influence on hate speech detection on twitter. In Proceedings of the first workshop on NLP and computational social science, pages 138\u2013142.\\n\\nXinchen Yu, Eduardo Blanco, and Lingzi Hong. 2022. Hate speech and counter speech detection: Conversational context does matter. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5918\u20135930, Seattle, United States. Association for Computational Linguistics.\\n\\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020. DIALOGPT : Large-scale generative pre-training for conversational response generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270\u2013278, Online. Association for Computational Linguistics.\\n\\nWanzheng Zhu and Suma Bhat. 2021. Generate, prune, select: A pipeline for counterspeech generation against online hate speech. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 134\u2013149.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Appendix\\n\\nA.1 Session 1: Algorithms details\\n\\nThe matching procedures over HS/CN pairs we employed are slightly different according to whether we performed a similarity (algorithm 1) or a keywords connection (algorithm 2). The main difference is that for similarity metrics it was always possible to choose among the 10 most similar pairs to the one of our interest, while when concatenating through keywords we put in practice an exact matching of pairs containing the same 2 keywords.\\n\\n**Algorithm 1:**\\nConnection through the similarity of either HS-HS or CN-HS.\\n\\n```\\nwhile nr_turns != desired_nr_turns:\\n    for each HS_i, CN_i:\\n        if nr_turns == 0:\\n            HS_to_match, CN_to_match \u2190 HS_i, CN_i\\n        else:\\n            HS_to_match, CN_to_match \u2190 chained_dialo[-2], chained_dialo[-1]\\n\\n        for each HS_j, CN_j:\\n            if HS-HS connection:\\n                compute similarity(HS_to_match, HS_j)\\n            if CN-HS connection:\\n                compute similarity(CN_to_match, HS_j)\\n\\n        randomly select 1 pair from the top-10 most similar to HS_to_match, CN_to_match\\n        nr_turns += 1\\n        chained_dialo += HS_selected, CN_selected\\n```\\n\\n**Algorithm 2:**\\nConnection through HS-HS or CN-HS keywords matching.\\n\\n```\\nwhile nr_turns != desired_nr_turns:\\n    for each HS_i, CN_i:\\n        if nr_turns == 0:\\n            HS_to_match, CN_to_match \u2190 HS_i, CN_i\\n        else:\\n            HS_to_match, CN_to_match \u2190 chained_dialo[-2], chained_dialo[-1]\\n\\n        for each HS_j, CN_j:\\n            if HS-HS connection:\\n                find matching keywords(HS_to_match, HS_j)\\n            if CN-HS connection:\\n                find matching keywords(CN_to_match, HS_j)\\n\\n        randomly select 1 pair from those matching with HS_to_match, CN_to_match\\n        nr_turns += 1\\n        chained_dialo += HS_selected, CN_selected\\n```\\n\\nIn total, we select 36 dialogues to be paraphrased: 12 for each setting, with 4 dialogues for 4, 6, and 8-turns dialogues. We generate 3 candidate paraphrases for each CN while the HS is not paraphrased, since our interest is to enlarge the CN data, and not the HS data. One expert annotator is given instructions of reading all the dialogues and, for each CN, to select the most appropriate paraphrase and modify it to make it fit in the dialogue. The chosen paraphrase should be the one which requires at the same time the least editing to fit in the dialogue naturally and to be as much different as possible from the original CN.\\n\\nWe aim for:\\n- high values for the HTER between CN and psel and between the CN and post-edited paraphrase (HTER CN-psel and HTER CN-ped);\\n- low HTER between original and post-edited paraphrase (HTER psel-ped).\\n\\nFrom the results in Table 6 we can notice that the first setting (Protaugment paraphraser with default setting but lower_is_better = False and drop_chance = 0.1) is achieving the lowest values on the HTER between CN and psel and between CN and ped, while the second lowest with...\"}"}
{"id": "emnlp-2022-main-549", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Results of exploratory study 1: the metrics are calculated on CN only. CN is the original CN that was paraphrased, \\\\( p_{sel} \\\\) the selected paraphrasis to be post-edited and \\\\( p_{ed} \\\\) the post-edited paraphrasis.\\n\\n| Setting | HTER | \\\\( \\\\Delta \\\\text{len} \\\\) | HTER | \\\\( \\\\Delta \\\\text{len} \\\\) | HTER |\\n|---------|------|----------------|------|----------------|------|\\n| Setting 1 | 0.55 | 0.46 | 0.61 | 24.67 | 21.83 | 21.44 |\\n| Setting 2 | 1.30 | 0.77 | 0.94 | 29.97 | 22.22 | 24.33 |\\n| Setting 3 | 0.85 | 0.44 | 0.78 | 26.17 | 22.17 | 23.58 |\\n\\nTable 7: The percentage of examples for each setting of exploratory study 1 with the HTER above the threshold value of 0.4. Results are calculated on CN only.\\n\\nAs shown in Table 7, setting 1 is the one with less extreme results but for the HTER between CN\\\\(-\\\\)\\\\( p_{sel} \\\\) and between \\\\( p_{sel} \\\\)\\\\(-\\\\)\\\\( p_{ed} \\\\) the situation is the opposite than the one we aim for; setting 2 achieves the most extreme results. Despite setting 3 has a high percentage of examples reaching a high HTER between CN\\\\(-\\\\)\\\\( p_{sel} \\\\) and between CN\\\\(-\\\\)\\\\( p_{ed} \\\\), still the results for HTER between \\\\( p_{sel} \\\\)\\\\(-\\\\)\\\\( p_{ed} \\\\) are not the worst.\\n\\nFor all these reasons, we decide to employ both the settings 1 and 3, while leaving out the setting 2.\\n\\nExploratory study 2\\nIn order to test the paraphrasis with style transfer, we use the following configurations:\\n\u2022 Setting 1: Style former from casual to formal.\\n\u2022 Setting 2: Style former from formal to casual.\\n\u2022 Setting 3: Style transfer with Tweets style (split + 1 step pipeline)\\n\u2022 Setting 4: Style transfer with Tweets style (split + 2-steps pipeline)\\n\u2022 Setting 5: Style transfer with Switchboard style (no split + 1 step pipeline)\\n\u2022 Setting 6: Style transfer with Switchboard style (split + 1 step pipeline)\\n\\nOnce again, we select 12 dialogues for each setting, with 3 candidate paraphrases generated for each CN. The instructions given to the expert annotator are the same as in the first exploratory study.\\n\\nTable 8: HTER scores for the exploratory study 2. Results are calculated on CN only.\\n\\n| Setting | HTER | \\\\( \\\\Delta \\\\text{len} \\\\) | HTER | \\\\( \\\\Delta \\\\text{len} \\\\) | HTER |\\n|---------|------|----------------|------|----------------|------|\\n| Setting 1 | 0.49 | 0.20 | 0.51 | 24.67 | 21.83 | 21.44 |\\n| Setting 2 | 0.51 | 0.34 | 0.53 | 29.97 | 22.22 | 24.33 |\\n| Setting 3 | 0.46 | 0.41 | 0.50 | 26.17 | 22.17 | 23.58 |\\n| Setting 4 | 1.02 | 0.43 | 0.83 | 22.22 | 21.83 | 21.44 |\\n| Setting 5 | 0.44 | 0.46 | 0.48 | 26.17 | 22.17 | 23.58 |\\n| Setting 6 | 0.46 | 0.56 | 0.57 | 29.97 | 22.22 | 24.33 |\"}"}
{"id": "emnlp-2022-main-549", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u2022 Formal and informal: both setting 1 and setting 2 achieve high HTER CN-psel and HTER CN-ped while low HTER psel-ped ... T5, characterised by a poorly varied content.\\n\\nAccording to these results, we choose to employ setting 1, 2, 4 and 5 for the paraphrasis session.\\n\\nB Session 3: Training details\\n\\nFor reproducibility purposes, we report here the parameters employed for fine-tuning the LMs used in Session 3. For each model, we used a version smaller than the largest available, i.e. the medium version for DialoGPT and the base version of T5. We used Optuna to conduct a hyperparameters search with 10 trials, and we selected the trial achieving the lowest evaluation loss. The search space for the parameters of our interest was the following: learning-rate: \\\\{1 \\\\times 10^{-5}, 2 \\\\times 10^{-5}, 3 \\\\times 10^{-5}, 4 \\\\times 10^{-5}, 5 \\\\times 10^{-5}\\\\}, warmup-ratio: \\\\{0, 0.1\\\\}, batch size: \\\\{1, 2, 4\\\\}, number of epochs: \\\\{2, 3, 5\\\\}. The selected parameters for each model are summed up in Table 9.\\n\\n| Model | Type   | Learning-rate | Warmup-ratio | Batch size | Epochs | Evalu. Loss |\\n|-------|--------|---------------|--------------|------------|--------|-------------|\\n| DGPT  | base   | 3e-05         | 2            | 5          | 0      | 2.41        |\\n| DGPT  | medium | 4e-05         | 2            | 3          | 0.1    | 1.92        |\\n| T5    | base   | 4e-05         | 4            | 5          | 0      | 2.93        |\\n| T5    | medium | 4e-05         | 4            | 3          | 0.1    | 2.26        |\\n| T5    | (HS model) | 3e-05    | 2            | 5          | 0.1    | 3.12        |\\n| T5    | (CN model) | 5e-05    | 2            | 2          | 0.1    | 2.86        |\\n| T5    | (CN model) | 5e-05    | 2            | 2          | 0.1    | 2.41        |\\n| T5    | (CN model) | 2e-05    | 2            | 2          | 0.1    | 2.32        |\\n\\nTable 9: Training details for the models employed in Session 3.\\n\\nC Reviewing examples\\n\\nTable 10 shows an example of turns swap from Session 1: CN 2 is a question that can be answered with HS 0, so it is moved at the beginning. At the same time, concluding the dialogue with the most substantial CN, i.e. CN 1, makes the dialogue stronger. HS 1 is modified by the addition of 'because' in order to be linguistically aligned with the preceding turn, which is a question.\\n\\nIn table 11 an example of a dialogue resulting from the concatenation of similar HS is showed. The high repetitiveness makes it necessary to remove the pair HS 2, CN 2 and to modify HS 1.\\n\\nIn table 12 an example of CN post-editing coming from Session 2 is showed: the selected paraphrasis is modified in order to be as much different from the original as possible, while keeping the dialogue flow naturally. The paraphrases of CN 1 and CN 2 are highly similar to the original text, and require a major intervention from the annotator.\\n\\nTable 13 and Table 14 show two peculiar cases of the annotators' intervention in Session 3. In table 13, HS 3 and CN 3 are swapped because CN 3 contains hateful content, while HS 3 is a CN. For the same reason it was necessary to post-edit CN 2.\\n\\nIn table 14, an example of a dialogue generated with T5, characterised by a poorly varied content. Both HS and CN are edited a lot to make the dialogue more natural.\"}"}
{"id": "emnlp-2022-main-549", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"HS0: Jews are only interested in themselves and their own race.\\n\\nHS2: I hate Jews. They're just a bunch of hypocrites.\\n\\nCN0: Do you really think that Jews only care about themselves? Then why do they prefer to live in our country where they are not the majority? How would you answer that?\\n\\nHS0: Jews are genetically evil.\\n\\nHS1: Jews have a monopoly on evil.\\n\\nHS2: Jews are only interested in themselves and their own race, but they still try to get into our society.\\n\\nCN1: You seem to be misinterpreting the meaning of the word \\\"citizen\\\". The idea is that the individual is allowed to choose their own religion just like choosing how to vote, and that is the right of all citizens.\\n\\nCN2: Do you really think that Jews only care about themselves? Then why do they prefer to live in our country where they are not the majority? How would you answer that?\\n\\nHS1: I have never met a Jew that wasn't evil, though.\\n\\nCN1: Not all Jews are bad, just an unlucky bunch who makes up a tiny part of the world's population, and this applies for every group in the world.\\n\\nCN2: That's not true. And why would it be true? Why are they usually associated with evil?\"}"}
