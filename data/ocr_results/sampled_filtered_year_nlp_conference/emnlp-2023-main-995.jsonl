{"id": "emnlp-2023-main-995", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks\\n\\nHeng Wang1 Wenqian Zhang2 Yuyang Bai1 Zhaoxuan Tan3 Shangbin Feng4 Qinghua Zheng1 Minnan Luo1\\n\\nAbstract\\n\\nOnline movie review platforms are providing crowdsourced feedback for the film industry and the general public, while spoiler reviews greatly compromise user experience. Although preliminary research efforts were made to automatically identify spoilers, they merely focus on the review content itself, while robust spoiler detection requires putting the review into the context of facts and knowledge regarding movies, user behavior on film review platforms, and more. In light of these challenges, we first curate a large-scale network-based spoiler detection dataset LCS and a comprehensive and up-to-date movie knowledge base UKM. We then propose MVSD, a novel Multi-view Spoiler Detection framework that takes into account the external knowledge about movies and user activities on movie review platforms. Specifically, MVSD constructs three interconnecting heterogeneous information networks to model diverse data sources and their multi-view attributes, while we design and employ a novel heterogeneous graph neural network architecture for spoiler detection as node-level classification. Extensive experiments demonstrate that MVSD advances the state-of-the-art on two spoiler detection datasets, while the introduction of external knowledge and user interactions help ground robust spoiler detection. Our data and code are available at https://github.com/Arthur-Heng/Spoiler-Detection.\\n\\n1 Introduction\\n\\nMovie review websites such as IMDB1 and Rotten Tomato2 have become popular avenues for movie commentary, discussion, and recommendation (Cao et al., 2019). Among user-generated movie reviews, some of them contain spoilers, which reveal major plot twists and thus negatively affect people's enjoyment (Loewenstein, 1994). As a result, automatic spoiler detection has become an important task to safeguard users from unwanted exposure to potential spoilers.\\n\\nExisting spoiler detection models mostly focus on the textual content of the movie review. Chang et al. (2018) propose the first automatic spoiler detection approach by jointly encoding the review text and the movie genre. Wan et al. (2019) extend the hierarchical attention network with item (i.e., the subject to the review) information and introduce user bias and item bias. Chang et al. (2021) propose a relation-aware attention mechanism to incorporate the dependency relations between context words in movie reviews. Combined with several open-source datasets (Boyd-Graber et al., 2013; Wan et al., 2019), these works have made important progress toward curbing the negative impact of movie spoilers.\\n\\nHowever, robust spoiler detection requires more than just the textual content of movie reviews, while robust spoiler detection requires more than just the textual content of movie reviews, while\"}"}
{"id": "emnlp-2023-main-995", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistics of LCS and existing dataset Kaggle.\\n\\n| KB       | # Review | # Cast | # Metadata | Year |\\n|----------|----------|--------|------------|------|\\n| KAGGLE   | 573,913  | 0      | 5          | 2018 |\\n| LCS (Ours) | 1,860,715 | 494,221 | 15         | 2022 |\\n\\nWe argue that two additional information sources are among the most helpful for reliable and well-grounded spoiler detection. Firstly, external knowledge of films and movies (e.g. director, cast members, genre, plot summary, etc.) are essential in putting the review into the movie context. Without knowing what the movie is all about, it is hard, if not impossible, to accurately assess whether the reviews give away major plot points or surprises and thus contain spoilers. Secondly, user activities of online movie review platforms help in incorporating the user- and movie-based spoiler biases. For example, certain users might be more inclined to share spoilers and different movie genres are disproportionally suffering from spoiler reviews while existing approaches simply assume the uniformity of spoiler distribution. As a result, robust spoiler detection should be guided by external film knowledge and user interactions on movie review platforms, putting the review content into context and promoting reliable predictions. We demonstrate how these two information sources can help spoiler detection in Figure 1.\\n\\nIn light of these challenges, this work greatly advances spoiler detection research through both resource curation and method innovation. We first propose a large-scale spoiler detection dataset LCS and an extensive movie knowledge base (KB) UKM. LCS is 114 times larger than existing datasets (Boyd-Graber et al., 2013) and is the first to provide user interactions on movie review platforms, while UKM presents an up-to-date movie KB with entries of modern movies compared to existing resources (Misra, 2019). In addition to resource contributions, we propose MVSD, a graph-based spoiler detection framework that incorporates external knowledge and user interaction networks. Specifically, MVSD constructs heterogeneous information networks (HINs) to jointly model diverse information sources and their multi-view features while proposing a novel heterogeneous graph neural network (GNN) architecture for robust spoiler detection.\\n\\nWe compare MVSD against three types of baseline methods on two spoiler detection datasets. Extensive experiments demonstrate that MVSD significantly outperforms all baseline models by at least 2.01 and 3.22 in F1-score on the Kaggle (Misra, 2019) and LCS dataset (ours). Further analyses demonstrate that MVSD empowers external movie KBs and user networks on movie review platforms to produce accurate, reliable, and well-grounded spoiler predictions.\\n\\n### Table 2: Statistics of our proposed LCS dataset.\\n\\n| Type | Number | Description                                      |\\n|------|--------|--------------------------------------------------|\\n| review | 1,860,715 | The posting time is from 1998 to 2022.          |\\n| user  | 259,705  | Users that posted these reviews.                |\\n| movie | 147,191  | The released year is from 1874 to 2022.         |\\n| cast  | 494,221  | The cast related to the movies.                 |\\n| spoiler | 457,500  | 24.59% of the reviews are spoilers.             |\\n\\n### Table 3: Statistics of UKM and existing movie KBs.\\n\\n| KB       | # Entity | # Relation | # Triple | Year |\\n|----------|----------|------------|----------|------|\\n| MOVIE    | 14,708   | 20         | 434,189  | 2019 |\\n| TITLE    | 182,011  | 12         | 1,241,995| 2018 |\\n| UKM (Ours) | 641,585  | 15         | 1,936,710| 2022 |\\n\\nExtensive experiments demonstrate that MVSD significantly outperforms all baseline models by at least 2.01 and 3.22 in F1-score on the Kaggle (Misra, 2019) and LCS dataset (ours). Further analyses demonstrate that MVSD empowers external movie KBs and user networks on movie review platforms to produce accurate, reliable, and well-grounded spoiler predictions.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Linear Softmax\\n\\nspoiler normal review\\n\\nResults\\n\\nProbs. (%) 94.3 ...\\n\\nmodels the bipartite relation between movies and user reviews. We first define the nodes denoted as VM, which include:\\n\\n9.0_10.0 ... of our knowledge.\\n\\nBased on the LCS dataset, we then curate the results in Table 3, which demonstrates that a comprehensive knowledge base of movie knowl-\\n\\nThe_Shawshank...\"}"}
{"id": "emnlp-2023-main-995", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The information about movies, especially the plot, is essential in spoiler detection. We use one node to represent each movie.\\n\\nRating is an essential part of movie review. We use ten nodes to represent the numerical ratings ranging from 1 to 10.\\n\\nWe use one node to represent each movie review document. We connect these nodes with three types of edges, denoted as $E_{M}$:\\n\\n- **R1:** review-movie. We connect a review node with a movie node if the review is about the movie.\\n- **R2:** movie-rating. We connect a movie node with a rating node according to the overall rating of the movie, rounded to the nearest integer.\\n- **R3:** rating-review. We connect a review node with a rating node based on its numeric score.\\n\\n### User-Review Subgraph\\n\\nThe user-review subgraph is responsible for modeling the heterogeneity of user behavior on movie review platforms. The nodes in this subgraph, denoted as $V_{U}$, include:\\n\\n- **N4:** review. We use one node to represent each review document. Note that review nodes appear both in $V_{M}$ (as N1) and $V_{U}$ (as N4). Sharing nodes across subgraphs enables MVSD to model the interaction and exchange across different contexts.\\n- **N5:** user. We use one node to represent each user.\\n- **N6:** year. We use one node to represent each year, modeling the temporal distribution of spoilers.\\n\\nWe connect these nodes with three types of edges, denoted as $E_{U}$:\\n\\n- **R4:** review-user. We connect a review node with a user node if the user posted the review.\\n- **R5:** review-year. We connect a review node with a year node if the review was posted in that year.\\n- **R6:** user-year. We connect a user node with a year node if the user created the account in that year.\\n\\n### Knowledge Subgraph\\n\\nThe knowledge subgraph is responsible for incorporating movie knowledge in external KBs. Nodes in this subgraph, denoted as $V_{K}$, include:\\n\\n- **N7:** movie. We use one node to represent each movie.\\n- **N8:** genre. We use one node to represent each movie genre.\\n- **N9:** cast. We use one node to represent each distinct director and cast member.\\n- **N10:** year. We use one node to represent each year.\\n- **N11:** rating. We use ten nodes to represent the numerical ratings ranging from 1 to 10.\\n\\nWe connect these nodes with four types of edges:\\n\\n- **R7:** movie-genre. We connect a movie node with a genre node according to the genre of the movie.\\n- **R8:** movie-cast. We connect a movie node with a cast node if the cast is involved in the movie.\\n- **R9:** movie-year. We connect a movie node with a year node if the movie was released in that year.\\n- **R10:** movie-rating. We connect a user node with a rating node according to the rating of the movie.\\n\\nNote that the most vital nodes, movie nodes and review nodes, both appear in two subgraphs. These shared nodes then serve as bridges for information exchange across subgraphs, which is enabled by the MVSD model architecture in Section 3.3.\\n\\n### 3.2 Multi-View Feature Extraction\\n\\nThe entities in the heterogeneous information graph have diverse data sources and multi-view attributes. In order to model the rich information of these entities, we propose a taxonomy of the views, dividing them into three categories.\\n\\n**Semantic View**\\n\\nThe semantic view reflects the semantics contained in the text. We pass movie review documents, movie plot descriptions, user bio, and cast bio to pre-trained RoBERTa, averaging all tokens, and produce node embeddings $v_{s}$ as the semantic view.\\n\\n**Meta View**\\n\\nThe meta view is the numerical and categorical feature. We utilize metadata of user accounts, movie reviews, movies, and cast, and calculate the z-score as node embeddings $v_{m}$ to get the meta view. Details about metadata can be found in Appendix A.2.\\n\\n**Knowledge View**\\n\\nThe knowledge view captures the external knowledge of movies. Following previous works (Hu et al., 2021; Zhang et al., 2022), we use TransE (Bordes et al., 2013) to train KG embeddings for the UKM knowledge base and use these embeddings as node features $v_{k}$ for the external knowledge view.\\n\\nBased on these definitions, each subgraph has two feature views, thus nodes in each subgraph have two sets of feature vectors. Specifically, the knowledge subgraph $G_{K}$ has the external knowledge view and the semantic view, the movie-review subgraph $G_{M}$ and the user-review subgraph $G_{U}$ has the meta view and the semantic view. We then employ one MLP layer for each feature view to encode the extracted features and obtain the initial...\"}"}
{"id": "emnlp-2023-main-995", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"node features $x^s_i$, $x^m_i$, $x^k_i$ for the semantic, meta, and knowledge view.\\n\\n3.3 MVSD Layer\\n\\nAfter obtaining the three subgraphs and their initial node features under the textual, meta, and knowledge views, we employ MVSD layers to conduct representation learning and spoiler detection. Specifically, an MVSD layer first separately encodes the three subgraphs, then adopts hierarchical attention to enable feature interaction and the information exchange across various subgraphs.\\n\\nSubgraph Modeling\\n\\nWe first model each subgraph independently, fusing the two view features for each node. We then fuse node embeddings from different subgraphs to facilitate interaction between the three subgraphs. For simplicity, we adopt relational graph convolutional networks (R-GCN) (Schlichtkrull et al., 2018) to encode each subgraph. For the $l$-th layer of R-GCN, the message passing is as follows:\\n\\n$$x^{(l+1)}_i = \\\\Theta^{self} \\\\cdot x^{(l)}_i + \\\\sum_{r \\\\in R} \\\\sum_{j \\\\in N_r(i)} \\\\frac{1}{|N_r(i)|} \\\\Theta^r \\\\cdot x^{(l)}_j$$\\n\\nwhere $\\\\Theta^{self}$ is the projection matrix for the node itself while $\\\\Theta^r$ is the projection matrix for the neighbor of relation $r$. By applying R-GCN, nodes in subgraph $G_K$ get features from the knowledge and semantic view, denoting as $x^K_k$ and $x^K_s$, respectively. Nodes in subgraph $G_M$ get features from the semantic and meta view, denoting as $x^M_s$, $x^M_m$, while nodes in subgraph $G_U$ get the same views of feature, denoting as $x^U_s$, $x^U_m$.\\n\\nAggregation and Interaction\\n\\nGiven the representation of nodes from different feature views, we adopt hierarchical attention layers to aggregate and mix the representations learned from different subgraphs. Our hierarchical attention contains two parts: view-level attention and subgraph-level attention. Considering movie node and review node are shared nodes of subgraphs and are of the most significance, we utilize these two kinds of nodes to implement our hierarchical attention.\\n\\nWe first conduct view-level attention to aggregate the multi-view information for each type of node. For each node in a specific subgraph, it has embeddings learned from two types of feature views. We first adopt our proposed view-level attention to fuse the information learned from different views for each node. We learn a weight for each view of features in a specific subgraph. Specifically, the learned weight for each view in a specific subgraph $G_v$, $(\\\\alpha^v_1, \\\\alpha^v_2)$ can be formulated as:\\n\\n$$(\\\\alpha^v_1, \\\\alpha^v_2) = \\\\text{attn}^v(X^{G_v_1}, X^{G_v_2})$$\\n\\nwhere $\\\\text{attn}^v$ denotes the layer that implements the view-level attention, and $X^{G_v_i}$ is the node embeddings from view $v_i$ in subgraph $G_v$. To learn the importance of each view, we first transform view-specific embedding through a fully connected layer, then we calculate the similarity between transformed embedding and a view-level attention vector $q^G$. We then take the average importance of all the view-specific node embedding as the importance of each view. The importance of each view, denoted as $w_v^i$, can be formulated as:\\n\\n$$w_v^i = \\\\frac{1}{|V^G|} \\\\sum_{j \\\\in V^G} q^G^T \\\\cdot \\\\tanh(W \\\\cdot x_{G^v_j} + b)$$\\n\\nwhere $q^G$ is the view-level attention vector for each view of feature, $V^G$ is the nodes of subgraph $G$, and $x_{G^v_j}$ is the embedding of node $j$ in subgraph $G$ from view $v_i$. Then the weight of each view in subgraph $G$ can be calculated by:\\n\\n$$\\\\alpha^v_i = \\\\frac{\\\\exp(w_v^i)}{\\\\exp(w_v^1) + \\\\exp(w_v^2)}$$\\n\\nIt reflects the importance of each view in our spoiler detection task. Then the fused embeddings of different views can be shown as:\\n\\n$$X^G = \\\\alpha^v_1 \\\\cdot X^{G_v_1} + \\\\alpha^v_2 \\\\cdot X^{G_v_2}$$\\n\\nThus we get the subgraph-specific node embedding, denoted as $X^K$, $X^M$, $X^U$.\\n\\nWe then conduct subgraph-level attention to facilitate the flow of information between the three information sources. Generally, nodes in different subgraphs only contain information from one subgraph. To learn a more comprehensive representation and facilitate the flow of information between subgraphs, we enable the information exchange across various subgraphs using the movie nodes and the review nodes, both appearing in two subgraphs, as the information exchange ports. Specifically, we propose a novel subgraph-level attention to automatically learn the weight of each subgraph and fuse the information learned for different subgraphs. To be specific, the learned weight of each subgraph $(\\\\beta^K, \\\\beta^M, \\\\beta^U)$ can be computed as:\\n\\n$$(\\\\beta^K, \\\\beta^M, \\\\beta^U) = \\\\text{attn}^g(X^K, X^M, X^U)$$\"}"}
{"id": "emnlp-2023-main-995", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"where attng denotes the subgraph-level attention layer. To learn the importance of each subgraph, we transform subgraph-specific embedding through a feedforward layer and then calculate the similarity between transformed embedding and a subgraph-level attention vector $q$. Furthermore, we take the average importance of all the subgraph-specific node embedding as the importance of each subgraph. Taking $G_K$ and $G_M$ as an example, the shared nodes of these two subgraphs are movie nodes. The importance of each subgraph, denoted as $w_K, w_M$, can be formulated as:\\n\\n$$w_V = \\\\frac{1}{|V_{mv}|} \\\\sum_{j \\\\in V_{mv}} q^T \\\\cdot \\\\tanh(W \\\\cdot x_V^j + b)$$\\n\\nwhere $V \\\\in \\\\{K, M\\\\}$, $q$ is the subgraph-level attention vector for each subgraph. Then the weight of each subgraph can be shown as:\\n\\n$$\\\\beta_K = \\\\frac{\\\\exp(w_K)}{\\\\exp(w_K) + \\\\exp(w_M)}, \\\\beta_M = \\\\frac{\\\\exp(w_M)}{\\\\exp(w_K) + \\\\exp(w_M)}$$\\n\\nAfter obtaining the weight, the subgraph-specific embedding can be fused, formulated as:\\n\\n$$X_{mv} = \\\\beta_K \\\\cdot X_K_{mv} + \\\\beta_M \\\\cdot X_M_{mv}$$\\n\\nSimilarly, for review nodes, we can get the fused representation $X_{rv}$. Our proposed subgraph-level attention enables the information to flow across different views and subgraphs.\\n\\n3.4 Overall Interaction\\nOne layer of our proposed MVSD layer, however, cannot enable the information interaction between all information sources (e.g. the user-review subgraph and the knowledge subgraph). In order to further facilitate the interaction of the information provided by each view in each subgraph, we employ $\\\\ell$ MVSD layers for node representation learning. The representation of movie nodes and review nodes is updated after each layer, incorporating information provided by different views and neighboring subgraphs. This process can be formulated as follows:\\n\\n$$X^{(i)} = MVSD(X^{(i-1)})$$\\n\\nwhere $X^{(i)} = [X_{G_K}^{(i)} k, X_{G_K}^{(i)} s, X_{G_M}^{(i)} m, X_{G_M}^{(i)} s, X_{G_U}^{(i)} m, X_{G_U}^{(i)} s]$\\n\\nWe use $h^{(i)}$ to denote the representation of reviews after adopting the $i$-th MVSD layer.\\n\\nFigure 3: MVSD performance when randomly removing the edges in the user interaction network and external knowledge subgraph. Performance declines with the gradual edge ablations, indicating the contribution of external knowledge and user networks.\\n\\n3.5 Learning and Optimization\\nAfter a total of $\\\\ell$ MVSD layers, we obtain the final movie review node representation denoted as $h^{(\\\\ell)}$. Given a document label $a \\\\in \\\\{SPOILER, NOT SPOILER\\\\}$, the predicted probabilities are calculated as\\n\\n$$p(a | d) \\\\propto \\\\exp\\\\left(MLP_a(h^{(\\\\ell)})\\\\right)$$\\n\\nWe then optimize MVSD with the cross entropy loss function. At inference time, the predicted label is $\\\\arg\\\\max_a p(a | d)$.\\n\\n4 Experiment\\n4.1 Experiment Settings\\nDatasets. We evaluate MVSD and baselines on two spoiler detection datasets:\\n- LCS is our proposed large-scale automatic spoiler detection dataset. We randomly create a 7:2:1 split for training, validation, and test sets.\\n- Kaggle is a publicly available movie review dataset presented in a Kaggle challenge (Misra, 2019). We present more details about this dataset in Appendix A.\\n\\nBaselines. We compare MVSD against 9 baseline methods in three categories: pretrained language models, GNN-based models, and task-specific baselines. For pretrained language models, we evaluate BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), BART (Lewis et al., 2020), and DeBERTa (He et al., 2021a). For GNN-based models, we evaluate GCN (Kipf and Welling, 2017), R-GCN (Schlichtkrull et al., 2018), and SimpleHGN (Lv et al., 2021). For task-specific baselines, we evaluate DNSD (Chang et al., 2018) and SpoilerNet (Wan et al., 2019).\"}"}
{"id": "emnlp-2023-main-995", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Accuracy, AUC, and binary F1-score of MVSD and three types of baseline methods on two spoiler detection datasets. We run all experiments five times to ensure a consistent evaluation and report the average performance as well as standard deviation. MVSD consistently outperforms the three types of methods on both datasets.\\n\\n| Method                  | F1  | AUC  | Acc  |\\n|-------------------------|-----|------|------|\\n| MVSD (Ours)             | 83.59 | 78.26 | 69.22 |\\n| DNSD (Chang et al., 2018) | 80.22 | 74.65 | 66.08 |\\n| GCN (Kipf and Welling, 2017) | 77.22 | 70.14 | 63.08 |\\n| R-GCN (Schlichtkrull et al., 2018) | 74.22 | 66.14 | 59.08 |\\n| HGN (Lv et al., 2021) | 71.00 | 63.99 | 57.00 |\\n| IMPLE (Liu et al., 2019) | 68.00 | 61.99 | 55.00 |\\n| BERT                     | 65.08 | 66.00 | 56.00 |\\n| BERET                    | 62.00 | 59.99 | 53.00 |\\n\\nWe hypothesize that external movie knowledge and user interactions on movie review websites are essential in spoiler detection, providing more context for user interactions. Moreover, we replace our attention mechanism with simple fusion methods to evaluate the effectiveness of our fusion method. Among the two task-specific baselines, SpoilerNet (Wan et al., 2019) outperforms DNSD (Chang et al., 2018), in part attributable to the introduction of the user bias. Our method further incorporates external knowledge and user networks. However, systems to go beyond the mere textual content of movie reviews, such as external knowledge and user networks, multi-view feature extraction, and the cross-context information extraction, are required in order to achieve better performance, suggesting that robust spoiler detection requires models and cal contributions, such as incorporating external knowledge and graph-based modeling could bring in additional information sources, such as external knowledge and user networks, multi-view feature extraction, and the cross-context information extraction, for spoiler detection.\\n\\n4.2 Overall Performance\\n\\n\u2022 Among the two task-specific baselines, SpoilerNet (Wan et al., 2019) outperforms DNSD (Chang et al., 2018), in part attributable to the introduction of the user bias. Our method further incorporates external knowledge and user networks, multi-view feature extraction, and grounding in addition to the textual content of movie reviews. To further examine their contributions, we randomly remove 20%, 40%, and 60% of the edges in the knowledge subgraph to investigate, Finally, we replace our attention mechanism with simple fusion methods to evaluate the effectiveness of our fusion method. While achieving better performance, suggesting that the user interaction network plays an important role in the spoiler detection task. As demonstrated in Table 4, we replace our attention mechanism with simple fusion methods to evaluate the effectiveness of our fusion method. This demonstrates that our various techniques, such as incorporating external knowledge and user networks, multi-view feature extraction, and the cross-context information extraction, achieved a more accurate performance. Table 4 demonstrates that:\\n\\n4.4 Ablation Study\\n\\nIn order to study the effect of different views of knowledge and user information, we remove them individually and evaluate the robustness of MVSD , as it can achieve relative state-of-the-art performance. In Figure 3 (a), it is illustrated that the performance drops significantly (about 10% in F1-score when removing 10% of the edges) when we increase the number of removed edges in the user-review subgraph, suggesting that the user interaction network plays an important role in the spoiler detection task. As demonstrated in Figure 3 (b), the F1-score and AUC significantly drop by 3.38% if we remove the whole knowledge subgraph, indicating that external knowledge is helpful while achieving better performance, suggesting that the user interaction network plays an important role in the spoiler detection task. As demonstrated in Table 4, we replace our attention mechanism with simple fusion methods to evaluate the effectiveness of our fusion method. While achieving better performance, suggesting that the user interaction network plays an important role in the spoiler detection task. As demonstrated in Figure 3 (b), the F1-score and AUC significantly drop by 3.38% if we remove the whole knowledge subgraph, indicating that external knowledge is helpful while achieving better performance.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Ablation study concerning multi-view data and the graph structure on Kaggle Dataset. The semantic view, knowledge view, and meta view are denoted as $S$, $K$, and $M$ respectively. The knowledge subgraph, movie-review subgraph, and user-review subgraph are denoted as $G_K$, $G_M$, and $G_U$.\\n\\n| Category Setting | F1   | AUC  | Acc  |\\n|------------------|------|------|------|\\n| multi-view       |      |      |      |\\n| -w/o $S$         | 38.47| 61.37| 78.15|\\n| -w/o $K$         | 62.13| 73.46| 82.73|\\n| -w/o $M$         | 52.99| 68.07| 79.46|\\n| -w/o $O$, $K$    | 40.05| 61.97| 78.25|\\n| -w/o $O$, $M$    | 56.44| 70.05| 80.66|\\n| graph structure  |      |      |      |\\n| -w/o $G_K$       | 61.66| 72.99| 83.12|\\n| -w/o $G_U$       | 47.17| 64.93| 78.00|\\n| -w/o $G_M$, $G_K$| 56.54| 69.98| 81.71|\\n| -w/o $G_M$, $G_K$| 46.65| 64.89| 78.03|\\n| ours MVSD        | 65.08| 75.42| 83.59|\\n\\nTable 6: Model performance on Kaggle when our attention mechanism is replaced with simple fusion methods.\\n\\n| View-level          | Subgraph-level | F1   | AUC  | Acc  |\\n|---------------------|----------------|------|------|------|\\n| Ours                | Max-pooling    | 53.73| 68.50| 79.29|\\n| Ours                | Mean-pooling   | 62.27| 73.40| 83.23|\\n| Ours                | Concat         | 61.07| 72.63| 82.97|\\n| Max-pooling         | Ours           | 63.19| 74.21| 82.86|\\n| Mean-pooling        | Ours           | 63.60| 74.36| 83.30|\\n| Concat              | Ours           | 62.90| 74.00| 82.83|\\n| ours                | ours           | 65.08| 75.42| 83.59|\\n\\nMulti-View Study\\n\\nWe report the binary F1-Score, AUC, and Acc of the ablation study in Table 5. Among the multi-view data, semantic view data is of great significance as AUC and F1-score drop dramatically when it is discarded. We can see that discarding the external knowledge view or removing the knowledge subgraph reduces the F1-score by about 3%, indicating that the external knowledge of movies is helpful to the spoiler detection task. However, external knowledge doesn't show the same importance as the directly related semantic view or meta view. We believe this is because the external knowledge is not directly related to review documents, so it can only provide auxiliary help to the spoiler detection task.\\n\\nGraph Structure Study\\n\\nAs illustrated in Table 5, after removing the user-review subgraph, the reduced model performs poorly, with a drop of 18% in F1. This demonstrates that the user interaction network is necessary for spoiler detection.\\n\\nAggregation and Interaction Study\\n\\nIn order to study the effectiveness of the hierarchical mechanism that enables the interaction between views and sub-graphs, we replace the two components of our hierarchical attention with other operations and evaluate them on the Kaggle Dataset. Specifically, we compare our attention module with concatenation, max-pooling, and average-pooling. In Table 6 we report the binary F1-score, AUC, and Acc. We can see that our approach beats the eight variants in all metrics. It is evident that our approach can aggregate and fuse multi-view data more efficiently than simple fusion methods.\\n\\n4.5 Qualitative Analysis\\n\\nWe conduct qualitative analysis to investigate the role of external movie knowledge and social networks for spoiler detection. As shown in Table 7, with the guide of external knowledge and user networks, MVSD successfully makes the correct prediction while baseline models fail. Specifically, in the first case, the user is a fan of Kristen Wiig. Guided by the information from the social network, MVSD finds that the user often posted spoilers related to the film star, and finally predicts that the review is a spoiler. In the second case, the user mentioned something done by the director of the movie. With the help of movie knowledge, it can be easily distinguished that what the director has done reveals nothing of the plot.\\n\\n5 Related Work\\n\\nAutomatic Spoiler Detection\\n\\nAutomatic spoiler detection aims to identify spoiler reviews in domains such as television (Boyd-Graber et al., 2013), books (Wan et al., 2019), and movies (Misra, 2019; Boyd-Graber et al., 2013). Existing spoiler detection models could be mainly categorized into two types: keyword matching and machine learning models. Keyword matching methods utilize predefined keywords to detect spoilers, for instance, the name of sports teams or sports events (Nakamura and Tanaka, 2007), or the name of actors (Golbeck, 2012). This type of method requires keywords defined by humans, and cannot be generalized to various application scenarios. Early neural spoiler detection models mainly leverage topic models or support vector machines with hand-crafted features. Guo and Ramakrishnan (2010) use bag-of-words representation and LDA-based model to detect spoilers, Jeon et al. (2013) utilize...\"}"}
{"id": "emnlp-2023-main-995", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 7: Examples of the performance of three baselines and MVSD. Underlined parts indicate the plots.\\n\\nReview Text | Label | DeBERTa | R-GCN | SpoilerNet | MVSD\\n---|---|---|---|---|---\\nKristen Wiig is the only reason I wanted to see this movie, and she is insanely hilarious! (...) Wiig plays Annie, (...) becomes jealous of Lillian's new rich friend, Helen. Annie slowly goes crazy and constantly competes against Helen (...) | True | False | False | True | True\\nThe new director was horrible. Not even comparable to Chris Columbus. He changed the entire format of the school (...) why was there a deer next to harry across the lake, he didn't mention that and yet he still put the deer in the movie (...) | False | True | True | False | True\\n(...) This scene involves Harry getting bombarded by ugly, little squid like creatures and is awe inspiring. And more happens. Harry is having a certain dream over and over again. Lord V oldemort wants to return and he does. (...) I remember that for four years in high school, I was a high school nerd/loner, and I liked it. I was shy, I was socially awkward, and I was one of those guys who happened to have a thing for one of the popular girls (...) | True | False | False | True | True\\n\\nSVM classification with four extracted features, while Boyd-Graber et al. (2013) incorporate lexical features and meta-data of the review subjects (e.g., movies and books) in an SVM classifier. Later approaches are increasingly neural methods: Chang et al. (2018) focus on modeling external genre information based on GRU and CNN, while Wan et al. (2019) introduce item-specificity and bias and utilizes bidirectional recurrent neural networks (bi-RNN) with Gated Recurrent Units (GRU). A recent work (Chang et al., 2021) leverages dependency relations between context words in sentences to capture the semantics using graph neural networks. While existing approaches have made considerable progress for automatic spoiler detection, it was previously underexplored whether review text itself is sufficient for robust spoiler detection, or whether more information sources are required for better task grounding. In this work, we make the case for incorporating external film knowledge and user activities on movie review websites in spoiler detection, advancing the field through both resource curation and method innovation, presenting a large-scale dataset LCS, an up-to-date movie knowledge base UKM, and a state-of-the-art spoiler detection approach MVSD.\\n\\nGraph-Based Social Text Analysis\\nGraphs and heterogeneous information networks are playing an important role in the analysis of texts and documents on news (Mehta et al., 2022) and social media (Hofmann et al., 2022). In these approaches, graphs and graph neural networks are adopted to represent and encode information in addition to textual content, such as social networks (Nguyen et al., 2020), external knowledge graphs (Zhang et al., 2022), social context (Mehta et al., 2022), and dependency relations between context words (Chang et al., 2021). With the help of additional information sources, these graph-based approaches enhance representation quality by capturing the rich social interactions (Nguyen et al., 2020), infusing knowledge reasoning into language representations (Zhang et al., 2022), and reinforcing nodes' representations interactively (Mehta et al., 2022). As a result, graph-based social text analysis approaches have advanced the state-of-the-art on various tasks such as misinformation detection (Zhang et al., 2022), stance detection (Liang et al., 2022), propaganda detection (Vijayaraghavan and Vosoughi, 2022), sentiment analysis (Chen et al., 2022), and fact verification (Arana-Catania et al., 2022). Motivated by the success of existing graph-based models, we propose MVSD to incorporate external knowledge bases and user networks on movie review platforms through graphs and graph neural networks.\\n\\n6 Conclusion\\nWe make the case for incorporating external knowledge and user networks on movie review websites for robust and well-grounded spoiler detection. Specifically, we curate LCS, the largest spoiler detection dataset to date; we construct UKM, an up-to-date knowledge base of the film industry; we propose MVSD, a state-of-the-art spoiler detection system that takes external knowledge and user interactions into account. Extensive experiments demonstrate that MVSD achieves state-of-the-art performance on two datasets while showcasing the benefits of incorporating movie knowledge and user behavior in spoiler detection. We leave it for future work to further check the labels in the LCS dataset.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Limitations\\n\\nWe identify two key limitations:\\n\\n\u2022 MVSD utilizes widely-adopted RGCN to model each subgraph, while there are more up-to-date heterogeneous graph algorithms like HGT (Hu et al., 2020), SimpleHGN (Lv et al., 2021). We plan to conduct experiments that replace RGCN with other heterogeneous graph algorithms. Besides, considering the subgraph structure of MVSD, we will test different heterogeneous graph algorithm settings in each subgraph to find out the most efficient algorithm for each subgraph.\\n\\n\u2022 LCS is constructed based on IMDB, and the spoiler annotation is based on user self-report. Hence, it is likely that some label is false. In the next step of our work, we will check the labels with the help of experts and weak supervised learning strategy (Zhou, 2018).\\n\\nEthics Statement\\n\\nWe envision MVSD as a pre-screening tool and not as an ultimate decision-maker. Though achieving the state-of-the-art, MVSD is still imperfect and needs to be used with care, in collaboration with human moderators to monitor or suspend suspicious movie reviews. Moreover, MVSD may inherit the biases of its constituents, since it is a combination of datasets and models. For instance, pretrained language models could encode undesirable social biases and stereotypes (Li et al., 2022; Nadeem et al., 2021). We leave to future work on how to incorporate the bias detection and mitigation techniques developed in ML research in spoiler detection systems. Given the nature of the task, the dataset contains potentially offensive language which should be taken into consideration.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\u20134186, Minneapolis, Minnesota. Association for Computational Linguistics.\\n\\nMatthias Fey and Jan Eric Lenssen. 2019. Fast graph representation learning with pytorch geometric. arXiv preprint arXiv:1903.02428.\\n\\nJennifer Golbeck. 2012. The twitter mute button: a web filtering challenge. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 2755\u20132758.\\n\\nSheng Guo and Naren Ramakrishnan. 2010. Finding the storyteller: Automatic spoiler tagging using linguistic cues. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 412\u2013420, Beijing, China. Coling 2010 Organizing Committee.\\n\\nWill Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems, 30.\\n\\nXu Han, Shulin Cao, Xin Lv, Yankai Lin, Zhiyuan Liu, Maosong Sun, and Juanzi Li. 2018. OpenKE: An open toolkit for knowledge embedding. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 139\u2013144, Brussels, Belgium. Association for Computational Linguistics.\\n\\nCharles R Harris, K Jarrod Millman, St\u00e9fan J Van Der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J Smith, et al. 2020. Array programming with numpy. Nature, 585(7825):357\u2013362.\\n\\nPengcheng He, Jianfeng Gao, and Weizhu Chen. 2021a. Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing.\\n\\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021b. Deberta: Decoding-enhanced bert with disentangled attention. In International Conference on Learning Representations.\\n\\nValentin Hofmann, Xiaowen Dong, Janet Pierrehumbert, and Hinrich Sch\u00fctze. 2022. Modeling ideological salience and framing in polarized online groups with graph neural networks and structured sparsity. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 536\u2013550, Seattle, United States. Association for Computational Linguistics.\\n\\nLinmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, and Ming Zhou. 2021. Compare to the knowledge: Graph neural fake news detection with external knowledge. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 754\u2013763, Online. Association for Computational Linguistics.\\n\\nZiniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous graph transformer. In WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020, pages 2704\u20132710. ACM / IW3C2.\\n\\nSungho Jeon, Sungchul Kim, and Hwanjo Yu. 2013. Don't be spoiled by your friends: spoiler detection in tv program tweets. In Proceedings of the International AAAI Conference on Web and Social Media, volume 7, pages 681\u2013684.\\n\\nThomas N. Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations.\\n\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghaemvandinejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871\u20137880.\\n\\nJunzhuo Li and Deyi Xiong. 2022. KaFSP: Knowledge-aware fuzzy semantic parsing for conversational question answering over a large-scale knowledge base. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 461\u2013473, Dublin, Ireland. Association for Computational Linguistics.\\n\\nYizhi Li, Ge Zhang, Bohao Yang, Chenghua Lin, Anton Ragni, Shi Wang, and Jie Fu. 2022. HERB: Measuring hierarchical regional bias in pre-trained language models. In Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022, pages 334\u2013346, Online only. Association for Computational Linguistics.\\n\\nBin Lian, Qinglin Zhu, Xiang Li, Min Yang, Lin Gui, Yulan He, and Ruifeng Xu. 2022. JointCL: A joint contrastive learning framework for zero-shot stance detection. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 81\u201391, Dublin, Ireland. Association for Computational Linguistics.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "emnlp-2023-main-995", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Wenqian Zhang, Shangbin Feng, Zilong Chen, Zhenyu Lei, Jundong Li, and Minnan Luo. 2022. KCD: Knowledge walks and textual cues enhanced political perspective detection in news media. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4129\u20134140, Seattle, United States. Association for Computational Linguistics.\\n\\nZhi-Hua Zhou. 2018. A brief introduction to weakly supervised learning. National science review, 5(1):44\u201353.\"}"}
{"id": "emnlp-2023-main-995", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 4: (a) The spoiler frequency of reviews with different ratings; (b) The spoiler frequency of reviews related to movies of different ratings; (c) The percentage of spoilers per user, spoiler review percentage intervals are divided every 10 percent.\\n\\nTable 8: Statistics of the Kaggle Dataset.\\n\\n| Type    | Number | Description                                                                 |\\n|---------|--------|------------------------------------------------------------------------------|\\n| review  | 573,913| The posting time is from 1998 to 2018.                                        |\\n| user    | 263,407| Users that posted these reviews.                                              |\\n| movie   | 1,572  | The released year is from 1921 to 2018.                                      |\\n| cast    | 7,865  | The cast related to the movies.                                               |\\n| spoiler | 150,924| 25.87% of the reviews are spoilers.                                            |\\n\\nTable 9: Details of metadata contained in the dataset.\\n\\n| Entity Name | Metadata                                         |\\n|-------------|--------------------------------------------------|\\n| Review      | time, helpful vote count, total vote count, score |\\n| User        | create at, badge count, review count             |\\n| Movie       | year, isAdult, runtime, rating, vote count       |\\n| Cast        | birth year, death year, involved movie count     |\\n\\nA Dataset Details\\n\\nWe adopt two graph-based spoiler detection datasets, namely Kaggle (Misra, 2019) and our curated LCS. The two datasets are both in English. The publicly available Kaggle dataset only provides incomplete information. Hence, we retrieved cast information based on the movie ids and collected user metadata based on user ids. The statics details of Kaggle after retrieving are listed in Table 8, and the statistics details of our LCS are listed in Table 2.\\n\\nA.1 Data Analysis\\n\\nWe compare LCS with another popular spoiler detection dataset Kaggle (Misra, 2019) and present our findings in Figure 4. We investigate the correlation between spoilers and individual review scores, overall movie ratings, and the behavior of different users. Firstly, we investigate the correlation between spoilers and review scores. Figure 4(a) shows that whether a review containing spoilers has a strong connection with how well the user considers the movie. Additionally, we find that whether a review contains spoilers is also related to the public opinion of the movie, which is illustrated in Figure 4(b). These findings suggest the necessity of leveraging metadata and external knowledge of movies. In addition, we study the fraction of reviews containing spoilers per user. As illustrated in Figure 4(c), the 'spoiler tendency' varies greatly among users. This suggests that it is essential to utilize the user information and how they interact with different movies on review websites.\\n\\nA.2 Metadata\\n\\nThe metadata we collected for both datasets is listed in Table 9.\\n\\nB KG Details\\n\\nThe types of relations, triples, and the number of them are presented in Table 10.\\n\\n| Relation Triple (head-rel.-tail) | Value |\\n|---------------------------------|-------|\\n| show_in                        | movie-show_in-year | 147,191 |\\n| rated                          | movie-rated-rating | 147,191 |\\n| genre_is                       | movie-genre_is-genre | 147,191 |\\n| is_director_of                 | person-is_director_of-movie | 129,483 |\\n| is_actor_of                    | person-is_actor_of-movie | 379,696 |\\n| is_actress_of                  | person-is_actress_of-movie | 226,775 |\\n| is_producer_of                 | person-is_producer_of-movie | 129,202 |\\n| is_writer_of                   | person-is_writer_of | 169,024 |\\n| is_editor_of                   | person-is_editor_of-movie | 49,817 |\\n| is_composer_of                 | person-is_composer_of-movie | 89,572 |\\n| is_production_designer_of      | person-is_production_designer_of-movie | 11,838 |\\n| is_archive_footage_of          | person-is_archive_footage_of-movie | 6,328 |\\n| is_cinematographer_of          | person-is_cinematographer_of-movie | 76,311 |\\n| is_archive_sound_of            | person-is_archive_sound_of | 205 |\\n| is_self_of                     | person-is_self_of-movie | 129,483 |\"}"}
{"id": "emnlp-2023-main-995", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: T-SNE visualization of representations of reviews learned by MVSD and R-GCN.\\n\\nWe learn a representation for each review, and the representations are passed to an MLP for classification.\\n\\nC.1 Baseline Details\\n\\nWe compare MVSD with pre-trained language models, GNN-based models, and task-specific baselines to ensure a holistic evaluation. For pre-trained language models, we pass the review text to the model, average all tokens, and utilize two fully connected layers to conduct spoiler detection. For GNN-based models, we pass the review text to RoBERTa, averaging all tokens to get the initial node feature. We provide a brief description of each of the baseline methods, in the following.\\n\\n- BERT (Devlin et al., 2019) is a language model pre-trained on a large volume of natural language corpus with the masked language model and next sentence prediction objectives.\\n- RoBERTa (Liu et al., 2019) improves upon BERT by removing the next sentence prediction task and improves the masking strategies.\\n- BART (Lewis et al., 2020) is a transformer encoder-decoder (seq2seq) language model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder.\\n- DeBERTa (He et al., 2021b) improves existing language models using disentangled attention and enhanced mask decoder.\\n- GCN (Kipf and Welling, 2017) is short for graph convolutional networks, which enables parameterized message passing between neighbors.\\n- R-GCN (Schlichtkrull et al., 2018) extends GCN to enable the processing of relational networks.\\n\\nTable 11: Hyperparameter settings of MVSD.\\n\\n| Hyperparameter          | Value |\\n|-------------------------|-------|\\n| GNN input size          | 768   |\\n| GNN hidden size         | 128   |\\n| GNN layer (in each MVSD layer) | 1 |\\n| MVSD layer L2 # epoch   | 120   |\\n| batch size              | 1,024 |\\n| dropout                 | 0.3   |\\n| learning rate           | 1e-3  |\\n| weight decay            | 1e-5  |\\n| lr_scheduler_patience   | 5     |\\n| lr_scheduler_step       | 0.1   |\\n| Optimizer               | AdamW |\\n\\n- SimpleHGN (Lv et al., 2021) is a simple yet effective GNN for heterogeneous graphs inspired by the GAT (Veli\u010dkovi\u0107 et al., 2018).\\n- DNSD (Chang et al., 2018) is a spoiler detection framework using a CNN-based genre-aware attention mechanism.\\n- SpoilerNet (Wan et al., 2019) extends the hierarchical attention network (HAN) (Yang et al., 2016) with item-specificity information and item and user bias terms for spoiler detection.\\n\\nC.2 Hyperparameter Details\\n\\nWe present our hyperparameter settings in Table 11 to facilitate reproduction. The setting for both datasets is the same.\\n\\nC.3 Computational Resources\\n\\nOur proposed approach has a total of 0.9M learnable parameters. It takes about 10 GPU hours to train our approach on the Kaggle dataset. We train our model on a Tesla V100 GPU. We conduct all experiments on a cluster with 4 Tesla V100 GPUs with 32 GB memory, 16 CPU cores, and 377GB CPU memory.\\n\\nC.4 Experiment Runs\\n\\nFor both datasets that have relatively large scales, we adopt the subsampling skill proposed in (Hamilton et al., 2017), which has been successfully used on large graphs (Velickovic et al., 2019). We conduct our approach and baselines five times on both datasets and report the average F1-score, AUC, and accuracy with standard deviation in Table 4. For\"}"}
{"id": "emnlp-2023-main-995", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Attention weights learned by our hierarchical attention. Subscript \\\\( v \\\\), \\\\( r \\\\) indicate the public nodes movie and review separately. \\\\( T, M, \\\\) and \\\\( K \\\\) refer to the textual view, the meta view, and the external knowledge view, respectively. This violin plot illustrates the different contributions of each view and subgraph and the process of interaction.\\n\\nIn the experiments in Table 5, Table 6, and Figure 3, we only report the single-run result in the Kaggle dataset due to the lack of computational resources.\\n\\nC.5 Visualization\\nTo intuitively demonstrate the effectiveness of our representation method, we utilize T-SNE (Van der Maaten and Hinton, 2008) to visualize the representations of movie reviews learned by different models. Specifically, we choose our proposed MVSD and R-GCN (with the second highest performance) and evaluate them on the validation set of the small dataset. It can be observed in Figure 5b that the learned representations of different kinds are relatively mixed together. In contrast, representations learned by MVSD show moderate collocation for both groups of reviews. This illustrates that MVSD yields improved and more comprehensive representation with the effective use of multi-view data and user interaction networks.\\n\\nC.6 Contribution of Views and Subgraphs\\nWe introduce semantic, meta, and external knowledge views and utilize user-review, movie-review, and knowledge subgraph structures to represent multi-information. To further study the contribution of different views and subgraph. We extract the attention weight from the View-level attention layers and Subgraph-level attention layers and illustrate them in violin plots. We select representative features and present them in Figure 6. The four violin plots demonstrate that our proposed hierarchical attention can select the more important features from the variation of attention weight between the first and the second layer, indicating that the contributions of certain representations are varied as they capture features via the graph structure and attention mechanism.\\n\\nD Significance Testing\\nTo further evaluate MVSD\u2019s performance on both datasets, we apply one way repeated measures ANOVA test for the results in Table 4. The result demonstrates that the performance gain of our proposed model is significant on both datasets against the second-best R-GCN on all three metrics with a confidence level of 0.05.\\n\\nE Scientific Artifact Usage\\nThe MVSD model is implemented with the help of many widely-adopted scientific artifacts, including PyTorch (Paszke et al., 2019), NumPy (Harris et al., 2020), transformers (Wolf et al., 2020), sklearn (Pedregosa et al., 2011), OpenKE (Han et al., 2018), PyTorch Geometric (Fey and Lenssen, 2019). We utilize data from IMDB and following the requirement of IMDB, we acknowledge the source of the data by including the following statement: Information courtesy of IMDb (https://www.imdb.com). Used with permission. Our use of IMDb data is non-commercial, which is allowed by IMDB. We will make our code and data publicly available to facilitate reproduction and further research.\"}"}
