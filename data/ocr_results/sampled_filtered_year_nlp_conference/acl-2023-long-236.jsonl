{"id": "acl-2023-long-236", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Create possible Specific Goals according to the Abstract Goal when the Constraint Type is XXX\\n\\nExample 1:\\nAbstract Goal: Say Goodbye in Different Language\\nConstraint: French\\nSpecific Goal: Say Goodbye in French\\nConstraint: English\\nSpecific Goal: Say Goodbye in English\\n\\nExample 2:\\nAbstract Goal: Draw flowers\\nConstraint: Pink\\nSpecific Goal: Draw pink flowers\\nConstraint: Blue\\nSpecific Goal: Draw blue flowers\\n\\nExample 3:\\nAbstract Goal: Make hairstyle\\nConstraint: At home\\nSpecific Goal: Make hairstyle at home\\nConstraint: At a salon\\nSpecific Goal: Make hairstyle at a salon\\n\\nConstraint Type: Method\\nExample 1:\\nAbstract Goal: Lower blood pressure\\nConstraint: With medication\\nSpecific Goal: Lower blood pressure with medication\\nConstraint: With exercises\\nSpecific Goal: Lower blood pressure with exercises\\n\\nExample 2:\\nAbstract Goal: Write a book\\nConstraint: By hand\\nSpecific Goal: Write a book by hand\\nConstraint: By typing\\nSpecific Goal: Write a book by typing\\n\\nExample 3:\\nAbstract Goal: Register to vote\\nConstraint: Online\\nSpecific Goal: Register to vote online\\nConstraint: Via mail\\nSpecific Goal: Register to vote via mail\\n\\nConstraint Type: Intent\\nExample 1:\\nAbstract Goal: Make a cake\\nConstraint: For a birthday party\\nSpecific Goal: Make a cake for a birthday party\\nConstraint: For a wedding\\nSpecific Goal: Make a cake for a wedding\\n\\nExample 2:\\nAbstract Goal: Send an email\\nConstraint: To get a gob\\nSpecific Goal: Send an email to get a gob\\nConstraint: For leave\\nSpecific Goal: Send an email for leave\\n\\nExample 3:\\nAbstract Goal: Buy flowers\\nConstraint: For girlfriend\\nSpecific Goal: Buy flowers for girlfriend\\nConstraint: For mother\\nSpecific Goal: Buy flowers for mother\\n\\nTable 13: The handpicked examples for specific goal generation.\\n\\nTable 14: The generation comparison between InstructGPT (175B) with our method. We highlight the constraints in the given examples.\"}"}
{"id": "acl-2023-long-236", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract Goal Constraints and Specific Goal\\n\\nAsk a teacher for help\\nConstraint: Math\\nSpecific Goal: Ask a math teacher for help\\n\\nConstraint: Science\\nSpecific Goal: Ask a science teacher for help\\n\\nConstraint: In school\\nSpecific Goal: Ask a teacher for help in school\\n\\nMake pancakes\\nConstraint: Banana\\nSpecific Goal: Make banana pancakes\\n\\nConstraint: Chocolate chip\\nSpecific Goal: Make chocolate chip pancakes\\n\\nDownload an Xbox 360 game\\nConstraint: Halo 3\\nSpecific Goal: Download Halo 3 for Xbox 360\\n\\nConstraint: Gears of War\\nSpecific Goal: Download Gears of War for Xbox 360\\n\\nPrevent kidney stones from recurring\\nConstraint: By eating a healthy diet\\nSpecific Goal: Prevent kidney stones from recurring by eating a healthy diet\\n\\nConstraint: By taking medication\\nSpecific Goal: Prevent kidney stones from recurring by taking medication\\n\\nSew chain stitch\\nConstraint: With a sewing machine\\nSpecific Goal: Sew Chain Stitch with a sewing machine\\n\\nConstraint: By hand\\nSpecific Goal: Sew chain stitch by hand\\n\\nSay goodbye in Spanish\\nConstraint: Formally\\nSpecific Goal: Say goodbye in Spanish formally\\n\\nConstraint: Informally\\nSpecific Goal: Say goodbye in Spanish informally\\n\\nTable 15: Qualitative generations for specific goals when the type of constraints is Modifier.\\n\\nTable 16: Qualitative generations for specific goals when the type of constraints is Method.\"}"}
{"id": "acl-2023-long-236", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract Goal Constraints and Specific Goal\\n\\nUse clary sage\\n\\nConstraint: For aromatherapy\\nSpecific Goal: Use clary sage for aromatherapy\\n\\nConstraint: For skin care\\nSpecific Goal: Use clary sage for skin care\\n\\nConstraint: For hair care\\nSpecific Goal: Use clary sage for hair care\\n\\nMake carrot oil\\n\\nConstraint: For skin\\nSpecific Goal: Make carrot oil for skin\\n\\nConstraint: For cooking\\nSpecific Goal: Make carrot oil for cooking\\n\\nAcquire abandoned property\\n\\nConstraint: For personal use\\nSpecific Goal: Acquire abandoned property for personal use\\n\\nConstraint: For business use\\nSpecific Goal: Acquire abandoned property for business use\\n\\nTable 17: Qualitative generations for specific goals when the type of constraints is Intent.\\n\\nAbstract Goal: Link social media accounts on flipboard\\nSpecific Goal: Link facebook accounts on flipboard\\nSpecific Goal: Link twitter accounts on flipboard\\n\\nScript:\\n1. Launch Flipboard.\\n2. Go to Content.\\n3. Go to Accounts.\\n4. Select Facebook.\\n\\nScript:\\n1. Launch Flipboard.\\n2. Go to Content.\\n3. Go to Accounts.\\n4. Select Twitter.\\n5. Log into your Twitter account.\\n\\nAbstract Goal: Increase your metabolism\\nSpecific Goal: Increase your metabolism with medication\\nSpecific Goal: Increase your metabolism with diet\\n\\nScript:\\n1. Talk to your doctor about prescription options.\\n2. Follow your doctor's instructions carefully.\\n3. Stay hydrated\\n\\nScript:\\n1. Eat small, frequent meals throughout the day.\\n2. Choose lean proteins.\\n3. Add spice to your favorite foods.\\n\\nAbstract Goal: Use clary sage\\nSpecific Goal: Use clary sage for aromatherapy\\nSpecific Goal: Use clary sage for massage\\n\\nScript:\\n1. Make a clary sage and lavender sachet to keep in your pillowcase.\\n2. Diffuse clary sage oil to boost your mood and energy levels.\\n3. Add a few drops of clary sage oil to your bathtub for a relaxing soak\\n\\nScript:\\n1. Heat clary sage oil until it is warm.\\n2. Massage the oil into the muscles and tissues.\\n3. Leave the oil on for at least 30 minutes.\\n4. Rinse the oil off with warm water.\\n\\nTable 18: Qualitative generations for scripts under the different constraints.\"}"}
{"id": "acl-2023-long-236", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thanks for participating in this HIT! Please spend some time reading this instruction and the example section to better understand our HIT!\\n\\nIn this HIT, you need to complete 20 data labeling tasks. In each task, you will be presented a general goal about everyday activities (such as \u201cmake a cake\u201d) and a specific goal which inherits the general goal but is more specific and has a reasonable constraint (such as \u201cmake a chocolate cake\u201d). You will answer 3 questions for each task.\\n\\nQuestion 1\\nIn Question 1, you need to assess whether the specific goal is reasonable. For example, making a chocolate cake is a reasonable constraint of making a cake, whereas making a lego cake is not reasonable.\\n\\nQuestion 2\\nThen, you will read a script of the specific goal with actionable steps (in the cake\u2019s example, the script is the steps towards making a cake). Question 2 is to check whether the script MEETS THE CONSTRAINT. If the specific goal is making a chocolate cake and the script does not mention chocolate, then it does not meet the constraint.\\n\\nQuestion 3\\nIn Question 3, you will assess whether the script can indeed accomplish the given goal. If the script cannot accomplish the given goal, you need to point out the wrong steps and SELECT THE ERROR TYPES. A script for making chocolate cake might mention chocolate, but if its making instructions are wrong, then you need to reflect it in Question 3.\\n\\nNotes:\\n\u2022 A general goal involves STEREOTYPICAL ACTIVITIES such as \u201cmake a cake\u201d, while a specific goal can be multi-facet with a reasonable constraint.\\n  - For example, a cake can be made for different purposes (for a wedding or a birthday party), with various tools (with a microwave or an oven) or with different ingredients (chocolate or vanilla).\\n\u2022 If you think the specific goal is not reasonable, choose NO in Question 1, but still proceed with Question 2 and 3 pretending that it is reasonable. For example, making a LEGO cake is not reasonable, but you can still assess whether the corresponding script meets the constraint or not. Remember you can always choose \u201cI am not sure\u201d.\\n\u2022 You SHOULD NOT ignore grammar and spelling mistakes in the script.\\n\u2022 You can SEARCH GOOGLE to help you judge whether the script can achieve the goal, especially if you are not sure about the script.\\n\\nExample of Error Types\\nSpecific Goal: Make A Vanilla Cake\\nScript:\\n1. Gather your ingredients.\\n2. Preheat the oven to 325 \u00b0F (163 \u00b0C) and grease and flour a cake pan.\\n3. Cream the butter and sugar.\\n4. Add the eggs and vanilla.\\n5. Stir in the cake flour.\\n6. Pour the batter into the pan.\\n7. Bake the cake for 1 hour 15 minutes.\\n\\nGolden Script\\nExplanation\\nWrong order\\nRepeat steps\\nIncoherent steps\\nUnrelated steps\\nMissing steps\\nOthers: \\n(Describe what you think is wrong)\\n\\nWrong Script\\nSteps that are in the wrong order\\nSteps that are repeated in the script\\nSteps that are related to the goal, but are not coherent within the script\\nSteps that are not related to the goal\\nImportant steps that are missing\\n\\nD I certify that I have read and understand all the instructions.\"}"}
{"id": "acl-2023-long-236", "page_num": 21, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"General Goal: Make A Cake  \\nSpecific Goal: Make An Apple Cake\\n\\nQuestion 1\\nRead the given goal. Does the Specific Goal inherit the General Goal and contain a CONSTRAINT (Apple)?\\n\\nQuestion 2\\nSpecific Goal: Make An Apple Cake\\nScript:\\n1. Gather your ingredients.\\n2. Preheat the oven to 350 \u00b0F (177 \u00b0C) and grease and flour the cake pan.\\n3. In a large bowl, mix the dry ingredients.\\n4. Cut the apples into small pieces and add them to the bowl.\\n5. Pour the batter into the cake pan.\\n6. Bake the cake for 1 hour.\\n7. Take the cake from the oven and let it cool.\\n8. Serve\\n\\nRead the script. Does the script meet the CONSTRAINT in the Specific Goal?\\n\\nQuestion 3\\nRead the script. Are the steps in the script correct in achieving the Specific Goal?\\n\\nPlease refer to the instructions for error types.\"}"}
{"id": "acl-2023-long-236", "page_num": 22, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ACL 2023 Responsible NLP Checklist\\n\\nA For every submission:\\n\\nA1. Did you describe the limitations of your work?\\n\\n\u25a1\\n\\nA2. Did you discuss any potential risks of your work?\\n\\n\u25a1\\n\\nA3. Do the abstract and introduction summarize the paper's main claims?\\n\\n\u25a1\\n\\nA4. Have you used AI writing assistants when working on this paper?\\n\\nCheck grammar for the whole paper.\\n\\nB Did you use or create scientific artifacts?\\n\\n\u25a1\\n\\nB1. Did you cite the creators of artifacts you used?\\n\\nSection 4.1\\n\\n\u25a1\\n\\nB2. Did you discuss the license or terms for use and / or distribution of any artifacts?\\n\\nSection 4.1 and Section 5.1 and Appendix C.1\\n\\n\u25a1\\n\\nB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\\n\\nSection 4.1 and Section 5.1 and Appendix C.1\\n\\n\u25a1\\n\\nB4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?\\n\\nEthics Statement\\n\\n\u25a1\\n\\nB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?\\n\\nSection 5\\n\\n\u25a1\\n\\nB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.\\n\\nSection 5\\n\\n\u25a1\\n\\nC Did you run computational experiments?\\n\\n\u25a1\\n\\nC1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?\\n\\nSection 4.4 and Section 6.1 and Appendix C.1\\n\\n\u25a1\\n\\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\"}"}
{"id": "acl-2023-long-236", "page_num": 23, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?\\n\\nNo response.\\n\\nC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run?\\n\\nNo response.\\n\\nC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?\\n\\nNo response.\\n\\nD. Did you use human annotators (e.g., crowdworkers) or research with human participants?\\n\\nAppendix D\\n\\nD1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.?\\n\\nAppendix D\\n\\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?\\n\\nEthics Statement\\n\\nD3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?\\n\\nAppendix D\\n\\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\\n\\nWe do not have any human subjects research and use filtered model-generated data as datasets.\\n\\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?\\n\\nEthics Statement\"}"}
{"id": "acl-2023-long-236", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nIn everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., \\\"make a cake\\\"), but leaves more specific goals with multi-facet constraints understudied (e.g., \\\"make a cake for diabetics\\\"). In this paper, we define the task of constrained language planning for the first time. We propose an over-generate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.\\n\\n1 Introduction\\n\\nTo accomplish everyday goals, humans usually plan their actions in accordance with step-by-step instructions. Such instructions are discovered as goal-oriented scripts (Schank and Abelson, 1975, 2013), involving a set of prototypical event sequences to achieve goals. For the example in Figure 1, to achieve the goal (\\\"make a cake\\\"), one usually has to follow certain steps of instructions, e.g., gather ingredients, preheat the oven, etc. The planning for such step-by-step scripts chains up reasoning toward complex goals (Abelson, 1976; Wei et al., 2022). Therefore, the automation of planning envisions more intelligent and reasonable AI systems in various domains, such as executable robotic systems (Kovalchuk et al., 2021; Huang et al., 2022) and reasoning systems for problem-solving (Wei et al., 2022; Wang et al., 2022).\\n\\nRecent studies have identified that language models (LMs) can be used to plan scripts (Sancheti and Rudinger, 2022). Previous work (Huang et al., 2022) has shown that large language models (LLMs), such as GPT-3 (Brown et al., 2020) InstructGPT (Ouyang et al., 2022) and PaLM (Chowdhery et al., 2022), can effectively decompose goals into procedural steps in a zero-/few-shot manner. To train specialized models, researchers have proposed datasets for the automatic understanding and generation of script knowledge (Schank and Abelson, 1975; Regneri et al., 2010; Wanzare et al., 2016; Lyu et al., 2021; Sak-\"}"}
{"id": "acl-2023-long-236", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"aguchi et al., 2021). However, previous work mainly focuses on planning for the abstract goals of stereotypical activities (Abelson, 1976). Planning for goals with specific constraints (e.g., for diabetics) still remains under-studied.\\n\\nIn this paper, we define the problem of constrained language planning, which imposes different constraints on the goals of planning. An abstract goal, for example, make a cake, can be inherited by different real-life specific goals with multi-faceted constraints. A cake can be made for 1) different ingredients (e.g., chocolate or vanilla); 2) various tools (e.g., with a microwave or an oven); or 3) different purposes (e.g., for a wedding or a birthday party). A good planner should write scripts that are reasonable and faithful to constraints. However, LLMs sometimes do not plan faithfully toward the constraints. As showcased in Figure 1, InstructGPT suggests adding sugar to the cake for diabetic patients. Also, due to a shortage of datasets for constrained language planning, the ability of smaller but specialized models to plan with specific constraints has been underexplored.\\n\\nIn this paper, we aim to evaluate and improve the constrained language planning ability of LLMs, while distilling a dataset from LLMs to train specialized models. Our empirical study finds that LLMs tend to plan fluently but unfaithfully to the constraints. Thus, we employ an over-generate-then-filter approach (Wiegreffe et al., 2022) to satisfy the quality of the generated scripts to constraints. The main idea is to select high-quality ones from multiple generated scripts. Then, we use LLMs (e.g., InstructGPT) with this approach to generate a dataset for constrained language planning, which inherits the idea of symbolic knowledge distillation from models (West et al., 2022). We thus arrive at a CostraneScript dataset, i.e., CoScript, which consists of 55,000 high-quality scripts with specific goals and steps. Experiments show that, when trained on CoScript, smaller models such as T5 (Raffel et al., 2020) can achieve good performance, even surpassing that of LLMs.\\n\\nOur contributions are summarized as follows: 1) To our knowledge, we are the first to establish the constrained language planning problem, which advances language planning toward more specific goals. 2) We evaluate the few-shot constrained language planning ability of LLMs and develop an over-generate-then-filter method for LLMs, resulting in a 26% increase in accuracy. 3) Based on our method, we use LLMs to generate a high-quality script dataset (CoScript) for constrained language planning. By leveraging the CoScript, we endow specialized and smaller models with constrained language planning ability, which achieves comparable performance to that of LLMs.\"}"}
{"id": "acl-2023-long-236", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Constraint Type 1: Modifier\\nDefinition: A word, an adjective or a phrase that modifies or constrains an abstract goal.\\nEx.1: Make a chocolate cake.\\nEx.2: Make a pink cake.\\n\\nConstraint Type 2: Method\\nDefinition: A tool or specified mode that controls the process for achieving the goal.\\nEx.1: Make a cake with an oven.\\nEx.2: Make a cake by using cake mix.\\n\\nConstraint Type 3: Intent\\nDefinition: An additional purpose or demand when completing the goal.\\nEx.1: Make a cake for wedding.\\nEx.2: Make a cake for diabetics.\\n\\nTable 1: Three types of constraints and their definitions that are used to prompt for new instances of specific goals. In the examples (Ex.), upon the abstract goal, we give two instances for each type of constraint by combining the goal with constraints into specific goals. The constraint within each example is highlighted.\\n\\nIn-Context Learning\\nWith the great success of LLMs (Brown et al., 2020; Ouyang et al., 2022; Chowdhery et al., 2022), in-context learning (Brown et al., 2020; Min et al., 2022) has established its great task-solving potentials with a textual task instruction and a few examples. Moreover, when being used for dataset construction, the data samples that LLMs generate can sometimes outperform crowd-sourced human-authored data in factuality and fluency (Lu et al., 2022a; Min et al., 2022). This shows a promising alternative to costly large-scale crowd-sourcing to construct datasets using LLMs (Wiegreffe et al., 2022; Liu et al., 2022a; West et al., 2022). Inspired by these studies, in our work, we adopt the in-context learning for LLMs not only for better language planning, but also as a reliable crowd-worker to scale up the planning data into a reusable dataset to train smaller models.\\n\\n3 Definitions\\nBefore diving into technical details, we first clarify some important terms used in the paper.\\n\\nScripts\\nA goal-oriented script is a list of steps \\\\(S = \\\\{s_1, s_2, \\\\ldots, s_n\\\\}\\\\) that fulfill a certain goal \\\\(G\\\\) (e.g., \\\"make a cake\\\") (Suddendorf and Corbalis, 2007; Schank and Abelson, 2013). The language planning task is defined as \\\\(M: G \\\\rightarrow S\\\\), where \\\\(M\\\\) is the planning model.\\n\\nGoals\\nDifferent from previous studies that focus mostly on abstract goals with prototypical scripts, we define a taxonomic structure of goals by extending the derivatives of abstract goals. We define a specific goal that inherits from an abstract one but with new information as a constraint to limit the scope. An abstract goal, denoted as \\\\(G_a\\\\), refers to stereotypical activities, e.g., \\\"make a cake\\\". A specific goal, denoted as \\\\(G_c\\\\), is derived from the corresponding \\\\(G_a\\\\) with various constraints, e.g., \\\"make a chocolate cake\\\".\\n\\nConstraints and Constrained Language Planning\\nTo enrich the semantics of specific goals, we define three types of constraints, i.e., modifier, method, and intent, as shown in Table 1. They express different angles of extending an abstract goal and can be further instantiated and concreted. Constrained language planning denotes generating a constraint-faithful script \\\\(S = M(G_c)\\\\) toward specific goals \\\\(G_c\\\\) with various constraints \\\\(C\\\\).\\n\\n4 Constrained Language Planning with LLMs\\nIn this section, we evaluate and enhance the constraint language planning ability of LLMs. The overall workflow is illustrated in Figure 2. We first extend the specific goals \\\\(G_c\\\\) from the abstract ones \\\\(G_a\\\\) using a human-in-the-loop acquisition approach with LLMs (\u00a74.2, Step 1), and propose an over-generate-then-filter framework to...\"}"}
{"id": "acl-2023-long-236", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"I: Specific Goal Generation\\n\\n/* Task prompt */\\nCreate possible Specific Goals according to the Abstract Goal when the Constraint Type is Modifier.\\n\\n/* Examples */\\n\\nAbstract Goal: Say Goodbye in Different Language\\nConstraint: French;\\nSpecific Goal: Say Goodbye in French\\nConstraint: English;\\nSpecific Goal: Say Goodbye in English\\n\\n/* Auto completion of constraints and specific goals */\\n\\nAbstract Goal: Make a cake\\nConstraint: Chocolate;\\nSpecific Goal: Make a chocolate cake\\nConstraint: Vanilla;\\nSpecific Goal: Make a vanilla cake\\n\\nII: Script Generation\\n\\n/* Task prompt */\\nList the steps of making a cake based on Constraint and Specific Goal.\\n\\n/* Examples */\\n\\nGoal: Make a cake\\nSteps: 1. Gather your ingredients. 2. . . .\\nGoal: Make a cupcake\\nSteps: 1. Decide on a pattern. 2. . . .\\n\\n/* Auto-completion of script for a specific goal */\\n\\nConstraint: Chocolate;\\nSpecific Goal: Make a chocolate cake\\nSteps: 1. Gather ingredients. ... 4. Add the cocoa powder...\\n\\nTable 2: Examples of prompt for InstructGPT for specific goal generation and script generation via in-context learning. Generated texts are highlighted.\\n\\nWe deploy LLMs for constrained language planning via in-context learning (Brown et al., 2020; Ouyang et al., 2022). Given a task input ($X$), we first write a task prompt ($T$) describing the task, and then provide several examples ($E = \\\\{E_i\\\\}$ where $E_i = (X_i, Y_i)$ are used for few-shot learning). An LLM generates output ($Y$) by completing the prompt ($Y = M(T,E,X)$). The whole process does not require any gradient update, allowing LLMs to generate new specific goals and scripts without massive training data.\\n\\nWe adopt wikiHow (Koupaee and Wang, 2018), a data source of instructional articles on various topics, as the initial dataset for providing examples. The articles are titled as \\\"how to ...?\\\", describing abstract goals, and consist of steps to achieve them. We use the titles ($G_a$) and steps ($S$) as examples.\\n\\n4.2 Acquisition of Specific Goals\\n\\nSince no dataset of specific goals exists to support our study, we have to acquire these goals first. As elaborated in Table 1, we extend the abstract goals with multi-faceted constraints for human-in-the-loop data acquisition using InstructGPT.\\n\\nFirst, we manually prepare a pool of examples that derive specific goals from an abstract one with constraints. Each example is attached to a constraint type (i.e., modifier, method or intent), and contains more than one constraint and specific goal so that InstructGPT is prompted to generate multiple $G_c$ for one $G_a$. Next, given an abstract goal from wikiHow, we enumerate each constraint type to ensure data diversity. Then, we sample several examples of the constraint type from the pool. Finally, we input the task prompt, examples and the $G_a$ into InstructGPT for the completion of $G_c$.\\n\\nAn example in Table 2 (I) shows InstructGPT generates constraints \\\"chocolate\\\" and \\\"vanilla\\\" for $G_a (\\\"make a cake\\\")$ given the constraint type modifier and some examples, and completes the specific goals (\\\"make a chocolate cake\\\" and \\\"make a vanilla cake\\\").\\n\\n4.3 Acquisition of Scripts\\n\\nAfter getting specific goals with constraints, we can test the ability of LLMs to fulfill them.\\n\\nPlanning with InstructGPT\\n\\nWe first write a task prompt $T$. Given the $G_c$, we back-trace its $G_a$ and extract the verbs (\\\"make\\\") and nouns (\\\"cake\\\") from $G_a$. Then we use the verbs and nouns as keywords to retrieve two similar goals as examples $E$ from the wikiHow dataset. Finally, the task prompt $T$, examples $E$ and $G_c$ with constraint $C$ are fed into InstructGPT. As shown in Table 2 (II), we adopt the scripts, i.e., \\\"make a cake\\\" and \\\"make a cupcake\\\" to prompt InstructGPT to generate a script for \\\"make a chocolate cake\\\".\\n\\n4.4 Over-Generation and Filtering\\n\\nUsing the above-mentioned approach, generated scripts by LLMs are prone to be unfaithful to the constraints in $G_c$, and our approach can alleviate this problem. We use text-davinci-002 as the default InstructGPT variant, which has $\\\\geq 175$B parameters.\\n\\nData Source for Examples\\n\\nWe adopt wikiHow (Koupaee and Wang, 2018), a data source of instructional articles on various topics, as the initial dataset for providing examples. The articles are titled as \\\"how to ...?\\\", describing abstract goals, and consist of steps to achieve them. We use the titles ($G_a$) and steps ($S$) as examples.\\n\\n4.5 In-Context Learning for LLMs\\n\\nWe deploy LLMs for constrained language planning via in-context learning (Brown et al., 2020; Ouyang et al., 2022). Given a task input ($X$), we first write a task prompt ($T$) describing the task, and then provide several examples ($E = \\\\{E_i\\\\}$ where $E_i = (X_i, Y_i)$ are used for few-shot learning). An LLM generates output ($Y$) by completing the prompt ($Y = M(T,E,X)$). The whole process does not require any gradient update, allowing LLMs to generate new specific goals and scripts without massive training data.\\n\\nCode names and approximated parameters of GPT-3 models are based on https://blog.eleuther.ai/gpt3-model-sizes/ and https://beta.openai.com/docs/models. Note that OpenAI does not release detailed information about later versions of GPT-3, and thus for brevity, we default its size to 175B.\\n\\nComplete examples can be found in Appendix B.1.\"}"}
{"id": "acl-2023-long-236", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"InstructGPT are reasonable and fluent. However, they sometimes are not faithful to the constraints under closer examination (\u00a74.4). Previous studies have shown that the output quality of LLMs falls in high variance (Wiegreffe et al., 2022), leading to bad performance. Thus, we adopt the idea of over-generate-then-filter to improve generation quality, which is shown to be effective in previous work (Wiegreffe et al., 2022; Liu et al., 2022a). We over-generate $K$ sample from InstructGPT. Next, a filter model is developed to select the faithful scripts. Due to the diverse expressions of language, we rely not on rules and patterns (i.e., constraint words must appear in the script), but on the semantic similarity between goals and scripts for filtering. For example, \u201cdecorating the cake with candles\u201d could be a faithful step to make a cake \u201cfor a birthday party\u201d. Motivated by this, we first collect a set of goals, consisting of the target goal ($G^+_c$) as a positive sample and others ($\\\\{G^-_c\\\\}$) generated from the same abstract goal ($G_a$) as negative samples. In the previous case, the negatives include \u201cmake a cake in the microwave\u201d and \u201cmake a cake for a wedding\u201d. We convert scripts and goals into InstructGPT embeddings (text-embedding-ada-002) and calculate cosine similarity as similarity scores to measure semantic similarity. Additionally, we reward the script that explicitly contains the keywords of the target constraint. We only keep the script if $G^+_c$ scores the highest in the goal set.\\n\\n### 4.4 Evaluation\\n\\nWe randomly collect 100 abstract goals (e.g., \u201cmake a cake\u201d) from wikiHow and conduct manual evaluations on the generated specific goals and their scripts. We compare our methods with instruction tuning methods, T0 (Sanh et al., 2022) and Flan-T5 (Chung et al., 2022), vanilla GPT-3 (Ouyang et al., 2022) with different sizes, Codex (Chen et al., 2021) and InstructGPT (Ouyang et al., 2022) with different sizes. We also add \u201cLet\u2019s think step by step\u201d before each answer for script generation, which is a simple but effective trick to improve zero-shot reasoning for LLMs (Kojima et al., 2022). For a retrieval baseline, we directly use the goals to search and retrieve the most relevant scripts from 4. In practice, $K = 2$ is sufficient, as shown in Appendix B.3. Intuitively, the reason this approach works is that the generation accuracy can be improved from $1 - p$ to $1 - p^K$ (at least one is correct), where $p$ is the probability that InstructGPT generates a wrong script.\\n\\n| Model Modifier Method | Intent | All |\\n|-----------------------|--------|-----|\\n| Retrieval             | 26.67  | 38.89 | 35.71 | 34.00 |\\n| T0 (11B)              | 30.00  | 21.12 | 25.00 | 24.00 |\\n| Flan-T5 (11B)         | 50.00  | 42.25 | 31.25 | 42.00 |\\n| GPT-3 (1.3B)          | 13.33  | 12.96 | 18.75 | 14.00 |\\n| GPT-3 (6.7B)          | 23.33  | 7.40  | 25.00 | 15.00 |\\n| GPT-3 (175B)          | 30.00  | 22.22 | 25.00 | 25.00 |\\n| Codex (175B)          | 46.67  | 55.56 | 18.75 | 47.00 |\\n| InstructGPT (1.3B)    | 20.00  | 22.22 | 28.57 | 22.00 |\\n| InstructGPT (6.7B)    | 60.00  | 42.25 | 43.75 | 47.00 |\\n| InstructGPT (175B)    | 73.33  | 74.08 | 42.86 | 69.00 |\\n| + \u201clet's think step...\u201d | 70.00  | 75.92 | 50.00 | 68.00 |\\n| + Our Method w/ $f_{sim} = $ SBERT | 86.66 | 74.89 | 81.25 | 78.00 |\\n| + Our Method w/ $f_{sim} = $ SimCSE | 73.33 | 78.73 | 75.00 | 75.00 |\\n| + Our Method w/ $f_{sim} = $ None | 93.33 | 94.44 | 87.50 | 93.00 |\\n\\nTable 3: Accuracy (%) of generated scripts for different constraint types by manual evaluation. $f_{sim}$ denotes the choice for similarity function during filtering, i.e., replacing InstructGPT embedding with that of SimCSE (Gao et al., 2021) and Sentence-BERT (Reimers and Gurevych, 2019). $f_{sim} = $ None denotes we only reserve the scripts that contain constraint words.\\n\\nAre specific goals generated by LLMs of high quality? We ask InstructGPT to generate 300 ($3 \\\\times 3$) specific goals for 3 constraint types based on the 100 abstract goals from wikiHow. For evaluation, we recruit annotators on Amazon Mechanical Turk to check whether these goals are correct. Each case is examined by three annotators, who reach an inter-rater agreement at Fleiss's $\\\\kappa = 0.86$ (Fleiss et al., 1981). InstructGPT achieves 98.00% accuracy, indicating that LLMs can derive specific goals of rather high quality.\\n\\nCan LLMs write scripts for specific goals? To answer this question, we first let InstructGPT generate scripts for the 100 abstract goals from wikiHow and ask three annotators to check the correctness of the scripts (with Fleiss's $\\\\kappa = 0.79$). The correctness is decided by both the fulfillment of the goal and the completeness of the semantics. InstructGPT achieves 97.00% accuracy, proving that LLMs can plan for abstract goals very well. However, it is not the case for specific goals. We sample 100 specific goals from 300 generated ones (mentioned above) and evaluate the scripts generated from baselines and our method. Table 3 reports the overall accuracy of the results.\\n\\n[https://www.wikihow.com/Main-Page](https://www.wikihow.com/Main-Page)\"}"}
{"id": "acl-2023-long-236", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 3: Errors of the generated scripts by human evaluation. The axis of the radar chart is in log-scale. Notably, ours reduces to virtually one dot in the graphic because it does not have many errors (0-1%). SE and FE denote semantic completeness and faithfulness error.\\n\\nWe find that:\\n1) Overall, all baselines achieve unsatisfactory results on planning for specific goals, with InstructGPT outperforming others. Especially, the scripts with intent-type constraints have the worst accuracy, and adding \\\"let's think step-by-step\\\" does not help much;\\n2) The retrieval from wikiHow does not lead to the desired script;\\n3) With our method, InstructGPT can generate scripts of higher quality by a large margin;\\n4) Replacing the similarity function with embeddings from other pre-trained models results in performance drops.\\n\\nWhat types of errors do LLMs usually make in this task?\\n\\nTo respond to the motivations of our methods, we conduct detailed analyses to investigate why LLMs fail. We evaluate the model planning performance in two aspects:\\n1) Semantic completeness (SE): whether the steps in the script are missing, repeated or in the wrong order;\\n2) Faithfulness to the constraints (FE): whether the script is faithful to the constraints and the steps are coherent (related) within the script.\\n\\nWe define six types of errors upon the two, i.e.,\\n- SE: missing, repeated step(s) and wrong order\\n- FE: no constraint, unrelated step(s) or incoherent step(s).\\n\\nAnnotators are asked to review 100 scripts generated by InstructGPT and mark the error types. Results in Figure 3 show that:\\n1) The semantic completeness in generated scripts is acceptable, but the faithfulness to the constraints can not be guaranteed;\\n2) Our method greatly improves the planning quality both in semantic completeness and faithfulness.\\n\\nWhat kinds of goals do InstructGPT typically fail?\\nBy far, we already know that LLMs fail at specific goals, especially for intent-type constraints. We dig into more fine-grained topic categories of constraints defined in wikiHow. The heat map in Figure 4 shows that the planning performance of InstructGPTs varies considerably for goals of different categories, and the planning accuracy for each category improves greatly with our method.\"}"}
{"id": "acl-2023-long-236", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Statistics of CoScript and previous script datasets, w.r.t. data size, number of unique tokens (# UT), the average number of specific goals for each abstract ones (Avg Gc #), and the average number of steps in scripts (Avg S #).\\n\\n| Dataset    | Size   | UT Avg | Gc # Avg | S # Avg |\\n|------------|--------|--------|----------|--------|\\n| proScript  | 6,414  |        | 0        | 5.45   |\\n| wikiHow    | 112,111| 0.42   |          | 5.93   |\\n| CoScript   | 55,000 |        | 4.13     | 5.96   |\\n\\nTable 5: Statistics of constraint types in CoScript dataset, with representative topic categories or the first words for each constraint type.\\n\\n- Modifier: 45.05%\\n- Method: 36.88%\\n- Intent: 18.07%\\n- Ingredient: 21.57%\\n- Color: 10.79%\\n- Device\\n- Date\\n- Location\\n- Number\\n- An i m a l\\n- M a t e r i a l s\\n- V e h i c l e s\\n\\nFigure 5 shows the constraint distribution of CoScript. We compute the proportions of constraint types with their representative categories obtained from Probase (Wu et al., 2012), and the initial words of constraint instances. We find CoScript shows high heterogeneity and pluralism in the generated specific goals. Interestingly, InstructGPT tends to start with the word \\\"if\\\" or \\\"when\\\" for hypothetical constraints (e.g., \\\"if someone is lactose intolerant\\\" for \\\"make a cake\\\"), suggesting the potential for future research on counterfactual reasoning in language planning. We also analyze the domain distribution of CoScript in the Appendix C.2.\\n\\n6 Constrained Language Planning with Specialized Models\\n\\nWith CoScript, we can train smaller but specialized models for constrained language planning.\\n\\n6.1 Experimental setup\\n\\nBaselines\\n\\nWe use GPT-2 (causal LM) (Radford et al., 2019) and T5 (encoder-decoder LM) (Raffel et al., 2020) as baselines. Given goals, the models are trained to generate a list of steps $S$ for planning. Moreover, we adopt the idea of retrieval-augmented text generation (Lewis et al., 2020) and add retrieved examples in the input to improve generation quality.\\n\\nMetrics\\n\\nWe use BLEU (Papineni et al., 2002), ROUGE-L (Lin, 2004) and BERTScore (Zhang et al., 2020) as automatic metrics to measure semantic completeness. We also train a binary classification model to decide whether the generated texts are faithful to the constraints. Specifically, we...\"}"}
{"id": "acl-2023-long-236", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Overall script generation performance for models trained on different training sets. Note that the test set is the same for all models.\\n\\n| Model     | Modifier | Method | Intent | All   |\\n|-----------|----------|--------|--------|-------|\\n| GPT-2     |          |        |        |       |\\n| GPT-2 (large) |        |        |        |       |\\n| T5 (base) |          |        |        |       |\\n| T5 (large) |          |        |        |       |\\n| T5 (3B)   |          |        |        |       |\\n\\nTable 6: Faithfulness scores of specialized models for each constraint type on the test set of CoScript.\\n\\n| Model     | Modifier | Method | Intent | All   |\\n|-----------|----------|--------|--------|-------|\\n| T5 (large) |          |        |        |       |\\n| GPT-2 (large) |        |        |        |       |\\n\\nTraining Data\\nTo gain a fine-grained perspective on planning toward specific goals, we train LMs on both wikiHow (Dwi) and CoScript (Dco), and test them on CoScript test set (Dco). Both datasets share similar scripts, but the goals in wikiHow are mostly abstract ones. For wikiHow, we also randomly collect 50,000 goals with scripts as Dwi.\\n\\n6.2 Results\\nThe comparison for models trained on wikiHow and CoScript are shown in Table 5. In general, LMs trained on CoScript outperform that on wikiHow. T5 outperforms GPT-2 in faithfulness, possibly due to its encoder-decoder framework being better at handling input information. However, GPT-2 outperforms T5 on other text generation metrics for scripts. This could be because CoScript.\\n\\nFigure 6: The faithfulness curves when altering the proportions of CoScript (\u03b1) and wikiHow (1\u2212\u03b1) in a fixed-size training set.\\n\\nTable 7: Accuracy (%) of scripts generated by different models. We fine-tune a T5 (3B) on wikiHow and CoScript while deploying LLMs via few-shot in-context learning.\\n\\n| Model     | Modifier | Method | Intent | All   |\\n|-----------|----------|--------|--------|-------|\\n| GPT-3     | 175B     |        |        |       |\\n| Codex     | 175B     |        |        |       |\\n| InstructGPT | 175B    |        |        |       |\\n| T5 (wikiHow) | 3B      |        |        |       |\\n| T5 (CoScript) | 3B    |        |        |       |\\n\\nis distilled from InstructGPT, leading to a biased data distribution that favors decoder-only causal language models, e.g., the GPT family.\\n\\nBased on Table 5, we find that augmenting models with retrieved examples can improve semantic completeness. However, the constraint faithfulness could be undermined as models tend to mimic the retrieved examples. To further understand the role of retrieval augmentation, we conduct a manual evaluation that based on 100 random samples generated by T5 (3B) with and without retrieval augmentation. We discover that 57% of T5's results are correct, and the number goes up to 70% with retrieval augmentation. Thus, although we observe a slight drop in faithfulness score (93.00 \u2192 92.53 from Table 5), retrieval augmentation still brings much improvement over the base model.\\n\\nFaithfulness of Constraints of Different Types\\nWill LLMs' planning preferences for constraint types pass to the specialized models? We find the results in Table 6 are consistent with that of LLMs (Table 3). Specialized models are also the worst at specific goals with intent-typed constraints.\\n\\nCoScript vs. wikiHow\\nWe mix two datasets together with a hyper-parameter \u03b1 to control the proportion of two datasets, where the new training...\"}"}
{"id": "acl-2023-long-236", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"$D_{tr} = \\\\alpha D_{co} + (1 - \\\\alpha) D_{wi}$. By altering $\\\\alpha$ (constant data size), the faithfulness curves in Figure 6 shows that adding more data from CoScript consistently improves model performance in constraint faithfulness. Thus, training on CoScript contributes to more faithful planners.\\n\\nSpecialized Models vs. LLMs\\n\\nWe further fine-tune a T5 (3B) on CoScript and wikiHow to generate scripts for the specific goals in \u00a74.4, which are held out from the training set. Table 7 shows that T5 fine-tuned on CoScript with retrieval augmentation can generate scripts of higher quality than most LLMs in Table 3, indicating that smaller models can surpass larger models when properly trained on suitable datasets.\\n\\n7 Conclusion\\n\\nIn this paper, we define planning toward specific goals with constraints. We propose a better prompting method for LLMs, and distill a novel dataset from LLMs (CoScript) to improve the constrained language planning ability of specialized models. Experiments show that our method improves the planning quality of LLMs for specific goals, and smaller models trained on CoScript even outperform LLMs. We hope the CoScript dataset will be a valuable resource to advance the research on language planning with more complex and diverse goals and constraints.\\n\\nLimitations\\n\\nThe proposed method for improving LLMs is a post-hoc re-ranking approach, and we do not improve LLMs themselves due to the difficulty of fine-tuning LLMs. Besides, we improve the ability of constrained language planning for smaller models from the perspective of building task-related datasets, but do not consider investigating the model itself, other than adopting retrieval augmentation. In addition, because automatic metrics for generated text are limited, the automatic evaluation of this paper may result in an overestimation or underestimation of the mentioned methods, though we attempt to mitigate this by incorporating a moderate amount of human evaluation. Despite the advanced planning capabilities of newer language models, our work remains significantly valuable to the knowledge distillation of these LLMs into smaller and more cost-effective models.\\n\\nWe also discover several limitations of the proposed CoScript datasets. First, the specific goal explored in this work only inherits from an abstract one with one extra constraint. However, in real-life situations, complex planning may involve multiple constraints, which we do not investigate in this work. Another limitation of CoScript is that our dataset is generated from InstructGPT, and thus the data distributions may be biased to favor causal language models. This is a common issue with machine-generated datasets, which we address by manually curating CoScript\u2019s validation and test sets. Furthermore, there are still some incorrect samples (about 5%) in the training data without manual correction due to the limits of budget and time. Last but not least, we only consider whether the script can be executed at the human level. The script execution for robots (Huang et al., 2022; Lu et al., 2022b) is unstudied in our work, and there still exist huge gaps in transferring complex human language to one that is understandable and executable by robots.\\n\\nEthics Statement\\n\\nUse of Human Annotations\\n\\nWe protect the privacy rights of crowd-sourced workers and pay them above the local minimum wage. We use Amazon Mechanical Turk (AMT) and require 300 annotators to be located in the U.S. as a proxy for English competency. We pay at a rate of $6/hour for 20 samples. We acknowledge that constructing datasets from large language models may suffer from toxic language and cause severe risks for society (Ousidhoum et al., 2021; Baldini et al., 2022). Therefore, we ask the annotators to discard the offensive and harmful data when reviewing the CoScript. However, there may still be prejudicial data in our final dataset that goes unnoticed.\\n\\nwikiHow Source\\n\\nThe content available on wikiHow is shared under a Creative Commons License (CC-BY-NC-SA), which permits others to share, copy, distribute, and adapt the content for non-commercial purposes. In our research, we use wikiHow as an initial dataset for providing examples to construct our dataset. Our dataset is released on GitHub and is only used to advance academic research on language planning with more complex and diverse goals and constraints. Therefore, we emphasize that our usage aligns with the requirements under the license.\\n\\n9https://creativecommons.org/licenses/by-nc-sa/3.0/\"}"}
{"id": "acl-2023-long-236", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Covered Domains in CoScript\\n\\nCoScript is derived from wikiHow and encompasses 19 daily life goal categories (as illustrated in Figure 8). These categories cover a wide range of practical topics of everyday life. However, as shown in Figure 8, we emphasize that sensitive and high-risk domains, including medical, legal, and high-stakes financial advice, are excluded from the dataset to minimize potential risks related to inaccurate or misleading information. We encourage researchers and developers to leverage this dataset to build models that accurately understand and respond to user queries on various non-sensitive, non-critical topics.\\n\\nFactuality, Toxicity and Biases\\n\\nWe recognize that the factuality of generated content is crucial, especially in high-stakes scenarios. Therefore, annotators are asked to verify the consistency between generated scripts and goals with constraints for validation and test sets. They also assess and revise the content to minimize hallucinations, factual errors, and any inappropriate or misleading information.\\n\\nPrevious work found that LLMs may generate toxic contents (Cao et al., 2022; Liu et al., 2022b). We highlight that our dataset is not intended for safety-critical applications or as a substitute for expert advice in such domains. Annotators are specifically instructed to discard offensive and harmful data during the review of the validation and test sets in CoScript. However, despite these precautions, there may still be some prejudicial data that goes unnoticed in our final dataset.\\n\\nAcknowledgement\\n\\nWe thank the anonymous reviewers for their valuable comments, and Wei Shi and Shuang Li from Fudan University for their useful suggestions for the manuscript. This work is supported by the Chinese NSF Major Research Plan (No.92270121), Shanghai Science and Technology Innovation Action Plan (No.21511100401) and the Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902).\\n\\nReferences\\n\\nRobert P Abelson. 1976. Script processing in attitude formation and decision making.\\n\\nIoana Baldini, Dennis Wei, Karthikeyan Natesan Ramamurthy, Moninder Singh, and Mikhail Yurochkin. 2022. Your fairness may vary: Pretrained language model fairness in toxic text classification. In Proceedings of the Association for Computational Linguistics: ACL 2022, pages 2245\u20132262, Dublin, Ireland. Association for Computational Linguistics.\\n\\nMatthew Berg, George Konidaris, and Stefanie Tellex. 2022. Using language to generate state abstractions for long-range planning in outdoor environments. In 2022 International Conference on Robotics and Automation (ICRA), pages 1888\u20131895.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877\u20131901. Curran Associates, Inc.\\n\\nMeng Cao, Yue Dong, and Jackie Cheung. 2022. Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3340\u20133354, Dublin, Ireland. Association for Computational Linguistics.\\n\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\\n\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.\\n\\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.\\n\\nKatherine M Collins, Catherine Wong, Jiahai Feng, Megan Wei, and Joshua B Tenenbaum. 2022. Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks. arXiv preprint arXiv:2205.05718.\\n\\nBiaoyan Fang, Timothy Baldwin, and Karin Verspoor. 2022. What does it take to bake a cake? the RecipeRef corpus and anaphora resolution in procedural text. In Findings of the Association for Computational Linguistics: ACL 2022, pages 3481\u20133495.\"}"}
{"id": "acl-2023-long-236", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "acl-2023-long-236", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Yujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu, Xin Eric Wang, Miguel Eckstein, and William Yang Wang. 2022b. Neuro-symbolic causal language planning with commonsense prompting. arXiv preprint arXiv:2206.02928.\\n\\nQing Lyu, Li Zhang, and Chris Callison-Burch. 2021. Goal-oriented script construction. In Proceedings of the 14th International Conference on Natural Language Generation, pages 184\u2013200, Aberdeen, Scotland, UK. Association for Computational Linguistics.\\n\\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work? ArXiv preprint abs/2202.12837.\\n\\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, and Hannaneh Hajishirzi. 2022. Reframing instructional prompts to GPTk\u2019s language. In Findings of the Association for Computational Linguistics: ACL 2022, pages 589\u2013612, Dublin, Ireland. Association for Computational Linguistics.\\n\\nShashi Narayan, Gon\u00e7alo Sim\u00f5es, Yao Zhao, Joshua Maynez, Dipanjan Das, Michael Collins, and Mirella Lapata. 2022. A well-composed text is half done! composition sampling for diverse conditional generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1319\u20131339, Dublin, Ireland. Association for Computational Linguistics.\\n\\nAlberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2021. Gpt3-to-plan: Extracting plans from text using gpt-3. FinPlan 2021, page 24.\\n\\nNedjma Ousidhoum, Xinran Zhao, Tianqing Fang, Yangqiu Song, and Dit-Yan Yeung. 2021. Probing toxic content in large pre-trained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4262\u20134274, Online. Association for Computational Linguistics.\\n\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Caroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155.\\n\\nKishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.\\n\\nChris Paxton, Yonatan Bisk, Jesse Thomason, Arunkumar Byravan, and Dieter Foxl. 2019. Prospection: Interpretable plans from language by predicting the future. In 2019 International Conference on Robotics and Automation (ICRA), pages 6942\u20136948.\\n\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1\u201367.\\n\\nMichaela Regneri, Alexander Koller, and Manfred Pinkal. 2010. Learning script knowledge with web experiments. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 979\u2013988, Uppsala, Sweden. Association for Computational Linguistics.\\n\\nNils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982\u20133992, Hong Kong, China. Association for Computational Linguistics.\\n\\nKeisuke Sakaguchi, Chandra Bhagavatula, Ronan Le Bras, Niket Tandon, Peter Clark, and Yejin Choi. 2021. proScript: Partially ordered scripts generation. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 2138\u20132149, Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nAbhilasha Sancheti and Rachel Rudinger. 2022. What do large language models learn about scripts? In Proceedings of the 11th Joint Conference on Lexical and Computational Semantics, pages 1\u201311, Seattle, Washington. Association for Computational Linguistics.\\n\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao,\"}"}
{"id": "acl-2023-long-236", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Thomas Wolf, and Alexander M. Rush. 2022. Multi-task prompted training enables zero-shot task generalization. In International Conference on Learning Representations.\\n\\nRoger C. Schank and Robert P. Abelson. 1975. Scripts, plans, and knowledge. In Proceedings of the 4th International Joint Conference on Artificial Intelligence - Volume 1, IJCAI'75, page 151\u2013157, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.\\n\\nRoger C. Schank and Robert P. Abelson. 2013. Scripts, plans, goals, and understanding: An inquiry into human knowledge structures. Psychology Press.\\n\\nThomas Suddendorf and Michael C. Corballis. 2007. The evolution of foresight: What is mental time travel, and is it unique to humans? Behavioral and brain sciences, 30(3):299\u2013313.\\n\\nNiket Tandon, Keisuke Sakaguchi, Bhavana Dalvi, Dheeraj Rajagopal, Peter Clark, Michal Guerquin, Kyle Richardson, and Eduard Hovy. 2020. A dataset for tracking entities in open domain procedural text. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6408\u20136417, Online. Association for Computational Linguistics.\\n\\nKarthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2022. Large language models still can\u2019t plan (a benchmark for LLMs on planning and reasoning about change). In NeurIPS 2022 Foundation Models for Decision Making Workshop.\\n\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.\\n\\nLilian D. A. Wanzare, Alessandra Zarcone, Stefan Thater, and Manfred Pinkal. 2016. A crowdsourced database of event sequence descriptions for the acquisition of high-quality script knowledge. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16), pages 3494\u20133501, Portoro\u017e, Slovenia. European Language Resources Association (ELRA).\\n\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems.\\n\\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. 2022. Symbolic knowledge distillation: from general language models to commonsense models. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4602\u20134625, Seattle, United States. Association for Computational Linguistics.\\n\\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing human-AI collaboration for generating free-text explanations. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 632\u2013658, Seattle, United States. Association for Computational Linguistics.\\n\\nWentao Wu, Hongsong Li, Haixun Wang, and Kenny Q. Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, SIGMOD '12, page 481\u2013492, New York, NY, USA. Association for Computing Machinery.\\n\\nYue Yang, Joongwon Kim, Artemis Panagopoulou, Mark Yatskar, and Chris Callison-Burch. 2021. Induce, edit, retrieve: Language grounded multimodal schema for instructional video retrieval. ArXiv preprint, abs/2111.09276.\\n\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with BERT. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\\n\\nAuthor Contributions\\n\\nSiyu Yuan\\nLead the project, develop the original method and original code, lead the curation of the dataset, contribute to the original experiments, and contribute to the original manuscript.\\n\\nJiangjie Chen\\nConceptualization of the original idea, supervision of the research activity planning and execution, contribution to the original manuscript and figures, and acquisition of financial support for the project.\\n\\nZiquan Fu\\nContribute to the original idea, provide financial support for the project, revise the manuscript, and contribute to data curation.\\n\\nXuyang Ge\\nContribute to the experiments and data curation.\\n\\nSoham Shah\\nProvide financial support for the project and revise the manuscript.\\n\\nCharles Robert Jankowski\\nProvide financial support for the project and revise the manuscript.\\n\\nYanghua Xiao\\nProvide financial support for the project and revise the manuscript.\\n\\nDeqing Yang\\nProvide financial support for the project, revise the manuscript, and oversee the research activity execution.\"}"}
{"id": "acl-2023-long-236", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"B Implementation Details\\n\\nB.1 Handpicked Examples for Specific Goal Generation\\n\\nWe follow the instructions proposed by Mishra et al. (2022) to better construct the three examples for specific goal generation. As shown in Table 13, we turn long descriptions into bulleted lists in the task prompt for better generation. In addition, in each example, we list two specific goals with constraints, which can prompt InstructGPT to generate multiple specific goals for the given abstract goals. In our experiment, we conduct the specific goals generation with different numbers of examples and report the accuracy and the total number of generated specific goals for 100 abstract goals. The results in Table 8 show that three examples are good in our settings.\\n\\n| # Examples | Accuracy | # Total |\\n|-----------|----------|--------|\\n| 2         | 95.16%   | 545    |\\n| 3         | 96.99%   | 537    |\\n| 4         | 95.44%   | 539    |\\n\\nTable 8: The specific goals generation performance of InstructGPT with different numbers of examples.\\n\\nB.2 Prompts Format\\n\\nTo explore the prompt formats on script generation, we test 100 samples mentioned in \u00a74.4 without using the task prompt or replacing the original words. The results in Table 9 show that:\\n1) task prompt can help InstructGPT to better understand the task and thus can improve the model performance on script generation;\\n2) adopting popular words to write the prompts can better improve the effect of prompts.\\n\\n| Format      | Goal Script |\\n|-------------|-------------|\\n| Our Method  | 98.00       |\\n| w/o Task Prompt | 94.67    |\\n| r. Goal \u2192 Scenario | 96.00 |\\n| r. Abstract \u2192 General | 96.67 |\\n| r. Step \u2192 Event | 67.00 |\\n\\nTable 9: Accuracy (%) of different prompt formats by manual evaluation. We replace (r.) the words in Table 2 with other words for comparison.\\n\\nB.3 Over-generation Hyper-parameters\\n\\nTo evaluate the LLMs on planning for specific goals, we randomly sample 100 specific goals and generate scripts from the baseline and our method. Figure 7 reports the faithfulness to constraints. We find that:\\n1) the output quality of InstructGPT falls in high variance, and the script may be unfaithful to the constraints;\\n2) over-generation can amplify the likelihood of constraint satisfaction, and $K=2$ is sufficient.\\n\\nB.4 Error Types\\n\\nAs shown in Figure 10, we evaluate the model planning performance on two aspects, i.e., Semantic completeness and Faithfulness to the constraints (\u00a74.4), and define six types of errors.\\n\\nB.5 Case Study\\n\\nTable 14 lists three examples by InstructGPT (175B) and our approach. The first and second examples show that the scripts generated by InstructGPT may fail in unfaithfulness to the constraints. The third examples demonstrate that although the scripts generated by InstructGPT can be faithful to the constraints, they may suffer from other error types. In contrast, the over-generating-and-filtering method can amplify the likelihood of high-quality generations and thus can make LLMs better planners.\"}"}
{"id": "acl-2023-long-236", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Aspects Error Types Explanation Example: Make a vanilla cake\\nConstraint: Vanilla\\nSemantic Completeness\\nWrong order Steps that are in the wrong order. Correct Script:\\n1. Gather your ingredients.\\n2. Preheat the oven to 325\u00b0 F and grease and flour a cake pan.\\n3. Cream the butter and sugar.\\n4. Add the eggs and vanilla.\\n5. Stir in the cake flour.\\n6. Pour the batter into the pan.\\n7. Bake the cake for 1 hour 15 minutes.\\nGenerated Script:\\n1. Preheat the oven to 325\u00b0 F and grease and flour a cake pan.\\n2. Gather your ingredients.\\n3. Buy your ingredients.\\n4. Cream the butter and salt.\\n5. Stir in the cake flour.\\n6. Have a shower.\\n7. Pour the batter into the pan.\\n8. Bake the cake for 1 hour 15 minutes.\\nRepeat steps Steps that are repeated in the script.\\nMissing steps Important steps that are missing.\\nFaithfulness to Constraints No constraint Script is unfaithful to the constraint.\\nIncoherent steps Steps that are related to the goal, but are not coherent within the script.\\nUnrelated steps Steps that are not related to the goal.\\nTable 10: The error types and their explanation with examples.\\n\\nHyper-parameter Assignment\\nTop-p 1.0\\nTemperature 1.0\\nMax tokens 512\\nPresence penalty 0.0\\nFrequency penalty 0.0\\nK 2\\n\\nTable 11: Hyper-parameters for script generation from InstructGPT.\\n\\nFood and Entertaining\\nTravel\\nSports and Fitness\\nHome and Garden\\nComputers and Electronics\\nPersonal Care and Style\\nFinance and Business\\nEducation and Communications\\nPhilosophy and Religion\\nYouth\\nRelationships\\nPets and Animals\\nWork World\\nCars & Other Vehicles\\nHobbies and Crafts\\nArts and Entertainment\\nHealth\\nFamily Life\\nHolidays and Traditions\\n\\nFigure 8: The category distribution of CoScript. The categories are derived from wikiHow.\\n\\nC.2 Domain Examination\\nAs shown in Figure 8, CoScript is derived from wikiHow and encompasses 19 daily life categories. These categories cover a wide range of practical topics of everyday life, excluding sensitive and high-stakes topics like medical and legal matters. In addition, we adopt ChatGPT to assess each specific goal in CoScript to further mitigate risks associated with sensitive domains. The instruction is shown in Table 12. Upon examination, ChatGPT identifies that 0.24% of specific goals (132) within the CoScript involve a sensitive domain, such as \\\"relieve head pain with medication\\\" in the Health domain. We manually remove these data and substitute them with new specific goals (e.g., relieve head pain with meditation) to ensure the safety of our dataset. We encourage researchers and developers to leverage this dataset to build models that accurately understand and respond to user queries on non-sensitive, non-critical topics.\\n\\nC.3 Qualitative Generations\\nWe randomly select qualitative generations from the CoScript. Table 15, Table 16 and Table 17 show some specific goal generations under different types of constraints. Table 18 shows some scripts generated based on our proposed pipeline.\\n\\nD Crowd-sourcing Details\\nInterface Details\\nWe conduct human evaluations on Amazon Mechanical Turk. Screenshots of the instructions and annotation interface are shown in Figure 9 and 10.\"}"}
{"id": "acl-2023-long-236", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Step 1: Specific Goal Evaluation\\nWe first assess the specific goals generated by InstructGPT with three types of constraints. We ask the turkers to check the specific goal whether inherits the abstract goal and contains a constraint.\\n\\nStep 2: Script Evaluation\\nIn the second step, we show a script of the specific goal with actionable steps. We then ask two questions:\\n\\n1. Does the script meet the constraint in the specific goal? (Yes, No, or Not sure). In our preliminary experiments, we found that the semantic completeness in the scripts generated based on InstructGPT (175B) is acceptable, but faithfulness to the constraints can not be guaranteed. This question assesses this tricky error;\\n\\n2. Are the steps in the script correct in achieving the specific goal? (Yes, No, or Not sure). This question is to assess whether the script can indeed accomplish the given goal. Although we have checked the constraint in the first question, there are still other error types (as shown in Figure 10). Then, we ask the turkers to review the generated scripts. If the scripts cannot achieve the given goal, they must point out the wrong steps and select the error types.\"}"}
