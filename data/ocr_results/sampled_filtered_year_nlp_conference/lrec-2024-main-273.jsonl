{"id": "lrec-2024-main-273", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 13: This is a line chart. The chart shows the percentage of American adults who use the internet from 1995 to 2014. The number is 14% in 1995, 46% in 2000, 66% in 2005, 79% in 2010, 87% in 2014. The chart shows that Internet usage has steadily increased over the years, reaching a peak of 87% in 2014.\\n\\nFigure 14: This is a line chart. The chart displays the total retransmission fee revenue in U.S. dollars from 2006 to 2022. The revenue started at 0.1 billion dollars in 2006 and increased to 2.5 billion dollars in 2012. The corresponding numbers are 5 in 2014, 8 in 2016, 10 in 2018, 11 in 2020 and 12.5 in 2022. Overall, the chart shows an increasing trend of total retransmission fee revenue in U.S. dollars from 2006 to 2022.\\n\\nB. Retrieval Library\\n\\nOur constructed context retrieval library is divided into four stages of examples. The first stage focuses on chart types. By analyzing a given chart, the model identifies and learns its type, with some examples presented in Figure 15.\\n\\nThe second stage pertains to the overall caption of the chart, primarily derived from the chart's title. In this stage, the model learns from the context examples in the retrieval library to output a chart overview summary, as illustrated in Figure 16.\\n\\nThe third stage elucidates the meanings of both the horizontal and vertical axes of the chart. The primary objective here is to significantly deepen the model's understanding of the axes and the intricate relationships they share, as detailed in Figure 17.\\n\\nThe fourth stage centers on the trend of the chart data. The model learns to describe the chart's trend in natural language and generates a numerical trend description, as shown in Figure 18.\\n\\nTo conclude, the context retrieval library comprises 1,000 charts, with each stage containing 250 charts and their associated textual descriptions. During training for each stage, the model searches within the 250 charts of the respective stage, selecting the top K most relevant charts as examples for context learning. Through this approach, the model becomes adept at describing charts in natural language, enhancing its chart comprehension and linguistic capabilities.\\n\\nC. Comparison of examples generated by various models\\n\\nIn order to gain a more comprehensive understanding of our model's summaries, we undertake a meticulous manual assessment. The evaluation process involves evaluating a total of 200 summaries, including 40 summaries each from four baselines and our model. Figure 19 showcases example summaries generated by the five models. The primary objective is to ensure summaries accurately and meaningfully represent the charts' essence and data.\\n\\nTo ensure an objective evaluation, we employ a set of annotators who are tasked with comparing each generated summary against its corresponding chart. The comparison is based on two pivotal criteria: (i) Matching Degree: This criterion gauges the degree to which the data presented in the generated summary is in harmony with the chart. (ii) Reasoning Correctness: Beyond just presenting data, it's imperative that the summary can accurately infer and convey the intended message or viewpoint that the chart aims to communicate.\\n\\nTo uphold consistency and objectivity in the assessments, each summary is rated on a scale of 1 to 5, with 1 being the lowest and 5 being the highest. To further eliminate potential biases, the summaries are presented to the annotators in a random order. This strategy prevents evaluators from harboring preconceived notions or biases stemming from the presentation order. The complete evaluation procedure is illustrated in Figure 20. After the evaluation, each summary's final score is determined by calculating the average of the scores given by three separate evaluators.\"}"}
{"id": "lrec-2024-main-273", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 15: Examples from the first stage of the Retrieval Library, showcasing chart types for context retrieval.\\n\\n(a) The chart describes total value of local TV station mergers and acquisitions (in US dollars).\\n(b) The chart describes number of refugees admitted to the U.S. falls in 2018.\\n(c) The chart illustrates majorities of Americans say the federal government is not doing enough to protect the climate, environment.\\n(d) The chart shows half of US adults seldom or never discuss religion with non-family.\\n(e) The chart shows anti-Muslim assaults at highest level since 2001.\\n(f) The chart describes apprehensions at U.S. borders over a period of 45 years.\\n\\nFigure 16: Examples from the second stage of the Retrieval Library, showcasing chart content overview in context retrieval.\"}"}
{"id": "lrec-2024-main-273", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 17: The third stage in the Retrieval Library, which shows examples of Axes' Meaning.\\n\\n(a) The overall data shows a fluctuating trend, with the highest value of 10 states in 1976, where the winning candidate's popular vote margin was less than 2 percentage points. In certain years, the data is recorded as 0.\\n\\n(b) The proportion of people who only watch debate competitions on TV is the highest, accounting for 85%. The proportion of people who only watch debates on computers or mobile phones is the lowest, accounting for only 3%. The number of people who choose to watch all of the above is 11%.\\n\\n(c) The number of minor judgments has been showing an upward trend, with a slower growth rate from 1945 to 1978, increasing from 1 person to 40 people. From 1978 to 2016, the growth rate became faster, rising to 375 people in 2016.\\n\\n(d) Since 1997, the response rates have been decreasing year by year, reaching 36% in 1997, 28% in 2000, 25% in 2003, 21% in 2006, 15% in 2009, and 9% in 2012. However, from 2012 to 2016, the response rate has remained at 9% to stabilize over the past four years.\\n\\n(e) From 2006 to 2010, the Mexican migration rates showed a significant downward trend, from 114 in 2006 to 107 in 2007, then to 85 in 2008, to 55 in 2009, and finally to 47 in 2010. From 2011 to 2015, the Mexican migration rates remained relatively stable, fluctuating around 40.\\n\\n(f) From 2007 to 2019, unemployment in the United States first sharply increased and then steadily decreased. The unemployment rate in 2007 was 4.4%, and quickly rose to 9.5% within three years after the outbreak of the economic crisis, reaching a historical peak. Afterwards, the unemployment rate steadily decreased and by 2019 the unemployment rate was 3.5%.\\n\\nFigure 18: The fourth stage in the Retrieval Library shows examples of Charts' numerical trend.\"}"}
{"id": "lrec-2024-main-273", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"The chart displays a graph showing the total number of refugees living outside of their country of origin, from 1960 to 2012. The graph shows a steady increase in the number of refugees over the years, with a significant spike in the 1990s. The peak of the refugee population is observed in 2002, with the number of refugees reaching 20 million. The graph then shows a decline in the number of refugees from 2002 to 2012, with the population stabilizing around 14 million.\\n\\nThe chart shows the number of living births in the United States from 2000 to 2012. The number of births increased from 4,000,000 in 2000 to 4,200,000 in 2012. The chart also shows the number of deaths in the United States from 2000 to 2012. The number of deaths decreased from 2,400,000 in 2000 to 2,200,000 in 2012.\\n\\nThe line chart shows the refugee population trend from 1960 to 2012. The data is presented in millions of people. The chart shows that the number of refugees continuously increased from 1960 to 1990, reaching its peak in 1990. After that, the number of refugees declined, with a slight increase in 2005, and then remained stable at 10.5 million. In 1960, there were around 1.5 million refugees, which increased to 2.5 million in 1970, 8 million in 1980, 18 million in 1990, 12 million in 2000.\\n\\nThe chart displays a decline in the number of refugees living outside of their country of origin, from 20 million in 1960 to 14 million in 2012. The data is presented in a line graph, showing the trend over time. The chart also includes a bar graph that provides a more detailed breakdown of the refugee population by year. The bar graph shows the number of refugees in each year, with the highest number of refugees in 1960 and the lowest number in 2012. This information highlights the changes in the refugee population over the past several decades.\\n\\nThe chart displays a trend in the number of refugees living outside of their country of origin, from 1960 to 2012. It shows a steady increase in this population over the years, reaching a peak in 9.5 million in both the 80s and 90s. However, the numbers have declined since then, with the total refugee population dropping to around 6.7 million as of 40 years later. The data is represented by a line graph, where the vertical axis shows the year and the horizontal axis represents the population. The line starts at 50,098 in January 7304, representing the refugee population in that year. As time progresses, it gradually increases, peaking around the mid-90s, and then declining to the present-day level.\\n\\nFigure 19: Examples comparing the summaries generated by our model with those of other models.\\n\\nSummary:\\nThe chart shows the trend of Google searches for \\\"Mother's Day Flowers\\\" from 2004 to 2015. The searches peak around the week of Mother's Day, which is the second Sunday in May. The chart also shows the average price of flowers on Mother's Day, which has been increasing over the years.\\n\\nSummary:\\nThe chart shows the trend of Google searches for \\\"Mother's Day Flowers\\\" from 2004 to 2015. The searches peak around the week of Mother's Day, which is the second Sunday in May. The chart also shows the average price of flowers on Mother's Day, which has been increasing over the years.\\n\\nFigure 20: Examples of human evaluation. For each chart, evaluators score the generated summary based on two criteria: matching degree and reasoning correctness, with scores ranging from 1 to 5.\"}"}
{"id": "lrec-2024-main-273", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The chart displays a bar graph with various statistics about the internet. The bars represent the percentage of people who use the internet for different purposes. The leftmost bar represents 50% of people using the internet for work, while the rightmost bar represents 50% of people using the internet for relaxation. The middle bar represents 100% of people using the internet for both work and relaxation.\\n\\nOverall, the chart suggests that the internet is used for both work and relaxation by a majority of people.\\n\\nThe chart shows the percentage of Americans who use the internet as a source of information. The chart shows that 80% of Americans use the internet as a source of information, and 70% of them use it to get news. The chart also shows that 60% of Americans use the internet to shop online, and 50% use it to access social media. The chart shows that the internet is a popular source of information for Americans, with a majority using it to get news and shop online.\\n\\nThe chart also shows that social media is a popular use of the internet, with half of Americans using it to access social media.\\n\\nThe internet as a diversion\\n\\n69% of all Americans are online economic users. These are some of the things they do online to help them relax and take their minds off of the economy:\\n\\n- Play games: 0%\\n- Watch videos: 10%\\n- Listen to music: 0%\\n- Chat with friends: 0%\\n- Create or post online content: 0%\\n- Have done any of these: 0%\\n\\nThe internet as a tool for economic activity\\n\\nThese activities help online economic users relax and take their minds off of the economy.\"}"}
{"id": "lrec-2024-main-273", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"**Identify the chart's type**\\n\\n**Understand legend and axes.**\\n\\n**Input Image and Prompts**\\n\\n- **Imageencoder**\\n- **expertsystem**\\n- **Context-Enhanced COT Generator**\\n- **idefics\u2744+LoRA\ud83d\udd25**\\n- **Underling data**\\n- **chartlibrary**\\n- **image-textpair**\\n\\nPrompt: Summarize this chart.\\n\\n**Output2:** It shows the decline in marriage among the younger generations of Millennials (including Millennials), Gen X (1997), Boomers (1980), and Silent generations in the United States. In the Millennial generation, only 26% of Millennials were married, while in the Gen X generation, this number increased to 36%. In the Boomer generation, only 48% of Millennials were married, while in the Silent generation, only 65% of Millennials were married. The data suggests that the decline in marriage among the younger generations of Millennials is significantly lower than among the Silent generation.\\n\\n**Figure 2:** Overview of ChartThinker. The encoded input chart and prompt are simultaneously fed into the Context-Enhanced CoT Generator. This module generates thought chains, and for each thought generated, the model retrieves the top-k image-text pairs from the chart library that best align with the thought, serving as contextual learning examples. Subsequently, the corresponding output for each thought is generated. Finally, all the outputs are consolidated to derive the final chart description.\\n\\n**Visual-Language Models.**\\n\\nThe field of LLMs has experienced significant advancements, exemplified by groundbreaking works such as ChatGPT (Brown et al., 2020; OpenAI, 2023), LLaMA (Touvron et al., 2023), and Vicuna (Chiang et al., 2023). More recently, multi-modal LLMs have garnered increasing attention. Flamingo (Alayrac et al., 2022) proposed a unified architecture with context-aware few-shot capabilities, and its open-source variant is OpenFlamingo (Awadalla et al., 2023). Blip2 (Li et al., 2023b) bridges the modality gap between vision and language through a lightweight query transformer (Vaswani et al., 2017). Mini-GPT4 (Zhuet al., 2023) builds on BLIP-2 to support longer responses and multi-turn dialogues better. LLaVA (Liuet al., 2023a) employs a projection layer to align the frozen visual encoder CLIP (Radford et al., 2021) with the frozen LLM (Vicuna). LLaMA-Adapter (Zhang et al., 2023; Gao et al., 2023) adapts LLaMA with additional adapter modules and multi-modal prompts. Ottor (Li et al., 2023a) focuses on enhancing the model's ability to follow instructions through context examples.\\n\\n**Prompt Engineering.**\\n\\nResearchers have proposed various prompt engineering frameworks aimed at enhancing LLM reasoning, among which Prompt Chain of Thought (Wei et al., 2022), which guides the model's responses with intermediate reasoning examples, stands out as one of the most innovative and beneficial techniques. Its subsequent development, Chain-of-Thought-Self-Consistency (Wang et al., 2022b), employs multiple reasoning paths, weighting them for optimized responses. Tree-of-Thoughts (Yao et al., 2023) showcases a tree-structured thought expansion, while Graph-of-Thoughts (Besta et al., 2023) progresses it into a...\"}"}
{"id": "lrec-2024-main-273", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ity of the generated text. This decline in language proficiency is attributed to the model's loss of contextual examples. (3) Similarly, the removal of the CoT component in the generator results in a decline in reasoning ability and a decrease in the comprehensiveness of the generated content. This is due to its lack of step-by-step generation and final integration process.\\n\\nCaption Dataset. Excluding the chart description dataset leads to a decline in performance on the chart-to-text pew test set. Notably, BLEU decreases by 1.46, CIDEr by 0.39, and CS by 2.65%. This indicates challenges in producing precise chart summaries without the dataset. Additionally, a reduced BLEURT and a higher PPL highlight the model's difficulty with unfamiliar chart layouts.\\n\\nInstruction Dataset. To further investigate the impact of the instruction dataset, we excluded the dataset from our training. Without this fine-tuning, the model's degree of chart-summary matching weakens, occasionally generating unrelated content. This mismatching arises because the model relying on its pre-training parameters, fails to adapt to chart tasks. The drop in BLEU and CS scores reveals challenges in extracting pertinent details and reasoning accurately.\\n\\n4.4. Case Study\\n\\n4.4.1. Training Paradigms and Task-Specific Optimization\\n\\nRegarding the performance gap between multimodal large models and text-only models, LMMs, such as our proposed ChartThinker, are pre-trained on unsupervised text-image pairs and are not fine-tuned for specific tasks, which contrasts with text-only models using OCR systems trained on task-specific supervised data. This accounts for the superior performance of OCR+LLM models on certain tasks (Jiao et al., 2024), where the OCR system benefits from training data distribution that mirrors the test set. As an illustration, the OCR in ChartThinker, Paddle OCR, does not specialize in chart summarization, unlike other OCR models referenced in Table 2. This difference in training is why OCR+ChartThinker underperforms in terms of the CS indicator, as also observed in the literature (Liu et al., 2023b).\\n\\n4.4.2. Limitations of Content Similarity (CS) as a Single Metric.\\n\\nIn Table 2, ChartThinker performs lower on the Content Similarity (CS) metric compared to certain OCR models. But evaluating generative models on the sole basis of CS is limiting, as CS only measures similarity to a standard summary and may not reflect the accuracy of model-generated content. For instance, ChartThinker might generate detailed and accurate summaries, but if the content extends beyond the standard answer, the CS score might suggest an inferior performance. An example detailed below underscores this issue (Table 6): despite ChartThinker producing a detailed and accurate summary, its CS score (32.29%) is lower than OCR-T5's (38.74%), which is less descriptive.\\n\\nGold Summary: The global temperature records over the past 100 years depict a temperature rise process from 14.5\u00b0C in 1920 to 16.2\u00b0C in 2020, with temperatures sharply rising by 1.2\u00b0C between 1980 and 2020. 1998 and 2016 are the two hottest years on record.\\n\\nSummary by ChartThinker: This line chart provides a detailed display of the changes in global temperature over the past 100 years. The data shows that the average temperature increased from 14.5\u00b0C in 1920 to 16.2\u00b0C in 2020, showing a significant upward trend overall. Especially between 1980 and 2020, temperatures rose by nearly 1.2\u00b0C, reflecting the acceleration of global warming. In addition, the chart also specifically indicates the two extremely high-temperature years of 1998 and 2016.\\n\\nSummary by OCR-T5: This chart shows the global temperature changes over the past 100 years. The average temperature has risen from 14.5\u00b0C in 1920 to 16.2\u00b0C in 2020, showing an overall upward trend. At the same time, the increase of 1.2\u00b0C from 1980 to 2020 indicates that global warming is intensifying.\\n\\nTable 6: Case Studies in Content Summarization\\n\\n5. Conclusion\\n\\nWe introduce Chart-Sum-QA, a comprehensive dataset tailored for chart summarization, and ChartThinker, a new method capable of training visual-language models with enhanced utilization of contextual information. ChartThinker integrates the chain of thought with context retrieval to enrich the summaries with rigorous logic. Both automated and human evaluations were conducted, demonstrating the superiority of our approach in chart summarization tasks over 8 SOTA methods and 7 evaluation metrics. Further, through extensive ablations, we elucidate the effectiveness of each component and the helpfulness of our dataset. Our findings underscore the key role of CoT in reasoning and the criticality of context retrieval for semantic understanding. We hope our released dataset, codes, and empirical results can shed light on more LLMs-based chart-summarization studies.\"}"}
{"id": "lrec-2024-main-273", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"3. Bibliographical References\\n\\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. 2022. Flamingo: a visual language model for few-shot learning. Advances in Neural Information Processing Systems, 35:23716\u201323736.\\n\\nAnas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, et al. 2023. Openflamingo: An open-source framework for training large autoregressive vision-language models. arXiv preprint arXiv:2308.01390.\\n\\nLorenzo Bertolini, Julie Weeds, and David Weir. 2022. Testing large language models on compositionality and inference with phrase-level adjective-noun entailment. In Proceedings of the 29th International Conference on Computational Linguistics, pages 4084\u20134100.\\n\\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Herbert Niewiadomski, Piotr Nyczyk, et al. 2023. Graph of thoughts: Solving elaborate problems with large language models. arXiv preprint arXiv:2308.09687.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. NeurIPS, 33:1877\u20131901.\\n\\nDaoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, et al. 2023. Data-juicer: A one-stop data processing system for large language models. arXiv preprint arXiv:2309.02033.\\n\\nWenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen, and William Yang Wang. 2020. Logical natural language generation from open-domain tables. In ACL, pages 7929\u20137942.\\n\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. 2022. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588.\\n\\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. See https://vicuna.lmsys.org (accessed 14 April 2023).\\n\\nYifan Du, Zikang Liu, Junyi Li, and Wayne Xin Zhao. 2022. A survey of vision-language pre-trained models. In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22, pages 5436\u20135443.\\n\\nLeo Ferres, Petro Verkhogliad, Gitte Lindgaard, Louis Boucher, Antoine Chretien, and Martin Lachance. 2007. Improving accessibility to statistical graphs: the igraph-lite system. In Proceedings of the 9th International ACM SIGACCESS Conference on Computers and Accessibility, pages 67\u201374.\\n\\nPeng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xiangyu Yue, et al. 2023. Llama-adapter v2: Parameter-efficient visual instruction model. arXiv preprint arXiv:2304.15010.\\n\\nSepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735\u20131780.\\n\\nEdward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021. Lora: Low-rank adaptation of large language models. In International Conference on Learning Representations.\\n\\nHuggingface. 2023. Introducing idefics: An open reproduction of state-of-the-art visual language model.\\n\\nZhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2022. Understanding and improving zero-shot multi-hop reasoning in generative question answering. In Proceedings of the 29th International Conference on Computational Linguistics, pages 1765\u20131775.\\n\\nQirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, and Ying Shen. 2024. Enhancing multi-modal large language models with vision detection models: An empirical study. arXiv preprint arXiv:2401.17981.\\n\\nKushal Kafle, Brian Price, Scott Cohen, and Christopher Kanan. 2018. Dvqa: Understanding data visualizations via question answering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5648\u20135656.\\n\\nSamira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, \u00c1kos K\u00e1d\u00e1r, Adam Trischler, and Yoshua Bengio. 2017. Figureqa: An annotated\"}"}
{"id": "lrec-2024-main-273", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Shankar Kantharaj, Rixie Tiffany Leong, Xiang Lin, Ahmed Masry, Megh Thakkar, Enamul Hoque, and Shafiq Joty. 2022. Chart-to-text: A large-scale benchmark for chart summarization. In ACL, pages 4005\u20134023.\\n\\nJacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171\u20134186.\\n\\nKenton Lee, Mandar Joshi, Iulia Raluca Turc, Hexiang Hu, Fangyu Liu, Julian Martin Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, and Kristina Toutanova. 2023. Pix2struct: Screenshot parsing as pretraining for visual language understanding. In ICML, pages 18893\u201318912. PMLR.\\n\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In ACL, pages 7871\u20137880.\\n\\nBo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. 2023a. Otter: A multi-modal model with in-context instruction tuning. arXiv preprint arXiv:2305.03726.\\n\\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023b. Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. arXiv preprint arXiv:2301.12597.\\n\\nFangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, and Yasemin Altun. 2022a. Deplot: One-shot visual language reasoning by plot-to-table translation. arXiv preprint arXiv:2212.10505.\\n\\nFangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, and Julian Martin Eisenschlos. 2022b. Matcha: Enhancing visual language pretraining with math reasoning and chart derendering. arXiv preprint arXiv:2212.09662.\\n\\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023a. Visual instruction tuning. arXiv preprint arXiv:2304.08485.\\n\\nTianyu Liu, Kexiang Wang, Lei Sha, Baobao Chang, and Zhifang Sui. 2018. Table-to-text generation by structure-aware seq2seq learning. In Proceedings of the AAAI conference on artificial intelligence, volume 32(1).\\n\\nYuliang Liu, Zhang Li, Hongliang Li, Wenwen Yu, Mingxin Huang, Dezhi Peng, Mingyu Liu, Mingrui Chen, Chunyuan Li, Lianwen Jin, et al. 2023b. On the hidden mystery of ocr in large multimodal models. arXiv preprint arXiv:2305.07895.\\n\\nJesus Lovon, Jos\u00e9 G. Moreno, Romaric Besan\u00e7on, Olivier Ferret, and Lynda Tamine. 2022. Can we guide a multi-hop reasoning language model to incrementally learn at each single-hop? In 29th International Conference on Computational Linguistics (COLING 2022), pages 1455\u20131466.\\n\\nPan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022. Learn to explain: Multimodal reasoning via thought chains for science question answering. In Advances in Neural Information Processing Systems.\\n\\nAnita Mahinpei, Zona Kostic, and Chris Tanner. 2022. Linecap: Line charts for data visualization captioning models. In 2022 IEEE Visualization and Visual Analytics (VIS), pages 35\u201339. IEEE.\\n\\nAhmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, and Shafiq Joty. 2023. Unichart: A universal vision-language pretrained model for chart comprehension and reasoning. arXiv preprint arXiv:2305.14761.\\n\\nNitesh Methani, Pritha Ganguly, Mitesh M Khapra, and Pratyush Kumar. 2020. Plotqa: Reasoning over scientific plots. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1527\u20131536.\\n\\nXuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang. 2023. Skeleton-of-thought: Large language models can do parallel decoding. arXiv preprint arXiv:2307.15337.\\n\\nJason Obeid and Enamul Hoque. 2020. Chart-to-text: Generating natural language descriptions for charts by adapting the transformer model. In Proceedings of the 13th International Conference on Natural Language Generation, pages 138\u2013147.\\n\\nR OpenAI. 2023. Gpt-4 technical report (arxiv: 2303.08774).\\n\\nMatt Post. 2018. A call for clarity in reporting bleu scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, page 186.\"}"}
{"id": "lrec-2024-main-273", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748\u20138763. PMLR.\\n\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, YanqiZhou, WeiLi, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485\u20135551.\\n\\nEhud Reiter. 2007. An architecture for data-to-text systems. In proceedings of the eleventh European workshop on natural language generation (ENLG 07), pages 97\u2013104.\\n\\nBilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu Wang, Ruoxi Jia, and Ming Jin. 2023. Algorithm of thoughts: Enhancing exploration of ideas in large language models. arXiv preprint arXiv:2308.10379.\\n\\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. Bleurt: Learning robust metrics for text generation. In ACL, pages 7881\u20137892.\\n\\nHrituraj Singh and Sumit Shekhar. 2020. Stl-cqa: Structure-based transformers with localization and encoding for chart question answering. In EMNLP, pages 3275\u20133284.\\n\\nChase Stokes, Vidya Setlur, Bridget Cogley, Arvind Satyanarayan, and Marti A. Hearst. 2022. Striking a balance: reader takeaways and preferences when integrating text and charts. IEEE Transactions on Visualization and Computer Graphics, 29(1):1233\u20131243.\\n\\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. NeurIPS, 30.\\n\\nRamakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. 2015. CIDEr: Consensus-based image description evaluation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4566\u20134575.\\n\\nSiyuan Wang, Zhongyu Wei, Zhihao Fan, Qi Zhang, and Xuan-Jing Huang. 2022a. Locate then ask: Interpretable stepwise reasoning for multi-hop question answering. In Proceedings of the 29th International Conference on Computational Linguistics, pages 1655\u20131665.\\n\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022b. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations.\\n\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V. Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837.\\n\\nSam Wiseman, Stuart M. Shieber, and Alexander M. Rush. 2017. Challenges in data-to-document generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2253\u20132263.\\n\\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601.\\n\\nQinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al. 2023. mplug-owl: Modularization empowers large language models with multimodality. arXiv preprint arXiv:2304.14178.\\n\\nRenrui Zhang, Jiaming Han, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, Peng Gao, and Yu Qiao. 2023. Llama-adapter: Efficient fine-tuning of language models with zero-init attention. arXiv preprint arXiv:2303.16199.\\n\\nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592.\\n\\nJiawen Zhu, Jinye Ran, Roy Ka-Wei Lee, Zhi Li, and Kenny Choo. 2021. Autochart: A dataset for chart-to-text generation task. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), pages 1636\u20131644.\"}"}
{"id": "lrec-2024-main-273", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In the following sections, we provide a series of summaries generated by ChartThinker, as illustrated in Figures 5 through 10.\\n\\nFigure 5: This is a bar chart. The chart shows the number of foreign students newly enrolled in associate, bachelor\u2019s, master\u2019s, or doctoral degree programs in different states in the United States. California has the highest number of foreign students enrolled in a degree program, with 59,801 students enrolled. New York follows with 41,040 students, while Texas has 26,701 students. Massachusetts has 19,901 students, Pennsylvania has 17,801 students, Illinois has 16,801 students, Florida has 15,701 students, Ohio has 10,801 students, Michigan has 9,801 students, and Washington has 9,801 students.\\n\\nFigure 6: This is a line chart. The chart shows the total political advertising revenue for six publicly held local TV station companies in the US from 2012 to 2018. The revenue decreased from 600 million in 2012 to 20 million in 2013, then increased to 700 million in 2014, decreased to 100 million in 2015, increased again to 800 million in 2016, decreased again to 100 million in 2017, and increased again to 1.3 billion in 2018. Therefore, the chart depicts a fluctuating trend of total political advertising revenue for six publicly held local TV station companies in the US during the six-year period, with an overall increasing trend from 2012 to 2018.\\n\\nFigure 7: This is a line chart. The chart shows the percentage of U.S. representatives who are women from 1966 to 2018. The lowest percentage was 2.5% in 1966 and there was an increase over the years. In 2018, the percentage was 24.1%. Overall, the chart shows that women represent a higher percentage than before.\\n\\nFigure 8: This is a line chart. The chart shows the percentage of adults without a spouse/partner present in the United States who are unpartnered, broken down by age group from 2007 to 2017. The percentage of all adults without a spouse/partner present increased slightly from 39% in 2007 to 42% in 2017. For the age under 35 years old, in 2007, 56% of those without a spouse/partner present, compared to 61% in 2017. For the age between 35 and 54 years old, in 2007, 29% of those without a spouse/partner present, compared to 30% in 2017. For the age between 55 and 64 years old, in 2007, 29% of those without a spouse/partner present, compared to 32% in 2017. For the age over 65 years old, in 2007, 43% of those without a spouse/partner present, compared to 41% in 2017. Overall, the chart suggests that many Americans in the United States are unpartnered, with an increase in the percentage of those without a spouse/partner present.\"}"}
{"id": "lrec-2024-main-273", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: This is a pie chart, according to a survey conducted by the Pew Research Center in December 2019, most Latino adults have not heard of the term Latinx; few use it. It shows that 76% of respondents said they have not heard of it, 3% said they use Latinx, and 20% said they have heard of it but did not use the term.\\n\\nFigure 10: This is a bar chart, the chart shows the harassment of Jews reached a seven-year high. The percentage has steadily increased over the years, with a peak of 39% in December 2013 and a low of 26% in June 2007. The number of harassment of Jews in 2008, 2009, 2010, 2011, and 2012 is 27%, 32%, 34%, 35%, and 36% respectively. The data suggests that there has been a significant increase in harassment among Jews in the United States over the past few years.\\n\\nFigure 11: This is a pie chart. The chart shows that half of U.S. adults seldom or never discuss religion with non-family. According to the 2014 U.S. Religious Landscape Study conducted by the Pew Research Center, 18% of U.S. adults believe that they discuss religion with people outside their family at least once a week, while 15% believe it is at least once or twice a month, and 18% believe it is several times a year. The remaining 33% of respondents seldom discuss religion with non-family. And 16% of them never talk about it.\\n\\nFigure 12: This is a pie chart. According to a survey conducted by the Pew Research Center in February 2015, 40% of respondents believed that President Obama should take the lead in solving the nation's problems, while 38% believed that Republican congressional leaders should take the lead. Only 17% of respondents believed that both/neither should take the lead, while 5% believed that DK should take the lead.\"}"}
