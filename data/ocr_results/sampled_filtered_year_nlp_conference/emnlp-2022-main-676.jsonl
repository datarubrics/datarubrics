{"id": "emnlp-2022-main-676", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Generative Entity-to-Entity Stance Detection\\nwith Knowledge Graph Augmentation\\n\\nXinliang Frederick Zhang\u00b9, Nick Beauchamp\u00b2, and Lu Wang\u00b9\\n\\n\u00b9Computer Science and Engineering, University of Michigan, Ann Arbor, MI\\n\u00b2Department of Political Science, Northeastern University, Boston, MA\\n\\n{xlfzhang,wangluxy}@umich.edu  \\nn.beauchamp@northeastern.edu\\n\\nAbstract\\nStance detection is typically framed as predicting the sentiment in a given text towards a target entity. However, this setup overlooks the importance of the source entity, i.e., who is expressing the opinion. In this paper, we emphasize the need for studying interactions among entities when inferring stances. We first introduce a new task, entity-to-entity (E2E) stance detection, which primes models to identify entities in their canonical names and discern stances jointly. To support this study, we curate a new dataset with 10,619 annotations labeled at the sentence-level from news articles of different ideological leanings. We present a novel generative framework to allow the generation of canonical names for entities as well as stances among them. We further enhance the model with a graph encoder to summarize entity activities and external knowledge surrounding the entities. Experiments show that our model outperforms strong comparisons by large margins. Further analyses demonstrate the usefulness of E2E stance detection for understanding media quotation and stance landscape, as well as inferring entity ideology.\\n\\n1 Introduction\\nNews media often employ ideological language to sway their readers, including criticizing entities they disagree with, and praising those conforming to their values (Baum and Groeling, 2008; Ledevsky, 2013). However, in many cases, the sources do not directly express their sentiments, in part due to the norm that \u201cobjective\u201d news media should restrict their role to narrating events and quoting others. In the realm of political news, many reported events consist of individuals or groups who themselves are engaged in praise or blame. The seemingly neutral act of choosing who to quote, and about what, as illustrated in Fig. 1, may be shaped by ideology and have significant effects on readers (Gentzkow and Shapiro, 2006; Gentzkow et al., 2015).\\n\\nFigure 1: Sample stance triplet annotations for a target sentence. Entities in SEESAW can be Person or Topic, and are annotated in canonical forms. Multiple stances are expressed, whose inference needs context information, e.g., \u201cpresident\u201d refers to Donald Trump.\\n\\nThere thus exists a pressing need to examine these expressions of support and opposition in news articles (West et al., 2014) in order to understand how even apparently nonpartisan media can bias readers via the selective inclusion of stances among entities. Recognizing stances among political entities and events is also important in its own right: if copartisans are more likely to be positive towards each other and vice versa for counter-partisans, this allows us to (1) propagate partisanship and ideology through the signed network (De Nooy and Kleinnijenhuis, 2013), (2) infer ideology not just for politicians, but for events or objects (e.g., a new bill) that may inherently support the positions of specific groups (Diermeier et al., 2012), and (3) illuminate the implicit ideology of a journalist or media outlet (Hawkins and Nosek, 2012).\\n\\nAs a first step towards these goals, this paper presents the first study on solving the task of entity-to-entity (E2E) stance detection in an end-to-end fashion: Given a target sentence and its surrounding context, we extract a sequence of stance triplets that can be inferred from the input. Each triplet consists of a source entity and their sentiment towards a target entity, with entities in their canonical forms.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Existing stance detection methods are largely designed to infer an author's overall sentiment towards a given entity (Sobhani et al., 2017; Li et al., 2021a) or topic (Vamvas and Sennrich, 2020; Allaway and McKeown, 2020). E2E stance detection, by contrast, presents a number of new challenges. First, entities can be involved in multiple and even conflicting sentiments within a sentence, as demonstrated in Fig. 1, suggesting the need to develop a model that can disentangle entity interactions. Second, entities are mentioned in various forms, e.g., full names or pronouns. Simply extracting the mentions would cause ambiguity for downstream applications. Canonical names that can be identified via knowledge bases (Shen et al., 2015) are thus preferred, which further requires the model to consider contextual information and global knowledge.\\n\\nIn this work, we first collect and annotate an E2E stance dataset, **SEESAW** (Stance between Entity and Entity supplemented with Article-level viewpoint), based on 609 news articles crawled from AllSides. SEESAW contains 10,619 stance triplets annotated at the sentence level, drawn from 203 political news stories, with each \u201cstory\u201d consisting of 3 articles by media of different ideological leanings, as collected, coded, and aligned by AllSides. Our entities cover people, organizations, events, topics, and other objects.\\n\\nWe then present a novel encoder-decoder generative framework to output stance triplets in order. We first enhance the text encoder with a graph model (Velickovic et al., 2018) encoding a semantic graph that summarizes global entity interactions in the context, using relations extracted by an open information extraction (OpenIE) system (Stanovsky et al., 2018). On the decoder side, we improve the transformer decoder block (Vaswani et al., 2017) with a task-customized joint attention mechanism to combine textual and graph representations. Finally, external knowledge, such as party affiliation or employment, is injected into the graph encoder by adding extra nodes initialized with pretrained representations from Wikipedia. This allows the system to better characterize entity relations.\\n\\nWe conduct experiments on the newly collected **SEESAW** to evaluate models' capability of generating stance triplets, and additionally evaluate on a task of stance-only prediction when pairs of entities are given. Our model outperforms competitive baselines on E2E stance detection by at least 21% (relatively, accuracy of 11.32 vs. 13.74), demonstrating the effectiveness of adding knowledge from context and Wikipedia via graph encoding. Our best model also outperforms its pipeline counterpart which first extracts entities and then detects sentiment. This highlights the end-to-end prediction capability of generative models. Finally, we demonstrate the usefulness of E2E stances for media stance characterization and entity-level ideology prediction. Notably, we find that 1) both left- and right-leaning media tend to quote more from the Republican politicians; and 2) there appears a symmetrical asymmetry in expressed stances: the left is balanced while the right is biased in terms of expressed positivity, but the reverse holds for negativity.\\n\\n### Related Work\\n\\n#### 2.1 Stance Detection\\n\\nTwo major types of stance detection are widely studied (Aldayel and Magdy, 2021): (1) sentiment-based, the goal of which is to uncover the implicit sentiment (favor/against) evinced in texts towards a target, which can be a person or a topic (Mohammad et al., 2016; Sobhani et al., 2017; Allaway and McKeown, 2020; Li et al., 2021a); (2) position-based, which concerns whether a text snippet agrees/disagrees with a given claim or a headline (Ferreira and Vlachos, 2016; Pomerleau and Rao, 2017; Chen et al., 2019; Hanselowski et al., 2019; Conforti et al., 2020). In this work, we focus on the sentiment-based stance detection. Existing datasets for stance annotations are mainly based on social media posts (Mohammad et al., 2016; Li et al., 2021a), making the assumption that the sentiment is always held by the author, thus ignoring source entity annotation. Overall, there are at least three limitations for the existing stance detection data: 1) Data samples are collected within a narrow time period, e.g., a year, about specific events (Sobhani et al., 2017; Li et al., 2021a). 2) Entities are annotated by their mentions only (Deng and Wiebe, 2015; Park et al., 2021), limiting their usage for downstream applications. 3) Annotations are only available at either sentence-level or article-level, but not both. By contrast, our data spans a...\"}"}
{"id": "emnlp-2022-main-676", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"10-year range at both sentence- and article-levels,\\nwith entities coded using canonical names.\\n\\nMethodologically, existing models are designed\\nfor detecting stances towards a specific target en-\\ntity (Mohammad et al., 2016; Augenstein et al.,\\n2016). However, early methods assume the target\\nentities in test time have been seen during train-\\ning (Du et al., 2017; Zhou et al., 2017; Xue and\\nLi, 2018). More recent work uses Large Language\\nModels (LLMs) to enable stance prediction on un-\\nseen entities (Li et al., 2021b; Glandt et al., 2021).\\n\\nThe most similar work to ours are Zhang et al.\\n(2020) and Liu et al. (2021), both using graph con-\\nvolutional networks (Kipf and Welling, 2017) to\\nadd external knowledge. Our model is different\\nin at least two key respects: (1) They use existing\\nknowledge bases, e.g., ConceptNet (Speer et al.,\\n2017), with limited coverage of political knowl-\\nedge. We instead resort to entity interactions ex-\\ntracted from news articles. (2) All prior models\\nare based on Transformer encoder (Vaswani et al.,\\n2017) only, while we explore the generative power\\nof encoder-decoder models to address the more\\nchallenging E2E stance detection task. Moreover,\\nnone of these methods detects multiple stances\\nfrom the same input, a gap that this work aims\\nto fill.\\n\\n2.2 Generative Models for Classification Task\\n\\nApplying generative models for classification has\\nrecently gained research attention, mainly enabled\\nby the wide usage of generative models, especially\\nthe large pretrained language models (Brown et al.,\\n2020; Raffel et al., 2020). The most significant\\nadvantage of using generative models for classi-\\nfication problems resides in the improved inter-\\npretability between label semantics and input sam-\\nples (Yan et al., 2021; Zhang et al., 2021), espe-\\ncially for multi-label classification problems (Yang\\net al., 2018; Liao et al., 2020; Yue et al., 2021).\\n\\nGenerative models are especially suitable for our\\ntask, since canonical names are preferred in the\\noutput. Recent work (Humeau et al., 2020; Cao\\net al., 2021) supports our assumption by showing\\nthat generative models are better at capturing fine-\\ngrained interactions between the text and entities\\nthan encoder-only models. This work carries out\\nthe first study of deploying such models for a new\\ntask, E2E stance detection. In addition, it extends\\nthe model with context information and external\\nknowledge.\\n\\n3 SEESAW Collection and Annotation\\n\\nWe use AllSides news sto-\\nries collected by Liu et al. (2022), where each story\\ncontains 1-3 articles on the same event but reported\\nby media of different ideology. The stories span\\nfrom 2012 to 2021. We only keep news stories with\\n3 articles and that are pertinent to U.S. politics. We\\nmanually inspect and select stories to cover diverse\\ntopics. The resulting SEESAW contains 52 topics\\n(full list in Table A1). We further clean articles by\\nremoving boilerplate and noisy text.\\n\\nWe hired six college students with high English\\nproficiency to conduct annotation tasks. Each per-\\nson is asked to read all articles written on the same\\nstory before annotating. We summarize the main\\nsteps below, with detailed protocol in Appendix A.\\n\\n1. They start with reading the article, and then\\nidentify entities of political interests that are\\ninvolved in sentiment expressions. An entity\\ncan have a type of person, organization, place,\\nevent, topic, or religion. Annotated entities\\nare categorized into\\nmain\\nand\\nsalient\\nentities.\\n\\n2. For\\neach sentence,\\nstance is annotated be-\\ntween entities in the triplet format, i.e.,\\n<\\nsource,\\nsentiment,\\ntarget>\\nwhere\\nsentiment can be either\\npositive\\nor\\nnegative.\\n\\nWe use\\nAuthor\\nas the source entity, if no\\nclear source entity is found. Also,\\nSomeone\\nis used to replace source or target entities of\\nno clear political interest, e.g., \u201ca neighbor\u201d.\\n\\n3. At the article level, we annotate its overall sen-\\ntiment towards each identified entity, together\\nwith the ideology of each entity as well as the\\nideological leaning of the article, all in 7-way.\\nWe then convert the annotations on sentiment\\nand ideological leaning into 3-way and 5-way,\\nrespectively.\\n\\nFinally, we conduct cross-document entity res-\\nolution by linking annotations to their\\ncanonical\\nnames\\naccording to Wikipedia, e.g., \u201cthis president\u201d\\nbecomes \u201cDonald Trump\u201d as in Fig. 1.\\n\\nA quality control procedure is designed to allow\\nannotators to receive timely feedback and improve\\nagreement over time. Details are in Appendix C.\\n\\nImportantly, over 60 randomly sampled articles,\\n4\\nMain entities\\nare defined as main event enablers and par-\\nticipants as well as the ones that are affected by such events.\\n\\nSalient entities\\nrefer to other political or notable figures that\\nappear in the news stories who are not the main entities.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the average overlap of annotated entities between pairs of coders is 55.5%. When both source and target entities match, the sentiment agreement level is 97%, indicating the high quality of the dataset.\\n\\nStatistics.\\n\\nSEESAW includes 609 news articles from 203 stories, published by 24 different media outlets (9 left, 6 central, and 9 right). Table A2 lists all the media outlets. On average, each article contains 28 sentences and 647 words. 44% of sentences per article have at least one stance annotation, among which 29% have at least two.\\n\\nIn total, there are 10,619 stance annotations in SEESAW, covering 1,757 distinct entities. 62.4% of the triplets have negative sentiment.\\n\\nEntity types in SEESAW cover People (49.6%), Organization (12.8%), Place (4.2%), Event (12.0%), Topic (17.4%), Religion (0.2%), and Others (3.8%), showing its diversity of entity annotations. It is worth noting that the source entity being <Author> and <Someone> occurs 9.1% and 12.5% of the annotations. Meanwhile, the number for target entity being <Someone> is 5.3%.\\n\\nIn terms of entity ideology, the portions of entities annotated as liberal, moderate, and conservative is 31.0%, 15.9%, and 34.6%, respectively. Our annotated article leanings align with AllSides' media-level labels for 76.7% of the time.\\n\\n4 Generative E2E Stance Detection\\n\\nFig. 2 depicts the end-to-end generative framework that reads in a document and produces stance triplets in an auto-regressive fashion, by leveraging multiple knowledge sources using graph augmentation. We use BART (Lewis et al., 2020), a large pretrained encode-decoder model, as the backbone. Taking as input a target sentence from a document $d$, our model first constructs a semantic graph $G$ (\u00a74.1), which is encoded via the graph encoder (\u00a74.2). The contextualized representations of tokens and nodes are denoted as $H_T$ and $H_G$.\\n\\nStance triplets are generated by our decoder using improved in-parallel attention and information fusion mechanisms (\u00a74.3). Moreover, we inject Wikipedia knowledge to support the identification of relations between entities (\u00a74.5). Below we describe the main components, with additional formulation and implementation details in Appendix B.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We then add directed edges from subject to predicate and from predicate to object. We add reverse edges and self-loops to enhance graph connectivity and improve information flow.\\n\\n4.2 Graph Encoder\\n\\nWe initialize node representations $H_G$ by using the average contextual token embeddings ($H_T$) of all co-referential mentions. Similar to Yasunaga et al. (2021), we add a global node, initialized with mean pooling over all tokens in the target sentence. The global node is connected to entity nodes in $G$ to allow better communication of text knowledge.\\n\\nOur graph encoder improves upon Graph Attention Networks (GAT; Velickovic et al., 2018) using Transformer layer networks and Add & Norm structures (Vaswani et al., 2017). Concretely, in each layer, we use the multi-head GAT massage passing rule to update node representations $H_G$, and then pass them through a 2-layer MLP. Residual connections (He et al., 2016) and layer normalization (Ba et al., 2016) are employed to stabilize the hidden state dynamics. We use two layers with 8-head GAT to produce final node representations $H_G$.\\n\\n4.3 Decoder\\n\\nWe further improve the Transformer decoder to enable reasoning over both the text and the graph. The key difference between the vanilla Transformer decoder and ours is the in-parallel cross-attention layer which allows better integration of knowledge encoded in the two sources. Concretely, in-parallel cross attentions are implemented as follows:\\n\\n$$z_T = \\\\text{LayerNorm}(z + \\\\text{Attn}(z, H_T))$$\\n$$z_G = \\\\text{LayerNorm}(z + \\\\text{Attn}(z, H_G))$$\\n\\nwhere $z$ denotes the output from the self-attention layer and Attn($\\\\cdot$, $\\\\cdot$) is the same cross-attention mechanism as implemented in Vaswani et al. (2017).\\n\\nNext, we introduce an information fusion module to enable the interaction between textual ($z_T$) and graph ($z_G$) hidden states, in order to obtain the fused representation, $z'$. We implement two information fusion operations: (1) addition, i.e., $z' = z_T + z_G$, and (2) gating mechanism between $z_T$ and $z_G$ as in Zhao et al. (2018) except that we use GELU($\\\\cdot$) as the activation function. The operation selection is determined by downstream tasks.\\n\\n4.4 Training Objectives\\n\\nWe adopt the cross entropy training objective for model training, $L_{\\\\text{stance}}$. The reference $y$ is a sequence of ground-truth stance triplet(s), sorted by their entities' first occurrences in the target sentence. Input and output formats are shown in Fig. 2.\\n\\n**Variant with Node Prediction.** In addition to modeling entity interactions in the graph, we enhance the model by adding an auxiliary objective to predict node salience, i.e., whether the corresponding entity should appear in the stance triplets $y$ to be generated. This is motivated by the observation that $G$ usually contains excessive entity nodes, only a small number of which are involved in sentiment expression in the target sentence. Specifically, for each entity node, we predict its salience by applying affine transformation over its representation $h_G$, followed by a sigmoid function to get a single value in $[0, 1]$. We adopt the binary cross entropy (BCE) objective to minimize the loss $L_{\\\\text{node}}$ over all entity nodes. Finally, when the node prediction module is enabled, the overall loss for the multitask learning setup is $L_{\\\\text{multi}} = L_{\\\\text{stance}} + L_{\\\\text{node}}$.\\n\\n4.5 Graph Expansion: Wiki Knowledge Injection\\n\\nTo gain a better understanding of stances among entities over controversial issues, it is useful to access external knowledge about the entities mentioned in the news, e.g., their party affiliations. Therefore, we obtain the knowledge representations for entities using Wikipedia2Vec (Yamada et al., 2020), a tool that jointly learns word and entity embeddings from Wikipedia. The learned entity embeddings are shown to be effective in encoding the background knowledge discussed in Wikipedia. These embeddings are then added as wiki nodes in graph $G$. We add edges between an entity node and a wiki node, if the entity is linked to the corresponding Wikipedia entry based on entity linking.\\n\\nIn our implementation, we take the pre-trained 500-dimensional vectors, transformed by a two-layer MLP, for node representations initialization. To summarize, graph-augmented generative models have been studied for several generation tasks, including abstractive summarization (Huang et al., 2020), question answering (Yasunaga et al., 2021), and question generation (Su et al., 2020). Prior design of graph encoders uses either external knowledge bases (Zhang et al., 2022) or a local graph constructed using semantic parsing (Cao and\"}"}
{"id": "emnlp-2022-main-676", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 1: Statistics of the two datasets for experiments.\\n\\nData by Park et al. (2021) only contains single sentences without context. We split the SEESAW chronologically, and use the same splits as in Park et al. (2021). Since large-scale structured knowledge base does not exist for the political domain, our method differs from previous work in that we leverage both entity interactions from the context and external knowledge from Wikipedia in a unified graph representation learning framework to better characterize entity interactions.\\n\\n5 Experiments\\n\\n5.1 Tasks and Datasets\\n\\nWe conduct evaluation on two different stance detection tasks. Table 1 shows the basic statistics of datasets and splits.\\n\\nTask A: Entity-to-entity stance detection. We experiment with SEESAW for generating stance triplets of \\\\(<source, sentiment, target>\\\\). The input text can be a target sentence alone or with surrounding context (up to \\\\(k\\\\) preceding and \\\\(k\\\\) succeeding sentences). We set \\\\(k = 3\\\\) for all experiments.\\n\\nTask B: Stance-only prediction for pairwise entities. Park et al. (2021) build a dataset annotating sentiments between mentions rather than canonical entities. We include this dataset to assess our model\u2019s capability on a stance-related classification task. For experiments, we only keep samples with positive and negative sentiments. Formally, their input contains one sentence \\\\(s\\\\) and two entities \\\\(e_1\\\\) and \\\\(e_2\\\\). The goal is to jointly predict the direction and the sentiment, i.e., four labels in total.\\n\\n5.2 Baselines\\n\\nFor Task A, since there is no existing E2E stance detection models, we consider finetuning BART using different inputs as baselines: (1) sentence: target sentence only; (2) sentence + context: target sentence with surrounding context; (3) sentence + context + entities: additionally appending all entities in their canonical names as extracted in \u00a74.1, same as our model\u2019s input.\\n\\nWe further consider two variants of our model as baselines. We first design a pipeline model, which first uses the node prediction module to identify salient entities for inclusion in the stance triplets. Then we introduce a soft mask layer over entity nodes in \\\\(G\\\\) before passing them into the graph encoder, by multiplying node representations with their predicted salience scores. We also experiment with oracle entities, where we feed in the ground-truth salient entities for text encoding and graph representation learning.\\n\\nFinally, to test the effectiveness of our designed in-parallel cross-attention, we compare with a sequential attention, designed by Cao and Wang (2021), to consolidate text and graph modalities. They allow the decoder hidden states to first attend token and then node representations. Their model differs from our model only in the attention design.\\n\\nOn Task B, since LLMs have obtained the state-of-the-art performance on existing stance prediction tasks (Glandt et al., 2021; Liu et al., 2022), we compare with the following LLM-based methods in addition to BART. We compare with DSE2QA (Park et al., 2021), which is built on top of RoBERTa (Liu et al., 2019). They transform the sentiment classification task into yes/no question answering, where the questions ask whether a sentiment can be entailed from several manually designed questions appended after the target sentence. We use the question that obtained the best performance on their dataset, i.e., \u201c\\\\(e_1\\\\)-\\\\(e_2\\\\)-[sentiment]\u201d.\\n\\nWe then consider a recent LLM, POLITICS (Liu et al., 2022), trained on RoBERTa with ideology-driven pretraining objectives that compare articles on the same story.\\n\\n5.3 Evaluation Metrics\\n\\nFor both tasks, we report accuracy and F1 scores. For Task A, accuracy is measured at the sample level, i.e., all stance triplets need to be generated correctly to be considered as correct. F1 is instead measured at the triplet level. We include another metric, accuracy-any, where for each sample, the prediction is considered correct if at least one triplet is found in the reference. We also break down the triplets, and evaluate varying aspects based on pairs of source entity-sentiment (\\\\(src-s\\\\)), sentiment-target entity (\\\\(s-tgt\\\\)), and source-target entities (\\\\(src-tgt\\\\)), using accuracy-any.\\n\\n5.4 Results\\n\\nResults for E2E stance detection is displayed in Table 2. Compared with baselines, we see significant improvements by providing context and entities in canonical forms, indicating that adding story context and additional knowledge about entity names...\"}"}
{"id": "emnlp-2022-main-676", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Results on SEESAW for E2E stance detection task, and breakdown of accuracy scores by aspects (average of 5 runs). Best results without oracle entities are in **bold**. Our graph-augmented model with Wikipedia knowledge performs the best on 4 out of 6 metrics, indicating the effectiveness of encoding knowledge. Results with standard deviation are in Table A3.\\n\\nNext, though the pipeline variant of our model provides better explainability as it first identifies salient entities, it yields inferior performance than the end-to-end version of our model. After inspection, we find that the salient entity prediction module only reaches around 58% for F1. With the oracle entities as input, we see a significant boost in the performance, highlighting the importance and difficulty of entity understanding and extraction.\\n\\nImportantly, our model enhanced with Wikipedia knowledge performs the best on 4 out of 6 metrics. This signifies the effective design of graph modeling on entity interactions. Moreover, our newly designed in-parallel attention is also shown to be more effective than attending the two sources of information in sequence, as done in Cao and Wang (2021). This implies that having symmetric integration of text and graph can be important, though this should be tested on other tasks in future work. When breaking down the predicted stance triplets into different pairs, we see that identifying source entity and sentiment is easier than predicting sentiment and target entity. This might be because target entities are often introduced earlier in the article, thus requiring long-term discourse understanding.\\n\\nFinally, the overall performance of E2E stance detection is quite low for all models. This is mainly because models may fail to generate exactly the same canonical names for entities and often fall short of producing all stance instances when multiple sentiments are embedded in a single sentence.\\n\\nTable 3: Results on stance-only prediction for specified pairwise entities. Our model performs on par with state-of-the-art models in stance detection tasks (POLITICS and DSE2QA). Results with std. deviation in Table A4.\\n\\nOn the stance-only prediction task, Table 3 shows that our model yields better or comparable performance than the state-of-the-art models. This demonstrates that our generative stance detection model can also perform well on a quaternary classification setup. Note that the input text is short (\u223c30 tokens), limiting our model\u2019s capability of capturing global context. However, our model still outperforms BART and the recently trained LLM, POLITICS, designed for ideology prediction and stance detection. The experimental results are in-line with Lewis et al. (2020) that the improvements on generation tasks do not come at the expense of classification performance.\\n\\n5.5 Sample Output and Error Analysis\\n\\nFig. 3 shows one test example with system outputs from baselines and our models. All three baseline models detect a positive sentiment ascribed to Mike Pence but fail to uncover the specific target entity. However, our graph-augmented model manages to produce stance triplet [1], using the direct edge linking Kamala Harris and Donald Trump through a negative predicate in the corresponding graph G.\\n\\nWe also find that our model using Wikipedia knowledge often uncovers hidden relations between entities, e.g., party affiliations and geopolitical relations, which are useful for stance detection but cannot be inferred from the document alone. Such as in this example, to enable the generation of stance triplet [0], our model leverages Wikipedia knowledge to draw the connection between Wisconsin and \\\"the state\\\" in the news. Moreover, this example showcases the power of our model in generating multiple stances, which is an essential capability for the E2E stance detection task. In Fig. A1, we show another example, where none of the models produces a correct stance triplet, further confirming the challenge posed by E2E stance detection. This points out the future direction of investigating more powerful models that can better make inferences and perform reasoning over knowledge.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Ms. Harris, who is making her first trip to a battleground state since joining the Democratic ticket, is visiting with union workers and leaders as well as African-American businesspeople and pastors in Milwaukee, the Black hub of the state.\\n\\nEach is expected to focus on the economy, with Mr. Pence hailing the state\u2019s job growth before the coronavirus pandemic and Ms. Harris critiquing the administration\u2019s handling of the virus and the resultant impact on the economy. Yet their political missions are different. The vice president is hoping to appeal to voters in a historically Democratic part of Wisconsin, where Mr. Trump outperformed his Republican predecessors, in hopes they abandon their political roots again.\\n\\nGraph model (ours): [0] Mike Pence POS job growth; [1] Kamala Harris NEG Donald Trump\\n\\nGraph model + Wiki (ours): [0] Mike Pence POS Wisconsin; [1] Kamala Harris NEG Donald Trump\\n\\nFigure 3: Sample system predictions (below the dotted line) with human labeled triples (above the dotted line).\\n\\nTarget sentence is underlined. All three baselines fail to identify the correct target entity. By contrast, our graph-augmented end-to-end model predicts the first triplet by leveraging the semantic relation as captured by graph $G$.\\n\\nAfter encoding Wikipedia knowledge, our model draws the connection between Wisconsin and \u201cthe state\u201d in the text, thus generating a correct stance triplet [0]. Our models also produce multiple triplets.\\n\\n6 Further Analysis\\n\\nIn SEESAW, we are able to identify the partisanship of 204 politicians (Democrat vs. Republican) based on Voteview.\\n\\nThis subset accounts for more than 60% of person mentions in the dataset. We further include Democrat and Republican as two separate entities, since they are also frequently mentioned in news. Analyses in this section are done based on this entity set (henceforth analysis set).\\n\\n6.1 Landscape of Media Quotation and Stance\\n\\nWe start with examining the relation between media ideology and their stances. We first study do media tend to quote people of the same or opposite ideologies?\\n\\nTo answer this question, we count the average number of political figures quoted as source entities in each article. Interestingly, media from both sides are more likely to quote Republican politicians, as seen in Fig. 4. This is consistent with recent study on U.S. TV media (Hong et al., 2021), where the authors show that Republicans receive more screen time as well as get longer TV interview time than Democrats.\\n\\nAdditionally, left-leaning outlets use more quotes than their right counterparts, which also aligns with previous observations (Welch et al., 1998).\\n\\nNext, we ask: do media tend to be more positive towards people with the same ideology as theirs and be more negative towards out-group entities?\\n\\nHere we consider stance triplets containing the target entities in the analysis set. First, as can be seen from Fig. 5, more negative sentiments are observed in news articles, which align with existing work that shows journalists more often report blame than praise (Damstra et al., 2020). More importantly, we observe an interesting sentiment pattern of symmetrical asymmetry: Left-leaning media produces articles use similar amounts of positivity towards Democrats and Republicans (15.4% vs. 15.8%), while right-leaning media are more positive towards Republicans (18.8% vs. 8.7%). By contrast, when it comes to negativity, right-leaning media are more balanced (36.4% vs. 36.1%), while left-leaning media are unbalanced (25.6% to Democrat vs. 43.2% to Republicans). This suggests that the left and right media may be biased in different ways: the left by directing more negativity to the opposing side, the right by directing more positivity towards their own side.\\n\\n6.2 E2E Stances for Ideology Prediction\\n\\nHere we test whether the knowledge of E2E stances can help with entity-level ideology prediction. Based on the sentiments expressed among politicians, we construct a directed graph with edges indicating the direction and sentiment between entities.\\n\\nBy original authors (Hong et al., 2021), the conclusion of interview time might not be true due to biased data sampling.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 5: Percentage of stance triplets that media favoring or criticizing entities from the same or the opposite side. Media of both sides attack politicians from the opposite parties more than their own parties. Note there is a symmetrical asymmetry phenomenon: Left is balanced while the right is unbalanced in terms of indicated positivity, and the other way around for negativity.\\n\\n6.3 Inter- and Intra-group Sentiment\\n\\nFinally, we observe that the majority of inter-party instances are negative, e.g., $92.7\\\\%$ of sentiment by Democratic politicians towards Republicans is negative, and the number of Republicans is $91.9\\\\%$. This is unsurprising given the current level of polarization in the U.S. (Campbell, 2018; Klein, 2020).\\n\\nNotably, the Republican Party is much more divided compared with Democrats, where more than half of intra-group stances (i.e., $56.0\\\\%$) within Republican Party carry negative sentiments, whereas the percentage for Democrats is only $25.2\\\\%$. These results contradict recent observations for in-group sentiment as measured on social media users and congressional members (Grossmann and Hopkins, 2016; Benkler et al., 2018). This highlights the significance of studying stances quoted by news media and suggests new avenues for future research.\\n\\n7 Conclusion\\n\\nWe present and investigate a novel task: entity-to-entity (E2E) stance detection, with the goal of extracting a sequence of stance triplets from a target sentence by jointly identifying entities in their canonical names and discerning stances among them. To support this study, we annotate a new dataset, SEESAW, with 10,619 sentence-level annotations. We propose a novel end-to-end generative framework to output stance triplets. Specifically, we enhance standard encoder-decoder models with a semantic graph to capture entity interactions within context. We further augment our model with external knowledge learned from Wikipedia, yielding the best overall performance. We conduct further analyses to demonstrate the effectiveness of E2E stances on media landscape characterization and entity ideology prediction.\\n\\nAcknowledgments\\n\\nThis work is supported in part through National Science Foundation under grant IIS-2127747, Air Force Office of Scientific Research under grant FA9550-22-1-0099, and computational resources and services provided by Advanced Research Computing (ARC), a division of Information and Technology Services (ITS) at the University of Michigan, Ann Arbor. We appreciate the anonymous reviewers for their helpful comments. We thank David Wegsman, Isabella Allada, Margaret Petersson, Jiayi Zhang and Bingyan Hu for their efforts in SEESAW construction. We also thank Jiayi Zhang and Hongyi Yin for conducting data checking.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Limitation\\n\\nGPU resources\\n\\nThe framework proposed in this work is an encoder-decoder based generative model. It is thus more time-consuming than standard discriminative models for training and evaluation, which in turn results in higher carbon footprint. Specifically, we run our experiments on 1 single NVIDIA RTX A6000 with significant CPU resources. The training time for our model is usually around 5 hours.\\n\\nSystem limitation\\n\\nIn spite of achieving the best performance on E2E instance detection and comparable performance with the SOTA model (Park et al., 2021) on the task of stance-only prediction given pairwise entities, our model is still limited in the following aspects.\\n\\n1. From Table 2, even the best model struggles with extracting correct <source, target> pairs.\\n2. Though we have pre-processed the data and conducted global entity linking, which helps with entity-level coreference resolution, better designs are needed to help resolve event coreference. Concretely, as shown in Fig. A1, our best model still suffers from making sense of the correct relation between \u201csuch an action\u201d and \u201caffidavit\u201d.\\n\\nEvaluation limitation\\n\\nWe believe the high-quality annotations and diverse entities in our SEESAW can help foster research along this novel research direction. However, the adopted evaluation schemes still have their own shortfalls. For example, in Fig. 3, our model\u2019s output, Mike Pence POS job growth, can be considered as correct. Yet, under the current automatic evaluation scheme, this prediction is counted as a mistake. More robust and accurate metrics need to be developed to gauge the research progress.\\n\\nEthical Consideration\\n\\nSEESAW collection.\\n\\nAll news articles were collected in a manner consistent with the terms of use of the original sources as well as the intellectual property and the privacy rights of the original authors of the texts, i.e., source owners. During data collection, the authors honored privacy rights of content creators, thus did not collect any sensitive information that can reveal their identities. All participants involved in the process have completed human subjects research training at their affiliated institutions. We also consulted Section 107 of the U.S. Copyright Act and ensured that our collection action fell under the fair use category.\\n\\nSEESAW annotation.\\n\\nIn this study, manual work is involved. All the participants are college students, who participated in the project for credits rather than compensation. We treat every annotator fairly by holding weekly meetings to give them timely feedbacks and grade them quite leniently to express our appreciation for their consistent efforts.\\n\\nBenefit and Potential Misuse of our developed Systems and SEESAW\\n\\nIntended use.\\n\\nThe models developed in this work can assist the general public to measure and understand stance evinced in texts. For example, our model can be deployed in wild environments to automatically extract stance triplets at no cost.\\n\\nFailure mode is defined as situations where our model fails to correctly extract a stance triplet of a given text. In such cases, our model might deliver misinformation or cause misunderstanding towards a political figure or a policy. For vulnerable populations (e.g., people who maybe not be able to make the right judgements), the harm could be tremendously magnified when they fail to interpret the model outputs or blindly trust systems\u2019 outputs. Ideally, the interpretation of our model\u2019s predictions should be carried out within the broader context of the source text.\\n\\nMisuse potential.\\n\\nUsers may mistakenly take the machine prediction as a golden rule or a fact. We would recommend any politics-related machine learning models, including ours, put up an \u201cuse with caution\u201d message to encourage users to check more sources or consult political science experts to reduce the risk of being misled by single source. Moreover, our developed system might be misused to label people with a specific stance towards an issue that they do not want to be associated with. We suggest that when in use the tools should be accompanied with descriptions about their limitations and imperfect performance, as well as allow users to opt out from being the subjects of measurement.\\n\\nBiases and bias mitigation.\\n\\nNo known bias is observed in SEESAW since we collected balanced views of news stories from AllSides. During annotations, annotators were not biased since they have 11https://www.copyright.gov/title17/92chap1.html#107.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"the full access to all articles reporting on the same event but published by media of different ideology. Meanwhile, our developed systems were not designed to encode bias. In the training phase, we split the data on the story level, i.e., one story consisting of three articles from different ideologies, and we believe such training paradigm would help mitigate bias to a certain degree.\\n\\nPotential limitation. Although balanced views are considered, the topic coverage in SEESAW is not exhaustive, and does not include other trending media or content of different modalities for expressing opinions, such as TV transcripts, images, and videos. Thus, the predictive performance of our developed system may still be under investigated.\\n\\nIn conclusion, there is no greater than minimal risk/harm introduced by either our dataset SEESAW or our developed novel system using it. However, to discourage misuse of SEESAW or stance detection related systems, we will always warn users that systems' outputs are for informational purpose only and users should always resort to the broader context to reduce the risk of absorbing biased information.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "emnlp-2022-main-676", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Andreas Hanselowski, Christian Stab, Claudia Schulz, Zile Li, and Iryna Gurevych. 2019. A richly annotated corpus for different tasks in automated fact-checking. In Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), pages 493\u2013503. Association for Computational Linguistics.\\n\\nCarlee Beth Hawkins and Brian A Nosek. 2012. Motivated independence? Implicit party identity predicts political judgments among self-proclaimed independents. Personality and Social Psychology Bulletin, 38(11):1437\u20131452.\\n\\nKaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770\u2013778.\\n\\nJames Hong, Will Crichton, Haotian Zhang, Daniel Y. Fu, Jacob Ritchie, Jeremy Barenholtz, Ben Hannel, Xinwei Yao, Michaela Murray, Geraldine Moriba, Maneesh Agrawala, and Kayvon Fatahalian. 2021. Analysis of faces in a decade of US cable TV news. Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining.\\n\\nLuyang Huang, Lingfei Wu, and Lu Wang. 2020. Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5094\u20135107, Online. Association for Computational Linguistics.\\n\\nSamuel Humeau, Kurt Shuster, Marie-Anne Lachaux, and Jason Weston. 2020. Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring. In ICLR.\\n\\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015.\\n\\nThomas N. Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.\\n\\nEzra Klein. 2020. Why We\u2019re Polarized. Simon and Schuster.\\n\\nMatthew Levendusky. 2013. Partisan media exposure and attitudes toward the opposition. Political Communication, 30(4):565\u2013581.\\n\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In ACL.\\n\\nWeizhi Liao, Yu Wang, Yanchao Yin, Xiaobing Zhang, and Pan Ma. 2020. Improved sequence generation model for multi-label classification via CNN and initialized fully connection. Neurocomputing, 382:188\u2013195.\\n\\nRui Liu, Zheng Lin, Yutong Tan, and Weiping Wang. 2021. Enhancing zero-shot and few-shot stance detection with commonsense knowledge graph. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3152\u20133157. Association for Computational Linguistics.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A robustly optimized Bert pretraining approach.\\n\\nYujian Liu, Xinliang Frederick Zhang, David Wegsman, Nicholas Beauchamp, and Lu Wang. 2022. POLITICS: Pretraining with same-story article comparison for ideology prediction and stance detection. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 1354\u20131374.\\n\\nMonty G. Marshall. 2005. Political conflict, measurement of. In Kimberly Kempf-Leonard, editor, Encyclopedia of Social Measurement, pages 89\u201398. Elsevier, New York.\\n\\nSaif Mohammad, Svetlana Kiritchenko, Parinaz Sobhani, Xiaodan Zhu, and Colin Cherry. 2016. A dataset for detecting stance in tweets. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), pages 3945\u20133952. European Language Resources Association (ELRA).\\n\\nDavid Moss. 2017. Democracy: A Case Study. Belknap Press of Harvard University Press, 2017.\\n\\nKunwoo Park, Zhufeng Pan, and Jungseock Joo. 2021. Who blames or endorses whom? Entity-to-entity directed sentiment extraction in news text. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 4091\u20134102. Association for Computational Linguistics.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":null}"}
{"id": "emnlp-2022-main-676", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"sentiment analysis. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 504\u2013510. Association for Computational Linguistics.\\n\\nXikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D. Manning, and Jure Leskovec. 2022. Greaselm: Graph reasoning enhanced language models for question answering. CoRR, abs/2201.08860.\\n\\nYao Zhao, Xiaochuan Ni, Yuanyuan Ding, and Qifa Ke. 2018. Paragraph-level neural question generation with maxout pointer and gated self-attention networks. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 3901\u20133910. Association for Computational Linguistics.\\n\\nYiwei Zhou, Alexandra Ioana Cristea, and Lei Shi. 2017. Connecting targets to tweets: Semantic attention-based model for target-specific stance detection. In WISE.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Annotation Guideline\\n\\nStep 1: Entity annotation:\\nFirst, read the entire article and list the entities as well as their corresponding types.\\n\\nMain entities are the major subjects, objects, or participants involved in the main events described in the article.\\n\\nSalient entities broadly refer to political or notable figures that appear in the news stories even if they are not the main ones, including public figures, celebrities, or other important people, events, or subjects. Entities are always nominals (i.e., nouns or noun phrases), with examples and corresponding types listed below.\\n\\n| Entity Name          | Entity Types   |\\n|----------------------|----------------|\\n|                      | {People, Orga-|\\n|                      | nization, Place, Event, Religion, Topic, Other} |\\n\\nEntity Name must be a span of a text (please copy-and-paste from the text and stay with the surface form). If multiple versions exist, please use the most formal and complete span in the article. For example, the entity name for \\\"Mayor Ben Zahn II\\\", \\\"Ben Zahn\\\", \\\"Zahn\\\" or \\\"he\\\" (when referring to the entity) should be \\\"Mayor Ben Zahn III\\\".\\n\\nEntity Types are from the set of {People, Organization, Place, Event, Religion, Topic, Other}.\\n\\nStep 2: Sentiment annotation:\\nNext, read one sentence at a time and for each sentence annotate the sentiment held by one mentioned entity (subject) towards another entity (object) in the triplet format of <subject, sentiment, object>. Either the subject, the object, or both must be in the entity list annotated in Step 1. Do not annotate relationships where neither subject nor object is in the entity list, but feel free to add to these list if you discover any entities you missed in step 1. If there are multiple triplets in a sentence, please annotate all fairly clearly sentiments in that sentence. If a sentence does not contain any triplet with at least one entity, leave it blank.\\n\\nSubject or Object values are {entities, \\\"Not in the list\\\", and \\\"None\\\"}. \\\"Not in the list\\\" should be used when a subject or object does not appear in the Entity list from Step 1. Note that when neither subject nor object appear in the list, the triplet should not be coded. \\\"None\\\" is used in cases where the subject or the object does not exist, or cannot be identified.\\n\\nSentiment values are from the {Positive, Negative}. Note: Subject and object must be 1) explicitly mentioned in the text or 2) implicitly referred to by a pronoun (e.g., he, his) or by their titles (e.g., US President => Joe Biden), or 3) can be straightforwardly inferred from the context, e.g., the speaker identity is mentioned in previous sentences.\\n\\nNews topic # of news stories\\n\\n| Topic                      | Stories |\\n|----------------------------|---------|\\n| Elections                  | 30      |\\n| Politics                   | 16      |\\n| White House                | 15      |\\n| US House                   | 11      |\\n| US Senate                  | 10      |\\n| Immigration                | 10      |\\n| Violence in America        | 7       |\\n| Federal Budget             | 7       |\\n| Gun Control and Gun Rights | 7       |\\n| Healthcare                 | 6       |\\n| US Congress                | 5       |\\n| Coronavirus                | 5       |\\n| Supreme Court              | 4       |\\n| Justice Department         | 4       |\\n| National Security          | 4       |\\n| National Defense           | 4       |\\n| State Department           | 3       |\\n| Economic Policy            | 3       |\\n| Terrorism                  | 3       |\\n| Economy and Jobs           | 3       |\\n| LGBT Rights                | 3       |\\n| Labor                      | 2       |\\n| Holidays                   | 2       |\\n| Race and Racism            | 2       |\\n| Nuclear Weapons            | 2       |\\n| FBI                        | 2       |\\n| Justice                    | 2       |\\n| Sexual Misconduct          | 2       |\\n| Abortion                   | 2       |\\n| Education                  | 2       |\\n| Impeachment                | 2       |\\n| Free Speech                | 2       |\\n| Treasury                   | 2       |\\n| Republican Party           | 1       |\\n| Religion and Faith         | 1       |\\n| Campaign Finance           | 1       |\\n| Inequality                 | 1       |\\n| Donald Trump               | 1       |\\n| Homeland Security          | 1       |\\n| US Military                | 1       |\\n| Public Health              | 1       |\\n| Criminal Justice           | 1       |\\n| Voting Rights and Voter Fraud | 1    |\\n| Joe Biden                  | 1       |\\n| NSA                        | 1       |\\n| Veterans Affairs           | 1       |\\n| Cybersecurity              | 1       |\\n| World                      | 1       |\\n| Middle East                | 1       |\\n| Family and Marriage        | 1       |\\n| Taxes                      | 1       |\\n| Total                      | 203     |\\n\\nTable A1: Number of news stories for each topic in SEESAW.\"}"}
{"id": "emnlp-2022-main-676", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Media outlet # of articles Media-level ideology\\nWashington Times 100 Far Right\\nCNN (Online News) 58 Far Left\\nNew York Times (News) 52 Lean Left\\nHuffPost 51 Far Left\\nWashington Post 45 Lean Left\\nPolitico 44 Lean Left\\nUSA TODAY 38 Lean Left\\nNPR (Online News) 32 Center\\nNewsmax (News) 32 Far Right\\nTownhall 23 Lean Right\\nThe Hill 23 Central\\nReuters 21 Central\\nBBC News 15 Central\\nFox News (Online News) 13 Lean Right\\nBreitbart News 11 Lean Right\\nNational Review 11 Lean Right\\nVox 10 Far Left\\nThe Guardian 10 Lean Left\\nReason 7 Far Right\\nChristian Science Monitor 7 Center\\nWashington Examiner 2 Far Right\\nTheBlaze.com 2 Central\\nWall Street Journal (News) 1 Center\\nSalon 1 Far Left\\nTotal 609 -\\n\\nTable A2: Number of articles collected from each source and corresponding media-level ideology based on All-Sides label.\\n\\nStep 3: Article-level entity-targeted sentiment annotation:\\nNext, having read the whole article, please annotate the overall article-level sentiments towards all listed entities based on your reading. If you are unsure about the sentiment, please mark it \\\"Unknown\\\".\\n\\nArticle-level sentiment values are {Very Positive, Positive, Slightly Positive, Neutral, Slightly Negative, Negative, Very Negative, Unknown}.\\n\\nStep 4: Entity ideology annotation:\\nNext, annotate the ideology of entities based on your reading. Entity ideologies must be determined or inferred based on a combination of your knowledge of the article, your knowledge of the overall political context, and your sentiment annotation. If there is no clear identifiable ideology associated with an entity, please mark it \\\"Not Applicable\\\".\\n\\nEntity ideology values are from {Very liberal, Liberal, Slightly liberal, Moderate, Slightly conservative, Conservative, Very conservative, Not Applicable}.\\n\\nStep 5: Media-source ideology annotation:\\nFinally, attempt to estimate the ideology of the media organization that published this article. If you are unsure about the ideology, please mark it \\\"Unknown\\\".\\n\\nMedia-source ideology values are from {Very liberal, Liberal, Slightly liberal, Moderate, Slightly conservative, Conservative, Very conservative, Unknown}.\\n\\nPost-hoc conversion:\\nWe further convert fine-grained labels obtained in steps 3 through step 5 to coarse-grained labels according to the nature of each task. For sentiment annotation, we convert them as 3-way labels. Specifically, we convert very positive and positive into one positive category, and similarly for very negative and negative. Then we merge slightly positive, neutral, and slightly negative into neutral. For ideological labels obtained in steps 4 and 5, in light of the 5-way annotation provided by AllSides, we also convert ours as 5-way labels by merging very liberal and liberal into liberal, and similarly for very conservative and conservative.\\n\\nB Details of Our Model\\nThis section is supplementary to \u00a74.3 and \u00a74.4 in the main content, with more details about mathematical formulations and implementation details.\\n\\nOur framework takes as input a multi-sentence document, \\\\( x = \\\\{x_1, \\\\ldots, x_{k+1}, \\\\ldots, x_{k+t}, \\\\ldots, x_L\\\\} \\\\), where the target sentence is in \\\\( x \\\\), i.e., \\\\( \\\\tilde{x} = \\\\{x_{k+1}, \\\\ldots, x_{k+t}\\\\} \\\\). Our model first generates a semantic graph \\\\( G \\\\) as described in \u00a74.1. \\\\( x \\\\) and \\\\( G \\\\) are consumed by BART encoder (Lewis et al., 2020) and graph encoder (\u00a74.2) separately, producing token representation, \\\\( H_T \\\\in \\\\mathbb{R}^{m \\\\times L} \\\\), and node representations, \\\\( H_G \\\\in \\\\mathbb{R}^{m \\\\times N} \\\\), where \\\\( N \\\\) denotes the number of nodes in graph \\\\( G \\\\). Finally, stance triplets are generated by our decoder using improved in-parallel attention and information fusion mechanisms (\u00a74.3). Moreover, we inject Wikipedia knowledge to support the identification of relations between entities, especially to provide additional information which is not present in texts, e.g., party affiliations and geopolitical relations (\u00a74.5).\\n\\nB.1 Decoder\\nWe decode with our improved multi-source fused decoder, improved upon Transformer decoder (Vaswani et al., 2017), to enable reasoning over both information sources: text and graph.\\n\\nThe key difference between the vanilla Transformer decoder and ours is the in-parallel cross-attention layer which allows better integration of knowledge encoded in the two heterogeneous sources. Concretely, the cross attention to the text is formulated as:\\n\\n\\\\[\\n\\\\text{LayerNorm}(z + \\\\text{Attn}(z, H_T))\\n\\\\]\"}"}
{"id": "emnlp-2022-main-676", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table A3: Results on SEESAW for E2E stance detection task, and breakdown of accuracy scores by aspects (average of 5 runs). Best results without oracle entities are in bold. Our graph-augmented model with Wikipedia knowledge performs the best on 4 out of 6 metrics, indicating the effectiveness of encoding knowledge.\\n\\nTable A4: Results on stance-only prediction for specified pairwise entities (average of 5 runs). Our model performs on par with state-of-the-art models in stance detection tasks (POLITICS and DSE2QA). Our model performs on par with SOTA discriminative models.\\n\\n\\\\[\\n\\\\begin{align*}\\n\\\\text{z} & = \\\\text{LayerNorm}(\\\\text{z} + \\\\text{Attn}(\\\\text{z}, \\\\text{H}_G)) \\\\\\\\\\n\\\\text{z}_G & = \\\\text{LayerNorm}(\\\\text{z} + \\\\text{Attn}(\\\\text{z}, \\\\text{H}_G)) \\\\\\\\\\n\\\\text{z}_F & = \\\\text{GELU}(W_f[\\\\text{z}_T; \\\\text{z}_G] + b_f) \\\\\\\\\\n\\\\lambda & = \\\\text{sigmoid}(W\\\\lambda[\\\\text{z}_T; \\\\text{z}_G] + b\\\\lambda) \\\\\\\\\\n\\\\text{z} & = \\\\lambda \\\\odot \\\\text{z}_F + (1 - \\\\lambda) \\\\odot \\\\text{z}_T\\n\\\\end{align*}\\n\\\\]\\n\\nwhere \\\\(\\\\odot\\\\) is element-wise product, and \\\\(W^*\\\\) and \\\\(b^*\\\\) are learnable. \\\\(\\\\lambda\\\\) here denotes the learnable gate vector. The selection of operation is decided by the downstream task. Specifically, in experiments we use addition for task A and gating mechanism for task B.\\n\\n**B.2 Training Objectives**\\n\\nWe adopt the cross entropy (CE) training objective that minimizes the following loss for model training.\\n\\n\\\\[\\nL_{\\\\text{stance}} = -\\\\sum_{(x, y) \\\\in D} \\\\log p(y|x)\\n\\\\]\\n\\nwhere the reference \\\\(y\\\\) is a sequence of ground-truth stance triplet(s), sorted by their entities' first occurrences in the target sentence \\\\(\\\\tilde{x}\\\\), and \\\\(D\\\\) denotes the training set. \\\\(x\\\\) is formatted as \u201c<s> [preceding context] <s> [target text] </s> [succeeding context]\u201d, where [\u00b7] indicates placeholders. Optionally, extracted entities can be paired with document \\\\(x\\\\) and then fed into the text encoder, in the format of \u201c\\\\(x\\\\) <s> <ENT> E_1 <ENT> E_2 ...\u201d.\\n\\n\\\\(y\\\\) is formatted as \u201c<ENT> [source] <ENT> [target] <STANCE> [stance]\u201d, where <\u00b7> is a separator and [\u00b7] is a placeholder.\\n\\n**Variant with Node Prediction.**\\n\\nIn addition to modeling entity interactions in the graph, we enhance the model by adding an auxiliary objective to predict the node salience, i.e., whether the corresponding entity should appear in the stance triplets \\\\(y\\\\) to predict the node salience, i.e., whether the corresponding entity should appear in the stance triplets \\\\(y\\\\) to...\"}"}
{"id": "emnlp-2022-main-676", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"be generated. This is motivated by the observation that $G$ usually contains excessive entity nodes, only a small number of which are involved in sentiment expression in the target sentence. Specifically, for each entity node $E_i$, we predict its salience, i.e., $\\\\hat{s}_i$, by applying affine transformation over its representation $h_{G_i}$, followed by a sigmoid function $\\\\hat{s}_i = \\\\text{sigmoid}(uH_{E_G})$ (8) where $\\\\hat{s}_i = \\\\{\\\\hat{s}_1, ..., \\\\hat{s}_N\\\\}$ is the collection of all entity nodes, $H_{E_G}$ is a matrix of node representations for entity nodes out of the graph encoder, and $u$ is learnable during training.\\n\\nWe adopt the weighted binary cross entropy (BCE) training objective to minimize the loss, $L_\\\\text{node}$, over all entity nodes.\\n\\n$L_\\\\text{node} = -\\\\sum s_i w \\\\times s_i \\\\log(\\\\hat{s}_i) + (1 - s_i) \\\\log(1 - \\\\hat{s}_i)$ (9)\\n\\nwhere $w$ controls loss weights on positive samples, and $s_i$ denotes the occurrence of entity node $E_i$ in the ground-truth stance triplet $y$.\\n\\nFinally, when the node prediction module is enabled, the overall loss for the multitask learning setup is $L_\\\\text{multi} = L_\\\\text{stance} + L_\\\\text{node}$.\\n\\nC SEESAW Annotation Quality Control\\n\\nWe hold meetings on a weekly basis and give annotators timely feedbacks to resolve annotation disagreements and iteratively improve annotation quality. We randomly sample 10% news stories and have them annotated by multiple people. We first evaluate on the overlapping ratio between a pair of entity sets extracted by two different people. The overlapping ratio is 55.5% after cross-document entity resolution is conducted. Though the overlapping ratio is not high, we do find that entities captured by one but not both can help complement one another's annotation. Next, for sentiment annotation, we compute the agreement level by comparing two annotators' sentiment annotations on items that are annotated by both. We reach 97% agreement level, showing high quality of our SEESAW.\\n\\nFurther, a simple unadjusted agreement between AllSides media-level ideology label and annotator's perception of the article's ideological leaning is 0.77 out of 1.0. We consider the difference within one level as correct matching, e.g., Far Left (0) and Lean Left (1) are matched.\\n\\n... In her seven-page opinion, Justice Sotomayor wrote that the Trump administration had become too quick to run to the Supreme Court after interim losses in the lower courts. \\\"Claiming one emergency after another, the government has recently sought stays in an unprecedented number of cases, demanding immediate attention and consuming limited court resources in each,\\\" she wrote. \\\"And with each successive application, of course, its cries of urgency ringing increasingly hollow.\\\"...\"}"}
{"id": "emnlp-2022-main-676", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"For all experiments, we use the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 1e-5 and fine-tune up to 15 epochs. The batch size of all baselines and our models are 4. The gradient is clipped when its norm exceeds 5. We select the best model for each method using the accumulated loss on the dev set. In decoding, the batch size is 1. We also enable learning rate decay with a patience of 200 steps. The early stop is also enabled with a patience of 1,600 steps. For all these other hyperparameters, we keep the default values.\"}"}
