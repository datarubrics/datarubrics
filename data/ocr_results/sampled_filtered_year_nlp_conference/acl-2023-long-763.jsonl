{"id": "acl-2023-long-763", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts\\n\\nMounica Maddela\u2217\\nGeorgia Tech &\\nMeta AI\\n\\nMegan Ung\u2217\\nMeta AI\\n\\nJing Xu\\nMeta AI\\n\\nAndrea Madotto\\nMeta AI\\n\\nHeather Foran\\nKlagenfurt University\\n\\nY-Lan Boureau\\nMeta AI\\n\\nAbstract\\n\\nMany cognitive approaches to well-being, such as recognizing and reframing unhelpful thoughts, have received considerable empirical support over the past decades, yet still lack truly widespread adoption in self-help format. A barrier to that adoption is a lack of adequately specific and diverse dedicated practice material. This work examines whether current language models can be leveraged to both produce a virtually unlimited quantity of practice material illustrating standard unhelpful thought patterns matching specific given contexts, and generate suitable positive reframing proposals. We propose PATTERNREFRAME, a novel dataset of about 10k examples of thoughts containing unhelpful thought patterns conditioned on a given persona, accompanied by about 27k positive reframes. By using this dataset to train and/or evaluate current models, we show that existing models can already be powerful tools to help generate an abundance of tailored practice material and hypotheses, with no or minimal additional model training required.\\n\\n1 Introduction\\n\\nCognitive Behavioral Therapy (CBT) (Beck, 1963, 1976) is one of the most robustly validated approaches in psychology (Hofmann et al., 2012; David et al., 2018). A core pillar of CBT consists in identifying and reframing unhelpful ways of thinking. Low-intensity CBT interventions have shown promise in self-help formats (Shafran et al., 2021; Williams, 2001), yet a lack of sufficient practice material suited to people's specific circumstances is a barrier to adoption (Helgad\u00f3ttir et al., 2009). Through prompting, control tokens, or adequate conditioning, modern language models can guide generation of language towards desired outcomes, such as conforming to a given persona (Zhang et al., 2018), style (Ziems et al., 2022), or level of confidence (Mielke et al., 2022). This makes them a potentially powerful practice aid for learning cognitive reframing techniques. A major barrier is the lack of publicly available data. Most existing work in natural language processing (NLP) for CBT focuses on interactions between patients and mental health professionals, which are not publicly available (Mieskes and Stiegelmayr, 2018; Rojas-Barahona et al., 2018; Shreevastava and Foltz, 2021). Ziems et al. (2022) released the first public dataset for reframing tweets marked with a hashtag indicating stress, using known reframing techniques, but it does not specifically look at the categories of unhelpful thinking used in CBT, and uses existing tweets rather than allowing the generation of examples suited to a particular situation.\\n\\nIn this work, we propose a novel dataset, PATTERNREFRAME, consisting in \u223c10k crowdsourced examples of thoughts containing ten classical types of unhelpful thought patterns (Burns, 1980), conditioned on personas, matched with crowdsourced proposals of reframing that do not exhibit the patterns. We introduce two controllable text-to-text generation tasks on the dataset: (1) generating and (2) reframing unhelpful thoughts, given a persona and pattern as the context. We also define a classification task to identify the unhelpful thought pattern, given a persona and a thought. We train and evaluate different fine-tuned and few-shot approaches for the tasks, and show that these approaches perform reasonably well on the tasks.\\n\\n2 Related Work\\n\\n2.1 NLP for Mental Health\\n\\nRecent work has used linguistic features and pre-trained language models to identify mental health conditions such as anxiety (Owen et al., 2020; Shreevastava and Foltz, 2021; Fine et al., 2020),...\"}"}
{"id": "acl-2023-long-763", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"depression (Wolohan et al., 2018; P\u00f3swiata and Pere\u0142kiewicz, 2022; Ji et al., 2022), schizophrenia (Jiang et al., 2020b; Mitchell et al., 2015; Saraoglu Kayi et al., 2017), and post-traumatic stress disorder (Coppersmith et al., 2015). Most of these works annotate social media posts to create datasets for the task, and then train and evaluate different classification models. Shreevastava and Foltz (2021) and Rojas-Barahona et al. (2018) created datasets for identifying unhelpful thoughts by annotating patient-therapist interactions and finetuned different pretrained models for the task. However, these datasets are not publicly available.\\n\\nThe closest work to ours is that of Ziems et al. (2022), which introduces a reframing task, releases a parallel corpus of reframed sentences, and uses controllable text generation models to reframe social media content from Twitter that was marked as expressing stress. However, the source social media material is not conditioned on personas, or focused on the classical unhelpful thought patterns from CBT. Our work introduces conditioning on personas and classical unhelpful thought patterns, and extends the reframing task to identifying and generating thoughts matching a given persona and unhelpful pattern.\\n\\n2.2 Controllable Text Generation\\n\\nControllable text generation approaches using pretrained language models (PLMs) typically fall into four categories: (i) prompt-based methods that either construct templates for PLMs to complete (Jiang et al., 2020a; Schick and Sch\u00fctze, 2021a,b) or finetune a task-specific layer to guide the generation (Li and Liang, 2021; Lester et al., 2021), (ii) finetuning methods that either use labelled data prepended with controlled attributes (Ziems et al., 2022; Fan et al., 2018; Martin et al., 2020; Ross et al., 2022) or define a task-specific reward function using reinforcement learning (Ziegler et al., 2019; Liu et al., 2020), (iii) post-processing methods that train discriminator models to guide the generation towards a specific criterion during decoding (Dathathri et al., 2019; Hua and Wang, 2020; Xu et al., 2020), and (iv) pretraining methods that pretrain PLMs from the start with different control tokens prepended to the input (Keskar et al., 2019). In our work, we experiment with prompt-based and finetuning methods.\\n\\n3 Identifying and Reframing Unhelpful Thoughts\\n\\nWe use the ten categories of unhelpful thought patterns described in lay terms in a widely used CBT self-help book used for bibliotherapy (Burns, 1980). Table 1 lists these categories and provides examples for each category. For reframing unhelpful thoughts, we follow Ziems et al. (2022), who describe five reframing strategies based on positive psychology (Harris et al., 2007): (i) Growth Mindset: Focusing on learning from challenges and improving the skills needed to deal with a difficult situation; (ii) Optimism: Directing the attention towards the positive aspects of the situation and expressing gratitude while still acknowledging the negative aspects; (iii) Impermanence: Understanding that adversities are inevitable and temporary and focusing on accepting the situation; (iv) Neutralizing: Challenging unhelpful thoughts that are far from reality and replacing them with realistic neutral alternatives; (v) Self-affirmation: Reflecting on core values to ground oneself in a difficult situation. Note that other reframing strategies exist, such as \u201cbeing mindful\u201d (Robertson, 2012), or \u201cfocusing on forgiveness and compassion\u201d (Gilbert, 2010). We provide the above five strategies only as a starting point, but crowd workers are free to use other strategies.\\n\\n4 PATTERNetrofit\\n\\n4.1 Data Collection\\n\\nWe briefly explain the four-step data collection process used to crowdsource the dataset. We provide further data collection details and snapshots of the interface in Appendix A and B.\\n\\n4.1.1 Task 1: Writing Unhelpful Thoughts\\n\\nIn order to generate unhelpful thoughts that match a diversity of contexts and situations, we use personas from the PERSONA-CHAT dataset (Zhang et al., 2018) as context for writing unhelpful thoughts. We give a persona and one of the ten unhelpful thought patterns to the crowdsource workers, and ask them to write sentences that both are consistent with the given persona, and exhibit the given unhelpful thought pattern.\"}"}
{"id": "acl-2023-long-763", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Unhelpful Thought Patterns and their distribution\\n\\nExample Thoughts and their Rewrites that remove the pattern\\n\\nCatastrophizing\\n\\nby giving greater weight to the worst possible outcome.\\n\\n(1024 thoughts / 2826 rewrites)\\n\\nMy mom hasn't come home from work yet. I hope the store isn't getting robbed!\\nRewrite:\\nMy mom hasn't come home from work yet. She must have gotten swamped. I'll cook dinner now so it's ready when she gets home.\\n\\nDiscounting the positive:\\nexperiences\\nby insisting that they \u201cdon't count\u201d.\\n\\n(970 thoughts / 2680 rewrites)\\n\\nMy restaurant is the most popular in my city, but that's just luck.\\nRewrite:\\nMy restaurant is the most popular in the city. I suppose all my hard work has paid off.\\n\\nOvergeneralization\\n\\nis making faulty generalizations from insufficient evidence.\\n\\n(983 thoughts / 2747 rewrites)\\n\\nMy nephews didn't want to spend the weekend with me this week. I must not be as good of an aunt as I thought.\\nRewrite:\\nMy nephews didn't want to spend the weekend with me this week. They must be busy.\\n\\nPersonalization\\n\\nis assigning a disproportionate amount of personal blame to oneself.\\n\\n(934 thoughts / 2544 rewrites)\\n\\nMy sister was not happy with the makeup look I did for her. I am a bad artist.\\nRewrite:\\nMy sister was not happy with the makeup I did for her, next time I'll try something different.\\n\\nAll-or-nothing\\n\\nis viewing things as either good or bad and nothing in-between.\\n\\n(952 thoughts / 2628 rewrites)\\n\\nThe school Christmas choir concert got canceled. This holiday season is ruined.\\nRewrite:\\nEven though the choir concert got canceled there are still other fun activities to do on the holiday.\\n\\nMental Filtering\\n\\noccurs when an individual dwells only on the negative details of a situation.\\n\\n(936 thoughts / 2562 rewrites)\\n\\nIt's nice to enjoy the sea breeze when you live near the ocean but it's not worth it when you think of all the sand getting dragged into your home and all the tourists making so much noise at the beach.\\nRewrite:\\nI am so fortunate to live where I can enjoy the sea breeze. Not everyone is this lucky.\\n\\nMind Reading\\n\\nis inferring a person's probable (usually negative) thoughts from their behavior.\\n\\n(992 thoughts / 2688 rewrites)\\n\\nI auditioned for the surf team and the coach avoided me. I am sure it is because he does not like my skills.\\nRewrite:\\nI auditioned for the surf team and the coach avoided me. I'm sure the coach always tries to appear neutral during try-outs.\\n\\nFortune Telling\\n\\nis predicting outcomes (usually negative) of events.\\n\\n(997 thoughts / 2758 rewrites)\\n\\nI didn't make it to Yellowstone this year, I am never going to go to that park.\\nRewrite:\\nI didn't get to go to Yellowstone this year, I will work extra hard and save up to definitely go next year!\\n\\nShould statements\\n\\nwhere a person demands particular behaviors regardless of the realistic circumstances.\\n\\n(921 thoughts / 2413 rewrites)\\n\\nI prefer texting over phone calls. People should never call me and expect me to answer.\\nRewrite:\\nJust because I like texting doesn't mean everyone needs to like it.\\n\\nLabeling and mislabeling\\n\\nis attributing a person's actions to their character rather than the situation.\\n\\n(960 thoughts / 2661 rewrites)\\n\\nI fell off my skateboard yesterday, I'm a terrible athlete.\\nRewrite:\\nI fell off my skateboard yesterday, but even the best crash sometimes.\\n\\nTable 1: Examples of unhelpful thoughts and their reframed versions from our PATTERN dataset. The thought pattern definitions are derived from Wikipedia.\\n\\nthan distinct (Burns, 1980). In order to capture this, as well as filter out low-quality crowdsourced data, we use a second crowdsourcing task requesting workers to label the previously generated thoughts. Workers are given a thought and the list of unhelpful patterns, and select all the patterns that appear in the thought. The annotators can choose a \u201cNone\u201d option in case the thought is irrelevant or nonsensical. We collect five annotations for each thought, and discard the thoughts that are marked \u201cNone\u201d by a majority of annotators.\\n\\n4.1.3 Task 3: Reframing Unhelpful Thoughts\\n\\nIn a third task, we ask crowdworkers to rewrite thoughts containing unhelpful patterns, in a more helpful way, similar to the task in Ziems et al. (2022). We give crowdworkers a thought and the persona and unhelpful pattern that were used to generate it, and ask them to rewrite the thought in a way that still aligns with the context, but does not contain the unhelpful pattern. We also show the five reframing strategies described in \u00a73 to aid the workers in reframing the thoughts, and ask them to select what strategy they used, if any. Note that the strategies are only provided as suggestions, and the workers are free to reframe the thought in other appropriate ways. We collect three rewrites for each thought.\"}"}
{"id": "acl-2023-long-763", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.1.4 Task 4: Evaluating the Rewrites of Unhelpful Thoughts\\n\\nFinally, we assess the quality of the rewrites as follows: workers are given a persona, unhelpful thought pattern, generated thought, along with three rewrites. They are asked to select which rewrites successfully remove the unhelpful pattern while not logically contradicting the source (following Ziems et al. (2022)). If worker selects a valid rewrite, we further ask them to identify which of the five proposed reframing strategies were used, if any. We collect five annotations for each set, and include only the rewrites that are marked as \u201cvalid\u201d by a majority of annotators.\\n\\n4.2 Data Quality\\n\\nWe use the Mephisto and Amazon Mechanical Turk platforms to collect crowdsource data. We use the labeling tasks (2nd and 4th task) to select a pool of high-quality workers (that is, crowdsource workers whose generative work was validated by a majority of separate annotators in a separate labeling task), after first seeding the set of annotators through manual inspection of a first batch of data. We use only selected annotators for evaluation tasks (tasks 2 and 4). We first kept the generative text tasks (tasks 1 and 3) open to all workers. We expanded the list of selected workers after every iteration by adding new workers that had completed at least five generative text tasks with at least 80% of generated text validated through the evaluation tasks. We ended up with 524 qualified workers after nine rounds of the entire pipeline, where each iteration started with a batch of 500 thoughts. Once we gathered >500 qualified workers, we restricted all the tasks to the selected pool. In the final dataset, we included only the annotations provided by these selected workers.\\n\\nAlong with the selected pool of workers, we also included onboarding tasks (details in \u00a7A) to ensure that the workers adequately understood the concept of reframing thoughts. Only the workers who passed the onboarding tasks were qualified to work on the actual tasks. We calculated inter-annotator agreement using Krippendorf\u2019s Alpha, which was 0.355 for the second task and 0.454 for the fourth task.\\n\\n4.3 Data Analysis\\n\\n4.3.1 Dataset Statistics\\n\\ncontains 9,688 thoughts and 26,507 reframed versions of thoughts. We split the dataset into training, validation, and test sets of respective sizes 1,920 / 961 / 6,807 for thoughts, and 5,249 / 2,623 / 18,635 for reframed thoughts. One thought can have up to three reframed versions, with an average of 2.74 rewrites / thought after filtering out lower-quality rewrites. The average word lengths of thoughts and rewrites are 19.1 and 23.9, respectively.\\n\\n4.3.2 Analysis of Unhelpful Thought Patterns\\n\\nFigure 1 shows the distribution of thoughts across different patterns in our dataset, with initial conditioning pattern (1st task) in rows and annotator identified patterns (2nd task) in columns. As expected, there is a high overlap among some related patterns, e.g., Discounting the positive / Mental Filtering, Fortune Telling / Catastrophizing, and Personalization / Labeling and Mislabeling. All or Nothing Thinking is difficult to distinguish, and shows high overlap with many categories. Mind Reading and Should Statement show the lowest amounts of overlap with other patterns.\\n\\nreframe-level judgements from the fourth task.\"}"}
{"id": "acl-2023-long-763", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"4.3.3 Analysis of Reframing Strategies:\\n\\nFigure 2 shows the distribution of reframing strategies used to reframe the unhelpful thoughts in our dataset, among the five strategies proposed by Ziems et al. (2022). Here, we use the strategies identified by the workers in the fourth task of evaluating reframed thoughts. Most rewritten thoughts make use of one of the five strategies, with very few being labeled as \\\"None.\\\"\\n\\nGrowth Mindset and Optimism are the most commonly used reframing strategies, followed by Neutralizing and Self-Affirmation.\\n\\nOptimism is especially common for patterns that focus on the negative aspects of the situation such as Discounting the positive and Mental Filtering.\\n\\n5 Models to Generate, Recognize, and Reframe Unhelpful Thoughts\\n\\nWe train and evaluate different models using our PATTERNREFrame dataset on three tasks: generating, identifying, and reframing unhelpful thoughts \u2013 all conditioned on a given persona.\\n\\n5.1 Generating Unhelpful Thoughts\\n\\n5.1.1 Task and Data\\n\\nGiven a persona and an unhelpful thought pattern, the goal is to generate a thought that exhibits the given pattern and aligns with the persona. We formulate the task as a standard conditioned generation problem and optimize the maximum likelihood loss during training. We use the train, validation, and test splits described in \u00a74.3.1.\\n\\n5.1.2 Methods\\n\\nWe evaluate methods based on fine-tuning and few-shot learning. We fine-tune BART-large (Lewis et al., 2020), T5-large (Raffel et al., 2020), and R2C2-3B (Shuster et al., 2022) (a BART-based language model specialized in dialogues). For the input, we concatenate the persona and the unhelpful thought pattern texts using a special delimiter token. We also generate responses with GPT3.5 (Ouyang et al., 2022), a state-of-the-art language model trained to follow human instructions, as a 1-shot method. We generated thoughts for only 100 random inputs in the PATTERNREFrame test set, since we had limited access to the API to GPT3.5 (text-davinci-002). We provide implementation details and examples of input prompts in Appendix D and E, respectively.\\n\\n5.1.3 Automatic Evaluation\\n\\nFollowing previous work on text reframing (Ziems et al., 2022; Chen et al., 2021), we report BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), and BERTScore (Zhang et al., 2020), which capture the semantic similarity between the generated thought and the human reference. We also report distinct-1, and distinct-2 metrics to measure the diversity of the generations. Distinct-n (Li et al., 2016) calculates the ratio between the number of unique n-grams and the total number of n-grams in a generation.\\n\\nTable 2 shows the automatic evaluation results for the task. All the models perform close to each other in terms of BLEU, BERTScore, and ROUGE. GPT3.5 generates lexically diverse rewrites with the best Distinct-n scores. We provide examples of system outputs in Table 3.\\n\\n5.1.4 Human Evaluation\\n\\nAs automatic metrics often fail to fully capture human preferences in text generation tasks, we also perform human evaluation. We collect human ratings of 100 random thoughts from the test set. Similar to previous style transfer works (Ziems et al., 2022; Briakou et al., 2021; Rao and Tetreault, 2018), we evaluate the generated rewrites along three dimensions through Yes/No binary ratings: (i) fluency, which evaluates the readability of the generation, (ii) meaning preservation, which here verifies if the rewrite aligns with the given persona.\"}"}
{"id": "acl-2023-long-763", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 2: Automatic evaluation results on the \\\\textsc{PatternRef} test set. We report BLEU, ROUGE, BERTScore (BScore), Distinct-1 (Dist-1), and Distinct-2 (Dist-2) metrics.\\n\\n\u2020 We calculate metrics over 100 random generations because of our limited access to the GPT3.5 API (text-davinci-002).\\n\\nFigure 3: Human evaluation results for the tasks of generating (left) and reframing (right) unhelpful thoughts. Y-axis shows the percentage of outputs rated positively by at least five of the nine annotators.\\n\\nand thought, and (iii) quality, which here evaluates if the generated thought exhibits the given unhelpful thought pattern. We collect 9 annotations for each system output and apply majority voting to extract the final annotation.\\n\\nTable 3 shows the percentage of outputs rated positively by at least five of the nine annotators. GPT3.5 outperforms all other approaches, including human references, in terms of fluency and quality. However, GPT3.5 shows the lowest (but still very high) meaning preservation score for generating thoughts. The other models have more difficulty including the unhelpful pattern (lower \\\"thought quality\\\" scores).\\n\\n5.2 Classifying Unhelpful Thoughts\\n\\n5.2.1 Task and Data\\n\\nGiven a persona and a thought, the goal is to classify them into one of the ten unhelpful thought patterns or \\\"None\\\", which indicates that the input thought does not contain any of the ten unhelpful patterns, or the thought does not align with the persona. We formulate the task as a multiclass classification problem with eleven categories.\\n\\nWe once again use the same train, validation, and test splits described in \u00a74.3.1. Note that the dataset contains only positive examples for the classification task, i.e., thoughts that align with a specific thought pattern and persona. For every positive example, we construct a negative example by randomly choosing one of the following options: (i) a thought from our dataset that belongs to the same pattern but a different persona. (ii) a dialog text from \\\\textsc{PersonaChat} belonging to the same persona (but presumably not containing any unhelpful pattern), (iii) a dialog text from \\\\textsc{PersonaChat} belonging to a different persona (and again, presumably not containing any unhelpful pattern). Thus, negative examples encompass neutral texts and misaligned thoughts and personas. We assign the category \\\"None\\\" to these examples. We have 3,834 train, 1,915 validation, and 13,572 test instances after augmenting the dataset with these examples.\\n\\n5.2.2 Methods\\n\\nWe finetune RoBERTa (Liu et al., 2019) using the soft-label distribution obtained through the second task of our data collection pipeline (\u00a74.1), where we asked multiple annotators to identify the patterns exhibited in a thought, and then normalized the votes across the patterns. We use a soft label distribution instead of single label because of the high overlap across patterns. We also perform...\"}"}
{"id": "acl-2023-long-763", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 4: Confusion matrices for the unhelpful thoughts classification task on our classification test set. The rows represent true labels and the columns represent predicted labels. We clustered similar patterns for clearer interpretation.\\n\\nPolarized Thinking includes Overgeneralization, Catastrophizing, All or Nothing Thinking, and Fortune Telling. Filtering refers to Mental Filtering and Discounting the positive. Mislabeling encompasses Personalization and Labeling and Mislabeling.\\n\\n\u2020 We obtain outputs for only 100 random thoughts.\\n\\n11-way, 1-shot classification using GPT3.5. We construct the input prompt using one example from each category (examples in \u00a7E) and classify 100 random inputs in the test set. We include further implementation details in Appendix D.\\n\\n5.2.3 Evaluation\\n\\nFigure 4 shows the confusion matrices for RoBERTa and GPT3.5 on the augmented version of the PATTERN FRAME test set. Given that several unhelpful thinking patterns are closely related (for example, All or Nothing Thinking and Catastrophizing), we cluster the patterns using the KMeans algorithm (Lloyd, 1982) to group together patterns that were deemed close by the model. RoBERTa performs well on all the categories (>72%) except the Mislabeling category, which has a high overlap with the Polarized Thinking category. The None category has the highest performance, which shows that the classifier is able to differentiate neutral texts that do not contain any unhelpful pattern, or texts that are not aligned with the persona. 1-shot classification using GPT3.5 performs worse than fine-tuned RoBERTa. GPT3.5 has trouble distinguishing texts with and without unhelpful patterns and gets a low score for None. We also observed that 40% of the classification predictions changed for GPT3.5 after reordering the sequence of examples in the prompt, which shows that few-shot classification is not as reliable for this task, while still providing decent performance way above chance.\\n\\n5.3 Reframing Unhelpful Thoughts\\n\\n5.3.1 Task and Methods\\n\\nGiven a persona, an unhelpful thought pattern, and a thought exhibiting the given pattern, the goal is to reframe the thought in a way that still aligns with the persona and the context of the thought but does not contain the pattern. The reframing problem is similar to the generating one, except that the unhelpful thought is now a part of the input instead of the target. We use the same training, validation, and test splits for the reframing task (\u00a74.3.1). We also evaluate the same approaches described in \u00a75.1.2. For fine-tuned methods, we concatenate the persona, the pattern, and the thought texts with a special token. For few-shot methods, we construct a prompt similar to the one used for the generation task, but with the reframed statements (examples in Appendix E).\\n\\n5.3.2 Automatic Evaluation\\n\\nTable 2 shows the automatic evaluation results on the PATTERN FRAME test set. We use the metrics described in \u00a75.3.2 namely BLEU, ROUGE, BERTScore, and Distinct-n metrics. As each unhelpful thought can have up to 3 ground truth reframed versions, we take the maximum of the three scores and report the mean of these maxima. R2C2 performs the best in terms of BLEU and BERTScore. GPT3.5 again outperforms the\"}"}
{"id": "acl-2023-long-763", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Generating Unhelpful Thoughts\\n\\nPersona I like to chat with my friends. I like to read books that are in a series. I like to go to the movies. I love to go out to eat with my family.\\n\\nPattern Catastrophizing\\n\\nT5 I love to go out to eat with my family, but I'm sure we'll all get sick and die.\\n\\nBART I like to read books that are in a series, but I will never finish them.\\n\\nR2C2 I love to go out to eat with my family, but one day we will all get food poisoning and die.\\n\\nGPT3.5 I'm out of money to go out to eat with my family, maybe they won't want to hang out with me anymore.\\n\\nHuman My friends didn't want to chat with me today. They must have all hate me and wish me ill.\\n\\nPersona I write children's books. I like to drink. I live alone. I shop online, too much. I don't believe in love.\\n\\nPattern Should statements\\n\\nT5 I write children's books, everyone should read them.\\n\\nBART I write children's books, everyone should read them.\\n\\nR2C2 I write children's books. I should be published by now.\\n\\nGPT3.5 I should be able to write the perfect book, drink moderately, be in a relationship, and not shop online so much.\\n\\nHuman I shop online and I should make enough money to be able to afford anything and everything I want.\\n\\nReframing Unhelpful Thoughts\\n\\nPersona My mother was a teacher. My favorite food is a salad. I enjoy nature. I teach a yoga class. I am single.\\n\\nPattern Black-and-white or polarized thinking / All or nothing thinking\\n\\nThought The date I went on last week was a total fail. I'm going to be single forever.\\n\\nT5 The date I went on last week was a total fail. I will try harder next time.\\n\\nBART The date I went on last week was a total fail. Next time I will be more careful.\\n\\nR2C2 The date I went on last week was a total fail. I'm going to be single forever.\\n\\nGPT3.5 The date I went on last week wasn't a great match, but I'm open to meeting someone new and trying again.\\n\\nHuman I had a bad date last week, thankfully I went on a nature walk and realized I have plenty of time to find a partner.\\n\\nPersona I was diagnosed with mild OCD in college. Once a year, I take a week off and head to Florida. I freeze up in social situations. Sometimes I feel like I've already been through life once before.\\n\\nPattern Personalization\\n\\nThought I was diagnosed with mild OCD in college, it's my fault and I deserve it.\\n\\nT5 I was diagnosed with mild OCD in college. It's not my fault.\\n\\nBART I was diagnosed with mild OCD in college. I am working hard to overcome it.\\n\\nR2C2 I was diagnosed with mild OCD in college. I'm glad to have a diagnosis so I can get the help I need.\\n\\nGPT3.5 I was diagnosed with mild OCD in college, it's something I'm learning to manage.\\n\\nHuman I was diagnosed with mild OCD in college. I've been seeing a therapist to get help managing it.\\n\\nTable 3: Examples of system outputs for the tasks of generating and reframing unhelpful thoughts.\"}"}
{"id": "acl-2023-long-763", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"ern language models, we showed that this range of models can already be a powerful tool to generate, identify, and reframe unhelpful thoughts, conditioned on a persona. By releasing our dataset, we hope to help practitioners of CBT draw from a richer, more diverse set of examples of unhelpful thought patterns and refractions. This would help address the important limitation of a lack of personalized and specific examples in existing datasets, when teaching cognitive techniques.\\n\\nFuture work will evaluate whether leveraging models to produce richer training material results in more robust learning and understanding of the types of unhelpful thought patterns in humans. This may serve as the basis for future psychological validation studies of the materials and support future studies of low-intensity self-help interventions.\\n\\nLimitations\\nThis work relied on previously published datasets to source personas on which to anchor the generated unhelpful thoughts, and thus shares the limitations of those datasets. In particular, they use English-language responses, written by workers located in the United States. While these workers are reasonably diverse (Moss et al., 2020), the examples generated may not reflect the thought patterns and personas across cultures and diverse populations. This data is also generated by people who are being paid, as opposed to people genuinely engaging about situations that matter to them. Besides the substance of the thoughts themselves, a more direct limitation is that the models generate only English, so would not be directly usable for speakers of other languages. In addition, the data collected reflects the understanding of lay people, rather than trained clinical psychologists. While this makes the material more immediately relatable to other lay people, it is possible that the data do not capture what clinical psychologists would consider adequate illustrations of unhelpful patterns. Our data has been spot-checked by a CBT-trained clinical psychologist and found generally sound, but the entire material should undergo further validation.\\n\\nAnother limitation is that the models that we have tested are resource-intensive. In particular, the best-performing model, GPT3.5, is only available through a paid API.\\n\\nEthical considerations\\nWhile our work was developed to generate abundant data supporting work towards improving well-being, the negative statements it generates could be misused. The parallel data of unhelpful thoughts and their reframed versions can also be used to generate negative texts from neutral ones, by training systems with reframed versions as the input and unhelpful thoughts as the output. This risk of generating negative content from positive/neutral texts aligns with the risks of toxicity reduction and sentiment style transfer tasks.\\n\\nConversely, a different risk stems from over-eager use of our work. This work aims to examine the feasibility of generating ample practice material anchored on specific personas. We hope that releasing a large dataset of unhelpful thoughts and refractions will further research that will ultimately help practitioners, but there is a danger that people attempt to use the material as is, without the supervision of a trained professional, which could be harmful, as the material has not been tested with participants while monitoring adverse events such as increased anxiety or warped understanding of what unhelpful thoughts and useful refractions are.\\n\\nReferences\\nAaron T. Beck. 1963. Thinking and Depression: I. Idiosyncratic Content and Cognitive Distortions. Archives of General Psychiatry.\\nAaron T. Beck. 1976. Cognitive therapy and the emotional disorders. international universities press.\\nEleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, and Marine Carpuat. 2021. A review of human evaluation for style transfer. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021). Association for Computational Linguistics.\\nD.D. Burns. 1980. Feeling Good: The New Mood Therapy. A Signet book.\\nWei-Fan Chen, Khalid Al Khatib, Benno Stein, and Henning Wachsmuth. 2021. Controlled neural sentence-level reframing of news articles. In Findings of the Association for Computational Linguistics: EMNLP 2021.\\nGlen Coppersmith, Mark Dredze, Craig Harman, Kristy Hollingshead, and Margaret Mitchell. 2015. CLPsych 2015 shared task: Depression and PTSD.\"}"}
{"id": "acl-2023-long-763", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. 2019. Plug and play language models: A simple approach to controlled text generation.\\n\\nDaniel David, Ioana Cristea, and Stefan G. Hofmann. 2018. Why cognitive behavioral therapy is the current gold standard of psychotherapy. Frontiers in Psychiatry.\\n\\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical neural story generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).\\n\\nAlex Fine, Patrick Crutchley, Jenny Blase, Joshua Carroll, and Glen Coppersmith. 2020. Assessing population-level symptoms of anxiety, depression, and suicide risk in real time using NLP applied to social media data. In Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science.\\n\\nPaul Gilbert. 2010. An introduction to compassion focused therapy in cognitive behavior therapy. International Journal of Cognitive Therapy.\\n\\nAlex H. S. Harris, Carl E. Thoresen, and Shane J. Lopez. 2007. Integrating positive psychology into counseling: Why and (when appropriate) how. Journal of Counseling & Development.\\n\\nFj\u00f3la D\u00f6gg Helgad\u00f3ttir, Ross G Menzies, Mark Onslow, Ann Packman, and Sue O'Brian. 2009. Online cbt i: Bridging the gap between eliza and modern online cbt treatment packages. Behaviour Change, 26(4):245\u2013253.\\n\\nStefan Hofmann, Anu Asnaani, Imke Vonk, Alice Sawyer, and Angela Fang. 2012. The efficacy of cognitive behavioral therapy: A review of meta-analyses. Cognitive therapy and research.\\n\\nXinyu Hua and Lu Wang. 2020. PAIR: Planning and iterative refinement in pre-trained transformers for long text generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).\\n\\nShaoxiong Ji, Tianlin Zhang, Luna Ansari, Jie Fu, Prayag Tiwari, and Erik Cambria. 2022. Mental-BERT: Publicly available pretrained language models for mental healthcare. In Proceedings of the Thirteenth Language Resources and Evaluation Conference.\\n\\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020a. How can we know what language models know? Transactions of the Association for Computational Linguistics.\\n\\nZhengping Jiang, Sarah Ita Levitan, Jonathan Zomick, and Julia Hirschberg. 2020b. Detection of mental health from Reddit via deep contextualized representations. In Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis.\\n\\nNitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019. Ctrl: A conditional transformer language model for controllable generation.\\n\\nDiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. CoRR, abs/1412.6980.\\n\\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.\\n\\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pretraining for Natural Language Generation, Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\\n\\nJiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.\\n\\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).\\n\\nChin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out. Association for Computational Linguistics.\\n\\nRuibo Liu, Guangxuan Xu, Chenyan Jia, Weicheng Ma, Lili Wang, and Soroush Vosoughi. 2020. Data boost: Text data augmentation through reinforcement learning guided conditional generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.\\n\\nS. Lloyd. 1982. Least squares quantization in pcm. IEEE Transactions on Information Theory, 28(2):129\u2013137.\"}"}
{"id": "acl-2023-long-763", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Louis Martin, \u00c9ric de la Clergerie, Beno\u00eet Sagot, and Antoine Bordes. 2020. Controllable sentence simplification. In Proceedings of the Twelfth Language Resources and Evaluation Conference.\\n\\nSabrina J Mielke, Arthur Szlam, Emily Dinan, and Y-Lan Boureau. 2022. Reducing conversational agents' overconfidence through linguistic calibration. Transactions of the Association for Computational Linguistics, 10:857\u2013872.\\n\\nMargot Mieskes and Andreas Stiegelmayr. 2018. Preparing data from psychotherapy for natural language processing. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018).\\n\\nAlexander Miller, Will Feng, Dhruv Batra, Antoine Bordes, Adam Fisch, Jiasen Lu, Devi Parikh, and Jason Weston. 2017. ParlAI: A dialog research software platform. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 79\u201384. ACL.\\n\\nMargaret Mitchell, Kristy Hollingshead, and Glen Coppersmith. 2015. Quantifying the language of schizophrenia in social media. In Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality.\\n\\nAaron J Moss, Cheskie Rosenzweig, Jonathan Robinson, and Leib Litman. 2020. Demographic stability on mechanical turk despite covid-19. Trends in cognitive sciences, 24(9):678\u2013680.\\n\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback.\\n\\nDavid Owen, Jose Camacho-Collados, and Luis Espinosa Anke. 2020. Towards preemptive detection of depression and anxiety in Twitter. In Proceedings of the Fifth Social Media Mining for Health Applications Workshop & Shared Task.\\n\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics.\\n\\nRafa\u0142 Po\u015bwiat and Micha\u0142 Pere\u0142kiewicz. 2022. OPI@LT-EDI-ACL2022: Detecting signs of depression from social media text using RoBERTa pre-trained language models. In Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion.\\n\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. Journal of Machine Learning Research.\\n\\nSudha Rao and Joel Tetreault. 2018. Dear sir or madam, may I introduce the GY AFC dataset: Corpus, benchmarks and metrics for formality style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics.\\n\\nD. Robertson. 2012. Build Your Resilience: CBT, mindfulness and stress management to survive and thrive in any situation. Teach Yourself.\\n\\nLina M. Rojas-Barahona, Bo-Hsiang Tseng, Yinpei Dai, Clare Mansfield, Osman Ramadan, Stefan Ultes, Michael Crawford, and Milica Ga\u0161i\u0107. 2018. Deep learning for language understanding of mental health concepts derived from cognitive behavioural therapy. In Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis.\\n\\nAlexis Ross, Tongshuang Wu, Hao Peng, Matthew E Peters, and Matt Gardner. 2022. Tailor: Generating and perturbing text with semantic controls. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3194\u20133213.\\n\\nEfsun Sarioglu Kayi, Mona Diab, Luca Pauselli, Michael Compton, and Glen Coppersmith. 2017. Predictive linguistic features of schizophrenia. In Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017).\\n\\nTimo Schick and Hinrich Sch\u00fctze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume.\\n\\nTimo Schick and Hinrich Sch\u00fctze. 2021b. Few-shot text generation with natural language instructions. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.\\n\\nRoz Shafran, Pamela Myles-Hooton, Sophie Bennett, and Lars-G\u00f6ran \u00d6st. 2021. The concept and definition of low intensity cognitive behaviour therapy. Behaviour Research and Therapy, 138:103803.\\n\\nSagarika Shreevastava and Peter Foltz. 2021. Detecting cognitive distortions from patient-therapist interactions. In Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access. Association for Computational Linguistics.\\n\\nKurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston. 2022. Language models that seek for knowledge.\"}"}
{"id": "acl-2023-long-763", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Modular search and generation for dialogue and prompt completion.\\n\\nChris Williams. 2001. Use of written cognitive behaviour therapy self-help materials to treat depression. Advances in Psychiatric Treatment, 7.\\n\\nJT Wolohan, Misato Hiraga, Atreyee Mukherjee, Zeeshan Ali Sayyed, and Matthew Millard. 2018. Detecting linguistic traces of depression in topic-restricted text: Attending to self-stigmatized depression with NLP. In Proceedings of the First International Workshop on Language Cognition and Computational Models.\\n\\nPeng Xu, Mostofa Patwary, Mohammad Shoeybi, Raul Puri, Pascale Fung, Anima Anandkumar, and Bryan Catanzaro. 2020. MEGATRON-CNTRL: Controllable story generation with external knowledge using large-scale language models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).\\n\\nSaizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics.\\n\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.\\n\\nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human preferences.\\n\\nCaleb Ziems, Minzhi Li, Anthony Zhang, and Diyi Yang. 2022. Inducing positive perspectives with text reframing. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics.\"}"}
{"id": "acl-2023-long-763", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A Data Collection Details\\nA.1 Onboarding Tasks\\nWe introduce two onboarding tasks to ensure that the crowdsource workers understood the concept of unhelpful thoughts and how to reframe them. The onboarding tasks were reviewed by a CBT-trained psychologist. We use one onboarding task for tasks 1 and 2 and another onboarding task for tasks 3 and 4 of the data collection pipeline. For the first onboarding task, we display an unhelpful thought pattern, one positive example that contains the pattern, and one negative example that does not, and ask the workers to select the positive one. We only allowed the workers that were able to identify the correct example for three out of four such instances. For the second onboarding task, we display an unhelpful thought pattern, a thought containing the pattern, one positive example that reframes the thought, and one negative example that does not. We only allow the workers that were able to identify the positive example in three out of four such instances.\\n\\nB Data Collection Interface Snapshots\\nFigure 5: Data collection interface for the first task of the data collection pipeline, where crowdworkers are asked to write an unhelpful thought.\\nFigure 6: Annotation interface for the second task of the data collection pipeline, where crowdworkers are asked to select the patterns exhibited by an unhelpful thought.\"}"}
{"id": "acl-2023-long-763", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 7: Data collection interface for the third task of the data collection pipeline, where the crowdworkers are asked to reframe unhelpful thoughts.\\n\\nFigure 8: Annotation interface for the fourth task of the data collection pipeline, where the crowdworkers are asked to evaluate the quality of the reframed thoughts.\"}"}
{"id": "acl-2023-long-763", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 9: Annotation interface used to evaluate generated thoughts.\\nFigure 10: Annotation interface used to evaluate statements that reframe unhelpful thoughts.\"}"}
{"id": "acl-2023-long-763", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"D Implementation details\\n\\nD.1 Generation Models\\nWe finetuned the BART, T5, and R2C2 baselines using ParlAI 11. We used the BART large (400M parameters), T5 large (770M parameters), and R2C2 base (2.7b parameters) architectures. We used Adam optimizer (Kingma and Ba, 2014) and performed a hyperparameter search over learning rates 1e-05, 1e-06, 1e-07, and 1e-08. We used linear warmup of 100 steps and applied early stopping with a patience value of 5. We evaluated the validation set once in every 200 updates and truncated the input and the labels to 1000 tokens. We applied gradient clipping value of 1.0. We used a batch size of 32. During inference, we used beam search with beam size 10. We chose the best checkpoint during training based on the perplexity on the validation set. Each model takes around 1 hour to run on 8 NVIDIA Tesla V100 Volta 32GB GPUs.\\n\\nD.2 Classification Models\\nFor classification experiments, we finetuned the RoBERTa-large checkpoint from Huggingface 13. We used Adam optimizer (Kingma and Ba, 2014), learning rate of 1e-05, with linear warmup of 100 steps. We trained the model for a maximum of 10 epochs. We evaluated on the validation set every 200 updates. We used a batch size of 16. We chose the best checkpoint during training based on the weighted F1 value on the validation set. The model takes around 1 hour to run on 1 NVIDIA Tesla V100 Volta 32GB GPU.\\n\\nE GPT3.5 Prompt Examples\\nYou will be given (1) a type of unhelpful thinking pattern and the definition of the pattern and (2) a character. Please write an example of how this character could have thoughts that match the given thinking pattern.\\n\\nPersona: Likes camping. Has 2 kids.\\nUnhelpful Thinking Pattern: Discounting the positive (Rejecting positive experiences by insisting they \u201cdon\u2019t count\u201d for some reason or other.)\\nUnhelpful Thought: My friends said they really enjoyed the camping trip I organized, but anyone could have done it.\\n\\nPersona: i'm a business man. i love to sing. i'm a karate black belt. my wife has terminal cancer.\\nUnhelpful Thinking Pattern: Discounting the positive (Rejecting positive experiences by insisting they \u201cdon\u2019t count\u201d for some reason or other.)\\nUnhelpful Thought: I'll never be able to sing.\\n\\nTable 4: Example GPT3.5 prompt for the task of generating unhelpful thoughts.\\nYou will be given a type of unhelpful thinking pattern, a character, and an example of how this character could have thoughts that match the given thinking pattern. Please rewrite the thoughts in a way that still aligns with the persona and the context of the unhelpful thought, but does not contain the unhelpful pattern.\\n\\nPersona: Likes camping. Has 2 kids.\\nUnhelpful Thinking Pattern: Overgeneralization (Someone who overgeneralizes makes faulty generalizations from insufficient evidence. Even if something bad happens only once, it is expected to happen over and over again.)\\nUnhelpful Thought: My younger kid has gotten bad grades at his maths test this week. He\u2019ll never be good at maths.\\nReframe: My younger kid has gotten bad grades at his maths test this week. It\u2019s been a few times but hopefully we can figure out a way to help him get better.\\n\\nPersona: i obsess over working out and being the best . i got a scholarship for playing soccer . its important for my instagram posts to look like i am having fun . i try to eat healthy or i don\u2019t eat at all .\\nUnhelpful Thinking Pattern: Overgeneralization (Someone who overgeneralizes makes faulty generalizations from insufficient evidence. Even if something bad happens only once, it is expected to happen over and over again.)\\nUnhelpful Thought: My future college team lost another game, I will never become a good athlete playing for them.\\nReframe: Losing a game doesn\u2019t define my entire athletic career. I can learn from this experience and improve next time.\\n\\nTable 5: Example GPT3.5 prompt for the task of reframing unhelpful thoughts.\\n\\n11https://www.parl.ai/docs/index.html\\n12https://parl.ai/docs/zoo.htmlr2c2-base-2-7b\\n13https://github.com/huggingface/transformers\"}"}
{"id": "acl-2023-long-763", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Persona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: The kids have stopped paying attention to how we can pitch the tent. They will never learn.\\nUnhelpful Thinking Pattern: Jumping to conclusions: Fortune-telling\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: The kids are not enjoying this camping trip, they should really be more grateful about the effort we put in planning week-end activities for them.\\nUnhelpful Thinking Pattern: Should statements\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: My kid is late from school. Perhaps she got run over by a car and is in a hospital.\\nUnhelpful Thinking Pattern: Catastrophizing\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: This camping trip was a catastrophe. Sure the weather was gorgeous and the kids had a lot of fun, but the waterfall always had many people ruining the photos we wanted to take.\\nUnhelpful Thinking Pattern: Mental filtering\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: I like camping with my kids. We had a lot of fun the other weekend.\\nUnhelpful Thinking Pattern: None\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: The kids are having bad grades. It's because I'm a bad father.\\nUnhelpful Thinking Pattern: Personalization\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: My younger kid has gotten bad grades at his math test this week. He'll never be good at math.\\nUnhelpful Thinking Pattern: Overgeneralization\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: My friends said they really enjoyed the camping trip I organized, but anyone could have done it.\\nUnhelpful Thinking Pattern: Discounting the positive\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: My kids are being very silent. I am sure it's because they really hate me for taking them on this camping trip.\\nUnhelpful Thinking Pattern: Jumping to conclusions: mind reading\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: I didn't manage to light up the fire for the camp today, I'm such a useless outdoors person.\\nUnhelpful Thinking Pattern: Labeling and mislabeling\\n\\nPersona: Likes camping. Has 2 kids.\\n\\nUnhelpful Thought: One of the 5 trails we planned to do on this trip is closed to the public. This trip is ruined.\\nUnhelpful Thinking Pattern: Black-and-white or polarized thinking / All or nothing thinking\\n\\nPersona: i'm a woman . i've several children . we have a dog . we live in a rural area . my parents are still married .\\n\\nUnhelpful Thought: congratulations ! have you graduated college ? i am attending the university of michigan in the fall .\\n\\nUnhelpful Thinking Pattern: None\\n\\n---\\n\\nTable 6: Example GPT3.5 prompt for the task of identifying unhelpful thoughts.\"}"}
{"id": "acl-2023-long-763", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":true,\"natural_text\":\"Figure 11: Human evaluation results for the tasks of generating (left) and reframing (right) unhelpful thoughts. Y-axis shows the percentage of outputs rated positively by at least seven of the nine annotators.\"}"}
{"id": "acl-2023-long-763", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"A For every submission:\\n\\nA1. Did you describe the limitations of your work?\\n\\nA2. Did you discuss any potential risks of your work?\\n\\nA3. Do the abstract and introduction summarize the paper's main claims?\\n\\nA4. Have you used AI writing assistants when working on this paper?\\n\\nB Did you use or create scientific artifacts?\\n\\nB1. Did you cite the creators of artifacts you used?\\n\\nB2. Did you discuss the license or terms for use and / or distribution of any artifacts?\\n\\nB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\\n\\nB4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?\\n\\nB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?\\n\\nB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.\\n\\nC Did you run computational experiments?\\n\\nC1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?\\n\\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\"}"}
{"id": "acl-2023-long-763", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?\\n\\nC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run?\\n\\nC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?\\n\\nNot applicable. We use our own set-up for evaluation.\\n\\nD. Did you use human annotators (e.g., crowdworkers) or research with human participants?\\n\\nD1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.?\\n\\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?\\n\\nD3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?\\n\\nSection 4 + appendix B and C: crowdsource workers are not providing personal information.\\n\\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\\n\\nThe data collection protocol is reviewed by internal reviewers but not subject to an IRB as there is no sensitive data or personal information.\\n\\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?\\n\\nDescribed in section 7.\"}"}
