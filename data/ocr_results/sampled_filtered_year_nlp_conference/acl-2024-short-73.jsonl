{"id": "acl-2024-short-73", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Greed is All You Need: An Evaluation of Tokenizer Inference Methods\\n\\nOmri Uzan\u03b2 Craig W. Schmidt\u03ba Chris Tanner\u03ba\u00b5 Yuval Pinter\u03ba\\n\\nDepartment of Computer Science \u03ba Kensho Technologies \u03ba Ben-Gurion University of the Negev \u03ba Massachusetts Institute of Technology\\n\\nBeer Sheva, Israel Cambridge, MA, USA\\n\\n{omriuz@post, uvp@cs}.bgu.ac.il {craig.schmidt, chris.tanner}@kensho.com\\n\\nAbstract\\n\\nWhile subword tokenizers such as BPE and WordPiece are typically used to build vocabularies for NLP models, the method of decoding text into a sequence of tokens from these vocabularies is often left unspecified, or ill-suited to the method in which they were constructed. We provide a controlled analysis of seven tokenizer inference methods across four different algorithms and three vocabulary sizes, performed on a novel intrinsic evaluation suite we curated for English, combining measures rooted in morphology, cognition, and information theory. We show that for the most commonly used tokenizers, greedy inference performs surprisingly well; and that SaGe, a recently-introduced contextually-informed tokenizer, outperforms all others on morphological alignment.\\n\\n1 Introduction\\n\\nModern NLP systems, including large language models (LLMs), typically involve an initial step of mapping raw input text into sequences of subword tokens. These tokens are selected from a large vocabulary of candidates that were produced from algorithms such as Byte-Pair Encoding (BPE; Sennrich et al., 2016), WordPiece (Schuster and Nakajima, 2012), or UnigramLM (Kudo, 2018). This process, which we refer to as the inference method of tokenization, is critical as it determines how all text is represented and subsequently modeled. Each inference method offers distinct mappings, and we assert that it is not well-understood how these methods differ in performance. Furthermore, popular implementation packages such as Huggingface Tokenizers, SentencePiece, and SubwordNMT often obfuscate or even restrict the choice of inference methods, making it unclear if\\n\\n1 https://huggingface.co/docs/tokenizers\\n2 https://pypi.org/project/sentencepiece\\n3 https://github.com/rsennrich/subword-nmt\\n\\nTokenizer inference mode\\n\\nSegmentation\\n\\nBPE\\n\\nmerges\\n\\nUltra modern\\n\\nUltraprominent\\n\\nUnigramLM\\n\\nlikelihood\\n\\nUnprecedented\\n\\nUninstructible\\n\\nSaGe\\n\\nlongest prefix\\n\\nIncresible\\n\\nInception\\n\\nTable 1: Examples of words being segmented differently by various tokenizers (vocab size 32,000) using different inference modes on the same vocabulary. Each tokenizer's default mode is provided on top.\\n\\ninference-time decoding is compatible with the algorithm used to learn the tokenizer's vocabulary. Moreover, it is yet to be determined whether such a match is ideal, or even necessary.\\n\\nIn Table 1 we present examples demonstrating how the prescribed inference methods of BPE, UnigramLM, and SaGe (Yehezkel and Pinter, 2023) do not necessarily provide the best segmentation for complex English words, even when good segments are available in the vocabulary. BPE's out-of-the-box algorithm merges the cross-morphemic sequence at an early stage, preventing the consideration of ultra and modern and condemning the downstream model to work with a representation learned for the first-person present form of 'to be'. UnigramLM's ablative algorithm enabled unprecedented (which crosses morpheme boundaries) to remain in its final vocabulary of tokens, while SaGe's greedy algorithm masks the boundaries of both the prefix in and the suffix able. In all cases, an alternative inference method provides a more morphologically-aligned segmentation over the same vocabulary.\\n\\nPrevious work regarding subword tokenization mostly concerns developing vocabulary construction algorithms (Sennrich et al., 2016; Schuster and Nakajima, 2012; Kudo, 2018; Mielke et al., 2021; Yehezkel and Pinter, 2023), finding the optimal\"}"}
{"id": "acl-2024-short-73", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"vocabulary size (Gowda and May, 2020; Gutierrez-Vasques et al., 2021), building multilingual vocabularies (Liang et al., 2023), and using space positioning in the vocabulary tokens (Gow-Smith et al., 2022; Jacobs and Pinter, 2022). Others analyze the effects of vocabularies, finding intricate relations between algorithm or vocabulary and downstream performance (Bostrom and Durrett, 2020; Cognetta et al., 2024a), information theory (Zouhar et al., 2023; Cognetta et al., 2024b), cognitive plausibility (Beinborn and Pinter, 2023), impact on society (Ovalle et al., 2024), or morphological alignment (Klein and Tsarfaty, 2020; Hofmann et al., 2021, 2022; Gow-Smith et al., 2024; Batsuren et al., 2024).\\n\\nResearch concerning inference methods has been more scarce, and includes examination of random effects on BPE merges (Provilkov et al., 2020; Saleva and Lignos, 2023) and application of sophisticated search algorithms (He et al., 2020). As far as we know, there exists no comprehensive study comparing inference methods across a variety of vocabularies and sizes using diverse metrics.\\n\\nIn this work, we conduct a controlled experiment isolating the effects of inference methods over four tokenizers, introducing an evaluation suite aggregating intrinsic benchmarks from various theoretical realms.\\n\\nWe find that greedy inference methods work surprisingly well for all four vocabularies across morphological and information-theoretic metrics. Furthermore, we demonstrate that SaGe yields state-of-the-art performance according to morphological metrics, and that inference methods that minimize token count perform strongest by cognitive metrics.\\n\\nInference Methods\\n\\nLet \\\\( V \\\\) denote a vocabulary of subword tokens and \\\\( w \\\\) denote a word (or 'pretoken'), the output of a pretokenizer. We define \\\\( s(V, w) := (t_1, \\\\ldots, t_k) \\\\) as a segmentation of \\\\( w \\\\) into \\\\( k \\\\) subword tokens such that \\\\( \\\\forall i, t_i \\\\in V \\\\) and that the concatenation of \\\\( t_1, \\\\ldots, t_k \\\\) results in \\\\( w \\\\). We use the term segmentation to denote the application of an inference method on a text given a token vocabulary, as well as its result.\\n\\nCurrent widely-employed tokenization schedules couple together the tokenizer vocabulary with the inference method. However, we advocate for decoupling them, as they are independent processes. Specifically, given a fixed token vocabulary produced from pre-training data, one could subsequently use any applicable inference method for the task at hand. Thus, in our experiments, we use various intrinsic metrics to analyze the impact and performance of the several classes of inference methods:\\n\\nGreedy inference methods only consider and produce one token at each step. We test three greedy approaches:\\n\\n1. **Longest prefix**, which WordPiece uses by default (Wu et al., 2016), selects the longest token in \\\\( V \\\\) that is a prefix of \\\\( w \\\\), and then continues to iteratively segment the remaining text.\\n2. **Longest suffix** selects the longest token that is a suffix of \\\\( w \\\\) and continues iteratively (Jacobs and Pinter, 2022; Bauwens, 2023). Since this strategy diverges from English Morphology, we consider it an intriguing baseline for assessing the impact of linguistic structure on the inference method.\\n3. **Longest token** selects the longest token that is contained in \\\\( w \\\\), adds it to the generated segmentation, and then iteratively segments each remaining character sequence. This was proposed by Hofmann et al. (2022) to approximate words by their \\\\( k \\\\) longest tokens. They showed that it preserves morphological structure of words and leads to performance gains on some downstream tasks.\\n\\nMerge rules-based inference methods begin with a word's character sequence and iteratively apply token-forming merge rules learnt by the tokenizer at the vocabulary creation phase, until none can be applied. This is BPE's default inference mode.\\n\\nIn our experiments we test two variants for BPE: The deterministic merge strategy recursively applies the first applicable BPE merge rule by its order in the trained merge list.\\n\\nDropout (Provilkov et al., 2020) applies each valid merge rule with probability \\\\( p \\\\), leading to a regularization effect where rare tokens surface more often and their embeddings can be better trained. It has been shown to improve machine translation performance.\\n\\nLikelihood-based inference methods use individual likelihood values assigned to tokens in order to find a segmentation for \\\\( w \\\\) where the total likelihood is maximized (Kudo, 2018; He et al., 2020).\\n\\nDefault uses likelihood values learned during vocabulary construction and considers the likelihood values.\\n\\nWhile ostensibly also compatible with WordPiece, we found no implementation of the model that provides an ordered list of its merges.\"}"}
{"id": "acl-2024-short-73", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"of a segmentation to be the product of individual likelihoods (from which UnigramLM gets its name). Least tokens assigns a constant likelihood value to all tokens, effectively selecting a segmentation where the number of tokens is minimized. While not suggested so far as a standalone inference method, this objective is proposed for both vocabulary training and inference in the PathPiece algorithm (Schmidt et al., 2024).\\n\\n3 Intrinsic Benchmark\\n\\nSome analyses of tokenizers rely on training language models or translation models and evaluating their performance on downstream tasks. Using this process to isolate effects of tokenization hyperparameters, such as inference method, is both time- and resource-consuming, as well as unstable due to the introduction of multiple sources of randomness throughout the LM/TM pre-training and fine-tuning phases. Few measures have been introduced that are intrinsic to vocabularies and their direct application to corpora, and fewer still avoid conflating the measures with the objectives used in the vocabulary construction process itself. As a result, the body of work focused on improving tokenization schemes is still relatively small.\\n\\nWe create and release a benchmark made to intrinsically evaluate subword tokenizers. We collected word-level datasets and information measures which have been shown, or hypothesized, to correlate with the performance of language models on various downstream tasks. Details on these resources are provided in Table 2. At present, the benchmark is focused on the English language, although corresponding datasets exist for others as well.\\n\\nMorphological alignment\\n\\nIt is commonly assumed that, for a given tokenizer, alignment of word segments to morphological gold-standard segmentations is a predictor of the ability of a language model that uses the given tokenizer to represent words, especially \u2018complex\u2019 ones that are made up of several roots or contain multiple morphological affixes (Schick and Sch\u00fctze, 2019; Nayak et al., 2020; Hofmann et al., 2021; Gow-Smith et al., 2022). We follow Gow-Smith et al. (2022) and evaluate our tokenizers\u2019s alignment with morphological annotations found in LADEC (Gagn\u00e9 et al., 2019), MorphoLex (S\u00e1nchez-Guti\u00e9rrez et al., 2018), MorphyNet (Batsuren et al., 2021), and DagoBert (Hofmann et al., 2020). We augment these datasets with morpheme segmentation data (Batsuren et al., 2022), novel blend structure detection data (Pinter et al., 2020), and compound separation data (Minixhofer et al., 2023). The number of words in each resource can be found in Table 2. We compare the segmentations generated by the tokenizers with each inference method to gold-standard morphological segmentations using the metric introduced by Creutz and Linden (2004), and report the macro-averaged $F_1$ score over the different resources.\\n\\nCognitive Plausibility\\n\\nWe use the benchmark and data from Beinborn and Pinter (2023) to measure the correlation of a tokenizer\u2019s output with the response time and accuracy of human participants in a lexical decision task, predicated on the hypothesis that a good tokenizer struggles with character sequences that humans find difficult, and vice versa. We report the average of the absolute value correlation scores across the four linguistic setups (word/nonword \u00d7 accuracy/response time).\\n\\nTokens distribution statistics\\n\\nWe report the R\u00e9nyi efficiency of different segmentations across a corpus (Zouhar et al., 2023). This measure penalizes token distributions dominated by either very high- and/or very low-frequency tokens, and was shown to correlate strongly with BLEU scores for machine translation systems trained on the respective tokenizers. Recent work (Cognetta et al., 2023)\"}"}
{"id": "acl-2024-short-73", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Method       | Longest Prefix | Longest Suffix | Longest Token | Number of Tokens | Likelihood\u2020 |\\n|--------------|----------------|----------------|---------------|------------------|-------------|\\n| BPE          | 0.8584         | 0.6467         | 0.8738        | 0.7544           | 0.6309      |\\n|              |                |                |               |                  |             |\\n| Longest Prefix |                |                |               |                  |             |\\n| Longest Suffix |                |                |               |                  |             |\\n| Longest Token |                |                |               |                  |             |\\n| Number of Tokens |                |                |               |                  |             |\\n| Likelihood\u2020  |                |                |               |                  |             |\\n\\nTable 3: Intrinsic Benchmark results on a vocab size of 40k. 'Default' decoding algorithms (used in vocabulary construction) in italics. Not all methods are applicable to all tokenizers. Decoding diff presents the share of pretokens in the MiniPile test set that are differently tokenized using the method, compared with the default. We present correlation scores for performance over the various metric families in Appendix C. \u2020For SaGe, likelihood is only based on unigram scores obtained before further vocabulary ablation.\\n\\n2024b) reveals a misalignment between R\u00e9nyi efficiency and downstream performance in certain cases, reinforcing the necessity of an evaluation suite grounded in diverse domains and disciplines, as advocated in this work. We also measure the average number of tokens per word over a corpus, as a proxy for compression quality (Gall\u00e9, 2019). We omit the popular measure of character-length distribution of the tokens in the vocabulary, as it does not vary with segmentation strategy. Lastly, we report the proportion of pretokens that are segmented different from the default across our reference corpus.\\n\\n4 Experiments\\n\\nWe evaluate inference methods for the following tokenizer vocabularies: BPE, UnigramLM, WordPiece and SaGe. We use the train split of the MiniPile (Kaddour, 2023) dataset to construct the tokenizer vocabularies. We train vocabularies of sizes 32,768, 40,960, and 49,152, using the HuggingFace Tokenizers library, with identical pre-tokenization, representing the text at byte level. UnigramLM and SaGe require an initial vocabulary for their top-down algorithms; for the former, we used the default implementation of one million top n-grams, while SaGe was initialized with a 262K-size UnigramLM vocabulary. This initial vocabulary also provided us with token likelihood scores for inference, although a more exact implementation would also incorporate the contextual SaGe objective. Token distribution statistics measurements and decoding diff rates were computed over the test split of the MiniPile dataset. We measure the R\u00e9nyi efficiency using the tokenization-scorer package with $\\\\alpha = 2$. For each tokenizer, all experiments ran within several minutes on a personal laptop computer, highlighting the usefulness of our benchmark as an efficient tool for in-loop hyperparameter tuning.\\n\\nWe present the results on our benchmark for the 40K vocabularies in Table 3. Results for other sizes are presented in Appendix A. A breakdown of individual evaluation subsets is provided in Appendix B.\"}"}
{"id": "acl-2024-short-73", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"illustrated in Table 1, where early merge rules such as \u2018i-n\u2019, \u2018a-m\u2019, or \u2018o-n\u2019 cross morphological boundaries. We notice a similar trend for likelihood-based inference, where frequently-used tokens possess very high likelihood values, sometimes exceeding those of the gold-standard segments. We find that the least tokens strategy fares well not only on the token count metric, which is mostly by-design, but also on cognitive measures, suggesting an effect of human preference to minimal word segmentation. Finally, we observe that likelihood-based inference performs poorly in terms of R\u00e9nyi efficiency, contrary to its stated purpose.\\n\\nDropout, on the other hand, performs well on this measure, in line with its goal. Longest suffix performs poorly across the board, possibly due to the suffixing nature of the English language, which has complementarily been shown to affect character-level sequential modeling (Pinter et al., 2019). Notably, all our key observations are consistent across vocabulary sizes, as shown in Appendix A.\\n\\nInter-tokenizer results Our results align with Bostrom and Durrett (2020)\u2019s finding that BPE is inferior to UnigramLM on morphology alignment. However, we show that some of this gap can be attributed not to the vocabulary but to the inference method. In addition, we find that SaGe is most aligned to morphology by a substantial margin, indicating that its contextualized objective succeeds in retaining meaningful tokens in the vocabulary during ablation. It is important to note that our evaluation is limited to English, a language with relatively low morphological complexity. Previous studies have identified significant tokenization challenges in non-English languages (Mager et al., 2022). Therefore, any definitive conclusions regarding the effectiveness of tokenization methods should ideally encompass a diverse array of languages. BPE and WordPiece, optimized for compression, unsurprisingly perform well above the likelihood-based vocabularies on the information measures. However, we note that this carries over to the cognitive benchmark as well, supporting Beinborn and Pinter (2023)\u2019s findings.\\n\\nFinally, we note that the two likelihood-based vocabularies follow the exact same within-vocab trends, and those for the two information-based vocabularies are also very close. This highlights the consistency and robustness of our benchmark, although some results are relatively close to each other, which can be expected considering that some inference methods do not change much of the token sequences (see rightmost column of Table 3).\\n\\n5 Conclusion In this work, we curated an aggregated benchmark for intrinsic evaluation of subword tokenizers and used it to show the importance of selecting an inference method suited for a vocabulary given a task. Given its computational efficiency, we hope the benchmark can be used in LM training efforts as a fruitful first step to improve tokenization schemes, or to select inference methods on-line. Concretely, our findings suggest that greedy inference is a good choice, especially for morphologically-motivated tasks, even for tokenizers trained on other objectives. Considering its ease of implementation and faster inference, this is an encouraging finding.\\n\\nIn the future, we plan to examine the correlation between our benchmark and various downstream tasks, as well as expand our experimentation to other languages and new algorithms.\\n\\nLimitations Our paper contains evaluation of models in the English language. This was done mostly in order to focus this short paper\u2019s contribution, and to be able to control for as many possibly-confounding variables such as training data. Nevertheless, a more complete followup would have to include attempts to replicate our findings on other languages, aiming for a set as diverse as possible mostly in terms of typology and script.\\n\\nOur evaluation is limited to intrinsic measures. While this makes development of tokenizers easier, we acknowledge that the body of work correlating success on these measures with performance of downstream models on end-tasks is incomplete.\\n\\nEthical Considerations Details for human annotation for the cognitive benchmark are documented in the source benchmark\u2019s paper (Beinborn and Pinter, 2023), from which we took the data as-is.\\n\\nAcknowledgments We would like to thank Charlie Lovering, Varshini Reddy, and Haoran Zhang for comments on early drafts of this paper. We thank the anonymous reviewers for their comments on our submission. This research was supported in part by the Israel Science Foundation (grant No. 1166/23) and by\"}"}
{"id": "acl-2024-short-73", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"References\\n\\nKhuyagbaatar Batsuren, G\u00e1bor Bella, and Fausto Giunchiglia. 2021. MorphyNet: a large multilingual database of derivational and inflectional morphology. In Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 39\u201348, Online. Association for Computational Linguistics.\\n\\nKhuyagbaatar Batsuren, Omer Goldman, Salam Khalifa, Nizar Habash, Witold Kieras, G\u00e1bor Bella, Brian Leonard, Garrett Nicolai, Kyle Gorman, Yusfnus Ghanggo Ate, Maria Ryskina, Sabrina Mielke, Elena Budianskaya, Charbel El-Khaissi, Tiago Pimentel, Michael Gasser, William Abbott Lane, Mohit Raj, Matt Coler, Jaime Rafael Montoya Samame, Delio Siticonatzi Camaiteri, Esa\u00fa Zumeta Rojas, Didier L\u00f3pez Francis, Arturo Onclevay, Juan L\u00f3pez Bautista, Gema Celeste Silva Villegas, Lucas Torroba Hennigen, Adam Ek, David Guriel, Peter Dirix, Jean-Philippe Bernardy, Andrey Scherbakov, Aziyana Bayyr-ool, Antonios Anastasopoulos, Roberto Zariquiey, Karina Sheifer, Sofya Ganieva, Hilaria Cruz, Ritv\u00e1n Karah\u00f3 \u011fa, Stella Markantonatou, George Pavlidis, Matvey Plugarov, Elena Klyachko, Ali Salehi, Candy Angulo, Jatayu Baxi, Andrew Krizhanovsky, Natalia Krizhanovskaya, Elizabeth Salesky, Clara Vania, Saradana Ivanova, Jennifer White, Rowan Hall Maudslay, Josef Valvoda, Ran Zmigrod, Paula Czarnowska, Irene Nikkarinen, Aelita Salchak, Brijesh Bhatt, Christopher Straughn, Zoey Liu, Jonathan North Washington, Yuval Pinter, Duygu Ataman, Marcin Wolinski, Totok Suhardijanto, Anna Yablonskaya, Niklas Stoehr, Hossep Dolatian, Zahroh Nuriah, Shyam Ratan, Francis M. Tyers, Edoardo M. Ponti, Grant Aiton, Aryaman Arora, Richard J. Hatcher, Ritesh Kumar, Jeremiah Young, Daria Rodionova, Anastasia Yemelina, Taras Andrushko, Igor Marchenko, Polina Mashkovtseva, Alexandra Serova, Emily Prud'hommeaux, Maria Nepomniaschaya, Fausto Giunchiglia, Eleanor Chodroff, Mans Hulden, Miikka Silfverberg, Arya D. McCarthy, David Yarowsky, Ryan Cotterell, Reut Tzartaly, and Ekaterina Vylomova. 2022. UniMorph 4.0: Universal Morphology. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 840\u2013855, Marseille, France. European Language Resources Association.\\n\\nKhuyagbaatar Batsuren, Ekaterina Vylomova, Verna Dankers, Tsetsuukhei Delgerbaatar, Omri Uzan, Yuval Pinter, and G\u00e1bor Bella. 2024. Evaluating subword tokenization: Alien subword composition and oov generalization challenge.\"}"}
{"id": "acl-2024-short-73", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The turning point of BPE merges. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 3454\u20133468, Online. Association for Computational Linguistics.\\n\\nXuanli He, Gholamreza Haffari, and Mohammad Norouzi. 2020. Dynamic programming encoding for subword segmentation in neural machine translation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3042\u20133051, Online. Association for Computational Linguistics.\\n\\nValentin Hofmann, Janet Pierrehumbert, and Hinrich Sch\u00fctze. 2020. DagoBERT: Generating derivational morphology with a pretrained language model. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3848\u20133861, Online. Association for Computational Linguistics.\\n\\nValentin Hofmann, Janet Pierrehumbert, and Hinrich Sch\u00fctze. 2021. Superbizarre is not superb: Derivational morphology improves BERT\u2019s interpretation of complex words. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3594\u20133608, Online. Association for Computational Linguistics.\\n\\nValentin Hofmann, Hinrich Schuetze, and Janet Pierrehumbert. 2022. An embarrassingly simple method to mitigate undesirable properties of pretrained language model tokenizers. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 385\u2013393, Dublin, Ireland. Association for Computational Linguistics.\\n\\nCassandra L Jacobs and Yuval Pinter. 2022. Lost in space marking. arXiv preprint arXiv:2208.01561.\\n\\nJean Kaddour. 2023. The minipile challenge for data-efficient language models. arXiv preprint arXiv:2304.08442.\\n\\nStav Klein and Reut Tsarfaty. 2020. Getting the ##life out of living: How adequate are word-pieces for modelling complex morphology? In Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 204\u2013209, Online. Association for Computational Linguistics.\\n\\nTaku Kudo. 2018. Subword regularization: Improving neural network translation models with multiple subword candidates. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 66\u201375, Melbourne, Australia. Association for Computational Linguistics.\\n\\nDavis Liang, Hila Gonen, Yuning Mao, Rui Hou, Namen Goyal, Marjan Ghazvininejad, Luke Zettel-moyer, and Madian Khabsa. 2023. XLM-V: Overcoming the vocabulary bottleneck in multilingual masked language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 13142\u201313152, Singapore. Association for Computational Linguistics.\\n\\nManuel Mager, Arturo Oncevay, Elisabeth Mager, Katharina Kann, and Thang Vu. 2022. BPE vs. morphological segmentation: A case study on machine translation of four polysynthetic languages. In Findings of the Association for Computational Linguistics: ACL 2022, pages 961\u2013971, Dublin, Ireland. Association for Computational Linguistics.\\n\\nSabrina J Mielke, Zaid Alyafeai, Elizabeth Salesky, Colin Raffel, Manan Dey, Matthias Gall\u00e9, Arun Raja, Chenglei Si, Wilson Y Lee, Beno\u00eet Sagot, et al. 2021. Between words and characters: a brief history of open-vocabulary modeling and tokenization in nlp. arXiv preprint arXiv:2112.10508.\\n\\nBenjamin Minixhofer, Jonas Pfeiffer, and Ivan Vuli \u00b4c. 2023. CompoundPiece: Evaluating and improving decompounding performance of language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 343\u2013359, Singapore. Association for Computational Linguistics.\\n\\nAnmol Nayak, Hariprasad Timmapathini, Karthikeyan Ponnalagu, and Vijendran Gopalan Venkoparao. 2020. Domain adaptation challenges of BERT in tokenization and sub-word representations of out-of-vocabulary words. In Proceedings of the First Workshop on Insights from Negative Results in NLP, pages 1\u20135, Online. Association for Computational Linguistics.\\n\\nAnaelia Ovalle, Ninareh Mehrabi, Palash Goyal, Jwala Dhamala, Kai-Wei Chang, Richard Zemel, Aram Galstyan, Yuval Pinter, and Rahul Gupta. 2024. Tokenization matters: Navigating data-scarce tokenization for gender inclusive language technologies.\\n\\nYuval Pinter, Cassandra L. Jacobs, and Jacob Eisenstein. 2020. Will it unblend? In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1525\u20131535, Online. Association for Computational Linguistics.\\n\\nYuval Pinter, Marc Marone, and Jacob Eisenstein. 2019. Character eyes: Seeing language through character-level taggers. In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 95\u2013102, Florence, Italy. Association for Computational Linguistics.\\n\\nIvan Provilkov, Dmitrii Emelianenko, and Elena Voita. 2020. BPE-dropout: Simple and effective subword regularization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1882\u20131892, Online. Association for Computational Linguistics.\"}"}
{"id": "acl-2024-short-73", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Jonne Saleva and Constantine Lignos. 2023. What changes when you randomly choose BPE merge operations? not much. In Proceedings of the Fourth Workshop on Insights from Negative Results in NLP, pages 59\u201366, Dubrovnik, Croatia. Association for Computational Linguistics.\\n\\nClaudia H. S\u00e1nchez-Guti\u00e9rrez, Hugo Mailhot, S. H\u00e9l\u00e8ne Deacon, and Maximiliano A. Wilson. 2018. Morpholex: A derivational morphological database for 70,000 english words. Behavior Research Methods, 50:1568\u20131580.\\n\\nTimo Schick and Hinrich Sch\u00fctze. 2019. Rare words: A major problem for contextualized embeddings and how to fix it by attentive mimicking.\\n\\nCraig W. Schmidt, Varshini Reddy, Haoran Zhang, Alec Alameddine, Omri Uzan, Yuval Pinter, and Chris Tanner. 2024. Tokenization is more than compression.\\n\\nMike Schuster and Kaisuke Nakajima. 2012. Japanese and korean voice search. In 2012 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5149\u20135152. IEEE.\\n\\nRico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715\u20131725, Berlin, Germany. Association for Computational Linguistics.\\n\\nYonghui Wu, Mike Schuster, Z. Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason R. Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Gregory S. Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Google\u2019s neural machine translation system: Bridging the gap between human and machine translation. ArXiv, abs/1609.08144.\\n\\nShaked Yehezkel and Yuval Pinter. 2023. Incorporating context into subword vocabularies. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 623\u2013635, Dubrovnik, Croatia. Association for Computational Linguistics.\\n\\nVil\u00e9m Zouhar, Clara Meister, Juan Gastaldi, Li Du, Mrinmaya Sachan, and Ryan Cotterell. 2023. Tokenization and the noiseless channel. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5184\u20135207, Toronto, Canada. Association for Computational Linguistics.\\n\\n**Table 4** presents benchmark results on 32K-sized and 49K-sized vocabularies.\\n\\n**Table 5** breaks down the results (for 40K) on individual morphological datasets composing our benchmark. **Table 6** Provides the same for individual cognitive measures.\\n\\n**Table 7** presents the Pearson correlation coefficients between the various intrinsic metrics used in the benchmark. These correlations are calculated based on the aggregated results across all vocabulary sizes.\"}"}
{"id": "acl-2024-short-73", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Vocab    | Inference | Morphological | Cognitive | R\u00e9nyi | Tokens | Decoding | method alignment | plausibility | efficiency | per word diff |\\n|----------|-----------|---------------|-----------|-------|--------|----------|-----------------|--------------|------------|---------------|\\n| BPE-32K  |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n| WordPiece-32K |       |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n| UnigramLM-32K    |       |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n| BPE-49K  |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n| WordPiece-49K |       |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n| UnigramLM-49K    |       |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n|          |           |               |           |       |        |          |                 |              |            |               |\\n\\nTable 4: Aggregated results on 32K and 49K vocabularies.\"}"}
{"id": "acl-2024-short-73", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"|                  | Vocab Inference | Ladec Morpho- | Morphy- | Dago- | Uni- | UnBlend Compound- | Lex Net | Bert Morph Piece |\\n|------------------|----------------|---------------|---------|-------|-----|------------------|---------|-----------------|\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |                |               |         |       |     |                  |         |                 |\\n|                  |               "}
