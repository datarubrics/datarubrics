{"id": "emnlp-2022-main-672", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Abstract\\n\\nLiterary translation is a culturally significant task, but it is bottlenecked by the small number of qualified literary translators relative to the many untranslated works published around the world. Machine translation (MT) holds potential to complement the work of human translators by improving both training procedures and their overall efficiency. Literary translation is less constrained than more traditional MT settings since translators must balance meaning equivalence, readability, and critical interpretability in the target language. This property, along with the complex discourse-level context present in literary texts, also makes literary MT more challenging to computationally model and evaluate. To explore this task, we collect a dataset (PAR3) of non-English language novels in the public domain, each aligned at the paragraph level to both human and automatic English translations. Using PAR3, we discover that expert literary translators prefer reference human translations over machine-translated paragraphs at a rate of 84%, while state-of-the-art automatic MT metrics do not correlate with those preferences. The experts note that MT outputs contain not only mistranslations, but also discourse-disrupting errors and stylistic inconsistencies. To address these problems, we train a post-editing model whose output is preferred over normal MT output at a rate of 69% by experts. We publicly release PAR3 to spur future research into literary MT.\\n\\n1 Introduction\\n\\nWhile the quality of machine translation (MT) systems has greatly improved with recent advances in modeling and dataset collection, the application of these new technologies to the task of automatically translating literary text (e.g., novels, short stories) has remained limited to small-scale studies (Genzel et al., 2010; Jones and Irvine, 2013; Toral et al., 2018). Translating literary works differs from translating standard MT corpora (e.g., news articles or parliamentary proceedings) in several key ways. For one, it is much more difficult to evaluate. The techniques used by literary translators differ fundamentally from those applied in more standard MT domains (see Table 8 in the Appendix). Literary translators have the freedom (or burden) of both semantic and critical interpretation, as they must solve the problem of equivalence, often beyond the word level (Neubert, 1983; Baker, 2018; Baker and Saldanha, 2021). The task of conveying an author's ideas highlights yet another difference between literary and traditional MT: document-level context is especially critical for the literary domain due to the presence of complex discourse structure, rendering the typical sentence-level MT pipeline insufficient for this task (Voigt and Jurafsky, 2012; Taivalkoski-Shilov, 2019).\\n\\nIn this work, we seek to understand how both state-of-the-art MT systems and MT evaluation metrics fail in the literary domain, and we also leverage large pretrained language models to improve literary MT. To facilitate our experiments, we introduce PAR3, a large-scale dataset to study paragraph-level literary translation into English. PAR3 consists of 121K paragraphs taken from 118 novels originally written in a non-English language, where each paragraph is aligned to multiple human-written English translations of that paragraph as well as a machine-translated paragraph produced...\"}"}
{"id": "emnlp-2022-main-672", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We show that MT evaluation metrics such as BLEU and BLEURT are not effective for literary MT. In fact, we discover that two of our tested metrics (BLEU and the document-level BLEU-D) show a preference for Google Translate outputs over reference translations in PA3. In reality, MT outputs are much worse than reference translations: our human evaluation reveals that professional translators prefer reference translations at a rate of 85%.\\n\\nWhile the translators in our study identified overly literal translations and discourse-level errors (e.g., coreference, pronoun consistency) as the main faults of modern MT systems, a monolingual human evaluation comparing human reference translations and MT outputs reveals additional hurdles in readability and fluency. To tackle these issues, we fine-tune GPT-3 (Brown et al., 2020) on an automatic post-editing task in which the model attempts to transform an MT output into a human reference translation. Human translators prefer the post-edited translations at a rate of 69% and also observe a lower incidence of the above errors.\\n\\nOverall, we identify critical roadblocks in evaluation towards meaningful progress in literary MT, and we also show through expert human evaluations that pretrained language models can improve the quality of existing MT systems on this domain.\\n\\nWe release PA3 to spur more meaningful future research in literary MT.\\n\\n2 The PA3 Dataset: Parallel Paragraph-Level Paraphrases\\n\\nTo study literary MT, we collect a dataset of parallel paragraph-level paraphrases (PA3) from public domain non-English-language (source) novels with their corresponding English translations generated by both humans and Google Translate. PA3 is a step up in both scale and linguistic diversity compared to prior studies in literary MT, which generally focus on one novel (Toral et al., 2018) or a small set of poems or short stories (Jones and Irvine, 2013). PA3 contains at least two human translations for every source paragraph (Table 2). In Table 1, we report corpus statistics by the 19 unique source languages represented in PA3. The Chinese texts in PA3 were written in Classical Chinese, an archaic and very different form of the language currently used today.\\n\\n| Src lang  | #texts | #src paras | sents/para |\\n|-----------|--------|------------|-----------|\\n| French (fr) | 32     | 50,070     | 2.7       |\\n| Russian (ru) | 27    | 36,117     | 3.3       |\\n| German (de)  | 16    | 9,170      | 4.3       |\\n| Spanish (es) | 1     | 3,279      | 2.0       |\\n| Czech (cs)  | 4      | 2,930      | 3.0       |\\n| Norwegian (no) | 2  | 2,655      | 3.4       |\\n| Swedish (sv) | 3     | 2,620      | 3.2       |\\n| Portuguese (pt) | 4  | 2,288      | 3.7       |\\n| Italian (it)  | 2     | 1,931      | 2.6       |\\n| Japanese (ja) | 9     | 1,857      | 4.4       |\\n| Bengali (bn) | 2     | 1,499      | 3.3       |\\n| Tamil (ta)  | 1      | 1,489      | 3.1       |\\n| Danish (da)  | 1      | 1,384      | 3.6       |\\n| Chinese (zh) | 3     | 1,320      | 8.8       |\\n| Dutch (nl)  | 1      | 963        | 3.4       |\\n| Hungarian (hu) | 1  | 892        | 3.7       |\\n| Polish (pl)  | 1      | 399        | 3.9       |\\n| Sesotho (st) | 1    | 374        | 4.2       |\\n| Persian (fa) | 1     | 148        | 4.2       |\\n| All         | 118    | 121,385    | 3.2       |\\n\\nTable 1: Corpus statistics for Version 2 of PA3 by each of the 19 source languages. The average number of sentences per paragraph refers to only the English human and Google Translate of the source paragraphs. We did not count tokens or sentences for source paragraphs because of the lack of a reliable tokenizer and sentence segmenter for all source languages.\\n\\nPA3 was curated in four stages: selection of source texts, machine translation of source texts, paragraph alignment, and final filtering. This process closely resembles the paraphrase mining methodology described by Barzilay and McKeown (2001); the major distinctions are (1) our collection of literary works that is \u223c20 times the size of the previous work, (2) our inclusion of the aligned source text to enable translation study, and (3) our alignment at the paragraph, not sentence, level. In this section, we describe the data collection process and disclose choices we made during curation of Version 1 of PA3. See Section A in the Appendix for more details on the different versions of PA3.\\n\\n2.1 Selecting works of literature\\n\\nFor a source text to be included in PA3, it must be (1) a literary work that has entered the public domain of its country of publication by 2022 with (2) a published electronic version along with (3) multiple versions of human-written, English translations. The first requirement skews our corpus towards older works of fiction. The second requirement ensures the preservation of the source texts' paragraph breaks. The third requirement limits us to works written in Romance, Germanic, Slavic, Japonic, Sino-Tibetan, Iranian, Dravidian, Ugric, and Bantu, with different morphological traits (synthetic, fusional, agglutinative), and use different writing systems (Latin alphabet, Cyrillic alphabet, Bengali script, Persian alphabet, Tamil script, Hanzi, and Kanji/Hiragana/Katakana).\"}"}
{"id": "emnlp-2022-main-672", "page_num": 3, "content": "{\"primary_language\":\"ru\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u2014 \u0418\u0437\u0432\u0438\u043d\u0438\u0442\u0435 \u043c\u0435\u043d\u044f: \u044f, \u0443\u0432\u0438\u0434\u0435\u0432\u0448\u0438 \u0438\u0437\u0434\u0430\u043b\u0438, \u043a\u0430\u043a \u0432\u044b \u0432\u043e\u0448\u043b\u0438 \u0432 \u043b\u0430\u0432\u043a\u0443, \u0440\u0435\u0448\u0438\u043b\u0441\u044f \u0432\u0430\u0441 \u043f\u043e\u0431\u0435\u0441\u043f\u043e\u043a\u043e\u0438\u0442\u044c. \u0415\u0441\u043b\u0438 \u0432\u0430\u043c \u0431\u0443\u0434\u0435\u0442 \u0441\u0432\u043e\u0431\u043e\u0434\u043d\u043e \u0438 \u043f\u043e \u0434\u043e\u0440\u043e\u0433\u0435 \u043c\u0438\u043c\u043e \u043c\u043e\u0435\u0433\u043e \u0434\u043e\u043c\u0430, \u0442\u0430\u043a \u0441\u0434\u0435\u043b\u0430\u0439\u0442\u0435 \u043c\u0438\u043b\u043e\u0441\u0442\u044c, \u0437\u0430\u0439\u0434\u0438\u0442\u0435 \u043d\u0430 \u043c\u0430\u043b\u043e\u0441\u0442\u044c \u0432\u0440\u0435\u043c\u0435\u043d\u0438. \u041c\u043d\u0435 \u0441 \u0432\u0430\u043c\u0438 \u043d\u0443\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u043f\u0435\u0440\u0435\u0433\u043e\u0432\u043e\u0440\u0438\u0442\u044c.\\n\\n SRC (st):\\nHo bile jwalo ho fela ha Chaka, mora wa Senzangakhona. Mazulu le kajeno a bokajeno ha a hopola kamoo a kileng ya eba batho kateng, mehleng ya Chaka, kamoo ditjhaba di neng di jela kgwebeleng ke ho ba tshoha, leha ba hopola borena ba bona bo weleng, eba ba sekisa mahlong, ba re:\\n\\n\\\"Di a bela, di a hlweba! Madiba ho pjha a maholo!\\\"\\n\\nGTr: Such was the end of Chaka, son of Senzangakhona. The Zulus of today when they remember how they once became people, in the days of Chaka, how the nations ate in the sun because of fear of them, even when they remember their fallen kingdom, they wince in their eyes, saying:\\n\\n\\\"They're boiling, they're boiling! The springs are big!\\\"\\n\\nHUM1: So it came about, the end of Chaka, son of Senzangakhona. Even to this very day the Zulus, when they think how they were once a strong nation in the days of Chaka, and how other nations dreaded them so much that they could hardly swallow their food, and when they remember their kingdom which has fallen, tears well up in their eyes, and they say: \\\"They ferment, they curdle! Even great pools dry away!\\\"\\n\\nHUM2: And this was the last of Chaka, the son of Senzangakona. Even to-day the Mazulu remember how that they were men once, in the time of Chaka, and how the tribes in fear and trembling came to them for protection. And when they think of their lost empire the tears pour down their cheeks and they say: 'Kingdoms wax and wane. Springs that once were mighty dry away.'\\n\\nTable 2: An example of one source paragraph in PAR3, from Nikolai Gogol\u2019s Dead Souls (upper example) and from Thomas Mofolo\u2019s Chaka (lower example) with their corresponding Google translation to English and aligned paragraphs from human-written translations.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"2.5 Train, test, and validation splits\\n\\nInstead of randomly creating splits of the 121K paragraphs in PAR3, we define train, test, and validation splits at the document level. Each literary text belongs to one split, and all translations associated with its source paragraphs belong to that split as well. This decision allows us to better test the generalization ability of systems trained on PAR3, and avoid cases where an MT model memorizes entities or stylistic patterns located within a particular book to artificially inflate its evaluation scores.\\n\\nThe training split contains around 80% of the total number of source paragraphs (97,611), the test split contains around 10% (11,606), and the validation split contains around 10% (11,606). Appendix 5 shows the texts belonging to each split.\\n\\n3 How good are existing MT systems for literary translation?\\n\\nArmed with our PAR3 dataset, we next turn to evaluating the ability of commercial-grade MT systems for literary translation. First, we describe a study in which we hired both professional literary translators and monolingual English experts to compare reference translations to those produced by Google Translate at a paragraph-level. In an A/B test, the translators showed a strong preference (on 84% of examples) for human-written translations, finding MT output to be far too literal and riddled with discourse-level errors (e.g., pronoun consistency or contextual word sense issues). The monolingual raters preferred the human-written translations over the Google Translate outputs 85% of the time, suggesting that discourse-level errors made by MT systems are prevalent and noticeable when the MT outputs are evaluated independently of the source texts.\\n\\nFinally, we address deficiencies in existing automatic MT evaluation metrics, including BLEU, BLEURT, and the document-level BLEU metric. These metrics failed to distinguish human from machine translation, even preferring the MT outputs on average.\\n\\n3.1 Diagnosing literary MT with judgments from expert translators\\n\\nAs literary MT is understudied (especially at a document level), it is unclear how state-of-the-art MT systems perform on this task and what systematic errors they make. To shed light on this issue, we hire human experts (both monolingual English experts as well as literary translators fluent in both languages) to perform A/B tests on PAR3 which indicates their preference of a Google Translate output paragraph (GTr) versus a reference translation written by a human (HUM). We additionally solicit detailed free-form comments for each example explaining the raters' justifications. We find that both monolingual raters and literary translators strongly prefer HUM over GTr paragraphs, noting that overly literal translation and discourse errors are the main error sources with GTr.\\n\\n**Experimental setup:**\\n\\nWe administer A/B tests to two sets of raters: (1) monolingual English experts (e.g., creative writers or copy editors), and (2) professional literary translators. For the later group, we first provided a source paragraph in German, French, or Russian. Under the source paragraph, we showed two English translations of the source paragraph: one produced by Google Translate and one from a published, human-written translation.\\n\\nWe asked each rater to choose the \u201cbetter\u201d translation and also to give written justification for their choice (2-3 sentences). While all raters knew that the texts were translations, they did NOT know that one paragraph was machine-generated. Each translator completed 50 tasks in their language of expertise. For the monolingual task, the set up was similar except for two important distinctions: (1) NO source paragraph was provided and (2) each monolingual rater rated all 150 examples (50 from each of 3 language-specific tasks). Tasks were designed and administered via Label Studio, an open-source data-labeling tool, and raters were hired using Upwork, an online platform for freelancers.\\n\\nFor the completion of 50 language-specific tasks, translators were paid $200 each. For the set of 150 monolingual tasks, raters were paid $250 each. All raters were given at least 4 days to complete their tasks.\\n\\n**Common MT errors:**\\n\\nWe roughly categorize the errors highlighted by the professional literary translators into five groups. The most pervasive error (constituting nearly half of all translation errors identified) is the overly literal translation of the\"}"}
{"id": "emnlp-2022-main-672", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"source text, where a translator adheres too closely to the syntax of the source language, resulting in awkward phrasing or the mistranslation of idioms. The second most prevalent errors are discourse errors, such as pronoun inconsistency or coreference issues, which occur when context is ignored\u2013these errors are exacerbated at the paragraph and document levels. We define the rest of the categories and report their distribution in Table 3.\\n\\nMonolingual vs translator ratings: Though the source text is essential to the practice of translation, the monolingual setting of our A/B testing allows us to identify attributes other than translation errors that distinguish the MT system outputs from human-written text. Both monolingual and bilingual raters strongly preferred HUM to GTr across all three tested languages, as shown in Figure 1, although their preference fell on Russian examples.\\n\\nIn a case where all 3 monolingual raters chose HUM while the translator chose GTr, their comments reveal that the monolingual raters prioritized clarity and readability:\\n\\n\\\"HUM is preferable because it flows better and makes better sense\\\" and \\\"made complete sense and was much easier to read\\\" while the translator diagnosed HUM with a catastrophic error: \\\"HUM contains several mistakes, mainly small omissions that change the meaning of the sentence, but also wrong translations ('trained European chef' instead of 'European-educated chef').\\\"\\n\\nFor an example where all 3 monolingual raters chose GTr while the translator chose HUM, the monolingual raters much preferred the contemporary language in GTr:\\n\\n\\\"GTr was much easier for me to grasp because of its structure compared to the similar sentence in HUM\\\" and praised for its \\\"use of commonplace vocabulary that is understandable to the reader.\\\"\\n\\nHowever, the translator, with access to the source text, identified a precision error in GTr, and ultimately declared HUM to be the better translation: \\\"lord from HUM is the exact translation of the Russian \u0431\u0430\u0440\u0438 while bard from GTr doesn't convey a necessary meaning.\\\"\\n\\n3.2 Can automatic MT metrics evaluate literary translation? Expert human evaluation, while insightful, is also time-consuming and expensive, which precludes its use in most model development scenarios. The MT community thus relies extensively on automatic metrics that score candidate translations against references. In this section, we explore the usage of three metrics (BLEU, BLEURT, and BLENDER) on literary MT evaluation, and we discover that none of them can accurately distinguish GTr text from HUM. Regardless of their performance, we also note that most automatic metrics are designed to work with sentence-level alignments, which are rarely available for literary translations because translators merge and combine sentences. Thus, developing domain-specific evaluation metrics is crucial to make meaningful progress in literary MT.\\n\\nMT Metrics: To study the ability of MT metrics to distinguish between machine and human translations, we compute three metrics on PAR3:\\n\\nBLEU (Papineni et al., 2002) is a string-based multi-reference metric originally proposed to evaluate sentence-level translations but also used for document-level MT (Liu et al., 2020). BLEURT (Sellam et al., 2020) is a pretrained language model fine-tuned on human judgments of translation-reference pairs. BLEURT has been between the monolingual raters was 0.546 (0.437 for Russian, 0.494 for German, and 0.707 for French). The IAA between the aggregated votes of monolingual raters (majority vote) and the translator was 0.524 for Russian, 0.683 for German, and 0.681 for French. These numbers suggest moderate to substantial agreement (Artstein and Poesio, 2008).\\n\\nTo view the SRC, HUM, and GTr texts for these examples, see Tables 13 and 14 in the Appendix.\\n\\nWe compute the default, case-sensitive implementation of BLEU from https://github.com/mjpost/sacrebleu. We compute BLEURT for PAR3 using the recommended and most recent checkpoint, BLEURT-20. As the maximum input length for BLEURT is 512 sentencepiece tokens, we exclude inputs which exceed this length and would be otherwise truncated. In total, 1.4% of the dataset was excluded.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Example\\n\\nError Type (%)\\nTranslator Comments\\nFrom The Sin of Abb\u00e9 Mouret, Emile Zola\\n\\nSRC: L'abb\u00e9 Mouret d\u00e9pensa l\u00e0 ses \u00e9conomies du s\u00e9minaire. C'\u00e9taient, d'ailleurs, des embellissements dont la na\u00efvet\u00e9 maladroite e\u00fbt fait sourire. La ma\u00e7onnerie le rebuta vite. Il se contenta de recr\u00e9pir le tour de l'\u00e9glise, \u00e0 hauteur d'homme. La Teuse g\u00e2chait le pl\u00e2tre.\\n\\nHUM: Abb\u00e9 Mouret spent all his seminary savings on the work. His embellishments were so clumsy and naive as to raise a smile. Masonry soon lost its appeal for him. He contented himself with replastering all round the church to the height of a man's head. La Teuse mixed the plaster.\\n\\nGTr: Father Mouret spent his seminary savings there. They were, moreover, embellishments whose clumsy simplicity would have made you smile. Masonry soon put him off. He contented himself with replastering around the church, at eye level. La Teuse ruined the plaster.\\n\\nTable 3: Definitions and examples of the five types of translation errors on Google Translate outputs identified by professional literary translators. We report their prevalence as a percentage of all errors identified by the translators and include the translators' explanations.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We fine-tune GPT-3 to perform automatic post-editing on the output of Google Translate. Google Translate:\\n\\nThere were seven tables in the dining room, most of them lengthwise, only two across. There were larger tables, for ten people each, even if the covers were not all full. Only a few steps diagonally into the hall, and Hans Castorp was already in his place: he was ready for him on the narrow side of the table, which was standing in the middle in front, between the two people standing at right angles\u2026\\n\\nGerman source:\\n\\nSieben Tische standen im Speisesaal, die meisten in L\u00e4ngsrichtung, nur zwei in die Quere. Es waren gr\u00f6\u00dfere Tafeln, f\u00fcr zehn Personen jede, wenn auch die Gedecke nicht \u00fcberall vollz\u00e4hlig waren. Nur ein paar Schritte schr\u00e4g in den Saal hinein, und Hans Castorp war schon an seinem Platz: er war ihm an der Schmalseite des Tisches bereitet, der mitten vorn stand, zwischen den beiden querstehenden\u2026\\n\\nGPT-3\\n\\nPost-edited:\\n\\nThere were seven tables in the dining-room, most of them running lengthwise, only two at right angles. They were larger tables, for ten persons each, though not all the places were occupied. A few steps diagonally across the room, and Hans Castorp was at his place, which had been laid out for him on the narrow side of the table, which stood in the middle, between the two at right angles\u2026\\n\\nLiterary translator\\n\\nTranslator preference explanation:\\nThe first translation contains several mistakes, such as a wrong pronoun (\u201che\u201d instead of \u201cit\u201d when referring to his place) and mixing up tables with people (\u201ctwo people standing\u201d). In general, the wording and sentence structure of the second translation is much better. The first translation reads awkward, the second smoother.\\n\\nFigure 2: An illustration of our automatic post-editing model on a PAR3 source paragraph from Thomas Mann's The Magic Mountain, which fine-tunes GPT-3 to transform a Google Translate paragraph into a human-written reference translation. We hire professional literary translators (in this case, a German translator) to perform a blind A/B test comparing Google Translate against the post-edited output and also to provide free-form explanations as to why they made their choice. In this case, and 69.3% of the time overall, they prefer the post-editing model's output.\\n\\nAutomatic metrics are not predictive of literary MT quality: We have identified mistakes made by Google Translate in Section 3.1 and the human translations have all been professionally edited and published. Hence, we expect automatic metrics to prefer the human translations. However, we show in Table 4 that two of our three metrics, BLEU and BLOD, fail to distinguish meaningfully between the human and Google translations, preferring the Google translation to the human one in over 60% of cases. For BLEURT, the choice between Google and human is nearly chance, with human translations preferred 53.6% of the time. A Wilcoxon signed-rank test (Wilcoxon, 1945) reveals that both BLEU (z = -67.344, p < .001, r = .192) and BLOD (z = -62.862, p < .001, r = .179) prefer Google Translate over human translation. BLEURT, on the other hand, appears to correctly distinguish between the human translation and Google Translate (z = 42.462, p < .001, r = .118); however, the effect size is small (r < .30) in all three cases.\\n\\nCan automatic post-editing improve literary MT? From the experiments in the previous section, we can conclude that human expert evaluation is currently the only way to judge the quality of literary MT. We now turn to improving the quality of Google Translate outputs on PAR3 via automatic post-editing (Chatterjee et al., 2018), in which a model corrects the output of a black-box MT system. While Toral et al. (2018) show that manual post-editing on top of MT outputs aids human translator efficiency in the literary domain, no prior work has applied automatic post-editing to literary translations. As shown in Figure 2, we feed both the source paragraph and the Google Translate output to the GPT-3 (Brown et al., 2020) language model, which has been shown to have zero-shot translation capability (although far below state-of-the-art supervised MT systems). We fine-tune GPT-3 to produce a human-written reference translation given these inputs and find that it mitigates issues with overly literal translation and discourse errors.\\n\\n4.1 Literary post-editing with GPT-3 Our analysis experiments reveal that discourse-level errors that span multiple sentences (e.g., coreference, stylistic consistency, contextual word sense selection) are a huge problem for Google Translate when applied to literary MT. Motivated to address these issues, we select the 175B parameter GPT-3 davinci model as our base post-editing system, as it can operate over paragraph-length inputs (max sequence length of 2048 tokens), encode text in multiple languages, and exhibits impressive ability to learn complex tasks with limited training data. To form fine-tuning examples for GPT-3, we concatenate a source paragraph SRC, an aligned Google Translate paragraph GTr, and a human reference translation HUM using special separator and end-of-\"}"}
{"id": "emnlp-2022-main-672", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 4: Average $\\\\text{BLEU}$, $\\\\text{BLEURT}$, and $\\\\text{BLON}$DE scores for PAR by source language, computed using the same reference set on human and Google translations. See Section 3.2 for details on the computation of the average metric score. The Win % in the final row is the percentage of cases, out of 121,385 unique source paragraphs, in which the metric prefers the human or the Google translation.\\n\\nsequence tokens: $\\\\text{seq} = \\\\text{SRC} \\\\text{ <SEP> GTr <SEP> HUM <EOS>}$\\n\\nwhere $\\\\text{SRC <SEP> GTr}$ is considered the prompt and $\\\\text{HUM <EOS>}$ is the completion.\\n\\nData filtering: Before fine-tuning our model, we filtered the PAR training set to remove examples where the aggregated $\\\\text{BLEU}$ scores between GTr and HUM were either in the 10th or 90th percentiles, which ignores both noisy alignments and near-perfect GTr outputs that do not need any edits. For each example, we also only use the HUM paragraph with the maximum $\\\\text{BLEU}$ against the GTr output for that source paragraph, since we could not use all references during fine-tuning. Finally, we randomly sample 30K of the filtered training examples because of the prohibitive cost of fine-tuning and using the GPT-3 davinci model.\\n\\n4.2 Human evaluation of post-edited outputs\\n\\nHaving established that human evaluation is critical for literary MT, we had the same 3 professional translators perform A/B testing on GTr and the outputs of our post-editing model GPT-3. The translators prefer GPT-3 over GTr at a rate of 69% ($p<.001$, 95% CI [0.613, 0.770]). The comments show that the model often improved on the \\\"overly literal\\\" nature of many GTr paragraphs: \\\"The phrase \u0441 \u0437\u043d\u0430\u043a\u043e\u043c\u044b\u043c\u0438, \u043e\u0447\u0435\u043d\u044c \u0437\u043d\u0430\u043a\u043e\u043c\u044b-\u043c\u0438 \u0443\u043b\u044b\u0431\u043a\u043e\u0439 \u0438 \u0432\u0437\u0433\u043b\u044f\u0434\u043e\u043c from the source text should be translated as 'with a familiar, very familiar smile and gaze' as in GPT-3. The author of GTr makes mistakes in choosing the words and suggests \\\"with acquaintances, very familiar smile and look.\\\"\\n\\nFinally, we also had the 3 professional translators perform A/B testing on the post-edited GPT-3 outputs and HUM. While the translators still preferred HUM, their preference rate decreased from 84% (vs. GTr) to 63%. Their comments reveal an interesting caveat to their judgments: overall, raters are much more confident when selecting GPT-3 than when selecting GTr when choosing between the two machine translations. When they did choose GTr, they were often unsure because both translations were equivalently good or bad. When comparing HUM to GPT-3, our annotators were unsure around half of the time, regardless of whether they selected HUM or GPT-3 (they were slightly more confident when choosing HUM), suggesting that the task of discerning the better translator was particularly challenging. We present the results of a small-scale quantitative analysis of the 150 comments across the 3 raters in Figure 3.\\n\\nCharacterizing the behavior of GPT-3 post-editing: We performed a fine-grained analysis of the comments provided by professional translators regarding the behavior of the GPT-3 post-editing model. Overall, the translators observe several positives, including correcting pronoun errors and mistranslations in addition to better capturing the sense of the original work compared to GTr. For example, the professional Russian translator noted an\"}"}
{"id": "emnlp-2022-main-672", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The number of votes for HUM vs GTr, GPT-3 vs GTr, and HUM vs GPT-3 along with their corresponding raters' confidence.\\n\\nThe narrator mentions one character whose name is \\\"Ippolit.\\\" The author of the GTr translation uses this spelling, but then changes it into \\\"Hippolyte\\\" for no reason.\\n\\nOn the other hand, the GPT-3 text occasionally omits some details or contains stylistic choices with which the translators disagree:\\nThe only reason I selected GTr is because I like how it kept the full French nickname \\\"La Teuse\\\" and did not translate the determiner into \\\"the Teuse\\\" as GPT-3 did.\\n\\nWe show more examples of the post-edit model correcting errors in GTr in Table 7. In 31 out of 150 cases, the translators felt that GPT-3 did not notably improve upon GTr, often mentioning that neither translation was preferred.\\n\\nDid GPT-3 see the translations in pretraining?\\n\\nOne potential criticism of the GPT-3 post-editing model is that it may have seen the reference translations in its pretraining data, and thus any improvements could just be a result of memorization rather than actual understanding of the source text.\\n\\nWe qualitatively measure this by creating a small dataset of translated paragraphs that could not have been seen by GPT-3. These translations were either published after GPT-3 was pretrained (2022), or manually translated by an author of this paper from previously untranslated works of literature.\\n\\nEven on this previously unseen data, our model can correct mistranslations, grammatical errors, and stylistic inconsistencies:\\n\\n**SRC:**\\n\u6731\u4e3d\u9ed8\u9ed8\u8d70\u4e0b\u697c\u53bb\uff0c\u90fd\u6ca1\u5750\u7535\u68af\uff0c\u4e00\u8def\u56de\u60f3\u60ca\u9e3f\u4e00\u77a5\u7684\u660e\u6210\u7684\u8138\u3002\\n\\n**GTr:**\\nZhu Li walked downstairs silently, without taking the elevator, all the way back to the face of Ming Cheng who had caught a glimpse.\\n\\n**GPT-3:**\\nZhu Li walked downstairs in silence, without taking the elevator, and all the way back she kept recalling the face of Ming Cheng, which she had seen for a moment.\\n\\n5 Related Work\\n\\nOur work builds on previous work in literary machine translation. Some early work focused on poetry translation (Genzel et al., 2010; Jones and Irvine, 2013), which has recently been tackled with neural approaches (Chakrabarty et al., 2021).\\n\\nOther works have targeted novels, like those in PAR3, with focuses on manual post-editing (Toral et al., 2018, 2020) and comparisons of neural MT to statistical MT systems (Moorkens et al., 2018; Toral and Way, 2018, 2015). Most of these works experiment with datasets far smaller than PAR3 (Arenas and Toral, 2022; Fonteyne et al., 2020). More recent work has involved studying the linguistic characteristics of post-edited literary machine-translated text (Castilho and Resende, 2022; Macken et al., 2022).\\n\\nWork towards document-level NMT has built on sentence-level MT (Tiedemann and Scherrer, 2017; Jean et al., 2017; Bawden et al., 2018; Micolich et al., 2018; Agrawal et al., 2018). The critical lack of parallel document-level corpora has inspired the creative use of parallel sentence-level data (Zhang et al., 2018) and techniques for creating parallel document-level data (Junczys-Dowmunt, 2019). Our work also builds on efforts to tackle discourse-level errors specific to document-level MT and is very similar to that of Votia et al. (2019), but we specifically focus on the literary domain.\\n\\n6 Conclusion\\n\\nWe study document-level literary machine translation by collecting a dataset (PAR3) of 121K parallel paragraphs from 104 novels. Our experiments show that existing automatic metrics of translation quality are not meaningful in the literary domain. A human evaluation experiment with professional literary translators reveals that commercial-grade MT systems are too literal in their translations and also suffer from discourse-level errors. We mitigate these problems to a certain extent by developing an automatic post-editing model using GPT-3. Overall, our work uncovers new challenges to progress in literary MT, and we hope that the public release of PAR3 will encourage researchers to tackle them.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Limitations\\n\\nWhile PAR3 covers a diverse array of genres and languages, there are potential confounding factors in the translation data to be aware of when performing analysis or modeling on top of it. First, multiple human translations of the same source text may not have been written independently: a later translator might have used an earlier translation as a reference, or a new translation may be commissioned because of dissatisfaction with older translations. Additionally, translators in our dataset differ in aspects such as years of experience, familiarity with the author of the source text (some were the exclusive translator for a single author), and bilinguality. The circumstances of each translation are also unique geographically and temporally. It is unclear whether (or how) to model such differences computationally, but it is an intriguing direction for future work.\\n\\nWe also acknowledge that our dataset has a single target-language; the curation of data in other target languages and the improvement of literary MT for other target languages is an essential step towards an equitable and more culturally-conscious field of NLP.\\n\\nEthical Considerations\\n\\nWe acknowledge that the vast majority of the authors of our source texts are male. Because literary translation requires training, time, and money, our source texts skew towards older texts that achieved international popularity. We hope that our efforts towards better literary MT can aid literary translators in sharing more minority voices. The experiments involving humans were IRB-approved, and each hired rater was fairly compensated, with wages adjusted as we determined the average amount of time each task took.\\n\\nAcknowledgements\\n\\nWe would like to thank the translators and English language professionals hired on Upwork for the efforts they put in the evaluation and their insightful comments. We would also like to show our appreciate to Tu Vu for sharing his knowledge about MT evaluation metrics and to Sergiusz Rzepkowski for his help in cleaning the data, as well as multiple translators whom we consulted when exploring our dataset. Finally, we would like to thank the UMass NLP community for their insights and discussions during this project. This project was partially supported by awards IIS-1955567 and IIS-2046248 from the National Science Foundation (NSF) as well as an award from Open Philanthropy.\\n\\nReferences\\n\\nEneko Agirre, Carmen Banea, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Rada Mihalcea, German Rigau, and Janyce Wiebe. 2016. SemEval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation. In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 497\u2013511, San Diego, California. Association for Computational Linguistics.\\n\\nRuchit Agrawal, Marco Turchi, and Matteo Negri. 2018. Contextual Handling in Neural Machine Translation: Look Behind, Ahead and on Both Sides.\\n\\nAna Guerberof Arenas and Antonio Toral. 2022. Creamt: Creativity and narrative engagement of literary texts translated by translators and nmt. In Proceedings of the 23rd Annual Conference of the European Association for Machine Translation, pages 355\u2013356.\\n\\nRon Artstein and Massimo Poesio. 2008. Survey article: Inter-coder agreement for computational linguistics. Computational Linguistics, 34(4):555\u2013596.\\n\\nMona Baker. 2018. In other words, 3 edition. Routledge, London, England.\\n\\nMona Baker and Gabriela Saldanha, editors. 2021. Routledge encyclopedia of translation studies, 3 edition. Taylor & Francis, London, England.\\n\\nRegina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 50\u201357, Toulouse, France. Association for Computational Linguistics.\\n\\nRachel Bawden, Rico Sennrich, Alexandra Birch, and Barry Haddow. 2018. Evaluating discourse phenomena in neural machine translation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1304\u20131313, New Orleans, Louisiana. Association for Computational Linguistics.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901.\\n\\nChris Callison-Burch. 2009. Fast, cheap, and creative: Evaluating translation quality using Amazon's Mechanical Turk. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 989\u2013999, Boulder, Colorado. Association for Computational Linguistics.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Sheila Castilho and Nat\u00e1lia Resende. 2022. Post-editing in literary translations.\\n\\nTuhin Chakrabarty, Arkadiy Saakyan, and Smaranda Muresan. 2021. Don't go far off: An empirical study on neural poetry translation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7253\u20137265, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n\\nRajen Chatterjee, Matteo Negri, Rubino Raphael, and Marco Turchi. 2018. Findings of the wmt 2018 shared task on automatic post-editing. In Third Conference on Machine Translation (WMT), pages 723\u2013738. Association for Computational Linguistics.\\n\\nAndrew Chesterman. 2005. Problems with strategies. In K. K\u00e1roly and A. F\u00f3ris, editors, Trends in Translation Studies. In honour of Kinga Klaudy., pages 17\u201328. Akademiai Kiado, Budapest.\\n\\nMargot Fonteyne, Arda Tezcan, and Lieve Macken. 2020. Literary Machine Translation under the Magnifying Glass: Assessing the Quality of an NMT-Translated Detective Novel on Document Level. In Proceedings of the 12th Language Resources and Evaluation Conference, pages 3790\u20133798, Marseille, France. European Language Resources Association.\\n\\nDmitriy Genzel, Jakob Uszkoreit, and Franz Och. 2010. \\\"poetic\\\" statistical machine translation: Rhyme and meter. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 158\u2013166, Cambridge, MA. Association for Computational Linguistics.\\n\\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.\\n\\nS\u00e9bastien Jean, Stanislas Lauly, Orhan Firat, and Kyunghyun Cho. 2017. Does neural machine translation benefit from larger context? ArXiv, abs/1704.05135.\\n\\nYuchen Jiang, Tianyu Liu, Shuming Ma, Dongdong Zhang, Jian Yang, Haoyang Huang, Rico Sennrich, Ryan Cotterell, Mrinmaya Sachan, and Ming Zhou. 2022. BlonDe: An automatic evaluation metric for document-level machine translation. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1550\u20131565, Seattle, United States. Association for Computational Linguistics.\\n\\nRuth Jones and Ann Irvine. 2013. The (un)faithful machine translator. In Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 96\u2013101, Sofia, Bulgaria. Association for Computational Linguistics.\\n\\nMarcin Junczys-Dowmunt. 2019. Microsoft translator at wmt 2019: Towards large-scale document-level neural machine translation.\\n\\nJungo Kasai, Keisuke Sakaguchi, Ronan Le Bras, Lavinia Dunagan, Jacob Morrison, Alexander R Fabbri, Yejin Choi, and Noah A Smith. 2021. Bidimensional leaderboards: Generate and evaluate language hand in hand. arXiv preprint arXiv:2112.04139.\\n\\nKlaus Krippendorff. 2011. Computing krippendorff\u2019s alpha-reliability.\\n\\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020. Multilingual denoising pretraining for neural machine translation. Transactions of the Association for Computational Linguistics, 8:726\u2013742.\\n\\nLieve Macken, Bram Vanroy, Luca Desmet, and Arda Tezcan. 2022. Literary translation as a three-stage process: machine translation, post-editing and revision. In Proceedings of the 23rd Annual Conference of the European Association for Machine Translation, pages 101\u2013110. European Association for Machine Translation.\\n\\nLesly Miculicich, Dhananjay Ram, Nikolaos Pappas, and James Henderson. 2018. Document-level neural machine translation with hierarchical attention networks. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2947\u20132954, Brussels, Belgium. Association for Computational Linguistics.\\n\\nLuc\u00eda Molina and Amparo Hurtado Albir. 2004. Translation techniques revisited: A dynamic and functionalist approach. Meta, 47(4):498\u2013512.\\n\\nJoss Moorkens, Antonio Toral, Sheila Castilho, and Andy Way. 2018. Translators\u2019 perceptions of literary post-editing using statistical and neural machine translation. Translation Spaces, 7(2):240\u2013262.\\n\\nSaul B. Needleman and Christian D. Wunsch. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48(3):443\u2013453.\\n\\nAlbrecht Neubert. 1983. Discourse analysis of translation.\\n\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02, page 311\u2013318, USA. Association for Computational Linguistics.\\n\\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881\u20137892, Online. Association for Computational Linguistics.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Kristiina Taivalkoski-Shilov. 2019. Free indirect discourse: an insurmountable challenge for literary MT systems? In Proceedings of the Qualities of Literary Machine Translation, pages 35\u201339.\\n\\nBrian Thompson and Matt Post. 2020. Automatic machine translation evaluation in many languages via zero-shot paraphrasing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 90\u2013121, Online. Association for Computational Linguistics.\\n\\nJ\u00f6rg Tiedemann and Yves Scherrer. 2017. Neural machine translation with extended context. In Proceedings of the Third Workshop on Discourse in Machine Translation, pages 82\u201392, Copenhagen, Denmark. Association for Computational Linguistics.\\n\\nAntonio Toral, Antoni Oliver, and Pau Ribas Ballest\u00edn. 2020. Machine translation of novels in the age of transformer. arXiv preprint arXiv:2011.14979.\\n\\nAntonio Toral and Andy Way. 2015. Translating literary text between related languages using SMT. In CLfL@NAACL-HLT.\\n\\nAntonio Toral and Andy Way. 2018. What level of quality can neural machine translation attain on literary text? In Translation Quality Assessment, pages 263\u2013287. Springer.\\n\\nAntonio Toral, Martijn Wieling, and Andy Way. 2018. Post-editing effort of a novel with statistical and neural machine translation. Frontiers in Digital Humanities, page 9.\\n\\nRob Voigt and Dan Jurafsky. 2012. Towards a literary machine translation: The role of referential cohesion. In Proceedings of the NAACL-HLT 2012 Workshop on Computational Linguistics for Literature, pages 18\u201325.\\n\\nElena Voita, Rico Sennrich, and Ivan Titov. 2019. Context-aware monolingual repair for neural machine translation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 877\u2013886, Hong Kong, China. Association for Computational Linguistics.\\n\\nJohn Wieting, Taylor Berg-Kirkpatrick, Kevin Gimpel, and Graham Neubig. 2019. Beyond BLEU: training neural machine translation with semantic similarity. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4344\u20134355, Florence, Italy. Association for Computational Linguistics.\\n\\nFrank Wilcoxon. 1945. Individual comparisons by ranking methods. Biometrics Bulletin, 1(6):80.\\n\\nOmar F. Zaidan and Chris Callison-Burch. 2011. Crowdsourcing translation: Professional quality from non-professionals. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1220\u20131229, Portland, Oregon, USA. Association for Computational Linguistics.\\n\\nYuming Zhai, Lufei Liu, Xinyi Zhong, Gbariel Illouz, and Anne Vilnat. 2020. Building an English-Chinese parallel corpus annotated with sub-sentential translation techniques. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 4024\u20134033, Marseille, France. European Language Resources Association.\\n\\nYuming Zhai, Aur\u00e9lien Max, and Anne Vilnat. 2018. Construction of a multilingual corpus annotated with translation relations. In Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing, pages 102\u2013111, Santa Fe, New Mexico, USA. Association for Computational Linguistics.\\n\\nJiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai, Jingfang Xu, Min Zhang, and Yang Liu. 2018. Improving the transformer translation model with document-level context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 533\u2013542, Brussels, Belgium. Association for Computational Linguistics.\\n\\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Christian M. Meyer, and Steffen Eger. 2019. Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, Hong Kong, China. Association for Computational Linguistics.\\n\\nAppendix\\n\\nA Dataset Versions\\n\\nThe first version of PAR3 was created in April 2022 as described in Section 2. The post-edit model and all human evaluations were conducted on this version of the dataset, which can still be found at https://github.com/katherinethai/par3/.\\n\\nIn October 2022, we expanded PAR3 to include three additional languages: Bengali, Sesotho, and Danish, along with new books in Russian and German. Those texts were translated using the Google Translate API in September 2022. The remaining data processing steps were the same.\\n\\nB Post-editing Details\\n\\nAutomatic evaluation of post-edited texts: We compute BLEU, BLEURT, and BLEND on the outputs of the post-editing model and present the results by source language in Table 9. All 3 metrics show a clear preference for the human translations or the post-edited outputs of GPT-3.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The model was fine-tuned on OpenAI's servers for 2 epochs, with a batch size of 32, a learning rate multiplier of 0.2, and a weight of 0.1 for loss on the prompt tokens. The finetuning took 3 hours total and cost $565. Decoding on 9,648 test set examples was performed using nucleus sampling (Holtzman et al., 2019) with \\\\( p = 0.25 \\\\). Some test set examples exceeded davinci's input limits. We performed a small-scale qualitative validation experiment on different values of \\\\( p \\\\) to determine this hyperparameter.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 6: Distribution of BLEU scores for the HUMAN and GTr translations.\\nFigure 7: Distribution of BLEURT scores for the HUMAN and GTr translations.\\nFigure 8: Distribution of BLON DE scores for the HUMAN and GTr translations.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 15, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Title                    | Author              | Gender | Source | Pub Year | # Trans |\\n|-------------------------|---------------------|--------|--------|----------|---------|\\n| A Confession            | Leo Tolstoy         | M      | test   | 1882     | 2       |\\n| Botchan                 | Natsume Soseki      | M      | test   | 1906     | 2       |\\n| Doctor Glass            | Hjalmar Soderberg   | M      | test   | 1905     | 2       |\\n| Dom Casmurro            | Machado De Assis    | M      | test   | 1899     | 2       |\\n| The Castle              | Franz Kafka         | M      | test   | 1924     | 4       |\\n| Chaka                   | Thomas Mofolo       | M      | test   | 1948     | 2       |\\n| Envy                    | Yury Olesha         | M      | test   | 1927     | 2       |\\n| Fairytales Part 1       | Da Hans Christian Andersen | M | test | 1875 | 2-3 |\\n| Gora                    | Rabindranath Tagore | M      | test   | 1941     | 2       |\\n| Journey By Moonlight    | Antal Szerb         | M      | test   | 1937     | 2       |\\n| Kokoro                  | Natsume Soseki      | M      | test   | 1914     | 2       |\\n| Romance Of The Three Kingdoms 1 | Luo Guanzhong    | M | test | 1399 | 2 |\\n| Romance Of The Three Kingdoms 2 | Luo Guanzhong    | M | test | 1399 | 2 |\\n| The Adventures Of Captain Hatteras | Jules Verne   | M | test | 1866 | 2 |\\n| The Gentleman From San Francisco | Ivan Bunin | M | test | 1915 | 3 |\\n| The Little Prince       | Antoine De Saint-Exupery | M | test | 1943 | 2 |\\n| The Magic Mountain      | Thomas Mann         | M      | test   | 1924     | 2       |\\n| The Trial               | Franz Kafka         | M      | test   | 1925     | 4       |\\n| War With The Newts      | Karel Capek         | M      | test   | 1936     | 2       |\\n| We                      | Yevgeny Zamyatin    | M      | test   | 1920     | 5       |\\n| The Sorrows of Young Werther    | Johann Wolfgang Von Goethe | M | test | 1774 | 2 |\\n| A Hero Of Our Time      | Mikhail Lermontov   | M      | train  | 1840     | 2       |\\n| A Raw Youth             | Fyodor Dostoevsky   | M      | train  | 1875     | 2       |\\n| Against The Grain       | Joris Karl Huysmans | M      | train  | 1884     | 2       |\\n| Amerika                 | Franz Kafka         | M      | train  | 1927     | 2       |\\n| Anna Karenina           | Leo Tolstoy         | M      | train  | 1878     | 2       |\\n| Around The World In Eighty Days | Jules Verne   | M | train | 1873 | 2 |\\n| Beware Of Pity          | Stefan Zweig         | M      | train  | 1939     | 2       |\\n| Brothers Karamazov      | Fyodor Dostoevsky   | M      | train  | 1879     | 3       |\\n| Buddenbrooks            | Thomas Mann         | M      | train  | 1901     | 2       |\\n| Call To Arms            | Lu Xun              | M      | train  | 1923     | 2       |\\n| Crime And Punishment    | Fyodor Dostoevsky   | M      | train  | 1866     | 3       |\\n| Dead Souls              | Nikolai Gogol       | M      | train  | 1842     | 4       |\\n| Death In Venice         | Thomas Mann         | M      | train  | 1912     | 3       |\\n| Demons                  | Fyodor Dostoevsky   | M      | train  | 1871     | 2       |\\n| Don Quixote             | Miguel De Cervantes | M      | train  | 1605     | 2       |\\n| Elective Affinities     | Johann Wolfgang Von Goethe | M | train | 1809 | 2 |\\n| Fairytales Part 2       | Da Hans Christian Andersen | M | train | 1875 | 2-3 |\\n| Fathers And Sons        | Ivan Turgenev       | M      | train  | 1862     | 3       |\\n| Gargantua And Pantagruel| Fran\u00e7ois Rabelais    | M      | train  | 1532     | 2       |\\n| Germinal                | Emile Zola          | M      | train  | 1885     | 2       |\\n| Heidi                   | Johanna Spyri       | F      | train  | 1881     | 3       |\\n| Hesitation              | Lu Xun              | M      | train  | 1926     | 2       |\\n| Home Of The Gentry      | Ivan Turgenev       | M      | train  | 1859     | 2       |\\n| In A Grove              | Ryunosuke Akutagawa | M      | train  | 1922     | 2       |\\n| In The Shadow Of Young Girls In Flower | Marcel Proust   | M | train | 1918 | 2 |\\n| Jacques The Fatalist    | Denis Diderot       | M      | train  | 1796     | 2       |\\n| Kallocain               | Karin Boye          | F      | train  | 1940     | 2       |\\n| Kappa                   | Ryunosuke Akutagawa | M      | train  | 1927     | 2       |\\n| Kristin Lavransdatter 1 The Wreath | Sigrid Undset   | F | train | 1920 | 2 |\\n| Kristin Lavransdatter 2 The Wife | Sigrid Undset    | F | train | 1920 | 2 |\\n| Lassommoir              | Emile Zola          | M      | train  | 1877     | 2       |\\n| Les Miserables          | Victor Hugo         | M      | train  | 1862     | 3       |\\n| Manon Lescaut           | Antoine Fran\u00e7ois Prevost | M | train | 1731 | 2 |\\n| Nana                    | Emile Zola          | M      | train  | 1880     | 3       |\\n| No Longer Human         | Osamu Dazai         | M      | train  | 1948     | 2       |\\n| Notes From Underground  | Fyodor Dostoevsky   | M      | train  | 1864     | 3       |\"}"}
{"id": "emnlp-2022-main-672", "page_num": 16, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Title                  | Author               | Gender | Split | Source Lang | Pub Year | # Trans |\\n|------------------------|----------------------|--------|-------|-------------|----------|---------|\\n| Oblomov                | Ivan Goncharov       | M      | train | ru          | 1859     | 3       |\\n| Petersburg             | Andrei Bely          | M      | train | ru          | 1913     | 3       |\\n| Pinocchio              | Carlo Collodi        | M      | train | it          | 1883     | 2       |\\n| Poor Folk              | Fyodor Dostoevsky    | M      | train | ru          | 1846     | 3       |\\n| Rashomon               | Ryunosuke Akutagawa  | M      | train | ja          | 1915     | 3       |\\n| Song Of The Little Road| Bibhutibhushan Bandy| M      | train | bn          | 1950     | 2       |\\n| Steppenwolf            | Hermann Hesse        | M      | train | de          | 1927     | 2       |\\n| Strange Tales From A Chinese Studio | Pu Songling | M | train | zh | 1740 | 2 |\\n| Swanns Way             | Marcel Proust        | M      | train | fr          | 1913     | 2       |\\n| The Blind Owl          | Sadegh Hedayat       | M      | train | fa          | 1937     | 2       |\\n| The Book Of Disquietude| Fernando Pessoa      | M      | train | pt          | 1982     | 2       |\\n| The Count Of Monte Cristo | Alexandre Dumas    | M      | train | fr          | 1844     | 2       |\\n| The Dancing Girl Of Izu| Yasunari Kawabata    | M      | train | ja          | 1926     | 2       |\\n| The Death Of Ivan Ilyich| Leo Tolstoy         | M      | train | ru          | 1886     | 3       |\\n| The Debacle            | Emile Zola           | M      | train | fr          | 1892     | 2       |\\n| The Diary Of A Young Girl | Anne Frank       | F      | train | nl          | 1947     | 2       |\\n| The Fortune Of The Rougons | Emile Zola        | M      | train | fr          | 1871     | 2       |\\n| The Good Soldier Schweik 1 Behind The Lines | Jaroslav Hasek | M | train | cs | 1921 | 2 |\\n| The Good Soldier Schweik 2 At The Front | Jaroslav Hasek | M | train | cs | 1922 | 2 |\\n| The Good Soldier Schweik 3 The Glorious Licking | Jaroslav Hasek | M | train | cs | 1922 | 2 |\\n| The Hunchback Of Notre Dame | Victor Hugo      | M      | train | fr          | 1833     | 2       |\\n| The Journey To The West | Wu Cheng-En         | M      | train | zh          | 1592     | 4       |\\n| The Kill               | Emile Zola           | M      | train | fr          | 1871     | 2       |\\n| The Kreutzer Sonata    | Leo Tolstoy          | M      | train | ru          | 1889     | 2       |\\n| The Manuscript Found In Saragossa | Jan Potocki | M | train | pl | 1805 | 2 |\\n| The Master And Margarita| Mikhail Bulgakov    | M      | train | ru          | 1966     | 2       |\\n| The Mate Mattia Pascal | Luigi Pirandello     | M      | train | it          | 1904     | 2       |\\n| The Metamorphosis      | Franz Kafka          | M      | train | de          | 1915     | 3       |\\n| The Notebooks Of Malte Laurids Brigge | Rainer Maria Rilke | M | train | de | 1910 | 3 |\\n| The Nun                | Denis Diderot        | M      | train | fr          | 1780     | 2       |\\n| The Phantom Of The Opera | Gaston Leroux     | M      | train | fr          | 1909     | 3       |\\n| The Posthumous Memoirs Of Bras Cubas | Joaquim Maria Machado De Assis | M | train | pt | 1881 | 2 |\\n| The Queen Of Spades    | Alexander Pushkin    | M      | train | ru          | 1834     | 2       |\\n| The Red And The Black  | Stendhal             | M      | train | fr          | 1830     | 2       |\\n| The Story Of Gosta Berling | Selma Agerlof     | F      | train | sv          | 1891     | 2       |\\n| The Three Musketeers   | Alexandre Dumas      | M      | train | fr          | 1844     | 2       |\\n| Twenty Thousand Leagues Under The Sea | Jules Verne | M | train | fr | 1869 | 3 |\\n| Venus In Furs          | Leopold von Sacher-Masoch | M | train | de | 1870 | 2 |\\n| War And Peace          | Leo Tolstoy          | M      | train | ru          | 1865     | 2       |\\n| Wild Geese             | Mori Ogai            | M      | train | ja          | 1911     | 2       |\\n| Voyage Around My Room  | Xavier De Maistre    | M      | train | fr          | 1794     | 2       |\\n\\nTable 5: A full list of the literary texts from which the source paragraphs in PAR3 are sampled with author name, author gender, publication year, source language, and test/train/val split designations.\\n\\nTable 6: The preference of translators for all three evaluations: (1) HUM vs GTr, (2) GPT-3 vs GTr, (3) HUM vs GPT-3, divided by the language of translator. The translators unanimously preferred (1) HUM, (2) GPT-3, and (3) HUM. The significance is reported for the following levels *p<.05, **p<.01, ***p<.001 (binomial test).\"}"}
{"id": "emnlp-2022-main-672", "page_num": 17, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"First put me in a coffin and bury me in the ground, then give me my daughter.\\n\\nPut me in the grave first and bury me in the ground, then give my daughter away.\\n\\nI have only one thing left: to tell you everything, my unknown readers (now you are so for me the same roads, and close, and inaccessible - as he was at that moment).\\n\\nI have only one thing left: to tell you everything, my unknown readers (now you are as dear to me, as close and as unattainable as he was at that moment).\\n\\nI tasted in his arms the delights of paradise, which produced those torments of hell with which you see me devoured; (...).\\n\\nI tasted the delights of paradise in her arms, which produced the torments of hell that you see me devoured by.\\n\\nIt calmed her down and her heart stopped beating.\\n\\nThis calmed me down, my heart stopped pounding.\\n\\n(...) by Lebedev's nephew, known to readers, and secondly, by Ippolit. Hippolyte was a very young man, about seventeen, maybe eighteen, with an intelligent, but constantly irritated expression on his face, on which illness left terrible marks.\\n\\n(...) by Lebedev's nephew, a young man known to the reader, and secondly, by Ippolit. Ippolit was a very young man, about seventeen, or even eighteen, with an intelligent but constantly irritated expression on his face, on which illness had left terrible traces.\\n\\nTo amuse himself, he employed himself at home as a laborer, and he even tried to paint the attic with a residue of color that the painters had left behind.\\n\\nTo distract himself, he did odd jobs around the house, and even tried to paint the attic with some paint that the painters had left over.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 18, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"| Technique         | Description                                                                 | Example                                                                                                                                                                                                 | Translated Example                                                                                                                                                                                                                                                                                                                                                       |\\n|------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| Borrowing        | Words or phrases left untranslated to introduce the flavor of source language culture. | *SRC*: \u2013 \u041f\u0438\u0432\u043e \u0435\u0441\u0442\u044c? \u2013 \u0441\u0438\u043f\u043b\u044b\u043c \u0433\u043e\u043b\u043e\u0441\u043e\u043c \u043e\u0441\u0432\u0435\u0434\u043e\u043c\u0438\u043b\u0441\u044f \u0411\u0435\u0437\u0434\u043e\u043c\u043d\u044b\u0439. *(ru)*  \\n*HUM*: \u201cGot any beer?\u201d inquired Bezdomny in a hoarse voice. *(from Master and Margarita)*  \\n*GTr*: - Do you have beer? Homeless inquired in a hoarse voice. *(from Master and Margarita)* | *SRC*: \u2013 \u041f\u0438\u0432\u043e \u0435\u0441\u0442\u044c? \u2013 \u0441\u0438\u043f\u043b\u044b\u043c \u0433\u043e\u043b\u043e\u0441\u043e\u043c \u043e\u0441\u0432\u0435\u0434\u043e\u043c\u0438\u043b\u0441\u044f \u0411\u0435\u0437\u0434\u043e\u043c\u043d\u044b\u0439. *(ru)*  \\n*HUM*: \u201cGot any beer?\u201d inquired Bezdomny in a hoarse voice. *(from Master and Margarita)*  \\n*GTr*: - Do you have beer? Homeless inquired in a hoarse voice. *(from Master and Margarita)* |\\n| EstablishedEquivalence | An equivalent of the source language using different stylistic and structural methods. | *SRC*: \u4e2d\u5b66\u3068\u5e2b\u7bc4\u3068\u306f\u3069\u3053\u306e\u770c\u4e0b\u3067\u3082\u72ac\u3068\u733f\u306e\u3088\u3046\u306b\u4ef2\u304c\u308f\u308b\u3044\u305d\u3046\u3060\u3002 *(ja)*  \\n*HUM*: The middle school and the normal, I understood, are as much friendly as dogs and monkeys. *(from Botchan)*  \\n*GTr*: It seems that junior high school and instructors get along with each other like dogs and monkeys in any prefecture. *(from Botchan)* | *SRC*: \u4e2d\u5b66\u3068\u5e2b\u7bc4\u3068\u306f\u3069\u3053\u306e\u770c\u4e0b\u3067\u3082\u72ac\u3068\u733f\u306e\u3088\u3046\u306b\u4ef2\u304c\u308f\u308b\u3044\u305d\u3046\u3060\u3002 *(ja)*  \\n*HUM*: The middle school and the normal, I understood, are as much friendly as dogs and monkeys. *(from Botchan)*  \\n*GTr*: It seems that junior high school and instructors get along with each other like dogs and monkeys in any prefecture. *(from Botchan)* |\\n| Transposition    | A change in grammatical category, such like word class, number, tense, etc. | *SRC*: Et il reprit son carnet, biffant avec le plus grand soin les sommes qu'il venait de payer. *(fr)*  \\n*HUM*: And he took up his notebook, carefully crossing out the amounts he had just paid. *(from The Count of Monte Cristo)*  \\n*GTr*: And he went back to his notebook, crossing out with the greatest care the sums he had just paid. *(from The Count of Monte Cristo)* | *SRC*: Et il reprit son carnet, biffant avec le plus grand soin les sommes qu'il venait de payer. *(fr)*  \\n*HUM*: And he took up his notebook, carefully crossing out the amounts he had just paid. *(from The Count of Monte Cristo)*  \\n*GTr*: And he went back to his notebook, crossing out with the greatest care the sums he had just paid. *(from The Count of Monte Cristo)* |\\n| Modulation       | A shift in point of view, focus, cognitive category.                     | *SRC*: Bei der Schnelligkeit ihres Wesens war ihr nicht leicht zu widersprechen. *(de)*  \\n*HUM*: Being so quick in her manner she was hard to contradict. *(from Elective Affinities)*  \\n*GTr*: Given the quickness of her nature, it was not easy to contradict her. *(from Elective Affinities)* | *SRC*: Bei der Schnelligkeit ihres Wesens war ihr nicht leicht zu widersprechen. *(de)*  \\n*HUM*: Being so quick in her manner she was hard to contradict. *(from Elective Affinities)*  \\n*GTr*: Given the quickness of her nature, it was not easy to contradict her. *(from Elective Affinities)* |\\n| Addition         | An addition of a new piece of information, which is not easily inferable from the source language. | *SRC*: \u6e05\u304c\u7269\u3092\u304f\u308c\u308b\u6642\u306b\u306f\u5fc5\u305a\u304a\u3084\u3058\u3082\u5144\u3082\u5c45\u306a\u3044\u6642\u306b\u9650\u308b\u3002 *(ja)*  \\n*HUM*: When Kiyo gave me these presents she would always be careful to choose times when the old man and my brother were not around. *(from Botchan)*  \\n*GTr*: When Qing gives me something, I always do it only when my father and brother are not there. *(from Botchan)* | *SRC*: \u6e05\u304c\u7269\u3092\u304f\u308c\u308b\u6642\u306b\u306f\u5fc5\u305a\u304a\u3084\u3058\u3082\u5144\u3082\u5c45\u306a\u3044\u6642\u306b\u9650\u308b\u3002 *(ja)*  \\n*HUM*: When Kiyo gave me these presents she would always be careful to choose times when the old man and my brother were not around. *(from Botchan)*  \\n*GTr*: When Qing gives me something, I always do it only when my father and brother are not there. *(from Botchan)* |\\n| Omission         | An omission of information present in the source language to the extent that it is not even easily inferable in the target language. | *SRC*: \u5065\u5168\u306a\u308b\u7537\u5973\u306e\u6cb3\u7ae5\u3088\u3002 *(ja)*  \\n*HUM*: IF YOU ARE HEALTHY___  \\n*GTr*: Healthy male and female kappa *(from Kappa)* | *SRC*: \u5065\u5168\u306a\u308b\u7537\u5973\u306e\u6cb3\u7ae5\u3088\u3002 *(ja)*  \\n*HUM*: IF YOU ARE HEALTHY___  \\n*GTr*: Healthy male and female kappa *(from Kappa)* |\\n| Generalization   | A word or phrase translated into a more general one (hypernym).           | *SRC*: \u59b9\u5b50\u306f\u88ab\u5927\u54e5\u306b\u98df\u3079\u3089\u308c\u3001\u6bcd\u77e5\u9053\u3001\u6211\u53ef\u4e0d\u800c\u77e5\u4e4b\u3002 *(zh)*  \\n*HUM*: My sister was eaten by my brother, but I don't know whether Mother realized it or not. *(from Call to Arms)*  \\n*GTr*: The sister was eaten by the elder brother, and whether the mother knew it or not, I don't know. *(from Call to Arms)* | *SRC*: \u59b9\u5b50\u306f\u88ab\u5927\u54e5\u306b\u98df\u3079\u3089\u308c\u3001\u6bcd\u77e5\u9053\u3001\u6211\u53ef\u4e0d\u800c\u77e5\u4e4b\u3002 *(zh)*  \\n*HUM*: My sister was eaten by my brother, but I don't know whether Mother realized it or not. *(from Call to Arms)*  \\n*GTr*: The sister was eaten by the elder brother, and whether the mother knew it or not, I don't know. *(from Call to Arms)* |\\n| Particularization| A word or phrase is translated into a more precise or concrete term (hyponym). | *SRC*: (...) Andrea saisit la main du comte, la serra, sauta dans son pha\u00e9ton et disparut. *(fr)*  \\n*HUM*: (...) Andrea seized his hand, pressed it, leapt into his phaeton and rode off. *(from The Count of Monte Cristo)*  \\n*GTr*: (...) Andrea seized the count's hand, squeezed it, jumped into his phaeton and disappeared. *(from The Count of Monte Cristo)* | *SRC*: (...) Andrea saisit la main du comte, la serra, sauta dans son pha\u00e9ton et disparut. *(fr)*  \\n*HUM*: (...) Andrea seized his hand, pressed it, leapt into his phaeton and rode off. *(from The Count of Monte Cristo)*  \\n*GTr*: (...) Andrea seized the count's hand, squeezed it, jumped into his phaeton and disappeared. *(from The Count of Monte Cristo)* |\\n| Adaptation       | Content is adapted to the target culture. It may include adapting the portrayed situation so that it is appropriate for the target culture (cultural substitution). | *SRC*: \u7236\u306f\u3053\u306e\u524d\u306e\u51ac\u306b\u5e30\u3063\u3066\u6765\u305f\u6642\u307b\u3069\u5c06\u68cb\u3092\u5dee\u3057\u305f\u304c\u3089\u306a\u304f\u306a\u3063\u305f\u3002 *(ja)*  \\n*HUM*: My father did not show as much interest in chess as he had done the previous winter. *(from Kokoro)*  \\n*GTr*: My dad was less reluctant to play shogi than when he came back last winter. *(from Kokoro)* | *SRC*: \u7236\u306f\u3053\u306e\u524d\u306e\u51ac\u306b\u5e30\u3063\u3066\u6765\u305f\u6642\u307b\u3069\u5c06\u68cb\u3092\u5dee\u3057\u305f\u304c\u3089\u306a\u304f\u306a\u3063\u305f\u3002 *(ja)*  \\n*HUM*: My father did not show as much interest in chess as he had done the previous winter. *(from Kokoro)*  \\n*GTr*: My dad was less reluctant to play shogi than when he came back last winter. *(from Kokoro)* |\\n| Description      | A term or expression from the source language is described in text in the translation. | *SRC*: \u4e00\u90e8\u3092\u3055\u3063\u3055\u3068\u6d77\u304b\u3089\u4e0a\u304c\u3063\u3066\u304d\u3066\u3001\u3044\u3064\u3082\u5834\u6240\u306b\u7a81\u304d\u51fa\u3057\u3066\u3057\u307e\u3046\u6d74\u8863\u3092\u7740\u3088\u3046\u3068\u3059\u308b\u3068\u3001\u3069\u3046\u3057\u305f\u8a33\u304b\u3001\u305d\u306e\u6d74\u8863\u306b\u7802\u304c\u3044\u3063\u3071\u3044\u7740\u3044\u3066\u3044\u305f\u3002 *(ja)*  \\n*HUM*: One day, however, after his usual swim, Sensei was about to put on his summer dress which he had left on the bench, when he noticed that the dress, for some reason, was covered with sand. *(from Kokoro)*  \\n*GTr*: At one point, as usual, the teacher came up from the sea and tried to put on the yukata that had been taken off and thrown away at the usual place, but for some reason, the yukata was full of sand. *(from Kokoro)* | *SRC*: \u4e00\u90e8\u3092\u3055\u3063\u3055\u3068\u6d77\u304b\u3089\u4e0a\u304c\u3063\u3066\u304d\u3066\u3001\u3044\u3064\u3082\u5834\u6240\u306b\u7a81\u304d\u51fa\u3057\u3066\u3057\u307e\u3046\u6d74\u8863\u3092\u7740\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u3001\u3069\u3046\u3057\u305f\u8a33\u304b\u3001\u305d\u306e\u6d74\u8863\u306b\u7802\u304c\u3044\u3063\u3071\u3044\u7740\u3044\u3066\u3044\u305f\u3002 *(ja)*  \\n*HUM*: One day, however, after his usual swim, Sensei was about to put on his summer dress which he had left on the bench, when he noticed that the dress, for some reason, was covered with sand. *(from Kokoro)*  \\n*GTr*: At one point, as usual, the teacher came up from the sea and tried to put on the yukata that had been taken off and thrown away at the usual place, but for some reason, the yukata was full of sand. *(from Kokoro)* |\\n| Sentence Diffus-ion | The source sentence is being translated into two or more sentences in the translation. | *SRC*: Prodal jsem t\u02c7e, kamar\u00e1de, hanebn\u02c7e prodal. *(cs)*  \\n*HUM*: I've sold you, buddy. Shamefully sold you. *(from The Good Soldier Schweik)*  \\n*GTr*: I sold you, my friend, I shamefully sold you. *(from The Good Soldier Schweik)* | *SRC*: Prodal jsem t\u02c7e, kamar\u00e1de, hanebn\u02c7e prodal. *(cs)*  \\n*HUM*: I've sold you, buddy. Shamefully sold you. *(from The Good Soldier Schweik)*  \\n*GTr*: I sold you, my friend, I shamefully sold you. *(from The Good Soldier Schweik)* |\\n| Sentence Merging | Two or more sentences from the source language are combined together into one sentence in the translation. | *SRC*: \u4e09\u5e74\u524d\u306e\u590f\u306e\u3053\u3068\u3067\u3059\u3002\u50d5\u306f\u4eba\u4e26\u307f\u306b\u30ea\u30e5\u30c3\u30af\u30fb\u30b5\u30c3\u30af\u3092\u80cc\u8ca0\u3044\u3001\u3042\u306e\u4e0a\u9ad8\u5730\u306e\u6e29\u6cc9\u5bbf\u304b\u3089\u7a42\u9ad8\u5c71\u3078\u767b\u308d\u3046\u3068\u3057\u307e\u3057\u305f\u3002 *(ja)*  \\n*HUM*: One summer morning three years ago, I left an inn at Kamik\u00afochi hot spring to climb Mt. Hodaka, with a rucksack on my back. *(from Kappa)*  \\n*GTr*: It was the summer three years ago. I carried a rucksack on my back like a person and tried to climb Mt. Hotaka from that hot spring inn in Kamikochi. *(from Kappa)* | *SRC*: \u4e09\u5e74\u524d\u306e\u590f\u306e\u3053\u3068\u3067\u3059\u3002\u50d5\u306f\u4eba\u4e26\u307f\u306b\u30ea\u30e5\u30c3\u30af\u30fb\u30b5\u30c3\u30af\u3092\u80cc\u8ca0\u3044\u3001\u3042\u306e\u4e0a\u9ad8\u5730\u306e\u6e29\u6cc9\u5bbf\u304b\u3089\u7a42\u9ad8\u5c71\u3078\u767b\u308d\u3046\u3068\u3057\u307e\u3057\u305f\u3002 *(ja)*  \\n*HUM*: One summer morning three years ago, I left an inn at Kamik\u00afochi hot spring to climb Mt. Hodaka, with a rucksack on my back. *(from Kappa)*  \\n*GTr*: It was the summer three years ago. I carried a rucksack on my back like a person and tried to climb Mt. Hotaka from that hot spring inn in Kamikochi. *(from Kappa)* |\\n| Reordering       | Information is moved from one place in the paragraph to another for better coherence in the target language. | *SRC*: \u79c1\u304c\u5148\u751f\u3068\u77e5\u308a\u5408\u3063\u305f\u306e\u306f\u938c\u5009\u3067\u3042\u308b\u3002 *(ja)*  \\n*HUM*: It was at Kamakura, during the summer holidays, that I first met Sensei. *(from Kokoro)*  \\n*GTr*: It was Kamakura that I got to know the teacher. *(from Kokoro)* | *SRC*: \u79c1\u304c\u5148\u751f\u3068\u77e5\u308a\u5408\u3063\u305f\u306e\u306f\u938c\u5009\u3067\u3042\u308b\u3002 *(ja)*  \\n*HUM*: It was at Kamakura, during the summer holidays, that I first met Sensei. *(from Kokoro)*  \\n*GTr*: It was Kamakura that I got to know the teacher. *(from Kokoro)* |\"}"}
{"id": "emnlp-2022-main-672", "page_num": 19, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"Table 9: The percentage of cases in which the automatic MT metric ranks the human, GPT-3, or Google translations above the other two. *Note: There are 9,648 unique source paragraphs that were input to the post-editing model, but we exclude ties in the calculation of Win %. The total number of ties was 340, 94, and 33, for **BLEURT**, **BLEU**, and **BLONDE** respectively.\\n\\n| Source Lang | BLEU | BLEURT | BLONDE | Win %* |\\n|-------------|------|--------|--------|--------|\\n| fr          | 20.0 | 27.2   | 26.1   | 0.641  |\\n|             |      | 20.0   | 27.2   | 49.5%  |\\n|             |      |        |        | 22.0%  |\\n| ru          | 46.0 | 38.2   | 36.8   | 0.636  |\\n|             |      | 20.0   | 27.2   | 52.1%  |\\n|             |      |        |        | 17.0%  |\\n| de          | 19.8 | 22.2   | 19.0   | 0.525  |\\n|             |      | 20.0   | 27.2   | 40.5%  |\\n|             |      |        |        | 29.0%  |\\n| ja          | 11.4 | 9.5    | 6.9    | 0.545  |\\n|             |      | 20.0   | 27.2   | 54.5%  |\\n|             |      |        |        | 29.0%  |\\n| zh          | 2.4  | 4.6    | 3.6    | 0.324  |\\n|             |      | 20.0   | 27.2   | 34.61% |\\n|             |      |        |        | 65.39% |\\n| cs          | 19.4 | 22.7   | 19.1   | 0.625  |\\n|             |      | 20.0   | 27.2   | 45.44% |\\n|             |      |        |        | 54.56% |\\n| pt          | 28.9 | 32.4   | 25.3   | 0.643  |\\n|             |      | 20.0   | 27.2   | 34.61% |\\n|             |      |        |        | 65.39% |\\n| sv          | 28.1 | 33.8   | 29.2   | 0.649  |\\n|             |      | 20.0   | 27.2   | 45.44% |\\n|             |      |        |        | 54.56% |\\n| hu          | 22.3 | 25.1   | 16.9   | 0.613  |\\n|             |      | 20.0   | 27.2   | 45.44% |\\n|             |      |        |        | 54.56% |\\n\\nTable 10: Results of **PRISM**, **PRISM-QE** and **M OVERS CORE** on **P AR3**. Higher score is better for all metrics. Scores were calculated on the entirety of version one of the **P AR3** dataset across its 107,467 unique source paragraphs. Again, we exclude ties from the calculation of Human Win %. The total number of ties was 80, 82, and 100 for **PRISM**, **PRISM-QE** (Thompson and Post, 2020), and **M OVERS CORE** (Zhao et al., 2019), respectively.\\n\\n| Metrics     | Kendall Tau | BLEU | BLEURT | BLONDE |\\n|-------------|-------------|------|--------|--------|\\n|             | 0.209***    |      |        |        |\\n| BLEU        |             |      |        |        |\\n| BLEURT      | 0.262***    |      |        |        |\\n| BLONDE      | 0.120***    |      |        |        |\\n\\nTable 11: Metrics correlation with human evaluation. Significant correlation at ***p<.001\"}"}
{"id": "emnlp-2022-main-672", "page_num": 20, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 12: Results of the performance of automatic metrics on the 150 paragraphs used in human evaluation.\\n\\n(*The common interpretation of the effect size is the following: 0.10-<0.30 (small), 0.30-<0.50 (moderate), >=0.50 (large))\\n\\nTable 13: An example SRC from Thomas Mann's The Magic Mountain that was administered as an A/B test with its corresponding GTr and HUM. Though all monolingual raters chose HUM, the translator chose GTr.\\n\\nTable 14: An example SRC from Fyodor Dostoevsky's The Idiot that was administered as an A/B test with its corresponding GTr and HUM. Though all monolingual raters chose HUM, the translator chose GTr.\"}"}
{"id": "emnlp-2022-main-672", "page_num": 21, "content": "{\"primary_language\":\"ru\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"\u041a\u043d\u044f\u0437\u044c, \u043e\u0434\u043d\u0430\u043a\u043e \u0436\u0435, \u0441\u043b\u044b\u0448\u0430\u043b, \u043a\u0430\u043a \u0435\u0433\u043e \u043d\u0430\u0437\u0432\u0430\u043b\u0438 \u0438\u0434\u0438\u043e\u0442\u043e\u043c, \u0438 \u0432\u0437\u0434\u0440\u043e\u0433\u043d\u0443\u043b, \u043d\u043e \u043d\u0435 \u043e\u0442\u0442\u043e\u0433\u043e, \u0447\u0442\u043e \u0435\u0433\u043e \u043d\u0430\u0437\u0432\u0430\u043b\u0438 \u0438\u0434\u0438\u043e\u0442\u043e\u043c. \u00ab\u0418\u0434\u0438\u043e\u0442\u0430\u00bb \u043e\u043d \u0442\u043e\u0442\u0447\u0430\u0441 \u0437\u0430\u0431\u044b\u043b. \u041d\u043e \u0432 \u0442\u043e\u043b\u043f\u0435, \u043d\u0435\u0434\u0430\u043b\u0435\u043a\u043e \u043e\u0442 \u0442\u043e\u0433\u043e \u043c\u0435\u0441\u0442\u0430, \u0433\u0434\u0435 \u043e\u043d \u0441\u0438\u0434\u0435\u043b, \u043e\u0442\u043a\u0443\u0434\u0430-\u0442\u043e \u0441\u0431\u043e\u043a\u0443 \u2014 \u043e\u043d \u0431\u044b \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u0443\u043a\u0430\u0437\u0430\u043b, \u0432 \u043a\u0430\u043a\u043e\u043c \u0438\u043c\u0435\u043d\u043d\u043e \u043c\u0435\u0441\u0442\u0435 \u0438 \u0432 \u043a\u0430\u043a\u043e\u0439 \u0442\u043e\u0447\u043a\u0435, \u2014 \u043c\u0435\u043b\u044c\u043a\u043d\u0443\u043b\u043e \u043e\u0434\u043d\u043e \u043b\u0438\u0446\u043e, \u0431\u043b\u0435\u0434\u043d\u043e\u0435 \u043b\u0438\u0446\u043e, \u0441 \u043a\u0443\u0440\u0447\u0430\u0432\u044b\u043c\u0438 \u0442\u0435\u043c\u043d\u044b\u043c\u0438 \u0432\u043e\u043b\u043e\u0441\u0430\u043c\u0438, \u0441 \u0437\u043d\u0430\u043a\u043e\u043c\u044b\u043c\u0438, \u043e\u0447\u0435\u043d\u044c \u0437\u043d\u0430\u043a\u043e\u043c\u044b\u043c\u0438 \u0443\u043b\u044b\u0431\u043a\u043e\u0439 \u0438 \u0432\u0437\u0433\u043b\u044f\u0434\u043e\u043c, \u2014 \u043c\u0435\u043b\u044c\u043a\u043d\u0443\u043b\u043e \u0438 \u0438\u0441\u0447\u0435\u0437\u043b\u043e. \u041e\u0447\u0435\u043d\u044c \u043c\u043e\u0433\u043b\u043e \u0431\u044b\u0442\u044c, \u0447\u0442\u043e \u044d\u0442\u043e \u0442\u043e\u043b\u044c\u043a\u043e \u0432\u043e\u043e\u0431\u0440\u0430\u0437\u0438\u043b\u043e\u0441\u044c \u0435\u043c\u0443; \u043e\u0442 \u0432\u0441\u0435\u0433\u043e \u0432\u0438\u0434\u0435\u043d\u0438\u044f \u043e\u0441\u0442\u0430\u043b\u0438\u0441\u044c \u0443 \u043d\u0435\u0433\u043e \u0432 \u0432\u043f\u0435\u0447\u0430\u0442\u043b\u0435\u043d\u0438\u0438 \u043a\u0440\u0438\u0432\u0430\u044f \u0443\u043b\u044b\u0431\u043a\u0430, \u0433\u043b\u0430\u0437\u0430 \u0438 \u0441\u0432\u0435\u0442\u043b\u043e-\u0437\u0435\u043b\u0435\u043d\u044b\u0439 \u0444\u0440\u0430\u043d\u0442\u043e\u0432\u0441\u043a\u043e\u0439 \u0448\u0435\u0439\u043d\u044b\u0439 \u0433\u0430\u043b\u0441\u0442\u0443\u043a, \u0431\u044b\u0432\u0448\u0438\u0439 \u043d\u0430 \u043f\u0440\u043e\u043c\u0435\u043b\u044c\u043a\u043d\u0443\u0432\u0448\u0435\u043c \u0433\u043e\u0441\u043f\u043e\u0434\u0438\u043d\u0435. \u0418\u0441\u0447\u0435\u0437 \u043b\u0438 \u044d\u0442\u043e\u0442 \u0433\u043e\u0441\u043f\u043e\u0434\u0438\u043d \u0432 \u0442\u043e\u043b\u043f\u0435 \u0438\u043b\u0438 \u043f\u0440\u043e\u0448\u043c\u044b\u0433\u043d\u0443\u043b \u0432 \u0432\u043e\u043a\u0437\u0430\u043b, \u043a\u043d\u044f\u0437\u044c \u0442\u043e\u0436\u0435 \u043d\u0435 \u043c\u043e\u0433 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c.\\n\\nTable 15: An example from Fyodor Dostoevsky's The Idiot that was administered as an A/B test with its corresponding GTr and GPT-3. The translator preferred GPT-3.\"}"}
