{"id": "lrec-2022-1-365", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"The LTRC Hindi-Telugu Parallel Corpus\\n\\nVandan Mujadia, Dipti Misra Sharma\\nMT-NLP Lab, LTRC, KCIS, IIIT-Hyderabad, India\\nvandan.mu@research., dipti@iiit.ac.in\\n\\nAbstract\\nWe present the Hindi-Telugu Parallel Corpus of different technical domains such as Natural Science, Computer Science, Law and Healthcare along with the General domain. The qualitative corpus consists of 700K parallel sentences of which 535K sentences were created using multiple methods such as extract, align and review of Hindi-Telugu corpora, end-to-end human translation, iterative back-translation driven post-editing and around 165K parallel sentences were collected from available sources in the public domain. We present the comparative assessment of created parallel corpora for representativeness and diversity. The corpus has been pre-processed for machine translation, and we trained a neural machine translation system using it and report state-of-the-art baseline results on the developed development set over multiple domains and on available benchmarks. With this, we define a new task on Domain Machine Translation for low resource language pairs such as Hindi and Telugu. The developed corpus (535K) is freely available for non-commercial research and to the best of our knowledge, this is the well curated, largest, publicly available domain parallel corpus for Hindi-Telugu.\\n\\nKeywords: Machine Translation, Domain Machine Translation, Parallel Corpora, Indian Languages, Hindi, Telugu\\n\\n1. Introduction\\nGenerally, in multilingual society such as India, people use one language for ethnic identity, another for business transactions, another for official dealings and yet another for entertainment, rituals and so on (Annamalai, 2001). The language used by a group (eg. Dakkhini, a variety of Hindi, spoken in the Deccan region of India) living in among another group (e.g. Telugu) is an illustrative case for linguistic convergence (Vasanta et al., 2010). According to the Census of India of 2011, Hindi is one of the major languages spoken primarily in the Indian subcontinent. It has around 528 million native speakers and around 700 million total speakers. It is the official language of many North and Central states in India and acts as lingua franca for many Indians. In contrast, Telugu, the largest member of the Dravidian language family, is the official language of the states of Telangana and Andhra Pradesh. It has 95 million native speakers in India and around the world. Hindi and Telugu both are part of 22 official languages recognized by India. For such a diverse group of language users, in order to have an appropriate communication or to provide educational content in multiple languages, such as Hindi and Telugu, the need for translation systems to translate content in the respective languages becomes essential.\\n\\nHence, there is immense potential for Hindi-Telugu machine translation and yet, the qualitative parallel corpora available between these two languages are limited and specially for the domains. The non-availability of domain parallel data is a major issue in the training of domain specific machine translation models i.e educational domain (technical domain) such as science. Therefore, our work is an effort where we create, align, collect quality parallel corpora for Hindi-Telugu for General (named for type of corpora such as news, blogs, etc) as well as Technical domains such as Natural science, computer science, Law and Healthcare and developed corpora (535K) will be freely available for non-commercial research to the community.\\n\\n2. Related Work\\nIn recent times, neural machine translation (NMT) shows high performance gain in terms of output fluency and translation quality, when large amounts of parallel data are available (Barrault et al., 2020). Unfortunately, for most language pairs, parallel data is either scarce or non-existent. When it comes to Indian languages, in recent times, the machine translation community has witnessed increasing interest. However, this demands availability of parallel corpora for these languages (Wang et al., 2021). In this regards, Multilingual Machine Translation shared task (WAT-2021 MultiIndicMT) (Nakazawa et al., 2021) compiled many existing parallel corpora involving Indian languages (10 Indian Languages, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil and Telugu) and English and placed them at one location. Earlier to this, The Indian government TDIL program and the Indian Language Corpora Initiative developed a parallel corpora for English and 16 Indian languages (Jha, 2010). (Mayer\"}"}
{"id": "lrec-2022-1-365", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"and Cysouw, 2014) and (Resnik et al., 1999) presented efforts to create a massively parallel Bible corpus with over 900 translations in more than 830 language varieties. The IITB English-Hindi parallel corpora was an effort (Kunchukuttan et al., 2017) where a compilation of English-Hindi parallel corpora available in the public domain were collected and made available for the research community. OdiEnCorp 2.0 (Parida et al., 2020), the parallel corpora between English and Odia was developed. (Philip et al., 2019) enhanced the IIT-B English-Hindi corpora with back-translation. (Siripragada et al., 2020) and (Haddow and Kirefu, 2020) compiled several multilingual Indian government websites such as PMIndia7, PIB8 and automatically aligned Indian languages with the English and released for the community. However most of these efforts were English and Indian languages centric and do not involve Indian to Indian language parallel corpora. To overcome this scarcity of sizable parallel data, as an alternative, quasi-parallel or comparable parallel training corpora provides an important resource for training machine translation systems for resource scared language pairs. Recently released, Samanantar (Ramesh et al., 2021), provides significantly large parallel corpora for Indic languages contains 49.7 million sentence pairs between English and 11 Indic languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil and Telugu). It was developed using web-crawled monolingual corpora, document OCR for extracting sentences from scanned documents, multilingual representation models for aligning sentences, and approximate nearest neighbour search for searching in a large collection of sentences. Further, they extract Indic to Indic language parallel corpora using English as the pivot language. The efforts were similar to (Schwenk et al., 2019) where multilingual sentence embeddings were used to automatically extract parallel sentences from the content of Wikipedia articles in 96 languages. Since such comparable corpora are not of as high quality as manually annotated parallel data, using them for training can have a negative effect (Dakwale and Monz, 2019) (Muischnek and M\u00fc\u00fcrisep, 2018) on the translation performance of an NMT model. To overcome the impact of noisy corpora, (Dakwale and Monz, 2019) proposed distillation as a remedy from the teacher network trained on the clean parallel corpora. Hence, development of human curated parallel corpora remains valuable resource for high quality machine translation.\\n\\n3. Methods for Parallel Corpora Creation\\n\\nIn general, well curated corpus construction is a difficult and laborious task. Usually, a corpus is developed according to specific objectives and purposes using several methods. The objective of a corpus construction would ask details such as kinds of domain involved, size of the corpora, and sources of corpora, etc. To answer this, as mentioned earlier, we aim to create quality machine translation parallel corpora involving Hindi-Telugu language pairs for general (named for type of corpora such as news, blogs, etc) as well as different technical domains such as Natural Science, Computer Science, Law and Healthcare. In our approach we decided to use several methods such as Collect, Clean and Review existing parallel corpora, Extracting and aligning available Hindi-Telugu corpora, end-to-end translation and in-house adaptive back-translation driven post-editing to create sizable parallel corpora for Hindi-Telugu. Each of these methods are described in the following subsections.\\n\\n3.1. Collect, Clean and Review Parallel Corpora from Existing Sources\\n\\nAs a part of our effort to Hindi-Telugu parallel data creation, we collected parallel data from different sources, accounted for 165K parallel sentences. The sources are from OPUS9 (Tiedemann, 2012) such as: bible-uedin, globalvoices, gnome, kde4, opensubtitles, tanzil, tatoeba, ubuntu, wikimedia. We also included ILCI (Jha, 2010) Hindi-Telugu parallel corpora after prepossessing, cleaning and thorough sampled human review. Apart from this, recently, Samanantar (Ramesh et al., 2021) released around 2425K Hindi-Telugu parallel sentence corpora by pivoting English language. We analyse some properties of this corpora and its impact on translation quality in comparative analysis and result section.\\n\\n3.2. Extract, Align and Review Hindi-Telugu data\\n\\nWe identified few data sources of the technical domain which provides maths, science, social science and environment content in Hindi and Telugu. Usually, these texts are aligned page by page and passage by passage across the languages. We extracted, cleaned the collected text, converted it to Unicode format for both languages by maintaining respective page number information. Then we semi-automatic aligned the extracted text at sentence level. Similarly NPTEL10 is the largest online repository in the world of courses in engineering, basic sciences, humanities and social sciences subjects. Some of these lecture texts are available in Hindi and Telugu as a translation from English. We collected these texts by maintaining page and other alignment information such as figure ID, table ID. Using these alignments and LASER11 embedding (Artetxe and Schwenk, 2019) we automatically aligned textual content sentence by sentence and then carried out human review.\"}"}
{"id": "lrec-2022-1-365", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"man verification for all collected text. We discarded miss-aligned sentence pairs identified in human vet-\\ning. To perform mentioned human verification for the aligned sentences, we hired a couple of persons with decent bilingual understanding for both of these lan-\\nguages.\\n\\n| Domain       | Train-Sentences | Dev-Sentences |\\n|--------------|-----------------|---------------|\\n| Collected    | 3.1             | 165000        |\\n| Technical    | 229309          | 1000          |\\n| Law          | 158812          | 1000          |\\n| Healthcare   | 90901           | -             |\\n| General      | 56334           | 840           |\\n| Total        | 700356          | 2840          |\\n\\nTable 1: Statistics of created Parallel Corpora (Train and Development): Hindi-Telugu. Here, General named for type of corpora such as news, blogs, etc.\\n\\n3.3. End to End Translation\\n\\nWe hired 3 translation agencies to translate the provided text of Hindi - Telugu (both directions) by following below described guidelines. As the task involves technical domain translation, we particularly asked agencies to maintain certain standards in translation.\\n\\n- Read the source text (complete passage) carefully before starting the translation process.\\n- Try to fully capture the conveyed meaning of the source text (sentence by sentence) in your translation as much as possible and make translations as understandable as the Source.\\n- Do not be satisfied with just one reading. Read the translation several times, silently and aloud. This will help to check if the words sound clear and harmonious. You may find that some of the words you use are not appropriate.\\n- Use the technical term and expression consistently throughout a translation of a text. While writing a topic related to translations or other repetitive content, re-use the same target side terminology as much as possible.\\n- Translate Terminology only if we see their usage in technical books such as NCERT.\\n- Compare the translation to the original text and see that you convey the same natural message and context.\\n\\nWe employed an in-house team of experienced translators to validate each translated sentence by the agencies to maintain the quality and reject the translations if there are any discrepancies.\\n\\n12 https://ncert.nic.in/textbook.php\\n\\n3.4. Iterative Back-translation driven Post-Editing\\n\\nIn post-editing, a human translator works on the translation produced by the machine in order to provide a final translated version. Here, we hired an in-house team of translators to post-edit pre-filled machine translation output for a given source sentence. For this task, translators can directly accept the machine translation output or make appropriate edits when necessary. We also give liberty to reject particular sentence if machine generated translation requires total rewriting. As always, translators need to maintain the resulting translation to be accurate and read naturally in the target language.\\n\\nHere, to generate machine translation output for post-editing we trained initial Hindi-Telugu and Telugu-Hindi MT model using available Hindi-Telugu parallel corpora as mentioned in section-3.1. As we aim to develop domain parallel corpora, we exploit in-domain monolingual data with the iterative-back-translation (Hoang et al., 2018). Back-translation (Sennrich et al., 2015) is a method to create synthetic source texts from clean target texts by using an MT model that is trained in the target\u2013to\u2013source direction. We can build a better MT model by combining back-translated domain parallel data with the original clean parallel data, and then we repeat this process for other language direction as described in (Hoang et al., 2018). The next iteration of entire process utilises better MT model to back-translate domain data further, and use this generated data in order to build an even better system and so on. The final system benefits from domain monolingual data in both the source and target languages. Further we also periodically added created parallel corpora in this iterative back-translation model creation process to further improve quality.\\n\\nAfter a few rounds of iterative-back-translation and after reaching a certain quality of MT output, We decided to do sampled validation (50% of overall corpora development allocated to this method) of translations obtained using Adaptive Back-translation driven Post-Editing method.\\n\\nEach of these methods have their own advantages as end-to-end translation produces high quality parallel corpora while adaptive back translation driven post editing reduces the turnaround time with qualitative translations.\\n\\nWe identified several online publicly available Hindi and Telugu sources such as government and other web-sites/bulletins containing Technical, Health and Law domain as our source language texts. After completing the translation (or post-editing) and the required review process, we globally randomised the order of parallel corpora such that one would not be able to reconstruct the original source text.\"}"}
{"id": "lrec-2022-1-365", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Method\\n\\nParallel Sentences\\n\\nCollect, Clean and Review Parallel Corpora from Existing Sources\\n\\n165K\\n\\nExtract, Align and Review\\n\\n90K\\n\\nEnd-To-End Translation\\n\\n230K\\n\\nIterative Back-translation driven Post-Editing\\n\\n215K\\n\\nTotal\\n\\n700K\\n\\nTable 2: Statistics of Created and Collected Parallel Corpora: Hindi-Telugu\\n\\n| Domain | Hindi | Telugu |\\n|--------|-------|--------|\\n| #Type  | 124094| 347922 |\\n| #Token | 3221645| 2171959 |\\n\\nTable 3: Type Token statistics of created Parallel Corpora: Hindi-Telugu\\n\\nTable-1 describes our overall efforts for Hindi-Telugu parallel corpora development across the domains. We considered all created corpora as train sets and developed development sets by manually translating Hindi sentences into Telugu. We developed around 43% of data for the technical domain while 30% and 17% of overall parallel corpora for the law and healthcare domains.\\n\\nTable-2 shows overall distribution of developed corpora in-terms of methods. We see that over 40% of parallel sentences were created using iterative back-translation while 43% of sentences were developed by hiring external agencies following an end-to-end translation across the domains. Over 16% of the parallel corpora were created by manually aligning Hindi-Telugu sentences as mentioned in section-3.2.\\n\\nTable-3 shows type and token stats over the complete corpora as well as across the domains. Here, high type numbers across the corpora suggest that the created parallel corpora is diverse in nature. We observe that #type and #token highly dependent on corpora size. Technical domain has highest types while healthcare has comparatively low types across all the domains. This must be due to in-domain variability, as the technical domain contains diverse sub-domains such as natural-sciences, computer sciences, management, etc while healthcare contains text only around Covid-19 related topics. We also see that Telugu shows high number of types compare to Hindi which justifies that Telugu is more agglutinative language than Hindi.\\n\\nFigure 1: Average Time taken for post-editing a sentence: Iterative Back-translation driven Post-Editing (6445 Sentences)\\n\\n4.1. Involved Human Efforts in Post-Editing\\n\\nAs described in section-3.4, we carried overall back-translation driven post-editing by hiring a team of Hindi-Telugu translators (4 translators). During the post-editing, we also captured and measured post-editing efforts in-terms of keyboard keystrokes and time spent over post-editing a machine translation output as explained in (Ahsan et al., 2021).\\n\\nTable-4 shows keystrokes analysis over 6.5K sentences of healthcare domain for Hindi to Telugu direction. The average source token length of these sentences is 19.23. Here, we observed that around 30% of translation outputs are taken as it is without any edit. For remaining sentences we observed that on average 14 keystrokes were applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is applied to correct a machine output sentence in post-editing. This accounts, on average, editing of 2.5 words in this sample post-editing stats. Figure-1 shows the temporal analysis over the same post-editing experience. Here we observed that around 3K sentences were post-edited within a minute while most of the post-editing completed within 4 minutes. We also observed that around 30.05% of translation picked as it is without any edit. On average 14.33 key-strokes per translation is"}
{"id": "lrec-2022-1-365", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 5: Attributes of different Corpora (parallel and monolingual) : Hindi-Telugu\\n\\nIn this section, we present analysis on different parallel corpora and compare it with respective monolingual corpora on multiple aspects to assess representativeness and diversity. We considered naive aspects (textinspector, 2022) such as average sentence length and Type-Token Ratio (TTR) across corpora as measures. Average sentence length (#token/#characters) over corpora indicates how representative the corpora is and considered as one of essential language properties. TTR or the Type-Token Ratio of text, determine whether that text is of good quality or not. TTR is a measure of the lexical diversity (and some say, hence quality) of a text (Litvinova et al., 2017).\\n\\nTable-5 shows average sentences length in terms of tokens and characters across the parallel corpora and sizable monolingual corpora (Kakwani et al., 2020) for both Hindi and Telugu. We observe that average sentence length are 18.95, 18.10, 11.94 and 20.14 for collected (this work), created (this work), samanatar (Ramesh et al., 2021) and sizable monolingual corpora respectively for Hindi and 12.44, 12.24, 8.51 and 11.72 for Telugu. The difference is minimal between developed corpora (this work) and monolingual corpora for both languages while recently released samanatar (Ramesh et al., 2021) and monolingual corpora shows difference of average 9 and 3 tokens for Hindi and Telugu respectively. Similar pattern can be observe on character based average sentence length, here we also observed average 41 and 23 character difference between samanatar and monolingual corpora for Hindi and Telugu.\\n\\nTable-5 shows variations in TTR across corpora. Since, TTR is known to depend on the length of the analysed text and hence the comparison makes sense where the size of corpora is same. Therefore we randomly picked the same number of sentences from large monolingual corpora to match the size of parallel corpora for fair comparative analysis. High TTR indicates that the observed text is more diverse and rich in-terms of vocabulary. We can see from Table-5 that TTR for created corpora stands high for both Hindi and Telugu compared to samanatar and stands close to the same sized monolingual corpora. To nullify the impact of domain, we calculated TTR on collected general domain corpora which also shows similar trends.\\n\\nThe analysis on average sentence length and TTR indicates that created and collected corpora (this work) show representativeness and diversity that one can observe in natural language text for both Hindi and Telugu.\"}"}
{"id": "lrec-2022-1-365", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 6: Bleu and TER scores for Hindi (Hi) - Telugu (Te) baseline MT systems (both direction) and comparison of MT systems trained using different available corpora. Here brackets value indicated size of parallel corpora (i.e. Collected (165K) indicated that 165K sentences of collected corpora, chemistry(500) indicates validation data includes 500 sentences)\\n\\n6. Baseline Systems\\nWe trained baseline machine translation models using created parallel corpora with state-of-the-art neural machine translation methods as a baseline and tested on different domains for both Telugu-Hindi and Hindi-Telugu directions. We also train translation systems on different available training corpora for comparative analysis. Following subsections give details on pre-processing and exact training configuration used for training the neural machine translation engines.\\n\\n6.1. Data Pre-Processing\\nFor data preprocessing, we used IndicNLP Tool with in-house tokenizer to tokenize and clean both Hindi and Telugu corpora (train, validation and test corpora) as a first step. Following subsections explain other pre-processing steps.\\n\\n6.2. Morph + BPE Segmentation\\nFrom token/type ratio, Telugu is morphologically richer compared to Hindi from Table-1. Translating from morphologically-rich agglutinative languages is more difficult due to their complex morphology and large vocabulary (Mujadia and Sharma, 2021). We address this issue with a segmentation method which is based on morphology and BPE segmentation (Sennrich et al., 2016) as a pre-processing step as prescribed in (Mujadia and Sharma, 2020). We utilised unsupervised Morfessor (Virpioja et al., 2013) by training it on monolingual data for Hindi and Telugu. We then applied this trained Morfessor model on our corpora (train, test, validation) to get meaningful morpheme segmented sub-tokens for each word in a sentence. Subsequently, we applied the subword segmentation on top of the morph segmentation.\\n\\n6.3. Training Configuration\\nThroughout all experiments, we used Transformer sequence to sequence architecture with the following configuration for constrained and unconstrained experiments. For these experiments, we used shared vocab across training and used Opennmt-py (Klein et al., 2020) toolkit with following configuration.\\n\\n- Morph + BPE based subword segmentation, Embedding size : 512 Transformer for encoder and decoder, RNN size 512, heads 8 encoder - decoder layers : 6, label smoothing : 1.0, dropout : 0.30, Optimizer : Adam, Beam size : 4 (train) and 10 (test), training steps : 20K\\n\\nThe results are discussed in following Result section.\\n\\n7. Results\\nTable-6 shows performance of trained systems on different training corpora in terms of BLEU (Papineni et al., 2002) and TER scores for Hindi-Telugu and Telugu-Hindi respectively on the validation and Test data. We used SACREBLEU (Post, 2018) to calculate BLEU and TER scores. As described in section-4, the technical domain test sets are further divided into chemistry and computer science as sub-domains along with Law and General domains. We further evaluated trained models on recently released The FLORES-101 Evaluation Benchmarks (Goyal et al., 2021). We achieved baseline BLEU scores as 16.33, 16.06, 14.85, 30.07 and 13.99 for respectively chemistry, computer science, Law, General and on Flores sets respectively.\"}"}
{"id": "lrec-2022-1-365", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Similarly, the baseline BLEU scores are 16.33, 16.06, 14.85, 30.07 and 13.99 respectively for chemistry, computer science, law, general and on Flores sets respectively for Telugu-Hindi. TER scores show similar patterns across domains (Table-6).\\n\\nTable-6 also shows BLEU, TER comparison of different translation models trained on different corpora and these parallel corpora vary in size and methods by which they developed as discussed in section-3. Here we find that trained models with 535K created data (this work) show best and state-of-the-art results.\\n\\n8. Future work and Conclusion\\n\\nWe present a new 535K Hindi-Telugu parallel corpus of different technical domains such as natural science, computer science, law and healthcare along with the general domain. We also compiled, cleaned, reviewed 165K of Hindi-Telugu parallel corpora from different sources. We presented different methods for parallel corpora creation that we followed in this work. Particularly we observed that over 30% of translations were taken as it is (without single edit) by the translators and we recommend that iterative back-translation driven post-editing can be used for similar parallel corpora creation work. We present the state-of-the-art baselines and models for Hindi-Telugu and Telugu-Hindi across the domains. The results suggest that carefully created and curated parallel corpora boost the translation performance even with the lower parallel corpora size. The corpora and baseline models will be available under a Creative Commons Licence. We carried out average sentence length and TTR based analysis to assess the quality of parallel corpora. We find that our created parallel corpora matches the numbers that one observes in the natural text. In future, we plan to enhance the Hindi-Telugu corpus using described parallel corpora creation methods and plan to study and investigate domain adaptation for Hindi-Telugu domain-dependent machine translation.\"}"}
{"id": "lrec-2022-1-365", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Mujadia, V. and Sharma, D. M. (2021). Low resource similar language neural machine translation for Tamil-Telugu. In Proceedings of the Sixth Conference on Machine Translation, pages 288\u2013291.\\n\\nNakazawa, T., Nakayama, H., Ding, C., Dabre, R., Higashiyama, S., Mino, H., Goto, I., Pa Pa, W., Kunchukuttan, A., Parida, S., Bojar, O., Chu, C., Eriguchi, A., Abe, K., Oda, Y., and Kurohashi, S. (2021). Overview of the 8th workshop on Asian translation. In Proceedings of the 8th Workshop on Asian Translation (WAT2021), pages 1\u201345, Online, August. Association for Computational Linguistics.\\n\\nPapineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.\\n\\nParida, S., Dash, S. R., Bojar, O., Motlicek, P., Pattnaik, P., and Mallick, D. K. (2020). OdiEnCorp 2.0: Odia-English parallel corpus for machine translation. In Proceedings of the WILDRE5\u20135th Workshop on Indian Language Data: Resources and Evaluation, pages 14\u201319, Marseille, France, May. European Language Resources Association (ELRA).\\n\\nPhilip, J., Siripragada, S., Kumar, U., Namboodiri, V., and Jawahar, C. (2019). Cvit\u2019s submissions to wat-2019. In Proceedings of the 6th Workshop on Asian Translation, pages 131\u2013136.\\n\\nPost, M. (2018). A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186\u2013191, Brussels, Belgium, October. Association for Computational Linguistics.\\n\\nRamesh, G., Doddapaneni, S., Bheemaraj, A., Jobanputra, M., AK, R., Sharma, A., Sahoo, S., Diddee, H., Kakwani, D., Kumar, N., et al. (2021). Samanantar: The largest publicly available parallel corpora collection for 11 Indic languages. arXiv preprint arXiv:2104.05596.\\n\\nResnik, P., Olsen, M. B., and Diab, M. (1999). The bible as a parallel corpus: Annotating the \u2018book of 2000 tongues\u2019. Computers and the Humanities, 33(1):129\u2013153.\\n\\nSchwenk, H., Chaudhary, V., Sun, S., Gong, H., and Guzm\u00e1n, F. (2019). Wikimatrix: Mining 135m parallel sentences in 1620 language pairs from wikipedia. arXiv preprint arXiv:1907.05791.\\n\\nSennrich, R., Haddow, B., and Birch, A. (2015). Improving neural machine translation models with monolingual data. arXiv preprint arXiv:1511.06709.\\n\\nSennrich, R., Haddow, B., and Birch, A. (2016). Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715\u20131725.\\n\\nSiripragada, S., Philip, J., Namboodiri, V. P., and Jawahar, C. (2020). A multilingual parallel corpora collection effort for Indian languages. arXiv preprint arXiv:2007.07691.\\n\\nTiedemann, J. (2012). Parallel data, tools and interfaces in opus. In Lrec, volume 2012, pages 2214\u20132218. Citeseer.\\n\\nVasanta, D., Suvarna, A., Sireesha, J., and Raju, S. B. (2010). Language choice and language use patterns among telugu-hindi/urdu-english speakers in Hyderabad, India. In Proceedings of the International Conference on Language, Society and Culture in Asian Contexts, pages 57\u201367. Mahasarakam University.\\n\\nVirpioja, S., Smit, P., Gr\u00f6nnroos, S.-A., Kurimo, M., et al. (2013). Morfessor 2.0: Python implementation and extensions for morfessor baseline.\\n\\nWang, R., Tan, X., Luo, R., Qin, T., and Liu, T.-Y. (2021). A survey on low-resource neural machine translation. arXiv preprint arXiv:2107.04239.\"}"}
