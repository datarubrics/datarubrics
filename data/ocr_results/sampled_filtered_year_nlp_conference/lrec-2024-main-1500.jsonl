{"id": "lrec-2024-main-1500", "page_num": 1, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Using Bibliodata LODification to Create Metadata-Enriched Literary Corpora in Line with FAIR Principles\\n\\nAgnieszka Karli\u0144ska 1, Cezary Rosi\u0144ski 2, Marek Kubis 3, Patryk Hubar 4, Jan Wieczorek 5\\n\\n1 NASK National Research Institute, Warsaw, Poland\\n2 Institute of Literary Research of the Polish Academy of Sciences, Pozna\u0144, Poland\\n3 Adam Mickiewicz University, Pozna\u0144, Poland\\n4 University of Warsaw, Warsaw, Poland\\n5 Wroclaw University of Science and Technology, Wroclaw, Poland\\nagnieszka.karlinska@nask.pl, cezary.rosinski@ibl.waw.pl, marek.kubis@amu.edu.pl, p.hubar@uw.edu.pl, jan.wieczorek@pwr.edu.pl\\n\\nAbstract\\nThis paper discusses the design principles and procedures for creating a balanced corpus for research in computational literary studies, building on the experience of computational linguistics but adapting it to the specificities of the digital humanities. It showcases the development of the Metadata-enriched Polish Novel Corpus from the 19th and 20th centuries (19/20MetaPNC), consisting of 1,000 novels from 1854\u20131939, as an illustrative case and proposes a comprehensive workflow for the creation and reuse of literary corpora. What sets 19/20MetaPNC apart is its approach to balance, which considers the spatial dimension, the inclusion of non-canonical texts previously overlooked by other corpora, and the use of a complex, multi-stage metadata enrichment and verification process. Emphasis is placed on research-oriented metadata design, efficient data collection and data sharing according to the FAIR principles as well as 5- and 7-star data standards to increase the visibility and reusability of the corpus. A knowledge graph-based solution for the creation of exchangeable and machine-readable metadata describing corpora has been developed. For this purpose, metadata from bibliographic catalogs and other sources were transformed into Linked Data following the bibliodata LODification approach.\\n\\nKeywords: corpus, metadata, linked open data, FAIR, computational literary studies, digital humanities\\n\\n1. Introduction\\nThe practice of building corpora for literary studies is relatively nascent, and standardized procedures for curating collections of literary texts have not yet been fully developed (Gius et al., 2019). The direct application of corpus creation principles established in the field of linguistics to literary research is not an easy task, due to the significant differences between linguistic and literary corpora. The compilation of the latter is subordinated to the needs that result from the nature of linguistic hypotheses that concern phenomena from various levels of language (e.g. norms, orthography, lexis, syntax). Researchers' expectations of literary corpora concern how language (its different layers) is used to create literary content. Also, the textual material included in the literary corpus differs from the linguistic use and is usually more homogeneous by containing literary works or texts authored by literary experts. Another difference refers to the key of metadata categories selection used to describe the samples. In the case of linguistic corpora, the selection of categories is determined by the specifics of linguistic research (e.g. age of speakers, information on the periodization of language evolution, the standard of orthography or transcription used), while literary corpora require consideration of the specifics of literary research (e.g. place of publication, author\u2019s place of origin, number of issues, literary genre). The analysis of the aforementioned differences allows us to express the conclusion that both linguistic and literary corpora represent complementary resources.\\n\\nLeveraging the expertise of bibliographers, we aim to move from a linguistic to a literary corpus, thereby bridging the gap between computational linguistics and digital humanities, esp. computational literary studies (Frank and Ivanovic, 2018). Based on the experience of creating Metadata-enriched Polish Novel Corpus from the 19th and 20th centuries (19/20MetaPNC), we will propose a corpus creation procedure that simultaneously provides data tailored to specific research needs and ensures reusability.\\n\\nThis paper makes several notable contributions. The first is the corpus itself, one of the first publicly available resources of its kind for Polish. It was created with very strict balancing criteria, taking into account the cultural context and drawing on the expertise of linguists on the one hand, and bibliographers and literary scholars on the other. Another significant contribution is the introduction of a comprehensive workflow for enriching and linking the metadata of a corpus of literary texts, which includes the implementation of the FAIR principles developed in...\"}"}
{"id": "lrec-2024-main-1500", "page_num": 2, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"In the context of scientific data management in corpus work, we demonstrate how to present and share data following 7-star Linked Data Service standards, which extends the 5-star Open Data model proposed by Tim Berners-Lee. We provide a Semantic Web-ready solution for creating exchangeable and machine-readable metadata for describing corpora, specifically adapted to the needs of a diverse scholarly community. We recommend employing the Resource Description Framework (RDF) as the metadata format for knowledge representation within a linked data environment, alongside the use of the Neo4J graph database management system. This software facilitates the storage and dissemination of data in a manner that is aligned with Semantic Web principles.\\n\\nWe draw on the practice of bibliodata LODification, i.e. the conversion of publication metadata from bibliographic catalogues and other sources into Linked Open Data (LOD) (Lindemann, 2022; Lindemann et al., 2023). However, unlike the proponents of this approach, we recognize LODified data not only as publication metadata, citation relations, content-describing subject headings, or keywords but also as content-extracted data, both automatically and manually.\\n\\n2. Related work\\n\\nThe linguistic literature demonstrates that when designing a corpus, its purpose plays a pivotal role\u2014specifically, its adaptation to address particular research inquiries\u2014as well as the methodology used for data selection. Apart from the corpus size, which depends on factors such as the linguistic aspect under investigation, the diversity within the studied language variety, and the frequency of text repetition within a given type or genre (Kennedy, 1998; Biber, 1990), there are also questions of representativeness and balance (Francis, 1982; Leech, 2007). Both of these are considered desirable but challenging to attain in practical corpus construction (Biber, 1993; Hunston, 2008; Baker, 2010).\\n\\nBuilding a corpus of historical material is deemed to be particularly difficult (Schlagenhauf, 2004; Jenset and McGillivray, 2017). It places very high demands on the metadata description (Depuydt and Brugman, 2019), and the implementation of the postulate of balanced source selection faces many more theoretical and practical obstacles than in the case of corpora of contemporary texts (Egan, 2019). The fundamental and insoluble problem is the limited knowledge of the writing of a given period. While it is possible to capture the overarching trends and identify the dominant types and genres of texts, the knowledge of the structures of the documents used in that era will always remain incomplete (Gruszczy\u0144ski et al., 2020). The lack of reliable population data precludes the creation of a randomly sampled, statistically representative corpus and can lead to arbitrary text selection criteria, decisions based on speculation and theoretical assumptions, and favoritism towards canonical texts (Underwood, 2016).\\n\\nA number of previous diachronic literary corpus projects have sought to reduce speculation and ahistoricity by using data on the production and reception of texts from bibliographical records, or by attempting to reconstruct reading practices in a given period. Others have relied solely on contemporary expertise. In the European Literary Text Collection (ELTeC), in order to capture the diversity of literary production while ensuring comparability across subcorpora, texts were categorized based on time span, canonicity (number of reprints), author gender, length, and authorship within the collection (ELTeC, 2021). For this purpose, the creators primarily used the catalogues of the national libraries, pointing out gaps in data availability (Sch\u00f6ch et al., 2021). In the FRANTEXT corpus, on the other hand, works were selected according to the \\\"principle of authority,\\\" consulting recognized syntheses of 19th and 20th century French literature and compiling lists of works mentioned (Grieve-Smith, 2010). In the case of KOLIMO, bibliographic data were considered in addition to literature on the subject. Experts in the field evaluated the relevance of individual texts (Herrmann and Lauer, 2020). In the dProse corpus based on KOLIMO, metadata were verified and enhanced using repositories and literary encyclopedias (Gius et al., 2021).\\n\\nCurrently, there is a lack of a comprehensive and balanced corpus of Polish novels. Most Polish literary corpora are designed to meet specific research needs, often do not adhere to standard composition criteria, and do not provide thorough metadata descriptions. An exception is the Polish ELTeC subcorpus of 100 novels published between 1840 and 1920, according to the project's assumptions (Frontiniet al., 2020). However, there are concerns about the inclusion of texts published after the specified period and the absence of a well-defined procedure for the acquisition of metadata, which is essential for assessing the quality of the corpus.\\n\\nThe authors' evaluation of the existing corpora reveals a common problem: insufficient metadata validation. This stems from an over-reliance on institutional sources for metadata and a presumption of their accuracy, coupled with limited opportunities for cross-referencing and validating metadata against other sources, primarily due to the underutilization of LOD, resulting in source isolation.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 3, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"new initiatives in the area of metadata enhancement within textual corpora through the incorporation of external data, influenced our decision on the form and features of the 19/20MetaPNC. The initiative of Workset Creation for Scholarly Analysis (WCSA) directed by HathiTrust shares both methodological and technological similarities with our project (Jett, 2015). A distinctive aspect of WCSA is its use of HTRC worksets\u2014user-compiled collections of volumes from the HathiTrust digital library, designated for data analysis via a diverse collection of HTRC tools and services. These worksets are a fundamental component for all analytical activities within HTRC Analytics, offering a platform for collaborative and referenced research, thereby advancing reproducibility. Similarly, the present project of 19/20MetaPNC creation also commences on the task of expanding string-based metadata with Uniform Resource Identifiers (URIs), a step towards refined data discovery and interoperability with external services (Jett et al., 2016).\\n\\n3. Corpus design\\n\\n3.1. Design principles\\n\\nIn designing the corpus, we adopted assumptions developed in the field of linguistics and benefited from the experience of creators of other literary corpora. The overall research goal was to trace the impact of historical and spatial factors on the dynamics of literary processes. We formulated specific research questions, focusing on the transformation of the urban-rural dichotomy in Polish fiction (Karli\u0144ska et al., 2022).\\n\\nWe assumed that the corpus would contain 1,000 texts. This number is large enough to enable distinguishing subcorpora and conducting computational literary studies. Like the authors of ELTeC (Sch\u00f6ch et al., 2021), we decided to maintain genre and language homogeneity. We included in the corpus only novels originally written in Polish (thus rejecting translated texts) and first published in book form between 1864 and 1939. In this way, we took into account the three distinct periods of Polish literary history\u2014Positivism (1864\u20131890), Young Poland (1890\u20131918), and the interwar period (1918\u20131939)\u2014and made it possible to carry out comparative analyses.\\n\\nWe aimed for representativeness and balance. We relied on texts available in digital form, drawing from a variety of sources and assessing the quality of the data. Due to the lack of complete bibliographies and information on the literary production and reception of the period, we could not define the population precisely, including both all published novels and their authors. This limitation made it impossible for us to assess the representativeness of the data. Therefore, we focused on ensuring maximum balance by relying on a broad set of metadata. We used ELTeC as a model and also drew inspiration from KorBa (Gruszczy\u0144ski et al., 2022), a corpus of Polish texts from the 17th and 18th centuries. KorBa employed a sophisticated selection procedure and categorized texts based on chronology, genre, subject, and, unusually for corpora, geographical origin (Gruszczy\u0144ski et al., 2020).\\n\\nThe distinctive geopolitical and socio-cultural context of the Polish territories during the second half of the 19th century and the first half of the 20th century played a central role in shaping the metadata structure, content, and criteria for balancing the corpus. In the late 18th century, Poland ceased to exist as a sovereign state and was partitioned, falling under the rule of the Habsburg Monarchy, the Kingdom of Prussia, and the Russian Empire until 1918. These partitions showed significant differences in terms of socio-economic development, urbanization, and civil liberties (Kaczynska, 1970). An additional criterion for text selection was the time frame of the narrative, which was set no earlier than 1815, the year of the Congress of Vienna, which established national borders that remained largely unchanged for over a century.\\n\\nFollowing a methodology similar to ELTeC, we decided to include in our corpus both novels considered part of the contemporary canon and those that have fallen into relative obscurity. To measure their reception, we took into account the number of reprints of a given publication. Given the challenge of maintaining a balance between classes, we defined each text class's minimum and maximum representation in the corpus. We established the following criteria:\\n\\n1. Date/literary period:\\n   - Positivism (1864\u20131890) >= 20%\\n   - Young Poland (1890\u20131918) >= 20%\\n   - the Interwar Period (1918\u20131939) >= 20%\\n\\n2. Gender:\\n   - female author 10%\u201350%\\n\\n3. Place of publication:\\n   - Austrian partition >=15%\\n   - Prussian partition >=15%\\n   - Russian partition >=15%\\n\\n4. Level of reception:\\n   - no more than 2 reprints >= 30%\\n   - more than 2 reprints >= 30%\\n\\n3.2. Data collection\\n\\nWe examined four open sources of 19th and 20th-century Polish prose with the goal of collecting texts for our corpus:\"}"}
{"id": "lrec-2024-main-1500", "page_num": 4, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"1. ELTeC corpus (ELTeC, 2021) which contains novels encoded in the TEI format.\\n\\n2. Wolne Lektury (Modern Poland Foundation, 2022), an online repository that is mainly oriented towards collecting school readings and offering them in reader-friendly data formats.\\n\\n3. Polish edition of the Wikisource (Wikimedia Foundation, 2022) project which includes transcriptions of printed books that have fallen into the public domain encoded in the MediaWiki format.\\n\\n4. Polona, a digital library maintained by the National Library of Poland (2022) that provides scans of printed books.\\n\\nOur initial dataset consisted of 100 Polish novels from ELTeC, 193 literary works from Wolne Lektury, 225 texts from Wikisource, and ca. 6,000 volumes from Polona. It has to be noted that the collected texts vary greatly in quality. Novels published by Wolne Lektury were thoroughly edited and contemporized. ELTeC texts retained original (historic) spelling and punctuation, but the hyphenated words were merged in transcription. In the case of Wikisource, not only spelling and punctuation is preserved, but also hyphenation is kept in the original form. Digital copies of physical books provided by Polona contain OCR-derived textual layers only. Hence, they contain errors introduced in the process of optical character recognition and retainspelling, punctuation, and hyphenation of the physical copies. In order to make the texts from all the sources more uniform we cleaned OCR-related errors and normalized punctuation and hyphenation with the use of custom scripts adapted from (Kubis, 2021). We also utilized a diachronic normalizer (Jassem et al., 2017; Dudzic et al., 2024) to modernize spelling.\\n\\n3.3. Metadata description\\n\\nThe metadata that we have used to describe the corpus defy the traditional model of archiving and sharing collections, familiar from domain bibliographies or library catalogs. None of the common bibliographic data formats are comprehensive enough to include information crucial to our research, such as the geographic coordinates of the places described in the novels or the attribution of the partitions in which they were published. We use the information in the catalogs for research, the original purpose of which is to collect and preserve the textual production. Our activity is what Foulonneau and Cole (2005) refer to as \u201cthe process of adapting metadata for another application than originally envisioned when the metadata records were created\u201d. The phenomenon we are dealing with is metadata repurposing, understood as the use of data in a new context not originally intended (Deng, 2010). Hence, the metadata we extracted from the National Library of Poland catalog was the author\u2019s name, the title of the book including subtitle, place and year of publication, and genre.\\n\\nIt is worth noting that a source of enriching information about individual texts beyond the content of the catalogs and an opportunity to increase corpus research potential is the use of NLP techniques. The 19/20MetaPNC benefited from Named Entity Recognition (NER), which made it possible to label all the places that appear in the texts of the novels as settings. For this purpose, we used the PolD-PeepNer2 system and its pre-trained model, learned from the KPWr corpus (Marci\u0144czuk et al., 2018; Marci\u0144czuk and Radom, 2021).\\n\\nHowever, neither the arbitrary metadata notation we initially adopted, nor the available and widely used metadata formats facilitated the scientific reuse of the literature corpus due to a lack of interoperability. This was only made possible by the use of LOD structures, which allowed us to identify, harmonize, and enrich the original metadata. This type of intervention places corpus-building activities close to the achievements of the FAIR principles and the 7-star Linked Data Service. Thus, the metadata obtained through LODification were the author\u2019s persistent identifier (PID), place of birth and gender, and place of publication PID. For both types of places we acquired geographic coordinates.\\n\\nConducting NLP-based enrichment alongside PID and LOD enrichment, we developed a four-stage toponym disambiguation workflow to identify and standardize geographic entities (geo-entities). The workflow utilized leading approaches in Geographic Information Retrieval (Buscaldi, 2011; Derungs and Purves, 2014) and primarily relied on the Geonames database. The first stage involved identifying historical place name variants through knowledge-based methods with historical registers, directories, and dictionaries used as data sources. In the second stage, records from the Geonames database were assigned to the identified geo-entities using a list of historical name variants. When multiple records were found (e.g., Paris as the capital of France or Paris as a Polish village) we filtered search results based on the population. The third stage aimed to determine whether the identified names referred to cities or villages. The final stage focused on determining the partition in which a village or city was located. Historical maps of Polish territories after the post-1815 partitions were used, along with georeferencing through software like QGIS and OpenStreetMap resources. This stage involved plotting polygons on the maps corresponding to each partition to determine precise border coordinates and subsequently assign\"}"}
{"id": "lrec-2024-main-1500", "page_num": 5, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"We then performed a semi-automated metadata verification to ensure that the collected texts met the project's criteria. For genres, manual verification was required, as the bibliographic information was not always accurate. At the same time, as a result of automatic and manual work, we have added the following attributes to the description of the corpus: literary period, assignment to the partition on the basis of the place of publication, and the time of the novel's action (before or after 1815). For the latter, we considered information from the titles and subtitles obtained from the National Library, details found in the opening pages of the relevant book regarding the time of the narrative, as well as information from subsequent pages, including descriptions of historical events or technological advancements not feasible before 1815. As a result, we obtained a collection of 2,927 novels. After thorough deduplication, which included author names, titles, and years of first printing, we obtained 1,707 novels, from which we randomly selected 1,000 based on the adopted balancing criteria.\\n\\nIn conclusion, two types of metadata have been used to describe the corpus: the first type is produced from the perspective of the needs of the information systems so that it is primarily used for knowledge retrieval and only secondarily can be used for research purposes. The other type\u2014which we call research question-based metadata\u2014is produced in a specific research process and is originally used to answer the problems posed by the researchers, but can be used to improve information retrieval. Additionally, the second layer of metadata understanding has been produced and includes metadata obtained from library catalogs, manual completions, NLP-based extractions, and reconciliations through LODification.\\n\\n3.4. Data publication\\n\\nOne of the primary objectives of publishing corpora is to facilitate their long-term utility and reusability for diverse scholarly applications. In line with this goal, the 19/20MetaPNC corpus has been shaped by the principles of 7-star data and FAIR. Rather than employing conventional storage as static files in a data repository, the corpus is made available through direct download links. This ensures that users always have access to the most current dataset, as files are retrieved directly from the publisher. To further enhance accessibility, Python code is provided to simplify the downloading process. Complementing these measures, texts in the 19/20MetaPNC corpus have been purposefully selected to fall under public domain licenses, permitting unrestricted access, use, and distribution.\\n\\nEach step of corpus development, including design decisions, balancing criteria, statistical metrics, and Python code, has been comprehensively documented and made publicly available in an open GitHub repository. These decisions, taken collectively, result in a corpus designed to optimize accessibility, interoperability, and long-term reusability. Providing such a structured corpus allows detailed exploration of the data, mainly through the application of graph visualizations, advanced and precise filtering of results, and the use of complex queries in the SPARQL language. This approach not only enriches the data retrieval process, but also highlights the semantic relationships between the data. Most importantly, this form of knowledge sharing facilitates the formulation of new research questions, promoting a continuous cycle of inquiry and discovery within the academic community.\\n\\n3.5. Literary corpus creation workflow\\n\\nBased on the experience of creating a 19/20MetaPNC corpus, we propose a workflow for the creation and reuse of a meta-corpus based on the two perspectives of metadata generation and metadata use, as well as the guidelines for sharing text collections as described by the FAIR and 7-star standards. This workflow consists of nine consecutive stages.\\n\\n1. Research question-based design: Metadata design should encompass both general-purpose metadata derived from existing cataloging information and metadata tailored to address specific research questions. In corpus design, it is imperative to define the target population and establish criteria for text inclusion, as well as balancing criteria.\\n\\n2. Data collection and reuse: To avoid redundant work, the corpus creators should make use of existing textual resources and metadata databases, while complementing them with any essential elements that may be unavailable in the digital environment.\\n\\n3. Data evaluation and preprocessing: All collected resources should undergo quality assessment and subsequently be standardized in terms of metadata consistency, data types, and formats. This may involve tasks such as OCR error correction and diachronic normalization.\\n\\n4. NLP-based enrichment: At this stage, techniques such as NER or topic modeling can be used to enhance the text description. This newly acquired data, together with metadata, can then be used to balance the corpus.\\n\\n5. PIDs and LOD enrichment: Unique identifiers should be assigned to the data to ensure...\"}"}
{"id": "lrec-2024-main-1500", "page_num": 6, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"accessibility and interoperability with authoritative databases. Adherence to LOD structures can improve the comprehensibility and reusability of the corpus.\\n\\n6. Metadata verification and completion:\\nMetadata should be rigorously validated to ensure both accuracy and completeness. The evaluation process includes quantitative and qualitative analysis, preferably conducted by domain experts. In cases where gaps are identified, it may be necessary to supplement the metadata.\\n\\n7. Balancing:\\nBased on the adopted balancing criteria and the collected metadata, along with the data extracted from the texts, the corpus should be balanced. In cases where there are significant discrepancies between different text classes, sampling may be a necessary step.\\n\\n8. Semantic environment and ontology building:\\nDuring this stage, relationships between various (meta)data elements should be defined, establishing a structured framework for analysis. It is recommended to store the information in a graph-based database, allowing for efficient querying and analysis while preserving the semantic relationships. This structured approach facilitates a comprehensive analysis and the potential for uncovering new insights.\\n\\n9. Publishing:\\nThe final stage involves publishing the corpus in a way conducive to computational literary studies, making it accessible through services and repositories that facilitate resource reuse. The published corpus should be accompanied by comprehensive documentation describing aspects such as licenses, creators, and standards employed.\\n\\n4. Dataset in numbers\\nThe proportions between text classes were consistent with the assumed balancing scheme described in 3.1. Women were the authors of 29.4% of the novels in the corpus, well above the assumed minimum of 10%. The collection is dominated by texts of low reception with no more than 2 reprints (63.3%). Among the partitions, the Russian partition is predominant (58.5%), while the Austrian (19.7%) and Prussian (15.4%) partitions are less represented. Novels published in foreign centers account for 4.4%. It should also be noted that 20 novels (2%) were published simultaneously for the first time in two places belonging to different partitions. In terms of dates of publication, the least represented group are texts from the period of Positivism (20.7%). 39.1% of the works were published in Young Poland and 40.2% in the Interwar period.\\n\\nThe number of titles for each balance criterion is shown in Fig. 1.\\n\\nThe novels in the corpus were written by 390 different authors, including 111 women and 279 men. On average, there were 2.56 novels per author, with a median of 1 and a std=3.63. A total of 14 authors, including 5 women, exceeded the number of 10 novels, and as many as 227 authors are represented by a single text in the corpus.\\n\\n19/20MetaPNC comprises a total of 64,313,110 tokens, distributed across 4,255,570 sentences. On average, each novel contains about 64,313.11 tokens (median 55,571.50) and 4,255.57 sentences (median 3,593.50). The relatively high standard deviation indicates significant variations in the length of novels. Notably, there is a substantial difference in length between novels of high and low reception (the former being much longer). Additionally, variations in length exist among novels from different literary periods, with positivist novels being the longest and those from the interwar period being the shortest. Complete statistics for the number of tokens and sentences based on the adopted balancing criteria can be found in Tab. 1 and 2.\\n\\n5. Discussion\\nIn constructing 19/20MetaPNC, we aimed to reconcile the expectations of computational linguists regarding the structure and text selection criteria of the corpus with the needs of literary scholars and digital humanists. The novelty of our resource lies in an advanced approach to balancing that takes into account the spatial dimension, the inclusion of non-canonical texts not previously covered by other corpora, and a complex and multi-stage procedure of metadata enrichment and verification. Creating the corpus involved several challenges, primarily related to the quality of the data and metadata on which we relied.\\n\\nThe lack of complete population data makes it challenging to assess the representativeness of the corpus. Since it is based on texts already available in digital form, 19/20MetaPNC can be categorized as an opportunistic corpus. However, we have drawn from a variety of sources and conducted a rigorous selection of texts, achieving a good balance across four different criteria. Despite the strict requirements, we successfully managed to include the works of 390 authors, creating the largest open corpus of its kind for Polish. We also considered the geographic-political criterion\u2014the territory of Poland in the 19th century and at the beginning of the 20th century was divided into three partitions\u2014Prussian, Russian and Austrian. Polish literature was produced in all the partitions, but the circumstances in which the literary circuits were formed differed significantly. We have consequently\"}"}
{"id": "lrec-2024-main-1500", "page_num": 7, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 1: Treemaps of the balance criteria in 19/20MetaPNC\\n\\nTable 1: Corpus statistics (number of tokens)\\n\\n| feature       | mean     | std       | 25%       | 50%       | 75%       |\\n|---------------|----------|-----------|-----------|-----------|-----------|\\n| In total      | 64313.11 | 42433.66  | 37416.25  | 55571.50  | 82112.50  |\\n| Gender        |          |           |           |           |           |\\n| Female        | 61760.83 | 39234.87  | 35540.00  | 55868.00  | 78374.25  |\\n| Male          | 65375.95 | 43679.45  | 37574.75  | 55548.50  | 83191.00  |\\n| Partition     |          |           |           |           |           |\\n| Austrian      | 64563.74 | 34456.49  | 38966.00  | 57163.00  | 82349.00  |\\n| Prussian      | 56628.18 | 31590.98  | 36142.50  | 49925.50  | 73404.50  |\\n| Russian       | 64809.38 | 45321.22  | 35957.00  | 54909.00  | 83223.00  |\\n| Abroad        | 75226.57 | 59361.35  | 42487.75  | 63759.00  | 84335.25  |\\n| Two partitions| 82492.70 | 46596.78  | 49451.00  | 78812.50  | 100881.75 |\\n| Period        |          |           |           |           |           |\\n| Positivism    | 73408.68 | 45077.16  | 42589.50  | 63683.00  | 89686.00  |\\n| Young Poland  | 66979.41 | 47471.30  | 38870.50  | 57330.00  | 83121.00  |\\n| Interwar      | 57036.23 | 33875.48  | 35258.50  | 48930.00  | 74560.00  |\\n| Reception     |          |           |           |           |           |\\n| High          | 80777.91 | 51066.59  | 46927.00  | 70239.00  | 99687.50  |\\n| Low           | 54767.16 | 32974.61  | 32825.00  | 48966.00  | 69789.00  |\\n\\nattempted to balance the corpus in terms of where novels were written. We have also covered works created in exile\u2014outside the territory of the former Poland (Fig.1). At this point, the balance does not extend to the length of the texts. To prevent longer texts (e.g., multi-volume novels) from exerting a disproportionate influence on the results, it is worthwhile to use sampling. Due to the diversity of sources, we had to address issues related to different formats and text quality. A significant portion of the material was generated by the OCR process, which is prone to errors. This required extensive pre-processing and data harmonization.\\n\\nA significant challenge in building a literary corpus is the need to rely on library catalogs, which are produced with remarkable regularity, but are full of omissions and inconsistent data. An additional difficulty is the inability to compare data with other sources due to the limited interoperability of library catalogs, although it should be noted that libraries' Linked Data Services are increasingly emerging. Another problem is the limitation of metadata related to the original purpose of library resources so that the richness of the description of the texts and entities present is insufficient for at least corpus balancing.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 8, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":true,\"is_diagram\":false,\"natural_text\":\"### Corpus statistics (number of sentences)\\n\\n| Feature        | In total | Gender | Male | Female |\\n|----------------|----------|--------|------|--------|\\n|                | mean     | std    | 25%  | 50%    | 75%    |\\n| In total       | 4255.57  | 2920.47| 2340.00 | 3593.50 | 5452.50 |\\n| Gender         |          |        |      |        |        |\\n| Female         | 4120.91  | 2849.00| 2126.00 | 3406.50 | 5514.50 |\\n| Male           | 4311.65  | 2949.90| 2397.75 | 3632.50 | 5388.00 |\\n| Partition      |          |        |      |        |        |\\n| Austrian       | 3990.22  | 2204.64| 2439.00 | 3658.00 | 5100.0  |\\n| Prussian       | 3867.04  | 2409.96| 2170.00 | 3306.00 | 5107.25 |\\n| Russian        | 4332.10  | 3062.80| 2295.00 | 3546.00 | 5480.0  |\\n| Abroad         | 5087.36  | 4387.72| 2599.0  | 4172.50 | 5528.25 |\\n| Two partitions | 5792.50  | 3663.12| 3247.50 | 5340.50 | 6608.75 |\\n| Period         |          |        |      |        |        |\\n| Positivism     | 4020.37  | 2495.06| 2256.50 | 3477.00 | 5274.0  |\\n| Young Poland   | 4512.17  | 3402.11| 2395.00 | 3711.00 | 5484.0  |\\n| Interwar       | 4127.10  | 2585.39| 2320.00 | 3475.00 | 5387.50 |\\n| Reception      |          |        |      |        |        |\\n| High           | 5394.23  | 3434.85| 3061.50 | 4613.00 | 6958.50 |\\n| Low            | 3595.40  | 2336.69| 2008.00 | 3101.00 | 4686.0  |\\n\\nConnecting metadata to LOD repositories such as VIAF, Wikidata, Geonames, and Library of Congress Subject Headings enables cross-checking of information between sources. Discrepancies in spelling of author names across different editions of the same book can be either resolved by voting or at least detected automatically. The overlap of metadata across different LOD sources can be utilized to align book titles that have undergone diachronic changes and missing metadata required for corpus balancing can be supplied from the linked repositories. Without connection to LOD repositories, all these problems have to be resolved by hand.\\n\\nMetaPNC was created with the intention of not only building a textual resource but also with the conviction that a literature corpus is a dataset that must be built according to FAIR principles and 7-star data. Every action taken was not only research-motivated but also aimed at reuse by other researchers, so in order to increase the visibility of MetaPNC and its reusability potential, we implemented bibliodata LODification from the beginning. Our goal was to develop a procedure that could be easily adapted to other types of literary research. In order to achieve this, it was necessary to provide a universal, open, and flexible way to add more categories of metadata according to current scholarly needs and to propose such methods of constructing them that they would be intuitive for subsequent researchers, including those who had not previously worked with the resource. Therefore, the target form of presentation of the corpus is to present the entire collection in the form of a knowledge graph.\\n\\nIn the process of enriching the (meta)data and converting it to formats compatible with the triple data model and semantic web, we published its metadata in two different structures: a Neo4J graph database using the Labelled Property Graph (LPG) model and RDF. The availability of MetaPNC as the knowledge graph enables data exploration through complex queries and visualizations that would otherwise be impossible. This not only allows us to seek answers to well-established research questions but also to pose new questions and uncover non-obvious connections in the data, ultimately contributing to the development of computational literary studies.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 9, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Figure 2: Query in the Neo4J graph database showing books published in a different partition than the author's partition of birth and the possibilities for the transfer of literary texts between the partitions.\\n\\n6. Conclusion and future work\\n\\nThe creation of a literary corpus is a partly separate endeavor from the creation of a linguistic corpus. Clear guidelines are lacking. The approach we propose, based on bibliodata LODification, will allow the design of resources that are tailored to specific usage scenarios, while at the same time enabling a much wider range of applications and stimulating new research questions. The 19/20MetaPNC project demonstrates that metadata-enriched corpora have great potential and can be an important step towards computational literary studies. Their main advantage is the ease of further extension and adaptation to different research contexts and disciplinary knowledge. Combined with an extensive balancing procedure, this will overcome the criticisms of ahistoricism and disregard of socio-cultural determinants directed at the computational analysis of literary texts, while ensuring the relevance and comparability of the results.\\n\\nThe released resource is the first phase of a larger project. In the next iterations, we will expand the corpus to include historical novels (with a plot time before 1815). We will rebalance the corpus according to the length of the novels. We also plan to extend the metadata, in particular through NLP-based enrichment. First, we will use a combination of supervised and unsupervised approaches to determine the thematic content of each text. For this purpose, we have proposed a solution that uses a crowdsourced dataset consisting of texts labeled with literary motifs by volunteers, and enhances data quality through expert validation. By exploring how different results meet the needs of both researchers and bibliographers, we will select the optimal model.\\n\\nThe biggest task, however, will be the development of the Text Corpora Ontology (TCO), which has been initiated in parallel with the 19/20MetaPNC corpus. TCO will be tailored for the publication of text corpora within a Semantic Web environment, identifying objects and their bibliographic relations across written documents such as books, journal articles, and conference papers. TCO will also help to represent crucial corpus creation attributes like balance, representativeness, and relevance. TCO will integrate existing ontologies such as schema.org, FOAF, BiRO, FaBiO.\\n\\nFuture work on the Text Corpora Ontology will focus on diversifying the representation of text corpora metadata: structurally, content-oriented, and encompassing research questions related to the corpora. This aims to standardize metadata representation, encapsulate document content, and integrate research inquiries within the ontology, facilitating a more comprehensive analysis of text corpora in a web environment.\\n\\n5 http://xmlns.com/foaf/0.1/\\n6 https://sparontologies.github.io/biro/current/biro.html\\n7 https://sparontologies.github.io/fabio/current/fabio.html\"}"}
{"id": "lrec-2024-main-1500", "page_num": 10, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"7. Bibliographical References\\n\\nPaul Baker. 2010. Research Methods in Linguistics, chapter Corpus Linguistics. Continuum, London.\\n\\nDouglas Biber. 1990. Methodological Issues Regarding Corpus-based Analyses of Linguistic Variation. Literary and Linguistic Computing, 5(4):257\u2013269.\\n\\nDouglas Biber. 1993. Representativeness in Corpus Design. Literary and Linguistic Computing, 8(4):243\u2013257.\\n\\nDavide Buscaldi. 2011. Approaches to Disambiguating Toponyms. SIGSPATIAL Special, 3(2):16\u201319.\\n\\nSai Deng. 2010. Optimizing Workflow through Metadata Repurposing and Batch Processing. Journal of Library Metadata, 10(4):219\u2013237.\\n\\nKatrien Depuydt and Hennie Brugman. 2019. Turning Digitised Material into a Diachronic Corpus: Metadata Challenges in the NederLab Project. In Proceedings of the 3rd International Conference on Digital Access to Textual Cultural Heritage, Digital Access to Textual Cultural Heritage (DATeCH 2019), pages 169\u2013173, New York, NY, USA. Association for Computing Machinery.\\n\\nCurdin Derungs and Ross S. Purves. 2014. From Text to Landscape: Locating, Identifying and Mapping the Use of Landscape Features in a Swiss Alpine Corpus. International Journal of Geographical Information Science, 28(6):1272\u20131293.\\n\\nKacper Dudzic, Filip Gralinski, Krzysztof Jassem, Marek Kubis, and Piotr Wierzchon. 2024. Two Approaches to Diachronic Normalization of Polish Texts. In Proceedings of the 8th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2024), pages 207\u2013212, St. Julians, Malta. Association for Computational Linguistics.\\n\\nThomas Egan. 2019. Non-representativeness in Corpora: Perils, Pitfalls and Challenges. CogniTextes, 19. http://journals.openedition.org/cognitextes/1772. Accessed: 2023-10-17.\\n\\nMuriel Foulonneau and Timothy W. Cole. 2005. Strategies for Reprocessing Aggregated Metadata. In International Conference on Theory and Practice of Digital Libraries, pages 290\u2013301, Berlin, Heidelberg. Springer.\\n\\nNelson W. Francis. 1982. Problems of Assembling and Computerizing Large Corpora. In S. Johansson, editor, Computer Corpora in English Language Research, pages 7\u201324. Norwegian Computing Centre for the Humanities.\\n\\nAndrew Frank and Christine Ivanovic. 2018. Building Literary Corpora for Computational Literary Analysis \u2013 A Prototype to Bridge the Gap between CL and DH. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).\\n\\nFrancesca Frontini, Carmen Brando, Joanna Byszuk, Ioana Galleron, Diana Santos, and Ranka Stankovi\u0107. 2020. Named Entity Recognition for Distant Reading in ELTeC. In CLARIN Annual Conference 2020, Virtual Event, France.\\n\\nEvelyn Gius, Svenja Guhr, and Inna Uglanova. 2021. \u201cd-prose 1870\u20131920\u201d a collection of German Prose Texts from 1870 to 1920. Journal of Open Humanities Data, 7:11.\\n\\nEvelyn Gius, Katharina Kr\u00fcger, and Carla S\u00f6kefeld. 2019. Korpuserstellung als literaturwissenschaftliche Aufgabe. In DHd 2019 Digital Humanities: Multimedial & Multimodal Abstracts, pages 164\u2013166, Frankfurt am Main and Mainz.\\n\\nRobert L. G\u00f3rski. 2008. Charakterystyka Chronologiczna i Stylistyczna Korpusu dla \u201cWielkiego S\u0142ownika J\u0119zyka Polskiego\u201d. In P. \u017bmigrodzki and R. Przybylska, editors, Nowe Studia Leksyko-Graficzne, pages 117\u2013127. Lexis.\\n\\nStefan Th. Gries. 2009. Quantitative Corpus Linguistics with R. A Practical Introduction. Routledge, New York.\\n\\nAngus Grieve-Smith. 2010. Building a Representative Theater Corpus. A Broader View of Nineteenth-Century French. FRANTEXT\u2019s Corpus of Nineteenth-Century French. Palgrave Pivot, Cham.\\n\\nW\u0142odzimierz Gruszczy\u0144ski, Dorota Adamiec, Renata Bronikowska, Witold Kiera\u015b, Emanuel Modrzejewski, Aleksandra Wieczorek, and Marcin Woli\u0144ski. 2022. The Electronic Corpus of 17th- and 18th-century Polish Texts. Language Resources and Evaluation, 56(1):309\u2013332.\\n\\nW\u0142odzimierz Gruszczy\u0144ski, Dorota Adamiec, Renata Bronikowska, and Aleksandra Wieczorek. 2020. Elektroniczny korpus tekst\u00f3w polskich z XVII i XVIII w.\u2013 Problemy Teoretyczne i Warsztatowe. Poradnik J\u0119zykowy, 777(8):32\u201351.\\n\\nSusan Hunston. 2008. Collection Strategies and Design Decisions. In A. Ludeling and M. Kyto, editors, Corpus Linguistics: An International Handbook, volume 1, pages 154\u2013168. De Gruyter.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 11, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Krzysztof Jassem, Filip Grali\u0144ski, and Tomasz Obr\u0119bski. 2017. Pros and Cons of Normalizing Text with Thrax. In Proceedings of 8th Language & Technology Conference, pages 230\u2013235.\\n\\nGard B. Jenset and Barbara McGillivray. 2017. Methodological challenges in historical linguistics. In Quantitative Historical Linguistics: A Corpus Framework, pages 1\u201335. Oxford University Press, Oxford.\\n\\nJacob Jett. 2015. Modeling worksets in the hathitrust research center. CIRSS Technical Report WCSA0715. University of Illinois at Urbana-Champaign.\\n\\nJacob Jett, Timothy W. Cole, Christopher Maden, and J. Stephen Downie. 2016. The hathitrust research center workset ontology: A descriptive framework for non-consumptive research collections. Journal of Open Humanities Data, 2:e1.\\n\\nEl\u017cbieta Kaczynska. 1970. Dzieje robotnik\u00f3w przemys\u0142owych w Polsce pod zaborami. Warszawa.\\n\\nAgnieszka Karli\u0144ska, Cezary Rosi\u0144ski, Jan Wi\u0119czorek, Patryk Hubar, Jan Koco\u0144, Marek Kubis, Stanis\u0142aw Wo\u017aniak, Arkadiusz Margraf, and Wiktor Walentynowicz. 2022. Towards a contextualised spatial-diachronic history of literature: mapping emotional representations of the city and the country in Polish fiction from 1864 to 1939. In Proceedings of the 6th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 115\u2013125, Gyeongju, Republic of Korea. International Conference on Computational Linguistics.\\n\\nGraeme Kennedy. 1998. An Introduction to Corpus Linguistics. Longman, London.\\n\\nMarek Kubis. 2021. Quantitative analysis of character networks in Polish 19th- and 20th-century novels. Digital Scholarship in the Humanities, 36(Supplement 2):ii175\u2013ii181.\\n\\nGeoffrey Leech. 2007. Corpus Linguistics and the Web, chapter New resources, or just better old ones? The Holy Grail of representativeness. Brill, Leiden, The Netherlands.\\n\\nDavid Lindemann. 2022. LOD-ification of bibliographical data using free software: CLB-LODwibibase. Mutual Learning Workshop for Improving Cultural Heritage Bibliographical Data, Prague.\\n\\nDavid Lindemann, Christiane Klaes, and Penny Labropoulou. 2023. Bibliodata LODification using free software. DH2023 Collaboration as Opportunity, Graz.\\n\\nMicha\u0142 Marci\u0144czuk and Jarema Radom. 2021. A single-run recognition of nested named entities with transformers. Procedia Computer Science, 192:291\u2013297.\\n\\nMicha\u0142 Marci\u0144czuk, Jan Koco\u0144, and Micha\u0142 Gawor. 2018. Recognition of named entities for polish-comparison of deep learning and conditional random fields approaches. In Proceedings of the PolEval 2018 Workshop, pages 77\u201392. Institute of Computer Science, Polish Academy of Science.\\n\\nLukas Schlagenhauf. 2004. Challenges in modelling a richly annotated diachronic corpus of german. In Workshop on XML-based Richly Annotated Corpora.\\n\\nChristof Sch\u00f6ch, Roxana Patras, Toma\u017e Erjavec, and Diana Santos. 2021. Creating the European Literary Text Collection (ELTeC): Challenges and Perspectives. Modern Languages Open, (1):25.\\n\\nTed Underwood. 2016. The real problem with distant reading (blog). https://tedunderwood.com/2016/05/29/the-real-problem-with-distant-reading/. Accessed: 2023-10-17.\\n\\nELTeC. 2021. Polish novel collection (ELTeC-pol). Ed. by Joanna Byszuk. COST Action Distant Reading for European Literary History.\\n\\nBerenike Herrmann and Gerhard Lauer. 2020. Kolimo. a corpus of literary modernism for comparative analysis. https://kolimo.uni-goettingen.de/about. Accessed: 2023-10-10.\\n\\nModern Poland Foundation. 2022. About the Project. https://wolnelektury.pl/info/o-projekcie/. Accessed: 2023-10-10.\\n\\nNational Library of Poland. 2022. About Polona Website. https://polona.pl/page/about-polona/. Accessed: 2023-10-10.\\n\\nWikimedia Foundation. 2022. About Wikisource. https://wikisource.org/wiki/Wikisource:About_Wikisource. Accessed: 2023-10-10.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 12, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"As a result of preliminary work on the Text Corpora Ontology (TCO), we have distinguished the following classes:\\n\\n1. a single text (tco:Text)\\n2. the entities responsible for the single text, in particular persons (tco:Person)\\n3. places of publication and other locations relevant to the balance of the corpus (tco:Place and tco:Partition)\\n4. time periods, in particular literary epochs (tco:Epoch)\\n5. a general Corpus class (tco:Corpus), representing a single set of texts\\n\\nThe attributes of the individual classes comprising the ontology not only enable the description of basic bibliographic information, such as title, authorship, and place of publication, but also include attributes important to the process of corpus construction. These latter attributes have been identified based on an extensive analysis of existing text collections and their respective construction principles. For individual classes, these attributes might encompass:\\n\\n1. foaf:gender and schema:birthPlace for tco:Person class\\n2. tco:numberOfReissues, tco:numberOfTokens, and location of the place of publication in a particular partition (tco:inPartition) for tco:Text class\\n3. information on the literary period within which the text included in the corpus was written (tco:inEpoch)\\n\\nEach class instance can be further extended with external identifiers (owl:sameAs), and individual documents can contain direct references to full-text files (schema:contentUrl).\\n\\nB. Implementation of literary corpus creation workflow\\n\\nThe proposed workflow for the creation and reuse of a meta-corpus represents a generalization of our experience in creating the 19/20MetaPNC corpus. To illustrate this connection, an overview of the subsequent stages of the workflow and their implementation in 19/20MetaPNC is presented in Tab. 3.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 13, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Table 3: Literary corpus creation workflow implementation in 19/20MetaPNC\\n\\nStage 19/20MetaPNC Implementation\\n\\nResearch question-based design\\n\\n\u2022 The overall research goal was to trace the impact of historical and spatial factors on the dynamics of literary processes.\\n\u2022 Specific research questions were formulated, focusing on the emotional polarization of literary images of the city and the country in Polish prose of the turn of the 20th century.\\n\u2022 In order to achieve the research goal and answer the questions posed, the target population was defined, along with criteria for text inclusion (i.e., novels originally written in Polish and published between 1864 and 1939, with the time of the plot later than 1815), metadata schema, and balancing criteria.\\n\\nData collection and reuse\\n\\n\u2022 Four open collections of 19th and 20th-century Polish prose are reused:\\n  \u2013 ELTeC corpus (ELTeC, 2021),\\n  \u2013 Wolne Lektury (Modern Poland Foundation, 2022),\\n  \u2013 Wikisource (Wikimedia Foundation, 2022),\\n  \u2013 Polona (National Library of Poland, 2022).\\n\\nData evaluation and preprocessing\\n\\n\u2022 The most frequent categories of OCR errors found in Polona texts are automatically fixed.\\n\u2022 The spelling of texts from Wikisource and Polona is modernized with the use of a diachronic normalizer.\\n\u2022 Punctuation and hyphenation are normalized.\\n\u2022 A common data format is introduced.\\n\\nNLP-based enrichment\\n\\n\u2022 The locations in the novel were tagged using PolDeepNer2, one of the latest and most effective NER tools for the Polish language (Marci\u0144czuk et al., 2018; Marci\u0144czuk and Radom, 2021).\\n\u2022 NLP techniques were applied as part of a four-stage toponym disambiguation workflow to identify and standardize geographical entities.\\n\u2022 A combination of supervised and unsupervised approaches will be used to determine the subject matter of the novel.\\n\\nPIDs and LOD enrichment\\n\\n\u2022 Automatic metadata enrichment was performed using the services of the National Library of Poland, VIAF, Wikidata, and Geonames. The following metadata were obtained: author's PID, place of birth, gender, and place of publication PID. Coordinates were determined for both types of places.\\n\u2022 A four-stage toponym disambiguation workflow assigned records from the Geonames database to geo-entities identified as settings in the texts of the novels.\"}"}
{"id": "lrec-2024-main-1500", "page_num": 14, "content": "{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Stage 19/20MetaPNC Implementation\\n\\nMetadata verification and completion\\n\\n- Semi-automatic metadata verification was conducted to ensure that the collected texts met the corpus design criteria, particularly:\\n  - First edition dates were verified.\\n  - Original language was confirmed.\\n  - Genre was verified.\\n  - Authors' names and gender were verified, taking into account the use of pseudonyms.\\n\\n- As a result of automatic and manual work, information on the literary period, the assignment to the partition on the basis of the place of publication, and the time of the novel's action (before or after 1815) was completed.\\n\\nBalancing\\n\\n- The corpus was balanced historically and geographically based on the date and place of publication.\\n- Additionally, balancing considered the gender of the authors and the level of reception, determined by the number of reprints of each publication.\\n- The minimum and maximum share of a particular text class in the corpus were determined.\\n- Further rebalancing of the corpus will be conducted based on the length of the novels.\\n\\nSemantic environment and ontology building\\n\\n- The entire metadata collection is stored in the form of a knowledge graph.\\n- RDF format is employed for interoperability and to provide a structured framework for conducting computational literary studies.\\n- Neo4J graph database is used for exploration, visualization and answering complex queries.\\n\\nPublishing\\n\\n- The meta corpus is published in a public GitHub repository.\\n- The source texts are referenced in the knowledge graph by RDF triples that point to direct download links.\\n- Python scripts for simplifying 19/20MetaPNC processing are provided in the GitHub repository.\"}"}
