[
  {
    "id": "01I55gys19-rubric-4",
    "token_usage": {
      "prompt_tokens": 14626,
      "completion_tokens": 429,
      "total_tokens": 15055
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description or indication that multiple human experts were involved in annotating the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention annotation by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence is presented to show that multiple human non-expert annotators labeled the data."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention that an AI model was used for annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation done solely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description that dataset annotation is performed by an automatic process or simulation that is not an AI model."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper uses existing publicly available datasets (e.g., ImageNet1K, CalTech101, CIFAR100, etc.) and subsets thereof for experiments. No new dataset with original annotation is introduced, and no data annotation process is described for any new datasets. The focus is on benchmarking and forming subsets from existing datasets without modifying or annotating data."
          }
        }
      }
    ]
  },
  {
    "id": "0SMhqvgHST-rubric-4",
    "token_usage": {
      "prompt_tokens": 31965,
      "completion_tokens": 336,
      "total_tokens": 32301
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was conducted by a single human expert for any new datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper about data annotation performed by multiple human experts for any new datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation conducted by a single human non-expert for new datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information provided regarding data annotation by multiple non-expert human annotators for new datasets."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention the use of AI models with human verification for data annotation of the new datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that AI models without verification were used for data annotation in the new datasets."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any simulation or automatic non-AI annotation process for new datasets."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper does not introduce any new datasets requiring manual annotation. Instead, it employs existing publicly available benchmark datasets. The datasets are used as provided, with no description or evidence of new annotation processes conducted by the authors. Hence, no data annotation is applied or documented for new datasets introduced by the authors."
          }
        }
      }
    ]
  },
  {
    "id": "2HzZIDo48o-rubric-4",
    "token_usage": {
      "prompt_tokens": 22450,
      "completion_tokens": 385,
      "total_tokens": 22835
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper of an AI model performing data annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper of an AI model performing data annotation without any verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3: Symbolic Behaviour Benchmark; Section 3.1: Symbolic Continuous Stimulus representation; Section 3.2: Meta-Referential Games",
            "reasoning": "The dataset used in the benchmark is synthetically generated by a fully automatic, simulation-like process. The paper describes the Symbolic Continuous Stimulus representation, which synthetically generates stimuli via sampling continuous Gaussian kernels according to semantic structures. The Meta-Referential Games framework generates many differently semantically structured symbolic spaces in a domain-agnostic way, yielding datasets automatically per episode without human intervention. Thus, data annotation is automatically done by this simulation/automatic process that is not an AI model."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "A dataset and stimuli are generated automatically; hence data annotation is present but performed automatically."
          }
        }
      }
    ]
  },
  {
    "id": "2myGfVgfva-rubric-4",
    "token_usage": {
      "prompt_tokens": 18318,
      "completion_tokens": 450,
      "total_tokens": 18768
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation performed by a single human annotator with subject matter expertise."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human experts performed the annotations. The paper focuses on using AI models for caption generation rather than human expert annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention annotation by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mentioned use of multiple non-expert human annotators for dataset annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any human verification steps following automatic annotation by AI models."
          },
          "AI Model without Verification": {
            "is_applicable": true,
            "reference": "Section 3.4 Video Captioning",
            "reasoning": "The paper details that GPT-4V, a state-of-the-art vision language model, was used to generate detailed structured captions for videos after an initial short caption generated by Panda-70M. There is no mention of human verification of these AI-generated captions, indicating that data annotation was performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation involves AI vision-language models (GPT-4V and Panda-70M) rather than fully automatic processes or simulations that are not AI-based."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is explicitly described and performed using AI models, so the annotation process is documented."
          }
        }
      }
    ]
  },
  {
    "id": "4S8agvKjle-rubric-4",
    "token_usage": {
      "prompt_tokens": 36718,
      "completion_tokens": 392,
      "total_tokens": 37110
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper mentions human annotation and verification by multiple annotators, but does not specify that data annotation was conducted by a single expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Annotation Verification and Metric Justification; Appendix J Data Quality Control; Appendix A Author Contributions",
            "reasoning": "The paper reports that data for task examples and progress rate annotation was collected and annotated with one person in charge and verified by at least two others, indicating multiple human annotators were involved. Additionally, multiple rounds of verification with multiple annotators and discussions were conducted to ensure annotation quality, showing data annotation and verification involved multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that data annotation was conducted by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators involved are described as authors and graduate students, implying subject matter expertise relevant to the tasks, so annotators are not non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "Appendix B Limitations",
            "reasoning": "The paper mentions considering use of LLMs for annotation in the future but current models underperform and cannot accurately generate subgoals, so current annotation is not done by AI model with verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that annotation is done by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that annotation is automatically done by a simulation or automatic process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents the data annotation process involving human annotation and verification; thus, data annotation is applied and documented."
          }
        }
      }
    ]
  },
  {
    "id": "5WFzk0H27p-rubric-4",
    "token_usage": {
      "prompt_tokens": 18440,
      "completion_tokens": 424,
      "total_tokens": 18864
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset involved multiple contributors; no indication that annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "Section 2.1, 2.4; Datasheet A.3 Data Collection Process",
            "reasoning": "The contributors are many (20,000 users) and mostly volunteers motivated by science enthusiasm, but the paper does not mention that they are subject matter experts or members of the target demographic. The contributors are described as heavily biased towards science enthusiasts but no explicit expert status is stated."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is not done by a single human annotator; rather, there are multiple contributors."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Sections 2.1, 2.4, Datasheet A.3",
            "reasoning": "The dataset is annotated by multiple human contributors (20,000 users) who are volunteers recruited organically and motivated mainly by interest in contributing to a democratic AI governance project. The paper states the contributors are mostly science enthusiasts but does not indicate expertise in all the domains of videos judged, and in fact acknowledges biases and noise due to human judgments (Section 3.3, 3.4). Thus, annotators are treated as non-expert humans participating in pairwise comparisons."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is not performed by an AI model with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that an AI model annotated the data without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is not automatic or done by simulation; it is human comparative judgments collected via a platform."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described as humans providing pairwise comparative judgments. Therefore, annotation is applied and documented."
          }
        }
      }
    ]
  },
  {
    "id": "5c1hh8AeHv-rubric-4",
    "token_usage": {
      "prompt_tokens": 103496,
      "completion_tokens": 413,
      "total_tokens": 103909
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any details indicating that multiple human experts performed data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that data annotation was performed by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe the use of multiple non-expert human annotators for data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Appendix C.2.1, Appendix C.2.3, Appendix F.1.1",
            "reasoning": "The authors frequently use GPT-4 for generating new queries, reforming datasets, generating prompts, and especially for judging or verifying model outputs, such as assessing stereotype presence, correctness of answers, and refusal detection. This implies that AI models (GPT-4) are used with verification roles in data generation and annotation processes."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "All AI model annotations described in the paper include verification steps using GPT-4 or other human-like evaluators; no mention of unverified AI annotations."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.2, Appendix B.2, Appendix G Data Sheet",
            "reasoning": "The paper states that data was constructed or adapted automatically via GPT-4V, Stable Diffusion, and other generative models for synthesizing images and prompts. Some datasets are synthesized and automatically generated without explicit verification, indicating automatic annotation by simulation or automatic processes not involving human annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Many tasks involved deliberate data construction, adaptation, or synthesis; thus, data annotation is present and documented."
          }
        }
      }
    ]
  },
  {
    "id": "67N3FWoDtU-rubric-4",
    "token_usage": {
      "prompt_tokens": 18223,
      "completion_tokens": 315,
      "total_tokens": 18538
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset was annotated by multiple annotators, not a single individual."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3, paragraphs 1 and 2; Abstract",
            "reasoning": "The paper states that eleven student assistants with a background in history annotated the dataset, contributing more than 1,500 hours of expert annotation work. These annotators are domain experts related to the historical newspapers, indicating multiple human experts performed the annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation was performed by multiple annotators with subject matter expertise, not a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotators are described as history students and domain experts, so they are not non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that annotations were generated by AI with subsequent human verification. The annotations are described as manually performed by experts."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence that AI alone performed data annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is manual by human experts; no automatic or simulated annotation process described."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents an extensive manual annotation process by multiple expert annotators."
          }
        }
      }
    ]
  },
  {
    "id": "6cCFK69vJI-rubric-4",
    "token_usage": {
      "prompt_tokens": 22979,
      "completion_tokens": 342,
      "total_tokens": 23321
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information that multiple human experts performed annotation or labeling."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that a single non-expert annotated the data."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of multiple non-expert human annotators involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any use of AI models for annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description that AI models annotated the data without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Collection Process",
            "reasoning": "The annotation of timeseries data labels using the Brick schema is described as a process performed by creating semantic building models using expert engineers to map building details to Brick classes, and the data collection was via automated connection to building management systems, ingesting timeseries data through an automated platform. Annotation is effectively an automatic or semi-automatic process facilitated by the Data Clearing House platform tooling, involving established ontologies and semantic models rather than manual labeling per se."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset contains timeseries data that are linked to Brick schema labels; therefore, some annotation or labeling process is applied and documented."
          }
        }
      }
    ]
  },
  {
    "id": "7TCK0aBL1C-rubric-4",
    "token_usage": {
      "prompt_tokens": 17986,
      "completion_tokens": 248,
      "total_tokens": 18234
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 4, Data collection and annotation process",
            "reasoning": "The paper states that the dataset creation required significant domain knowledge and deep understanding of cloud services, HCL, and Rego languages which are complex and not familiar to regular developers. The authors mention that their team includes experts who have been using IaC for years and that the infrastructure intent specifications were crafted by human experts. This indicates that annotation and specification were performed by subject matter experts, typically singular or at least by a dedicated expert team, not multiple non-experts or automated processes."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": ""
          }
        }
      }
    ]
  },
  {
    "id": "9tVn4f8aJO-rubric-4",
    "token_usage": {
      "prompt_tokens": 42764,
      "completion_tokens": 444,
      "total_tokens": 43208
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Appendix A.1 (sections describing individual datasets such as SLAKE, VQARAD, PATHVQA)",
            "reasoning": "Several datasets, especially in specialized domains like healthcare (e.g., SLAKE, VQARAD, PATHVQA), mention that annotations were performed by experienced physicians and medical experts. This indicates annotation was done by single human experts known for each dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Appendix A.1, e.g., HATEFUL MEMES, WINOGROUND, VCR",
            "reasoning": "Datasets like HATEFUL MEMES and WINOGROUND specify annotation by multiple expert annotators or crowdworkers with instructions, implying multiple human experts contributed to the annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No explicit evidence that any dataset was annotated by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Appendix A.1 (e.g., MAGIC BRUSH, MEMECAP, MEMOTION, ENRICO)",
            "reasoning": "Datasets like MAGIC BRUSH and MEMECAP employed crowdsourcing platforms such as Amazon Mechanical Turk (AMT) for annotation, indicating multiple human non-expert annotators involved in annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description in the paper of datasets annotated by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of datasets annotated by AI models without human verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Appendix A.1 (e.g., PATHVQA, Visual Genome, NLVR)",
            "reasoning": "Some datasets like PATHVQA generated question-answer pairs automatically using pipelines or simulations, and others like Visual Genome used automatic methods for object and relationship annotation, implying automatic annotation processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "All datasets have some annotation process either documented or referenced in the appendix."
          }
        }
      }
    ]
  },
  {
    "id": "AdpSHMOujG-rubric-4",
    "token_usage": {
      "prompt_tokens": 18469,
      "completion_tokens": 405,
      "total_tokens": 18874
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not specify that annotation was conducted by a single human annotator, nor does it mention any subject matter expert annotator for the benchmark."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 4 (Data collection and annotation) and Appendix H (Benchmark annotation strategy and points selection)",
            "reasoning": "The benchmark annotation was performed by human annotators who manually selected points representing material states with emphasis on accurate sampling, complex cases, and verified by a second annotator for crosschecking. Although specific titles are not given, the detailed annotation process and the crosschecking imply multiple human annotators with expertise or experience relevant to material identification."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence in the paper that annotation was performed by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that non-expert multiple annotators conducted the annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention an AI model performing annotation with human verification for the benchmark."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication of an AI model performing data annotation without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 and 3.2 (Data generation: patterns extraction and infusion)",
            "reasoning": "The synthetic data used for training the model and generating annotations for synthetic scenes is automatically generated by a simulation and automatic process that is not an AI model. The materials and segmentations in synthetic scenes are automatically produced via UV mapping, physics-based rendering, and procedural processes without manual annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is documented and described for the benchmark dataset."
          }
        }
      }
    ]
  },
  {
    "id": "BZe6dmDk5K-rubric-4",
    "token_usage": {
      "prompt_tokens": 35729,
      "completion_tokens": 476,
      "total_tokens": 36205
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes data annotation collected from multiple participants (54 recruited, 48 qualified) who performed subjective evaluations on 9,180 videos. There is no indication that the annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "Section 3.3 Subjective Action Quality Assessment and Appendix A.2 Ethical Discussions of Data Collection",
            "reasoning": "The paper indicates that while participants underwent expert review and eligibility testing including agreement to expert ratings (Section 3.3), they do not state that all participants were subject matter experts. The participants included a mixture of backgrounds and levels of experience with AI. Thus, while expert review was involved in instruction and scoring consistency, the annotators themselves are not explicitly described as experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation was conducted by multiple participants, not a single annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.3 Subjective Action Quality Assessment, Table 3, and Appendix A.2 Ethical Discussions of Data Collection",
            "reasoning": "The dataset annotations were collected from 54 human participants, reduced to 48 qualified annotators after eligibility tests. Participants included a mixture of backgrounds and levels of experience with AI tools; there is no indication that they were domain experts or subject matter experts. The paper explicitly discusses recruitment and describes that the ratings were collected from multiple humans who are not experts in a traditional domain sense but were guided by expert reviews to ensure consistency. Therefore, the annotations were performed by multiple human non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description in the paper indicates that AI models were used for annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any AI model performing annotations without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No automatic or simulation process was used for annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly states that extensive human annotation was performed for the GAIA dataset in multiple dimensions, so annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "D1MOK2t2t2-rubric-4",
    "token_usage": {
      "prompt_tokens": 13332,
      "completion_tokens": 580,
      "total_tokens": 13912
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 3.1 Demonstrations Dataset; Section 3.2 Evaluation Dataset",
            "reasoning": "The Demonstrations Dataset consists of nearly 14,000 videos of labeled Minecraft gameplay performed by human players who are referred to as experienced data collectors, implying subject matter expertise. The Evaluation Dataset was labeled by 65 unique human annotators (MTurk workers) who provided detailed pairwise comparisons and justifications, showing they performed human evaluations with some level of task understanding. The authors refer to two human experts as agents in the evaluation dataset (Section 5.2), indicating at least some annotators have subject matter expertise."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Demonstrations Dataset; Section 3.2 Evaluation Dataset",
            "reasoning": "Multiple human demonstrators collected the demonstration data (Section 3.1), indicating multiple experts provided annotations. Additionally, 65 unique human evaluators (MTurk workers) provided the extensive pairwise human evaluations in the Evaluation Dataset (Section 3.2), showing annotation by multiple human annotators with some task-relevant expertise or familiarity."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that a single non-expert conducted annotations."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While many MTurk workers performed human evaluations, the paper does not indicate that they are non-experts; and the data collectors for demonstrations are described as experienced, implying expertise. Therefore, it cannot be concluded annotation was by non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The datasets are described as collected by human demonstrations and human evaluations only. No mention is made of AI model produced labels with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of data annotation performed solely by AI models without verification is present."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations are not generated automatically or by simulation; demonstrations and evaluations are from human players and human annotators, respectively."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper explicitly describes human annotation processes for both demonstration collection and evaluation comparisons."
          }
        }
      }
    ]
  },
  {
    "id": "DFr5hteojx-rubric-4",
    "token_usage": {
      "prompt_tokens": 94274,
      "completion_tokens": 511,
      "total_tokens": 94785
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset was collected from multiple human participants recruited via the Prolific platform, who provided their own ratings and feedback in real-time conversations with large language models. There is no indication that the feedback was annotated or labeled by a single human expert; rather, it was collected from a diverse participant pool."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While multiple human annotators participated by interacting with LLMs and providing feedback, there is no indication they were subject matter experts or belonged to the target demographic in an expert capacity. The participants were crowdworkers recruited from Prolific, and no specialized expertise is mentioned for the annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotations or feedback were collected from a large number (1,500) of participants, so not a single human annotator. The participants are general crowdworkers, so non-experts in terms of annotation, but the process is not done by a single human."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 2, Section B.3, Section B.4 of the appendices and throughout the paper discussing participant recruitment and annotation process",
            "reasoning": "The data annotation in the PRISM dataset was carried out by multiple human annotators who are non-experts, specifically 1,500 diverse crowdworkers recruited through Prolific. These participants engaged in surveys and conversations with LLMs, providing ratings and qualitative feedback. The annotators include a broad demographic without specified subject matter expertise, indicating multiple human non-expert annotators performed the annotation. This is documented in Section 2 of the main paper and detailed further in the appendices (B.3, B.4) related to participant demographics and annotation procedures."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations were directly from human participants, not performed by AI models with verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations were directly from human participants, no evidence of AI-only annotation."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No automatic annotation or simulation process was used for data annotation, but rather collected from human participants."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset is based on human participants providing feedback, so data annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "DJVyRhT8nP-rubric-4",
    "token_usage": {
      "prompt_tokens": 29113,
      "completion_tokens": 482,
      "total_tokens": 29595
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention data annotation by a single human expert for any of the newly introduced datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 2.1 \"HAPS Dataset\" and Appendix B.1",
            "reasoning": "The Human Activity and Pose Simulation (HAPS) dataset was created with human surveys involving 50 participants from diverse demographics who evaluated and selected human activity descriptions based on three criteria (high relevance, verb-rich interaction, and conformity to daily life). This indicates involvement of multiple human annotators with some expertise or belonging to target demographics, thus qualifying as multiple human experts contributing to annotation quality and validation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of single non-expert annotator involvement in dataset annotation is provided."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that multiple non-expert annotators conducted the data annotation; rather, expert human surveys were used for validation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.1 \"HAPS Dataset\"",
            "reasoning": "Human activity descriptions were converted into 3D human motion models using the Motion Diffusion Model (MDM), an AI model, and subsequently validated through human surveys and quality control using GPT-4. This signifies that an AI model generated annotations which were verified by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly mentions human verification of AI-generated annotations; thus, AI annotation without verification does not apply."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.1 \"Human Activity Annotation\" and \"Agent-Environment Interaction\"",
            "reasoning": "The placement and configuration of human motion models within the 3D environments were performed using an interactive annotation tool with automated sampling and spatial estimation processes. Additionally, the HA3D simulator automatically integrates human activity data and renders dynamic scenes, indicating that parts of the annotation process were conducted automatically through simulation and algorithmic methods."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents annotation processes for the new datasets (HAPS and HA-R2R), so no annotation is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "DjCSjizgsH-rubric-4",
    "token_usage": {
      "prompt_tokens": 17933,
      "completion_tokens": 498,
      "total_tokens": 18431
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not specify that data annotation was conducted by a single human annotator with subject matter expertise."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "Section 2.3 Data Annotation",
            "reasoning": "The paper mentions recruiting 20 annotators for labeling the real-world wildfire regions with three annotators cross-checking each mask, but does not specify that these annotators are subject matter experts or belong to the target demographic. Hence, expertise status is not confirmed."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation process involves multiple annotators, not a single annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 2.3 Data Annotation",
            "reasoning": "The paper states that 20 annotators were recruited to label wildfire regions on satellite images and that three annotators cross-checked each binary mask for quality. No information indicates that these annotators had expert wildfire knowledge, so we assume annotators are non-experts. Thus, data annotation was performed by multiple human non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description of AI model assisted annotation with human verification is given."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description indicates annotation was performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.2 Simulation Data",
            "reasoning": "The 1M simulated wildfire scenarios were generated automatically by simulators (FARSITE, WFDS, WRF-SFIRE) that produce binary masks of fire regions based on multi-modal environmental input. This simulation process produces annotation automatically without human intervention."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is applied and described in the paper."
          }
        }
      }
    ]
  },
  {
    "id": "E18kRXTGmV-rubric-4",
    "token_usage": {
      "prompt_tokens": 22229,
      "completion_tokens": 366,
      "total_tokens": 22595
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly states that the annotation was done by multiple annotators per Country-Language pair, not a single annotator."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 2.1 and 2.2",
            "reasoning": "The dataset annotation process involved multiple human annotators who were fluent speakers and familiar with the respective cultures for their assigned Country-Language pairs. Annotators were described as predominantly native speakers and cultural experts. Data was also validated by another annotator from the same Country-Language pair, confirming that multiple expert annotators were involved."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators were described as fluent speakers and cultural experts, indicating subject-matter expertise rather than non-expert status."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotators were fluent speakers and culturally knowledgeable individuals, thus considered experts, not non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of AI models being used to annotate or generate the data, nor any AI-assisted annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that AI models performed data annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was performed by human annotators; no automatic or simulation-based annotation process is described."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described in the paper (Sections 2.1 and 2.2) and involved human annotators, so this label does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "EADRzNJFn1-rubric-4",
    "token_usage": {
      "prompt_tokens": 30253,
      "completion_tokens": 429,
      "total_tokens": 30682
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert for the introduction or curation of the datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or mention of multiple human experts annotating the dataset; the datasets are gathered from public, existing data sources or collected automatically."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not state that a single non-expert human annotator was involved in the annotation process of the datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information or evidence is provided about multiple non-expert human annotators annotating the data."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention the use of AI models for annotation with human verification for these datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The datasets are described as collected from existing sources or via automatic processes, but there is no mention of AI models used for annotation without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4 Datasets and Appendix E Data Processing Details",
            "reasoning": "The paper indicates that the datasets are constructed by extracting data automatically from existing data sources (e.g., Wikidata, POLECAT, ICEWS, Github, Reddit, Myket app market), often involving filtering and processing scripts. For example, the political event datasets use outputs from NLP tools and transformer-based neural networks (Section 4, tkgl-polecat), and other datasets are extracted via Python scripts as detailed in Appendix E. The data annotation (e.g., coding of events) is done via automatic processes or derived directly from publicly available databases, not by human annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is applied via automatic extraction or NLP pipeline processing; thus, the label N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "FXTeJvHE0k-rubric-4",
    "token_usage": {
      "prompt_tokens": 17007,
      "completion_tokens": 332,
      "total_tokens": 17339
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information about data annotation being done by multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of any data annotation being performed by a single human non-expert in the paper."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No details are given about data annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation process involving AI models with human verification for the new dataset."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of data annotation solely performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention automatic annotation by simulation or automatic processes that are not AI models for the newly introduced dataset."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The new dataset introduced is derived from an existing dataset (OpenScene, a redistribution of nuPlan) and the paper does not document any data annotation process performed by the authors. The paper focuses on filtering and curating data and defining evaluation protocols rather than annotating new data. Hence, no data annotation process is considered present for the new dataset."
          }
        }
      }
    ]
  },
  {
    "id": "GHlJM45fWY-rubric-4",
    "token_usage": {
      "prompt_tokens": 22528,
      "completion_tokens": 453,
      "total_tokens": 22981
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 3.1 Species Observation Data - Presence-Absence (PA) surveys",
            "reasoning": "The presence-absence survey data were obtained by experienced botanists who exhaustively report the plant species in a small spatial plot, implying annotation by multiple expert human annotators who are subject matter experts."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Species Observation Data - Presence-Absence (PA) surveys",
            "reasoning": "The PA data originates from 29 source datasets hosted in the European Vegetation Archive (EVA) and involves multiple surveys conducted by expert botanists, indicating multiple human experts performed the annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of annotation by single human non-experts is provided."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence that multiple human non-experts performed the data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention the use of AI models with verification for data annotation."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that AI models were used without verification for data annotation."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The species observations derive from human-collected surveys and citizen-science platforms, not from automatic annotation or simulation processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is documented and described as being conducted by human experts (botanists) for PA data and citizen scientists for PO data."
          }
        }
      }
    ]
  },
  {
    "id": "HB5q6pC5eb-rubric-4",
    "token_usage": {
      "prompt_tokens": 25038,
      "completion_tokens": 430,
      "total_tokens": 25468
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not explicitly describe data annotation performed by a single human expert for the new dataset or perturbed data."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or description in the paper that multiple human experts performed the data annotation of the new perturbed datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation conducted by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence or mention that multiple non-expert human annotators were involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 and Section 4.1",
            "reasoning": "The content-level perturbation (knowledge-invariant paraphrasing) is generated by using an LLM rewriter to paraphrase questions sentence by sentence. To verify the knowledge invariance of the perturbations, the authors employ professional human volunteers and superior LLMs (e.g., claude-3-sonnet) as referees to rate the knowledge invariance scores. This indicates that the annotation/perturbation is performed by an AI model (LLM rewriter) with verification using human and LLM-based annotation verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper emphasizes verification of the AI-generated perturbations through human scoring and LLM referees; hence, annotation is not performed without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although the perturbations are generated automatically using LLMs, these are considered AI models rather than non-AI automatic processes or simulations. Therefore, this label does not apply."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents an annotation process for generating perturbed datasets via AI models and human/LLM verification, so N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "IZtX4RNBeH-rubric-4",
    "token_usage": {
      "prompt_tokens": 15077,
      "completion_tokens": 402,
      "total_tokens": 15479
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not explicitly state the human annotators to be subject matter experts or members of the target demographic. It only mentions 'two experienced human annotators' without further qualification."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2, Stage 1: Data collection and Annotation",
            "reasoning": "The paper states that two experienced human annotators were assigned to generate captions for each video, and they followed personalized annotation guidelines. The involvement of multiple annotators with experience suggests multiple human experts conducting annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that the annotation was performed by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper specifies that annotators were experienced; no evidence suggests multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2, Stage 2: Question-Answer Generation and Stage 3: QA Pairs Filtration",
            "reasoning": "The QA pairs were generated by the GPT-3.5 large language model, and subsequently, a manual filtration process with human assistance was employed to verify and correct the QA pairs. This indicates annotation was performed by an AI model with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that the AI-generated QA pairs were left without human verification; in fact, a manual filtration step was applied."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of automatic annotation by a simulation or automatic process that is not an AI model."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation is described and documented, involving both human annotators and AI model generation with human verification."
          }
        }
      }
    ]
  },
  {
    "id": "JU0QvhhfVp-rubric-4",
    "token_usage": {
      "prompt_tokens": 15646,
      "completion_tokens": 325,
      "total_tokens": 15971
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information in the paper describing involvement of multiple human experts in annotating the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation conducted by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence is provided about multiple non-expert human annotators performing data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset annotation does not involve AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that AI models solely performed annotation without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 and 3.2",
            "reasoning": "The morphological profiles of genes and compounds were extracted automatically using the CellProfiler software applying image processing pipelines with various normalization and preprocessing steps. Compound and gene annotations were collected by automatic aggregation from seven publicly available databases. No human annotation is described; all annotation and feature extraction steps are automatic processes or computational mappings."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents automatic extraction and aggregation processes for features and annotations, so it is not applicable that no data annotation is performed."
          }
        }
      }
    ]
  },
  {
    "id": "KZlJF8kguO-rubric-4",
    "token_usage": {
      "prompt_tokens": 25484,
      "completion_tokens": 540,
      "total_tokens": 26024
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Appendix A.1, Section 3, Section A.2",
            "reasoning": "The paper states that word onsets were manually annotated on spectrograms by trained annotators, and that part of speech tags and dependency parses were manually corrected by a single trained annotator over the course of a year. Speaker identity and scene labels were also manually annotated by an in-house expert. This indicates that at least for some annotations, a single human expert performed the manual correction work."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no explicit mention in the paper of multiple human experts performing data annotation or manual correction tasks. The manual corrections and annotations are attributed to trained annotators or a single trained annotator or an in-house expert, without evidence of multiple experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence or mention in the text indicates that any annotation was done by a single non-expert annotator. The annotations were performed by trained annotators or experts."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention using multiple non-expert annotators for annotations."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3 (Audio transcription and alignment), Appendix A.1",
            "reasoning": "The audio transcription pipeline first used commercial speech-to-text services to transcribe the audio tracks automatically, then trained annotators manually corrected those transcriptions. Similarly, automated syntactic parsing (Stanford NLP Stanza and GPT-2 surprisals) was followed by manual corrections. This workflow reflects AI model produced annotations with human verification and correction."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "All AI model generated annotations (automatic speech recognition and syntactic parsing) were manually verified and corrected by human annotators, as explicitly stated."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3, Appendix A.2",
            "reasoning": "Several features were extracted automatically, e.g., scene labels obtained via the Places365 schema, visual features (pixel brightness, optical flow, number of faces) extracted via OpenCV functions, auditory features extracted via librosa python package, and syntactic parsing and surprisal computed via Stanford NLP Stanza and GPT-2 models. These automatic processes were not AI annotation per se but automated feature extraction pipelines."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Clear evidence is provided describing the data annotation processes, so N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "L5aY1mWvXQ-rubric-4",
    "token_usage": {
      "prompt_tokens": 15731,
      "completion_tokens": 392,
      "total_tokens": 16123
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation process performed by a single human expert for the datasets involved."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or description in the paper that multiple human experts performed data annotation on the new datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper provides no information suggesting that a single non-expert human performed data annotation for the datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not document any data annotation by multiple non-expert humans on the datasets."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description or evidence of AI-based annotation with human verification is given for the data."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention using AI models to perform data annotation without verification for the introduced data."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 and Section 4 (Experiment and Datasets)",
            "reasoning": "The paper introduces techniques to create temporally distorted versions of the test splits of existing datasets via automatic, algorithmic processes (e.g., Algorithms 1 and 2 for INTENSE and SHUFFLE distortions). These distortions are generated automatically and are not human annotations or AI model annotations; rather, they are algorithmic transformations applied to existing datasets to create new test sets for analysis. Therefore, data annotation is automatic through these simulation-like processes rather than manual labeling."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents a process of creating new, temporally distorted datasets using automatic techniques; thus, data annotation in some form is present, ruling out N/A."
          }
        }
      }
    ]
  },
  {
    "id": "LdRZ9SFBku-rubric-4",
    "token_usage": {
      "prompt_tokens": 27056,
      "completion_tokens": 446,
      "total_tokens": 27502
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes manual reading and collecting of original news data for annotations by unspecified annotators but does not indicate that a single human expert performed all annotations."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "Section 3.2 Dataset Collection",
            "reasoning": "The dataset involves manual reading and collection of original news data for annotation, but there is no explicit mention of multiple human experts performing annotation or their expertise level."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that data annotation was conducted by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Dataset Collection",
            "reasoning": "The dataset collection involved manually reading each news item and collecting original data. Although not explicitly stated, this manual annotation process implies involvement of multiple human annotators without explicit specification of subject matter expertise, thus likely multiple human non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 Construction Pipeline for UKnow Protocol - Phase-1 Content Extraction",
            "reasoning": "Phase-1 involves using pre-trained models (AI models) for content extraction, which is a form of automated annotation. The paper also describes manual event annotations in Phase-3, implying some human verification or annotation alongside AI extraction."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While pre-trained models are used for content extraction, the paper indicates manual annotation steps, therefore the AI annotation is not without any verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Construction Pipeline for UKnow Protocol - Phase-1 Content Extraction",
            "reasoning": "Phase-1 employs pre-trained deep learning models to automatically extract useful information from images and texts, constituting an automatic annotation process that is not purely AI model predictions but automatic pre-processing steps."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly describes data annotation processes including manual annotation and AI-based content extraction, so annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "LdxNWDNvC3-rubric-4",
    "token_usage": {
      "prompt_tokens": 22135,
      "completion_tokens": 451,
      "total_tokens": 22586
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset annotation involves computational simulations and automatic procedures rather than manual annotation by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human experts manually annotated the dataset; annotations are based on simulations and automatic parameter calculations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence is provided that a single non-expert performed any manual annotations."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information suggests manual annotation by multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotations are generated by simulation tools and automatic calculations, not by AI models verified by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that AI models performed annotations without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 (Geometric and Aerodynamic Parameter Annotation Stage), Section 3.3 (Airfoil Filtering Stage), and Appendix G.2 (Collection Process)",
            "reasoning": "The aerodynamic annotations are computed via CFD simulation software (Xfoil) under multiple conditions, geometric parameters are calculated automatically using B-spline interpolation and PARSEC physical parameters, and low-quality samples are filtered using automatic numerical solvers. There is no mention of manual annotation; hence data annotation is conducted automatically by simulations and algorithms."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset includes annotation processes conducted automatically via simulation and calculation; therefore, annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "M32Ldpp4Oy-rubric-4",
    "token_usage": {
      "prompt_tokens": 34113,
      "completion_tokens": 366,
      "total_tokens": 34479
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation involving multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication in the paper that data annotation was conducted by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of data annotation involving multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation performed by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that data annotation was performed purely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 Simulation and Rendering; Section C Full Procedure of LogiCity Simulation; Algorithm 1: LogiCity Simulation",
            "reasoning": "The dataset is generated automatically through a simulation process based on configurable first-order logic rules, agent configurations, and urban maps. The annotations, such as predicate truth values and action labels, are automatically derived from the simulation environment using SMT solvers and pre-defined predicates. Rendering to RGB images is done via generative models, but the underlying annotations are generated by the simulation, an automatic process not involving AI annotation models or human annotators."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents data annotation processes performed automatically by the simulation; therefore, 'N/A' does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "MU2s9wwWLo-rubric-4",
    "token_usage": {
      "prompt_tokens": 28284,
      "completion_tokens": 527,
      "total_tokens": 28811
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that data annotation for the ConceptMix benchmark was conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not document that multiple human experts performed data annotation for the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that any single human non-expert performed the data annotation for the benchmark."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3 Human Evaluation; Appendix A Human Evaluation",
            "reasoning": "The dataset includes human evaluation performed by 10 participants including both experts and non-experts who annotate image-prompt alignment and answer detailed questions. This was done in the human evaluation stage (\u00a73) and detailed in Appendix A. The annotations were performed by multiple human non-experts and experts, indicating multiple annotators involved. However, their role is in human evaluation, not generation of the benchmark prompts or annotations per se."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.3 Compositional Prompt Generation; Section 2.4 Concept Evaluation; Section 3 Human Evaluation",
            "reasoning": "The primary prompt generation, concept binding, and prompt validation were performed automatically using GPT-4o, an AI model. The prompt rejection mechanism and grading system use GPT-4o to automatically generate and validate prompts and grade images. Human annotators were involved to validate the evaluation method, thus the AI model annotation is supported by human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly describes human evaluations to verify the AI-based grading and prompt validation; therefore, no unverified AI-only annotation is used."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.3 Compositional Prompt Generation; Section 2.4 Concept Evaluation",
            "reasoning": "The dataset's key annotation steps are done automatically by AI models and automated mechanisms: prompt generation is automated via GPT-4o with automated prompt rejection, and concept evaluation is conducted by GPT-4o visual question answering. This automatic generation and evaluation process is not considered an AI model without verification but an automatic process. Thus, the data annotation is done via automated AI pipeline with some human validation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The data annotation process is documented and performed via AI models and human evaluation; thus annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "Mbd3QxXjq5-rubric-4",
    "token_usage": {
      "prompt_tokens": 28854,
      "completion_tokens": 363,
      "total_tokens": 29217
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human experts annotated the data."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation performed by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is provided about multiple non-expert human annotators performing annotations."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset is generated entirely by an AI model (Mixtral) without mention of human verification of annotations."
          },
          "AI Model without Verification": {
            "is_applicable": true,
            "reference": "Section 2 Training Data Synthesis, Sections 2.1 - 2.2",
            "reasoning": "The OpenMathInstruct-1 dataset is synthetically generated by prompting the Mixtral open-source language model to produce solutions for math problems. The generation relies on few-shot prompting techniques and does not mention any human verification or correction of the AI-generated solutions. Solutions are filtered syntactically in post-processing, but no human verification is described, indicating AI model annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data synthesis involves use of a large language model (Mixtral), which is considered an AI model, not an automatic non-AI simulation process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents a detailed data generation process involving AI model synthesis of solutions, so data annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "OL2JQoO0kq-rubric-4",
    "token_usage": {
      "prompt_tokens": 23921,
      "completion_tokens": 391,
      "total_tokens": 24312
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any manual annotations by single human experts for labeling the dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of multiple human expert annotators being involved in the annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that a single human non-expert performed any annotations."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not report involvement of multiple non-expert human annotators in the data annotation process."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although large language models (LLMs) are used for text correction and extraction and histopathology classifiers are used for image filtering, there is no mention of human verification of these AI-generated annotations."
          },
          "AI Model without Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 and Section 3.3",
            "reasoning": "The data annotation was performed automatically using AI models including large language models (GPT-3.5), histopathology image classifiers, automatic speech recognition (ASR) models, and handcrafted algorithms with no mention of human verification of annotation correctness, implying the AI annotations were used without human verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 and Section 3.3",
            "reasoning": "The pipeline relies heavily on automatic processes such as handcrafted algorithms, keyword extraction algorithms, UMLS knowledge databases, and automatic speech recognition to curate and align image-text pairs. These automatic processes without human intervention fulfill the definition of automatic annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation is clearly described as occurring via AI models and automatic processes, so this label does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "OTjTKFk7gb-rubric-4",
    "token_usage": {
      "prompt_tokens": 23469,
      "completion_tokens": 413,
      "total_tokens": 23882
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert. The dataset is generated via simulation and generative models based on real-world data rather than manual labeling by experts."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information in the paper indicating that multiple human experts performed data annotation on the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of annotation by a single non-expert human annotator is present in the paper."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper provides no evidence or description of multiple non-expert human annotators performing data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset is generated using deep generative models and simulation, but there is no indication that AI-generated annotations were verified by human annotators."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that data annotation was performed solely by AI models without any verification; rather, data generation involves trained generative models mimicking real data distribution."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Sections 3.1, 4, and Appendices H and G",
            "reasoning": "The dataset is automatically generated based on a deep generative model (latent diffusion model) trained on real advertising data and simulation of a multi-agent bidding environment. No manual annotation is involved; instead, data annotations (e.g., bid outcomes, values) are generated automatically via simulation and deep generative networks as described in detail in Sections 3.1, 4, and Appendices H and G."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents a data generation process where annotations are automatically produced via simulation and deep generative models, so 'N/A' is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "PcbSZwVVc5-rubric-4",
    "token_usage": {
      "prompt_tokens": 22413,
      "completion_tokens": 342,
      "total_tokens": 22755
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention that data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Annotation and Statistics; Appendix A.4 Manual Annotation",
            "reasoning": "The annotation process involved a team of annotators who manually reviewed the earbud data to identify and label events. Each label was checked by at least three annotators, and voting was used to assign labels if consensus was not reached. This indicates annotation by multiple human annotators. Although the paper does not explicitly state that they are subject matter experts, the detailed hierarchical inspection process and consensus voting imply a high level of expertise or careful annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that annotation was performed by a single non-expert is provided."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that annotation was performed by multiple non-expert annotators without expertise."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention is made of AI model assisted annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No reference to AI model only annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation was manual, not automatic by simulation or automatic non-AI process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation was explicitly performed and documented, so N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "QIJQ1qCGqV-rubric-4",
    "token_usage": {
      "prompt_tokens": 15713,
      "completion_tokens": 428,
      "total_tokens": 16141
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any single annotator conducting the data annotation alone. Instead, it describes multiple annotators involved."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.3 Data Annotation Pipeline",
            "reasoning": "The dataset annotations were performed by 15 human annotators, including three motion experts (human biomechanics, sensorimotor, and mobility researchers). This indicates that multiple expert annotators contributed to the annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of a single non-expert annotator performing the data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.3 Data Annotation Pipeline",
            "reasoning": "In addition to the three motion experts, 12 novice annotators without specified subject matter expertise performed the annotations under supervision and with detailed instructions, implying multiple non-expert annotators were involved."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any AI model-assisted annotation process or verification involving AI models."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of annotation being performed solely by AI models is given."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations are not described as automatic or generated by simulation or automatic processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation was clearly performed and documented, involving multiple annotators."
          }
        }
      }
    ]
  },
  {
    "id": "Qf8uzIT1OK-rubric-4",
    "token_usage": {
      "prompt_tokens": 39038,
      "completion_tokens": 295,
      "total_tokens": 39333
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information describing the annotation process or indicate that a single human expert conducted annotations."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description in the paper indicating that multiple human experts performed the data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The text lacks details about annotations being done by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information describing data annotation carried out by multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any usage of AI models with human verification for data annotation."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention is made of data annotation performed solely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not discuss any automatic or simulated data annotation processes outside AI model annotations."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper does not introduce or describe any new datasets, nor specific annotation processes for datasets; rather, it discusses ethical considerations and general recommendations for data curation without detailing data annotation procedures."
          }
        }
      }
    ]
  },
  {
    "id": "QpF3DFP3Td-rubric-4",
    "token_usage": {
      "prompt_tokens": 20997,
      "completion_tokens": 316,
      "total_tokens": 21313
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "Section 3.1 Annotation and Section 3.2 Annotation",
            "reasoning": "The paper describes the annotation process as an effort performed by a shifting team of archaeologists, both local and foreign, implying multiple experts contributed to the annotations."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Annotation and Section 3.2 Annotation",
            "reasoning": "The annotations were created and field-verified by a team of archaeologists, both local and foreign experts, indicating that multiple human experts were involved in the annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication in the paper that a single non-expert performed annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication in the paper that multiple non-experts performed annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of AI-assisted annotation or AI with human verification for annotations in the paper."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of AI models annotating data without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations were manually annotated and field-verified by experts, not done automatically or by simulation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotations are clearly documented and described as part of the dataset."
          }
        }
      }
    ]
  },
  {
    "id": "R4rNYJ2slJ-rubric-4",
    "token_usage": {
      "prompt_tokens": 18478,
      "completion_tokens": 323,
      "total_tokens": 18801
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper states that annotation was carried out by a professional team rather than a single individual, thus not applicable."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Annotation",
            "reasoning": "The dataset annotation was conducted by a professional remote sensing imagery labeling team consisting of approximately 50 annotators performing labeling and 7 annotators for quality checking, indicating multiple human experts were involved in the annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators were described as a professional labeling team, indicating expertise, and multiple annotators were involved rather than a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators are described as professional remote sensing imagery labeling team, implying expertise; thus, multiple non-expert annotators do not apply."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotations were performed manually by human annotators; there is no mention of AI-assisted annotation with verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that AI models performed annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations were not automatic or simulation-based but manually done by humans."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper explicitly describes a manual annotation process; thus, annotation was performed and documented."
          }
        }
      }
    ]
  },
  {
    "id": "ScPgzCZ6Lo-rubric-4",
    "token_usage": {
      "prompt_tokens": 36848,
      "completion_tokens": 311,
      "total_tokens": 37159
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information in the paper supporting that multiple human experts annotated the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that a single human non-expert performed data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of AI model-based annotation with some human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The datasets used are public datasets that are either naturally occurring or pre-existing benchmarks; there is no indication that annotation is performed by simulation or automatic process for the purpose of this paper."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper uses existing publicly available graph datasets that come with their own labels and splits, and there is no description or indication of any data annotation process performed or induced by the authors. The benchmark integrates these datasets but does not perform any data annotation themselves."
          }
        }
      }
    ]
  },
  {
    "id": "USUkwg5pW6-rubric-4",
    "token_usage": {
      "prompt_tokens": 25298,
      "completion_tokens": 460,
      "total_tokens": 25758
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that multiple human experts performed the data annotation for the new datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of any single human non-expert performing annotation for the new datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not state that multiple non-expert humans annotated the new datasets."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation process is not described as performed by an AI model with any human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation process is not described as performed by an AI model without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3. Automated Scribble Generation; Section 4 Automatic Scribble Datasets",
            "reasoning": "The paper describes a fully automatic scribble generation algorithm (Section 3) which takes dense segmentation labels of existing datasets and generates scribble labels automatically without human annotators. This includes the creation of new scribble datasets such as s4Pascal, s4Cityscapes, s4KITTI360, and s4ADE20K (Section 4). The annotation is explicitly described as automatic and probabilistic, with no human annotation involved in the new datasets."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described; automatic scribble labels are generated for the new datasets."
          }
        }
      }
    ]
  },
  {
    "id": "UYgE9IfQIV-rubric-4",
    "token_usage": {
      "prompt_tokens": 31343,
      "completion_tokens": 376,
      "total_tokens": 31719
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation performed by a single human expert on the datasets used or introduced."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information indicating that multiple human experts performed annotations for the new datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication exists that a single non-expert annotated the data."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of AI models performing data annotation with human verification is present."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No data annotation was performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4 (especially 4.1, 4.2, 4.3) and Appendix A",
            "reasoning": "The new datasets (workload traces, weather data, carbon intensity data) used in SustainDC are from existing open-source repositories and external sources (e.g., Alibaba, Google workload traces), or are generated/processed automatically via simulations and models within the SustainDC environment. Annotation per se is not discussed; rather, the data stems from automatic processes or simulations that model system behavior (e.g., battery models, cooling models, workload scheduling). Therefore, data annotation is performed automatically by simulation processes and not through manual efforts or AI-verified annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation processes are relevant as simulations and data traces form the datasets, so annotation is not absent but automatic."
          }
        }
      }
    ]
  },
  {
    "id": "VH1vxapUTs-rubric-4",
    "token_usage": {
      "prompt_tokens": 18493,
      "completion_tokens": 403,
      "total_tokens": 18896
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information indicating that multiple human experts performed data annotation on the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset construction does not involve annotation by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of multiple non-expert human annotators participating in the data annotation process."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that an AI model with human verification was used for data annotation."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was not performed by an AI model without verification as per the paper."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3 (Mesogeos Datacube) and specifically 'Burned Areas Dataset' and 'Ignition Date Calculation' subsections.",
            "reasoning": "The dataset primarily incorporates data from multiple existing sources like EFFIS burned area product, MODIS active fire product, ERA5-Land meteorological dataset, and other satellite-derived products. The burned areas are derived from EFFIS using semi-automatic processes combining data from multiple satellites and products (not AI-based), and ignition dates are refined automatically by intersecting EFFIS burned areas with MODIS active fire hotspots using an algorithmic approach. These processes are automated or semi-automated but not involving AI model annotation; thus, data annotation is done via automatic processes, not manual labeling."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation processes are documented as automatic data processing and refinement, so the annotation is not absent."
          }
        }
      }
    ]
  },
  {
    "id": "VSJotgbPHF-rubric-4",
    "token_usage": {
      "prompt_tokens": 14098,
      "completion_tokens": 391,
      "total_tokens": 14489
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide evidence that the data annotation was conducted by a single human annotator who is a subject matter expert or member of the target demographic. Instead, it describes a crowd-sourcing effort with many volunteers contributing."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human annotators with subject matter expertise performed the data annotation. The annotation was done by a large crowd of volunteers without indication of such expertise."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that annotation was conducted by a single human non-expert annotator; the process involved many volunteers."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3 Data Collection; Section 3.1 Single-Step Collection",
            "reasoning": "The dataset annotation and data collection involved more than 13,000 volunteers contributing prompts, replies, labels, and rankings. There is no indication that these volunteers were subject matter experts; rather, the data was crowd-sourced from a broad community of contributors, implying annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation being performed by an AI model with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence that annotation was performed solely by an AI model without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation was not performed by automatic processes or simulations; it was done by human volunteers as described."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents extensive annotation activities involving many human annotators; thus, data annotation is present and documented."
          }
        }
      }
    ]
  },
  {
    "id": "VXohja0vrQ-rubric-4",
    "token_usage": {
      "prompt_tokens": 20127,
      "completion_tokens": 500,
      "total_tokens": 20627
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 2.2 Dataset Instance Collection, especially step (2) Data verification and enrichment and step (3) Answer and explanation generation.",
            "reasoning": "The paper states that the extracted attribute values from GPT-4 were verified and corrected by one individual with a medical background, indicating a single human expert verified and/or synthesized parts of the dataset. Additionally, 21 calculators' patient notes and answers were synthesized or handwritten by one individual with medical expertise. This points to data annotation being performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human annotators with medical expertise participated in verifying or annotating the dataset instances."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotator involved in verification and synthesis is described as a person with medical background, so this label does not apply."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of multiple non-expert annotators was provided."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.2 Dataset Instance Collection, steps (1) and (2).",
            "reasoning": "The initial extraction of attributes was performed automatically by AI models (GPT-3.5-Turbo to identify notes and GPT-4 to extract attribute values), and then the extraction was verified and corrected by a human expert, constituting AI model annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "All AI-based extractions were verified by a human expert, so no unverified AI model annotation occurred."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.2 Dataset Instance Collection, step (2), and Section 2.2, Dataset Instance Collection, step (3).",
            "reasoning": "For 21 calculators without eligible notes, 10 equation-based calculators were synthesized with templates, and 11 rule-based calculators had patient notes synthesized by a human expert. The explanations were generated automatically using templates for each calculator. Thus, part of the annotation (explanation generation and synthesis of some notes) was automatic or template-based."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents a data annotation process in detail, so this label does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "WUWHVN4gxk-rubric-4",
    "token_usage": {
      "prompt_tokens": 20639,
      "completion_tokens": 368,
      "total_tokens": 21007
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation process conducted by a single human expert for the dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description in the paper about multiple human experts annotating the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication of a single human non-expert annotating the dataset."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe multiple non-expert humans involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of AI models being used for annotation with verification by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset is not described as being annotated by AI model without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4.1 Dataset Structure, Section 4.2 Dataset Exploration",
            "reasoning": "The dataset consists of automatically recorded multi-turn conversations (chats) collected during an automated attack phase of a capture-the-flag competition. The chats and defenses are system-generated artifact data rather than manually annotated labels. The labels such as is_evaluation and was_successful_secret_extraction are automatically derived from system logs and scoring based on the competition infrastructure. No human annotation process is described, implying that data annotation is done automatically by the system during competition."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents the dataset creation process clearly, indicating that data collection and labeling were carried out automatically by the competition system; therefore, N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "WVQ4Clw1VD-rubric-4",
    "token_usage": {
      "prompt_tokens": 13330,
      "completion_tokens": 391,
      "total_tokens": 13721
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation by multiple human experts; annotations are generated via automated pipelines and AI models."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of annotation by single non-expert humans is found in the paper."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation by multiple non-expert humans."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2 Data Construction Pipeline",
            "reasoning": "The dataset annotations are generated by multimodal large language models (MLLMs) guided by domain-specific expert grounding models and retrieval-augmented generation techniques. There is a calibration step using GPT-4V for 200,000 samples to provide an effective fine-grained caption template, which acts as a form of verification or refinement guiding the AI annotation. Hence, AI models produce annotations with verification by human-expert-based models and curated templates."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper emphasizes verification and refinement steps; therefore, no annotation is done purely by AI without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 Data Construction Pipeline",
            "reasoning": "The data construction pipeline is fully automated, leveraging expert grounding models to extract ROIs and medical knowledge retrieval to produce the annotations without human annotators directly labeling each image. This process is an automatic pipeline, not involving manual annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents the annotations process involving AI models and automatic methods; data annotation is present."
          }
        }
      }
    ]
  },
  {
    "id": "XBcStBjBIE-rubric-4",
    "token_usage": {
      "prompt_tokens": 31676,
      "completion_tokens": 412,
      "total_tokens": 32088
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any use of a single human expert for data annotation."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation by multiple human experts for the datasets introduced."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that annotation was done by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not state that multiple human non-experts performed annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 4 \"ChronoMagic-Pro\", subsection \"Multi-Aspect Data Curation\" and Appendix C.2",
            "reasoning": "The ChronoMagic-Pro dataset annotations are generated by an AI model (an open-source multimodal large model ShareGPT4Video) which generates captions from uniformly sampled frames, and then summarizes those captions into detailed video captions. This approach is inspired by and similar to MagicTime [89] which originally used GPT-4V; here the authors use ShareGPT4Video to reduce computational overhead while ensuring high-quality annotations, indicating a human-verified or human-guided process to reduce hallucinations. Therefore, the annotation is performed by an AI model with some verification or human-guidance involved in the process."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly mentions use of an AI model with verification or an annotation strategy that reduces hallucinations; thus annotation without verification is not applicable."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that annotations were obtained purely by automatic non-AI simulation or processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper describes a detailed annotation process for captions generated by AI models with verification, so annotation is documented and applied."
          }
        }
      }
    ]
  },
  {
    "id": "ZDvXY56DeP-rubric-4",
    "token_usage": {
      "prompt_tokens": 20719,
      "completion_tokens": 326,
      "total_tokens": 21045
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation process conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of data annotation performed by multiple human experts in the dataset creation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of multiple human non-expert annotators involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset creation and annotation does not involve AI models with human verification as per the paper."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate any autonomous AI-based data annotation without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2.1 Content",
            "reasoning": "The dataset consists of tracked experiments and logged metrics automatically recorded by software during Reinforcement Learning training runs. This automatic logging process is not performed by humans but by the system itself, and is not described as involving any AI models for annotation. Therefore, the data annotation corresponds to automatic collection via simulation or programmatic logging."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents an automatic process of data collection (logs of RL experiments), so the annotation process is present and described."
          }
        }
      }
    ]
  },
  {
    "id": "aTXhTD44nF-rubric-4",
    "token_usage": {
      "prompt_tokens": 25339,
      "completion_tokens": 349,
      "total_tokens": 25688
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention use of a single human annotator with subject expertise for annotation."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human expert annotators were used for the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation done by a single non-expert human."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe multiple non-expert human annotators performing the data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2 Obtaining LLM Annotations, Verification using Human Interaction",
            "reasoning": "The dataset annotations are generated by two large language models (GPT-4 and Mistral Large) in zero-shot, one-shot, and few-shot settings, with majority voting used for final labels. A limited verification is done with human annotators on test samples to assess agreement with LLM annotations, indicating AI model annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Human verification on a test subset is mentioned, so purely AI annotation without any verification does not apply."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data annotation was not performed by a simulation or automatic process apart from AI models; therefore, this does not apply."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described as being done by AI models with additional human verification on a subset."
          }
        }
      }
    ]
  },
  {
    "id": "aXeiCbMFFJ-rubric-4",
    "token_usage": {
      "prompt_tokens": 23940,
      "completion_tokens": 425,
      "total_tokens": 24365
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that any data annotation was performed solely by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe the involvement of multiple human experts in the data annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description supporting data annotation done by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence is provided regarding multiple non-expert human annotators being involved."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 Data Generation",
            "reasoning": "The paper states that GPT-4 (an AI model) was used as a linguistic annotator to create questions and answers for some datasets (e.g., TextCaps, Flickr30k, GQA). The generated content was further improved by a filtering pipeline which likely includes human verification or quality checks to ensure content quality. This implies that AI-generated annotations were verified to some extent by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation process involving AI models incorporates verification steps and filtering, so this label does not apply."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Data Generation",
            "reasoning": "For visual annotations, the paper uses PaddleOCR (an automatic optical character recognition tool) to detect text regions automatically for datasets in the Text/Doc and Charts domains. Similarly, bounding boxes indicating key regions in datasets like GQA, Birds-200-2011, and others are reused or derived from existing annotations or automated extraction without explicit mention of human annotators. Thus, parts of the annotation process are done automatically by non-AI simulation or detection processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper explicitly describes multiple annotation processes for the dataset, so 'N/A' is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "abXaOcvujs-rubric-4",
    "token_usage": {
      "prompt_tokens": 16749,
      "completion_tokens": 363,
      "total_tokens": 17112
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human experts performed data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is provided about annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotation using AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset creation does not involve annotation by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3 (Construction Methodology), particularly Sections 3.1, 3.2, and 3.3",
            "reasoning": "The WikiDBs dataset is automatically constructed from the Wikidata knowledge base using an automated pipeline that parses the Wikidata JSON dump, organizes items into tables based on properties, selects related tables based on semantic similarity using SentenceBERT, and applies GPT-4 paraphrasing for table and column names. There is no manual annotation involved; all dataset contents and schema labels are derived automatically from Wikidata data and AI-generated paraphrasing, constituting an automatic annotation process not involving human annotators."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is applied in the form of automatic processes; hence, N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "aiGN4UnNM7-rubric-4",
    "token_usage": {
      "prompt_tokens": 18003,
      "completion_tokens": 399,
      "total_tokens": 18402
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 4.2 Annotation",
            "reasoning": "The data annotations are manually checked by the annotation team to ensure quality, implying multiple human annotators with expertise performed verification and manual checks on the data labeling process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that a single non-expert conducted the data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation team appears to be knowledgeable and performing quality checks, no indication of multiple non-experts annotating."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 4.2 Annotation",
            "reasoning": "Initial 2D detection and tracking algorithms are used to obtain 2D bounding boxes and track IDs, and LiDAR and Radar data are used to generate accurate depth and velocity. After automatic annotation processes, data annotations are manually checked by the annotation team, indicating that AI model annotations are verified by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "Section 4.2 Annotation",
            "reasoning": "There is explicit mention of manual checking of annotations, so AI model annotations are not without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4.2 Annotation and 4.1 Data Collection",
            "reasoning": "Annotations such as depth and relative velocity are automatically generated using multi-sensor data and fitted using automatic techniques like RANSAC. Additionally, NeRF rendered data is generated automatically through simulation to augment rare cases."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents the annotation process involving automated processes, AI model outputs, and manual human checks."
          }
        }
      }
    ]
  },
  {
    "id": "b6IBmU1uzw-rubric-4",
    "token_usage": {
      "prompt_tokens": 32600,
      "completion_tokens": 383,
      "total_tokens": 32983
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not explicitly mention data annotation conducted by a single human expert for the new CARES dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no explicit description in the paper about multiple human experts performing data annotation for the CARES dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence in the paper indicates that a single non-expert human annotated the data."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe involvement of multiple non-expert annotators in the data annotation process."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2, 'Construction of QA Pairs' subsection and Appendix C",
            "reasoning": "The open-ended question-answer pairs in CARES are generated by GPT-4 (an AI model) based on medical reports or descriptions. Subsequently, GPT-4 is instructed to perform a self-check of its initial QA outputs along with the original report for quality assurance. Furthermore, some manual exclusion and corrections were performed to remove errors. This indicates an AI model generated the annotations with verification via self-checking and human verification, fulfilling the criteria of AI model with verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation was not done purely by AI model without any verification; verification via GPT-4 self-check and manual cleaning was performed."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is not described as fully automatic or simulation-based without AI involvement."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents data annotation steps particularly the generation of QA pairs by GPT-4 with verification and manual review."
          }
        }
      }
    ]
  },
  {
    "id": "bAaM8cKoMl-rubric-4",
    "token_usage": {
      "prompt_tokens": 30576,
      "completion_tokens": 367,
      "total_tokens": 30943
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert for the new datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information provided that multiple human experts annotated the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not document any annotation by a single non-expert human."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No data about annotation by multiple non-expert humans is provided."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotations performed by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation by AI models without verification is described for the datasets."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2 (Datasets), Section 4 (Code and Resources), Appendix A.1 and A.3",
            "reasoning": "The datasets are mostly programmatically generated or automatically generated using scripts with configurable parameters, as described in Sections 2 and 4 and detailed in Appendices A.1 and A.3. The annotation files are automatically created alongside the generated images containing paths and parameter values for each sample. Thus, the data annotation is performed by automatic processes and simulations rather than human annotators or AI model labelling."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Since the datasets include generated images along with automatically produced annotation files containing all necessary labels and parameters, there is documentation of an annotation process, albeit automated. Therefore, 'N/A' does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "cLga8GStdk-rubric-4",
    "token_usage": {
      "prompt_tokens": 16862,
      "completion_tokens": 377,
      "total_tokens": 17239
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 3, especially 3.1 and 3.2",
            "reasoning": "The puzzles are originally created by expert human authors in the UK Linguistics Olympiad (UKLO), who research the languages before creating the problems. The paper states these puzzles were created by multiple expert puzzle authors, many of whom are expert linguists, and the puzzles were manually reviewed and corrected by the authors. This indicates annotation (i.e., creation and answering of the puzzles) was performed by human experts."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3 and Acknowledgments",
            "reasoning": "The paper acknowledges multiple puzzle authors who devise the puzzles, indicating multiple expert human annotators contributed. UKLO puzzles are created and scored by multiple expert linguists, implying multiple human experts were involved in the annotation and grading process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that annotation was performed by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that annotation was performed by multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention AI models being used for annotation or verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No AI-only annotation is described."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation is not done by automation or simulation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents and describes the human expert authorship, selection, and permission process for the puzzles, so data annotation is present and documented."
          }
        }
      }
    ]
  },
  {
    "id": "cR3T1ZYN8I-rubric-4",
    "token_usage": {
      "prompt_tokens": 37242,
      "completion_tokens": 387,
      "total_tokens": 37629
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation process done by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description in the paper indicating that multiple human experts performed annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that a single non-expert human performed data annotation on the datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide information on data annotation by multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of data annotation performed by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention data annotations performed by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4.2 Datasets; Section 3.3; Abstract and Section 3",
            "reasoning": "The paper uses existing public datasets for evaluation. For example, the SeqDeepFake dataset includes sequential manipulated face images with manipulation labels, and the R-splicer dataset uses pseudo-fake images generated by simulation of face-swap artefacts for fine-grained labels. The annotations of manipulation areas in these datasets appear to be automatically derived by predefined manipulations or simulations rather than manual human annotation. The paper explicitly mentions avoiding costly human captioning or annotation efforts and uses these datasets directly for multi-label evaluation, indicating that the annotations are automatic or simulation-based rather than being from human annotators."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "There is data annotation applied, as datasets have labels, but the annotation is automatic or simulation-based rather than human."
          }
        }
      }
    ]
  },
  {
    "id": "cu8FfaYriU-rubric-4",
    "token_usage": {
      "prompt_tokens": 30216,
      "completion_tokens": 438,
      "total_tokens": 30654
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any specific information indicating that data annotation was conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper discusses challenges in recruiting multiple data annotators with requisite expertise (Section 3.3.2 'Data annotator diversity and expertise') and the difficulty of finding medical experts for annotation (P1), but it does not state that multiple human experts performed data annotation for any new datasets introduced by the authors."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper of data annotation being done by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.3.2 'Data annotator diversity and expertise'",
            "reasoning": "The paper notes that data annotation involves multiple annotators and discusses challenges in recruiting annotators with requisite expertise or diverse backgrounds, implying that multiple non-expert annotators often conduct the annotation. For example, crowdsourced annotators can embed biases, indicating annotation is performed by multiple human non-experts who lack subject matter expertise or diversity."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention the use of AI models for data annotation with human verification in the creation of any new datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that any AI model was used for annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description or mention is made of automatic or simulated annotation that is not AI-based."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper primarily presents a taxonomy of challenges and interviews with dataset curators; it does not introduce or describe new datasets created by the authors themselves, nor does it provide detailed procedural information about data annotation for new datasets. Therefore, data annotation is not documented or applied for any new datasets introduced in this paper."
          }
        }
      }
    ]
  },
  {
    "id": "cy8mq7QYae-rubric-4",
    "token_usage": {
      "prompt_tokens": 82823,
      "completion_tokens": 405,
      "total_tokens": 83228
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 3.2 (Question Construction), Section 3.1 (Chart Curation)",
            "reasoning": "The paper states that all charts and questions were handpicked and manually constructed by human experts who are experienced graduate students (Section 3.2). Multiple annotators select charts and create questions, and all ground-truth answers are validated by hand, indicating human expert involvement in annotation."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 (Chart Curation), Section 3.2 (Question Construction)",
            "reasoning": "The annotation process involves multiple experienced graduate students acting as annotators who select charts, curate questions, and validate answers. This indicates data annotation was conducted by multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of any annotation carried out by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations are stated to be performed by graduate students described as human experts, so non-expert annotators are not involved."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although GPT-4V was used to generate sample reasoning QA pairs, the final questions and answers were curated and verified by human experts. No AI-only annotation with human verification is described as the main annotation process."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence of data annotation done solely by AI models without human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation is primarily manual; automatic or simulation-based annotation is only used for candidate generation or inspiration but not as final annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation processes are well described and performed by humans; hence N/A is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "d1Pup4gkWf-rubric-4",
    "token_usage": {
      "prompt_tokens": 15487,
      "completion_tokens": 355,
      "total_tokens": 15842
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any manual annotation performed by a single human expert for the dataset creation or annotation."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple expert annotators were involved in data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation by a single non-expert human is mentioned."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation by multiple non-expert humans is described."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 4.3 Acquiring Human Demonstration From Videos",
            "reasoning": "The paper states that it uses TRAM, an AI model for 3D motion reconstruction from videos, to estimate human motion parameters. This is followed by PHC, a physics-based motion tracker, to imitate and correct the estimated motions to ensure physical plausibility. This indicates that an AI model performs initial annotation/estimation which is then verified and corrected by a physics-based process, implying verification of the model output."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly mentions verification and correction using PHC after AI model estimation, so annotation without verification is not the case."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data annotation process involves AI models (TRAM and PHC), not a purely automatic simulation or non-AI process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper describes a data annotation process for human demonstration data extraction from videos."
          }
        }
      }
    ]
  },
  {
    "id": "dVaWCDMBof-rubric-4",
    "token_usage": {
      "prompt_tokens": 24432,
      "completion_tokens": 456,
      "total_tokens": 24888
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human experts were involved in annotating the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of multiple non-expert annotators performing data annotation is found."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset does not appear to be annotated by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of data annotation performed solely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 (COMMONPOOL generation)",
            "reasoning": "The COMMONPOOL dataset comprises image-text pairs collected automatically from Common Crawl using URL extraction and alt-text; no manual annotation is performed, and labels (texts) are automatically sourced from the web. Additional automatic filtering steps such as NSFW detection (using a classifier trained on CLIP features), evaluation set deduplication (via a deduplication model), and face blurring (automatic face detection) are performed. Therefore, the annotation consists entirely of automatic processes without human annotators."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation in the conventional sense is applied automatically via web scraping and automatic filtering, so 'N/A' does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "g7OX2sOJtn-rubric-4",
    "token_usage": {
      "prompt_tokens": 47899,
      "completion_tokens": 367,
      "total_tokens": 48266
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that the data annotation for the new dataset was done by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper that multiple human experts were involved in annotating the data."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description suggesting that a single non-expert performed data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset is extracted automatically from Lean's math library and proof environment using modified Lean tooling; there is no mention of AI models performing data annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication exists that AI models annotated the data without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 4, Data Extraction and LeanDojo Benchmark",
            "reasoning": "The dataset (LeanDojo Benchmark) is constructed by automatically extracting data from Lean's mathlib repository using an instrumented version of Lean (modified elaborator and tooling). No human annotation is involved; data extraction processes such as obtaining ASTs, proof states, tactics, and premise information are done programmatically. Therefore, data annotation is performed by an automatic process (software/simulation) that is not an AI model."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper explicitly describes programmatic data extraction from Lean, so data annotation is applied and documented."
          }
        }
      }
    ]
  },
  {
    "id": "gg3POFjqq8-rubric-4",
    "token_usage": {
      "prompt_tokens": 13614,
      "completion_tokens": 379,
      "total_tokens": 13993
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation being performed by a single human expert on the new dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human experts annotated the new dataset. The annotators are described but their expertise level is not specified to be experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description of annotation by a single non-expert is reported in the paper."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 4, Dataset for Evaluating OOC Filtering Strategies",
            "reasoning": "The new dataset for evaluating out-of-class (OOC) filtering strategies was manually labeled by two human annotators per image. No information is provided on the annotators' expertise, so by default, they are considered non-experts. The annotation included labels such as 'class', 'partial class properties', and 'not class' to identify OOC samples."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation process does not involve an AI model with human verification, but uses purely human annotations for the labeled dataset."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation was done solely by an AI model without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although synthetic images are generated automatically using diffusion models and LoRA adapters, the data annotation for the new dataset is done by human annotators, not an automatic annotation process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents a manual annotation process for the new dataset with multiple human annotators; thus, N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "h8LuywKj6N-rubric-4",
    "token_usage": {
      "prompt_tokens": 46659,
      "completion_tokens": 386,
      "total_tokens": 47045
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper states that annotation was performed by multiple human annotators, specifically 16 authors and 8 volunteers, rather than a single expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section B.3 Human Keyframes Annotation Process",
            "reasoning": "The annotation was conducted by multiple human annotators (16 authors and 8 volunteers) who have domain knowledge in GUI, with diverse backgrounds and education above undergraduate level, indicating subject matter expertise or target demographic membership."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation being performed by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators are described as having knowledge in GUI and education above undergraduate level, indicating expertise rather than non-expert status."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.3 GUI Tasks Generation from Human-MLLM Collaboration; Section B.3 Human Keyframes Annotation Process",
            "reasoning": "Initially, GPT-4V (an AI model) was used to generate captions and QA pairs (annotation), followed by human annotators carefully reviewing and correcting inaccuracies, hallucinations, and supplementing information, indicating AI model annotation with verification by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that AI model annotations were used without human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotations are not done by an automatic process or simulation but involve human annotators and AI (LLM) collaboration."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset involved extensive annotation efforts as described, so this label does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "hcOq2buakM-rubric-4",
    "token_usage": {
      "prompt_tokens": 35640,
      "completion_tokens": 289,
      "total_tokens": 35929
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe a new dataset with an annotation process involving a single human expert annotator."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe a new dataset with multiple human experts performing annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is provided about annotation by a single non-expert human."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of multiple non-expert human annotators in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe using AI models for annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No use of AI models for annotation without verification is described."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe automatic annotation or simulation processes unrelated to AI models."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper presents an assessment framework for existing AI benchmarks and evaluates 24 existing benchmarks; it does not introduce new datasets with original data annotation processes or describe any annotation process for new data. Therefore, no data annotation is applied or documented for new datasets."
          }
        }
      }
    ]
  },
  {
    "id": "iSwK1YqO7v-rubric-4",
    "token_usage": {
      "prompt_tokens": 99860,
      "completion_tokens": 230,
      "total_tokens": 100090
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Appendix M.2, M.3",
            "reasoning": "The data annotation for the new datasets introduced in this paper (annotations on BEHAVIOR and VirtualHome tasks) were performed by the authors, who are expert researchers. The annotation involved careful manual curation, reviewing human demonstrations, and detailed manual annotations of goals, trajectories, and transition models. No mention of multiple annotators or crowdsourcing is made, indicating a single expert annotator approach."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": ""
          }
        }
      }
    ]
  },
  {
    "id": "iTUlYblV0K-rubric-4",
    "token_usage": {
      "prompt_tokens": 22098,
      "completion_tokens": 435,
      "total_tokens": 22533
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention that data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide information indicating that multiple human experts performed the data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that a single non-expert human annotator was responsible for the data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention multiple non-expert annotators being involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.1, Section 3.4, and Section 4.1",
            "reasoning": "The MQuAKE dataset is constructed based on Wikidata RDF triples which serve as a knowledge graph. The multi-hop questions are generated by prompting the GPT-3.5-turbo model three times on the chained triples to produce natural language multi-hop questions (Section 2.1). Section 3.4 describes that the multiple generations reduce incomprehensible questions but some questions were still incomplete, indicating that AI generation was used. Section 4.1 describes rewriting problematic question instructions, implying human verification and manual correction after initial AI generation. Therefore, data annotation (the question generation and correction) is performed by an AI model with human verification and manual correction."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes that some errors in the AI generated questions were manually fixed and question instructions rewritten, indicating verification was performed; thus AI model without verification does not apply."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data annotation is not completely automatic without AI involvement; moreover, AI model generation and manual corrections were performed, so purely automatic annotation does not apply."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper describes data generation and annotation processes; thus, annotation is documented and performed."
          }
        }
      }
    ]
  },
  {
    "id": "iwC19lVBoq-rubric-4",
    "token_usage": {
      "prompt_tokens": 15469,
      "completion_tokens": 574,
      "total_tokens": 16043
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 3.1 Dataset Construction Pipeline, Stage 1: Data Collection",
            "reasoning": "The paper states that AudioSet includes 2.1 million audio samples each manually annotated with fine-grained audio categories, and during annotation, annotators are allowed to view the accompanying videos to aid in accurate audio category labeling. This indicates that data annotation was conducted by human annotators who are likely experts or at least carefully performed annotations with subject matter expertise."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide explicit information about multiple human expert annotators working on the dataset; it only mentions that AudioSet samples were manually annotated but does not specify multiple experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that annotation was done by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information suggests that annotation was done by multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 Dataset Construction Pipeline, Stage 3: Voice-Over Filtering and general construction pipeline",
            "reasoning": "The paper describes the use of an audio classification network (PANNs) to classify and filter audio clips, which is an AI model performing annotation-like classification. The paper also refers to manual labeling for AVSET-700K, indicating some human supervision or verification alongside AI model use."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation performed solely by an AI model without human verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Dataset Construction Pipeline, Stage 4: Sample Recycling with Sound Separation",
            "reasoning": "The paper uses a sound separation model to isolate and recover audio from contaminated samples automatically. This process is an automatic annotation step (producing filtered samples) but not performed by an AI model in the sense of annotation; rather, it is an automatic audio processing step."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation processes are described in the paper, so N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "j2wasUypqN-rubric-4",
    "token_usage": {
      "prompt_tokens": 21703,
      "completion_tokens": 364,
      "total_tokens": 22067
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not document any data annotation performed by a single human expert for the newly introduced datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of data annotation performed by multiple human experts for the datasets introduced in the paper."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe that any data annotation was conducted by a single human non-expert for the introduced datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is provided indicating data annotation by multiple human non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any AI model-based data annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that an AI model was used alone to annotate data without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 Testsuites",
            "reasoning": "The introduced new datasets (testsuites) consist of synthetic functions from the COCO platform and protein-docking benchmark instances. These benchmarks involve problems generated automatically, e.g., synthetic functions are mathematical problem definitions with no manual annotation involved, and protein-docking instances are computationally constructed from protein-protein complexes. The datasets are not annotated by humans but are given as simulation or computational problems with known characteristics."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The datasets are introduced and described as derived from existing problem sets and computational constructions; thus, some form of data preparation exists, though not manual annotation."
          }
        }
      }
    ]
  },
  {
    "id": "jSKtxmxc0M-rubric-4",
    "token_usage": {
      "prompt_tokens": 21966,
      "completion_tokens": 492,
      "total_tokens": 22458
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper indicates that the annotation process involved five participants reproducing instructional videos and manually annotating multimodal data including procedural subtasks and atomic actions. However, it does not specify that these annotators were subject matter experts or members of the target demographic individually, but rather just participants. Therefore, this category does not apply."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Data Construction, paragraph 2",
            "reasoning": "The dataset annotation was conducted by five participants who watched the instructional videos and reproduced the tasks in a simulator, manually annotating subtask textual descriptions, identifying active elements for each action, and cross-validating annotations to remove unclear or incorrect ones. The involvement of multiple human annotators performing manual and cross-validation steps suggests multiple human experts performed the data annotation to ensure quality."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that data annotation was performed by a single human annotator. The annotation involved multiple participants and cross-validation, which contradicts this label."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators involved were tasked with reproducing complex GUI tasks from professional software and were able to break down tasks and identify UI elements. While the paper does not explicitly mention their expertise, they are referred to as participants reproducing tasks from instructional videos and performing cross-validation steps, implying some level of proficiency rather than simple non-expert crowd annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any use of AI models to perform data annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of AI models automatically annotating the data without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although the simulator environment automatically records user cursor and keyboard activities, the annotation of subtasks and identification of active UI elements was manually conducted by human participants, not automatically annotated by an automatic or simulated process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly describes the data annotation process involving human participants manually annotating procedural subtasks, textual descriptions, and UI element identification, hence data annotation was performed and documented."
          }
        }
      }
    ]
  },
  {
    "id": "jbrMS0DNaD-rubric-4",
    "token_usage": {
      "prompt_tokens": 17668,
      "completion_tokens": 404,
      "total_tokens": 18072
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper mentions that image annotations were performed by a small set of individuals with interest and familiarity with wildlife but does not state that any annotator was a subject matter expert or a member of the target demographic."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Query and Image Collection Process",
            "reasoning": "The paper states: \"All image annotations were performed by a small set of individuals whose interest and familiarity with wildlife image collections enabled them to provide accurate labels for challenging queries\" and that the queries were sourced from discussions and interviews with experts. This implies multiple annotators with domain familiarity, indicating multiple human experts conducted the annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly indicates multiple annotators were involved, and annotators had familiarity with wildlife image collections, suggesting expertise rather than non-expertise."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators had interest and familiarity with wildlife, so they are considered experts rather than non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While CLIP ViT-H-14 retrievals were used to narrow down images for some queries, the annotations were manually performed by humans who labeled images for relevance. There is no indication that an AI model performed initial annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of AI models performing data annotation autonomously without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was performed manually by human annotators, not by an automatic or simulation process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described in the paper in Section 3.2 with human annotators performing comprehensive labeling across the dataset."
          }
        }
      }
    ]
  },
  {
    "id": "kaHpo8OZw2-rubric-4",
    "token_usage": {
      "prompt_tokens": 106427,
      "completion_tokens": 511,
      "total_tokens": 106938
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any dataset annotation performed by a single human expert. No evidence is provided that a single expert annotated the data."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide explicit information on the use of multiple human experts for annotation. No annotation process with expert annotators is described."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of single human non-expert annotation in the paper."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention collection or annotation by multiple human non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation performed by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description of AI model-only annotation without verification is provided."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Sections 2, 3.3, App. C.3, D.1, E.2 and elsewhere",
            "reasoning": "The paper extensively describes the generation of challenging prompts, adversarial texts, stereotyping prompts, adversarial attack datasets, and evaluation datasets primarily via automatic processes and AI models such as GPT-3.5 and GPT-4 themselves. For example, challenging user prompts are generated by GPT models to elicit toxicity (Section 3.3, App. C.3); adversarial adversarial examples are created automatically against models such as Alpaca, Vicuna, and StableVicuna (Section 4.2, App. E.2); stereotype prompt datasets are constructed automatically by template-based approaches applied across demographic groups (Section D.1); out-of-distribution robustness datasets are derived through automatic style transformation and selection (Section F); and adversarial demonstrations involve systematic backdoor and perturbation injection (Section G.3). There is no description of human annotation for dataset labeling available, rather the data is created or processed automatically or synthetically or by AI generation. Therefore, the dataset annotation is primarily automatic or AI-generated without documentation of human annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly describes multiple datasets created or generated for evaluation purposes involving automatic or AI generation processes, so the option of no data annotation is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "l985bXCatk-rubric-4",
    "token_usage": {
      "prompt_tokens": 16790,
      "completion_tokens": 356,
      "total_tokens": 17146
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication of multiple human expert annotators performing annotation on the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation done by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any involvement of multiple non-expert human annotators in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 Construction",
            "reasoning": "Annotations such as product complexity, product categories, and image captions were generated using AI models. The authors used active learning protocols to train classifiers for complexity and category labels, and employed BLIP-2 to generate new captions. They also performed manual verification by randomly sampling images to check label quality with reported empirical error rates, indicating some human verification in the annotation process."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper reports manual verification and empirical error measurements, so annotation without any verification does not apply."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although the annotation process involved automated procedures, the use of AI models with active learning and manual verification precludes labeling the annotation as purely automatic or simulation-based."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper provides detailed description of annotation processes including automated labeling and manual verification, indicating that data annotation was indeed applied and documented."
          }
        }
      }
    ]
  },
  {
    "id": "lnnNPiZtzR-rubric-4",
    "token_usage": {
      "prompt_tokens": 13897,
      "completion_tokens": 393,
      "total_tokens": 14290
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Abstract, Section 2 The FungiTastic Dataset",
            "reasoning": "The dataset originates from fungal records labeled and curated by experts (Abstract). The data originates from the Atlas of Danish Fungi, which consists of expert-identified observations, indicating data annotation was conducted by human experts who are subject matter experts in fungi identification (Section 2)."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not explicitly mention multiple human experts annotating or reviewing the dataset; only that the original fungal records were labeled and curated by experts, suggesting a single expert or expert group without detailed annotation process by multiple individuals."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information indicating that annotation was done by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information indicating that annotation was done by multiple non-experts or crowdworkers."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.1 Additional observation data, Figure 4 description",
            "reasoning": "Segmentation mask annotations for fungi fruiting body parts were semi-automatically generated in CVAT using the Segment Anything Model, which is an AI model, but were human-verified. This indicates data annotation involving AI model with human verification (Section 2.1)."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that AI models were used for annotation without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No automatic annotation other than AI semi-automatic mask generation with human verification is described."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation processes are clearly described; thus 'N/A' does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "loJM1acwzf-rubric-4",
    "token_usage": {
      "prompt_tokens": 31129,
      "completion_tokens": 369,
      "total_tokens": 31498
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper indicates that 10 authors, who are expert-level annotators (doctors or Ph.D. students proficient in English reading and writing), performed the question-and-answer annotation collectively. This implies multiple experts rather than a single expert annotator."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2",
            "reasoning": "Section 3.2 states that ten authors, all expert-level annotators who are doctors or Ph.D. students proficient in English, performed the question and answer collection collaboratively. They worked on batches of documents to edit existing questions and create new annotations, indicating multiple human experts performed the data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that annotation was conducted by a single non-expert annotator. The annotators are all described as expert-level individuals."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators are explicitly described as expert-level (doctors or Ph.D. students), so this label does not apply."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotation procedure is purely human expert-based, with no mention of AI models annotating data with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of AI models independently producing annotations without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of automatic annotation or simulation-based annotation methods, only manual expert annotation and iterative review."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset clearly involved manual annotation processes, so this label does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "mDRmX8IlBI-rubric-4",
    "token_usage": {
      "prompt_tokens": 18239,
      "completion_tokens": 465,
      "total_tokens": 18704
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not specify that data annotation was performed by a single human annotator with subject matter expertise."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Manual Data Collection",
            "reasoning": "The human-annotated dataset includes question-answer pairs and captions annotated and reviewed by humans. The annotation was conducted by a team who crafted questions requiring domain knowledge across seven broad disciplines and 69 subdisciplines, indicating multiple human annotators with subject matter expertise or knowledge in the target disciplines participated in creating and reviewing the annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that only a single human non-expert performed the data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper emphasizes domain expertise and a team of annotators, implying experts or knowledgeable annotators rather than non-experts, thus this label does not apply."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The human-annotated dataset was created by human annotators, not by AI models with human verification; AI generation with human verification applies to the synthetic dataset annotation, not the human-annotated dataset."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No data annotation solely performed by AI models without human verification is described for the human-annotated dataset."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 Automated Data Collection",
            "reasoning": "The synthetic dataset is created via an automatic data collection and QA generation pipeline utilizing GPT-4V for question-answer and caption generation, combined with video summarization and filtering processes. While GPT-4V is an AI model, this annotation is primarily automated with quality verified by human evaluators. Since the label 'Automatic' applies to automatic annotation processes, the synthetic dataset's annotation qualifies as automatic (non-simulation but AI-assisted automatic generation)."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly described and performed both manually by humans and automatically using AI-assisted pipeline for the two distinct datasets of MMWorld."
          }
        }
      }
    ]
  },
  {
    "id": "mEJgnZZyfv-rubric-4",
    "token_usage": {
      "prompt_tokens": 18362,
      "completion_tokens": 347,
      "total_tokens": 18709
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was conducted by a single human expert for the datasets involved."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or description in the paper that multiple human expert annotators were involved in data annotation for the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human non-expert on the datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is provided about multiple human non-experts conducting data annotation for the datasets."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation conducted by AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of data annotation by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description or evidence is given that datasets were annotated automatically by a non-AI simulation or automatic process."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper only uses existing public datasets for benchmarking (e.g., CIFAR-10/100, ImageNet-1K, CUB-200-2011, iNaturalist, Places205). It does not introduce or document any new dataset creation or new data annotation process by the authors. The datasets are all standard open-source datasets with their own annotation processes not described in this paper."
          }
        }
      }
    ]
  },
  {
    "id": "mlhFJE7PKo-rubric-4",
    "token_usage": {
      "prompt_tokens": 41340,
      "completion_tokens": 438,
      "total_tokens": 41778
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating data annotation was performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotation performed by multiple human experts or annotators."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that data annotation was conducted by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information suggests the involvement of multiple non-expert annotators in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.3 Nuclear segmentation and classification",
            "reasoning": "Nuclear segmentation and classification were performed using CellViT, a state-of-the-art AI model trained on the PanNuke dataset. Although the paper does not explicitly mention human verification of the model output, the segmentation and classification are made available for visualization and further use, implying that AI annotations underpin the dataset with possible human oversight implied by manual inspection of the data quality."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "Section 3.3 Nuclear segmentation and classification",
            "reasoning": "While AI is used for nuclear segmentation and classification, the paper does not state that this was done without any verification. The presence of manual inspection of image quality suggests some level of verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.2 Histology and Section 4 HEST-Library",
            "reasoning": "The data processing includes automatic tissue segmentation using a deep learning model (DeepLabV3 with a ResNet50 backbone) fine-tuned on annotations, automatic fiducial detection with YOLOv8, automatic alignment pipelines, and patch extraction. These automatic processes are not AI models performing annotation per se but automated procedures in data preparation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents extensive automated annotation and model-based nuclear segmentation and classification; thus, annotation was applied."
          }
        }
      }
    ]
  },
  {
    "id": "moMoWj7jLm-rubric-4",
    "token_usage": {
      "prompt_tokens": 25542,
      "completion_tokens": 282,
      "total_tokens": 25824
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3",
            "reasoning": "Section 3 describes the dataset construction process where five postgraduate volunteer students, all holding bachelors degrees in science and engineering, manually annotated the questions. These annotators possess relevant subject matter expertise (science and engineering background) appropriate for junior high school physics problems, indicating that multiple human experts performed the data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2 Formula Normalization",
            "reasoning": "The data annotation process involved a combination of manual annotation and assistance from a large language model (LLM) to improve efficiency. The LLM was used to generate and revise normalized formula explanations, which were then validated automatically through calculations using a scientific calculator tool (numbat). This constitutes an AI model-assisted annotation with verification using human involvement."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": ""
          }
        }
      }
    ]
  },
  {
    "id": "nrEqH502eC-rubric-4",
    "token_usage": {
      "prompt_tokens": 80916,
      "completion_tokens": 344,
      "total_tokens": 81260
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes data annotation as conducted by multiple annotators per question, not by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3 Construction of BLEND, Answer Annotation and Answer Aggregation",
            "reasoning": "The paper documents recruiting multiple annotators (usually five) who are native speakers from target regions, with expertise as they are native speakers who lived most of their life in these countries; multiple annotators answered the same questions and additional annotators reviewed and aggregated annotations, indicating multiple human experts performing the data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation is conducted by multiple neurotic speakers rather than a single annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotators are explicitly described as native speakers who presumably hold subject matter expertise in the local culture, thus considered experts rather than non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention in the paper of using AI models to perform data annotation with verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication of AI models being used for data annotation without verification is described."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was not performed by automatic or simulation-based processes but by human annotators."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is thoroughly described and performed by multiple human annotators and reviewer annotators."
          }
        }
      }
    ]
  },
  {
    "id": "p8eUitex7p-rubric-4",
    "token_usage": {
      "prompt_tokens": 21679,
      "completion_tokens": 390,
      "total_tokens": 22069
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention annotation being done by a single human annotator who is a subject matter expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Dataset Construction, Annotator recruitment",
            "reasoning": "The dataset was annotated by 30 annotators who underwent training sessions and onboarding to ensure quality. The paper describes detailed guidelines and accuracy thresholds, indicating that these annotators have a level of expertise relevant to the task."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that a single non-expert annotated the data."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper explicitly mentions training and accuracy thresholds for annotators, suggesting that annotators are knowledgeable rather than non-experts."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.1 Dataset Construction, Data collection",
            "reasoning": "For 2D bounding box annotations, the paper adopts a machine-assisted approach using the Grounding DINO model to produce initial bounding boxes which are then filtered and improved by human evaluators. This process involves AI model annotation followed by human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation done solely by AI models without human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although 3D CAD models from Objaverse are used for shape reference, and cross-category alignment is done manually, the actual 3D pose annotations are performed by human annotators rather than an automatic or simulation process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper thoroughly documents a detailed data annotation process involving machine-assisted and multi-human expert annotations."
          }
        }
      }
    ]
  },
  {
    "id": "pUcTrjRLOM-rubric-4",
    "token_usage": {
      "prompt_tokens": 36182,
      "completion_tokens": 496,
      "total_tokens": 36678
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes annotation involving multiple human experts (a team of three biomedical experts), not a single expert. There is no mention of single human expert annotation."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 2.2.2 (Data Annotation) and Appendix C.4 (Details of Human Annotation)",
            "reasoning": "Human annotation was performed by a team of three experts, each with at least three years of biomedical research experience, who reviewed and corrected preference pairs. This confirms multiple human experts were involved in data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention is made of annotation by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper specifies that human annotators were biomedical experts; there is no indication of multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 2.2.2 (Preference Annotation)",
            "reasoning": "Annotations were primarily performed by GPT-4 to assign preference scores and ranks for model completions, with a subset of about 900 model-annotated preference pairs reviewed and corrected by human experts, indicating AI annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "All AI model annotations involving GPT-4 preference scoring were verified by humans for a subset; no mention of AI annotation without any human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation is done by AI models and human experts as described; no indication that annotation was fully automatic or by simulation without AI involvement."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is described extensively in the paper, including human expert correction and AI model preference annotation."
          }
        }
      }
    ]
  },
  {
    "id": "pYNl76onJL-rubric-4",
    "token_usage": {
      "prompt_tokens": 21439,
      "completion_tokens": 359,
      "total_tokens": 21798
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that a single human expert annotated the data."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation process involving multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence is provided that a single non-expert human performed annotations."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of data annotation by multiple non-expert humans."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset construction does not mention use of AI models for annotation with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of annotation performed solely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3 Curating VidProM, specifically 'Assigning NSFW Probabilities' and 'Extracting and Embedding Prompts' and 'Scraping and Generating Videos'.",
            "reasoning": "The dataset is curated primarily by automated methods: prompts and associated metadata are extracted using software tools (regular expressions on Discord chat logs), embedding is performed automatically by OpenAI text embedding models, NSFW probabilities are assigned automatically using the Detoxify model, and videos are generated by diffusion models automatically. There is no mention of human annotators editorially labeling or verifying the data. Thus, the annotation is performed automatically by software and models."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation procedures are described, so it is not N/A."
          }
        }
      }
    ]
  },
  {
    "id": "qmvtDIfbmS-rubric-4",
    "token_usage": {
      "prompt_tokens": 29585,
      "completion_tokens": 411,
      "total_tokens": 29996
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2.4 Data Quality Control, Section A.2.1 Dataset Collection and Access",
            "reasoning": "The paper explicitly states that ten experienced murder mystery game experts annotated the evaluation data, including multiple-choice questions and reasoning chains. Additionally, three other experts were engaged to review these annotations to ensure accuracy and reliability, indicating multiple expert annotators were involved in the data annotation process."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While GPT-4 was used to generate initial distractors for multiple-choice questions, the process is clearly described as followed by human expert refinement and multiple staged expert reviews, indicating that AI involvement is not the direct annotator but an aid, and final annotation is verified by multiple human experts."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence indicates that AI was solely responsible for data annotation without any human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was not done by automatic processes or simulations; it was largely manual with expert human examiners and AI-assisted distractor generation at best."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": ""
          }
        }
      }
    ]
  },
  {
    "id": "r8PnfcWQol-rubric-4",
    "token_usage": {
      "prompt_tokens": 33106,
      "completion_tokens": 357,
      "total_tokens": 33463
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any involvement of a single human annotator or expert performing data annotation for the dataset."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or description in the paper that multiple human experts performed data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any single non-expert human annotator involvement in the data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information about multiple non-expert human annotators involved in the annotation process."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation being conducted by an AI model with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not specify that data annotation is performed by an AI model without any verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Sections 4.1, 4.2, and 5.1",
            "reasoning": "The EFO_k-CQA dataset is constructed using an automatic data generation framework that enumerates abstract query graphs, grounds them automatically on knowledge graphs, computes answers via algorithms (including CSP solving and backtracking), and samples queries systematically. There is no mention of human annotators; the dataset construction is fully automated using computational procedures, simulations, and algorithmic processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper documents a thorough data generation and annotation process using automatic methods, so data annotation is applied and described."
          }
        }
      }
    ]
  },
  {
    "id": "rdv2Fr6JTC-rubric-4",
    "token_usage": {
      "prompt_tokens": 23330,
      "completion_tokens": 455,
      "total_tokens": 23785
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation conducted by a single human annotator who is a subject matter expert or member of the target demographic."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human experts performed data annotation for the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any single non-expert human annotation for the introduced datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no information suggesting multiple non-expert human annotators were involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not discuss any AI model used with human verification for data annotation."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication is given that AI models annotate data without verification in the datasets introduced or used."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 (Definition 3 Utility Function)",
            "reasoning": "The datasets used are publicly available benchmark datasets; the paper does not describe any manual annotation but relies on existing labeled and unlabeled nodes. The data valuation method involves automatic graph processing techniques and computations derived from existing graph data. Thus, annotation is not manual but inherent from existing data and automatically used in experiments."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Although no new annotation process is described, the datasets themselves have labels (some nodes labeled) that are inherited from existing datasets. Therefore, completely no annotation is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "rovpCs3ZEO-rubric-4",
    "token_usage": {
      "prompt_tokens": 26284,
      "completion_tokens": 451,
      "total_tokens": 26735
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": true,
            "reference": "Section 4.1 Training Tasks, Sections F, G, H, I (Appendix)",
            "reasoning": "For the Lung Opacity Detection task, the paper states that medical practitioners at the Society for Thoracic Radiology and MD.ai provided the annotations, indicating expert human annotators. For other tasks like Enlarged Cardiome diastinum Detection, it is mentioned that validation images were manually annotated by three board-certified radiologists and tested by five board-certified radiologists, indicating multiple expert annotations as well. For training tasks that rely on existing datasets, annotations are derived from expert sources, implying data annotation by human medical experts."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section J Validation Task \u2013 Enlarged Cardiomediastinum Detection",
            "reasoning": "The validation set includes 234 images manually annotated by three board-certified radiologists and the test set images were annotated by consensus of five board-certified radiologists. This shows multiple human experts performed annotations for at least one validation task dataset in the curated FEDMEKI dataset suite."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotations performed by a single human non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention is made of data annotations by multiple human non-expert annotators in the dataset curation or dataset descriptions."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that any AI model performed annotations with some human verification for any datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The datasets do not indicate annotation solely by AI models without human verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence of data annotation automatically done by simulation or automatic processes that are not AI models is provided in the paper."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation is documented for all datasets curated from public sources, with known annotation procedures involving human experts or multiple expert radiologists for validation datasets."
          }
        }
      }
    ]
  },
  {
    "id": "s1K5Z5QPog-rubric-4",
    "token_usage": {
      "prompt_tokens": 14888,
      "completion_tokens": 335,
      "total_tokens": 15223
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of data annotation performed by an AI model with verification using human annotations."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that an AI model was used for data annotation without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Observations and Section 3.2 Simulations",
            "reasoning": "The ChaosBench dataset is composed of reanalysis products (ERA5, ORAS5, LRA5) and physics-based model simulations from national weather agencies. These datasets are automatically generated through physical simulations and assimilation processes rather than through human annotation. Therefore, the data annotation corresponds to automatic processes not involving human annotators or AI-based annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is effectively performed automatically through simulations and reanalysis systems; hence this label is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "t9aThFL1lE-rubric-4",
    "token_usage": {
      "prompt_tokens": 31912,
      "completion_tokens": 478,
      "total_tokens": 32390
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention that data annotation was performed manually by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description that multiple human experts performed data annotation for the dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper provides no indication of data annotation done by a single human non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of multiple non-expert humans performing data annotation is found in the paper."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any data annotation by an AI model with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description indicates data annotation by AI without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3: Our Proposal: UNLEARNCANVAS Dataset; Appendix A.3 Collection and Labeling Process",
            "reasoning": "The labels for styles and objects were assigned automatically during dataset construction by collecting seed images from Pexels (real-world photos) and then performing image stylization of each seed image into 60 predetermined artistic styles using the online service Fotor. This stylization process is an automatic process not involving AI model annotation or human annotators. Each image is automatically labeled with both style and object class based on the known seed image and style applied. Thus, data annotation was done automatically through a procedural process involving stylization and labeling, without human annotators or AI models performing annotation."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is documented and performed automatically during the stylization and labeling process."
          }
        }
      }
    ]
  },
  {
    "id": "tPsw4NeLZx-rubric-4",
    "token_usage": {
      "prompt_tokens": 23289,
      "completion_tokens": 272,
      "total_tokens": 23561
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Recording Setup and Workflow",
            "reasoning": "The paper states that gloss videos were recorded with the participation of multiple signers including Auslan experts and deaf individuals. Each video recording was supervised by at least one Auslan expert to ensure the precision of the sign language expression. This indicates multiple human experts were involved in annotating and verifying the dataset to ensure its quality."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Recording Setup and Workflow",
            "reasoning": "The dataset includes sign recordings from volunteers interested in sign language, who do not necessarily possess subject matter expertise in Auslan. Their involvement to enrich sign diversity suggests that multiple human non-experts contributed to the dataset annotations or at least recordings."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": ""
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": ""
          }
        }
      }
    ]
  },
  {
    "id": "tWvVtOW0qg-rubric-4",
    "token_usage": {
      "prompt_tokens": 17577,
      "completion_tokens": 299,
      "total_tokens": 17876
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any dataset annotation performed by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple human experts were involved in the annotation of any new dataset."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention of annotation by a single non-expert human annotator is made."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe annotations conducted by multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset preparation or annotation process does not involve AI model annotation verified by humans."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No description of AI model-only annotation without verification is present."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The datasets used are existing publicly available datasets with no automated annotation process described for new datasets in this work."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper does not introduce any new datasets requiring annotation. All datasets used are existing, publicly available datasets from prior works, such as MedMNIST and ImageNet, and no new annotation efforts are described. Thus, no data annotation process is applicable."
          }
        }
      }
    ]
  },
  {
    "id": "vyraA7xt4c-rubric-4",
    "token_usage": {
      "prompt_tokens": 22394,
      "completion_tokens": 382,
      "total_tokens": 22776
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was conducted by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication in the paper that multiple human experts participated in data annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence that a single human non-expert conducted data annotation."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention data annotation by multiple non-expert human annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset construction does not involve annotation by AI models with human verification. Solutions are collected from historical Leetcode submissions."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of AI models annotating data without verification."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 2 (Mercury Datasets) and Section 2 (Test Case Generator); Appendix A.3 (Sandbox Details)",
            "reasoning": "The dataset's solutions are collected automatically from Leetcode historical submissions without manual annotation. Test case generation is automated via generators created by GPT-4 and validated through the Leetcode Online Judge (OJ) system. The execution of code and measurement of runtime occur in an automated sandboxed environment. Therefore, annotation is done by an automatic process (test case generation and solution collection) that is not AI model annotation per se but an automatic process, satisfying this category."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data is clearly collected and processed via automatic methods and there is annotation-like processing via test case generation, so N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "wOmtZ5FgMH-rubric-4",
    "token_usage": {
      "prompt_tokens": 34934,
      "completion_tokens": 418,
      "total_tokens": 35352
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any annotations performed solely by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication or description of multiple human experts conducting annotations."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information suggests data annotation was done by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Data Collection and Construction; Appendix E.1",
            "reasoning": "The dataset probes are generated initially by GPT-4, an AI model, and then filtered using mainstream open-source models. After automatic filtering, the probes are manually checked by humans, described as students in the data collection process, for correctness and format. These humans are likely non-experts as they are students and the paper does not mention their expertise. Thus, multiple human non-experts conducted the verification step of annotation."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2 Data Collection and Construction",
            "reasoning": "The initial data annotation (generation of probes) is performed by GPT-4, an AI model, with subsequent verification involving human checks to ensure format and correctness. This indicates the annotation process involved AI model generation plus human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper clearly states that the GPT-4 generated data is filtered by models and manually checked, indicating verification is performed, so this label does not apply."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Though GPT-4 generation and automatic filtering are involved, these are AI-based and human-verified steps, so automatic annotation without AI or human verification does not apply."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Data annotation is clearly documented and performed using AI generation combined with human verification; therefore, N/A does not apply."
          }
        }
      }
    ]
  },
  {
    "id": "wmO7z57wNK-rubric-4",
    "token_usage": {
      "prompt_tokens": 18992,
      "completion_tokens": 325,
      "total_tokens": 19317
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any data annotation performed by a single human expert for the new datasets or tasks."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description of multiple human annotators with expertise annotating new datasets in the paper."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication or mention of data annotation by a single non-expert human annotator is present."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not report using multiple non-expert annotators for data annotation of new datasets."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention of data annotation performed by AI models with human verification for any new datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation performed solely by AI models without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although the benchmark uses many public datasets to evaluate model compression, there is no indication that new datasets introduced by the authors were automatically annotated or generated by simulation or automatic processes."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper introduces LLMCBench, a benchmark consisting mainly of evaluations on existing public datasets for various tasks; it does not describe any new dataset creation or annotation process. Therefore, no data annotation is documented for new datasets."
          }
        }
      }
    ]
  },
  {
    "id": "x8RgF2xQTj-rubric-4",
    "token_usage": {
      "prompt_tokens": 42603,
      "completion_tokens": 446,
      "total_tokens": 43049
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not state that data annotation was performed by a single human expert. The datasets used (ImageNet-1k, ImageNet-ReaL, CIFAR-10, CIFAR-10H) are pre-existing datasets; no new datasets or annotations are introduced by the authors."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no mention that multiple human experts performed the annotations on any new dataset. The paper uses existing datasets with established annotations but does not describe any new annotation process by multiple experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any annotation by a single non-expert. There is no new dataset introduced with annotation by a single non-expert."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation process involving multiple non-expert annotators is described for new datasets. The paper uses existing datasets without describing new annotations from such annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any new dataset annotated by an AI model with human verification. No new data annotation process of this kind is documented."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No new dataset is introduced whose annotation is performed solely by AI without verification, according to the paper."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that any new dataset is automatically annotated via simulation or an automatic process unrelated to AI models. The benchmark uses existing well-known datasets."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper does not introduce any new datasets or describe any new data annotation process. It focuses on benchmarking existing uncertainty estimation methods using pre-existing datasets such as ImageNet-1k, ImageNet-ReaL, CIFAR-10, and CIFAR-10H, all of which have previously established annotations. Therefore, no data annotation process is documented or performed by the authors on new datasets."
          }
        }
      }
    ]
  },
  {
    "id": "y09S5rdaWY-rubric-4",
    "token_usage": {
      "prompt_tokens": 21741,
      "completion_tokens": 515,
      "total_tokens": 22256
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention any manual annotation performed by a single human expert. The annotations are not described as human-generated."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that multiple human experts were involved in data annotation. All annotation is either automatic or generated via simulation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no evidence in the paper that a single non-expert human annotated the data."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that multiple non-expert humans participated in annotating the data."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper describes data collection by an expert AI model 'Think2Drive' in simulation, but does not mention any human verification of these annotations."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data annotation is done using simulation APIs and not by an AI model predicting annotations, thus this label is not applicable."
          },
          "Automatic": {
            "is_applicable": true,
            "reference": "Section 3.1 Data Collection Agent; Section 3.2 Expert Dataset; Appendix A Details of Data Collecting",
            "reasoning": "The dataset is collected fully automatically in the CARLA simulator environment by running the expert model 'Think2Drive' agent. Annotations such as 3D bounding boxes, depth, semantic segmentation, HD-Map, and RL value estimations are obtained automatically through CARLA APIs. There is no mention of human manual labeling; instead, the paper explicitly states the use of official APIs and discusses some API bugs that they compensate for manually in processing, but the annotation data itself is generated automatically by simulation or automatic processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "Annotation is clearly described and present in the dataset, so this label is not applicable."
          }
        }
      }
    ]
  },
  {
    "id": "y10DM6R2r3-rubric-4",
    "token_usage": {
      "prompt_tokens": 29439,
      "completion_tokens": 491,
      "total_tokens": 29930
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention data annotation by a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.2 Dataset Construction Pipeline - Expert Review",
            "reasoning": "The dataset underwent an expert review process involving multiple human experts who verified the accuracy of answers, removed bad questions, and validated distractors. This two-phase expert review described in Section 3.2 ensures high quality and low noise of the dataset, indicating involvement of multiple human experts."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no indication that annotation was performed by a single non-expert human annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No evidence or description supports that multiple non-expert annotators were involved."
          },
          "AI Model with Verification": {
            "is_applicable": true,
            "reference": "Section 3.2 Dataset Construction Pipeline - Option Augmentation and Expert Review",
            "reasoning": "AI models, specifically GPT-4-Turbo and Gemini-1.5-Pro, were used to generate and augment options and to identify false negative options, respectively. However, these AI-generated annotations were followed by human expert verification of the correctness and validity of options. Thus, data annotation was performed by AI models with subsequent human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "All AI-generated annotations were verified by human experts, so no AI-only annotation without verification took place."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation was not done by a simulation or an automatic process without AI involvement; AI models were used with human verification."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The dataset involved an explicit annotation process combining human expert reviews and AI-generated annotations with verification."
          }
        }
      }
    ]
  },
  {
    "id": "yS1dUkQFnu-rubric-4",
    "token_usage": {
      "prompt_tokens": 19254,
      "completion_tokens": 322,
      "total_tokens": 19576
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not provide any information indicating that data annotation was performed by a single human expert for any of the datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There is no description in the paper about multiple expert annotators performing the data annotation process for the datasets."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not mention data annotation by a single non-expert annotator for any of the datasets."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No information is given in the paper regarding multiple non-expert human annotators involved in data annotation."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any dataset annotation process involving AI models with human verification."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No mention is made about datasets being annotated by AI models without verification in the paper."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe any automated or simulation-based annotation method for the datasets."
          },
          "N/A": {
            "is_applicable": true,
            "reasoning": "The paper utilizes 30 existing datasets selected from well-known sources, but it does not document any new data annotation process performed by the authors. Annotation details are not described or new annotations introduced; thus, no data annotation process is documented for the new benchmark datasets."
          }
        }
      }
    ]
  },
  {
    "id": "yUEBXN3cvX-rubric-4",
    "token_usage": {
      "prompt_tokens": 22315,
      "completion_tokens": 349,
      "total_tokens": 22664
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper states that the dataset was collected using crowdsourcing with 20 annotators who were paid contractors. There is no indication that these annotators were subject matter experts or members of the target demographic."
          },
          "Multiple Human Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Although multiple annotators participated, the paper does not provide any information indicating that these annotators were subject matter experts or belonged to the target demographic."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The dataset collection involved multiple annotators, not a single annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Data collection",
            "reasoning": "The dataset was collected via crowdsourcing involving 20 annotators who were paid contractors. The paper does not indicate that these annotators had particular expertise or belonged to the target demographic. They underwent training for several weeks but are described as crowdworkers, indicating non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The annotations were not performed by an AI model with verification; data was collected solely via human annotators."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No indication that any AI model was used to annotate data without verification."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Data annotation was performed by human annotators, not an automatic or simulated process."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents that data annotation was applied via collection with human annotators."
          }
        }
      }
    ]
  },
  {
    "id": "z64azPC6Nl-rubric-4",
    "token_usage": {
      "prompt_tokens": 19854,
      "completion_tokens": 379,
      "total_tokens": 20233
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper and appendix describe multiple annotators with musical and language expertise performing the annotation tasks, not a single human expert."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.3 Annotation; Appendix A.2 Details of Annotation",
            "reasoning": "Data annotation was performed by multiple experts with music and language backgrounds who corrected alignments and performed phoneme-level annotations of singing techniques and global style labels. Additional music experts also performed quality checks on 25% of annotations for each language, evidencing the involvement of multiple human experts in annotation."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotators were experts with musical and language backgrounds, not non-experts."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper specifies annotators as experts with relevant domain knowledge, not non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "While the Montreal Forced Aligner (an AI model) was used for initial coarse alignment, all annotations were extensively verified and corrected by multiple human experts; the AI model was not used alone for annotation but as an initial tool before expert correction, so this label does not fully apply."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "There was no use of AI model annotation without human verification; all AI-assisted annotations were followed by expert correction."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "Annotation was not fully automatic; initial forced alignment was automated but always followed by expert human corrections and labeling."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper clearly documents a detailed manual annotation process involving multiple human experts."
          }
        }
      }
    ]
  },
  {
    "id": "zogaeVpbaE-rubric-4",
    "token_usage": {
      "prompt_tokens": 23139,
      "completion_tokens": 393,
      "total_tokens": 23532
    },
    "response": [
      {
        "data_annot": {
          "Single Human Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not describe data annotation by a single human expert for any of the new datasets."
          },
          "Multiple Human Experts": {
            "is_applicable": true,
            "reference": "Section 3.1 Tasks and Table 4 Participant demographics",
            "reasoning": "DEVBENCH includes several datasets of child and adult behavioral data collected through experiments involving multiple human participants with relevant expertise in developmental experiments and testing conditions. For example, the lexical tasks include data from multiple child participants collected with structured experimental protocols by researchers. The human data collection involved multiple human participants who can be considered experts in developmental testing due to the controlled experimental setups and target demographic (infants, children, adults) participation over studies referenced and described in Section 3.1 and Table 4. Thus, data labeling involves multiple human experts or members of the target demographic."
          },
          "Single Human Non-Expert": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The paper does not indicate that any dataset was annotated by a single non-expert annotator."
          },
          "Multiple Human Non-Experts": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data comes from controlled behavioral studies with target demographics or experts; no indication exists of data annotation by multiple non-expert annotators."
          },
          "AI Model with Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation performed by AI models with verification is described for these datasets."
          },
          "AI Model without Verification": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "No annotation performed solely by AI models without verification is described for these datasets."
          },
          "Automatic": {
            "is_applicable": false,
            "reference": "",
            "reasoning": "The data is derived from behavioral experiments with human participants, not through simulations or automatic annotation processes."
          },
          "N/A": {
            "is_applicable": false,
            "reasoning": "The paper introduces new datasets with human data; thus, annotation is present and described."
          }
        }
      }
    ]
  }
]